[
  {
    "id": 37466027,
    "title": "The Project Gutenberg Open Audiobook Collection",
    "originLink": "https://marhamilresearch4.blob.core.windows.net/gutenberg-public/Website/index.html",
    "originBody": "About Listen Code Paper Accountability The Project Gutenberg Open Audiobook Collection Thousands of free and open audiobooks powered by Microsoft AI About Project Gutenberg and Microsoft have worked together to create thousands of free and open audiobooks using new neural text-to-speech technology and Project Gutenberg's large open-access collection of e-books. This project aims to make literature more accessible to (audio)book-lovers everywhere and democratize access to high quality audiobooks. Whether you are learning to read, looking for inclusive reading technology, or about to head out on a long drive, we hope you enjoy this audiobook collection. Listen Code Paper For more technical information on the code used to generate these audiobooks please see our IEEE Big Data paper: Large Scale Intelligent Microservices Bibtex: @article{hamilton2020large, title={Large-Scale Intelligent Microservices}, author={Hamilton, Mark and Gonsalves, Nick and Lee, Christina and Raman, Anand and Walsh, Brendan and Prasad, Siddhartha and Banda, Dalitso and Zhang, Lucy and Zhang, Lei and Freeman, William T}, journal={arXiv preprint arXiv:2009.08044}, year={2020}} Accountability The audiobooks here are generated by new neural text to speech technology and automated parsing of the e-books in the Project Gutenberg collection. Some audiobooks may contain errors, strange pronunciations, offensive language, or content not suitable for all audiences. The language and views presented in these audiobooks are do not represent the views of Microsoft or Project Gutenberg. To report an issue with a recording please visit https://aka.ms/audiobook-issues.",
    "commentLink": "https://news.ycombinator.com/item?id=37466027",
    "commentBody": "The Project Gutenberg Open Audiobook CollectionHacker NewspastloginThe Project Gutenberg Open Audiobook Collection (windows.net) 376 points by isbn 21 hours ago| hidepastfavorite154 comments ferfumarma 2 minutes agoThirty five seconds in to the very first link [1] and I hear the phrase \"kon-fee de rate\". It took me five seconds to realize the AI can&#x27;t pronounce \"confederate\".[1] https:&#x2F;&#x2F;archive.org&#x2F;download&#x2F;synapseml_gutenberg__quot_run_t... reply xrd 20 hours agoprevWhen I read Rikki Tikki Tavi to my 8 yr old daughter, we play a game. She asks me to change one of the words in the page and she tries to listen and see if she can figure it out. It is mentally taxing at the end of a long day to do that on the fly without pausing to figure out the word to slip in. And, my daughter is very sharp and catches them.I listened to a few of these. The voice sounds muted at times, as if the reader has a stuffy nose. H.G. Wells was read with a pause in between each period because it \"thinks\" that each letter boundary is a sentence change, which drove me batty. And, there is zero life in the stories. It might be a good thing to put in front of a kid to put them to sleep, maybe? But, it would not put me to sleep because it is just aggravating to listen to these stories stripped of all life by AI.Like Louis CK said: \"Everything is amazing and no one is happy.\" I know this is incredible that AI can take in a transcript and produce something that most people would be able to distinguish between a real human. But, we should ask if you would want to hang out with the voice actor at a party. reply ecshafer 19 hours agoparent> Like Louis CK said: \"Everything is amazing and no one is happy.\"Everything is not amazing. Sure things are amazing from a technical perspective. But most tech advancements I think have been harmful to society in the last 30 years or so. Its awesome that computers are so powerful and we have awesome video and photos and can share things so easily. But technology should better lives, and not cheapen it, which it often does. Tech is being used to try and replace essential human lived experiences to try and inject advertising into it and extract money.Technology can not replace the human, its impossible. No matter how good the AI is at reading the book, it will never replace sitting next to your parent and them reading it. No matter how easy it is to share a video or a photo, it will never replace sitting next to someone and them showing you photos, or better yet being there when the photo was taken. reply jzb 16 hours agorootparentI forget the exact quote but the thing I&#x27;ve seen making the rounds sums it up pretty well: Computers were supposed to do the work so people could make art and write poetry. Now the computers are making art and writing poetry and I still have to have a job.In another life I&#x27;d love to do voice over work. (I even have a face for radio!) But, instead, technology is being used to avoid even having humans do that type of work. Sure, today it&#x27;s PG, but they&#x27;re definitely doing this with an eye to replacing actual voiceover actors.Every advance in AI is \"how can we replace people and save money?\" and not \"how can people have better lives and work less?\" And it&#x27;s going to continue until it&#x27;s \"what the fuck do we do with all these jobless people who&#x27;ve been replaced?\" reply cxr 14 hours agorootparentAs software developers, we know what getting workers to have better lives while working less looks like. There&#x27;s some sleight of hand at play, though, in the employer&#x2F;employee relationship (favoring the employer).> Every advance in AI is \"how can we replace people and save money?\" and not \"how can people have better lives and work less?\"It&#x27;s not just AI, but technology generally. And it&#x27;s because when it comes to managing people, organizations for the most part don&#x27;t actually concern themselves with getting their employees to produce value—that is, whether they are, and how much, and at what cost (to the business) it comes at, and where that measure of productivity lies (objectively) when scored against some rubric. Instead what they make their most immediate concern is whether their employees are exposed to sufficient toil. Look at any example that involves someone accepting a new job with a set of work duties&#x2F;expectations where they proceed to automate part of their workload and thus provide the same value (or more) in comparison to what they were doing before, or in comparison to their coworkers, or in comparison to whomever would have ended up with the job if the person who did accept and automate it had accepted an offer elsewhere instead: they end up soliciting feedback (or opining themselves) about whether what they&#x27;re doing is unethical.This is the mechanism that wealth disparity through concentration of wealth comes from, but everyone (the employer and the employee alike) walks around as if they either don&#x27;t notice it or—if they do—as if it&#x27;s wrong when there&#x27;s a known path for the concentration to flow upward but it isn&#x27;t happening. reply WalterBright 5 hours agorootparent> favoring the employerIf you&#x27;ve ever been an employer, you&#x27;d be disabused of that quickly. reply WalterBright 5 hours agorootparentprevWealth in a free market is not concentrated, it is created. It does not \"flow\", either, as free trades are an exchange of value, not a flow of value.Wealth disparity comes from people creating different amounts of value. reply timmb 1 hour agorootparentI think it’s more complex than that. Wealth is often created by monopolising things (e.g. enclosures) instead of by creating them. reply RichEO 38 minutes agorootparentprevOn what do you base these statements? reply WalterBright 5 hours agorootparentprev> what the fuck do we do with all these jobless people who&#x27;ve been replaced?Around 1800, 93% of labor in America worked on farms. Today we have jobs that were unimaginable in 1800.> \"how can we replace people and save money?\" and not \"how can people have better lives and work less?\"Those two are actually the same thing. reply RichEO 35 minutes agorootparent> Those two are actually the same thing.How exactly are they the same thing? It seems that the savings are made by the employer here at the expense of the employee.There’s no guarantee that the savings will be passed on as price cuts. reply WalterBright 5 hours agorootparentprev> I&#x27;d love to do voice over workVoice over work and screen actors put stage actors and burlesque workers and traveling minstrels out of business. reply Towaway69 15 hours agorootparentprevIt will probably all fall apart when there is no one left to purchase this stuff, no job, no money, no purchasing power.Once purchasing power has evaporated, then and only then will the system change.Alternatively AI will also replace the jobless. reply toomuchtodo 14 hours agorootparentI wouldn&#x27;t blame folks wanting to work on fast takeoff AI with no human alignment concerns. Heads, the world ends because you&#x27;ve bootstrapped something unsympathetic and more powerful than humanity. Tails, you&#x27;ve bootstrapped something that might be able to overpower entrenched interests, providing a chance at a better societal outcome. reply civilitty 14 hours agorootparentprevWe&#x27;ll invent a third World War long before that happens - to thin the herd and remind everyone using rationing and austerity about how great consumerism is, while creating plenty of jobs rebuilding the industrialized world. reply m463 13 hours agorootparentprev> Every advance in AI is \"how can we replace people and save money?\"I think what happens is that the repeat jobs are automated, and the (remaining) people get the hard corner cases. reply mvdtnz 13 hours agorootparentI think the thing that has surprised everyone in this revolution is that the opposite has happened. Musk wasted billions trying to automate vehicle manufacturing while AI is threatening to take the jobs of novelists and graphic designers. reply satvikpendem 8 hours agorootparentIt hasn&#x27;t been a surprise to anyone in the field. Turns out it&#x27;s much easier to read digital content in the form of bits then to read real world data. Hardware is harder than software. reply brigandish 7 hours agorootparentprevOn the other hand, I am reminded of a quote by Christopher Hitchens (from memory), “They say that everyone has a book in them. For most of them, it would be better if it stayed there\".Some of the films and TV programmes I&#x27;ve watched recently have made me wonder, as I gaze across at the writers on strike who have some legitimate concerns but who have also provided some bloody awful writing, if I wouldn&#x27;t prefer AI to take over the production of art - it certainly wouldn&#x27;t be able to produce a messy bed, would it? That&#x27;d be a win too.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;My_Bed reply MrVandemar 4 hours agorootparent> I gaze across at the writers on strike who have some legitimate concerns but who have also provided some bloody awful writingToo often the writing of film and TV is dictated by the producers&#x2F;studio -- people who have an interest in financial returns, not quality. Those writers would probably love to write their own show, their way, unhindered, and would probably produce something watchable.Of course, writers subvert their instructions sometimes to great effect. On BSG I believe they were told their show was \"too dark\" and someone insisted someone have \"a birthday party\". Which they duly put in, and then had them all die in some kind of terror&#x2F;bomb incident. reply WalterBright 5 hours agorootparentprev90% of books and movies are not worth the time to read or watch. reply mistrial9 13 hours agorootparentprev> Every advance in AI is \"how can we replace people and save money?\"this is not true now, and also does not have to be true. Instead of a \"look at the incentives\" talk to someone having a bad comment moment.. instead we can be reminded of Doug Englebart, who said \"computer systems can augment human intelligence and team interaction\" and specifically NOT \"replace humans\" .. As I understand it, in Palo Alto, Doug found great interest among the DoD crowd .. a good portion of whom would have a second meeting after his demos, and then discuss how they can get back to the important work of replacing people.Consider the incentives, consider who has an interest in this hype cycle, and sales profits. When you see a US visit to Vietnam this week, with MSFT pitching \"social trust\" AI services to \"ordinary people\" .. does this really sound like trust in the making? Is AI drones in combat really what we need now ? Replacing striking Hollywood writers and getting name-brand actors for pennies on the dollar, is that what \"we\" need?I do not agree that AI can only replace people.. however, there is a lot of short term profit and control ready for those that do.. maybe something needs to be done about that? reply OfSanguineFire 18 hours agorootparentprev> it will never replace sitting next to someone and them showing you photosIt definitely does replace that. It sucks so much to be trapped next to someone showing you their photo album or vacation slides, when you don’t really care, that this became a stock scene in 20th-century comedy TV series and films. Nowadays when people are sharing their photos online, that gives their peers the choice of whether to look or whether to ignore, and that is immensely freeing. reply ecshafer 17 hours agorootparentThe photo slide show of someone&#x27;s vacation was a stock scene in comedies. But have you never sat down with family and went through old photos? Having conversations about where was that? who was this? who was this as a baby? Its a very different and much more personal experience than flipping through facebook. reply TedDoesntTalk 17 hours agorootparentHe cherry-picked one of the three examples in your post and attacked it. He won&#x27;t choose the other two because he has no argument for them. Ignore. reply c0pium 12 hours agorootparentprevSure have, it’s hellacious. I don’t give a fuck about who that baby was, why would I? Relations who my parents only vaguely remember going somewhere boring that I would never go, or someone’s 12th trip to the same lake, is a great use for Facebook. Most people are crazy boring, if I care I can always ask. reply lolinder 7 hours agorootparentTo quote a GP comment:> But most tech advancements I think have been harmful to society in the last 30 years or so.I thought this was overly cynical until I read your comment. Now I&#x27;m not so sure. Has our attention span really become so shot that just being with family has become a chore, and we&#x27;d rather our parents just post their life stories into the void that is Facebook? reply mathgeek 17 hours agorootparentprevYou’re talking about _being shown_ photos you don’t care about, while GP is talking about showing your own photos to someone. I agree with the example you’re discussing, though. reply c0pium 12 hours agorootparentAh, you’re talking about main character syndrome. Showing pictures to someone is one of the cruelest things you can do; you’re probably boring and a terrible storyteller (most people are) but they’re going to feel obligated to not tell you that.It’s always amazing to me that people almost universally hate other people’s slideshows, and then don’t have the self awareness to realize that they do the exact same thing. reply edgarvaldes 11 hours agorootparent>Showing pictures to someone is one of the cruelest things you can doSo you are saying that friends, family and significant others better no share old photos and memories with you? Because that is one of the cruelest things to do? reply karmelapple 13 hours agorootparentprevI&#x27;d suggest reading How to Do Nothing by Jenny Odell [1]. I think it addresses some of the concerns you have.1. https:&#x2F;&#x2F;www.goodreads.com&#x2F;en&#x2F;book&#x2F;show&#x2F;42771901 reply janekm 20 hours agoparentprevElevenlabs is a lot closer to compelling audiobook narration (needs a better way to deal with multiple characters in a story without manual use of multiple voices): https:&#x2F;&#x2F;pub-a24da573c61f4b2d905bdebb2d0ecf88.r2.dev&#x2F;ElevenLa... (an H.G.Wells example I just asked it to read). reply petemir 19 hours agorootparentftfyhttps:&#x2F;&#x2F;pub-a24da573c61f4b2d905bdebb2d0ecf88.r2.dev&#x2F;ElevenLa... reply janekm 18 hours agorootparentthanks! reply tkgally 20 hours agorootparentprevI was going to mention ElevenLabs, too. Their samples are very impressive in how the intonation and word stress are varied based on the text’s meaning. Their pricing is a bit high for personal use, though.(The link you posted seems to have been truncated. Can you try posting it again?) reply janekm 18 hours agorootparentYeah, sadly it&#x27;d cost about $100 to get a book per month... Not quite competitive with Audible yet, but give it a year perhaps, or a few iterations of the open source models... (fixed the link) reply shaky-carrousel 14 hours agorootparent100 dollars per book, right, but that book is public and can be shared between millions of people. reply satvikpendem 8 hours agorootparentprevAny open source alternatives? reply janekm 1 hour agorootparentNone of the open source models I&#x27;ve seen are as \"well-rounded\", production ready as Eleven Labs. Though for example bark is really great at prosody: https:&#x2F;&#x2F;suno-ai.notion.site&#x2F;Bark-Examples-5edae8b02a604b54a4... And piper isn&#x27;t bad at speech quality: https:&#x2F;&#x2F;rhasspy.github.io&#x2F;piper-samples&#x2F;We might only be a few papers away from a good open source Elevenlabs competitor. reply prepend 20 hours agoparentprev> But, we should ask if you would want to hang out with the voice actor at a party.I think the question is really “Will I be able to enjoy great books I otherwise would not have experienced?”For me, it’s not that these are superior or equivalent books to parents reading to their kid or voice actors; it’s whether I’ll listen to a book for free that I wouldn’t be able to afford $10-30. reply therealdrag0 2 hours agorootparentPlus lots of books don’t have audiobooks. I’ve a few sitting on my to read list for years on end just cuz there’s no audio. Being able to make one myself with AI would be awesome. reply low_tech_love 19 hours agorootparentprevAudible is $7.95 a month and you can listen to whatever book you want (like Spotify). If you’re not willing to go even with that in order to listen to an actual human, then maybe yeah, you can try AI. reply philomath_mn 19 hours agorootparent> Audible is $7.95 a month and you can listen to whatever book you want (like Spotify)Not true at all. Audible Plus gives you access to a tiny subset of the full library, the rest (which includes all the best titles) need to be purchased separately. reply bodge5000 15 hours agorootparentUnless things have changed since I was a subscriber, you get a token every month which can be used to purchase any book from the full library. So its effectively 1 book a month + a few extras bonuses for $7.95 reply izzydata 15 hours agorootparentYou don&#x27;t get a token without paying for the premium plan at $15 a month. Also, don&#x27;t tell anyone but if you subscribe and then cancel and give the reason that it is too expensive you can often get a reduced price the next few months. reply servercobra 19 hours agorootparentprevIt&#x27;s not at all like Spotify. The library you get for $7.95&#x2F;mo is very limited. If it was like Spotify I&#x27;d happily pay a hell of a lot more than that. reply prepend 17 hours agorootparentprevAudible is $15&#x2F;month and you get to choose one title.I think you’re confusing audible today with audible of 20 years ago. reply thinkmassive 16 hours agorootparentI typically buy at least two titles per month, and the best deal ended up being:Audible Premium Plus - 1 Credit Every Other Month for $17 ($8.50&#x2F;mo)You can buy 3 more credits for $37.99 (12.66&#x2F;ea). It’s also worth checking individual titles because quite a few cost less than the credits.Correction: I guess I actually buy slightly fewer than 2&#x2F;mo because there’s a plan for that ($22.95&#x2F;mo) that’s cheaper than the 27.50&#x2F;mo from my numbers above. I had that one for a while but ended up feeling pressured to use them before they expire. reply swores 13 hours agorootparentYou probably won&#x27;t be interested since it&#x27;s even more pressure to use them before they expire, but there&#x27;s also annual plans which are even cheaper if you can be happy using 12 (or 24) tokens within 12 months (you get them at the start and they expire at the end of the year):Audible Premium Plus Annual - 12 Credits $149.50&#x2F;year (way cheaper in UK: £69.99&#x2F;year)Audible Premium Plus Annual - 24 Credits $229.50&#x2F;year (£109.99&#x2F;year)US: https:&#x2F;&#x2F;www.audible.com&#x2F;ep&#x2F;memberbenefits UK: https:&#x2F;&#x2F;help.audible.co.uk&#x2F;s&#x2F;article&#x2F;what-are-the-different-...Although, as soon as I&#x27;m logged in with my account (UK) which had subscribed in the past but isn&#x27;t currently, it doesn&#x27;t seem to be giving me any options except to start a 1 month free trial for 1 token&#x2F;month, not sure if other options aren&#x27;t available or just extremely well hidden...edit: no it is available for my account, though I&#x27;m going to remain a non-subscriber and keep using my local digital library :) reply thinkmassive 11 hours agorootparentHah thank you, the optionality is worth $0.20&#x2F;mo to me.I wish there were better options for listening 20-25 hours&#x2F;mo. Like Amazon in general, the selection + convenience is tough to beat. replybarrenko 20 hours agoparentprevWe&#x27;re living through the Great Enshitification. reply fuzztester 12 hours agorootparentAnd it is living through us, or on us. reply lynx23 3 hours agoparentprevNow you have a pretty good idea how blind people must feel. Yes, a good audiobook should be read by a human. But if you dont have that, speech synthesis is the best or even only thing you can get. And then, many years later, you read a post like yours. And you realize that man is spoiled.Signed, a blind man reply gnutrino 18 hours agoparentprevSeth Godin did a whole Akimbo podcast that was written by ChatGPT, and the audio was AI generated. The voice was spot on, the content and delivery was dead. I almost fell asleep listening to it, which is NEVER the case for any other episode of Akimbo I&#x27;ve listened to. reply Pxtl 20 hours agoparentprev> H.G. Wells was read with a pause in between each period because it \"thinks\" that each letter boundary is a sentence changeThis is why I&#x27;m a firm \"two spaces after the period\" guy. Makes it unambiguous the difference between the abbrevs. period and the sentence-end period. Otherwise you get sentences like \"Let&#x27;s not forget that Dr. Principal does not care about this.\" which can be read in two valid ways. reply bloak 19 hours agorootparentOf course some style guides would tell you not to put a dot after \"Dr\" because \"r\" is the last letter of \"Doctor\". Similarly, the abbreviation of \"Saint\" would be \"St\", while the abbreviation of \"Street\" would be \"St.\", according to those style guides.Meanwhile the GB military style guide says never to use a dot after any abbreviation, I think.Also, the style guides I&#x27;m familiar with prescribe \"H. G. Wells\", rather than \"H.G. Wells\", but \"H.G.W.\" if you&#x27;re abbreviating all of the words.None of this is of much interest to anyone who isn&#x27;t an editor but I thought I&#x27;d mention it anyway. reply Pxtl 18 hours agorootparent> \"H. G. Wells\",Right. That&#x27;s probably the most common historical form, and is a good example of how the punctuation for sentence-ends and abbreviations is often the same - period and then single-space. reply cxr 19 hours agorootparentprevThis trick doesn&#x27;t work across linebreaks (unless you adopt a rule like \"treat the spaces in the nouns as non-breaking and do not permit a linebreak for anything that isn&#x27;t a sentence boundary\"). reply bloak 18 hours agorootparentEmacs does (or did) exactly that, perhaps by default: I think I had to disable it once because it was annoying me ... (setq sentence-end-double-space nil)? reply cxr 13 hours agorootparentNot the same thing. reply ta988 19 hours agorootparentprevSidenote, I asked ChatGPT about where to put the comma and how it would change the meaning of the sentence. It got it right. reply Pxtl 19 hours agorootparentFair point, the sentence I invented off the top of my head isn&#x27;t perfectly grammatically correct but it&#x27;s close-enough that it shows the ambiguity problem. It&#x27;s a lot to ask text-to-speech and typesetting programs to figure out contextually which periods are abbreviations and which periods are end-of-sentence, and so having a hard text cue like double-space would help. Then typesetters would have a hard cue of when to replace the space with a thin-space (which is supposed to happen in the case of something like \"H. G. Wells\"). reply jtbayly 16 hours agorootparentprevHow does it feel to have websites and books and newspapers and practically every other place silently ignore your double spaces and treat them as a single space? replydidntcheck 21 hours agoprevSee also: Librivox [1], for public-domain audio books read by actual humans[1] https:&#x2F;&#x2F;librivox.org&#x2F; reply bunderbunder 20 hours agoparentLit2Go is also good: https:&#x2F;&#x2F;etc.usf.edu&#x2F;lit2go&#x2F;The sibling poster is right, the quality varies. But the upper end of the quality range is really quite good. One of the best-read audiobooks I&#x27;ve ever heard was a Lit2Go edition of Pygmalion. And, for that matter, one of the worst-read audiobooks I&#x27;ve ever heard was an edition of an extremely famous and commercially successful book that I bought on Audible. reply low_tech_love 21 hours agoparentprevAre you a specist? Why should we value more an audiobook that&#x27;s read by a human?Sorry, just joking. But here&#x27;s a reason: these things were not quality-checked at all. Click on Moon Voyage by Jules Verne and be greeted with a very human-like voice reading an numbered list of \"other works by the author\" in an extremely awkward fashion that&#x27;s probably caused by how the .TXT file is organized. reply yorwba 21 hours agoparentprevMost likely the AI was actually trained on LibriVox, potentially even on largely the same books...EDIT: The first book on the list https:&#x2F;&#x2F;marhamilresearch4.blob.core.windows.net&#x2F;gutenberg-pu... is \"100%: the Story of a Patriot\" and the LibriVox version is at https:&#x2F;&#x2F;librivox.org&#x2F;100-the-story-of-a-patriot-by-upton-sin... reply DanielleMolloy 17 hours agorootparentNot a good idea then. The librivox experience turned me away from professionally read audiobooks for far too long.Amateur readers are hit & miss. A lot of professional readers are actors or have a lot of experience. There is a reason people do pay for professionally read books instead of electronic reading or librivox only. reply JKCalhoun 20 hours agoparentprevThanks, I&#x27;m happy this exists. I think I&#x27;ll start contributing this fall. reply tmountain 19 hours agoprevI was kind of hoping this was going to be human beings contributing read aloud versions of Gutenberg content. Since it’s not, I’ll propose a cool project. Raise money to enlist high quality voice actors to create audiobooks from Gutenberg. Release these audiobooks to the world for free. Which books come first could be voted upon. As someone who has used TTS a Lot in recent projects, I’m not excited about listening to AI read a book to me. It feels soulless. reply crop_rotation 18 hours agoparentI have used TTS in the past and in the last few years there has been a quantum leap in TTS quality. A similar such leap in the next few years and it will dominate the audiobook scene for good or bad. reply totetsu 59 minutes agorootparentDoes anyone know of and TTS available now that doesn&#x27;t completely muck up foreign words? I know you can make custom pronouncing dictionaries to use with some of the open source ones, but I wonder if any of the more modern systems are good for this. I have been listening to the english news podcast from a japanese news paper that is made with TTS and it gets its one job, pronouncing Japanese names and places completely jarringly wrong. reply hedora 18 hours agorootparentprevAI might dominate, but it would be a loss. Here’s a tutorial explaining modern audio fiction:https:&#x2F;&#x2F;www.drabblecast.org&#x2F;2018&#x2F;07&#x2F;30&#x2F;inside-drabblecast-au...(In audio format, of course; roughly 1.5 hours)————This episode takes you inside Drabblecast audio production. Ever wonder how we produce an episode of the Drabblecast? Wonder no more!We dig into all the technical aspects like voice acting, sound editing and mixing, foley effects, music and more.Preproduction? Reading? Acting? Yeah, it’s all here folks, all the blood sweat and tears that go into every production of the Drabblecast. reply crop_rotation 17 hours agorootparentIt might be worse than human narration, but at some point the economics becomes so loopsided that it&#x27;s dominance is inevitable. One good thing I can see coming out of that will be an abundance of audiobooks of copyright expired books. reply falcolas 17 hours agorootparentAre the economics actually better, or do they look better due to a lack of quality control? Because no TTS - even the most current AI ones - are perfect. They need corrections, which involves a human&#x27;s time. And it&#x27;s time that dictates prices, not skill (which largely reduces time). reply nazcan 12 hours agorootparentThe key is just which time is faster. If you are able to just listen to it once, and note a few errors, and slightly adjust, it may still may be much faster to use AI. reply falcolas 10 hours agorootparentBased off Apple’s advertised times to produce AI audiobooks, the times are comparable. AI is not running quickly nor inexpensively for this task it seems. reply hedora 14 hours agorootparentprevThe economics are only lopsided if the cost of producing the audio version is significant compared to the cost of writing the work of fiction. reply dirtyid 16 hours agoparentprev>As someone who has used TTS a Lot in recent projects, I’m not excited about listening to AI read a book to me. It feels soulless.AI TTS still uncanny valley enough to distract. I prefer even more soulless traditional TTS which sounds \"neutral\" after habituation. To the point where my brain can start layering on characterization as if I was reading. AI TTS feels like listening to to medicore voice actor, where it&#x27;s hard to overwrite their creative choices, so just left disapointmented and annoyed. reply IggleSniggle 8 hours agorootparentI agree completely! I kinda like the neutral tone of a soulless robot when it knows how to stay out of the way. Far better than a bad AI _or_ a poor human reading. reply j3d 19 hours agoprevShameless plug - if you download lots of audiobooks and need help organizing them and figuring out which to listen to next, check out Audiobook Locker: https:&#x2F;&#x2F;gitlab.com&#x2F;fonner&#x2F;audiobook-locker. It&#x27;s a desktop app (built with Tauri) that scans your audiobook folder and lets you sort, search and tag your audiobooks. reply Borrible 20 hours agoprevSounded better than the handful of random corresponding Librivox recordings I listened to in order to compare them. To be honest, a lot of people go to great lengths to make Librivox recordings without having the skills to read aloud.Which is a pity, but nonetheless. reply jawns 20 hours agoparentI agree. I love the idea of Librivox, but the volunteers vary widely in quality.Some are non-native English speakers, some have lisps or other articulation problems, some have other marks of fluency deficiencies, some have under- or over-dramatic intonation, etc.And even if they&#x27;re perfect voice actors, often their microphone setups are sub-par, and it comes through in the recording.Frankly, these AI voices are now at a level where the few mistakes they make are easier to forgive than some of those issues from human readers.That said, the final hurdle -- giving them the brains to know when to skip or resolve hiccups in the source material, such as typos, formatting issues, or text not intended to be read aloud -- is going to be very hard to overcome. reply everybodyknows 19 hours agorootparent> hiccups in the source materialFrom Joyce&#x27;s Ulysses (capitalization possibly wrong): \"nes. yo.\"Good luck with that! reply Borrible 20 hours agorootparentprevAbsolutely.So, will your books be available with an audio section as a free encore in the future? :) reply dirtyid 16 hours agoparentprevIt&#x27;s getting more passable. As someone who listens to a lot of TTS at high speed for years, eventually I adapted my brain do it and now it feels similar to phsyical reading with subvocalization where I can adjust the voices of characters. It&#x27;s occasionally even preferrable, i.e. too much over produced podcasts these days where I just TTS the transcript. reply The_suffocated 21 hours agoprevGreat news. It seems there is still much room for improvement, though. E.g. in “A Short History of the World” by H. G. Wells, the AI reads Darius I and Charles V as “Darius Eye” and “Charles Vee”. Open and closed brackets in sentences are not read out. The intonation is also a bit unnatural. But it is intelligent enough to parse 1,782 as 1782 rather than two numbers.Another problem is that the audio clips are not broken into sessions. There is no way to locate the beginning of a chapter, for instance. reply low_tech_love 21 hours agoparentI noticed the same, especially when some kind of structure text (like a bullet point or numbered list) comes in. reply hedora 18 hours agoparentprevSome podcasts embed chapter start timestamps into the rss (atom? m3u?) metadata.That way, you get one file (and gapless playback), but most players have a chapter skip button that will do what you are asking for. reply hedora 18 hours agoprevIf you are looking for short stories, I strongly recommend audio fiction podcasts.Escape Artists is one of my favorite production houses. The recordings are creative commons licensed, and the authors (and other artists) get paid professional rates:https:&#x2F;&#x2F;escapeartists.net&#x2F;Other sites to check out (all are donation-supported and pay authors):https:&#x2F;&#x2F;www.drabblecast.org&#x2F;https:&#x2F;&#x2F;www.lightspeedmagazine.com&#x2F;podcasting&#x2F;https:&#x2F;&#x2F;www.asimovs.com&#x2F;more-stuff&#x2F;podcasts&#x2F;To give you an idea of what’s available, “Money in the Bank” by John Kessel and Bruce Sterling will likely sit well with the HN crowd:https:&#x2F;&#x2F;www.lightspeedmagazine.com&#x2F;fiction&#x2F;money-in-the-bank...I could have picked literally 100’s of other stories; this one wins due to recency bias and the authors cyberpunk roots. reply jmspring 17 hours agoparentFor horror short stories - I&#x27;m a fan of the \"Horrorbabble\" podcast - https:&#x2F;&#x2F;www.google.com&#x2F;search?client=firefox-b-1-d&q=horrorb... reply sequoia 18 hours agoprevThis has dictation errors in the very first two words, in the title no less. https:&#x2F;&#x2F;ia801604.us.archive.org&#x2F;29&#x2F;items&#x2F;synapseml_gutenberg...\"Mrs. [pause] Shelly by Lucy Maddox Brown Rosetti\"I expected a bit better than this for a launch of \"the next amazing cool thing\"; distinguishing between full stops and honorifics seems pretty dang basic. As xrd said issues like this make the books unlistenable, it&#x27;s too distracting and weird. didntcheck plugged librivox which is nice if mixed in terms of quality, I&#x27;d also plug \"libby\" for anyone who doesn&#x27;t have it: check out audiobooks from your library. reply sb057 13 hours agoprevI picked Alice&#x27;s Adventures in Wonderland[1] just to check out the quality and was met with:>Lice was beginning to get very>tired of sitting by her sister on>the bank and of having nothing>to do. Once or twice she hadGreat concept but jeez the execution leaves a lot to be desired.[1] https:&#x2F;&#x2F;ia801606.us.archive.org&#x2F;35&#x2F;items&#x2F;synapseml_gutenberg... reply davidzweig 19 hours agoprevOh, snap, we&#x27;ve been working on importing Gutenburg to LR:https:&#x2F;&#x2F;www.languagereactor.com&#x2F;m&#x2F;t_en_-We&#x27;re ranking them using the download count, and also this prompt to chatGPT (it&#x27;s primarily for language learners):\"Is this text engaging and interesting for a modern reader, someone not into fine literature? Rate the text excellent, good, ok or poor. I don&#x27;t want crusty, flowery, contorted language, talking about buttons and mannerisms and the hue of the sky etc.\"Then, we&#x27;re rewriting the ~1000 most popular books using chatGPT to modernise&#x2F;simplify the text.Using some markdown as an internal format, drawing from the gutenberg plain text and html formats, this will go to a github repo shortly.There&#x27;s translations, and then, need to look at current best TTS voices. reply hedora 18 hours agoparentStandard Ebooks has the ability to filter books by reading level.That seems much better for people trying to learn English.https:&#x2F;&#x2F;standardebooks.org&#x2F;They carefully curate and copy-edit their books, and go for quality over quantity. I think that is probably the right choice. We already have free access to an effectively infinite amount of mediocre content on the internet. reply davidzweig 9 hours agorootparentI did check that out. The thing is, the criteria is a little different. This is for learners who need to practice reading English. The scripts surface a lot of material in Gutenberg that otherwise would be time-consuming to find. 1950&#x27;s science fiction that still reads well, or story books for children. Someone could certainly call these books &#x27;mediocre&#x27;, but I think that&#x27;s a bit adjacent to what we&#x27;re trying to do here. If this idea is worth the effort relative to other sources of material.. still undecided. reply letmevoteplease 13 hours agoparentprevJust for fun, here&#x27;s what happens to Pride and Prejudice:User: Rewrite and simplify the following text for a modern audience: \"It is a truth universally acknowledged, that a single man in possession of a good fortune must be in want of a wife. However little known the feelings or views of such a man may be on his first entering a neighbourhood, this truth is so well fixed in the minds of the surrounding families, that he is considered as the rightful property of some one or other of their daughters.\"ChatGPT: \"People generally believe that a rich single guy must be looking for a wife. Even if we don&#x27;t really know what he&#x27;s thinking when he moves to a new area, everyone assumes he&#x27;s up for grabs by one of the local girls.\" reply e12e 19 hours agoparentprevIf you&#x27;ve already determined the text is interesting to the modern reader, why rewrite?Wouldn&#x27;t it make more sense to look for texts that are thematically relevant, but with inaccessible language - and rewrite those?I still shudder to think how this system will handle something like Shakespeare&#x27;s sonnets... reply davidzweig 10 hours agorootparentIt&#x27;s for students learning English. The top 1000 will be rewritten and be available in addition to the original version, and about another 10,000 available in original only (selected using vocabulary frequency analysis and the chatGPT query).Midsummer Night&#x27;s Dream:THESEUS Now, fair Hippolyta, our nuptial hour Draws on apace; four happy days bring in Another moon: but, O, methinks, how slow This old moon wanes! she lingers my desires, Like to a step-dame or a dowager Long withering out a young man revenue.HIPPOLYTA Four days will quickly steep themselves in night; Four nights will quickly dream away the time; And then the moon, like to a silver bow New-bent in heaven, shall behold the night Of our solemnities.Rewritten:THESEUS Now, dear Hippolyta, our wedding day is approaching quickly. In just four more happy days, a new moon will arrive. But oh, it feels like this current moon is taking forever to disappear! It&#x27;s holding back my excitement, like an old, slow stepmother or a widow who keeps a young man&#x27;s money for far too long.HIPPOLYTA Don&#x27;t worry, Theseus. Four days will pass by in no time, and then four nights will also quickly slip away. After that, the new moon will shine brightly in the sky, like a freshly bent silver bow, and it will witness the night of our special celebration.Hmm. Shakespeare is the extreme case. It does make it more accessible. The style is lost. shrug reply floren 12 hours agoparentprevIt&#x27;s amazing that a decade ago I&#x27;d have called you an exceptionally demented individual for doing this, but these days there&#x27;s so much stupid unconscionable shit going on with AI that it hardly stands out. reply davidzweig 9 hours agorootparentfloren: In epochs bygone, a mere decade hence, I would have proffered thee the epithet of an egregiously unhinged denizen, were thou to embark upon such an endeavor. However, in these current times, wherein the domain of artificial intelligence doth teem with preposterous and morally indefensible machinations, thy conduct emerges as naught but a faint ember in the vast tapestry of perplexities that now envelop us.davidzweig: Hark! Methinks &#x27;tis the act of rewriting, not the sifting, that doth wound thy pride most deeply, and affront thee grievously. Set thine eyes upon the instance presented hence, to glean a clearer understanding of our noble mission, one that doth strive to render these splendid volumes more reachable:Original:The other person was a man named O’Brien, a member of the Inner Party and holder of some post so important and remote that Winston had only a dim idea of its nature. A momentary hush passed over the group of people round the chairs as they saw the black overalls of an Inner Party member approaching.O’Brien was a large, burly man with a thick neck and a coarse, humorous, brutal face. In spite of his formidable appearance he had a certain charm of manner. He had a trick of resettling his spectacles on his nose which was curiously disarming—in some indefinable way, curiously civilized. It was a gesture which, if anyone had still thought in such terms, might have recalled an eighteenth-century nobleman offering his snuffbox.Winston had seen O’Brien perhaps a dozen times in almost as many years. He felt deeply drawn to him, and not solely because he was intrigued by the contrast between O’Brien’s urbane manner and his prize-fighter’s physique. Much more it was because of a secretly held belief—or perhaps not even a belief, merely a hope—that O’Brien’s political orthodoxy was not perfect. Something in his face suggested it irresistibly.Rewritten:The other person was a man named O&#x27;Brien. He belonged to a group called the Inner Party and had a very important job that Winston didn&#x27;t fully understand. When people saw O&#x27;Brien, they became quiet, because he was a high-ranking member of the Inner Party.O&#x27;Brien was a big, strong man with a thick neck and a rough, funny, and tough-looking face. Despite his intimidating appearance, he had a certain charm in the way he acted. He had a habit of adjusting his glasses on his nose, which was oddly disarming, and in some way, it seemed polite and refined, like an old-fashioned nobleman offering his snuffbox.Winston had seen O&#x27;Brien about a dozen times over the past few years. He felt a strong connection to him, not just because he was curious about the difference between O&#x27;Brien&#x27;s polite behavior and his tough appearance. It was more because Winston secretly hoped that O&#x27;Brien wasn&#x27;t completely loyal to the government&#x27;s beliefs. There was something about his face that made Winston believe this, even though it was just a feeling.---> Orwell already has a clear style that I very much admire. The somewhat minor changes here would make for easier parsing by students, without changing the message much. I can&#x27;t imagine Orwell would have objected.I think your message is misplaced and pretty rude. reply floren 9 hours agorootparentThe example doesn&#x27;t change my mind.It throws away the flavor of the original text. Why reword the great works of literature into YA-level blandness? Might as well just read the Cliffs Notes at that point. 1984 isn&#x27;t a particularly challenging work, either, and I think readers do themselves a disfavor if they don&#x27;t read the original.Edit: hey I do want to apologize my tone in the first comment though, it was too much. Sorry. reply davidzweig 7 hours agorootparentWell, the filtering prompt could have caused offense to someone that enjoys literature. It was the prompt I used after some iterations. If you go through gutenberg (~70,000 books), much of it is pretty undigestable to a modern reader, never mind a learner. Personally I&#x27;m finding a learning curve with chatGPT etc. where you have to relearn to directly ask for what you want. reply davidzweig 9 hours agorootparentprevOur software is used by Koreans, Turks, Brazilians, Hungarians etc. that are trying to learn a foreign language (English). If importing (and rewriting some of) Gutenburg was the best use of time for them, well, I&#x27;m not sure. If you don&#x27;t see a difference in difficulty in the two texts, then, I don&#x27;t think you are able to appreciate the perspective of a language learner. reply bzhang255 9 hours agorootparentprevI don&#x27;t really understand the purpose here, given that literature is significantly aesthetic by nature. Can&#x27;t students just read contemporary, accessible books if they want something easier? reply davidzweig 9 hours agorootparentLiterature: \"Anything written in print that&#x27;s not Twilight.\" (urban dictionary) :)Yes, they could.. but we can&#x27;t put Harry Potter in the public library of texts for copyright reasons, and licensing material is difficult and not fun, I prefer to write software. Users can paste it in themselves, but then there&#x27;s steps. The center of the project is still a browser extension that runs on Netflix and Youtube, we thus sidestep the copyright issue. replyyread 21 hours agoprevVery cool. Although they shouldn&#x27;t have even bothered with the poems, it sounds terriblehttps:&#x2F;&#x2F;archive.org&#x2F;download&#x2F;synapseml_gutenberg_a_bell_s_bi... reply saw-lau 21 hours agoparentI thought I&#x27;d look up something I knew and spotted &#x27;Thérèse Raquin&#x27;, which gets butchered into &#x27;Rackwin&#x27;... some way to go yet, I think!https:&#x2F;&#x2F;ia804709.us.archive.org&#x2F;35&#x2F;items&#x2F;synapseml_gutenberg...(Hats off for the effort, though.) reply noufalibrahim 7 hours agoprevA good human reader doesn&#x27;t read as much as he dramatises the book. This conveys ideas and feelings more than what is just written. He takes liberties doing that which makes the narration interesting. I don&#x27;t know if that&#x27;s possible in the same way with an AI voice. I read to my kids often and try to dramatise the books in a similar way.The libre vox project which is contributer driven audio books is, I think, a more valuable contribution to human culture than AI generated audio files reply systemvoltage 6 hours agoparentYeah it’s still robotic, I just tried. When enunciating long conjugate parts of a sentence such as “A long windy snow filled country road”, it doesn’t know that this is a one set of adjectives describing a country road. It’s a dead give away it’s AI. Maybe they can fix this. reply noufalibrahim 41 minutes agorootparentI&#x27;m sure they will but even if they do and produce something that&#x27;s exactly the same as a human narrator, there&#x27;s something intangible that&#x27;s lost. That&#x27;s more or less my point. To make it even more intangible, I think the loss is greater to the narrator than to the listener as is the case with many of these AI generated creative pieces. reply jcon321 19 hours agoprevThis is cool. Narration of audio books is a time consuming process! I agree with some of these comments here about how AI narration can sound robotic though and may not be too pleasant to listen to.However, for anyone who is, or knows a family member&#x2F;friend with a certified disability, or is a veteran, there is a free program to listen to a vast collection of audio books (with real narration) provided by the US Government. Check out https:&#x2F;&#x2F;www.loc.gov&#x2F;nls&#x2F; (Braille material too!) reply taskforcegemini 4 hours agoparent>I agree with some of these comments here about how AI narration can sound robotic though and may not be too pleasant to listen to.I have encountered readers on librivox with such terrible pronunciation that following the story was rather difficult. on the other hand, a robotic voice could work well on some cyberpunk material reply 8s2ngy 20 hours agoprevUpon first impression, this is incredible! Audiobooks have enabled me to enjoy fiction books that I, otherwise, would not have been able to due to time constraints or other commitments. Perhaps, in the near future, AI will be able to make many obscure books that are collecting dust in museums and libraries accessible to the public through audiobooks. That is a future to look forward to. reply aedocw 19 hours agoprevI put together a script to read epub books using Coqui TTS and I think the results are not far off from this. It&#x27;s super quick if you&#x27;ve got a GPU, but it&#x27;s reasonable too if it&#x27;s just using CPU to do the text to speech.https:&#x2F;&#x2F;github.com&#x2F;aedocw&#x2F;epub2tts reply kwerk 19 hours agoparentDoes this handle text cleanup? Eg replace Roman numerals so they aren’t read literally etc? May need to dust off my Python for a Pr if not reply aedocw 15 hours agorootparentIt does not handle that. A PR to replace stuff like that would be fantastic, I&#x27;d love it - please do! reply mlhpdx 18 hours agoprevIn sampling a couple I would call these narrations \"serviceable\" rather than \"high quality\". My benchmark is the voice of my mom reading Shakespeare and Grahame, with intonation and voice to each character. Perhaps AI authored narration could do that, but these haven&#x27;t. reply Brajeshwar 19 hours agoprevI&#x27;m curious about the sub-domain https:&#x2F;&#x2F;marhamilresearch4.blob.core.windows.net. Are these auto-generated? I&#x27;m guessing these style of subdomains are not named by a human. reply freeplay 18 hours agoparentLooks like Azure Blob Storage and &#x27;marhamilresearch4&#x27; is the name of the storage account (think website hosted in a public S3 bucket).Azure requires these names are globally unique and only allows alphanumerics. reply data_ders 14 hours agorootparentthis is likely Mark Hamilton&#x27;s static site deployed from his own blob storage account https:&#x2F;&#x2F;github.com&#x2F;mhamilton723 reply rhyme-boss 20 hours agoprevIsn&#x27;t listening to people tell stories fundamental to what we are? Wouldn&#x27;t you rather be a part of a culture that cares about the difference between listening to a person&#x27;s voice vs. a bot?Edit: My concern is audio files ending up in places where they aren&#x27;t clearly labelled as AI-generated. reply brudgers 20 hours agoparentI think we should recognize that most choices are not between bread and cake.They are between bread and going hungry.I am not certain AI voiced audio books are better than nothing, but that&#x27;s the way I&#x27;d bet. YMMV. reply chthonicdaemon 20 hours agoparentprevDo you have the same objection to reading transcripts? reply rhyme-boss 19 hours agorootparentTranscripts of what? I think stories are special, and I wouldn&#x27;t lump them together with \"all text\". reply nineplay 18 hours agoprevAnyone interested in free, well-narrated audiobooks should check out the Classic Tales podcast. I can&#x27;t really say enough about it. The host is a fantastic narrator and the books range from Plutarch&#x27;s Lives to Philip K Dick. reply cush 14 hours agoprevThe audio book for Project Hail Mary is brilliantly done with amazing voice acting and even uses effects on Rocky’s voice to emphasize his musicality. Listening to a good audio book is like listening to the perfect film adaptation - it adds to the reading experience.There’s a long, long way to go for AI to learn emotion before I’d spend 20+ hours listening to a book read by one. reply darknavi 13 hours agoparentGreat example. I agree that Ray Porter knocked it out of the park with that book.Listen to this. Apple must of licensed his voice and while it is impressive, it goes to show how dead-pan the voice still is.\"Mitchell, a digital voice\"https:&#x2F;&#x2F;authors.apple.com&#x2F;support&#x2F;4519-digital-narration-aud... reply _the_inflator 13 hours agoprevFantastic progress. Nevertheless, here is something for the internet veterans: Remember Microsoft Sam? MS came a long way to finally do good text to speech: https:&#x2F;&#x2F;youtu.be&#x2F;3db_4xYahVc?si=SsXKvfHCabQ5rLefEnjoy the ROFLcopter. ;) reply andrewstuart 16 hours agoprevI cannot listen to audiobooks read by text to speech they sound awful.Only human narrators are acceptable. reply hackernj 15 hours agoparentOnly professional, human narrators are acceptable to me. With few exceptions (e.g., Jimmy Carter), I can’t listen to an audiobook that was narrated by the author. reply tbalsam 16 hours agoparentprevhttps:&#x2F;&#x2F;www.gutenberg.org&#x2F;browse&#x2F;categories&#x2F;1 reply bachmeier 13 hours agoparentprevI applaud the effort, but the voices are too distracting for me to focus for more than a minute. reply iandanforth 19 hours agoprevThe first example I clicked on turned out to be a super racist book! Luckily the narration was repetitive (like a record skipping), a tonal, and with prosody that chopped up sentences to the point of near intelligibility. reply olav 18 hours agoprevThe site is curiously broken in Safari browser. reply Mistletoe 20 hours agoprevI tried to listen to The Call of the Wild and it was impossible to follow since accents and emphasis on words are all wrong. I could barely understand the story. I guess AI has more work to do. reply ta8645 19 hours agoparentYes, the voice sounds very natural and not computer-generated. But it gets a lot of, even simple, pronunciations wrong. There&#x27;s a long way to go before this is genuinely an enjoyable and useful option. reply artyn 19 hours agoprevSo many works are labeled [] or nan. reply hospitalJail 17 hours agoprevOh man they have obscure Plato! I can&#x27;t even spend money to get all of plato read. reply GrumpyNl 19 hours agoprevListening to a few of them, im amazed in what bad shape text to speech technology is. After all these years it still sounds robotic. reply i_am_a_squirrel 16 hours agoprevSearch> kritik der praktischen vernunft gutenbergand then go to 2:00 and listen until it says \"Moral reason\" it&#x27;s a bit creepy :( reply pjmlp 21 hours agoprev [–] Yet another example on how jobs will go away, goodbye voice actors. reply low_tech_love 21 hours agoparentI am an avid consumer of audiobooks and I will never pay&#x2F;listen to anything AI-generated. Maybe it&#x27;s just me, I don&#x27;t know, but just because they have shown that it is technically feasible, that doesn&#x27;t mean that there is a market for it. I am skeptical. Listening to audiobooks is already a compromise over reading the book, listening to an AI-generated audiobook sounds to me like a bit too much. But let&#x27;s see. reply hedora 17 hours agorootparentCheck out audio fiction podcasts. Some do full productions of short stories. Depending on the work, reading the text is a compromise over listening to the reading. For instance, music is extremely important to these two stories by Aliya Whiteley:https:&#x2F;&#x2F;www.drabblecast.org&#x2F;2007&#x2F;12&#x2F;20&#x2F;drabblecast-43-jelly-...Warning: the above has mild language and adult themes.https:&#x2F;&#x2F;www.drabblecast.org&#x2F;2010&#x2F;07&#x2F;27&#x2F;drabblecast-173-go-be... reply atrus 20 hours agorootparentprevYou&#x27;ll never pay&#x2F;listen to anything you&#x27;re able to identify as AI-generated. reply ghaff 20 hours agorootparentObviously there are lots of short snippets of audio that are machine generated. But, no, at the current state of the art I&#x27;m not going to listen to a machine generated audiobook much less pay for it. reply prepend 20 hours agorootparentprevIt’s not for you, it’s for the millions&#x2F;billions not currently listening to audiobooks.This reminds me of the “I’ll never listen to mp3, I love my .” The goal wasn’t to convince existing people but to expand to new people. reply freedomben 20 hours agorootparentprevI would agree but there is one big exception: books I really want to read but there&#x27;s no audiobook version.I have a particular interest in early Mormon history and the history of the western US, and there are some really great books that aren&#x27;t available as audio. I ended up generating some with aws and while the voice annoyed me, I was willing to do it, and the cost was much higher than a normal audiobook would cost.I think in reality, the more popular books will get a pro reading, but as long as it&#x27;s labeled, there will be a market for ai audiobooks. reply cush 20 hours agoparentprevIt’s all voice and no acting reply ghaff 21 hours agoparentprevIt seems pretty obvious that, at least at this point, the competition is either people doing this sort of thing as a hobby or (maybe) at race to the bottom wages. (Or not at all--as is largely the case with machine transcription vs. human transcription.)If I want mediocre text to speech, I have that on my Kindle. reply JKCalhoun 20 hours agoparentprevSeems like reasonable backfill for the countless books that will never get audio treatment. reply crop_rotation 21 hours agoparentprevTrue, and sadly they will go too quickly for voice actors to have any time to adapt. reply eole666 21 hours agoparentprev [–] For now, actual voice actors make audiobooks listening way more enjoyable. Those AI voices are convincing but lack the soul, emotions and art direction of actual voice acting. Think about listening to a book for 8 hours with a monotonous AI voice reading it... reply mcpackieh 7 hours agorootparent [–] I mostly listen to real audiobooks now so I understand their appeal, but I have also listened to dozens of books using the primitive TTS built into my old Kindle (keyboard model). TTS was rough at first but I knew it could work, because I know blind people use it, so I stuck with it and I found that after a few hours I no longer perceived the awkwardness and it became an effective and satisfying way for me to &#x27;read&#x27; books. Brain plasticity is a marvel. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Project Gutenberg and Microsoft are collaborating to develop a large collection of free, open audiobooks using advanced neural text-to-speech technology.",
      "The motive behind this project is to democratize access to superior-quality audiobooks and promote literature accessibility.",
      "However, there might be issues such as errors, offensive language, or inappropriate content in some audiobooks, which do not mirror the views of the collaborating entities. The users can report these problems via a specified link."
    ],
    "commentSummary": [
      "The Hacker News discussion revolves around AI-generated audio in audiobooks, with users lamenting the lack of emotional expression and debating the impact of AI on various industries and society.",
      "Users discuss the affordability and accessibility of these audiobooks and question the quality of AI-generated audio, its potential market dominance, pronunciation issues, and audio clip structuring. They also mention alternative platforms for free or human-read audiobooks.",
      "The topic also ventures into AI's usage in rewriting texts for language learners and making obscure books more reachable. Views range from skepticism to an acknowledgment of AI's potential to widen the audience, albeit with a preference for accurate labeling of AI-generated content."
    ],
    "points": 376,
    "commentCount": 154,
    "retryCount": 0,
    "time": 1694433988
  },
  {
    "id": 37470318,
    "title": "Why did Visual Basic die?",
    "originLink": "https://news.ycombinator.com/item?id=37470318",
    "originBody": "I&#x27;ve been a software developer for almost 30 years. I remember using VB back in the 90&#x27;s and I was thinking about it the other day and it dawned on me; despite all the advances in technology since then, nothing I have found compares to that development experience today. I would go so far as to say we&#x27;ve gone backwards in a big way.Now, I&#x27;m no fan of Microsoft products but, I have yet to find a tool that can allow me to be as productive in so short a time as Visual Basic. Yet I can&#x27;t help wondering what problems it had that caused them to abandon it? Moreover, why hasn&#x27;t someone come out with a solid replacement?",
    "commentLink": "https://news.ycombinator.com/item?id=37470318",
    "commentBody": "Why did Visual Basic die?Hacker NewspastloginWhy did Visual Basic die? 373 points by Zelphyr 16 hours ago| hidepastfavorite463 comments I&#x27;ve been a software developer for almost 30 years. I remember using VB back in the 90&#x27;s and I was thinking about it the other day and it dawned on me; despite all the advances in technology since then, nothing I have found compares to that development experience today. I would go so far as to say we&#x27;ve gone backwards in a big way.Now, I&#x27;m no fan of Microsoft products but, I have yet to find a tool that can allow me to be as productive in so short a time as Visual Basic. Yet I can&#x27;t help wondering what problems it had that caused them to abandon it? Moreover, why hasn&#x27;t someone come out with a solid replacement? RyLuke 13 hours agoI actually wrote a long article on this [1]—and had a chance to interview some of the team that built the original version of VB that was sold to Microsoft. (Alan Cooper and Michael Geary; Michael actually frequents HN pretty regularly!)My opinion is that it was a confluence of a few factors:- Microsoft was very worried about the threat of Java&#x2F;Sun, and rotated hard into .NET and the common language runtime as a response.- The most vocal, but minority of VB users wanted more advanced functionality and a more powerful&#x2F;expressive language (as is often the case). Couple with the shift to .NET, Microsoft listened to them: VB got a full rewrite into an object-oriented language and the IDE moved further away from the VB6 visual building paradigm. That left the silent majority high and dry.- The web emerged. Working with the Win32 API was suddenly less relevant, and younger devs adopted PHP en masse, rather than adopting VB. (And existing VB6 devs upset about the change also migrated over when they could build for the web instead of Windows) Unforced error on Microsoft&#x27;s part, since IE had 96% browser marketshare in 2001.[1] https:&#x2F;&#x2F;retool.com&#x2F;visual-basic&#x2F; reply radicalbyte 13 hours agoparentThe web and the way MS handle the web killed it. Microsoft was pushing everyone towards these horrible activx components. Many moved to PHP or Adobe Flash.I was using MS Access back in the day to solve business problems - it was like a VB6 DSL focused fully on data-driven applications. It was extremely time efficient thanks to that focus - what took me days to build took a VB developer (or PHP developer) months. That died thanks to web (and the web version being horrific and a dataleak waiting to happen).The move to C# and the path they&#x27;ve followed since then was, looking back, the way to go. I only wish that they had done more to make the experience for native programmers better out of the box. reply jamra 8 hours agorootparentIn my experience, ActiveX was not what they pushed. They pushed Asp.Net Webforms which used VBScript for the template language. The ViewState monstrosity made it an awful experience. Specifically how it send way more data than needed to and from the server on each request. I shiver when I think of it. reply fodkodrasz 3 hours agorootparentThe real problem was worse than that: it was not a technical, but a legal one: Licensing!You need to buy CALs for every concurrent user (yes, not only SMB&#x2F;terminal services users) was the way to go according to some MS license experts, and the licensing was totally incomprehensible, as is today. No wonder most didn&#x27;t want to risk building a business on these maybe not so solid foundations.Still I only dare using asp.net for serving public webpages from Linux.Of course the technical problems were also present, but many didn&#x27;t even get to think of that as the BSA bullying was keeping them away already. reply Sophistifunk 7 hours agorootparentprevI think GP is describing the period before the .net switch. I remember back in those days having to do web stuff on MS platforms, which meant classic ASP, which was great for the job it was designed for: gluing together ActiveX components.Unfortunately, nobody anywhere ever trusted ActiveX because it (at least gave everybody the impression it) had holes the size of a bus, so you were stuck using a limited language with no library support to do all the glue and all the heavy lifting, it was a very unpleasant period of time if you found your way into a Microsoft shop. reply bowsamic 3 hours agorootparentprevThe ViewState problem is easily avoided by keeping it on the server reply mike_hearn 1 hour agorootparentprevThe ActiveX era pre-dated ASP.NET.When the web was new, it was so clearly not designed for apps that pretty much everyone agreed it was absurd to use it that way. The UX and DX was just such a horrifically huge downgrade. Instead, HTML was for documents and linking, and apps would be given a rectangle (maybe the entire rectangle) through which they could appear in the browser. Netscape partnered with Sun for Java applets. ActiveX was therefore a response to that.ActiveX made a lot of sense for Microsoft at the time. Firstly, it let the enormous base of Windows devs put stuff into a web page almost overnight. Secondly, it leveraged existing tech that was already designed for embedding one app&#x27;s UI inside another app (OLE), and for shipping widget libraries to visual designers (OCX). Thirdly, ActiveX was a lot faster and more efficient than Java applets, being based around tightly written Win32 code. Finally, people weren&#x27;t so focused on security back then and anyway, Microsoft had recently been investing in adding code signing to Windows. It appeared to them at the time that code signing would be sufficient to stop abuse. We know in retrospect it didn&#x27;t quite work out that way for them, although it&#x27;s been pretty successful on Macs.And in fact ActiveX did see quite wide usage, albeit mostly as IE&#x27;s answer to Netscape&#x27;s plugin interface. But it didn&#x27;t take off in a big way because:1. ActiveX apps were native code and native code is very low level and thus very large compared to JavaScript and HTML. Performance is great because the CPU eats it directly with no intermediate translation layers, but you pay for it in code size. Back then bandwidth and CPU were both tight, but HTML&#x2F;JS were light on both at the cost of UI latency and primitive controls. People picked low startup time followed by high latency and primitive controls.2. The UI they picked for code signing was a (standard at the time) popup modal dialog. It had very poor usability, being filled with tons of complicated words, often asking you to approve software from a company you&#x27;d never heard of (i.e. products&#x2F;websites did not use the same name as the company that produced them) and worse, malicious web pages could put you into an infinite loop where if you clicked cancel they&#x27;d just immediately ask you again, forcing you to click yes. Which was equivalent to downloading and running an unsandboxed program. Back then browsers went years between updates so once they shipped that mistake, it was very hard to fix quickly and so the reputation of ActiveX became very poor.3. They had no way to sandbox native code at this time, the Windows kernel just didn&#x27;t support it at all and it probably wouldn&#x27;t have occurred to them anyway.The first problem was fundamental to the approach. The second problem was an unforced error.They could have tried to switch over to a sandboxable bytecode; VB used what they called \"P-code\" on an interpreter already. But they didn&#x27;t. Java was becoming too popular, too fast, and they lost confidence in their own tech stack. Instead Gates threw the company into a crash effort to clone Java. By the time .NET had the ability to do ActiveX controls they&#x27;d already moved on from that approach and were trying to make DHTML work instead. reply oliwarner 2 hours agorootparentprevI have the opposite take, as a non-native programmer in the early 00s.All the PostBack loops in ASP.Net and WYSIWYG editing in VS.Net 2003+ felt like they were trying to appease native programmers to a fault. VB.Net wasn&#x27;t bad but it was frustrating how hard it was just to script something without boilerplate. Being limited to IIS was also bunk. reply ksec 9 hours agoparentprev>The most vocal, but minority of VB users wanted more advanced functionality and a more powerful&#x2F;expressive language (as is often the case).This is the single reason why most computing tools, ( not limited to VB ) never reached wide enough audience. The nerds keep asking for complexity, but the majority actually wanted even more simplicity.HyperCard, Delphi, VB6, Flash. reply Qwertious 4 hours agorootparentI have a theory on why: it&#x27;s because the scope of a general-purpose-ish language inherently increases; there are always users that are mostly covered by the featureset, who just need one more feature and they&#x27;ll be fully covered, so they&#x27;ll ask for that feature. But by satisfying them, you&#x27;ll bring more non-users from their nowhere-near-covered position up to the \"99%-covered\" boundary, and then they&#x27;ll want their own last-1% feature.The same people who want simplicity in their language&#x2F;tooling also want to not learn a second almost-identical system just to achieve that last 1%, so refusing to expand your scope here isn&#x27;t necessarily \"optimizing for simplicity\". reply kalleboo 4 hours agorootparentprevI think there&#x27;s a deeper problem with development tools in general:There is no tool that goes from 0 to 100.The tools you listed (I&#x27;d also add Excel) were great for people starting out, people who had an itch to scratch, people solving a problem. But inevitably, the programs they made worked too well, they got adopted, got added features, became mission-critical, and now outgrow the tool they were written in. And that&#x27;s when you get the \"nerds asking for complexity\". Those people didn&#x27;t start out nerds, they started out as users solving a problem, but now their little \"make a formatted report out of this Excel sheet\" tool is running the whole companies realtime sales forecasting and they scaled up along with the project.I think the plan with VB.NET was that (\"start out with VB and if you need it you can seamlessly graduate to C#!\"), and Chris Lattner planned the same thing with Swift (\"it will replace Python!\") but none of those plans were ever carried out properly. reply makeitdouble 3 hours agorootparentprev> The nerdsThe people with money really. Few people care what the nerds complain about, but Microsoft will listen to Fortune 500 companies that hold thousands of top tier paying users and their complaints about how such or such feature would help them save days of work every months.This the ultimate \"vote with your wallet\" I think, those with bigger wallets will have bigger votes. reply glenngillen 4 hours agorootparentprevAn unfortunate byproduct of this, that I think is an unpopular opinion in these parts, is increased in product analytics&#x2F;telemetry. People eventually learn that the feedback you receive re your product only rarely reflects the experience of the majority of users. reply antupis 5 hours agorootparentprevAdding features to a popular tool later can make it messy. Building a tool where you can add features easily makes it elegant eg Lisp. reply ShadowBanThis01 3 hours agorootparentprevI worked for a company where we built a prototype for a rewrite of their flagship product in VB. Meanwhile a big team of programmers implemented the “production” version in VC++. But at that time a bunch of the controls available in VB were not in VC, so they lagged quite a bit. Of course management saw the prototype working (it was a CRUD app for property management) and said why not just use this. The C++ programmers turned up their noses at working in VB and were summarily fired, leaving me and a team of contractors to finish the job. 100% the right business decision and a good lesson on getting too precious with your tech. reply monalogue 12 hours agoparentprevThis article was excellent, @RyLuke — I read it a few months ago when it was first published and passed it on to just about everyone I know in my MSFT network.I cut my teeth on VB6 back in the day — for someone that didn&#x27;t know much about programming at the time it felt like I suddenly had found a new set of superpowers. VB6 was a big confidence booster + momentum builder that set me on a path to a happy career.Awesome that you were able to connect with Alan and Michael and thanks for the trip down memory lane. reply wkat4242 3 hours agoparentprevVb.net was a bit weird yes but visual basic did need work. Vb6 did not have multithreading which was really starting to hurt its efficacy by 2002. You could work around it by using events as much as possible but there were still some things that were blocking. Also the events were not even on a separate thread either leading to the need to pepper DoEvents everywhere.This was a dealbreaker for vb to ever become a serious language and kept it squarely in the hobby bob &#x2F; prototyping arena. But who wants to prototype in a language that requires a full rewrite in another language to go to production?In the long run this was always unsustainable. The rewrite to .net fixed this but it was a significant departure from vb underpinnings and in particular the seamless winforms integration that was pretty amazing.Also, with .net came multilingual capability and c# got really popular quickly and displaced vb.net reply gadders 1 hour agorootparentVB was probably 80%+ line of business CRUD apps. What would you write in VB that needed multi-threading? You&#x27;re not writing trading systems or games in it. reply wkat4242 29 minutes agorootparent> VB was probably 80%+ line of business CRUD apps.That&#x27;s more a result of it not supporting it I&#x27;m sure. It could have been a great general purpose language if it was a bit more powerful.I used to write apps in it and I often ran into these issues. Mainly small business custom administrative stuff. Like a management system for a chain of hostels. It was still important to have multithreading because things can get updated by other users, or even clients themselves through the internet (in fact I spent a lot of time adding ASP frontends back then). I don&#x27;t like using locking too much in a multi-user environment because it gives a terrible UX, so I would have to constantly check if nothing had changed.In this day and age you will also have to deal with a lot of web API calls that can happen asynchronously. Locking the main thread is really not an option. Remember that VB6 even locked the User Interface when it was doing something, even the visuals didn&#x27;t have their own thread. Making for a very choppy experience.Like I said peppering DoEvents everywhere helped mitigate this a bit, but sometimes you had to call stuff in external DLLs and while the call was away the whole UI would be hanging. reply 3np 3 hours agorootparentprevElectron seems successful regardless of lack of multithreading on the language level?I don&#x27;t buy this one. reply wkat4242 27 minutes agorootparentJavascript is better at asynchronism than VB was, and in Electron the user interface does run in a separate process. Unlike Visual Basic 6, where the UI would completely hang when you were busy with some external function call. reply mike_hearn 1 hour agorootparentprevCorrect, nobody cared about \"true\" VB multithreading. Besides VB supported multi-processing very well, much better than the JS world does today. You could call objects between threads no problem. Behind the scenes it was using DCOM, so if you passed an object from one thread to another, the other thread would get a proxy that&#x27;d do RPCs to the first thread. So there was no true shared memory multithreading, but for VB users what they had instead was in some way even better, it was basically web workers but more transparent. Specifically, it meant that object calls couldn&#x27;t run in parallel to UI updates or other logic so there was no need to think about locking. reply wkat4242 25 minutes agorootparentBut the whole thing of the UI being on the same thread was a really big problem. You could get around it by calling the Win32 Threads API but that would quickly lead to a crashfest due to the no shared memory thing. Electron doesn&#x27;t have this problem because the UI is handled by the renderer, not the JS engine. So in that sense the UI is in a separate thread. This wasn&#x27;t the case for VB6.And events in VB6 were not great. They were good for the time, sure. Because they had to be. If you&#x27;d write an app in it today with lots of external API calls it&#x27;d be a mess.VB6 was serviceable at the time but without multithreading support it didn&#x27;t have a future in an ever more API-driven environment. reply viraptor 13 hours agoparentprev> VB got a full rewrite into an object-oriented language and the IDE moved further away from the VB6 visual building paradigm.What do you mean by this? Visual Studio today has a designer &#x2F; code editor that works in a very similar way to VB6 that I remember. What do you think is missing? reply highwaylights 12 hours agorootparentHow much time do you have?P-code debugging with fully rewindable edit and continue.A one-true-way event model that was derided at the time but was really just years ahead of its time.Minimal runtime downloads to install apps locally, which also produced tiny, performant executables.The sweet, sweet With keyword. I know, I know. But I don’t care. Just be more aware of your namespaces.Also (and I still don’t understand why we can’t have this in VS Code when VS had this in 1998) object combos at the top of the code file for class and method (admittedly VS proper still has this I’m just grumpy at the regression) reply viraptor 11 hours agorootparent> The sweet, sweet With keyword.VB.net supports With though?> Minimal runtime downloads to install apps locally, which also produced tiny, performant executables..net framework 2.7 is guaranteed to be installed by default these days so you can deploy one exe without shipping your own runtime. Yes, officially you shouldn&#x27;t, but there&#x27;s so much stuff that depends on it now. reply wcoenen 3 hours agorootparent> net framework 2.7 is guaranteed to be installed by default these daysThere is no \"net framework 2.7\":https:&#x2F;&#x2F;learn.microsoft.com&#x2F;en-us&#x2F;dotnet&#x2F;framework&#x2F;migration... reply viraptor 3 hours agorootparentTypo - I meant 4.7. Although it looks like they finally moved to 4.8 in w11. reply sn_master 8 hours agorootparentprev> .net framework 2.7 is guaranteed to be installed by default these daysYes, but that wasn&#x27;t the case back in the mid-2000s when VB6 was dying and no one wanted to migrate to VB.Net reply ShadowBanThis01 2 hours agorootparentprevOne thing that sucks about those combos, if I remember correctly: Don’t they show only the members of the class your cursor happens to be sitting in, and not those in the whole file? That’s just monumentally dumb. I remember cursing at those as I hunted through a bunch of files for some function… only to find it was right there in the file I had up but Microsoft didn’t show it.I remember scorning Xcode back when it was Project Builder, but saying Hey, at least its drop-down member lists work properly. reply emodendroket 12 hours agorootparentprevA lot of people who wrote VB weren’t serious&#x2F;professional programmers and VB.NET was too complex for them. For the serious programmer group, the stink of “VB” tainted it right out of the gate (despite having complete feature parity for a long time VB.NET jobs always paid notably less than C# ones). So it was kind of a compromise that satisfied nobody. reply analog31 11 hours agorootparentThat was me. I wrote what I affectionately call \"crapware,\" which are small apps that solve a problem but are not intended for use at scale. There was a lot of this stuff, such as little database queries, or hacking together a few industrial sensors with a crude display. Businesses ran on crapware. Maybe they still do. A few thousand lines of code that I wrote for a manufacturing fixture ran bug-free for more than a decade.I remember that just downloading and installing VB.NET was burdensome, especially in the plant where many of the computers were not networked.When VB.NET came out, programmers hung on to their VB6 disks, and kept using it for easily another decade. By the time VB6 really reached the end of the road, its replacements (e.g., Python for me) were up to speed, and free. reply ta1243 11 hours agorootparentI&#x27;ve written a lot of crapware, still keeps my employer working 15+ years on. Meanwhile \"replacement\" systems have come and gone, but the users still keep using the crapware.1) See a business problem2) Put something together to solve the problem3) Move On reply MichaelZuo 10 hours agorootparentI was going to say, a few thousands lines of code that reliably solves a real business problem for over a decade is pretty much the exact opposite of &#x27;crapware&#x27;... reply emodendroket 10 hours agorootparentAs long as you don’t care about stuff like maintainability or logging sure. The issue is that a lot of times businesses outgrow their bespoke Access app or whatever and then it’s a huge headache to untangle the reliance on it and go more robust. Of course if that never happens it’s great and frees up developers’ time for higher-value work. reply jopsen 10 hours agorootparent> The issue is that a lot of times businesses outgrow their bespoke Access app or whatever... > Of course if that never happens it’s great..It could also be argued that outgrowing your initial business app is good thing.Lots of business don&#x27;t outgrow it, because they don&#x27;t grow :)Indeed, it might be reasonable not to invest too much upfront, before you have scale and can afford to build stuff you won&#x27;t outgrow. reply Spooky23 6 hours agorootparentThe issue is there’s no engineering process around it, even in a shitty organization where the “engineering” is garbage.One place I helped out at had a pretty awesome access app for doing some business functions. Way better than the Oracle whatever they failed to replace it with.The problem was, nobody was willing to claim ownership. The business guy who wrote it was long gone, and IT would not accept an Access app. reply MichaelZuo 10 hours agorootparentprevI don&#x27;t get the relation here?, most businesses care somewhat, and certainly the better run businesses do quite a bit, so they&#x27;ll make sure to record down everything important about the software. reply emodendroket 6 hours agorootparentSo when it goes wrong in many predictable ways it’s a nightmare. All the stuff software engineers put around software to make it reliable, fault tolerant, and generally having the expected behavior is not just for laughs but the result of hard-won experience. replysn_master 8 hours agorootparentprevAlso, most machines did not have the .Net framework installed, and back then it was 20 MB download which was gonna take ~2 hours on dial up back in the day vs MSVMVM6.dll which was on all Windows versions from 98 until 7 at least. reply jacquesm 11 hours agorootparentprevI came across such a project recently built using FileMaker in 2001 or so. On the original hardware, no less. reply deaddodo 7 hours agorootparentprev> When VB.NET came out, programmers hung on to their VB6 disks, and kept using it for easily another decade. By the time VB6 really reached the end of the road, its replacements (e.g., Python for me) were up to speed, and free.VS6 was still the majority IDE well into the mid-00s, at least in an academic setting. I still remember getting handed an academic license DVD to use for my C++ courses in University around that time.The disconnect between \"classic\" and \".NET\" VS took a long time to break, I would say until about VS2008&#x2F;2010. reply nextaccountic 6 hours agorootparentprevwhat you called crapware is just scripting, but with a gui rather than running in terminalit&#x27;s like a quick and dirty shell script or what once could be a tcl or perl script, but today would most probably be a python script reply SamuelAdams 11 hours agorootparentprevI think today python fills that void - people who are not serious programmers but need to put something together. Think academics, data analysts, etc. And since Python is cross platform and easy to get started with it is a lot more attractive than VB. reply cstejerean 9 hours agorootparentIt&#x27;s significantly harder to put together a quick GUI application in Python than it used to be in the VB6 days. Just getting all the dependencies installed can be a pain, and then good luck trying to add another button to that app say 2 years later, chances are nothing will build anymore. reply Blackthorn 9 hours agorootparentHonestly it&#x27;s harder to put together a quick GUI application in anything than it was in the VB6 days. By losing VB6, we&#x27;ve lost a lot of power and ability to do GUI things quickly. reply sn_master 8 hours agorootparentWinForms in C# was pretty decent tbh. Not so sure about WCF&#x2F;Metro&#x2F;Modern and whatever it is now that Microsoft been releasing. They just stopped caring about consistent UI for apps on Windows altogether since ~2010 or so. reply emodendroket 6 hours agorootparentWinForms is fine but it makes it way too easy to put all your behavior in the code behind instead of doing things nicely. Which I guess is what you want for a non-programmer tool but it is a hassle for me. Either way the .NET UI situation is a mess and I’ve never seen the sense in picking up the latest flavor of the month since it will be out of favor by the time I have occasion to use it. reply Turskarama 6 hours agorootparentprevYou say was but winforms is still supported in VS2022 and is probably my go-to if I need to hack together a small windows program. reply markus_zhang 8 hours agorootparentprevWhat&#x27;s the bottleneck to build a modern VB6? Just curious. reply emodendroket 3 hours agorootparentThe people most interested in such a product are not those with the skills to build it. reply mike_hearn 1 hour agorootparentprevThere are VB like tools. These days they&#x27;re all SaaS though. Oracle APEX is one well known one, there are plenty of others out there.There are at least three massive problems faced by anyone who wants to hew closer to the VB6 model:1. Deployment tech.2. Getting people to pay for it.3. Developer culture.In order:Deployment. There are tools and UI toolkits today that support VB6&#x2F;Delphi-like development, but they aren&#x27;t web based. For example, you can also do VB6 like development using Java or Kotlin + JavaFX + Scene Builder (or Swing and one of the visual form designers for it). This leads to the question of how to deploy the result. Unfortunately, for the past 15 years or so the answer has been pretty much \"you can&#x27;t\".In the VB6&#x2F;Delphi era the answer to deployment was \"take your EXE and stick it on a shared Windows network drive\". For internal business distribution this worked fine. Java had JRE+Java Web Start, which also worked fine inside businesses. Unfortunately neither approach works anymore: Windows is no longer ubiquitous, tools don&#x27;t produce standalone EXEs anymore, users don&#x27;t know how to handle zips and folders (these skills have atrophied). Also security has got tighter so throwing EXEs around is harder, and people expect software updates to work smoothly. Java dropped WebStart and never replaced it with anything good enough, so the tooling actually regressed with time too.This isn&#x27;t fundamental and is fixable. I spent the last couple of years fixing the tooling situation [1]. You can now deploy desktop apps as easily as you do for a web app. Conveyor does signing, packaging for Win&#x2F;Mac&#x2F;Linux, and integrates auto-update as part of the packaging process. It will even generate icons and a download page for you and then upload the results. You do still need code signing certificates, however, and getting those isn&#x27;t as easy or cheap as it is for SSL certs with LetsEncrypt.A related issue is database and server side logic hosting. VB6 development assumed it was OK to just connect directly to a database using its native protocol and that e.g. every employee would have a DB user. People are more protective of their databases these days and would find this level of simplicity to be radical. I&#x27;ve experimented with that too and given a talk on it at KotlinConf [2]Payment. VB6&#x2F;Delphi were developed in an era when people expected to pay hundreds or even thousands of dollars for each version of their IDE&#x2F;compiler. There were no subscriptions but in practice new versions would come out every couple of years or so, so if you wanted to keep up you&#x27;d need to budget a few hundred dollars a year. Skipping versions was common.Nowadays, people&#x27;s payment expectations are different. They expect programming languages and platforms to be free and open source. They take absolutist positions on it, saying things like, \"it&#x27;s not open source so I can&#x27;t ever use this\". This rule vanishes if something is a proprietary SaaS however. This kills the incentives to develop better tools for standalone \"business crapware\" development as mentioned elsewhere in the thread - apps have to be tied to a subscription SaaS or else you can&#x27;t get paid to work on it. In turn that makes it hard for people to learn by just experimenting locally. For programming languages, every new language that comes along in the past 15 years or so is essentially either a hobby project of celebrity employees (e.g. Go), or a way for rich tech firms to solve tech debt and productivity issues (e.g. Kotlin, Rust, TypeScript), or commercialized by selling long term support (Java). The closest to a real commercial language is Kotlin and that&#x27;s very indirect, it incentivizes IDE sales, as IDEs are still something people are sometimes willing to pay for (but most use whatever&#x27;s free).It&#x27;s possible that the pendulum will swing back here.Developer culture. Part of why devs are so hardline on stuff being free is that they want to add it to their CV and learn tech that they can take with them to their next job. This means going where the crowd is. If you wanted to do something VB6 like you&#x27;d have to do things very differently to how they are done today (e.g. probably not web based) and that would mean people would stay away just out of fear that they&#x27;d stray too far from the herd.Still, despite these problems, there are ways you can do that. Like I said, take Java&#x2F;Kotlin+JavaFX+Scene Builder+Conveyor and you have something similar to the highly productive 90s era platforms. You do of course need the confidence to learn tech that some consider old fashioned, and which isn&#x27;t as widely used as React or whatever.You could even just go all-in on the Apple platform! Swift+Xcode+their Interface Builder still works.[1] https:&#x2F;&#x2F;conveyor.hydraulic.dev&#x2F;[2] https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=jKeHKe9ttas reply lelanthran 4 hours agorootparentprev> It&#x27;s significantly harder to put together a quick GUI application in Python than it used to be in the VB6 days. Just getting all the dependencies installed can be a pain, and then good luck trying to add another button to that app say 2 years later, chances are nothing will build anymore.I would say that it is harder, but not significantly so.Lazarus gets mentioned a lot on these forums, but have you tried it? I use it to whack together decent native looking applications.It&#x27;s a single download, it comes with a comprehensive list of components which you drag onto a form to build the GUI, never breaks old apps on an update, and works on Windows, Mac and Linux. reply emodendroket 10 hours agorootparentprevPython is also more palatable to professional developers than VB ever was. reply gabereiser 12 hours agorootparentprevVB6’s concept of OOP was different. Sure the same keywords are found: Module, Sub, etc but it was rewritten to run on IL&#x2F;NET VM. Fundamentally changing it from a COM compatible language to a .Net framework compatible one. reply wvenable 11 hours agorootparentVB6&#x27;s concept of OOP was simple enough it could have been translated into .NET and .NET is broadly compatible with COM. I&#x27;m certain Microsoft could have made it work. They really needed to consider VB6 as a backwards compatibility target instead of building VB.NET as a modern replacement. VB.NET really has no reason to exist; it&#x27;s not compatible enough with VB6 but then also includes a bunch of VB6&#x27;s weirdness. reply gabereiser 7 hours agorootparentYeah, I agree. They didn&#x27;t know it at the time but .Net and C# (their answer to java) would take over everything they did. reply deaddodo 7 hours agorootparentprevThe visual editor is the same...but even with VB Classic, you couldn&#x27;t just design a UI and have it magically work, you needed to wire up the logic. That component has a much higher learning curve backed by a particularly more difficult to grasp language. reply dkga 4 hours agoparentprevAs someone who loved coding in VB6: (I actually dreamt about it the other night, thought I woke up some 20 yrs ago!)- very cool that you got to interview the VB team, your article is high on my reading list :) - to OP’s point, I recently started doing some things in Swift with XCode and found sim having just as much fun. I’m using SwiftUI. So maybe not the same experience for everyone but I wanted to share here. reply ShadowBanThis01 3 hours agorootparentI did a shitload of programming in VBA, specifically Word macros. Word 6 was the peak of that product. I wrote entire text-processing applications in it, with dialog boxes and everything. Started my career at a Big-6 firm with one, actually.Now I’m learning SwiftUI as well, and like it so far. I’m an experienced iOS dev, but SwiftUI is new to me. But I like it (and QML in Qt) more than I expected. Good luck! reply dkga 1 hour agorootparentThanks! Good luck to you too!I don’t have experience with iOS - I am actually doing a bit of macOS development with that SwiftUI because, well, desktop apps kind of take me to my teen years building VB programmes (no one called them apps, at least I didn’t). reply thread_id 10 hours agoparentprevVB and the Web: The VB model for rendering Web pages was Active Server Pages and Server side rendering. Very similar to Java Server Pages. Which was still better than PHP but the IDE did not have a community version and php was easier to get started and was being taught in college curriculum.IE having so much browser market also killed anything MS because they always tried to create their own standards which nobody wanted to follow. The client side was so difficult to script with having to test which browser and accomodate quirks mode. Another unforced error. Corporate adopters are still trying sunset critical apps which only run in IE or Edge with IE mode turned on. reply seanmcdirmid 4 hours agoparentprevMy understanding is that the target audience for VB.net was happy enough with C# instead, so it was a product without much of a user base. reply nrivoli 7 hours agoparentprevAs someone that started in vb6 and then php in 2001, this. reply yoava 5 hours agoparentprevI do not think the problem with VB was the language. I think it was the graphic &#x2F; UI expressive power, a simple way to add and create custom components.At the same time that both VB and Delphi reached peak usage, the web started to show how easy it is to express graphically and UI using CSS. When you have to write tons of lines of code in VB to get to the same as 3 lines of CSS... reply marcus_holmes 5 hours agorootparentThis doesn&#x27;t match my experience, if anything the other way around.CSS back then was a lot harder than it is now. There&#x27;s still memes around this, but even something as common as centering an item with CSS was not trivial at all. Now we have flex and it&#x27;s easy, but back then it was very much not.VB didn&#x27;t work on the same paradigm - it was a more WYSIWYG environment. You drew a button on the form, set some properties in the sidepanel, and that&#x27;s that. Notably there are zero lines of code involved in this, so the whole \"you have to write tons of lines of code in VB\" is simply not true. Possibly you&#x27;re thinking of its successor, XAML, for which this is true. reply yoava 3 hours agorootparentHaving worked for 10 years on both Delphi and VS, I understand the experience you are talking about. Having the ability to draw UI is amazing, and super productive. For business applications, it is amazing.However, I still remember at around 2002 that we where asked to build specific custom user experiences, I think it was around reports, and using VB or Delphi was a lot of programming using draw commands... while using HTML and CSS it was fairly easy, even with the browser differences of CSS.Any custom component in VS or Delphi (I am talking atomic components, not composite) requires using basic draw commands, and a lot of them.The end result was that both platforms are not as expressive in terms of UI as the web, you cannot compare basic draw commands to structured CSS. reply marcus_holmes 2 hours agorootparentReports, yes, that was a pain in the arse. Anything where you had to generate controls on the fly based on data was painful. Crystal Reports was both a nightmare and a lifesaver at the same time. I always thought that someone should do a better job of it, but I did not want to go there ;) By comparison producing a report (or anything data-generated for that matter) in HTML was easy. reply mike_hearn 1 hour agorootparentprevThese tools were built for GUIs, not typography where they were very weak. They outsourced document production to other tools like Crystal. reply fendy3002 4 hours agorootparentprevcan vouch on this, since originally I really prefer WYSIWYG UI (VB, C# winforms, wpf) over web early. However security-wise it&#x27;s hard to enforce when using them, since they don&#x27;t really operating using client-server by default, having your backend logic prone to be reverse engineered.This doesn&#x27;t happen in web apps, since backend logic stays on the server. Whipping a html UI over the already server-client architecture is easier. In addition with ease of deployment of application making web apps very favorable. reply yoava 3 hours agorootparentVB and Delphi reference architecture was 2 tier - client and database. With this reference architecture, you are right about the security and distribution problems. You just reminded me of the shareware market and the hacked shareware markets...However, early on, around 1998, people started talking on 3 tier architecture of client - server - database on both platforms. There where even attempts to build web pages using both platforms (and later on .Net), which failed because of a lot of reasons, one big reason was not understanding the advantages of CSS. reply marcus_holmes 2 hours agorootparentprevI opened VS and looked at WPF again the other week. It was a surprisingly pleasant experience. Though my C# is sooooo rusty now (and not in a crab-like way).I wonder if there&#x27;s a market for \"WPF for Golang\"? ;) replydwheeler 15 hours agoprevVisual Basic (both of them) still exist, but their use has dropped dramatically through some big changes:* \"Visual .NET\" (aka \"Visual Fred\" http:&#x2F;&#x2F;catb.org&#x2F;jargon&#x2F;html&#x2F;V&#x2F;Visual-Fred.html ) was released by Microsoft. This was an incompatible language confusingly also called Visual Basic. I don&#x27;t think Microsoft realized how angry this made developers and businesses, who were being asked to spend hundreds of billions of dollars (USD) to rewrite code just to keep the same functionality. Before that time, many thought that Visual Basic&#x27;s wide use gave it a kind of \"herd immunity\". I don&#x27;t have numbers with me, but I remember that years later that a study found that some were sticking to the original Visual Basic (even though it was no longer supported), a few had moved to Visual .NET, and many other had abandoned Visual Basic entirely (some to C#, others beyond). In short, the Visual Basic community was split into multiple communities, and anyone using Visual Basic would have to worry about either lack of support or yet another harmful change.* The rise of the web and of platforms other than Windows (including Android, iOS, MacOS, Linux). Visual Basic is fine when you send files via sneakernet to another Windows user. Now people want to access through their web browser, smartphone, etc. If you have a website, anything can access it (as long as they have the permissions), and you don&#x27;t have to worry about synchronizing data changes the way you do if people make changes on their local device. Most of the simple \"fill in a form\" kinds of applications that Visual Basic was used for are more sensibly web applications (server side or client side).Visual Basic is still used. And yes, I think there could be better tools for developing software. But as best as I recall, that&#x27;s how we ended up here. reply madrox 14 hours agoparentAs someone who was writing Visual Basic.NET back when it came out, there was no upside to it over writing in C#. VB&#x27;s original sweet spot was for writing small scripts and apps in Windows, and it was the only language available. When the .NET line came out, you could do the same things in whichever language you wanted. When new tasks came in, I started defaulting to C# for that reason. I don&#x27;t think anyone actually prefers VB syntax. C# has a pretty robust community around it now. reply mike_d 14 hours agorootparent> When new tasks came in, I started defaulting to C# for that reason. I don&#x27;t think anyone actually prefers VB syntax. C# has a pretty robust community around it now.Which was your experience because you knew C. VB appealed to people who were not programmers (or not very good ones like me). Microsoft effectively tossed an easy to learn procedural language in the trash and said \"go learn all these advanced CS concepts or stop writing stuff\" to which most hardcore VB users chose the latter. reply eropple 13 hours agorootparentWhile maybe that&#x27;s true, that doesn&#x27;t map to my experience very well. After QBasic, I wrote a lot of Visual Basic 5 and 6. I had poked at C, but would not say I knew it, and had never done anything useful in the language. But I did exactly one thing in VB.NET before trying C# and realizing that it really did encapsulate and present a better way to think about code. It&#x27;s not perfect, but it&#x27;s much, much better--and in that era, .NET 2 or so, it was significantly more ergonomic and had better tooling than Java or PHP, the other two languages I learned about contemporaneously with C#.Maybe there&#x27;s a mass cohort of people who were simply not going to learn something new, but in the light of most of twenty years hence, I think that they made the right call. reply ethbr1 13 hours agorootparentI&#x27;ve worked with a ton (too many) VB programmers by virtue of the work that I do (UI automation).My experience all suggests that pure-VB (even .NET) is a treacherous dead-end, because it doesn&#x27;t scale in terms of complexity and project size, and the point at which is stops scaling is often unrealized by its developers.- VB(.NET) is amazing for small, simple gadgets.- VB(.NET) is terrible for large or complex systems.The problem is that VB is likely to be the only programming language that developer knows (moreso than developers in other languages).Consequently, when they reach the end of the reasonable VB road... they will NOT say \"Oh, I should learn C#.\"They will say \"How can I make this work in VB?\"And that&#x27;s when you start to get business-ending unsupportable messes of spaghetti code that just barely work, on a good day.Give a person only a hammer, and they&#x27;ll find a way to make the entire world a nail. reply ripley12 13 hours agorootparent> VB(.NET) is terrible for large or complex systems.This doesn&#x27;t make sense to me. I worked in a 50&#x2F;50 VB.NET&#x2F;C# codebase for years and while I don&#x27;t love the VB syntax, the two languages were 99% interchangeable. Nearly anything you can do in C# you can do in VB.NET, and vice versa. reply pishpash 8 hours agorootparentLol, it doesn&#x27;t scale because of the quality of the programmer, not because of the language. There may be some self-selection there but it isn&#x27;t because of the language or tooling. Any \"too easy\" language brings these comments. People complain about MATLAB too when in fact there is nothing wrong with it or VB. Of course you can abuse both for purposes they are not meant for. reply rightbyte 12 hours agorootparentprev> VB(.NET) is terrible for large or complex systems.Compared to what? It got support for multiple files and even luxuries like namespaces. reply bufordtwain 11 hours agorootparentprevI prefer VB syntax :) I&#x27;m not a fan of semicolons and curly braces. reply TedDoesntTalk 13 hours agorootparentprev> As someone who was writing Visual Basic.NET back when it came out, there was no upside to it over writing in C#Sure there was: C# didn&#x27;t exist yet. It didn&#x27;t exist for many years to come. It simply wasn&#x27;t an option. C&#x2F;C++ was, however. reply eropple 13 hours agorootparentVB.NET and C# were released concurrently, weren&#x27;t they? reply TedDoesntTalk 12 hours agorootparentYes. I thought he wrote VB, not VB.NET. reply babypuncher 12 hours agorootparentprevYou may be confusing Visual Basic .NET with Visual Basic 6 and its predecessors. C# actually predates VB.NET by about a year.VB.NET may be syntactically similar to VB6, but under the hood they were so different that migrating projects to VB.NET essentially meant a complete rewrite. reply danzk 10 hours agorootparentVisual Studio had a built-in migration utility which could get you 80-90% there. However if the original VB6 was spaghetti code written without Option Strict and Option Explicit enabled you had much bigger problems.The biggest breaking change was the removal of the global Printer Object so any printing code needed a complete rewrite. reply bc_programming 1 hour agorootparentMy recollection is that the migration tool was really just a tool that would fill your VB6 code with comments telling you that you had to rewrite stuff. Trouble spots were largely related to error handling On Error Goto and error handling blocks had to be refactored into proper Try...Catch blocks, which affected a lot of code, and another trouble spot was all File I&#x2F;O had to be rewritten&#x2F;redone, same with any drawing code; Resource files had to be recreated, etc; I don&#x27;t even think it could load the FRX files but I might be misremembering. I felt it simply wasn&#x27;t worth even bothering to try to directly convert to VB.NET, and since those programs I wanted to move forward I had to pretty much rewrite anyway, I decided to use C# instead and just make new versions. reply blincoln 9 hours agorootparentprevThe migrated VB6 code I saw back in the era when VS2003 came out was a thin glue layer over some compiled DLLs. So the result of using the converter was a thin VB.NET wrapper around very outdated, vulnerable, unsupported third-party code.Maybe other shops had a lot of pure VB6 code, though. replyjzb 14 hours agoparentprevVisual Basic is one of the best arguments for open source and community ownership in the history of computing, IMO. Microsoft&#x27;s decision to tank it was hugely painful for companies that had made major investments in it -- no company should make that kind of investment in a proprietary platform that can be killed off by a single company and not forked and maintained by others. reply _glass 13 hours agorootparentI totally agree with you, but unfortunately the lesson was not learned. Now in the back office you see \"standard\" software with their own scripting language, e.g., APAX in Salesforce, or ABAP in SAP. Which is seen as a step forward, which it is architecturally, but not the point that you rightfully mentioned. On the other hand, all code is cyclical, if someone were to make it in Python, that would have to be rewritten, too. At least if you go the Free Software way, you&#x27;re free to choose when. reply kdmccormick 15 hours agoparentprevLol, my first programming gig as a teenager was performing a VB6 -> VB.NET \"upgrade\" of a 200K sloc legacy desktop application, which obviously ended up being a total rewrite. Everything in my career since then has seemed easy in comparison. reply mdeeks 13 hours agorootparentIf this was mine, I&#x27;m so sorry :) Just kidding, I actually know my VB6 code is still running in prod.VB6 did let me learn to program very valuable utilities from scratch, with practically no programming experience. I probably owe my entire career to it and VBA. I took a C++ course once and it nearly turned me off of coding completely. VB6 saved me. reply mcmoor 6 hours agorootparentI learnt VB6 when I&#x27;m still 10 years old and all seems so simple and magical. Then I encounter \"Visual Basic\" again in high school and it&#x27;s almost unrecognizable with all the C# nonsenses. I still don&#x27;t enjoy programming GUI like I was in VB6. reply codazoda 14 hours agoparentprevI was a hobby VB developer at this time and I abandoned it shortly after VB.net without really realizing why. I also abandoned Windows completely shortly thereafter.The main thing that killed me was the size of the files that you had to distribute when you used VB.net. No one had the .net runtime early on and it was absolutely massive. I was paying for outgoing data by the gigabyte back then and our connections were much slower. reply wvenable 11 hours agoparentprevIf Microsoft had simply ported Visual Basic in a compatible way to .NET history would have been very different. What&#x27;s the point of the common language runtime when all the common languages are just reskinned C#?This was a major missed opportunity for Microsoft -- if they had brought Visual Basic proper in .NET it would have given hundreds of thousands of applications a smooth upgrade path into modern development. It also would have given the entire Office suite an upgrade path from VBA to .NET -- something they&#x27;ve still not managed.To this day, our office still has one critical commercial 3rd party application written in Visual Basic. It&#x27;s replacement is, of course, a web app written in .NET. reply redeeman 9 hours agorootparent> It also would have given the entire Office suite an upgrade path from VBA to .NET -- something they&#x27;ve still not managed.> To this day, our office still has one critical commercial 3rd party application written in Visual Basic. It&#x27;s replacement is, of course, a web app written in .NET.seems like they did, they just didnt care if it remained in office, and it seems the author didnt care that they got screwed over by microsoft :) reply Guvante 14 hours agoparentprevYeah, as someone who worked somewhere that had a VB6 project: VB.net was only at all useful as a stop gap between VB and C# and a barely useful one at that.The language as it stands is fine and interop with .NET means it is a decent choice to use, outside of C# just having a bigger user base from a \"how easy can I hire devs\" standpoint. reply alberth 14 hours agoparentprevASP & ASP.NETYou forget to mention those two, which are important to the history of events. reply swasheck 13 hours agoparentprevI wrote Dts package scripts in Vbs but had primarily used C# for application development. When Ssis came out with Sql Server 2015, they only released Vb.Net for scripting components. It wasn&#x27;t a natural transition from Vbs -> Vb.Net so we ended up writing libraries in C# and using those in Vb.Net. Brutal. reply agumonkey 14 hours agoparentprevGreat points. And in a tongue in cheek way, having reactive components you can attach handlers to fetch &#x2F; redraw you UI .. is still there, it&#x27;s just labelled vue or react ;) reply nickpsecurity 12 hours agoparentprevI was using Visual Basic 6 for throwing GUI&#x27;s together. I loved how it loaded and iterated in one second on a 400MHz P3. Then, we got Visual Basic .NET. It took forever to start up. Then, it wasn&#x27;t really Visual Basic. Then, iterations were slower.It was going to be a rough trip. I figured I might as well learn something different so the headaches have more of a payoff. I stayed on Visual Basic 6 for a while before quitting it. I&#x27;m using Python now and it still doesn&#x27;t feel as easy as VB6 did. reply mamcx 14 hours agoprevThe reason is even bigger than just VB.MS at the time just decide to fully kill the \"enthusiast\" developer and the \"single&#x2F;truly small\" team developer. This is mostly covered under the \"RAD\" umbrella.It kills VB, FoxPro, and now more evidently, Access (more like let it slowly die)..NET + Visual Studio + Sql Server are not a substitute in this market. Them are for \"professional developer\"&#x2F;\"a small cog in a big machine\". The worst part is that this move somehow kill the other tools in this space (because somehow others follow suit or whatever) and without somebody leading the charge to see how adapt this tool for the web. MS not getting the Web, Borland doing Hara-kiri and others getting annihilated by \"free\" open source and all that not helps.Ironically, this market have rebound in the myriad of tools like \"low code, notebooks, etc\" that fill (badly!) the gap. reply bonzini 14 hours agoparentSerious question: what is a good alternative to Access (edit: to build a GUI frontend to a database)? The database design tools and basic forms were incredibly easy to use, and there were very good tutorials for everything else. LibreOffice Base is different and not even close in comprehensiveness, and there seems to be nothing replacing it that isn&#x27;t a super expensive SaaS. reply mamcx 10 hours agorootparent> what is a good alternative to Access (or Fox, I add)Nothing.Access is(was) in fact a worse alternative to Fox:- Much worse DB engine, and that is saying a lot (FoxPro db can and get corrupted. A typical functionality that was added to any fox codebase was a utility to fix it)- MUCH MUCH worse programming language (VB) that is neither good as-is, much less as a data-programing language.Fox&#x2F;dbase is the only data-oriented language that was relatively popular and fit for the use-case.This is by a mile the main point: Is a desert looking for languages that are made for business app&#x2F;data oriented programing (and much harder looking for something not weird).The main options: Fox&#x2F;dBase&#x2F;Informix(? not remember), kdb+, Cobol, SQL(when extended as store procedure lang with loops and that)--This point is big. Having a good form builder (that is already rare) is not enough to be a real contender for this space. You need a language where making queries is truly nice.In short, you need a language that is `LINQ&#x2F;Relational` as first-class end-to-end.- If this lang needs an ORM: FAIL.- If this lang needs to compose strings to make a query: FAIL.- If exist \"impedance mismatch\" between data manipulation&#x2F;queries and the rest of the lang: FAIL.- It should also support super-advanced types like date, decimal, currency and ideally dimensional units. Ideally algebraic types as today.- It should have a version of Rust `serde, Into&#x2F;From` traits, for easy conversion between data + formats.- It should look \"normal\" like python&#x2F;swift with `LINQ` queries.This is the lang I trying to build: https:&#x2F;&#x2F;tablam.org reply olvy0 5 hours agorootparentAs someone who loves LINQ, this is really cool, best of luck with your language! There is certainly a void that is waiting to be filled by such a language.Although as other said on this thread, the real killer feature would be a form builder as in foxpro etc. It can be somewhat primitive, as long as it&#x27;s easy to build and extend. Ideally the forms should be web based. reply mamcx 5 hours agorootparentSure, the UI side is pretty important!But I try to get a good companion for it, so it get good synergy. reply no_wizard 9 hours agorootparentprevLooks alot like Lua!and thats not a bad thing per se reply fluidcruft 12 hours agorootparentprevLibreOffice Base is... okay. It&#x27;s not great but I was able to do most of the things I used to use Access for (simple small CRUD database tools that let you quickly build forms, simple table relationships, enter&#x2F;review data, generate reports). Basically, it&#x27;s better than nothing and nothing is what we&#x27;ve got now. Base can get pretty confusing at points and has given me a lot of head-scratchers at some times.Even with otherwise seemingly easy-to-use web-based improvements to Excel that my employer has like smartsheet... these don&#x27;t seem to let you do any sort of super basic many-to-one relationships (maybe with some expensive ad on package? dunno... and smartsheet has plastered their site with a bunch of 101 intro to databases SEO spam that explain what different types of relationships are rather than how to fucking build them with smartsheet) reply LeifCarrotson 14 hours agorootparentprevSQLite. It&#x27;s not close in terms of ease-of-use of the GUI administration and forms, but as a single-server database solution to embed into a line-of-business app it&#x27;s fantastic. reply afavour 14 hours agorootparentThe GUI and forms is what made Access, though. Back in the day I actually made a system with Access that connected to a SQL Server database on the backend rather than Access&#x27;s file-based engine.It&#x27;s a real shame Access died, now there&#x27;s no path from a spreadsheet to something more sensible. reply jkaplowitz 13 hours agorootparent> It&#x27;s a real shame Access died, now there&#x27;s no path from a spreadsheet to something more sensible.Although it has certainly died in terms of mindshare, it&#x27;s officially still supported for PC (not Mac):https:&#x2F;&#x2F;www.microsoft.com&#x2F;en-us&#x2F;microsoft-365&#x2F;accessI actually have it installed right now, because it comes with Microsoft 365 Family, which I have on the Windows PC on which I&#x27;m typing this comment. I haven&#x27;t used the modern version of it, though. reply eastern 8 hours agorootparentprevThis is so true.A cross platform Access-like front-end that used sqlite as the data storage engine would conqueror large parts the territory. reply chasil 13 hours agorootparentprev...it&#x27;s fantastic if you are able to live within its limitations, primarily being a single writer.If your application grows into the need for concurrent writes, then it will be time for another database. reply wild_egg 13 hours agorootparentYou may be surprised at how far you need to grow to truly need concurrent writes. Blazing fast sequential writes is good enough for the vast majority of applications reply bonzini 13 hours agorootparentprevI know how to write a Django app with a SQLite backend, but that&#x27;s not what Access does.There are basic SQLite GUIs, but they have no reporting functionality and no customizable forms. reply nvy 14 hours agorootparentprevEqually serious question: what is the use case for Access?It&#x27;s been installed on every corp workstation I&#x27;ve had and it&#x27;s never been useful. In my experience either Excel can do it or you need a real programming language&#x2F;database. reply mikewarot 13 hours agorootparentAccess allowed maintained \"relations\" between tables, so you didn&#x27;t need any code to have a master&#x2F;detail relationship between tables, it just handled it all. This carried over to forms, queries, reports, etc. You could have a system with data entry, master&#x2F;detail records, queries and reports built in a day, all without ever doing any SQL.Through ODBC, you could connect to pretty much any database around. I think Office 2000 Professional was one of the best products Microsoft ever produced, it&#x27;s all downhill since then. reply jkaplowitz 13 hours agorootparentPast tense? For PC users (not Mac), it&#x27;s still supported and included with Microsoft 365. reply mikewarot 11 hours agorootparentI don&#x27;t have Office 365 any more... so I wasn&#x27;t sure... Microsoft seems to slowly be killing functionality in everything, so I couldn&#x27;t be sure.Also, things went downhill when they got rid of full menus and introduced the accursed \"ribbon\". reply mike_d 14 hours agorootparentprevAccess was an app you had installed on your workstation but never opened because in the backend every late 90s early 2000s desktop app was using it as its data backend.Between Excel (with no functional API to use for storage) and a \"real database\" (your users now need to ask IT to deploy SQLServer) was a use case of app just needs to store persistent data for a single user. reply euos 6 hours agorootparentI remember there was at least one video game (some turn-based tactics game, don&#x27;t recall the name) that had Access as a savegame format. It was very convenient to edit the save file. reply piperswe 2 hours agorootparentprevSo basically the SQLite of its day? reply rvba 1 hour agorootparentAcess allowed you yo build small forms&#x2F;apps fast.Those business apps made \"by that one person\" that allowed few other to input data concurrently (back then no google sheets &#x2F; shared Excel... which are horrible and have no user defined GUI) and then to make reports.Also data manipulation when it didnt fit Excel (I know access has 2gb limit, but it was a lot). reply bluehatbrit 13 hours agorootparentprevI know of small companies and charities that would use Access as their homegrown CRM back in the 2000&#x27;s. It worked really well, you just needed one guy who&#x27;d be willing to set it up and they&#x27;d be good to go with the basic forms for a couple of years usually.It&#x27;s definetely not great by todays standards when it comes to backups and what not, but it was really fantastic at the time. reply Retric 13 hours agorootparentprevAccess had a very low barrier to entry and sanitized inputs. Excel doesn’t cater to minimally skilled people who want to hand off forms to someone else for data entry.Why is this zip code a phone number? It’s not the users fault, your using the wrong tool. reply CrimsonCape 13 hours agorootparentprevI used it to create a detailed opinion of cost with recursive summing, so that item costs were summed per section, section costs summed into summary costs, summary costs summed into project cost.No other document designer that I&#x27;m aware of allows for runtime integration of variables into the layout&#x2F;presentation. reply safaaus 9 hours agorootparentprevPrototyping - occasionally when starting out on a big in-house development project, we&#x27;d task one or two guys to build a prototype in access to understand the challenges, functionality, data issues and get user feedback on what worked and what didn&#x27;t. Invest 3-4 weeks of effort that saved us months of effort from the project overall and de-risked the project substantially. One time it back-fired a bit when the users liked the access proto-type more than the final system (pushed the envelope a bit too much and the performance was very poor), but typically got plenty of value out of it. reply harry8 9 hours agorootparentprevSeen a lot of screw-up by someone taking a databse export (csv or whatever) into excel to work on it, sorting but only sorting one column leading to disaster.This is just unbelievably &#x2F;common&#x2F;. reply sebazzz 13 hours agorootparentprevPowerApps probably, and with the transition to the cloud Microsoft will probably not invest too much into stuff that can&#x27;t run well in a web browser and mobile app. reply bonzini 13 hours agorootparentA monthly subscription is a non starter for charities and also it needs a work or school account. reply no_wizard 9 hours agorootparentLast I interacted with Microsoft they were quite generous here. They have special pricing for non-profits and they definitely have a whole different structural thing for schools reply pge 14 hours agorootparentprevAirtable is the closest I have found for ease of use - users that don’t know SQL can put together basic queries and views quickly. reply bonzini 13 hours agorootparent1000 records per table on the free tier is ridiculously low, it basically makes many to many relations impossible. It also doesn&#x27;t have reporting, and I have no need for attachments. reply xet7 6 hours agorootparentprevMaybe:a) https:&#x2F;&#x2F;www.nubuilder.comb) https:&#x2F;&#x2F;gambas.sourceforge.net&#x2F;en&#x2F;main.html reply phs318u 2 hours agorootparentAlso:c) https:&#x2F;&#x2F;github.com&#x2F;twinbasic&#x2F;twinbasicOnce it gets out of beta. reply dijit 14 hours agorootparentprevThe parents point is that there is no alternative, because everyone left the market chasing Microsoft. reply muststopmyths 13 hours agorootparentprevmaybe SqlServer Express ? It has limits on memory and DB size, but if your project is small it might suffice, in conjunction with Management Studio Express.I&#x27;ve never used Access so apologies if you&#x27;re looking for more than a GUI-driven interface to the DB. reply JohnBooty 12 hours agorootparentSQL Server Express is just a (fairly generous, last I looked!) limited version of the full SQL Server.So, it&#x27;s a substitute in terms of affordability. But absolutely not in terms of \"rapid GUI application development\" for the non-programmer. reply AdrianB1 11 hours agorootparentprevIt is not. Access was easy to build the app on top of a reasonable database seamlessly, integrated, visually. SQL Express is just the database part and there is nothing that integrates so well on it like Access does internally. Access is not powerful enough for larger databases, but boy it was easy to use for small ones. reply pmontra 4 hours agorootparentprevCheck Filemaker. A friend of mine is a 100% Filemaker freelance. Apparently it can also generate web sites over the data in its db. reply steve1977 14 hours agorootparentprevFor a long time I would have said FileMaker, but considering the strategic moves of Claris in the last few years probably not anymore reply layer8 13 hours agorootparentprevThere is no good alternative, really. reply gremlinunderway 5 hours agorootparentprevBudibase looks really impressive, basically a GUI frontend builder for postgres and its open source. Haven&#x27;t actually deployed it, but played with the GUI builder and its nice.There&#x27;s a few other similar ones out there too like Baserow [2], Appsmith [3] and nocodb [4].Finally, if you wanted a step up, then I guess supabase [5] would be the next one up but its more like \"I just want to write front end and have auth, database, API and storage taken care of for me\"But none of these really give you that all-in-one database and front-end via files like Access did and its a damn shame. Yeah I know Access lead to some god-awful applications, but honestly the people complaining about shadow IT don&#x27;t realize that its inevitable if IT isn&#x27;t fixing people&#x27;s problems. You just need to be clear that if the business unit goes down that path, they&#x27;re on their own. So if the guy who built your crazy Excel VBA app is gone, don&#x27;t expect that to be picked up by others just because its super important. But, if it is in fact that important, then its probably a prime candidate for actual development work, so the duct-taped together things do end up being sort of testbeds for whats actually important.The whole lowcode-nocode shtick is a bit oversold, but one good aspect of it is that if you allow for an easy onboarding sandbox for the type of person who would otherwise make an Excel VBA app, at least some of these platforms have sandboxes with guardrails and other compliance stuff you can apply.[1] https:&#x2F;&#x2F;budibase.com&#x2F; [2] https:&#x2F;&#x2F;baserow.io&#x2F; [3] https:&#x2F;&#x2F;www.appsmith.com&#x2F; [4] https:&#x2F;&#x2F;github.com&#x2F;nocodb&#x2F;nocodb [5] https:&#x2F;&#x2F;supabase.com&#x2F; reply bonzini 3 hours agorootparentAt least Access has a sound model underneath. Excel is nothing but a damn grid, while Access has tables, keys and constraints _and_ a visual GUI builder on top of those. The development environment was an only slightly pared-down Visual Basic but it was fully integrated in the rest of the GUI, while VBA always felt like it was tacked on the rest of the application. reply Biganon 14 hours agorootparentprevFilemaker? reply Tao3300 11 hours agoparentprevJesus Christ, not FoxPro.I briefly worked for a company whose main product had been a FoxPro application that they rewrote piece by piece in C#, reimplementing various FoxPro idioms as they went. It was a nightmare and no one knew what any of it did. One \"senior\" developer tearfully argued with me during a code review that even fixing comments could have dire consequences.I suspect that someone higher up liked it that way, because I was fired shortly after mathematically proving that something was really wrong in some of the accounting code. reply mamcx 10 hours agorootparentWell, no programing language is good for data applications as is FoxPro (certainly not C#), and is terrible to writer LANG-a in LANG-b.So sorry for you to get the worst of both worlds!P.D: I do a port from a Fox app using idiomatic C#, like 10-30x the size of it, but well it was idiomatic! reply pishpash 8 hours agoparentprevAll the consumer products were killed, like Encarta, games, Microsoft home stuff. MS went full enterprise. reply mamonster 16 hours agoprevDoes VBA for Excel count? Because if it does then VBA for Excel has reached the\"nuclear resistant cockroach\" level in finance.You wouldn&#x27;t believe what sort of processes in very big banks&#x2F;financial institutions are built using 10 year old VBA macros. In fact, VBA consulting for finance is a very juicy cottage industry at least in Europe to this very day. reply nottheengineer 16 hours agoparentExcel is literally 2D programming. Us mortal developers who can only put lines below one another are incapable of comprehending it, so we only get to ask the wise finance people how their enigma works.On a serious note, I dread excel. If your PC is set to german, excel will translate the VBA keywords to german. But if you want to type them, you have to do that in english and then have excel translate them.I don&#x27;t want to accept that crap like this is the standard. reply tombert 13 hours agorootparentI have grown a respect for Excel in the last decade or so. It&#x27;s slow, it&#x27;s clunky, and it&#x27;s far from perfect, but I think it&#x27;s among the most approachable language out there.A lot of people using Excel, even some of the more advanced stuff like if statements and logic, don&#x27;t even realize that they&#x27;re writing programs, and I think that&#x27;s genuinely awesome: people are able to utilize the power of programming by accident.I still use spreadsheets all the time for small number crunchy things, just due to how it&#x27;s \"reactive by default\". I find it&#x27;s actually really useful to immediately see everything update after changing a value. Admittedly, I mostly use Google Sheets nowadays simply because it&#x27;s \"good enough\" and much easier to share with friends. Could I write a program to do all that number crunching that performs better? Obviously yes, I could start a new Julia project and mop the floor with Excel or Google Sheets in regards to saving cycles, but that would take me 20x longer and I&#x27;d lose all the nice features of a spreadsheet.Granted, this is coming from a strictly Anglo-American perspective; I cannot speak to Excel&#x27;s ability to use other languages. reply benhurmarcel 1 hour agorootparent> I cannot speak to Excel&#x27;s ability to use other languages.I find it&#x27;s an overblown issue. Those of us that prefer functions in English can just set Excel to use it. When someone sends you a file it displays in your chosen language. And having the default being localized makes it usable for the majority of people who don&#x27;t speak English. reply harry8 9 hours agorootparentprevGnumeric is actually a good excel. The stats routines are shared with R so if ever someone demonstrates a bug, it is fixed!Free, fast, accurate. Pick any three!http:&#x2F;&#x2F;gnumeric.org reply quickthrower2 5 hours agorootparentprevI find a spreadsheet (Google Sheets will do) is a great thinking tool. Any thinking will involve probably some maths and some tables. Excel is built for both. reply wiz21c 15 hours agorootparentprev> Us mortal developers who can only put lines below one anotherAt least my spaghetti code goes into one direction only... reply eastern 8 hours agorootparentYes, but I bet your code cannot reveal its own spaghetti:-)Excel has long had an option to display &#x27;precedent&#x27; and &#x27;dependent&#x27; cells.You can actually see the spaghetti right there.https:&#x2F;&#x2F;support.microsoft.com&#x2F;en-au&#x2F;office&#x2F;display-the-relat... reply quickthrower2 5 hours agorootparentNow do that for the VBA! reply mikewarot 13 hours agorootparentprevExcel is a quite powerful mix of declarative programming (formulas in cells), and imperative programming (VBA procedures, event triggers, etc). If you&#x27;re not ready for it, it&#x27;ll break your brain.The main danger in Excel is that any area of a sheet can be treated as a pseudo table.... except it really isn&#x27;t, and you can inadvertently sort some fields, while leaving the others alone, effectively scrambling your data. reply eternityforest 14 hours agorootparentprevThe 2D aspect is the part of Excel I don&#x27;t understand. Why does it have to be a grid?It&#x27;s great for laying out things meant to print, and making invoices and stuff... But why didn&#x27;t we have code files and proper fixed layout DB-style tables as \"pages\" that can go in a workbook?Maybe keeping everything as 2D as possible is a necessary compromise for the spatial thinkers out there, and they just wouldn&#x27;t want it if it was full of boring linear stuff.I love the reactivity and the concept that anywhere you put a value, you can put an =expression. But the 2D stuff seems like it&#x27;s for the people who always have a sense of where things are in space.They&#x27;ve done a good job of convincing people that it&#x27;s not programming and they can do it, I can&#x27;t really complain, because if Excel didn&#x27;t exist we might all still have to use paper on a regular basis, or completely unstructured text files. reply function_seven 13 hours agorootparentThis is why I&#x27;m fanatical about using proper Tables in Excel wherever possible. Any db-like kind of data is first turned into a table, then I work with it using whatever formulas, code, or tools I need to. Half the time this means dropping into PowerQuery to do more transformations on the entire set, then finally using Excel formulas or pivots as needed.But I really like Excel for allowing me to just plop stuff down wherever when I&#x27;m brainstorming something, or just want to do a one-off calculation before I quit-without-saving. reply jpadkins 12 hours agorootparentprev> Why does it have to be a grid?Because we have been doing it that way for almost 4,000 years!https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Spreadsheet#HistoryHumans have organized data into tables, that is, grids of columns and rows, since ancient times. The Babylonians used clay tablets to store data as far back as 1800 BCE.[16] Other examples can be found in book-keeping ledgers and astronomical records.[17]Since at least 1906 the term \"spread sheet\" has been used in accounting to mean a grid of columns and rows reply philistine 5 hours agorootparentprevEverybody who replies to you, I think, has gotten it wrong. What you&#x27;re asking is not why any grid, but why an infinite un-malleable grid.What you want is the paradigm of Numbers from Apple. Their office suite is good, and it has the benefit of being opinionated. They&#x27;re not trying to ape Microsoft, like all the open-source projects. reply layer8 13 hours agorootparentprevIt’s because Excel sheets are often used like forms to fill some fields in, with labels, and dedicated formulas in the background. And sometimes part of that form is a table, but also graphical charts etc. on the side. Excel sheets can be designed almost like in a layout program, also to be suitable for printout. People like that freeform spatial-thinking flexibility about Excel. reply eternityforest 11 hours agorootparentIt&#x27;s amazing as a layout program for sure, as long as you&#x27;re not going to interact with it much on mobile.Then it&#x27;s pretty bad but still better than writing some custom software like people would probably do without it. reply nottheengineer 14 hours agorootparentprevWhen doing calculations on paper, you can write your interim results anywhere. That&#x27;s what excel copies. It&#x27;s also why text in excel files will gladly overflow into adjacent cells. reply mikewarot 13 hours agorootparentThe overflowing text isn&#x27;t actually stored in the adjacent cells, it&#x27;s just displayed on top of them. The difference is important. reply eternityforest 11 hours agorootparentprevThat kind of thing seems very natural if you&#x27;ve done any calculations on paper recently(Which most business people have) but seems strange to programmers who haven&#x27;t.You would think the ideal would be to allow everything Excel currently does, but also have some other model with more separation of code, data, and visuals, like node-based programming and separate cloud-synced pure tables.Excel can almost cover a lot of \"real programming\" use cases, but not quite. The upgrade path seems to be Excel to Access to Custom app, rather than Excel to Excel but with more of the advanced features. reply rzzzt 14 hours agorootparentprevWith side-effect free functions: https:&#x2F;&#x2F;youtu.be&#x2F;0yKf8TrLUOw reply vector_spaces 14 hours agorootparentprev\"2D programming\" is normally called array programming, and it&#x27;s common in scientific computing, ML, and finance. It does require a different mindset, kind of similar to SQL but not exactly. See APL, K, q, NumPy, matlab, Julia, and friends for languages that embrace this paradigm reply Philpax 14 hours agorootparentI don&#x27;t think you&#x27;re talking about the same thing? The parent poster is talking about Excel&#x27;s ability to spread computational steps across rows and columns (i.e. the structure of the code itself), while array programming traditionally refers to writing computations over arrays (i.e. the structure of the data) reply netsharc 14 hours agorootparentprev> But if you want to type them, you have to do that in english and then have excel translate them.Huh? At least in the versions I&#x27;ve used I&#x27;ve always needed to type the commands in German.There&#x27;s even an online German - English Excel dictionary... reply nottheengineer 13 hours agorootparentI wittnessed this very fuckery with my own eyes just two weeks ago:It was an excel file created in pandas that threw an error on english commands but worked if the code included german ones.I don&#x27;t know how or why that happens, I just know I need to get away from it. reply trimethylpurine 9 hours agorootparentprevI can&#x27;t understand why so many finance people won&#x27;t just learn SQL. reply quickthrower2 5 hours agorootparentSQL is not a replacement for Excel. reply davidmurdoch 16 hours agoparentprevI know of a restaurant franchisee with 170+ locations that uses a home grown ERP system built in VBA on top of Access by an accountant about 20 years ago.I once had to update it to optimize (minimize) front-line staff working hours so the company didn&#x27;t have to pay health insurance for those employees. A real nightmare of a task in more ways than one! reply matwood 15 hours agorootparentMy first programming job in the 90s while I was still in college was building systems exactly like you describe (and they were as poorly built as you think hah). I worked for a small IT programming&#x2F;consulting shop. We did small jobs like this in town in addition to installing networks, IVRs, etc... while working on larger software to sell (which is an entirely different&#x2F;crazy story that involved burning CD demos and using a hand &#x27;stomper&#x27; to label and then mail them out). reply protocolture 10 hours agorootparentprevIn high school I got a gig rebuilding a pre 2000 Access DB + VBA front end in office 2003ish due to some kind of incompatibility that was preventing them from upgrading their PC&#x27;s.It was a chemical safety database. It was used to identify chemical risks and track the storage of the chemicals.I pray near daily that someone else came along years later and rebuilt it in a modern language. reply davidmurdoch 10 hours agorootparentAh yes, where testing just means \"I hit save on the live database file and didn&#x27;t received an angry call from accounting 2 minutes later\" reply aj7 14 hours agorootparentprevThis post has more information than you realize. reply davidmurdoch 14 hours agorootparentWhat do you mean? Are you suggesting you can figure out who the company is? reply mattgreenrocks 12 hours agorootparentI have a guess, but don’t want to offend the big cheese there so I’ll just see how this plays out. reply schmookeeg 16 hours agoparentprevHealthcare and insurance too! I transform into some glorious magical elf when I volunteer to do the VBA tasks nobody else understands or can lower themselves to do.You can make Excel do some real wacky stuff. I have a spreadsheet that actually calls out to exec() to run a curl POST on commandline and consume REST API endpoints, parse the results, and update the spreadsheet -- why on earth?? because the API was ready but the web app was delayed. I was the fix. :D reply eli 15 hours agorootparentPretty sure you can access a REST API from VBA without resorting to exec() reply Shorel 15 hours agorootparentIt only works with toy examples and then stops working. For reasons unknown, as it should work. reply pillefitz 15 hours agorootparentNever had issues with the standard VBA HTTP Interfaces reply schmookeeg 10 hours agorootparentprevWe support both mac and pc excel -- the mac VBA is seriously gimped. reply TrackerFF 14 hours agoparentprevPre-face: I write a lot of VBAVBA is kind of the result of people only - ONLY - wanting to use Excel for everything. I work with those people. They have mastered excel, but have little to zero interest in learning anything else, and would rather see the world be built around excel.So you (like me) get tasked with building applications and forms in VBA.I was STOKED when MS announced Python for excel, but alas, turned out to not be what I (and many other) wanted.What&#x27;s the medicine? Dunno, hire analysts that are more open to using other tools . Don&#x27;t get me wrong, I love using excel for many tasks - but damnit, it&#x27;s not the only tool. reply wavemode 13 hours agorootparentThe company I worked for in college was in the \"VBA for everything\" world. It was like the Renaissance when they started experimenting with Power Query for some use cases. (Which, honestly, was still a terrible language. But slightly more maintainable than VBA.) reply j45 13 hours agorootparentprevVB is not VBA, VBA was a relatively small subset.I might be mistaken but wasn&#x27;t VBA brought into Excel as a familiar element from the VB world?It is true though that some of the more purer or more initial concepts of VB likely live on in the VBA subsets of Excel.And Access. reply TrackerFF 12 hours agorootparentVBA works fine if you want to create macros and automate various things for your spreadsheets, but the problem is that the end user want &#x2F; demand full-blown applications layered over their spreadsheets. The last thing I worked on was a CRUD -interface where the user could read and write data from their spreadsheet, to a azure DB.It wasn&#x27;t difficult, but at its core, I had to do it because the end users didn&#x27;t feel like using some other interface - they really didn&#x27;t want to leave their excel spreadsheet. reply dauertewigkeit 16 hours agoparentprevMy brother is a mechanical engineer and apparently, there&#x27;s lots of Excel VBA in traditional industries as well. reply tombert 13 hours agorootparentMy dad works in Aerospace (though admittedly more on the managerial side, but he still tries to stay technical), and he does all of his initial programming in Excel first, and then will port it over to Matlab if he needs something more code-like.I&#x27;ve been trying to get him to use Julia for that second step since I absolutely hate Matlab, but I honestly don&#x27;t fault him for using Excel in the initial phase. reply bmj 15 hours agorootparentprevI can confirm this: I know several mechanical engineers that do mission critical-type systems (think \"power plants\"), and they routinely use Excel VBA for calculations. reply pillefitz 15 hours agorootparentAnd it&#x27;s often the best tool for the job reply harry8 9 hours agorootparentOther than the known calculation bugs in excel that MS refused to fix for at least a decade and probably still 20 years later.http:&#x2F;&#x2F;www.pages.drexel.edu&#x2F;~bdm25&#x2F;gnumeric.pdfhttp:&#x2F;&#x2F;www.phusewiki.org&#x2F;docs&#x2F;2009%20PAPERS&#x2F;SP06.pdfhttp:&#x2F;&#x2F;www.tandfonline.com&#x2F;doi&#x2F;abs&#x2F;10.1198&#x2F;tas.2011.09076 reply rvba 1 hour agorootparentIt is funny how you talk tjat Excel is bad and the examples just dont work.Also lack of accuracy in calculating some complicated statistics that \"nobody\" uses is not really a calculation bug.Also most of those come from the fact that Excel has a precision of 15 digits. reply pillefitz 5 hours agorootparentprevOnly last link works replydatavirtue 16 hours agoparentprevThere is a book called: Professional Excel Development. If you want to get into it. You could probably use that book to build an OS in Excel. I&#x27;m not joking. reply Flowzone 14 hours agorootparentThis sounds like it would be right up my alley. I&#x27;m not a professional developer of any kind but have done hobby coding on&#x2F;off for years, and I&#x27;m better at excel than the average user.Currently working for a consulting company with a whole region&#x27;s health system as the client. They use excel for lots, but it&#x27;s all very basic stuff. I had one of my team members spend an hour whipping up an excel form for them that auto generates letters to different departments with all the necessary information. Even some basic standard work forms, let alone any sort of automation, would help them a lot as they rely on people to send certain information that gets missed every time. They described our excel sheet as a game changer for them.Almost no-one has access to their ERP system which is safeguarded by a certain department which is ridiculous. I&#x27;m working on a spreadsheet for their HR team to calculate bonuses for certain employees based on a bunch of variables, then auto-generating letters to review and distribute. The data from their ERP software is such a mess, but I&#x27;m making up for it by cleaning up their reports in excel. I plan to get access to their ERP system to look at what kind of reporting I can do as HR only gets a report from the system once a month. I want to help them track real time stats for hiring, etc. And curious if I&#x27;m able to connect some spreadsheets to their ERP with an API or something (haven&#x27;t done anything like that before).Anyways, that professional development for excel book looks interesting. I see the second version is from 2009 and may not even be up to date with 2007 excel. I&#x27;m sure most of the concepts would stay the same though, so I&#x27;ll definitely have to check it out.I realize excel wouldn&#x27;t be considered the most professional or robust way to build applications, but since microsoft 365 seems so standard and everyone uses excel, it makes sense to me why so many organizations use it. There seems to be a lot of potential to apply some excel automation in a lot of industries, especially ones that already rely on it as others have mentioned in this thread. I use it as a means to an end when helping clients, but I also see dollar signs as I find ways to build things that can be applied to so many industries. reply datavirtue 11 hours agorootparentMake sure you build subs (functions&#x2F;methods) for everything....I mean everything. Break all of your code into the smallest subs possible with clear names. Otherwise you will not be able to make heads or tails of your own code in a few months. I built a fairly sophisticated VBA project and left it for a few months, came back and was pulling my hair out. I had to refactor before I could move on, and it was very painful. After the refactor I could make changes and modify it without issue. You have to be, what seems like, over-granular. Its just \"clean code\" principles: the name of the sub should describe exactly what it does. If the name is too big...break stuff out into different subs.Excel is perfect for building proof-of-concept apps and Microsoft has a cloud offering called PowerApps that use a somewhat similar \"Excel concept.\" I have built a significant app in PowerApps...not recommended. If you don&#x27;t have a development team Excel is good. Same for PowerApps. Very painful if they get big. Keep things simple. reply jandrese 15 hours agorootparentprevIt&#x27;s no more crazy than trying to build an OS out of a web browser. reply vb-8448 16 hours agoparentprevSo true!!! :D :D :DIf Excel stops working, financial institutions around the world would collapse. reply daydreamtrip 12 hours agorootparentPython was just added to Excel so there&#x27;s not much chance of that reply JohnBooty 12 hours agorootparentReally?? Oh, wow: https:&#x2F;&#x2F;techcommunity.microsoft.com&#x2F;t5&#x2F;excel-blog&#x2F;announcing...Actually that&#x27;s really awesome, I think.My goal is basically to never touch Excel again. But, I have to admit - that 2D mixture of data and code called \"a spreadsheet\" is honestly a pretty cool programming paradigm for a lot of tasks. It can be horribly abused... but so can everything. reply Spinnaker_ 14 hours agoparentprevAnd not just old school financial institutions. Jane Street used to run out of an excel sheet. Many hedge funds still do. reply aj7 14 hours agoparentprevBefore VBA for Excel, I wrote numerous macros, including ATAN2(x,y) before there was an ATAN2.Afterwards, forget it. Maybe one. reply system2 3 hours agoparentprevI can&#x27;t imagine Excel without VBA. I tried Google Spreadsheets with js and it sucked big time. reply harry8 9 hours agoparentprev10 year old you say.... office 97. reply underlipton 14 hours agoparentprevI used it as a coding layman in 15-buck-an-hour \"admin\" (clerk&#x2F;secretary) roles to automate some processes that my predecessors had done by hand. Mostly just copying entries from a spreadsheet to company Excel&#x2F;Powerpoint templates and printing them without killing myself copy&#x2F;pasting or going into the save&#x2F;print dialog 50 times. It did its work as something any old schmuck could harness to save themselves from carpal tunnel.To that point, I imagine that there are a LOT of admin jobs (or, at least, a lot of tasks) that could be almost completely automated away. It&#x27;s probably not even a capability issue, but one of job security on the employee side and a lack of *waves hands vaguely* on the employer side. reply JackMorgan 13 hours agoprevThe productivity wasn&#x27;t really that good. Rose tinted glasses. All the VB apps I&#x27;ve seen (and still get paid to maintain&#x2F;rewrite to this day in the finance world) are an order of magnitude simpler than even a simple modern website. They often only have a few users, no devops automation, no deployment automation, terrible logging, terrible instrumentation, no tests, unacceptable access control, tons of failure edge cases, and poor performance.Most don&#x27;t even have central databases, they just sit on Access and get copy pasted around like spreadsheets.While the UI part of Visual Basic was fast and easy, so is writing a React frontend that just stores data in browser LocalStorage, has no authentication, no logging, no monitoring, no tests, and deployment is emailing an updated js file to customers.The complexity of modern development enables 10-100x better productivity across all aspects of: safety, security, monitoring, error handling, maintenance, and new feature development.I can whip together a modern website that ticks all these boxes. To achieve the same in VB+Access would be monumental. reply yc-kraln 13 hours agoparentI was with you until \"... so is writing a React frontend\".No. No it&#x27;s not. Making a functional UI in visual basic is childs play compared to the absolute cesspit of NIH and feature treadmill that frontend web development has become.You are gatekeeping with strawmen. reply JackMorgan 13 hours agorootparentI was trying to compare like for like on features. Slapping together a few fields and a button in react and posting the results to an unauthorized endpoint doesn&#x27;t feel any more difficult to me than the same in VB.However, it&#x27;s certainly an order of magnitude more complex to use react with all the features expected of modern development with design systems, auth&#x2F;z, logging, monitoring, etc. reply taeric 12 hours agorootparentI&#x27;m deploying react to a CDN for a living, and I would have no idea how to instruct someone to \"slap together a few fields and a button\" and put it somewhere meaningful. As a kid, I remember making full blown D&D character sheets based on an easy Access backend. You could even print them out.I want to, but I just can&#x27;t back any claim that things have gotten easier for pretty much anything. With a ton of extra power on the compute side, parts of the machine have gotten attainable. But nothing about the process is easier along the way. reply JohnBooty 12 hours agorootparentnext [–]I want to, but I just can&#x27;t back any claim that things have gotten easier for pretty much anything.I think it&#x27;s easier for a seasoned developer to spin up and deploy a \"real\" Djanjo&#x2F;Rails&#x2F;whatever app with decent table-stakes features like secure auth.But everything else is harder.I have zero idea how to tell a new developer to get started in the hobby&#x2F;industry these days.The real problem IMO is the absolute churning shitstorm that is front-end development. I don&#x27;t know how it got so bad, so quickly, and stayed that way for so long. We as an industry are not going to be happy until it takes at least 50 toolchain steps to produce a simple \"hello world.\" reply taeric 11 hours agorootparentGetting a rails app up and running used to be somewhat easy. You did have to ssh into a machine, but that wasn&#x27;t that complicated, all told. Comparable to standing up a BBS way back in the day. Restated, if you could have a machine that was dedicated to the serving of something, it wasn&#x27;t that hard back in the day.To that end, I suspect telling people to just stand up a node server is where to start hobbyists off? Still very complicated with the division between front and backend that is difficult to see for new folks.And I fully agree on the ridiculous churn. Having zero stability in documentation and how to do things has been terrible for our industry. What we have gained in better ways seems to mostly be lost in all of the previous ways that used to work. reply jaylittle 11 hours agorootparentprevA-fucking-men! reply hombre_fatal 11 hours agorootparentprevOn the other hand, I never understood how to build anything with Access despite having a book on it as a teen.Web tech, even in its early forms, was much more obvious to me and I could run code in the browser&#x27;s web console. I could find JS snippets online, paste them into index.html, and open the page. I found VB&#x2F;Access far more confusing than that.These days I help beginners pick up web dev and I think HNers overestimate (if not circlejerk over) how hard it is just because create-react-app does a lot of things. Client development always had a bunch of specific knowledge you had to learn, and the fat stack of supporting software you generally use (IDEs, Xcode, node_modules, SDK APIs, browser APIs, etc) was always a behemoth. reply taeric 10 hours agorootparentAccess was the hard part of those things. Using a form builder to get a basic form up and build some interactions, though, was trivial back in the day.Were there complications? Of course there were. Would I recommend some of those practices to build something? Not necessarily. But I can&#x27;t get behind any claims that we made any progress on making things easier for hobby programs.Closest we have to that, would be the scratch programs my kids have been making.Hilariously, the best thing for making games and similar ideas that my kids would have, is going to be Mario Maker. By a long shot. reply JackMorgan 7 hours agorootparentprevAnd where would you meaningfully deploy a VB form other than your personal computer? Likewise, you don&#x27;t need to deploy react at all if you are running it locally, just npm start. You can even print to PDF from the browser. You can use LocalStorage for persistence. Feature for feature, it approaches a local VB and Access project for about the same effort. I&#x27;ve taught many beginner students with this technique.My point was not that modern deployment is easy. Nor that modern react with all the trimmings is easy. My point was that the nostalgic view of VB is reductive and skips all the things we now consider essentials. And for the effort involved, we get much more done now than ever before, albeit at a much greater complexity cost and steeper learning curve. reply taeric 7 hours agorootparentI&#x27;m mostly with you on this, in that running `npm run start` or whatever feels close. However, it doesn&#x27;t give you the state management in near the same way. Nor does it have anything close to the form builders that you could use back when. Things can feel similar, if you ignore all of the other tooling that we had back then.Dreamweaver was surprisingly close for building a form or similar. We tossed a lot out the window when we decided to focus on the HTML side of that equation. I swear it is like a lot of the older assembly versus C that existed years ago. Only, we decided that we did, in fact, care about the assembly. reply quickthrower2 5 hours agorootparentprevI wonder how doable it would be to make a drag drop interface for building react complete with double click to add click handler and focus on that new code kinda stuff. reply Matumio 2 hours agorootparentprev> You are gatekeeping with strawmen.Love the image. \"Hey you! No visual aids go into this town! One more step, and my strawmen will React!\" But the accountant with the abacus continued towards the east gate. He squeezed between two strawmen, who didn&#x27;t React as much as the gatekeeper was implying. reply chaostheory 12 hours agorootparentprevA better comparison is with VB’a spiritual successor: Power Apps.Not sure, but I think VB is still responsible for most of MS’s security threats even now. It makes sense for MS to try to EOL reply anon____ 13 hours agoparentprevDon&#x27;t forget that most of those VB apps you&#x27;ve seen were hack",
    "originSummary": [
      "The author, possessing nearly three decades of software development experience, holds the view that no technology to date matches the development experience offered by Visual Basic in the 1990s.",
      "They express concern over Microsoft's decision to abandon Visual Basic and the apparent lack of a suitable successor."
    ],
    "commentSummary": [
      "The article discusses the decline in popularity of Visual Basic (VB) and VB.NET due to reasons such as Microsoft's focus on .NET and the rise of web technologies.",
      "It delves into the limitations and challenges in programming in VB.NET, the hurdles in transitioning from VB6 to VB.NET, and the demand for a more expressive language and advanced functionality.",
      "The conversation also covers topics such as the dwindling popularity of Microsoft Access, the quest for its alternatives, the pros and cons of using Excel, and a comparative analysis between older technologies like VB and modern tools like React and Power Apps."
    ],
    "points": 372,
    "commentCount": 463,
    "retryCount": 0,
    "time": 1694452376
  },
  {
    "id": 37477095,
    "title": "Death by a Thousand Microservices",
    "originLink": "https://renegadeotter.com/2023/09/10/death-by-a-thousand-microservices.html",
    "originBody": "RENEGADE OTTER Software BLOG DEATH BY A THOUSAND MICROSERVICES The software industry is learning once again that complexity kills Author: Andrei Taranchenko 10 Sep 2023 The Church of Complexity There is a pretty well-known sketch in which an engineer is explaining to the project manager how an overly complicated maze of microservices works in order to get a user’s birthday - and fails to do so anyway. The scene accurately describes the absurdity of the state of the current tech culture. We laugh, and yet bringing this up in a serious conversation is tantamount to professional heresy, rendering you borderline un-hirable. How did we get here? How did our aim become not addressing the task at hand but instead setting a pile of cash on fire by solving problems we don’t have? The perfect storm There are a few things in recent history that may have contributed to the current state of things. First, a whole army of developers writing Javascript for the browser started self-identifying as “full-stack”, diving into server development and asynchronous code. Javascript is Javascript, right? What difference does it make what you create using it - user interfaces, servers, games, or embedded systems. Right? Node was still kind of a learning project of one person, and Javascript back then was a deeply problematic choice for server development. Pointing this out to still green server-side developers usually resulted in a lot of huffing and puffing. This is all they knew, after all. The world outside of Node effectively did not exist, the Node way was the only known way, and so this was the genesis of the stubborn, dogmatic thinking that we deal with to this day. And then, a steady stream of FAANG veterans started merging into the river of startups, mentoring the newly-minted and highly impressionable young Javascript server-side engineers. The apostles of the Church of Complexity would assertively claim that “how they did things over at Google” was unquestionable and correct - even if it made no sense under current context and size. What do you mean you don’t have a separate User Preferences Service? That just will not scale, bro! But, it’s easy to blame the veterans and the newcomers for all of this. What else was happening? Oh yeah - easy money. What do you do when you are flush with venture capital? You don’t go for revenue, surely! On more than one occasion I received an email from management, asking everyone to be in the office, tidy up their desks and look busy, as a clouder of Patagonia vests was about to be paraded through the office. Investors needed to see explosive growth, but not in profitability, no. They just needed to see how quickly the company could hire ultra-expensive software engineers to do … something. And now that you have these developers, what do you do with them? Well, they could build a simpler system that is easier to grow and maintain, or they could conjure up a monstrous constellation of “microservices” that no one really understands. Microservices - the new way of writing scalable software! Are we just going to pretend that the concept of “distributed systems” never existed? (Let’s skip the whole parsing of the nuances that microservices are not real distributed systems). Back in the days when the tech industry was not such a bloated farce, distributed systems were respected, feared, and generally avoided - reserved only as the weapon of last resort for particularly gnarly problems. Everything with a distributed system becomes more challenging and time-consuming - development, debugging, deployment, testing, resilience. But I don’t know - maybe it’s all super easy now because toooollling. There is no standard tooling for microservices-based development - there is no common framework. Working on distributed systems has gotten only marginally easier in 2020s. The Dockers and the Kuberneteses of the world did not magically take away the inherent complexity of a distributed setup. I love referring to this summary of 5 years of startup audits, as it is packed with common-sense conclusions based on hard evidence (and paid insights): … the startups we audited that are now doing the best usually had an almost brazenly ‘Keep It Simple’ approach to engineering. Cleverness for cleverness sake was abhorred. On the flip side, the companies where we were like ”woah, these folks are smart as hell” for the most part kind of faded. Literally - “complexity kills”. The audit revealed an interesting pattern, where many startups experienced a sort of collective imposter syndrome while building straight-forward, simple, performant systems. There is a dogma attached to not starting out with microservices on day one - no matter the problem. “Everyone is doing microservices, yet we have a single Django monolith maintained by just a few engineers, and a MySQL instance - what are we doing wrong?”. The answer is almost always “nothing”. Likewise, it’s common for seasoned engineers to experience hesitation and inadequacy in today’s tech world, and the good news is that, no - it’s probably not you. It’s common for teams to pretend like they are doing “webs cale”, hiding behind libraries, ORMs, and cache - confident in their expertise (they crushed that Leetcode!), yet they may not even be aware of database indexing basics. You are operating in a sea of unjustified overconfidence, waste, and Dunning-Kruger, so who is really the imposter here? There is nothing wrong with a monolith The idea that you cannot grow without a system that looks like the infamous diagram of Afghanistan war strategy is largely a myth. Dropbox, Twitter, Facebook, Instagram, Shopify, Stack Overflow - these companies and others started out as monolithic code bases. Many have a monolith at their core to this day. Stack Overflow makes it a point of pride how little hardware they need to run the massive site. Shopify is still a Rails monolith, leveraging the tried and true Resque to proces billions of tasks. WhatsApp went supernova with their Erlang monolith and 50 engineers. How? WhatsApp consciously keeps the engineering staff small to only about 50 engineers. Individual engineering teams are also small, consisting of 1 - 3 engineers and teams are each given a great deal of autonomy. In terms of servers, WhatsApp prefers to use a smaller number of servers and vertically scale each server to the highest extent possible. Instagram was acquired for billions - with a crew of 12. And do you imagine Threads as an effort involving a whole Meta campus? Nope. They followed the Instagram model, and this is the entire Threads team: Perhaps claiming that your particular problem domain requires a massively complicated distributed system and an open office stuffed to the gills with turbo-geniuses is just crossing over into arrogance rather than brilliance? Don’t solve problems you don’t have It’s a simple question - what problem are you solving? Is it scale? How do you know how to break it all up for scale and performance? Do you have enough data to show what needs to be a separate service and why? Distributed systems are built for size and resilience. Can your system scale and be resilient at the same time? What happens if one of the services goes down or comes to a crawl? Just scale it up, yes? What about the other services that will get flooded with load? Did you war-game the endless permutations of things that can and will go wrong? Is there back pressure? Circuit breakers? Queues? Jitter? Sensible timeouts on every endpoint? Are there fool-proof guards to make sure a simple change does not bring everything down? The knobs you need to be aware of and tune are endless, and they are all specific to your system’s particular signature of usage and traffic. The truth is that most companies will never reach the massive size that will actually require building a true distribute system. Your cos playing Amazon and Google - without their scale, expertise, and endless resources - is very likely just an egregious waste of money and time. The only thing harder than a distributed system is a BAD distributed system. “But each team…but separate… but API” Trying to shove a distributed topology into your company’s structure is a noble effort, but it almost always backfires. It’s a common approach to break up a problem into smaller pieces and then solve those one by one. So, the thinking goes, if you break up one service into multiple ones, everything becomes easier, right? The theory is sweet and elegant - each microservice is being maintained rigorously by a dedicated team, walled off behind a beautiful, backward-compatible, versioned API. In fact, this is all so steely that you rarely even have to communicate with that team - as if the microservice was maintained by a 3rd party vendor. It’s simple! If that doesn’t sound familiar, that’s because this rarely happens. In reality, our Slack channels are flooded with messages from teams communicating about releases, bugs, configuration updates, breaking changes, and PSAs. Everyone needs to be on top of everything, all the time. And if that wasn’t great, it’s normal for one already-slammed team to half-ass multiple microservices instead of doing a great job on a single one, often changing ownership as people come and go. In order to win the race, we don’t build one good race car - we build a fleet of shitty golf carts. What you lose There are multiple pitfalls to building with microservices, and often that minefield is either not fully appreciated or simply ignored. Teams spend months writing highly customized tooling and learning lessons not related at all to the core product. Here are just some often overlooked aspects… Say goodbye to DRY After decades of teaching developers to write Don’t Repeat Yourself code, it seems we just stopped talking about it altogether. Microservices by default are not DRY, with every service stuffed with redundant boilerplate. Very often the overhead of such “plumbing” is so heavy, and the size of the microservices is so small, that the average instance of a service has more “service” than “product”. So what about the common code that can be factored out? Have a common library? How does the common library get updated? Keep different versions everywhere? Force updates regularly, creating dozens of pull requests across all repositories? Keep it all in a monorepo? That comes with its own set of problems. Allow for some code duplication? Forget it, each team gets to reinvent the wheel every time. Each company going this route faces these choices, and there are no good “ergonomic” options - you have to choose your version of the pain. Developer ergonomics will crater “Developer ergonomics” is the friction, the amount of effort a developer must go through in order to get something done, be it working on a new feature or resolving a bug. With microservices, an engineer has to have a mental map of the entire system in order to know what services to bring up for any particular task, what teams to talk to, whom to talk to, and what about. The “you have to know everything before doing anything” principle. How do you keep on top of it? Spotify, a multi-billion dollar company, spent probably not negligible internal resources to build Backstage, software for cataloging its endless systems and services. This should at least give you a clue that this game is not for everyone, and the price of the ride is high. So what about the tooooling? The Not Spotifies of the world are left with McGivering their own solutions, robustness and portability of which you can probably guess. And how many teams actually streamline the process of starting a YASS - “yet another stupid service”? This includes: Developer privileges in GitHub/GitLab Default environment variables and configuration CI/CD Code quality checkers Code review settings Branch rules and protections Monitoring and observability Test harness Infrastructure-as-code And of course, multiply this list by the number of programming languages used throughout the company. Maybe you have a usable template or a runbook? Maybe a frictionless, one-click system to launch a new service from scratch? It takes months to iron out all the kinks with this kind of automation. So, you can either work on your product, or you can be working on toooooling. Integration tests - LOL As if the everyday microservices grind was not enough, you also forfeit the peace of mind offered by solid integration tests. Your single-service and unit tests are passing, but are your critical paths still intact after each commit? Who is in charge of the overall integration test suite, in Postman or wherever else? Is there one? Integration testing a distributed setup is a nearly-impossible problem, so we pretty much gave up on that and replaced it with another one - Observability. Just like “microservices” are the new “distributed systems”, “observability” is the new “debugging in production”. Surely, you are not writing real software if you are not doing…. observability! Observability has become its own sector, and you will pay in both pretty penny and in developer time for it. It doesn’t come as plug-and-pay either - you need to understand and implement canary releases, feature flags, etc. Who is doing that? One already overwhelmed engineer? As you can see, breaking up your problem does not make solving it easier - all you get is another set of even harder problems. What about just “services”? Why do your services need to be “micro”? What’s wrong with just services? Some startups have gone as far as create a service for each function, and yes, “isn’t that just like Lambda” is a valid question. This gives you an idea of how far gone this unchecked cargo cult is. So what do we do? Starting with a monolith is one obvious choice. A pattern that could also work in many instances is “trunk & branches”, where the main “meat and potatoes” monolith is helped by “branch” services. A branch service can be a service that takes care of a clearly-identifiable and separately-scalable load. A CPU-hungry Image-Resizing Service makes way more sense than a User Registration Service. Or do you get so many registrations per second that it requires independent horizontal scaling? Side note: In version control, back in the days of CVS and Subversion, we rarely used \"master\" branches. We had \"trunk and branches\" because, you know - *trees*. \"Master\" branches appeared somewhere along the way, and when GitHub decided to do away with the rather unfortunate naming convention, the average engineer was too young to remember the trunk/branches pattern - and so the generic \"main\" default came to be. The pendulum is swinging back The hype, however, seems to be dying down. The VC cash faucet is tightening, and so the businesses have been market-corrected into exercising common-sense decisions, recognizing that perhaps splurging on web-scale architectures when they don’t have web-scale problems is not sustainable. Ultimately, when faced with the need to travel from New York to Philadelphia, you have two options. You can either attempt to construct a highly intricate spaceship for an orbital descent to your destination, or you can simply purchase an Amtrak train ticket for a 90-minute ride. That is the problem at hand. Renegade Otter is the developer of Friendly Fire - smarter pull request assignment for GitHub, with: Slack notifications Out-of-office support File matching Contact & Support Terms of Service Privacy Policy",
    "commentLink": "https://news.ycombinator.com/item?id=37477095",
    "commentBody": "Death by a Thousand MicroservicesHacker NewspastloginDeath by a Thousand Microservices (renegadeotter.com) 335 points by thunderbong 5 hours ago| hidepastfavorite236 comments jedberg 4 hours agoI am one of the biggest proponents of microservices. I helped build the platform at Netflix, I&#x27;ve literally traveled around the world extolling the virtues of microservices.But I also advise a lot of startups, and you know what I tell them nearly every time?Build a monolith.It&#x27;s so much easier to start out with one codebase and one database, and that will scale for a while. Especially if you use a key&#x2F;value store like DynamoDB (although you will lose relational functionality that can be helpful at the start). And did you know that you can deploy a monolith to Lambda and still get all the benefits of Lambda without building services?And then, when you start growing, that&#x27;s when you break out an independently scalable part of the system into a microservice (with it&#x27;s own data store!). The one that may need to scale independently, or that you want to be able to deploy separately.Microservices takes at least 25% of your engineering time just maintaining the platform. It&#x27;s not worth it unless you can recoup that 25% in efficiency. reply usrbinbash 2 hours agoparentWise words. They boil down to a very simple truth that was as accurate half a century ago as it is today:Make things as simple as possible, and as complex as necessary.I can always make something more complex than it is now. As you say, we can take out things from a monolith and make them into a service. It can be hard to do so, sure. But nowhere near as hard, as trying to get complexity OUT of a system once it&#x27;s in. Everyone who ever tried to revert a bunch of microservices back into a Monolith knows exactly what I am talking about. It usually amounts to the same work as a ground-up rebuild. reply glimshe 4 minutes agoparentprevMost people don&#x27;t understand the point of microservices. They look at the idea and are attracted by the power of modular interfaces, customizable scalability and independent deployment, without really thinking of the additional engineering overhead that are required to unleash these capabilities.I&#x27;ve seen ex-Netflix software engineers taking jobs elsewhere and proposing microservices for systems that would receive little to no benefit from them. In practice, the implementation of microservices in these contexts become a costly solution looking for a problem. reply crooked-v 4 hours agoparentprev\"A while\" is underselling it. As long as you have people who are half-decent with SQL, \"just put Postgres on a big db server\" will get you to 50 million row tables before you have to start thinking about even hiring a real DBA. reply baq 3 hours agorootparent50M is something that can easily be done with just a dev who understands that sql is more than select, insert and update with the manual, google and chatgpt.You can get really damn far with a fat postgres box. reply dalbasal 2 hours agorootparentThe problem with these discussions is that you can always get a lot out of any given architecture, structure, db approach or whatnot. Can. There&#x27;s just a lot of daylight between \"can\" and \"likely will.\"Ultimately, everything has its limitations and tradeoffs. If we respect them, it&#x27;s generally a smooth ride. Problem is that we rarely do... within a company (startup or otherwise) under real conditions. There&#x27;s also a dynamic where we build until the point where something stops us. Tech debt, complexity, over-engineering, under-engineering, feature bloat or antagonism between early decisions and current goals.There&#x27;s a self-regulating aspect to this. If architecture is spot on, perfect for the task at hand we can move faster to reach the point where it no longer is. reply baq 2 hours agorootparentYou&#x27;re right of course.My point is that postgres is, compared to almost everything else, easy to get from \"can\" to \"likely will\" with just somebody with a brain, a manual and google. In absolute terms it of course depends, but the point is relative. reply dalbasal 1 hour agorootparentA brain, a manual and google is usually a pretty good way generally to make solid decisions, respect the limits of your chosen stack.What happens when there is >1 brain involved... or when brainless, manualless decisions eventually get made... or two pivots from now...I&#x27;m not disagreeing with your approach. I agree with it, especially as starting point. I&#x27;m cautioning that resilience against complexity isn&#x27;t about how easy it is to make good decisions when you understand the spec, read the manual and calmly proceed. Complexity and fragility accumulate when one or all of these are absent. How easily you can (and thus inevitably will) make a mess... not how easily you can keep it clean.IRL situations with regular rdbs, a very common trend seems to be long term drift between schema and spec. The flexibility and approachability of postgres often enables a lot of kludge eventually.Data stores have this dichotomy between \"look how easy\" and \"is limiting factor\" that speaks to difficulties we don&#x27;t know how to articulate or isolate. reply szundi 2 hours agorootparentprevThe real tragedy is this clever people usually talking about their usecases and those present the requirements. There is no average system out there. reply cnity 2 hours agorootparent\"There is no average system\" is such a good insight. reply pizza234 2 hours agorootparentprevI&#x27;ve been on both the sysadmin, development, and hiring sides, and with data models at scales of 50M+ records, devs who \"understand that sql is more than select [...]\" are rare in my experience, as they&#x27;re a cross between db admins and developers.Administrating (in particular, query planning and production operations) databases with tables sizes with magnitude of 10M and more records is challenging, and requires a skill set that is very different from pure development.One won&#x27;t get \"really damn far with a fat postgres box\", unless they&#x27;re doing very simple SELECTs, which is not the case with modern web apps. reply lelanthran 1 hour agorootparent> Administrating (in particular, query planning and production operations) databases with tables sizes with magnitude of 10M and more records is challenging, and requires a skill set that is very different from pure development.Is it more or less challenging than the alternatives? Is it less challenging enough to add a new tech to your stack, add the required knowledge to the team, etc?I mean, knowing \"enough-to-perform-CRUD\" SQL is table stakes for developing on the back-end, but knowing $CURRENT-FLAVOUR-NOSQL (of which there are multiple products, all with such substantial differences that there is no knowledge transfer between using them) isn&#x27;t, so there&#x27;s going to be ramp-up time for every dev, and then every dev that is added to the team.I&#x27;m not disputing your argument, I&#x27;m just pointing out that, sometimes, it&#x27;s easier and faster to upskill your PostgreSQL developer to \"scale the DB\" than it is to teach them how to properly use, maintain, architect and code for DynamoDB and others. reply baq 1 hour agorootparentprev> are rare in my experience, as they&#x27;re a cross between db admins and developers.That&#x27;s fine. You only ( ;) ) need one on the team. reply jedberg 3 hours agorootparentprevTrue. \"While\" for some large value of time. And if you set up the auto-vacuumer correctly from the start, you can go even further! reply turtles3 2 hours agorootparentUnpopular opinion: if you&#x27;re skimping on ops&#x2F;DBA resources (as you may need to do in a startup), then MySQL is a better default. By all means use postgres if your use case demands it, but personally I find the ops story for MySQL takes less engineering overhead. reply lenkite 2 hours agorootparentI agree with this \"unpopular opinion\". Worked with both MySQL and postgres based mid-scale apps of several thousands of users. Postgres is so deeply lauded here at HN yet requires two more magnitudes of operations work to keep it up and running. Vacuuming sucks hard. reply avereveard 1 hour agorootparentprevThat&#x27;s not wrong, but postgres allows for cramming a lot of functionality in the db, and it&#x27;s fast at following storage trend, i.e. with pgvector reply turtles3 41 minutes agorootparentThat is a very specific use case, and might only be a small subset of your actual data. If you don&#x27;t have these specific requirements (eg. CRUD apps), you can save yourself a lot of unnecessary headaches by defaulting to MySQL.My main point is attempting to counter the narrative popular on HN that postgres should be an automatic default. For sure there are many aspects in which postgres is superior, I absolutely do not debate that, especially when it comes to developer experience. But there is much more to it than that when it comes to delivering business value. That&#x27;s where ops and DBA concerns start to matter, and IMO MySQL is so far ahead in this regard that it outweighs all the other hideous warts of working with it, when you consider the bigger picture of the business as a whole. reply jiggawatts 2 hours agorootparentprevIt’s so cute that you think 50M rows is big. Your phone can handle many times that, and update it tens of thousands of times per second. reply dagw 1 hour agorootparentThe problem isn&#x27;t storing or inserting 50M rows, it querying 50M rows in non trivial ways. And the difference in performance between doing that &#x27;right&#x27; and &#x27;wrong&#x27; is orders of magnitude. reply omegabravo 1 hour agorootparentdoing it on your phone only has one person querying it. Scale that to several thousand and it might appear different. reply jiggawatts 27 minutes agorootparentI&#x27;ve scaled 300M rows in just one of many similarly sized tables to 1M users... in 2007... on a single box with spinning rust in it. Heck, my laptop could handle 100x the production load.It amazes me that my comment (while admittedly flippant) got voted down.It really is true that your phone can update a 50M row table about 10K times per second!That people are incredulous of this is in itself a stunning admission that developers these days don&#x27;t have the faintest idea what computers can or cannot actually do.Just run the numbers: 50M rows with a generous 1 KB per row is 50 GB. My iPhone has 1TB of flash storage that has a random access latency of something like 50 microseconds, which equates to 200K IOPS. An ordinary NVMe laptop SSD can now do 2M. Writing even 10K random locations every second is well within mobile device capability, with 50% headroom to \"scale\". At 1 KB per row, this is just 10 MB&#x2F;s, which is hilariously low compared to the device peak throughput of easily a few GB&#x2F;s. replyaledalgrande 3 hours agoparentprev> And then, when you start growing, that&#x27;s when you break out an independently scalable part of the system into a microserviceRespectfully disagree. At this point you start refactoring your monolith into components and actually look at performance measurements via tracing.Do not do microservices when you&#x27;re growing (or ever, most of the time).And by the love of god, don&#x27;t split your data. Data is much more complex to manage than code. reply Aeolun 3 hours agorootparent> And by the love of god, don&#x27;t split your data.I think people feel that if they introduce a new data store, they won’t have to deal with the existing nearly unusable massive data store.Of course that just exacerbates the problem. reply theshrike79 2 hours agorootparentprevSplitting data is just a hardcore way of splitting the responsibility for the data.You can&#x27;t have 42 different classes directly poking the User-table for example. You need one clear location that has the responsibility for the data.If you move the User-table to a different database schema, other places CANNOT touch it because they won&#x27;t have access to it =) reply aledalgrande 2 hours agorootparentAnd then the order table will need to set user ids as a foreign key and you will have two sources of truth lolWill be fun when you decide that you want to have organizations to be linked to orders instead of users.All this to say, data management and having more than one source of truth complicates your world a lot. The responsibility for writing the data has to be solved at the appropriate layer: only one entity writing it. reply Copenjin 2 hours agorootparentprev> And by the love of god, don&#x27;t split your data.Most data problems can be fixed on the frontend with a few relatively simple graphql queries. &#x2F;s reply ngc248 2 hours agorootparentprevThere is a way to splitting data. The service which owns the data always does the writes and others who need reads on that data can store replicas. ofc the complication then will be in replicating data, but this will enable services to massively scale and eliminate SPOFs reply code_biologist 1 hour agorootparentThe other part of this pattern you mention (replicating data) seems solved in many cases by the data warehouse patterns of the last few years. Stuff it all in Snowflake or BigQuery then readers can query as they see fit. Query engines like Trino can paper over data storage heterogeneity &#x2F; breakdowns in centralization. I&#x27;m not a fan of the \"lakehouse\" terminology, but it is the thing.There are downsides to coupling more loosely with data consumers, but it keeps service owners moving without wasting time vending data. reply elliotec 3 hours agoparentprevAh, it’s you!You’ve got a hell of a resume. And been accidentally incredibly convincing in getting many people into many early messes.Jokes aside, thanks for at least coming around to advise startups sanely.I’d personally never advocate for microservices until at the scale of Netflix or Amazon or Reddit, and even then only with in-house expertise at your level. Otherwise it’s a nightmare.Thanks for everything, especially your contributions of sanity. reply jedberg 3 hours agorootparentAww, thanks for the kind words. I apologize if I caused you any harm with my talks. I did in fact start out saying everyone should use microservices, but I pulled back as I saw how damaging that can be to a small startup, or even a large enterprise that doesn&#x27;t actually need it.We all make mistakes! reply danielovichdk 39 minutes agoparentprevI honestly believe that doing small services is long term better approach than a monolith. But as you I strongly believe it&#x27;s not where you want to start.But I do not agree on is more time consuming than the other. It&#x27;s just time spent on different matters. For the sake of money spent, I have not seen any data on how a monolith outperforms small services. For maintaining the platform, I think 25% sounds a bit high.Money spent should be measured in many different aspects. One is definitely productivity. And I have seen more stale monoliths than I have seen stale small services. Whether it&#x27;s better or not is not up to me to judge. I just know what I prefer.Having been exposed to small service architecture where it has been working really well and very poor, there are few things that stand out.- Conquer and divide (your monolith over time). - Responsibility boundaries are easier to cope with for developers in a small service since they often don&#x27;t have generic and yagni abstractions. - Less code to comprehend for a small service and the cognitive load decreases. - Build time, test time, deployment time. - Should lean up against a direct business measurement and value. - Group chatting services into one.I have yet to see a monolith that over time is not really deteriorating, but I haven&#x27;t worked with SO or Shopify. We could also argue that Cobol and Fortran is still of good use but time has also changed leaving that style of system development exposed as old and dusty.But like any software development occurrence, it takes responsibility, mandate and proper leadership to get things done in a decent manner. So if you start by making 3 services that has to chat to find a user profile you probably don&#x27;t know what you&#x27;re doing. And 25 people (the Threads image) is not a small team IMO.Good luck reply lifeisstillgood 2 hours agoparentprevHow would you split the total overhead between monolith and monorepo?(sorry this ran away with me)A dumb example is that if I start with my single codebase running on a single server, I am likely to have a single git repo (foo).Then I have a genius idea and put all the email handling code into foo.mail and soon I have foo.web and foo.payments.All is fine as long as I am just checking out HEAD each time. The code running in the runtime is still one big set of code.If I get creative and put in load balancers it&#x27;s still a monolith.But if I split out the web servers from the email servers, then I kind of start to see microservices appear.I am trying not to be pedantic, but I am truly interested in experienced views on where the pain really starts to appear.At this point (server to server comms), I should look at mTLS, and centralised logging and all the good stuff to manage microservices.But how much pain was there before?What if I was a large company and so hired a dev or two per repo (you know to get that 9 women one month effect). Co-ordinating multiple devs over different repos, even with one monolithic runtime, is painful (experience tells me).So I am interested in where the break points are, and whether there are easier paths up the mountain? reply afiori 1 hour agorootparentSplitting out the webserver (assuming it is the main entrypoint for users) seems more like an infrastructure choice than application architecture and having an independent email-sending-service looks more like replacing a third-party offer (like turboSMTP) with an in-house service.I do not think that this is what people mean by microservices. reply lifeisstillgood 24 minutes agorootparentI get that. I was trying to describe a small path from monolith to microservice without inventing yet another student and teacher database. But the even the step you mention matters. going to a third party service is very similar to reaching out to your own internal service. Make it a \"customer\" service.Is the pain in microservices (or APIs and mTLS) or is the pain in managing a team that now has to do customer stuff only ? or email stuff only? reply hliyan 3 hours agoparentprevI wrote this 8 years ago: Microservices vs. \"air-gapped\" modules https:&#x2F;&#x2F;www.linkedin.com&#x2F;pulse&#x2F;maintainable-software-archite.... You can achieve the same end as a microservice using a module, by simply having lint rules that prevent you from importing other application level modules. This way the only possible comms interface is to pass events with a payload of primitive typed parameters. reply jedberg 2 hours agorootparentAn interesting idea. Sort of a good half way. But one issue I see is that you can still have a shared data store. That means you can accidentally (or intentionally) use the database to pass back-channel messages —- have one module store data and another read it.That could lead to hard to find bugs. Did this ever come up for you? reply 3np 2 hours agorootparentprevI think if we also \"air-gap\" (loosely) the dependencies, we get a typical monorepo in, say, JS or Golang? That is, a module in a monorepo is a special case of your airgapped modules? reply Copenjin 2 hours agoparentprevI wish you good luck with your redemption arc, every monolith counts. reply johnboy123 1 hour agoparentprevJust chipping in with thoughts on DynamoDB, (although I have worked on much smaller scale systems)I am a long term dev, done lots of SQL, but for the past few years I have been using DynamoDB, and I am using it for my new startup (So I rate it).Cons - You have to be very aware of your query patterns, and not having ad-hoc queries is a pain.Plus sides - With on demand billing, its free if you aren&#x27;t using it - Built correctly, it will scale - No Schema upgrades (This one is massive for me)On the last point, I really do appreciate not having to worry about keeping schemas upto date across all devs and environments.We use quite a simple pattern of a table per entity, as opposed to single table design, because it allows us to just use the API at the highest level of abstraction, where you just write your objects to dynamoDB. (You can still do lower level requests to poke values and such like) reply jwestbury 10 minutes agorootparent> No Schema upgrades (This one is massive for me)At Amazon, relational databases are banned unless you get an explicit exemption from senior leadership. This is the primary reason why. Too many cases of schema upgrades causing outages.The problem with DDB or other NoSQL applications, like you say, is how much you need to consider your query patterns. The last major project I worked on using DDB, we spent a couple of days just thinking through our query patterns so we could come up with the right database design and data structures. (We still believe it was the right choice, though.) reply HerculePoirot 29 minutes agoparentprevThe problem is not with the devs but with the investors I believe. They&#x27;re looking for unicorns, unicorns attract million of customers, so they need to work at scale, hence microservices. reply Gud 1 hour agoparentprevWise. Every time I’ve started a project trying to make an amazing platform with everything segregated with micro services etc. I’ve spent so much more time on the _platform_ than on the actual product.Now I go with SQLite and some basic python script and pivot from there. Ironically that’s how I used to do it before the micro service fad. reply ddalex 2 hours agoparentprevMy go to page about this is http:&#x2F;&#x2F;widgetsandshit.com&#x2F;teddziuba&#x2F;2008&#x2F;04&#x2F;im-going-to-scal... which perfectly summarizes the problem AND solution reply amelius 29 minutes agoparentprevOf course it is even better to build a distributed monolith... reply Shinchy 1 hour agoparentprevAbsolutely agree, I&#x27;ve seen far too many companies spend far too much time working out the infrastructural relationships of microservices. Spending very little time working on the actual applications needs itself. reply bradhe 2 hours agoprevI work on a massive monolith that has about 800 contributors and its just as complex to add something as simple as a user’s birthday, just not all the complexity is technological. It requires “organizational alignment” since you’re touching everyone’s code.There will be endless iterations on design and review. Sign off required by at least 2 architects. It will get added to multiple planning iterations. The actual code will take an afternoon or less. We’ll have to ensure we hit out 90% test coverage during code review but because of all the tests, it’ll be too big for one PR so it will need to be broken up into multiple PRs probably landing over multiple weekly releases. To facilitate that, we’ll put it behind a feature flag (of which there are currently 13,000). Once it hits production, and the dashboards&#x2F;monitoring are put in place, it will get enabled and disabled over and over again as we’re not totally sure why our birthdate feature broke the metering service, but we think that’s the root cause—need to do a few weeks of analysis.Then, finally, in a year the engineer who was tasked with it will get a good performance rating, maybe be up for a promo! Just in time for him to jump into another project that’s failing horribly headed into its 3rd year in development: Allowing the user to set their timezone. reply srvaroa 1 hour agoparentThis comment shows IMO that the real issue here is not really microservices or not microservices, but what the article calls \"The apostles of the Church of Complexity\".Neither microservices or monolith are a golden hammer, silver bullet or whatever (nor the opposite). They are tools each with their tradeoffs, which combine with the many context-dependent tradeoffs of each organization. They are not the problem.The problem is a) engineer&#x27;s fascination with complexity, and confusing \"simple\" with \"hack\", b) how organizations keep cargo-culting tools, architectural patterns, and so forth. Applying architectures, design patterns, whatever naively, based on the belief that usage alone will deliver benefits. It doesn&#x27;t. reply ramraj07 2 hours agoparentprevThis sounds like you work at a place that’ll bungle any tech stack paradigm. reply theshrike79 2 hours agoparentprevSome people who advocate for huge monorepos, like Google has, tend to forget that Google has whole teams building tools just to wrangle the huge singular codebase for refactoring and testing. reply bradhe 2 hours agorootparentBingo. Monorepos work because tooling makes it work. Just putting all your code in one place doesn&#x27;t make it a monorepo--just makes it a mess. reply gorgoiler 1 hour agorootparentIt was a mess before, but the mess wasn’t visible. Now the code is all visible to the IDE, it all compiles together, and tests together. You can see the mess and fix it. It’s possible to see enough of it to be able to change it and when you do the build stays green because you can make atomic changes.It’s less about why monorepos are good, and more about why on Earth would you split a product up over hard repo &#x2F; tooling boundaries. Perhaps a Big Brain could get those boundaries right. I can’t, so when I need to move the boundary I would rather it was done by editing code inside a repo than coordinating changes between micro products.I’m obviously describing one scenario. What are the counter examples for where hard polyrepo boundaries are helpful? When your team are all IC1s? reply jwestbury 2 minutes agorootparent> You can see the mess and fix it.The trouble is, you&#x27;re often left unwinding a half-dozen layers of abstraction, and in many cases experiencing what looks like some sort of quantum code interaction, where changes in one part of the codebase seem to impact completely unrelated bits of code which now fail tests.The polyrepo + microservices approach helps enforce boundaries. It also makes rapid iteration easier with more limited tooling, because my code can no longer blow up someone else&#x27;s code -- a problem which can be solved with dev toolchains, but those toolchains take a non-trivial amount of resources to support.I do agree, when you need to move boundaries, or need to refactor across multiple packages at once, a monorepo + monolith is great. (A monorepo + microservices can introduce many of the same problems as a polyrepo + microservices, though.) tm-guimaraes 1 hour agorootparentprevBingo.At $work i see lots of projects leaving the monorepo due to that very mess.The problem is that services outside have other CI and maintenance issues that wouldn’t happen in the monorepo. But monorepo got so messy that it got unbearable.The proper solution would be to have a dev teams dedicated to tooling for it, the org has the resources, but it’s just not investing enough in that area. replycamgunz 1 hour agoparentprevIt sounds like this company doesn&#x27;t have a competitive need to ship code changes, but when it does (i.e. a challenger appears or the moat disappears) it&#x27;ll be trouble.I&#x27;ve tried--with varying levels of success--to really take to heart that software engineering is a never ending battle against complexity. You have to do it all the time and it has to be your paramount value, otherwise stuff like this happens. I don&#x27;t think there&#x27;s an architecture or ideology that ends the war; this is just the nature of the job. reply martypitt 1 hour agoparentprevI think this is a great point, and shouldn&#x27;t be just hand-waved away like you hit some bizarre edge case of Monoliths.Monoliths can have crippling downsides -- just different flavours of downsides from Microservices. What you gain in network latency and DRYness, you can lose in Autonomy and Breadth of codebase.Microservices vs Monoliths - just like everything else - is a question of tradeoffs, and making informed choices about when to apply them, and how to mitigate their downsides.The slightly more nuanced point in the OP&#x27;s article is that adopting any engineering practice and blindly following as though your identity is linked to it, is a bad move. reply aledalgrande 2 hours agoparentprevOMG this sounds painful ;) both in processes and state of the codebaseI can ship something in a couple of hours on a monolith where 3000+ engs work and deploy every day, but to be fair that&#x27;s not what I&#x27;ve seen in any other company I worked at. reply PartiallyTyped 2 hours agorootparentWhere do you work at, and, are you hiring? reply andrewstuart 1 hour agoparentprevUgh that would make me hate software. reply deterministic 2 hours agoparentprevThat sounds crazy. Imagine how much worse it would be if it was a microservices system! reply scrlk 2 hours agorootparent\"Why is it so hard to display the birthday date on the settings page? Why can&#x27;t we get it done this quarter?\"\"Look...I&#x27;m sorry, we&#x27;ve been over this, it&#x27;s the design of our backend.\"https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=y8OnoxKotPQ reply lhnz 10 minutes agoprevnext [–]> First, a whole army of developers writing Javascript for the browser > started self-identifying as “full-stack”, diving into server development > and asynchronous code.This is gatekeeping--we&#x27;re all ultimately self-identifying as software engineers. But more importantly it&#x27;s not correct. Many of the original engineers working with Node had non-UI backgrounds. Node.js made asynchronous programming easy and promised that you could use the same language on the back-end and front-end, which seemed like good bang-for-buck for people that wanted to focus on products.Also, not to point the blame somewhere else, but wasn&#x27;t it Golang engineers that went really hard on the microservices koolaid? reply synack 4 hours agoprevMicroservices are a solution to a social problem, not a technical one.A team of N engineers requires N² coordination. Large teams get mired in endless meetings, email, design reviews. Small teams are more effective, but struggle to maintain large systems.Splitting a system into subsystems allows each team to focus on their piece of the puzzle while minimizing the amount of peer-to-peer coordination.Yes, microservices add complexity and overhead, but this approach enables a large organization to build and iterate on large systems quickly. reply brhsagain 4 hours agoparent> Splitting a system into subsystems allows each team to focus on their piece of the puzzle while minimizing the amount of peer-to-peer coordination.This does not happen at all. When you break a system into subsystems, all the previous connections that get remapped to new connections between subsystems still need to happen, in order to solve the fundamental problem that the system solves — except now instead of just making the connection directly, there has to be a \"cross-functional\" meeting between teams and a complicated communication layer between the systems. And if somehow you find a breakdown that requires minimal connections between subsystems, then those connections wouldn&#x27;t have existed in the original system either, and the N² problem doesn&#x27;t exist. reply devoutsalsa 2 hours agorootparentIt&#x27;s all fun & games until product wants to add a feature that doesn&#x27;t map cleanly to your micro servies architecture. Then you end up hard coding you services into a macrolith. Good times. reply jedberg 4 hours agorootparentprevIf that&#x27;s the experience then you&#x27;re doing services wrong. Each service should have its own datastore and a single API. The interface between services should be a single connection.There should be maybe one meeting where the caller defines what they need the service to return to them. reply 10000truths 2 hours agorootparentThe problem with this is that you have to be really damned careful how you split things up. If your separate data stores end up having to be joined together later on because some new business feature requires them to be cross-referenced, you&#x27;re painted into one of two corners:1. Merge the two services (and their data stores) into one and cause havoc downstream of either service2. Burn through your network latency&#x2F;throughput budget trying to reinvent a DB join across RPC boundaries (and god forbid if you can&#x27;t batch multiple lookups in a single API call!) reply threeseed 3 hours agorootparentprev> there has to be a \"cross-functional\" meeting between teams and a complicated communication layer between the systemsOf all the things wrong with micro-services this isn&#x27;t one of them.The \"complicated\" communication layer is always either REST&#x2F;JSON or GRPC.Both of which are simple, easy to debug, proven and require nothing more than a simple discussion over an API contract. reply The_Colonel 3 hours agorootparent> Of all the things wrong with micro-services this isn&#x27;t one of them.It is, exacerbated by the over-use.> The \"complicated\" communication layer is always either REST&#x2F;JSON or GRPC.Going over network, which is slower, unreliable, poorly typed. It&#x27;s orders of magnitude more difficult to refactor a published REST API in comparison to e.g. Java interface within a monolith.Microservices are generally far from easy to debug. In the best case scenario you have the whole stack locally and can put breakpoints, add logging immediately. But that happens rarely, debug port is often blocked (security), you can&#x27;t easily modify the code to add some diagnostics without a complex CI dance etc. reply threeseed 3 hours agorootparentMaybe you&#x27;ve only worked on small projects.But I&#x27;ve never worked on a monolith project that I could run entirely locally.And this idea that APIs are slow, unreliable and unable be to be strongly typed is nonsense. This is 2023. We have plenty of tooling and techniques to make this robust. reply The_Colonel 2 hours agorootparentThe (monolith) product I currently work on has about 200 engineers working on it (backend + frontend + devops). I&#x27;d say it&#x27;s of medium size, certainly not small. And yes, we can run it locally easily. The monolith starts up in like 20 seconds which I consider quite acceptable.There are few narrowly defined responsibilities which are handled by dedicated services, and it is often more awkward to get them working locally. But because they are so specialized, you need them only rarely.> And this idea that APIs are slow, unreliable and unable be to be strongly typed is nonsense.Network APIs are inherently slower and more unreliable in comparison to an in-process method call. Some typing solutions are there, but they are way more awkward (and in some ways weaker) than statically typed monolith interfaces. reply plugin-baby 3 hours agorootparentprev> I&#x27;ve never worked on a monolith project that I could run entirely locally.What are some examples of monolith components that couldn’t be run locally?Im guessing third-party integrations, but perhaps there are other things. reply threeseed 13 minutes agorootparentFor a monolith it&#x27;s having to run the entire platform locally to fix one bug.That includes databases, caching, auth, ML models, mock API endpoints etc all pre-populated with sample data then the actual application which for complex, JVM based ones can often fail to launch if there isn&#x27;t enough memory to pre-allocate.Many systems I have worked on all of that would simply not fit on a 16GB MBP. reply deterministic 2 hours agorootparentprevI work on very large monoliths all the time. The kind of code that runs international airlines and airports. I run it locally in a VM. No problem. replybaobabKoodaa 3 hours agoparentprevI&#x27;ve never seen teams organized around microservices like that. What I&#x27;ve seen, again and again, is one huge team where \"everyone is responsible for all the microservices\" (meaning, no-one is responsible for anything).On a theory level I would agree with you - I&#x27;ve just never seen that happen in practice. reply misja111 2 hours agorootparentI&#x27;m not that much of a supporter of microservices, but my experience is the opposite: in every company I&#x27;ve worked for that used microservices, each team had their own set of microservices they were responsible for. reply mirekrusin 3 hours agoparentprevPeople seem to forget they can create separate directories in their codebase.They solve \"people problem\" by converting trivial technical problem into complex distributed system problem.Well, now you have a _Problem_. reply meowtimemania 4 hours agoparentprevif you have a well modularized monolith, you can get best of both worlds. reply croo 3 hours agorootparentThat is a big if that can be easily broken by a new guy who don&#x27;t know the rules or if the pace is fast enough that you cannot review everything.If the codebase is different you can force the separation not just ask nicely to keep the code well modularized. reply jayd16 4 hours agorootparentprevNot really. You can&#x27;t really reduce the blast radius of crashes or bad deployments. You need to have the discipline of a good CI&#x2F;CD instead of siloed but decoupled workflows.Just keeping things neat doesn&#x27;t go nearly as far as a separate process on separate machines. Monolith might be better but I don&#x27;t think it&#x27;s a situation where you can have it all. reply aidos 3 hours agorootparentThis argument always confuses me. It depends on what you’re doing but if you’re doing web services, as most here are, the crash is limited to the request being served.The blast radius is a single request, right?In every likelihood it _is_ a separate process on a separate machine. reply threeseed 3 hours agorootparentThey are talking about deployment.With micro-services if you screw up a deployment the service is down and if your platform is well designed the system will be degraded but not down.With a monolith the whole system is down. reply gizzlon 31 minutes agorootparent> With micro-services if you screw up a deployment the service is down and if your platform is well designed the system will be degraded but not down.In theory, but when the getUser service is down, your app is probably broken as well. reply quickthrower2 3 hours agorootparentprevThere are a lot of deployments options to mitigate that risk. reply charcircuit 3 hours agorootparentprev>With a monolith the whole system is down.No, you are just at reduced capacity.The moral of the story is not to roll out to 100% right away. reply threeseed 3 hours agorootparentMonoliths go hand in hand with a centralised database.Bit hard to do schema evolution with a staggered rollout. reply DougBTX 2 hours agorootparentIf schema migrations take non-zero time and you want zero-downtime deployments, then the both service versions need to be compatible with either the new schema or the old schema, regardless of service size. reply ownagefool 2 hours agorootparentprevThe same problem exists in microservoce land, only you now have a load of separate teams managing their own database, perhaps with different solutions. reply hervem 28 minutes agorootparentWait, micro-service and sharing same DB? Did I miss something? reply charcircuit 3 hours agorootparentprevThe software should be compatible with both the old and new schema until all of your database servers have moved over to the new schema. All rollouts are going to be somewhat staggered even if you go straight to 100%. replyDougBTX 2 hours agorootparentprev> You need to have the discipline of a good CI&#x2F;CDGood CD is even more important if there are more services to deploy reply synack 4 hours agorootparentprevAgreed! Software modules and libraries can achieve the same independence of subsystems without implying a network topology. reply gscott 2 hours agoparentprevMaybe a solution to an anti-social problem!FT.com did a recorded seminar session on their microservices architecture and one of the benefits they extolled is if someone wanted to improve on a feature they could just make it all over again and replace the old microservice with a new one. No need to look at the last persons code, just blow it away like it never existed.I gathered their site is actually a black box filled with hundreds of black boxes of microservices. All a mystery, they either work or they don&#x27;t and if they don&#x27;t they fail gracefully quickly.https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=_qakAUjXiek reply hot_gril 4 hours agoparentprevYep, I work in a large org that used to be a monolith (which means single DB really). Was a mess for the reasons you&#x27;d expect. Even our subteam of 10 needs to split things up more. reply corethree 4 hours agoparentprevWhy do you have to split things into services?How about moving things into different folders. Have you thought about that?Why do you have to modularize it with a whole new repo, a whole new docker set up? Just use a folder bro. reply atoav 3 hours agorootparentThe problem microservices try (tried?) to solve isn&#x27;t about namespaces, it is about too tight coupling between code. Whether that tightly coupled code sits in a subdirectory or in a different repo doesn&#x27;t matter.It can be benefitial to maintain well defined interfaces at boundaries between certain parts of your code. It can also produce a lot of work and add complexity. But beyond a certain scale adding systemic boundaries and honoring them isn&#x27;t something you should avoid.Devs who do microservices just tend to go too far too early. reply corethree 2 hours agorootparent>The problem microservices try (tried?) to solve isn&#x27;t about namespaces, it is about too tight coupling between code.You can use folders to decouple code by making code private within that folder. Only publicize parts of the code with your languages version of exporting.Or you can make it private behind an entire new repo and behind an entire service. Only publicize parts of the code through api interfaces like http and make everything 10x harder for the sake of decoupling code. reply tored 2 hours agorootparentMany languages misses that abstraction to make things private in a folder (namespace) hierarchy to outside consumers. This is something I like to see solution to (integrated with your IDE of choice) reply corethree 1 hour agorootparentPython is the only one that I know of that does this. Additionally python uses private by convention: Just prefix the stuff with an underscore. reply atoav 1 hour agorootparentprevSure there are tons of ways to decouple code. My point was however, that moving code into a folder doesn&#x27;t automatically solve that coupling issue. reply hot_gril 4 hours agorootparentprevUsually the most important designation of the separate system is that it uses a separate database. You only have immediate consistency within one service. reply zmmmmm 4 hours agorootparentwhich is the main step on the pathway to hellAt the point where you have to write an API call instead of simply joining to a table, you have introduced orders of magnitude more complexity, failure points, testing challenges, race conditions, coherency issues, code duplication etc into your system.I don&#x27;t mind stateless microservices too much. This forms more of a hub and spoke model (many services talking to 1 database). But the minute you bring separate state into the equation it&#x27;s a chaos factory. reply hot_gril 3 hours agorootparentJoining a table is nice until that table is owned by a separate team. Becomes either gridlock or constant breakage, performance can get precarious, and testing involves populating a whole fake DB vs just mocking a few RPCs.I really like relational DBs. I&#x27;ll make a system rely heavily on complex joins. But I&#x27;d rather call some other team&#x27;s API than share DBs with them. reply corethree 3 hours agorootparentprevNah but there are real instances where you have to use a different database for performance profiles.The biggest one in web is regular entity databases vs. timeseries databases designed for analytics.For this case entity data is just synced to to time series database every so often. Not super chaotic. It does make sense to divide services along those lines.Though I would argue a folder still works for the web app part. reply aledalgrande 4 hours agorootparentprevlol good luck without centralized data reply jedberg 3 hours agorootparentIf you have centralized data then you have broken the abstraction and are in for a world of hurt. You shouldn&#x27;t need centralized data, just a service front door where that service is the master of that part of the data. reply aledalgrande 2 hours agorootparentSo what are you gonna do when you need data migrations?PS: I&#x27;m not saying using one DB with microservices, it&#x27;s still with the monolith reply hot_gril 4 hours agorootparentprevEach service is authoritative on its own data, and it works neatly. Any medium to large size system is going to have natural places to separate that, or else will buckle under complexity or even hardware constraints if you try to keep it all in one DB. I&#x27;ve seen it repeatedly. reply corethree 3 hours agorootparentNah this doesn&#x27;t work out. Because requirements are so chaotic and modular design isn&#x27;t an axiomatic science things will for sure go wrong with the design both because you got the design wrong and because the requirements shifted to a point where another design was better.You encapsulated data under one service and you find that it&#x27;s actually utilized much more in another service. This happens a lot.The longer you can centralize your storage the better and easier everything is. reply aledalgrande 2 hours agorootparentExactly. And having more than one source of truth for your data complicates a lot of things.Where I work we run a massive MySQL database that has a pretty simple sharding rule, so I don&#x27;t believe that you need to split the database even at scale. reply threeseed 3 hours agorootparentprevYou mean like having user authentication data in AD&#x2F;LDAP and everything else in an RDBMS.Because this is the standard architecture you will find for most platforms. reply gotimo 3 hours agorootparentprevinb4 the separate \"data consistency service\" reply nroms 1 hour agorootparentprev> Just use a folder broThis will be my new go-to response when discussing microservices reply abhiyerra 4 hours agorootparentprevI found Django apps to be a good middle ground. reply politelemon 4 hours agoparentprevShouldn&#x27;t it be n(n-1)&#x2F;2 coordination. Assuming you mean communication channels? reply jjgreen 1 hour agorootparentI&#x27;d assumed the OP meant O(n^2), and n(n-1)&#x2F;2 = O(n^2) reply chalcolithic 2 hours agoparentprevI wonder why people ever see it differently? reply mojuba 3 hours agoprev(God, how I love confirmation bias when it&#x27;s my own bias.)I&#x27;ve been saying this for years, the microservices insanity it&#x27;s just an excuse for mediocre engineers to be in demand. It is fueled by mediocrity but it is also what keeps so many tech companies going.There are simply not enough competent engineers who master UNIX and who can build beautiful minimalist systems like StackOverflow&#x27;s or a bunch of others&#x27; mentioned in this article. Therefore microservices as a smoke screen for mediocrity is here to stay, it&#x27;s not going away any time soon, especially considering that cloud providers like AWS promote themselves via all possible channels and encourage the decision makers to take that route anyway. reply dan_mctree 2 hours agoparentI don&#x27;t know why but no one hires or listens to the architect who recommends sticking to safe monolithic-esque systems. If you&#x27;re not talking cloud and microservices and the newest unproven frameworks, you&#x27;re an old fogey who needs to get with the times. Even though those types of systems are rarely the most efficient, powerful or safe systemsI work for a company that builds software to be used internally by other business. We have like 200 people tops using it simultaneously with no usage spikes, a perfect environment for regular web servers as we&#x27;ll never have unexpected scaling issues, yet everyone is dying to go to the cloud. Why? I think it&#x27;s just because our management, programmers and even customers are convinced by cloud provider marketing that the cloud is cool reply misja111 2 hours agorootparentArchitects that propose pragmatic and boring solutions are usually not hired. It&#x27;s the emperor&#x27;s new clothes, companies like the idea of an architect who comes with some revolutionary new concept that will lead to a breakthrough that finally will make everybody rich. If they don&#x27;t understand the architect&#x27;s idea, so much the better because then it must be really state of the art. reply danjac 1 hour agoparentprevWhile there are definitely developers who are enthusiastic about microservices for all the wrong reasons (e.g. it looks good on the resume) I think it&#x27;s more about how companies deal with complexity.Companies don&#x27;t just ship their org chart, they ship all their dysfunction and historical baggage. A beautiful, well-architected platform from 5 years ago, with an efficient, thought-out data model and API and well-written and tested code, might be a total mess after 5 years of constant pivots from the CEO, last minute customer requests the sales team have pushed through, product managers doing their hydrant-meets-dog act of adding features nobody needed or asked for, and never enough people and time to do as good a job as the developers would like.One day you wake up with a big pile of tech debt and fixing bugs and adding features takes way longer than it should, and microservices are that siren call that promises a solution that doesn&#x27;t involve burning the whole thing to the ground and starting over. reply Tade0 2 hours agoparentprev> I&#x27;ve been saying this for years, the microservices insanity it&#x27;s just an excuse for mediocre engineers to be in demand.Or just inexperienced ones who want to pad their CVs.I think we failed to educate the current generation on what&#x27;s important in this job. reply PartiallyTyped 2 hours agoparentprevOther senior in my team and I agree with you..We are wasting 20+ people&#x27;s time because we were forced to rush into something that resulted in 5-6 different microservices where a monolith written by 6 competent engineers over 6 months would have sufficed.What you describe regarding microservices and AWS is also a thing internally............. reply switch007 2 hours agoprevA common pattern I&#x27;ve seen is:- Current CTO&#x2F;VPs built&#x2F;helped build original monolith- Nobody wants to tell the CTO that their code is shit (and&#x2F;or is from a different era and needs a complete overhaul), unrelated to that fact it&#x27;s a monolith. CTOs are too busy doing marketing&#x2F;getting funding to make a decision on microservices vs monotolith, so the newly-hired architects gets to call the shots- Everyone cheers on microservices because it fits within the story of a fast growing, serious, technical company and nobody wants to be that lone dissenting opinion&#x2F;criticise the CTO.Nobody is seriously and truthfully recommending microservices because they believe them to be the best trade off and superior choice. It&#x27;s because they like their job, they like hiring people, and it fits within the narrative.And it just so happens during the massive overhaul that you get to rewrite a ton of code and improve it, while just calling it a migration to microservicesSo it&#x27;s a way of not hurting the feelings of the CTO, going along with the crowd and a way of rewriting a ton of old bad code with an excuse supported by almost everyone reply hnarayanan 1 hour agoparentOh my goodness, I feel like you’ve nailed it. reply ConcernedCoder 1 hour agoparentprevyou just described the last 5 years of stumbleupon... reply ConcernedCoder 1 hour agoprevI find it weirdly theraputic to read things like this, and reminisce about loudly proclaiming the same a decade ago while being shushed as a non-believer...Please excuse me if the paradigm of \"microservices\" has left a bad taste in my mouth, but I have real-world experience with the repercussions of whole-heartedly embracing the latest tech-dejour without completely understanding the tradeoffs...Many years ago I was hired at stumbleupon around the time the leading compsci doctor decided to take a working and profitable monolithic php app and turn it into a scala&#x2F;java microservices architecture... in fact part of the newhire process was a weird one-on-one with said mad-compscientist where he extolled the many merits of microservices and skillfully dodged questions like \"why would you build a distributed service that just adds a list of numbers?\" with a bunch of \"you wouldn&#x27;t understand why it&#x27;s so much better...\" type hand-waving. Fast-forward to 30+ new hires and 4+ long years of intense development and the no-longer profitable company was left with a new slower, buggier, impossible to debug distributed hellscape... as the main designer&#x2F;architect of it all decided it was a great time to take a \"sabbatical\"... it wasn&#x27;t long after that the Nth round of investor money ran out and we were all looking for work. reply cfeduke 3 hours agoprevI feel this, working on a small team moving things to microservices. My primary problem is observability. It&#x27;s become a huge chore figuring what, exactly, is going wrong in production when something goes wrong. It&#x27;s not enough to tail the logs of some distributed application, I need to tail the logs of several distributed applications where there messages are interspersed with one another. I suppose when we get some way to visualize these traces - tooling - it&#x27;ll be okay. But, small team, limited human bandwidth, and we don&#x27;t have this tooling in place yet.The monolith, in contrast, had NewRelic integrated years ago. There were performance problems with this monolith which have been mostly solved through indexes and a couple of materialized views. Trivial to figure out what is going wrong. The code may be old and full of race conditions, but solving problems isn&#x27;t difficult.I dread dealing with multiple separate database instances each backing their own microservice when it comes time to upgrade those databases instances. I was hoping for a single database instance with multiple databases, but that particular architecture isn&#x27;t on the menu. :\\ reply jskrablin 3 hours agoparentTake a look at the OTEL (Open Telemetry) tooling and libraries. Or Grafana stack&#x2F;offering with Prometheus, Tempo and Loki. Centralized logging and service calls&#x2F;code execution tracing is not exactly new. It is often an afterthought.. and then you get yourself is this kinds of unpleasant situations.And since you didn&#x27;t implement correct tooling from the start, your team is even smaller and more limited... because you have little to zero idea on what your services are up to.As per db instances... you upgrade them one by one. Unless there&#x27;s some really bad bugs present (security or otherwise) there&#x27;s no rush in upgrading stuff just because. reply antonvs 3 hours agoparentprevAre you not using cloud? Because the cloud providers provide centralized logging, so all you need to do is pass a request id between services and include that I’d in log entries, and you can trace requests across services. reply chronid 4 hours agoprevI have been fighting this in my current position, with some success with some teams and far less success with others (who are now fighting with the distributed monolith they have created). Ironically the ex-faanmg folks are all pro-monolith.I think most people fail to realize microservices are what you get from an iterative process. You pull out of the monolith the things you need to scale eventually.Microservices need plenty of basic infrastructure that you don&#x27;t want to mantain unless you need to. Most companies don&#x27;t have an adequate platform to support the pattern anyway. reply CraigJPerry 4 hours agoprevThis article is off the rails (to borrow the authors amtrak metaphor).The author posits that if you make pile of crap microservices then all you had to do instead was make a monolith and magically it’ll all be fine.You can put the same kind of design and engineering work in that results in a pile of crap microservices but if you target a monolith instead then you’ll be golden.The author enjoys stroking his own ego as he goes (the comment about full stack js devs for example). And yet, there’s very little here in terms of actual engineering. Want some measurements or some data to back up the waffle? Well the author says tough! You just get a diatribe instead.Keeping the cost to change a system low by managing complexity is a fine goal, but that’s not what’s being proposed here. This article could have been better if it recognised this. This article could have been better if it gave some data - hell even anecdata, a single motivating example, would have been a start.On my team, I’ll take on a bright enthusiastic front end dev who decided they want to spread their wings and grow into a full stack dev over someone who believes they already know everything and has no growing left to do. reply ConcernedCoder 1 hour agoparentupvoted, but honestly, the other side of that coin is:\"The author posits that if you make pile of crap monolith then all you had to do instead was make microservices and magically it’ll all be fine.\" reply bradhe 2 hours agoparentprevAgreed the dichotomy presented is so reductive that it makes you question the author’s credibility. Any architecture that isn’t well maintained will become crushing over time.Ask me how I know. reply knallfrosch 2 hours agoprevI feel that. At my shop, we have given up on debugging altogether, because the tooling simply doesn&#x27;t work.To run one service on our local machine would require us to adapt the other 9 to run against this one. And god forbid you build a \"feature\" for the \"customer.\" Now you have to, of course, touch at least 2 services at the same time to move more data. A breakpoint on one end is a timeout on the other.So every developer is deploying release builds (no hot reload) on a local VM, inserting console.logs, System.PrintLines() and _loggers and then reading the disparate log files. Needless to say, I&#x27;m jumping ship. reply masklinn 2 hours agoparentSounds like the third paragraph could at least be somewhat improved on by switching everything to structured logging and being able to point them all to a local aggregator.Moving everything to distributed tracing would be even better, but there’s a larger investment as the tracing metadata then has to be unified across the board to properly track requests.Would likely help more with ops than with dev but should help nonetheless, even just getting proper spanning information can provide a lot of insight into a clusterfuck.> A breakpoint on one end is a timeout on the other.No dev mode to increase or disable timeouts? reply angio 1 hour agoparentprevWe use mirrord together with a staging environment to run specific services without the need to bring up the rest of the stack locally (we have ~5 services so it wouldn&#x27;t even be an issue). reply mrelectric 1 hour agoparentprevTelepresence! reply ansmithz42 4 hours agoprevA post like this pops up every few months arguing one way or the other. I have lived in absolute nightmare monolith systems with so much cyclic dependency that you couldn&#x27;t move without breaking something. So monolith isn&#x27;t the answer. I have also seen many instances where people have completely missed the underlying principles of microservices and have ended up with an equal nightmare. Neither is a hero or panacea, what matters is to understand what you are building and why and get the interfaces correct. Then understand the principles of different architectures before moving forward. If you fail on this, you get predictably a nightmare. There is plenty of nightmare code sitting on this planet everywhere we look. My recommendation isn&#x27;t to vilify either architecture but to understand their strengths and weaknesses. reply antonvs 3 hours agoparentI agree. What’s the answer to the question “monolith or microservice”? The answer is “architecture”. reply Maxion 4 hours agoprevI am literally working on a project where the backend team consists of three coders, and the backend currently consists 33 microservices. Common tasks for this platform involves calling around 7+ microservices.Thankfully I am working on the frontend side of things, but this is going to be hell when when we launch. reply kgeist 3 hours agoparentOne of our projects has ~15 backend engineers and ~30 microservices. It also requires a separate platform team. A k8s cluster with several nodes. It has incidents like every week because the whole thing is like a house of cards. A small feature requires changes in ~5 microservices and a lot of coordination between the teams. They always need to think about things like circuit breakers, timeouts, APIs (schema synchronization, versioning), event queues, distributed transactions, sagas, distributed locking, k8s configs, Git repository management, distributed tracing etc. etc.On the other hand, there&#x27;s another project, which is a monolith. Around ~15 engineers. Incidents happen very rarely. The infrastructure is simple: just one beefy server without k8s (but there&#x27;s a standby replica of course), so the team often does maintenance of the server on their own instead of a separate SRE&#x2F;production team. The monolith is modular so it enjoys same advantages as microservices when it comes to module isolation etc. Highload functionality is moved to separate Go services only when needed (currently 2 or 3 satellite microservices). All changes happen in the same codebase so features are released faster and it&#x27;s easier to reason about.I&#x27;m currently on the second project and whenever I attend architecture reviews of the first project, I&#x27;m shocked how overcomplicated the first project has become. A simple addition of a new object property can end up in 5-10 engineers arguing for hours whose microservices are affected and how they should best communicate. reply f4c39012 2 hours agorootparentHas the microservice + backend project team ever observed the monolith project team? reply guideamigo_com 4 hours agoparentprevI once saw 5 backend engineers, 100 AWS lambdas, and 30+ GitHub repos! Awesome job security for everyone. reply corethree 4 hours agorootparentThis isn&#x27;t even a joke. Technology in software development has been progressing horizontally. Nothing is improving but abstractions and patterns are changing constantly.Engineers need something to talk about in their OKRs. One strategy is to refactor things into microservices. reply ttyyzz 4 hours agoparentprevYup. Are you using grphql+federation? reply Maxion 2 hours agorootparentLOL no, we&#x27;re using websockets but doing REST-like requests over it. It&#x27;s fun! reply ttyyzz 2 hours agorootparentSounds like you&#x27;re making it hard for yourselves on purpose. May I ask why you (the team) chose this over other technology and what was the decision process at the start the project? reply no_butterscotch 4 hours agorootparentprevDo you think GraphQL has contributed to more microservice driven development? reply ttyyzz 2 hours agorootparentYes, not in a bad way. I love graphql to be honest. Federation (using Apollo) is awesome. reply Freedom2 4 hours agoparentprev> Thankfully I am working on the frontend side of thingsHonestly, given the opinion of frontend on this forum, I&#x27;m surprised that you&#x27;re thankful! I am 100% certain everyone here would take any kind of backend work over the hype-driven mess that is frontend development. reply zdragnar 4 hours agorootparentI moved from backend to frontend years ago, when \"hype-driven mess\" was a much more accurate description of the field than it is today. There&#x27;s simply many more interesting challenges in web application front-ends than backends, especially if you need spacial design- things where canvas or webgl excel.Comparatively, there are far fewer backend positions available that are more than basic CRUD, even if it those CRUD operations are gussied up with a bunch of needless complexity juggling sources of truth across a bunch of different services.There&#x27;s plenty of drudgery out there, and some interesting work in every field, but on the whole I personally have found frontend product development- product configurators for engineering &#x2F; manufacturing, network visualization, visual design tool development, and data driven interfaces to be more fulfilling work.To each their own, but maybe you might want to be a little more aware of the people that you work with when you feel like saying something condescending.Edit: FWIW, you&#x27;d have to be blind to not see hype driven development in backend, especially in HN. \"Rewrite it in rust\" is the meme that continues to keep on giving. reply lenkite 2 hours agorootparentprev> I am 100% certain everyone here would take any kind of backend work over the hype-driven mess that is frontend developmentThe back-end is becoming an even more hype-driven mess these days. What with k8s and dozens of micro-services and controllers and telemetry-everything. And people don&#x27;t even listen nowadays if you try to propose something simpler.The front-end is at-least constrained by browser limitations and the client device. One can only do hanky-panky upto to a point. But at the backend, \"throw another cloud machine\" at it has become the de-facto solution for most performance issues. reply gherkinnn 3 hours agorootparentprevIsn’t it obvious that it is all the same?A dozen micro services per developer on rickety infrastructure serving data for a pixel generator built on top of 5 years worth of JS hype cycles. Why are we doing this to ourselves? It is just so stupid. reply Maxion 2 hours agorootparentWe all gotta pay the mortgage somehow! reply metalspot 22 minutes agoprevservice oriented architecture is a disaster even in large companies. without a monolithic database and normalized schemas you always end up with a bespoke ad-hoc never-consistent data store. data and results are unverifiable and continually incorrect and the performance is abysmal.a really large company can waste hundreds of millions of dollars papering over the inherent deficiencies of the architecture but it is an exercise in building additional stories on a house where the ground floor is made out of cardboard that happens to be on fire. soa was created purely for business organization needs. any technical justifications are post hoc rationalization. from a technical perspective it is pure trash.a much better architecture is to keep services but have them all built on top of a single monolithic db. at scale the monolithic db can be a facade and then you disaggregate the database into horizontally scalable services so that you can scale your monolithic db facade to whatever you need. reply bcoughlan 2 hours agoprevStarting with a monolith is nearly always great advice. However, monoliths tend towards spaghetti because it&#x27;s too easy essentially to draw new lines on the architecture diagram by importing from anywhere.To scale a monolith codebase without devolving into spaghetti you need to have a well defined layered structure for modules. The other aspect is being able to hide internal code to prevent it being imported by other modules.I did a write-up a while ago about how we do this on my current project [1], and published the Maven enforcer rule and ArchUnit test example as an open source project [2].[1] https:&#x2F;&#x2F;bcoughlan.github.io&#x2F;posts&#x2F;modulithic-architecture&#x2F; [2] https:&#x2F;&#x2F;github.com&#x2F;bcoughlan&#x2F;base-package-enforcer-rule&#x2F; https:&#x2F;&#x2F;github.com&#x2F;bcoughlan&#x2F;base-package-enforcer-rule&#x2F;blob... reply bryanph_ 3 hours agoprevI don&#x27;t quite understand the mentioning of node at the start of the article as a cause of this. You can write a monolith in node just as well as you can write a web of microservices. That said I agree with the sentiment of this article, it&#x27;s very frustrating to deal with in any company. Especially when these microservices aren&#x27;t versioned under the same repo and&#x2F;or are hosted at different providers causing unnecessary latency. reply weevil 1 hour agoparentThey argue that Node tricks frontenders into thinking they can do server-side, then says they &#x27;huff and puff&#x27; when this is pointed out to them. It&#x27;s an incredibly patronizing argument to make. reply bradhe 2 hours agoparentprevNode is just the whipping boy for the old guys who are afraid of 2023. I say this as an old guy. reply rahen 2 hours agorootparentHow would you sell Node to other old guys? Especially compared to Go.I try to favor simple, efficient software. I used to dislike PHP because it was so messy and inefficient, until newer frameworks like Django made it look like it was slim and snappy. Maybe, in this race to the bottom, Node stands out in a way I hadn&#x27;t seen, so I&#x27;m genuinely interested. reply Cyphase 48 minutes agorootparentDid you mean Python, or did you mean Laravel? reply Sohcahtoa82 2 hours agoprevI have two huge gripes that I&#x27;ve run into when dealing with microservices:1. They&#x27;re actually nanoservices. The article touched on this. A single function shouldn&#x27;t be its own service unless it&#x27;s something that requires a lot of processing, like a service that converts files from one type to another. But something like handling user registration? You don&#x27;t need separate services to handle registration, login, and the forgot password flow.2. The services are poorly named. At a previous job, we had services with names like \"Kafka\", \"Avatar\", and \"Sophos\" and none made sense for what they did, especially Kafka, which I expected to maybe be a wrapper around Apache Kafka? But no. It should have been called the User Preference Service, because it was simply a service for users to get&#x2F;set their preferences. reply karles 1 hour agoprevWell, the idea of microservices would be to build some degree of flexibility into the setup, so that you can handle problems you don&#x27;t have now, but you might have later.I understand that the Monolith - if done right - is a viable option as well.As a consultant, our customers rarely know what they want, and they can&#x27;t really describe their vision, no matter how many workshops we throw at them. Microservices give us the opportunity to say \"We might not know this now, but with this architecture, we won&#x27;t be locked into a certain pattern or meet certain technical limitations by a monolithic approach\".It seems that what you are really paying for with microservices is flexibility and maneuverability \"down the line\".Solving only the problems you have \"here and now\" with the simplest solution will also lead to technical debt. reply geewee 33 minutes agoparentI don&#x27;t think I agree with your thoughts. Microservice setups are generally less flexible than monolithic setups. Particularly if you get the boundaries wrong it&#x27;s notoriously difficult to refactor multiple microservices, particularly if you need full uptime.For monoliths you can refactor the whole thing with editor support, and then deploy a new version.So microservices will cost more, give you less flexibility and maneuverability, at more upfront cost. It seems like the worst of both worlds. reply EMM_386 3 hours agoprevI was involved in a merger with the platform I architected on one side, and a platform that does the same thing on the other side. We were told the company wanted one platform.I do everything I can to follow KISS. These are important enterprise systems that drive the entire company. I went with a front-end framework in TypeScript, C# APIs, and a relational SQL DB as the gist of it. It turned out great ... performant, reliable and the users were reporting positive feedback (this one was a recent upgrade from an older system).The other side had the same number of users, but had over 100 PHP microservices, Docker containers, queuing frameworks, and all sorts of additional technologies in the mix. It had 5 times the number of engineers on it, but was at the end of the day was functionally equivilant and had the same volume of traffic.When comparing the up-time, it was clear the microservices architecture was the main source of pain. They weren&#x27;t even comparable. We are always talking about whether we&#x27;re at \"5 nines\", and the other system was having major outages every other week.You could argue that it was a poorly architected system, and that microservices weren&#x27;t the root cause, but that really wasn&#x27;t the case. The entire system was based around the microservices, and they weren&#x27;t working as promised. What originally was seen as separation of logic and concerns and everything else that microservices offer eventually over time became a tangled, inter-dependant system of services that were very high in bandwidth, slow in performance, difficult to maintain and bad in reliability.This isn&#x27;t the first time I&#x27;ve seen this. I&#x27;ve worked with microservice architectures in other companies, and I haven&#x27;t yet seen it \"done right\", or at least how I understand it. It always comes across as great in principle but bad in practice. reply rawbert 2 hours agoprev> Micrsoservices are not DRYTell that my team mates putting all stuff into libraries because \"we made that already\" and building a huge distributed monolith. We combined sucessfully the worst of both worlds! reply sjducb 1 hour agoparentIt’s the whole coupling vs DRY trade off. Coupling is worse than code duplication. reply andrewstuart 4 hours agoprevMicroservices you trade application complexity for devops complexity.My theory is to make devops as simple as possible and push complexity into application code.This includes a rule to use cloud VMs but use the minimum possible cloud services, ideally none, especially not things like lambda&#x2F; cloud functions. reply corethree 4 hours agoparent>Microservices you trade application complexity for devops complexity.There&#x27;s a second trade off. Overall complexity. The application as a whole is more complex when split into two than when existing as one.So three things happen:1. Complexity of the individual microservices goes down.2. Dev ops complexity goes up.3. Overall complexity of the entire system in general goes up. reply andrewstuart 3 hours agorootparentYeah great point.Then trying to work out where the problem is spans both DevOps and development and suddenly you are in a world of hurt. reply aledalgrande 4 hours agorootparentprevAdd data complexity to that (consistency) reply hosh 4 hours agoparentprevA lot of microservices introduce unnecessary complexity.Erlang and Elixir are unusual in that you can have independent “microservices” running within a monolith. reply gehen88 1 hour agoprevWhy this is getting blamed on JavaScript &#x2F; Node.js is beyond me. Microservices were&#x2F;are all the rage in Java&#x2F;Scala land, and seemed to initially be pushed by (Dev)Ops engineers&#x27; desire to roll their own Kubernetes cluster (or whatever came before). I&#x27;ve been on multiple such project and I always loathed the additional complexity (especially combined with actors&#x2F;event sourcing and Cassandra). Node.js was limited to some frontend tooling that only ran locally or in CI. reply beaker52 2 hours agoprevI’m currently at a place using microservices, in a monorepo, where business logic is executed in consuming services, and some business logic is in a monolithic graphql layer, that only frontend clients call. Tries all the tricks, fails at all of them.Still, it’s a profitable business. The dirty truth is that the current crop of engineers are the ones paying with their blood, sweat and tears - and I’m not sure about you, but that’s not what I signed up for as a software engineer, so we should demand better. reply molly0 3 hours agoprevBeen working for 6 month at a company with ~150 engineers that uses Microservices.As a simple software engineer I love it, It allowed me to easily get right in to parts of the system and conceptually understand the boundaries between different systems and business unites.But it sure adds complexity - complexity that I fortunately do not need to deal with... Yet. reply DrDroop 3 hours agoprevI also know people that spend 40k euro a month to run the database of their rails app on the biggest instance they can find on aws. The traffic is seasonal and the workload is mostly one way payment traffic. But hey, they are still making money so good for them. I&#x27;ve personally been exploring a more flexible architecture for another project using a combination of cloudflare workers, storage and k&#x2F;v store. The hardest thing about it currently is that you have to engineer everything yourself to be specific to your problem. Either way, both monolith and microservices have their challenges, I hope to find something that can avoid both but it feels like a stab in the dark. reply sjducb 1 hour agoparentI’ve had contracting gigs bringing down the costs of SQL DBs that cost a million per year. You can usually get costs below 200k fairly easily.- Performance tuning - Migrate old data out of the DB - Delete unused indexes - Improve queries so they return less unnecessary dataThe problem is usually one massive table or 2-3 unoptimised queries.No need to rewrite the application to use NoSQLWith seasonal load in AWS it’s really easy to change the DB instance size manually. No need for auto scaling. reply nelsonic 4 hours agoprevJust use Elixir&#x2F;Phoenix and get all the scaling benefits of Microservices running seamlessly across datacenters while maintaining the sanity running a single app on your localhost that is fast to test, easy to reason about and deploy!Having worked in several places that adopted Microservices with nowhere near the Netflix or Uber scale just because it&#x27;s trendy I can attest to the mess and glacial pace of both learning and development for new team members. If you want to move fast and make something people want, don&#x27;t pretend you need \"webscale\", you don&#x27;t. You&#x27;re building an apartment block for a few people not a city for millions. The beauty of Erlang&#x2F;OTP is that it&#x27;s designed to scale to millions without any extra effort from the individual contributors or fancy DevOps. reply threeseed 3 hours agoparentNobody is using micro-services to solve a performance&#x2F;scaling issue.You can just horizontally scale a monolith to achieve this. reply bsaul 4 hours agoparentprevi don&#x27;t see how erlang &#x2F; otp or elixir &#x2F; phoenix is relevant to solve the problem most companies are facing when hitting their first \"web scale\" problem : bottleneck at the DB level. reply nelsonic 3 hours agorootparentAgreed. The DB is the bottleneck way before the code architecture. But that is a \"solved\" problem from a deployment perspective. All the Cloud providers have managed Postgres that scales to petabytes and millions of transactions per second. And the part being discussed in the article is the Microservices. Where Elixir&#x2F;Phoenix shines at delivering the benefits of Microservices i.e. scaling a specific function in your codebase to multiple processors&#x2F;instances while still being easy+fast to run on a single Dev machine without hundreds of Docker processes. reply tacker2000 1 hour agorootparentSorry but what are you talking about? Microservices in a monolith without containers? How does that even work? reply mdtrooper 3 hours agoprevAs other gifts of computers field: death by a thousand tables in DB, death by a thousand class in Java, death by a thousand tickets in Jira&#x2F;Redmine&#x2F;Bugtracker&#x2F;Gitlab..., death by a thousand \"go to\" in Basic... reply hnpxr 3 hours agoprevIt&#x27;s nice to see the trend unwinding, microservices are egregiously overused as a silver bullet for any problem (not just scaling).There are probably dozens (&#x2F;s) of companies that would benefit from going all-in with microservices. Some companies would benefit from having a few microservices; but most would be more than successful running a monolith.The most significant problems with microservices arise when they&#x27;re adopted too early and when data separation is not properly handled, resulting of even the simplest requests ended up querying 3-5+ microservices.Latest anecdata point: doing exactly that (unwinding microservices) in a team of 20 engineers (15 swe&#x2F;5 sre) and 400+ repositories (which isn&#x27;t a \"wrong\", but having so many different places to update, for example, Python version is nuts). The whole project is nuts.And persuading management was not an issue, it was enough to show current AWS bills and potential savings from moving from 50+ microservices to smaller numbers of consolidated services and deprecating&#x2F;refactoring some features. The real challenge was persuading the engineering team to prioritize and work on this issue - which is still ongoing. reply simonhamp 2 hours agoprevOne of the things this article alluded to (but I didn&#x27;t see it explicitly stated) as to why microservices is a default go-to architectural choice:Because then a bunch of engineers can stick it on their résumé and try to get a job at a big companyI worked in a funded startup where we built a service-oriented architecture out of a few key Laravel monoliths. This was entirely manageable for a team of less than 10 engineers and scalable for the context.Because we built it as a distributed system, each of those core services was ready to handle outages. So it was extremely easy to deployWhat&#x27;s more, it barely cost us $20k PER YEAR to run it allBut now I can&#x27;t say I&#x27;ve worked with microservices so I&#x27;ll likely not stand a chance at any of those interviews reply EricDeb 4 hours agoprevAs with a lot of things I find the answer is usually somewhere in the middle. Break out larger chunks when it makes sense. reply threeseed 3 hours agoparentUnfortunately in the middle where the answer is pragmatic and nuanced isn&#x27;t clickbait enough. reply weevil 1 hour agoprevThis post reads like a cry for help. I don&#x27;t really know what they&#x27;re arguing for. Sure the broad-strokes &#x27;microservices bad monolith good&#x27; is something I can get behind in some cases, but the slightly unhinged tirades against Node developers and the &#x27;bloated farce&#x27; of the modern tech industry might as well be satire for all the value it contributes to debate. reply yoava 3 hours agoprevHaving taken part in building the Wix microservices architecture, I have to say that I understand and accept the critique of the article. Microservices is not a magic architecture, it solves some problems with the price of others.When we stared Wix, we stared as a monolith - at 2006. In 2008 we split this monolith into two services due to different SLA - building websites and serving websites.In 2011 we stared splitting the monoliths into micro services to solve software delivery pipeline - ability to move fast and scale with number of developers. Today we have about 20,000 deployments of new software every year, with over 1000 developers.At Wix we are constantly investing a lot to maintain the microservices architecture and make it productive for our developers. We are making tools and utilities to return DRY into microservices architecture (think CDC support, GDPR support, Monitoring support, Scaling, Access Control, etc.).My takeaways -* Microservices do not come for free. You have to invest in making it work for you* When building a startup - build a monolith. Break it down later when you understand what you need.* We as an industry do not understand how to build micro services. There are a lot of fundamental aspects of microservices that are not commonly known &#x2F; understood or ready as of the shelf solutions. reply root_axis 3 hours agoprevI don&#x27;t think microservices are as common as often suggested. In my experience with small and medium sized companies, if they go SoA, its typically just \"services\", almost always sharing the same DB, and pretty much never \"microservices\". Usually it&#x27;s something like: a service for the webapp, maybe an api service, a couple services for something like a job queue or sockets, possibly with the a service for compute bound tasks like media processing or reports. I&#x27;ve also worked at places with 50+ services working together in production, but they&#x27;re rare (at small and medium sized companies). reply holoduke 3 hours agoprevA good maintainable software solution is always build out of relatively small and simple components with very important: clear inputs and outputs without too much sideeffect behavior. It says nothing about if its a monolith or microservice. I have seen a lot of microservice architectures so complex with 100s of layers and configurations that nobody in the company understood how it really worked. I have also seen the very same thing in large monoliths. Too big. Too complex. The discussion should be about the software component architecture. Not about ifs a monolith or microservice. reply tzahifadida 4 hours agoprevThe name microservice is a fanatical view of how a service should work. That is the problem. If you say you made a service, then it is not a \"micro\"-service, so you are lacking \"experience\" with microservices :) Therefor we must build microservices to have jobs.In reality, you need services that are engineered properly. They can be monolith or not, can share databases or not, can live on the same server or not... depends on the situation. But, as soon as you say the work \"micro\"service, you are doomed because it won&#x27;t be a microservice if it does not adhere to millions of articles on the internet saying how to it should behave... reply xyst 3 hours agoprevI can agree with this sentiment now after working at a handful of companies and many interpretations of micro-services oriented architecture.The one thing I don’t miss about monoliths, especially at low budget&#x2F;low rent firms, is that the project often exchanges so many hands&#x2F;owners&#x2F;teams between bottom bid contractors and “rockstars&#x2F;ninjas”. This often leads to the usual god classes, half assed abstractions, massive utility classes, and half assed code refactors. reply pulse7 2 hours agoprevMicroservices are often used as an excuse to be able to write part of the system (=microservice) in own technology stack and not in the one the rest of the system is already written in... reply RamblingCTO 2 hours agoprevITT: people promising exactly one magic bullet for a plethora of scenarios they know nothing about reply fendy3002 3 hours agoprevIf you have an expert in design &#x2F; architecture and know the domain problem &#x2F; scope &#x2F; boundaries, go for microservice. Otherwise, monolith.A good microservice is better than a good monolith since the boundaries are clearer. However a bad microservice are many times worse than bad monolith since on top of the wrong scope, intertwined boundaries and other problem from bad design that exists in monolith, now you&#x27;re faced with additional infra challenges. reply mihaaly 2 hours agoprev“how they did things over at Google”LOL. This is how a former out of academy right into startup CTO position colleague tried to argue his choice of approach to enforce. Those were dire times, luckily I found my new place fast, just in time to avoid the spectacular implosion. reply CptKriechstrom 1 hour agoprevI don&#x27;t get the hate about Microservices. Use Event Sourcing to eliminate the whole S2S Communication and gRPC to connect the Clients. Done. reply guideamigo_com 4 hours agoprevFWIW, Google and Facebook are mostly monoliths and not microservices. reply tra3 4 hours agoparentThere was a paper published about facebooks infrastructure: https:&#x2F;&#x2F;www.usenix.org&#x2F;system&#x2F;files&#x2F;atc23-huye.pdf> Scale is measured in millions of instances: On 2022&#x2F;12&#x2F;21, the microservice topology contained 18,500 active services and over 12 million service instances.They do go on to say that microservice as a concept is poorly defined. Are you suggesting that they mostly have 18500 of what we’d normally consider monoliths? reply guideamigo_com 1 hour agorootparentProbably some unit inside Meta. Most of Facebook backend was a deployed as a single unit. reply gigatexal 4 hours agoparentprevI thought Google at least was a bunch of micro services which is why they needed something like Borg and eventually open sourced a version of it called K8s. reply guideamigo_com 4 hours agorootparentTotal BS. Google has tons of services. They are lots of them but they don&#x27;t have a `fileRead` service and `fileWrite` service. Rather, they have a `gfs` service that can read&#x2F;write&#x2F;modify etc. everything related to files. reply daitangio 3 hours agoprevGold rule, to start with, is1 Microservices = 1 TeamIn a multivendor scenario, it could make sense to split a big monolith in say 2 or 3 components, but I have seen dozen of microservices (one of which just managed 3 read-only tables...).But if your 6-guys team ends up deploying 6+ microservices, you are doomed, in my huble opinion. reply RamblingCTO 2 hours agoparentWe have exactly two microservices atm: one sends emails, one registers users and creates a backend (one backend per customer with us). Should I hire a team just to adhere to your golden rule? I wrote them myself, no support from anyone needed, they are low maintenance.Do architecture first, have a modular monolith, if you need microservices, use &#x27;em. The rest if this thread is just a waste of time and a bunch of strong opinions.I just hate this whole thread. Full of weird assumptions. People here don&#x27;t know enough about the scenarios to hate on either solution. Do what&#x27;s right for your project and don&#x27;t listen to the internet. Easy as that. reply zarzavat 3 hours agoprevMicroservices are a bit like NoSQL DBs. There is nothing intrinsically wrong with the technology, it’s just overused.Many users of microservices would be better off with a monolith. Many users of NoSQL DBs would be better off with Postgres. reply fanksid 2 hours agoprevIt&#x27;s always right to start with a monolithic. After all, not everyone knows what they want. reply new_here 4 hours agoprevPosts laden with cynicism are always popular on HN. Gets boring after a while. Was hoping for a more measured take on a genuine issue like this. reply hughesjj 4 hours agoparentThere&#x27;s always something hot to hate on. I&#x27;m getting flashbacks to the days where everyone was going \"nosql is trash\" because they all cargo culted to mongodb back in the day and then tried to do olap on it.Heck, this isn&#x27;t even the first time SOA has been in the frame of hate. Member SOAP? Member how everyone more or less jumps between doing everything on the server vs everything on the client every year? We&#x27;ve been having that battle ever since networking or things clients have been a thing, the \"sportsification\" of that dichotomy is older than I am.I like the other person&#x27;s take in this thread about how you can largely get the semantic benefits of micro services by making a well crafted monolith. I honestly agree, but I think the followup is \"aren&#x27;t people who poorly break up service boundaries going to go do regardless if the interface is a network endpoint or a function call&#x2F;dependency injected class?\" reply throwaway_036 26 minutes agorootparent> \"aren&#x27;t people who poorly break up service boundaries going to go do regardless if the interface is a network endpoint or a function call&#x2F;dependency injected class?\"Today there are several tools we can use that enforces boundaries in a monolith (Spring Modulith for example). If the project uses one of these tools, it is harder to accidentally cross boundaries and you get many of the same benefits as you get with a micro service.The big advantage is that if you find out that you made a mistake, your only dependencies are within the same service and is easier to refactor. In a micro service oriented architecture, changes might impact several services and teams that needs to be coordinated. I&#x27;m not saying that refactoring a monolith can&#x27;t be time consuming, but you have at least a better control of the flow of data between modules. reply smokel 3 hours agoparentprevAn interesting angle would be how to get out of this mess.Here&#x27;s one: In politics we see national and supranational governments take on the job of making large decisions. Style guides and best practices on whether to use microservices or not are, at best, made at a company level.Would it be interesting if these architecture decisions were made, or at least kept in check by a body that is larger than a company?Perhaps we could have some laws that dictate that you must (at least partially) understand how software works before you can buy it. Especially for government contracts. reply threeseed 3 hours agorootparentJust a lesson in life.The second you think you are smarter and more informed than the people on the ground is the second you revealed yourself to be a fool.Because having spent decades working for government and enterprises I can assure you that we aren&#x27;t all stupid and need laws to protect us from ourselves. Instead we are often placed in really challenging and unique circumstances that drive the architecture and design of what gets built.For example micro-services often works well in places where you have distributed teams that for security, governance or logistical reasons need to work independently and can&#x27;t collaborate effectively with a monolith architecture. Or where certain components e.g. authentication, payments need a hard separation from the rest of the platform. reply corethree 4 hours agoparentprevI&#x27;m actually sick of the apples and oranges view point.There&#x27;s always someone saying that everything is a different tool in the toolbox.The reality is some tools are honest to god pieces of shit. That&#x27;s where the interesting content is.The whole fair and balanced viewpoint is played out, boring and obvious. reply revskill 1 hour agoprevTo me, it&#x27;s mostly skill issues when people couldn&#x27;t extract the code into indepedent parts.The point is, make everthing as a library.It doesn&#x27;t matter if microservice or monotholic, just import your library and use it. reply yieldcrv 4 hours agoprevThe small org I work for has two distinct AWS accounts and nobody knows whats in each one, let alone whats in the regions for each one. Everyone is an IAM user that a third party IT company creates after emailing helpdesk a few business days prior.both AWS Accounts have a bunch of lambdas randomly doing necessary things in a variety of our development environments, but mostly productiona single AWS account is fully capable of catering to multiple development environmentsthis is hilariously Byzantine reply deterministic 2 hours agoprevThe worst WTF system I have ever seen in my 30+ years career was a microservices system.The best most maintainable systems I have ever worked on were all 1 million+ line monoliths. Split into N libraries with clean API’s and separate teams working on them.You have a problem so you pick microservices. Now you have N*(N-1) problems. reply throwaway2990 2 hours agoprevI wish people would stop creating nano services, calling them micro services, then complaining about them. reply baz00 4 hours agoprevMicroservices is mostly an RDD (Resume Driven Development) practice I&#x27;ve found. Really, as the article says correctly and hilariously, unless you&#x27;re a greenfield or exceptionally large, you end up with a fleet of shitty golf carts.My personal anecdote is, watching from the sidelines with face cupped in hands, watching a monolith being broken into hundreds of microservices at the cost of decreasing performance, increasing complexity and 90% of the traffic still hitting the monolith. Of course there&#x27;s no time to do anything for the customers any more because everyone is updating software versions in all the microservices and promoting that \"it&#x27;ll all be fine if we just move one more thing to a microservice\". The architectural vision will be complete in 2130 at this rate.I want out from this demented ego driven fashion show. reply The_Colonel 3 hours agoparent> Microservices is mostly an RDD (Resume Driven Development) practice I&#x27;ve foundI agree. The worst I&#x27;ve seen is with contractors&#x2F;consultants, because the incentives are particularly bad.They often stay with the project only for a limited time and \"grokked customer&#x27;s business&#x2F;domain logic\" is not something you can put on your resume and the typical 6 months are too short for that anyway. But there&#x27;s enough time to introduce a schema registry or other piece of tech which can look pretty good on your CV. Jump onto a different customer, rinse and repeat. I call this \"technology-oriented mindset\" vs. \"goal oriented mindset\". reply quickthrower2 3 hours agoparentprevI have avoided, by luck alone, microservices, except the occasional small service where it makes sense (think AWS Lambda to covert doc to pdf for spikey loads) and I am glad. It means I don’t get far in interviews at small companies that bizarrely want microservices experience (as opposed to problem solving experience!) reply virgoerns 3 hours agoparentprevWe broke our monolith ~2015. 8 years later we still have the original monolith plus the original mircoservices are now monoliths too which need splitting. Upgrades were a nightmare for first 5 years, but we solved it with nitpicking code reviews where non-trival changes are blocked forever until everyone&#x27;s ready.At least we solved the problem of decreasing performance the old fashioned way: by throwing more RAM and CPU power at the problem. reply nonrandomstring 2 hours agoparentprev> I want out from this demented ego driven fashion show.The author of TFA kinda hits on this in the first paragraph:> absurdity of the state of the current tech culture. We laugh, and yet bringing this up in a serious conversation is tantamount to professional heresy, rendering you borderline un-hirableAs soon as I read that, I felt I knew what the rest of the essay would be about, and I was right. It&#x27;s about culture.A culture of insecurity, wannabeism, fads, in-groups cliques, so-called \"best practices\", megalomaniacal levels of scaling, over-reach..... let&#x27;s all admit shall we (at least privately) , that \"tech\" has an _ugly_ culture, that we&#x27;ve lost those early joys of solving problems. We&#x27;ve replaced that with a culture of making problems so we can look good by \"solving\" them. Just realising that would bring enormous economic benefits.In wider human culture, tech is looked down on, for good reasons. At worst it is a proxy battleground for personal whims and ideologies in which one group of people set out to impose upon another larger group, their particular idea of how the world should &#x27;work&#x27;. Code becomes our poor man&#x27;s",
    "originSummary": [
      "The article questions the perceived necessity of microservices for scalability, stating that successful companies have managed with simpler systems.",
      "It points out the challenges that microservices bring, including code duplication and decreased developer productivity.",
      "The piece suggests starting with a monolithic architecture, or a mixture of a monolith and branch services, hinting at an industry shift away from microservices towards more practical solutions."
    ],
    "commentSummary": [
      "The article debates the merits and demerits of utilizing microservices in software development, discussing additional engineering overhead and the complexities of managing large databases.",
      "It underscores the complications involved in debugging and maintaining distributed microservices, and concerns about the trend being potentially driven by inexperienced engineers for resume padding.",
      "The forum showcases varying views on employing microservices versus monolithic systems, emphasizing that decisions should be based on an organization's specific needs, recognizing the trade-offs and challenges of both architectural styles."
    ],
    "points": 330,
    "commentCount": 234,
    "retryCount": 0,
    "time": 1694495120
  },
  {
    "id": 37470285,
    "title": "Calculate the difference and intersection of any two regexes",
    "originLink": "http://phylactery.org/antimirov/",
    "originBody": "enter some regular expressions! α := β := ~α = ..* ~β = ..* αβ = false α & β = α ^ β = ∅ α - β = ∅ s := s ∈ α = false s ∈ β = false |α| = 1 |β| = 1 dfa(α) has 1 states α₀ dfa(β) has 1 states β₀ regex syntax . match any single character xy concatenation: match x and then y x|y alternation: match x or y x* kleene star: match x zero-or-more times (xyz) grouping: treat xyz as a single item (e.g. (xyz)*) () an empty regex matches the empty string x+ kleene plus: match x one-or-more times (equivalent to xx*) x? optional: optionally match x (equivalent to (x|)) x{n} exponentiation: concatenate x to itself n times x{m,n} repetition: concatenate x to itself between m and n times [a-z0-9] grouping: match any single character in the group [^a-z0-9] negative grouping: match any single character not in the group \\c escaping: match the special character c \\u001a unicode escaping: match the corresponding UTF-16 character a, b, c all other characters match themselves unsupported features - anchors (e.g. ^, $), although ^ and $ must still be escaped! - zero-width assertions (e.g. (?=...), (?<=...)) - back references (e.g. \\1, \\2) - subgroup extraction - searching or partial matching - other flags that change behavior (e.g. case-insensitivity) see https://github.com/non/antimirov for more information by eiríkr åsheim (@d6 on twitter and mastodon)",
    "commentLink": "https://news.ycombinator.com/item?id=37470285",
    "commentBody": "Calculate the difference and intersection of any two regexesHacker NewspastloginCalculate the difference and intersection of any two regexes (phylactery.org) 319 points by posco 17 hours ago| hidepastfavorite104 comments oever 14 hours agoThis library can be used to create string class hierarchies. That, in turn, can help to use typed strings more.For example, e-mails and urls are a special syntax. Their value space is a subset of all non-empty string which is a subset of all strings.An e-mail address could be passed into a function that requires a non-empty string as input. When the type-system knows that an e-mail string is a subclass of non-empty string, it knows that an email address is valid.This library can be used to check the definitions and hierarchy of such string types. The implementation of the hierarchy differs per programming language (subclassing, trait boundaries, etc). reply 1-more 13 hours agoparentIn languages with tagged union types you do this a lot! Some Haskell pseudocode for ya module Email (Address, fromText, toText) where -- note we do not export the constructor of Address, just the type data Address = Address Text fromString :: Text -> Maybe Address fromString = -- you&#x27;d do your validation in here and return Nothing if it&#x27;s a bad address. -- Signal validity out of band, not in band with the data. toText :: Address -> Text toText (Address addr) = addr -- for when you need to output it somewhere reply bradrn 9 hours agorootparentPedantic note: ‘Address’ should really be a ‘newtype’… reply 1-more 5 hours agorootparentHaha sorry, I get those backwards a lot. I was gonna do elm but then it’d be a conversation about why we’re writing our own email address validation on the front end instead of using the platform. reply alexvitkov 5 hours agorootparentDon&#x27;t worry, that&#x27;s normal -- in this forum we only talk about how good obscure languages are, nobody actually uses Haskell. reply alexeldeib 13 hours agorootparentprev> Signal validity out of band, not in band with the data.Could you expand on this? reply 1-more 12 hours agorootparentSure! Sorry that was a little too obtuse. So in this case we can imagine an app where we don&#x27;t use any tagged unions and just use primitive types (your strings, booleans, integers, things of that nature). And we want to signal the validity of some data. Say a user ID and an email address. We store the User ID as an integer to keep space down and store the email address as a string. We use semaphore values: if the user ID is invalid we store -1 (it&#x27;s JS and there are no unsigned numbers) and if the email address is invalid we store the empty string.Whenever we consume these values, we need to make sure that userId > 0 and email != \"\" I mean email !== \"\". We are testing for special values of the data. Data and \"this is for sure not meaningful data\" are the same shape! So your functions need to handle those cases.But with tagged unions you can check these things at the edge of the program and thereafter accept that the contents of the tagged data are valid (because you wrote good tests for your decoders).So your data is a different shape when it&#x27;s valid vs when it&#x27;s invalid, and you can write functions that only accept data that&#x27;s the valid shape. If you got Json that was hit by cosmic rays when trying to build your User model, you can fail right then and not build a model and find a way to handle that.It&#x27;s out of band because you don&#x27;t guard for special values of your morphologically identical data.If you want examples of any specific part of this let me know. IDK your level of familiarity and don&#x27;t want to overburden you with things you already get. reply usrusr 43 minutes agoparentprevNothing like a dive into the wondrous world of what is and isn&#x27;t allowed in an email address left of the @ on a warm late-summer morning. It&#x27;s one of the mysteries of the modern world. The simple heuristic that proposes that every regex trying to express \"valid email address\" is wrong is a sufficiently safe bet, but it ruins all the fun. reply _a_a_a_ 13 hours agoparentprev> Their value space...wossis mean? TIAEdit: instread of downvoting try answering. I&#x27;d like to know. TIA{2} reply umanwizard 10 hours agorootparentPeople are downvoting you because quirky&#x2F;jokey super-colloquial language like “wossis mean? TIA” is hard to understand, and also just doesn’t really mesh with the vibe of the site. reply eru 9 hours agorootparentWhat does TIA even mean? reply Tommstein 8 hours agorootparentThanks In Advance. reply oever 12 hours agorootparentprevValue space is the set of values a type can have. A boolean has only two values in its value space. An unsigned byte has 256 possible values, so does a signed byte.A string enumeration has a limited number of values. E.g. type A (\"Yes\"\"No\"\"Maybe\") has three values and is a superset of type B (\"Yes\"\"No\"). A function that accepts type A can also accept type B as valid input.If the value space is defined by a regular expression, as is often the case, the mentioned library could be used to check, at compile-time, which type are subsets of others. reply _a_a_a_ 12 hours agorootparentThank you. I guess I misread.\"For example, e-mails and urls are a special syntax. Their value space...\" seemed to talk about the &#x27;value space&#x27; of strings (these being e-mails and urls), not types (of e-mails and urls), which confused me. reply acchow 12 hours agorootparentIt is bout the &#x27;value space&#x27; of strings. Think of all possible strings. That is the entire value space of strings. Not every possible string is an email. Only a subset of this value space is a valid email. This subset is the &#x27;value space&#x27; of strings which are valid emails. reply brianpan 11 hours agorootparentprevIf I hadn&#x27;t seen your edit, I might have downvoted the comment for not being intelligible. reply JoelJacobson 14 hours agoprevI created a similar regex web demo that shows how a regex is parsed -> NFA -> DFA -> minimal DFA, and finally outputs LLVMIR&#x2F;Javascript&#x2F;WebAssembly for from the minimal DFA:http:&#x2F;&#x2F;compiler.org&#x2F;reason-re-nfa&#x2F;src&#x2F;index.html reply eru 9 hours agoparentThough going from NFA to explicit DFA isn&#x27;t always a good idea.Btw, you might also like looking into the Brzozowski derivative https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Brzozowski_derivative which can be used as an alternative way to match regular expressions. reply alphablended 8 hours agorootparentI think it is also worth mentioning that the site linked at the top uses the antimirov extension to brzozovzki work on regex deivatives. reply lubutu 4 hours agorootparentTo expand, Brzozowski introduced derivatives and Antimirov partial derivatives. Essentially the former correspond to DFAs and the latter to NFAs. reply mikhailfranco 3 hours agorootparentprevYou could implement the NFA directly with concurrent exploration of all paths:https:&#x2F;&#x2F;github.com&#x2F;mike-french&#x2F;myrex reply est 6 hours agoprevHa, trying to paste \"regex filter numbers divisible by 3\" and the page froze to death https:&#x2F;&#x2F;stackoverflow.com&#x2F;q&#x2F;10992279&#x2F;41948 ^(?:[0369]+|[147](?:[0369]*[147][0369]*[258])*(?:[0369]*[258]|[0369]*[147][0369]*[147])|[258](?:[0369]*[258][0369]*[147])*(?:[0369]*[147]|[0369]*[258][0369]*[258]))+$ ^([0369]|[147][0369]*[258]|(([258]|[147][0369]*[147])([0369]|[258][0369]*[147])*([147]|[258][0369]\\*[258])))+$I wonder if there&#x27;s a shortest one. reply abareplace 1 hour agoparentThe web page hangs on the regular expressions that produce a DFA with a lot of states. For example, these ones:(ab+c+)+(abc){100}a.*quick brown fox jumps over the lazy dog reply klysm 15 hours agoprevRegular expressions are a great example of bundling up some really neat and complex mathematical theory into a valuable interface. Linear algebra feels similar to me. reply dhosek 14 hours agoparentIt always amazes me how given the appropriate field, so much math can be transformed into linear algebra. Even Möbius transformations on the complex plane w=(az+b)&#x2F;(cz+d) can be turned into linear algebra. reply pishpash 11 hours agorootparentLinear transformations preserve the structure of the space so you can keep applying them. It&#x27;s not surprising that you can always find some \"space-preserving\" part of a problem and fold the rest (the \"non-linear\" structure) into transformations or the definition of the space itself. reply eru 8 hours agorootparentLinear transformations preserve some structure, not &#x27;the&#x27; structure. reply abecedarius 15 hours agoparentpreviirc connections with linear algebra come up in Conway&#x27;s https:&#x2F;&#x2F;store.doverpublications.com&#x2F;0486485838.html (which I only skimmed). reply Jaxan 15 hours agorootparentThere is a whole field of “weighted automata” which combine linear algebra and automata theory. reply pishpash 15 hours agoparentprevThat usually means the representation is getting close to the truth. Good interfaces have intrinsic value, which many result-focused people do not appreciate. reply jepler 8 hours agoprevThis is neat!I was surprised then not surprised that the union & intersection REs it comes up with are not particularly concise. For example the two expressions \"y.+\" and \".+z\" have a very simple intersection: \"y.*z\" (equality verified by the page, assuming I haven&#x27;t typo&#x27;d anything). But the tool gives yz([^z][^z]*z|z)*|y[^z](zz*[^z]|[^z])*zz*instead. I think there are reasons it gives the answer it does, and giving a minimal (by RE length in characters or whatever) regular expression is probably a lot harder. reply ufo 7 hours agoparentI think one of the reasons is the \".+z\" gets bigger and uglier after you convert it to a deterministic automaton. reply posco 17 hours agoprevThe amazing page computes binary relations between pairs of regular expressions and shows a graphical representation of the DFA.It’s a really incredible demonstration of some highly non-trivial operations on regular expressions. reply vintermann 16 hours agoparentIt&#x27;s very cool, but also no wonder that it doesn&#x27;t support all those features of regexes which technically make them not regular expressions anymore. Though, I would have thought ^ and $ anchors shouldn&#x27;t be a problem? reply rntz 14 hours agorootparent^ and $ are a problem, although one with a workaround.The standard theory of regular expressions focuses entirely on regex matching, rather than searching. For matching, ^ and $ don&#x27;t really mean anything. In particular, regexp theory is defined in terms of the \"language of\" a regexp: the set of strings which match it. What&#x27;s the set of strings that \"^\" matches? Well, it&#x27;s the empty string, but only if it comes at the beginning of a line (or sometimes the beginning of the document). This beginning-of-line constraint doesn&#x27;t fit nicely into the \"a regexp is defined by its language&#x2F;set of strings\" theory, much the same way lookahead&#x2F;lookbehind assertions don&#x27;t quite fit the theory of regular expressions.The standard workaround is to augment your alphabet with special beginning&#x2F;end-of-line characters (or beginning&#x2F;end-of-document), and say that \"^\" matches the beginning-of-line character. reply teraflop 16 hours agorootparentprevThis page implements regex matching, not searching. So in effect, every pattern has an implicit ^ at the beginning and $ at the end. reply abareplace 1 hour agorootparentprevThe double quote (\") is also broken. If you use it in the regex, then no DFA is displayed. reply o11c 14 hours agorootparentprevA lack of `^` is equivalent to prepending `(.*)`, then trimming the match span to the end of that capture. And similarly for a lack of `$` (but suddenly I remember how nasty Python was before `.fullmatch` was added ...).More interesting is word boundaries:`\\b` is just `\\` though that should be bubbled up and usually only one side will actually produce a matchable regex.`A\\`. reply Sharlin 14 hours agorootparentprevAs ^ and $ are implicit, you can opt out of them simply by affixing `.*`. reply zeroimpl 7 hours agorootparentOnly when the ^ or $ were at the start&#x2F;end of your string is it simple. Eg: (a|b|^)(c|d|^)fooRewriting without ^ can require much longer regex. reply wizofaus 5 hours agorootparentIsn&#x27;t that just ((a|b)?(c|d)|c|d)?fooUnless you mean it as a search expression, in which case it&#x27;s more like ((.*a|.*b)(c|d)|c|d)?fooWhich I have to admit was a lot harder to figure out than I thought it would be (and may not even be right!) replylayer8 14 hours agoprevI wanted to see the intersection between syntactically valid URLs and email addresses, but just entering the URL regex (cf. below) already takes too long to process for the page.[\\-a-zA-Z0-9@:%._+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([\\-a-zA-Z0-9()@:%_+.~#?&&#x2F;&#x2F;=]*)(source: https:&#x2F;&#x2F;stackoverflow.com&#x2F;a&#x2F;3809435&#x2F;623763) reply d66 14 hours agoparentexpressions like (...){1,256} are very heavyweight and the scala JS code ends up timing out or crashing the browser.if you replace that with (...)+ then it seems to work (at least for me). smaller expressions like (...){1,6} should be fine. reply noduerme 13 hours agorootparentJust wondering, what is it about testing repetition [a-z]{1,256} with an upper bound that&#x27;s so heavy? Intuitively it feels like greedy testing [a-z]+ should actually be worse since it has to work back from the end of the input. reply rntz 13 hours agorootparentThis depends heavily on how repetition is implemented.With a backtracking-search implementation of regexes, bounded iteration is pretty easy.But the linked webpage appears to compile regexes to finite state machines (it shows you their finite-state-machine, for instance), and eg [a-z]{1,256} will have 256 states: 256 times the 1 state needed for [a-z]. If [a-z] were a complex regex, you could get a combinatorial explosion.This alone probably isn&#x27;t the issue? 256 is not a very large number. But I suspect there are follow-on algorithmic issues. This is just speculation, but I wouldn&#x27;t be surprised if that 256-state machine were computed by applying DFA minimization, an algorithm with worst-case exponential running time, to a more naively generated machine. reply d66 13 hours agorootparentyou&#x27;re right. inclusion&#x2F;intersection&#x2F;etc. aren&#x27;t actually computed via DFA but instead are computed directly on the regular expression representation itself. and large disjunctions (with 256 branches) are what is very heavy.(it&#x27;s possible to instead do these operations on DFAs but at the time i found it hard to get from an automata back to a reasonable-looking regular expression.) reply d66 13 hours agorootparentprevthe library uses a fairly simple data representation where x{m,n} is compiled using conjunction and disjunction. so x{1,4} ends up being represented as x|xx|xxx|xxxx.this simplifies the code for testing equality and inclusion, since logically x{n} is just xx... (n times) and x{m,n} is just x{m}|x{m+1}|...|x{n}.but when you have x{m,n} and n-m is large you can imagine what kind of problems that causes. reply yorwba 12 hours agorootparentSeems like it should at least be x(|x(|x(|x))) instead of x|xx|xxx|xxxx to avoid quadratic blow-up. reply d66 12 hours agorootparentyes, that is the actual construction: the disjunction data type only supports a lhs and rhs, so that is the only possible way to represent it.i wrote it the way i did for clarity in the comments. replypimlottc 13 hours agoprevSuggestion: turn off auto suggest in the regex input fields to make it more usable on mobile.https:&#x2F;&#x2F;stackoverflow.com&#x2F;questions&#x2F;35513968&#x2F;disable-autocor... reply rsstack 14 hours agoprevI used this concept once to write the validation logic for an \"IP RegEx filter\" setting. The goal was to let users configure an IP filter using RegEx (no, marketing people don&#x27;t get CIDRs, and they knew RegEx&#x27;s from Google Analytics). How could I define a valid RegEx for this? The intersection with the RegEx of \"all IPv4 addresses\" is not empty, and not equal to the RegEx of \"all IPv4 addresses\". Prevented many complaints about the filter not doing anything, but of course didn&#x27;t prevent wrong filters from being entered. reply Etheryte 14 hours agoparentWouldn&#x27;t a simpler solution work here? Instead of trying to validate the filter regex, show some sample IP addresses or let the user insert a set of addresses, and then show which ones the filter matches and which ones it doesn&#x27;t. Also helps address the problem of incorrect filters. reply rsstack 14 hours agorootparentThe odds of the sample addresses matching is essentially zero, and adding work to the user is counterproductive. reply Etheryte 14 hours agorootparentI&#x27;m not sure I agree — most common regex editing tools available online include a section for adding test strings to verify what you actually wrote is correct. Clearly there is a benefit to it. In similar vein, allowing the user to test before they commit and then test actually reduces their work load, they don&#x27;t have to drop and then reload the whole regex in their mind. reply rsstack 14 hours agorootparentSure, I use that when authoring and editing a RegEx. That&#x27;s not the same as entry validation. replyx-complexity 8 hours agoprevI used 2 similar divide-by-3 regexes to test the page (after removing the ^ and $ to their ends), and it froze up:Regex 1: ([0369]|([258]|[147][0369]*[147])([0369]|([147][0369]*[258]|[258][0369]*[147]))*([147]|[258][0369]*[258])|([147]|[258][0369]*[258])([0369]|([147][0369]*[258]|[258][0369]*[147]))*([258]|[147][0369]*[147]))*Regex 2: ([0369]|[258][0369]*[147]|(([147]|[258][0369]*[258])([0369]|[147][0369]*[258])*([258]|[147][0369]*[147])))*Everything up until the last &#x27;*&#x27; is parsable. The moment I put in the *, the entire page freezes up.Without the *, it produced a valid verifier for parsing chunks of digits whose sum mod 3 = 0. reply emmanueloga_ 10 hours agoprevOne possible application: If an input to a function parameter must match a certain regex, and the output of a function produces results matching another regex, we can know if the functions are compatible: if the intersection of regular expressions is empty, then you cannot connect one function to the other.Combined with the fact the regular expressions can be used not only on strings but more generally (e.g. for JSON schema validation [1]), this could be a possible implementation of static checks, similar to \"design by contract\".--1: https:&#x2F;&#x2F;www.balisage.net&#x2F;Proceedings&#x2F;vol23&#x2F;html&#x2F;Holstege01&#x2F;B... reply simlevesque 16 hours agoprevKinda related but I&#x27;m looking for something that could give me the number of possible matching strings for a simple regex. Does such a tool exist ? reply contravariant 16 hours agoparentI feel like it shouldn&#x27;t be too hard to calculate from the finite automaton that encodes the regular expression, but surely in most cases it will simply be infinite? reply tetha 14 hours agorootparentThis is hitting back a long time. But the algorithm - if I recall right - is a simple DFS on the determinstic automaton for the regular expression and it can output the full set of matching strings if you&#x27;re allowed to use *s in the output.Basically, you need an accumulator of \"stuff up to here\". If you move from a node to a second node, you add the character annotating that edge to the accumulator. And whenever you end up with an edge to a visited node, you add a &#x27;*&#x27; and output that, and for leaf nodes, you output the accumulator.And then you add a silly jumble of parenthesis on entry and output to make it right. This was kinda simple to figure out with stuff like (a(ab)*b)* and such.This is in O(states) for R and O(2^states) for NR if I recall right. reply kadoban 15 hours agorootparentprevMaybe the number of possible matchings for a given length (or range of lengths) might be interesting? reply danieldk 15 hours agorootparentSay you want to compute all strings of length 5 that the automaton can generate. Conceptually the nicest way is to create an automaton that matches any five characters and then compute the intersection between that automaton and the regex automaton. Then you can generate all the strings in the intersection automaton. Of course, IRL, you wouldn&#x27;t actually generate the intersection automaton (you can easily do this on the fly), but you get the idea.Automata are really a lost art in modern natural language processing. We used to do things like store a large vocabulary in an deterministic acyclic minimized automaton (nice and compact, so-called dictionary automaton). And then to find, say all words within Levenshtein distance 2 of hacker, create a Levenshtein automaton for hacker and then compute (on the fly) the intersection between the Levenshtein automaton and the dictionary automaton. The language of the automaton is then all words within the intersection automaton.I wrote a Java package a decade ago that implements some of this stuff:https:&#x2F;&#x2F;github.com&#x2F;danieldk&#x2F;dictomaton reply contravariant 15 hours agorootparent> deterministic acyclic minimized automatonThat&#x27;s basically a Trie right? To be fair I have only heard of them and know they can be used to do neat tricks, I&#x27;ve rarely used one myself. reply Someone 14 hours agorootparentIf you do not plan to update it often and don’t need to store extra data with each word, a dawg (https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Deterministic_acyclic_finite_s...) is more compact. You often can merge leaf nodes.For example, if you have words talk talked talking talks walk walked walking walksthere’s no need to repeat the “”, “ed”, “ing”, “s” parts. reply danieldk 14 hours agorootparentprevNo. In a minimized automaton shared string suffixes also share states&#x2F;transitions. reply abecedarius 15 hours agorootparentprevThat was one of the short examples in Norvig&#x27;s Python program-design course for Udacity. https:&#x2F;&#x2F;github.com&#x2F;darius&#x2F;cant&#x2F;blob&#x2F;master&#x2F;library&#x2F;regex-gen... (I don&#x27;t have the Python handy.) reply 082349872349872 13 hours agorootparentprevsee https:&#x2F;&#x2F;www.cs.dartmouth.edu&#x2F;~doug&#x2F;nfa.pdf reply mikhailfranco 3 hours agoparentprevAnother interesting question is: how many possible successful matches are there for a given input string. For example:How many ways can (a?){m}(a*){m} match the string a{m}i.e. input m repetitions of the letter &#x27;a&#x27;.https:&#x2F;&#x2F;github.com&#x2F;mike-french&#x2F;myrex#ambiguous-exampleThe answer is a dot product of two vectors sliced from Pascal&#x27;s Triangle.For m=9, there are 864,146 successful matches. reply d66 15 hours agoparentprevthe page actually does give these. for α := [a-z]{2,4} the page gives |α| = 475228.however, as others have pointed out any non-trivial use of the kleene star means the result will be ∞. in this case the page will list numbers that roughly correspond to \"number of strings with N applications of kleene star\" in addition to infinity. reply rntz 11 hours agoparentprevHere&#x27;s a simple Haskell program to do it:(EDIT: this code is completely wrongheaded and does not work; it assumes that when sequencing regexes, you can take the product of their sizes to find the overall size. This is just not true. See reply, below, for an example.) -- https:&#x2F;&#x2F;gist.github.com&#x2F;rntz&#x2F;03604e36888a8c6f08bb5e8c665ba9d0 import qualified Data.List as List data Regex = Class [Char] -- character classSeq [Regex] -- sequence, ABCChoice [Regex] -- choice, A|B|CStar Regex -- zero or more, A* deriving (Show) data Size = Finite IntInfinite deriving (Show, Eq) instance Num Size where abs = undefined; signum = undefined; negate = undefined -- unnecessary fromInteger = Finite . fromInteger Finite x + Finite y = Finite (x + y) _ + _ = Infinite Finite x * Finite y = Finite (x * y) x * y = if x == 0 || y == 0 then 0 else Infinite -- computes size & language (list of matching strings, if regex is finite) eval :: Regex -> (Size, [String]) eval (Class chars) = (Finite (length cset), [[c]csequence langs) where (sizes, langs) = unzip $ map eval regexes eval (Choice regexes) = (size, lang) where (sizes, langs) = unzip $ map eval regexes lang = concat langs size = if elem Infinite sizes then Infinite -- finite, so just count &#x27;em. inefficient but works. else Finite (length (List.nub lang)) eval (Star r) = (size, lang) where (rsize, rlang) = eval r sizersize == 0 = 1rsize == 1 && List.nub rlang == [\"\"] = 1otherwise = Infinite lang = [\"\"] ++ ((++)[xxlang) size :: Regex -> Size size = fst . evalNB. Besides the utter wrong-headedness of the `product` call, the generated string-sets may not be exhaustive for infinite languages, and the original version (I have since edited it) was wrong in several cases for Star (if the argument was nullable or empty). reply sebzim4500 10 hours agorootparentSurely that fails for e.g. a?a?a?. I&#x27;d imagine you could do some sort of simplification first though to avoid this redundancy. reply rntz 9 hours agorootparentYou&#x27;re correct, and I don&#x27;t see any good way to avoid this that doesn&#x27;t involve enumerating the actual language (at least when the language is finite).Oof, my hubris. reply someguy101010 13 hours agoparentprevmight be something like this https:&#x2F;&#x2F;jvns.ca&#x2F;blog&#x2F;2016&#x2F;04&#x2F;24&#x2F;how-regular-expressions-go-f... which refs https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Brzozowski_derivative reply Drup 15 hours agoparentprevhttps:&#x2F;&#x2F;regex-generate.github.io&#x2F;regenerate&#x2F; (I&#x27;m one of the authors) enumerates all the matching (and non-matching) strings, which incidentally answers the question, but doesn&#x27;t terminate in the infinite case. reply clord 15 hours agoparentprevI feel like it might be possible with dataflow analysis. Stepping through the regex maintaining a liveness set or something like that. Sort of like computing exemplar inputs, but with repetition as permitted exemplars. Honestly probably end up re-encoding the regex in some other format, perhaps with &#x27;optimizations applied.&#x27; reply stvltvs 15 hours agoparentprevThe answer is usually an infinite number, except for very, very simple cases. Anything involving * for example means infinity is your answer. reply skulk 15 hours agorootparentI wonder if it makes sense to compute an \"order type\" for a regexp. For example, a* is omega, a*b* is 2 omega.https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Order_typehttps:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Ordinal_number reply contravariant 15 hours agorootparentI think that&#x27;s just the ordinal corresponding to lexicographic order on the words in the language, so yeah that should work. I wonder how easy it is to calculate... reply d66 14 hours agorootparentnormally you would use an ordinal number [1] to label individual elements of an infinite set while using a cardinal number [2] to measure the size of the set.i believe the cardinality of a set of words from a finite alphabet (with more than one member) is equivalent to the cardinality of the real numbers. this means that the cardinality of .* is c.unfortunately, i don&#x27;t think that cardinality gets us very far when trying to differentiate the \"complexity\" of expressions like [ab]* from ([ab]*c[de]*)*[x-z]*. probably some other metric should be used (maybe something like kolmogorov complexity).[1] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Ordinal_number[2] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Cardinal_number reply contravariant 13 hours agorootparentI wouldn&#x27;t say that&#x27;s their &#x27;normal&#x27; usage, I mean sure you can use them like that but fundamentally ordinal numbers are equivalence classes of ordered sets in the same way that cardinal numbers are equivalence classes of sets.As you&#x27;ve rightly noted the latter equivalence class gets us nothing so throwing away the ordering is a bit of a waste. Of all mathematical concepts &#x27;size&#x27; is easily the most subjective so picking one that is interesting is better than trying to be &#x27;correct&#x27;.In particular a*b* is exactly equivalent to ω^2, since a^n b^m2 * omega.Some more examples:omega ^ 3: a*b*c*omega ^ 2 + omega: a*b*|c*Maybe we can write down some composition rules:let X and Y be regular languages and ord(X) and ord(Y) be their ordinal representations. Then,X|Y => ord(X) + ord(Y)XY => ord(X) * ord(Y)X* => ord(X) * omegaI haven&#x27;t checked if these actually work, this is just a long rambly comment of dubious mathematical value. replypimlottc 13 hours agoparentprevWhat’s your use case? reply less_less 13 hours agoprevInteresting. I think this problem is actually EXPSPACE-complete in general? But still has a straightforward algorithm.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;EXPSPACE reply DannyBee 9 hours agoparentIt depends on your operators. For these, no.Equivalence of DFA or NFA is PSPACE complete by savitch&#x27;s theorem, regardless of time bound. As such, most types of regex equivalence is pspace-complete.https:&#x2F;&#x2F;citeseerx.ist.psu.edu&#x2F;viewdoc&#x2F;summary?doi=10.1.1.89....Has a detailed breakdown of operators vs complexity.In particular, the paper cited in the expspace page is talking about allowing a squaring operator.It is EXPSPACE complete if you allow squaring, but not if you use repetition.IE it is expspace complete if you allow e^2, but not if you only allow ee. reply baggy_trough 16 hours agoprevI love how it looks like a CS textbook. reply perihelions 14 hours agoparentThe graphics look identical to those in Hopcroft & Ullman&#x27;s \"Introduction to Automata Theory, Languages, and Computation\" (like the convention that they use a double-circle to denote accepting states). I imagine they&#x27;re GraphViz-based: it&#x27;s very easy [0] to draw these in GraphViz. I don&#x27;t know what Hopcroft & Ullman used though, because that one was published in 1979, and GraphViz didn&#x27;t exist before 1991. Suddenly I&#x27;m curious what the state of the art for vector diagrams was in 1979...?[0] e.g. https:&#x2F;&#x2F;graphviz.org&#x2F;Gallery&#x2F;directed&#x2F;fsm.html reply therealcamino 11 hours agorootparentMaybe something related to &#x27;pic&#x27;? This doc on it is a revised version of a 1984 edition, so maybe it&#x27;s a little too late, but there are references to other systems back to 1977 or so.https:&#x2F;&#x2F;pikchr.org&#x2F;home&#x2F;uv&#x2F;pic.pdf reply cobbal 15 hours agoparentprevIt has the look of graphviz about it, which is an excellent tool. Often helpful in debugging anything related to graphs.https:&#x2F;&#x2F;graphviz.org&#x2F; reply blibble 14 hours agoprevit always bugged me as a student that had to sit through all those discrete maths lectures that standard regex libraries don&#x27;t allow you to union&#x2F;intersect two \"compiled\" regular expression objects together(having to try them one an a time is pretty sad) reply snoble 16 hours agoprevOh neat, this is scala via scalajs. reply hoten 14 hours agoprevOn mobile: are the rectangle glyphs as suffixes on the states on purpose or am I missing a font? reply progbits 14 hours agoparentThe states are numbered, $\\alpha_0, ..., \\alpha_N$ and $\\beta_0, ...$. You might be missing the font for the digits. reply bjt12345 9 hours agoprev. reply _a_a_a_ 12 hours agoprevAny def for &#x27;difference and intersection of regexes&#x27; might actually mean?I guess for regexes r1 and r2 this means the diff and intersect of their extensional sets, expressed intensionally as a regex. I guess. But nothing seems defined, including what ^ is, or > or whatever. It&#x27;s not helpful reply d66 12 hours agoparentnext [–]negation (~α): strings not matched by α difference (α - β): strings matched by α but not β intersection (α & β): strings matched by α and β exclusive-or (α ^ β): strings matched by α or β but not both inclusion (α > β): does α matches all strings β matches? equality (α = β): do α and β match exactly the same strings? reply themusicgod1 12 hours agoprevugh STOP USING GITHUB reply haltist 13 hours agoprev [–] Can LLMs do this? reply vore 13 hours agoparent [–] I wouldn&#x27;t use an LLM for anything that can be done 100% precisely, like this. reply haltist 12 hours agorootparent [–] OK, just curious how LLMs are stacking up in logical tasks like this. I kept hearing we were close to AGI so just wondering how far there is to go. reply clbrmbr 10 hours agorootparentHumans can do these intersections, but we don’t do it by riffing off the top of our heads. We carefully develop and apply a formal system. LLMs are just (a very important) component. reply Izkata 6 hours agorootparentprev [–] We&#x27;ve been \"close\" to AGI for like 40+ years. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The given regular expressions contain features like concatenation, alternation, and kleene star, but lack advanced features like anchors, zero-width assertions, back references.",
      "For additional information on these expressions, the summary recommends exploring a specific website."
    ],
    "commentSummary": [
      "The article delves into multiple tech topics such as string class hierarchies, Haskell's tagged union types, and the role of linear algebra in practical applications.",
      "It explores the challenges and complexities linked to the use of regular expressions, including the configuration of an Internet Protocol (IP) filter via RegEx.",
      "It touches on logical tasks implementation using Low-Level Managers (LLMs) and discusses the concept of attaining Artificial General Intelligence (AGI)."
    ],
    "points": 319,
    "commentCount": 104,
    "retryCount": 0,
    "time": 1694452206
  },
  {
    "id": 37470611,
    "title": "Real-Time 3D Gaussian Splatting in WebGL",
    "originLink": "https://antimatter15.com/splat/",
    "originBody": "WebGL 3D Gaussian Splat Viewer By Kevin Kwok. Code on Github. Use mouse or arrow keys to navigate. 22 fps",
    "commentLink": "https://news.ycombinator.com/item?id=37470611",
    "commentBody": "Real-Time 3D Gaussian Splatting in WebGLHacker NewspastloginReal-Time 3D Gaussian Splatting in WebGL (antimatter15.com) 281 points by antimatter15 16 hours ago| hidepastfavorite56 comments naavis 13 hours agoThis is really cool! The control scheme is confusing though. Instead of the typical WASD for moving and using the mouse to look around, dragging the mouse moves forwards and backwards and orbits around some point, A and D strafe, while W and S look up and down.EDIT: Looks like a full list of controls is in the readme: https:&#x2F;&#x2F;github.com&#x2F;antimatter15&#x2F;splat#controls reply antimatter15 10 hours agoparentAuthor here- I&#x27;m sorry about the camera controls! Happy to accept pull requests that replace it with something more sensibleThe original idea was to be able to navigate around with just arrow keys (conceptually by turning yourself around in place and being able to walk back and forward). reply crubier 8 hours agorootparentThis is insanely cool!If you integrate this with ThreeJS you&#x27;d have a lot of control options for free!Whilst you&#x27;re here, I have a question for you: It seems like you don&#x27;t render read gaussians (I see sharp edges in many cases). Is this a bug on my side or is this an optimization made to be able to run fast? I created an issue to discuss if you prefer https:&#x2F;&#x2F;github.com&#x2F;antimatter15&#x2F;splat&#x2F;issues&#x2F;2 reply alanbernstein 12 hours agoparentprevIt&#x27;s very similar to the N64 FPS controls (i.e. Goldeneye): arrow keys (joystick) for the \"primary movements\" of forward&#x2F;backward and yaw, with which you can move and look anywhere in a 2D space. Then, WASD (C buttons) for the \"secondary movements\" of strafe and pitch. reply gorkish 11 hours agorootparentIt&#x27;s pretty telling that you had to reach back 26 years to find a control scheme that could be used as an analogy. I don&#x27;t even know where to start with the mouse controls. Up&#x2F;down translation lock after right click; reverse yaw. Thing is a test of patience! reply moffkalast 1 hour agorootparentIt actually seems like the FreeCAD control scheme almost verbatim, I always hated that thing and its insistence to not provide any way to orbit around the up vector.Like, are there people whose head does not rotate around their neck on axis but ends up sideways and rolled when they turn or something, to whom this makes perfect sense? I can&#x27;t see any other explanation. reply wingerlang 6 hours agoparentprevFWIW, OP, I liked the control scheme a lot (using mouse only). reply gorkish 11 hours agoparentprevBeing brutally honest here, but I just cant get over the control scheme enough to even appreciate the rendering demo. It is unusably unintuitive and awful. reply Lichtso 13 hours agoprevReally cool, I am also working on a port of gaussian-splatting [0] but to WebGPU.Like all the other implementations I have seen so far, this also makes the same mistake when projecting the ellipsoids in a perspective: First you calculate the covariance in 3D and then project that to 2D [1]. This approach only works with parallel &#x2F; orthographic projections and applying it to perspectives leads to incorrect results. That is because perspective projections have three additional effects:- Parallax movements (that is the view plane moves parallel to the ellipsoids) change the shape of the projected ellipse. E.g. a sphere only appears circular when in center of the view, once it moves to the edges it becomes stretched into an ellipse. This effect is manually counter balanced by this matrix I believe [2].- Rotating an ellipse can change the position it appears at, or in other words creates additional translation. This effect is zero if the ellipse has one of its three axes pointing straight at the view (parallel to the normal of the view plane). But, if it is rotated 45°, then the tip of the ellipse that is closer to the view plane becomes larger through the perspective while the other end becomes smaller. Put together, this slightly shifts the center of the appearance away from the projected center of the ellipsoid.- Conic sections can not only result in ellipses but also parabola and hyperbola. This however is an edge case that only happens when the ellipsoid intersects with the view plane and can probably be ignored as one would clip away such ellipsoids anyway.The last two effects are not accounted for in these calculations in any of the implementations I have seen so far. What would be correct to do instead? Do not calculate the 3D covariance. Instead calculate the bounding cone around the ellipsoid which has its vertex at the camera position (perspective origin). Then intersect that with the view plane and the resulting conic section is guaranteed to be the correct contour of the perspective projection of the ellipsoid.[0]: https:&#x2F;&#x2F;github.com&#x2F;graphdeco-inria&#x2F;gaussian-splatting [1]: https:&#x2F;&#x2F;github.com&#x2F;antimatter15&#x2F;splat&#x2F;blob&#x2F;3695c57e8828fedc2... [2]: https:&#x2F;&#x2F;github.com&#x2F;antimatter15&#x2F;splat&#x2F;blob&#x2F;3695c57e8828fedc2... reply porphyra 13 hours agoparentIn general, a Gaussian is no longer a true Gaussian after camera projection since the pinhole camera projection function is nonlinear (due to dividing by z). However, if the Gaussian is small relative to the size of the image, you can apporximate it by linearizing the projection function. Therefore the Gaussian splatting paper uses the Jacobian of the projection function as described in equation 5 of the paper [0]. In practice, this approximation is extremely good. This Jacobian is the matrix you mentioned in the third link and it is mathematically sound and not \"manually counter balanced\". For a derivation, see [1].[0] https:&#x2F;&#x2F;repo-sam.inria.fr&#x2F;fungraph&#x2F;3d-gaussian-splatting&#x2F;3d_...[1] https:&#x2F;&#x2F;math.stackexchange.com&#x2F;a&#x2F;4716514&#x2F;43771 reply Lichtso 13 hours agorootparentI read the paper and I am aware that the gaussian projection is an approximation anyway (hence I spoke about ellipsoids, not gaussians). Still, one could at least aim to get the iso contour right and yes using the Jacobian matrix is not unsound, just incomplete. As I said, this approach can not produce the distinctive \"wiggle\" that you get from rotating an ellipsoid while staring dead center at it. reply porphyra 12 hours agorootparentTrue, it is an approximation after all. But it is a useful approximation since the main advantage of Gaussian splatting is the speed. reply contravariant 13 hours agoparentprevYeah I think you&#x27;re right, they&#x27;re pretending the projection is a linear transformation (in cartesian coordinates) and using it to transform the Gaussian.Or viewed alternatively they&#x27;re approximating the projection by assuming all of the Gaussian is at a fixed depth, which I suppose works if it is far enough away.A projective transformation of a Gaussian seems somewhat annoying, though I assume someone will have done it before. Seems like it should be possible to do it with projective coordinates but the final projection to cartesian coordinates is tricky.For what it&#x27;s worth, projecting a contour is also wrong, the whole density changes which also affects the contours. reply jimmySixDOF 3 hours agoparentprevIf you can implement the intersecting bounding cone idea without impacting frame rates that&#x27;s going to be even smoother on WebGPU but it would be interesting to see the difference apples to apples with this type of implementation. reply ImHereToVote 3 hours agoparentprevHi. I&#x27;m not very familiar with the gaussian splat technique but aren&#x27;t they essentially quads with some intrinsic data in the vertices. I thought projecting quads was already a solved problem. Could you elaborate how this differs from a simple array of quads? Thank you. reply m1sta_ 13 hours agoparentprevDynamic? I&#x27;ve. video? reply bluescrn 14 hours agoprevWhen you zoom out there&#x27;s lots of visible polygon edges that don&#x27;t look like they should really be there, as if it&#x27;s trying to draw soft &#x27;blobs&#x27; but the texture coords aren&#x27;t quite right? Is that a bug or an intentional part of the technique? reply KaiserPro 14 hours agoparentIntentional.Basically its a semidense point cloud [1], but instead of a point, there is a blob which has been coloured, angled and scaled to match the input picture. This means they are optimised to be viewed from a certain distance.Think of it like a 3d vector drawing, if you zoom in too much, or pull one part away, it all starts to look a bit funky.[1]https:&#x2F;&#x2F;www.researchgate.net&#x2F;publication&#x2F;326621750&#x2F;figure&#x2F;fi... reply gsuuon 10 hours agoprevWould this technique work for video? The readme of the inria work[1] seems to imply a model is trained per static scene, does that rule out video?[1] https:&#x2F;&#x2F;github.com&#x2F;graphdeco-inria&#x2F;gaussian-splatting reply stefanbaumann 10 hours agoparentIt&#x27;s already a thing [1]. They also have a project website [2] with some nice videos, although the code hasn&#x27;t yet been released.[1] https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2308.09713[2] https:&#x2F;&#x2F;dynamic3dgaussians.github.io&#x2F; reply evrimoztamur 2 hours agorootparentThe recording from the point of view of the football they were tossing at each other made me feel things. My friend mentioned that it&#x27;s like the &#x27;braindance&#x27; from Cyberpunk 2077. reply jheriko 13 minutes agoprevwhy the hell is it that anyone who makes these \"clever\" demos provides the world&#x27;s shittiest camera that adds unwelcome rolls.late 90s bedroom me is shaking his head. reply deepangn 13 minutes agoparenttest me reply deepangn 13 minutes agorootparent&#x27;\"> reply andrewstuart 14 hours agoprevWhat am I looking at? reply KaiserPro 14 hours agoparentGaussian splatting is a fancy word for pointcloud but with coloured shapes instead of points.Its been around for ages, but It was never used because if you have a million points in a point cloud, you&#x27;d need to artistically manipulate a million points.Its like 3d hair, its pretty simple, just render a billion hairs, but in practice its hard to make it look good.Here we tell a machine learning model to adjust the angle, colour, shape and size of a million primitives (ie a square, circle, triangle etc.) so that it looks like a the photos we provide. reply Geee 14 hours agorootparentIt&#x27;s a little bit more than that. Gaussians are view-dependent, which means that they can capture the full radiance field of the scene, rather than just the color and geometry of the objects. All the light bouncing around from different objects can be reproduced, including reflections etc.See the reflections here: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=mD0oBE9LJTQThis is also pretty good, but more subtle: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=tJTbEoxxj0U reply ath92 4 hours agorootparentThis implementation does not support view-dependence though (mentioned in the readme) reply KaiserPro 13 hours agorootparentprev> Gaussians are view-dependent,indeed, but that&#x27;s just adding view dependent points. reply dclowd9901 12 hours agorootparentprevMy initial understanding is these scenes can’t be made dynamic (animated, physically responsive). Is that correct? reply bestest 14 hours agoparentprevbasically this: https:&#x2F;&#x2F;github.com&#x2F;graphdeco-inria&#x2F;gaussian-splatting — a somewhat different approach at rendering 3d scenes. reply underlipton 14 hours agorootparentA thought occurred to me: is this similar to how Media Molecule&#x27;s Dreams on the PS4&#x2F;5 renders its scenes? reply FinalDestiny 14 hours agorootparent> Media Molecule “Dreams” has a splat-based renderer (I think the shipped version is not purely splat-based but a combination of several techniques).From: https:&#x2F;&#x2F;aras-p.info&#x2F;blog&#x2F;2023&#x2F;09&#x2F;05&#x2F;Gaussian-Splatting-is-pr...Good eye reply pixelpoet 5 hours agorootparentAlso maybe worth mentioning that the 2nd author of the InstantNGP paper is also a cofounder of and lead tech guy at Media Molecule, Alex Evans. I&#x27;ve been a huge fan of his work since 90s demoscene and briefly got to work with him at Lionhead Studios, guy&#x27;s a legit genius. reply bluescrn 14 hours agorootparentprevInteresting video here (from 2015) on the development of the Dreams rendering tech: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=u9KNtnCZDMI replylwansbrough 13 hours agoprevDoes this use the method proposed by Kerbl and Kopanas at SIGGRAPH 2023?https:&#x2F;&#x2F;repo-sam.inria.fr&#x2F;fungraph&#x2F;3d-gaussian-splatting&#x2F; reply porphyra 13 hours agoparentYes, but this is just the splatting&#x2F;rendering part and not the optimization part that generates the reconstruction in the first place. reply crubier 8 hours agoprevWow this is insanely cool.If you make it work within ThreeJS, you&#x27;re going to leave a trace in the history of 3D on the web with that stuff! reply gabereiser 13 hours agoprevThis is beyond cool. Point clouds are one thing but this… this is amazing. Kudos and great job. It even runs on my work Lenovo at 60fps. reply esperent 6 hours agoparentIt runs on my mid range phone at 36fps. Did not expect that.Lots of artefacts though, especially if I move the camera. reply gabereiser 6 hours agorootparentthose artifacts are part of the algorithm. reply cchance 8 hours agoprevGotta try on a pc for some reason on iOS the cloudiness feels more like nerf than Gaussian to me for some reason, gotta try it on pc later reply matt3210 9 hours agoprevFancy! I like that on mobile I can drag to move around! reply adfm 13 hours agoprevVery impressive! Curious what the frame rate would be like for stereoscopic rendering of the same scene on the same hardware. Are there optimizations to be had past the halfway mark? reply Yenrabbit 5 hours agoparentDefinitely. One of the time-consuming parts of rendering is sorting the gaussians by distance to the camera, which for two nearby cameras could be optimized. This also goes for adjacent frames - assuming smooth motion im pretty sure there is some speedup to be had by assuming the previous sort will be close to correct rather than starting from scratch each frame. reply tmilard 10 hours agoprevGaussian Spatting is the new sensation of the sumer in the 3D Scanning Field. Will it live to its expectation ? reply smusamashah 12 hours agoprevIs it possible to increase the number of points (resolution) with some setting? I want to see more refined view on a higher end machine. reply teucris 10 hours agoprevWow. I was literally just working on my own implementation. You beat me to it! Great work! reply jansan 14 hours agoprevSo far I have only seen gaussian splatting used on photographic data. Would it make sens to use it for other graphics data, too. Or in other words, does it have potential to be used in games? reply Lichtso 13 hours agoparentDepends, radiance field approaches (like gaussian splatting) are basically 3D photos. They do only capture color at geometry (position and direction), but have no concept of surfaces, materials and light transport in general (emission, absorption, transmission, reflection, scattering, etc.). In other words, they can only do static scenes (no animations) with pre-baked lighting.The industry seems to be trying to move away from this with things like PBR (physical based rendering) and ray &#x2F; path tracing which enables far better dynamic lighting.Also, they are extremely space inefficient at the moment. A scene that would take a good traditional rendering engine a few dozen GB would take TB instead. Though, that might improve in the future with more optimization.One exception to the above, where gaussian splatting might be interesting to see is procedural &#x2F; generated content (possibly even animated). Especially for volumetric effects which currently use particle systems, like smoke, fire, clouds, flowing water, etc. reply poslathian 1 hour agorootparentI thought I understood that the speculator highlights and view dependent color problems you mention are massively improved via adding spherical harmonics into each ellipse? reply Solvency 14 hours agoparentprevSure, why not? It&#x27;s just a fancy point cloud. I can easily imagine an open world Minecraft-esque game that uses this for its base engine instead of voxels. reply crtasm 14 hours agoprevClick through to the github for a list of the controls (I didn&#x27;t think to try spacebar!) and links to other example scenes. reply q_andrew 8 hours agoprevCan&#x27;t wait to pull this up on my desktop tomorrow. reply msk-lywenn 12 hours agoprevRuns fine on my 2016 iPhone SE. kudos reply agys 12 hours agoprev [–] Last sentence of the readme…! replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The text discusses a 3D viewer which uses WebGL for interface rendering. This viewer supports navigation through mouse or arrow keys.",
      "It operates at 22 frames per second (fps), implying smooth performance and real-time user interaction.",
      "The source code for this 3D viewer has been made available by Kevin Kwok on Github, a platform where developers upload and share their software projects."
    ],
    "commentSummary": [
      "The article introduces a WebGL-based real-time 3D Gaussian splatting technique, covering challenges related to control scheme, rendering sharp edges, and ellipsoid projection.",
      "Gaussian splatting is a rendering technique using colored shapes, optimized for specific viewing distances. It's beneficial for procedural or generated content, but limited for dynamic scenes.",
      "The discourse involves the potential benefits of incorporating spherical harmonics, commonly used in systems like smoke, fire, clouds, and flowing water, into this rendering technique."
    ],
    "points": 280,
    "commentCount": 54,
    "retryCount": 0,
    "time": 1694453510
  },
  {
    "id": 37465086,
    "title": "The SHA256 for this sentence begins with: one, eight, two, a, seven, c and nine.",
    "originLink": "https://twitter.com/lauriewired/status/1700982575291142594",
    "originBody": "The SHA256 for this sentence begins with: one, eight, two, a, seven, c and nine.— LaurieWired (@lauriewired) September 10, 2023",
    "commentLink": "https://news.ycombinator.com/item?id=37465086",
    "commentBody": "The SHA256 for this sentence begins with: one, eight, two, a, seven, c and nine.Hacker NewspastloginThe SHA256 for this sentence begins with: one, eight, two, a, seven, c and nine. (twitter.com/lauriewired) 266 points by isp 1 day ago| hidepastfavorite128 comments oefrha 18 hours agoSince I&#x27;m slacking off, here&#x27;s a straightforward, not at all optimized Go implementation: package main import ( \"bytes\" \"crypto&#x2F;sha256\" \"encoding&#x2F;hex\" \"fmt\" ) var ( _chars = []byte(\"0123456789abcdef\") _names = []string{\"zero\", \"one\", \"two\", \"three\", \"four\", \"five\", \"six\", \"seven\", \"eight\", \"nine\", \"a\", \"b\", \"c\", \"d\", \"e\", \"f\"} _size = len(_chars) ) func main() { hexsum := make([]byte, 64) for i1 := 0; i1 16 cores, wrap the second level to spawn 256 goroutines. Very little code change, big speedup. reply awegio 12 hours agoparentprev> There&#x27;s exactly one hitThere are N possible sequences, and you try N times with a success probability of 1&#x2F;N each (because it is a good hash function). This means the expected number of hits is 1. reply thehappypm 10 hours agorootparentThe probability is 1&#x2F;e reply Dylan16807 4 hours agorootparentThe probability of missing is 1&#x2F;e reply dvh 15 hours agoparentprevYou can increase the odds by adding various suffixes, e.g \"what are the odds\" or \"imagine that\" or \"can you beat that\" or \"can you do better\" .... reply drexlspivey 15 hours agorootparentWhy would that increase the odds? It’s the same chance on every iteration reply jrm4 14 hours agorootparentI think they mean \"increase your possible search space?\" reply krackers 15 hours agorootparentprevyou effectively have multiple chances to try to get a given target hash (prefix) reply mike_hock 14 hours agorootparentTrying different prefixes doesn&#x27;t take less time than trying different sequences. Unless you&#x27;re hellbent on finding a match for a particular sequence.I&#x27;d settle on a fixed prefix instead and try longer sequences to make it look more impressive. reply recursive 13 hours agorootparentEvery time you lengthen the sequence you increase the \"luck\" requirement. replyskykooler 9 hours agoparentprevWhat is the reply? Following the link leads to the tweet with no context. reply tantalor 9 hours agorootparent> Was just verifying your tweet&#x27;s hash, and then...omg!!! I couldn&#x27;t believe what I realised. The SHA256 of THIS tweet starts with exactly the same 7 characters as your tweet&#x27;s hash. What are the chances of that? reply jeremyloy_wt 10 hours agoparentprevhttps:&#x2F;&#x2F;go.dev&#x2F;play&#x2F;p&#x2F;6Lg9L2up5mIHere is a slightly different version I wrote that has 0 allocations per loop.Took about 26 seconds.I&#x27;m welcome to suggestions on how to make it more readable! Its been a few years since I have written Go professionally reply H8crilA 15 hours agoparentprevThis means there&#x27;s quite a lot of solutions. Running the entire 2^56 would take over 770 core-days if one core can achieve an impossible 1 giga-iterations per second. reply yuliyp 14 hours agorootparentIt&#x27;s 2^28, not 2^56. A hex digit is 4 bits, and we have 7 such digits to match. reply H8crilA 14 hours agorootparentUgh, you are right. That was a bit embarrassing :) reply lun4r 17 hours agoparentprevnot that difficult either. i wrote a script in 10 minutes and had a result in under a minute: https:&#x2F;&#x2F;twitter.com&#x2F;schuilr&#x2F;status&#x2F;1701268438931460311 reply rawling 23 hours agoprev> Was just verifying your tweet&#x27;s hash, and then...omg!!! I couldn&#x27;t believe what I realised. The SHA256 of THIS tweet starts with exactly the same 7 characters as your tweet&#x27;s hash. What are the chances of that?As always, the real WTF is in the comments. reply johndough 17 hours agoparentIt&#x27;s not too difficult. All you need is to generate many variations of potential words and check whether the sha256 hash matches the wanted leading characters. For example, check this text. reply isp 16 hours agorootparentnext [–]$ echo -n $&#x27;It\\&#x27;s not too difficult. All you need is to generate many variations of potential words and check whether the sha256 hash matches the wanted leading characters. For example, check this text.&#x27;sha256sum 182a7c9d2e99162688aaaf3f97638edd7d06f8d295e456c7bb1f16abf3a8f70c - reply wppick 13 hours agorootparentIsn&#x27;t this kind of the same thing that crypto miners do? reply acchow 13 hours agorootparentYes except Bitcoin does double SHA (a second round of SHA on the first result) reply CobrastanJorji 11 hours agorootparentprevWell played.More seriously, is there a really good, open source library that generates many slight variations of an input block of text? reply TylerE 10 hours agorootparentLlama? reply stainablesteel 14 hours agorootparentprevcan we get this guy to pass a captcha? i&#x27;ve got questions reply isp 23 hours agoparentprevnext [–]$ echo -n $&#x27;Was just verifying your tweet\\&#x27;s hash, and then...omg!!! I couldn\\&#x27;t believe what I realised. The SHA256 of THIS tweet starts with exactly the same 7 characters as your tweet\\&#x27;s hash. What are the chances of that?&#x27;sha256sum 182a7c9c08b2f0f9333bf23828c5fbf47addf74e815b6a22ca10825450bc2ee1 -Checks out(!)Source: https:&#x2F;&#x2F;twitter.com&#x2F;benoconnor&#x2F;status&#x2F;1701057433131421935 reply rawling 23 hours agorootparentI&#x27;m confused as to how they&#x27;ve done this. The original message, sure, you can brute force the digits and hope you get a collision, and try a new, plausible preamble if not. But I don&#x27;t see how they&#x27;ve found this collision without it looking like anything is brute forced.Is it using substitute Unicode characters or something?E: no, just hand typed it and got the same... reply devit 18 hours agorootparentPresumably generated lots of variations of that sentence. It&#x27;s 28 bits, so you only need to have around 14 places where 4 variations are possible.For instance, it could start with \"Was\", \"I was\", \"verifying\" could be \"checking\" or \"computing\" or \"testing\", etc.A bit tight, but it seems feasible with some work. reply aib 14 hours agorootparentIndeed, this is how I did it. 2^28 is around 270 million. With little more than a handful options, it should be possible. Although I have to say, it turned out to be more difficult than I&#x27;d initially thought. Maybe it&#x27;s better to think of it as 28 different boolean choices. echo -n \"Indeed. This is how I managed to do it. 2^28 is around 300 million. With only a handful options, it&#x27;s possible. Although, I must say that it turned out to be more difficult than I&#x27;d initially thought. Perhaps it&#x27;s better to think of it as 28 different alternatives.\"sha256sum reply Alextigtig 9 hours agorootparentThis is crazy! The hash of this comment once again begins 182a7c9!!! Well done indeed! reply fbdab103 18 hours agorootparentprevThrowing a loop of numbers on the end seems far more feasible. I put together a hasty Python implementation which can immediately find three hits at 5 characters. TQDM is reporting ~450k tries per second, so depending on how lucky you are, would probably want to redo in a faster language to solve for 7+ import hashlib import itertools import tqdm BLOCKS_SIZE = 5 sentence_prefix = \"The SHA256 for this sentence begins with:\" itos = {0x00:\"zero\", 0x01:\"one\", 0x02:\"two\", 0x03:\"three\", 0x04:\"four\", 0x05:\"five\", 0x06:\"six\", 0x07:\"seven\", 0x08:\"eight\", 0x09:\"nine\", 0x0a:\"a\", 0x0b:\"b\", 0x0c:\"c\", 0x0d:\"d\", 0x0e:\"e\", 0x0f:\"f\"} for nums in tqdm.tqdm(itertools.product(itos.keys(), repeat=BLOCKS_SIZE)): sentence = f\"{sentence_prefix} {&#x27;, &#x27;.join(itos[num] for num in nums[:-1])}, and {itos[nums[-1]]}.\" hash_true = hashlib.sha256(bytes(sentence, \"utf8\")).hexdigest() guessed_prefix = \"\".join(f\"{n:x}\" for n in nums) true_prefix = hash_true[:BLOCKS_SIZE] if guessed_prefix == true_prefix: print(\"collision\") print(sentence) print(hash_true) reply hinkley 17 hours agorootparentprevAll we are demonstrating here is why Sha256 is 256 bits and not 32 bits. We have trivially identified collisions for the first 28 bits of the output, which is only 11% of the entire hash size.Difficulty of collisions roughly doubles for each additional bit. Imagine we had a SHA32, that would be 16 times harder to achieve a collision. SHA256 is 43 with 67 zeroes behind it more difficult than the examples here. reply rawling 17 hours agorootparentYeah, I forgot how many bits were in a hex digit and made it seem much harder than it really was to myself. reply hughesjj 3 hours agorootparentI also mess up base16 and either base 256 or base64 when doing Feynman estimates reply noctune 19 hours agorootparentprev7 digits of the hash makes for 16*7 possible hashes. I spot 4 potential \"filler\" lines in that tweet, so if you find log4(16*7)=14 candidates for each of those filler lines, then one combination would be expected to yield that hash. reply petercooper 18 hours agorootparentprevI just did an extremely lazy version of that and posted a reply of \"And the SHA-1 digest (in hex) of this tweet starts BEEF\" - https:&#x2F;&#x2F;twitter.com&#x2F;cooperx86&#x2F;status&#x2F;1701261047917633846Basically I had several substitutions around words, case, punctuation, etc. and just ran it until it found some hits. Quite easy with just four characters though but was only a proof of concept. reply nstbayless 14 hours agorootparentprevIt&#x27;s possible that the tweets were actually produced together somehow. This might buy just enough search space between the two of them. reply kazinator 19 hours agorootparentprevYou can generate sentences of the form \"This sentence begins with: \" followed by seven comma-separated english words denoting hex digits. Then search that space of digits, until you get a hit.For each digit combination, you can try it with multiple variations of the sentence like \"The SHA256 of this sentence begins with\", \"The SHA256 hash of this text starts with\" and many more. That increases the search space without increasing the number of digits that have to match, making it more likely that a hit is found. reply JamesSwift 17 hours agorootparentprevI think this is a really good usecase for chatGPT to generate a massive number of variations that you then feed into a validation function reply mcmoor 3 hours agoparentprevWhat&#x27;s the difference between \"this sentence\" and \"this tweet\" in this context? reply kazinator 19 hours agoparentprevWhat are the chances of that? From the perspective of one specific sentence: one in 7 digits of hex: 16 * 7 = 268,435,456. reply archgoon 16 hours agorootparentIf we don&#x27;t vary the sentence (\"begins with, starts with, is prefixed with\" etc...) and only consider the final part, then the number of english sentences is (unsurprisingly) equal to the number of possible hashes.So for each distinct sentence, we pick randomly from the n different hashes, and we attempt to brute force this n times. So the probability of not getting this is:(1-1&#x2F;n)^nAs n increases, this will yield e^-1, so we have about a 36.7% chance of this not happening for any given length. So this has a probability of happening of 63.3%.So there is a decent chance that there exists a sentence \"The sha256 of this sentence is ...\" for even the full sha256. If you are allowed to modify the sentence to be something like \"&#x27;Begins with&#x27;, &#x27;starts with&#x27;, &#x27;OMG guys, check this out&#x27;:\" you can get this up to almost 1. Finding it would be mildly hard though barring some novel discovery about sha256. reply krackers 14 hours agorootparentFyi your comment was dead on arrival, and seems many of your past ones are as well. I&#x27;d email dang and ask if you&#x27;ve tripped some spam filter. reply gtrubetskoy 18 hours agoprevThe original from July 2019 https:&#x2F;&#x2F;twitter.com&#x2F;humblehack&#x2F;status&#x2F;1088982929940848647$ echo -n &#x27;The SHA256 for this sentence begins with seven, seven, f, zero, a, b, b and five.&#x27;sha256sum 77f0abb54cd09ad7b654bd5e762d7be58e7daffd1a0da6a56f5135bd667856a3 - reply therein 14 hours agoparentWe have come full circle.I saw this on HN years ago from the original that linked here. 2-3 days ago posted on 4chan&#x27;s &#x2F;g&#x2F; board that I remembered this sentence but didn&#x27;t remember its source and the hash it contained.Someone on &#x2F;g&#x2F; found the post on HN and a large thread ensued that expired and auto-deleted 12 hours ago or so. And then this person posted it on Twitter and it got shared here.Actually fascinating. reply kurisufag 13 hours agorootparentfor the interested.https:&#x2F;&#x2F;desuarchive.org&#x2F;g&#x2F;thread&#x2F;95910112 reply input_sh 14 hours agorootparentprevSo, a Twitter Blue user contributing nothing original and not giving credit to the source? I&#x27;m shocked I tell you, shocked! reply janalsncm 10 hours agorootparentReposts do add value though. Think of it this way: there’s a pool of content you haven’t seen before and a subset of it which you’d enjoy seeing. If no one reposts anything ever, you won’t be able to see any of it.In fact, some of the things you have seen before you would probably not mind seeing again. Maybe you didn’t think to save it at the time or maybe your circumstances have changed.Anyways, I wouldn’t confuse low effort with low value. reply downvotetruth 13 hours agorootparentprevHides the source from other pirates by using X. reply nneonneo 11 hours agoprevWell, I got bored too, so here&#x27;s some results with CUDA (on an RTX 3090): The SHA256 hash of this message begins with 534d765 The SHA256 hash of this message begins with c18b2de The SHA256 hash of this message begins with 7fe17da2 The SHA256 hash of this message begins with a7fdc855d The SHA256 hash of this message begins with 46eae34f1My unoptimized implementation takes about 40s for 9 digits, so it will probably take about 10 minutes for 10 digits, about 3 hours for 11 digits, etc. It shouldn&#x27;t be hard to use words instead of hex digits, if that&#x27;s desired. reply nneonneo 9 hours agoparentWords aren&#x27;t so bad :)\"The SHA256 hash of this message begins with f, b, six, two, zero, b, one, six and e.\"\"The SHA256 hash of this message begins with f, zero, two, d, four, seven, one, zero, nine and b.\" reply Someone 23 hours agoprevThat’s 28 bits. Loop through 256 million of these strings, and you’re bound to find a hit.Bitcoin difficulty is at around 50 bits (https:&#x2F;&#x2F;ycharts.com&#x2F;indicators&#x2F;bitcoin_average_difficulty#:~....)It also uses SHA256.So, if my logic is right (is it? That seems awfully cheap to me), this is about 2^22 times as easy as mining a bitcoin. Bitcoin is at about $25k, so there are people who can find hits like this one for way less than a cent. reply tromp 18 hours agoparent> Bitcoin difficulty is at around 50 bitsThe minimum bitcoin difficulty of 1 corresponds to 2^32 double SHA256, so finding a block at difficulty 2^50 takes an insane 2^83 hashes... reply n2d4 10 hours agoparentprevBitcoin difficulty is not measured in bits but its own unit (some hashrate was defined as difficulty 1, and difficulty 10 means the hash rate is 10x that). The number you see on that website is also in trillions, so the current difficulty is about 50 trillion. Also, you get more than one Bitcoin per hash (currently 6.25, halving every few years).To mine six BTC, you currently need almost 80 bits of zeroes, so 28 bits is basically trivial. reply robertk 18 hours agoparentprevBy the pigeonhole principle, there is a sentence that writes out its entire SHA256 representation this way. Alternatively, the map from these kinds of sentences with 256 terms to 2^256 given by SHA256 admits a fixed point. reply anderskaseorg 18 hours agorootparentThe pigeonhole principle does not say that. It can be used to show that there are two different sentences with the same hash as each other (among any collection of 2^256 + 1 sentences), but it tells you nothing about hashes that agree with the content of the sentence. The probability that a random hash function on a collection of 2^256 sentences has a fixed point is about 1 - 1&#x2F;e, and it approaches 1 as you add more variations to grow the collection infinitely. But SHA-256 isn’t actually random, so the only way to know this for sure would be to find an example. reply TimWolla 18 hours agorootparentprevI don&#x27;t believe this is necessarily true. Unless I&#x27;m misunderstand you, each of the possible variants of spelling out 32 hexadecimal characters could theoretically SHA-256 into the spelled-out hash + 1 (looping around at ff…ff). reply delecti 18 hours agorootparentprevI don&#x27;t see how pigeonhole principle applies to that situation. It could well be that \"zero\" hashes to 1, \"one\" hashes to 2... and \"f\" hashes to 0, extended out to the hash&#x27;s length. reply curtisf 17 hours agoprevA semi-useful variant of this technique was posted nine months ago on Hacker News:https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=33704297Generating sequential Git short commits! It&#x27;s so pleasant looking I&#x27;m tempted to try using it one of my projects, but deep down I know it&#x27;s not worth the hassle. reply siraben 5 hours agoprevWith some clever information hiding, you can sort of mask the brute force: On 2015&#x2F;7&#x2F;6 at 00:00, I wrote this message&#x27;s hash down. It started with 1337. Thought #335552803: I love beef so much I made sure the sha256 of this message started with 0xbeef!A longer example: $ cat predestination.txt (1991&#x2F;4&#x2F;7 at 00:16)I know the hash of this message before you do! (1991&#x2F;4&#x2F;7 at 00:17)Huh. What is it? (1991&#x2F;4&#x2F;7 at 00:18)It starts with 1337. $ sha256sum predestination.txt 1337a4654163ab48761bf8acc75a407179e700f67f97d754b08c7afeac7da70a predestination.txt reply jph 13 hours agoprevRust implementation...The code searches permutations of increasing length. Benchmark is 8 seconds on a MacBook Pro M1 to discover the match of 182a7c9. The code is not yet optimized. use std::time::SystemTime; use itertools::Itertools; use sha256::digest; fn main() { let digits: [usize; 16] = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]; let chars = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"a\", \"b\", \"c\", \"d\", \"e\", \"f\"]; let words = [\"zero\", \"one\", \"two\", \"three\", \"four\", \"five\", \"six\", \"seven\", \"eight\", \"nine\", \"a\", \"b\", \"c\", \"d\", \"e\", \"f\"]; let mut length = 2; let start = SystemTime::now(); loop { for permutation in digits.iter().permutations(length) { let parts = permutation.iter().map(|x| words[**x]).collect_vec(); let sentence = format!( \"The SHA256 for this sentence begins with: {} and {}.\", &parts[0..(parts.len() - 1)].join(\", \"), &parts[parts.len() - 1] ); let checksum: String = digest(&sentence); let starts: String = permutation.iter().map(|x| chars[**x]).collect(); if checksum.starts_with(&starts) { println!(\"milliseconds: {:?}, {} \", start.elapsed().unwrap().as_millis(), &sentence); } }; length += 1; } }Output: milliseconds: 3, The SHA256 for this sentence begins with: zero, b, six and two. milliseconds: 54, The SHA256 for this sentence begins with: zero, e, d, eight and f. milliseconds: 8279, The SHA256 for this sentence begins with: one, eight, two, a, seven, c and nine.Repository:https:&#x2F;&#x2F;github.com&#x2F;joelparkerhenderson&#x2F;sha256-sentence reply chriskw 16 hours agoprevI did something similar once (with a bit of a twist) for my bio when I was a TA in college:\"Hi! I’m a senior studying CS. My hobbies include making semantic paradoxes and my bio includes eight a’s, seventeen e’s, fourteen i’s, eight o’s, six u’s, and one wrong number\" reply skilled 23 hours agoprevIt appears to have been taken from here,https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=19003644 (2019) reply rawling 23 hours agoparentThat makes the other collision even weirder. Someone took 4 years to find another plausible sentence that matched the same 7 digits?E: Ok, someone else in the tweet replies says it isn&#x27;t that hard. I&#x27;m going to stop reading and start thinking more about how. reply mgdm 14 hours agoprevSomething that I&#x27;m not seeing mentioned in these comments (I may just have missed it) is that you can precompute the hash of the static part of the string and then extend it with the numbers in a loop, saving some cycles. This is because the full hex representation of a SHA hash gives you the entire internal state of the algorithm. This can lead to security vulnerabilities:https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Length_extension_attack reply isp 1 day agoprevnext [–]$ echo -n \"The SHA256 for this sentence begins with: one, eight, two, a, seven, c and nine.\"sha256sum 182a7c930b0e5227ff8d24b5f4500ff2fa3ee1a57bd35e52d98c6e24c2749ae0 - reply omoikane 17 hours agoprevRelated, here is a program that prints its own SHA-512 hash:https:&#x2F;&#x2F;www.ioccc.org&#x2F;years.html#2019_diels-grabsch2 reply AnotherGoodName 16 hours agoparentHeh at first i thought &#x27;wait how did they get all 512bits in a collision!?&#x27;Then i realized the program just calculates it&#x27;s own hash and prints it. Simple as that. It&#x27;d be super interesting if the program had the hash as a string internally and printed that out but that&#x27;s (within the realm of breaking cryptography) impossible to pull off. reply olafalo 13 hours agoprevWell, this nerd sniped me... I made a quick Go tool for this. You simply write a string {like|this}, and then it finds a hash with the same prefix automatically. (Hash this comment, it&#x27;s also 182a7c9) reply nielsole 13 hours agoparent$ echo -n \"Well, this nerd sniped me... I made a quick Go tool for this. You simply write a string {like|this}, and then it finds a hash with the same prefix automatically.\" |sha256sum 9e9f6a7fba355220b4c999b29bd12a3f65ec40e7b03c7bfaf3f34a1524a232b6 reply olafalo 12 hours agorootparentThe whole comment:$ echo -n \"Well, this nerd sniped me... I made a quick Go tool for this. You simply write a string {like|this}, and then it finds a hash with the same prefix automatically. (Hash this comment, it&#x27;s also 182a7c9)\"|sha256sum 182a7c9ba0f815f77542774dc5ad9ea34975bf3747635ed0768748bcd772ef43 - reply nielsole 1 hour agorootparentyou are right, sorry. reply danbruc 14 hours agoprevAfter picking some scheme to generate messages that predict n bits of their hash in some form, the chance of finding at least one message that correctly predicts its hash is 1 - (1 - 1&#x2F;x)^x where x is 2^n. This approaches 1 - 1&#x2F;e = 63.2 % for large n. So by trying a few different schemes, for example slightly varying the prefix »The SHA256 for this sentence begins with:«, it becomes quickly very likely to succeed. In the limit of large n, for example only 5 different schemes will yield at least one correct message with 99 %.With 5 patterns, 24 bits and SHA-1. The SHA-1 hash of this text starts with 051E35. The hash of this text starts with A943BD. The SHA-1 hash of this text starts with B6640C. The SHA-1 hash of this message starts with C3B03D. The SHA-1 hash of this message starts with D93717.Or the same as before but as patterns just padding the 6 hex digits with zero zero to eight dots. 0AF3DE.. 2AF7DF....... 3E0E50. 8EE84C..... 919025... A57198.... B20775..... DA525A........ ED20F4.. reply dragontamer 4 hours agoprev28 bits of entropy? That&#x27;s definitely within brute-force regions with CPU. Possibly even single-threaded CPU honestly.-------GPU-level brute force is pushing ~40-bits. Assuming ~1 week of solid compute, a 6 TFlop computer has ~3.7 sextillion compute cycles. Or alternatively, that&#x27;s ~3 billion clock cycles (single thread) per check to reach 2^40 bits of entropy. More than easily doable for most simple brute-force computational problems IMO.If you go multi-GPU on top of that, you&#x27;ll have even more computational work available. reply istjohn 6 hours agoprevI now see that eyeballing the first and&#x2F;or last few characters of a checksum is not going to detect a skillfully altered executable or ISO. reply sixstringtheory 4 hours agoparentI usually look at the beginning and end characters. Is this any safer? Does the difficulty scale the same way with added bits even if they aren’t adjacent? reply SethTro 11 hours agoprevTook less than a minute to find a seven digit example in pythonThe SHA-256 of this sentence begins with 0, three, 9, four, 8, four, and 1 amazing!The SHA256 for this sentence begins with 0, 4, five, 5, eight, 6, and 7 amazing!Suffix extensions (hence the \"amazing!\") are several times faster to try than throwing away the entire sha256 state for each attempt. reply SethTro 9 hours agoparentI ran the python version for over an hour and found this eight digit exampleThe SHA256 of this sentence begins with 0, zero, 0, seven, five, 9, nine, and 5 wow! reply nneonneo 12 hours agoprevI bet you could hack hashcat (or just use CUDA) to find these quickly for larger prefixes. Might make a fun (silly) challenge. Hashcat can do 21B SHA256 hashes per second on an RTX 4090; this translates into bruteforcing a 9-digit prefix in 4 seconds, a 10-digit prefix in 52 seconds, or a 11-digit prefix in about 14 minutes. reply pontifier 14 hours agoprevThis is similar to the vanity address generation for Bitcoin and other cryptocurrency addresses. reply lionkor 4 hours agoprevYou would get more possibilities if you allowed \"eighteen\" instead of \"one, eight\" reply Obscurity4340 12 hours agoprevDumb question but what are the implications here? Is this problematic⌨ or is it more of an Easter egg? reply plasticeagle 12 hours agoparentIt&#x27;s an inevitable consequence of a good hash function. Every string you try is going to give you a different hash, so you just need to try enough strings.But each time you add another digit to the prefix you&#x27;re looking for, the difficulty of the match goes up by about 16 times.If you&#x27;re only looking for a few digits in the hash, then any brute force that is capable of changing the string every time you attempt the match will always find it. If you&#x27;re looking for seven digits in the hash only, then it&#x27;ll take on average 134217727 attempts. Which isn&#x27;t really all that many on modern hardware. reply Obscurity4340 11 hours agorootparentSo, implications-wise: where is the rub here? Where can this be used or exploited for fun or profit? reply rootw0rm 10 hours agorootparent1.) Pick one of the old abandoned Bitcoin addresses2.) Start looking for a key match using this technique3.) Heat death of the universe4.) Profit! reply Obscurity4340 4 hours agorootparentI wonder how many of the Lastpass vaults had the private keys in the very unencrypted notes sections... reply Dylan16807 4 hours agorootparentprevFind somewhere people look at only a small fraction of a hash?That&#x27;s mostly git commits. reply rawling 4 hours agorootparentOh, that&#x27;s evil.In some places my tooling only shows 7 digits of the git SHA. I wonder how hard it would be to write something to tweak my commits until those are all the same. And I wonder how long it would take until someone noticed... reply jongjong 3 hours agoparentprevIt just makes it seem like sha256 can be reversed (which would be a major security issue) but it&#x27;s an illusion as the sentence only predicts the first 7 digits of its own hash which isn&#x27;t difficult to guess through brute force.If you keep randomly changing letters or words in a sentence, you can eventually make sha256 spit out a hex string whose start matches any 7 digit hex sequence you want. reply grantmnz 9 hours agoprevSee also: https:&#x2F;&#x2F;github.com&#x2F;grantm&#x2F;no-more-f-s-repo reply kif 15 hours agoprevWhereas the SHA256 for this sentence begins with: five, three, e, two, one, f and e. reply Ekaros 13 hours agoprevNow a SHA256 hash that hashes to itself would be more interesting. reply acchow 12 hours agoparentFixed points? The sha256 algorithm makes it easy to compute themhttps:&#x2F;&#x2F;crypto.stackexchange.com&#x2F;questions&#x2F;48580&#x2F;fixed-point... reply msm_ 10 hours agorootparentIt&#x27;s \"just\" a fixed point of the sha256&#x27;s compression function, right? reply nuancebydefault 15 hours agoprevIt took some time for me to sink in why no explanation was needed. Is there a general term for such a thing, self-reflection or something the like? reply yowzadave 14 hours agoparenthttps:&#x2F;&#x2F;autograms.net&#x2F; reply gokhan 14 hours agoparentprevSomething like a recursive acronym. Like \"GNU&#x27;s Not Unix!\". reply knome 15 hours agoparentpreva partial cryptographic quine, perhaps? reply nabla9 16 hours agoprevWould you believe in God if sha256 of \"I am God. My name is BOB \" would be 4920616D20476F642E204D79206E616D6520697320424F4220202020202020 (the text in hex)? reply Dylan16807 4 hours agoparentBreaking sha2 is a pretty unconvincing miracle. reply narcindin 16 hours agoprevThis is cool. Isn&#x27;t finding these the same as minting a new block of bitcoin? So definitially hard using our best understanding of algorithms, math, etc. reply spullara 15 hours agoparentbitcoin is relatively easy. you are just hashing&#x2F;permuting the block header until you get the lowest hash of all miners. it isn&#x27;t hard, just expensive.https:&#x2F;&#x2F;www.mycryptopedia.com&#x2F;bitcoin-algorithm-explained&#x2F; reply matt3210 15 hours agoprevWhy is X covering code as “sensitive material”? reply Gunnerhead 19 hours agoprevI’m not sure I understand the significance. Can anyone explain? reply ursuscamp 19 hours agoparentSHA256 is a one-way hashing function. Which means that feeding that sentence into SHA-256 and it starting with the characters in that sentence is very unlikely chance.They probably wrote a script that tacked on a bunch of random letters and numbers to a sentence, then hashed it via brute force until it returned a hash that started with the exact same thing that the sentence said.This is similar to how Bitcoin&#x27;s proof of work algorithm. reply kzrdude 18 hours agoparentprevIt&#x27;s self-referential and that makes it non-obvious how it&#x27;s accomplished. Changing the sentence changes the hash, which also changes the sentence. So in any case it&#x27;s an interesting construction. reply sublinear 19 hours agoparentprevAnother potential issue that comes to mind is the usage of \"short hashes\" as an identifier instead of the full hash. reply wholesomepotato 17 hours agoprevThis is only 7 * 4 bits. That&#x27;s really nothing. reply Uptrenda 10 hours agoprevIt&#x27;s like a human-readable PoW, lol. reply PaulHoule 17 hours agoprevYou have to try like what, 2^24 ~ 16 million sentences to make that work? reply fleekonpoint 13 hours agoprevReminds me of this xkcd:https:&#x2F;&#x2F;xkcd.com&#x2F;917&#x2F; reply anon____ 13 hours agoparentOr this: https:&#x2F;&#x2F;xkcd.com&#x2F;688&#x2F;. reply kjrose 18 hours agoprevYay pigeon-hole principle combined with birthday attack. reply anderskaseorg 17 hours agoparentNo. The pigeonhole principle and the birthday attack both apply to situations where you’re looking for two inputs with the same hash as each other, not where you’re looking for one input that describes its own hash. reply atemerev 18 hours agoparentprevExplain this then: https:&#x2F;&#x2F;twitter.com&#x2F;benoconnor&#x2F;status&#x2F;1701057433131421935 reply kazinator 19 hours agoprevIn this game, the rules should be that the digit 9 counts as either \"nine\" and \"quine\". reply jimmywetnips 18 hours agoparentok bit whisperer reply bizzleDawg 17 hours agoprev [–] It&#x27;s way above my head mathematically as to if this is even possible, but it is hilarious how screwed so many things would be if sha256 was discovered to have a means to more quickly reverse at least a partial hash. Just off the top of my head: - SSL - Bitcoin (bonus: unlimited money hack if you can keep the discovery under wraps) - Signed updates for devicesGoodness only knows what I am missing, but that first one along is enough to cause an unmitigated disaster.I assume these tweets are effectively brute forced given the fairly short prefix though and we&#x27;re all safe reply Dylan16807 4 hours agoparent [–] Is brute forcing a hash not \"more quickly reversing at least a partial hash\"?What do you have in mind for \"more quickly\", then?Also even if you figured out a way to make sha256 a few orders of magnitude faster, that would not affect SSL or signing and bitcoin would adjust as soon as several people know the secret. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "LaurieWired's tweet from Sep 10, 2023, provides the starting alphanumeric characters for the SHA256 hash of a certain sentence.",
      "SHA256 refers to a specific type of cryptographic hash function. It is commonly used to verify data integrity through producing a unique, fixed-size 256-bit (32-byte) hash.",
      "The provided alphanumeric characters would be the initial segment of this unique hash, generated from a specific sentence."
    ],
    "commentSummary": [
      "The text highlights the discovery of a sentence with a unique SHA256 hash, prompting discussions on collision probability and ways to find similar collisions.",
      "It expounds on the difficulty of finding collisions in SHA256 hashes and explains the linkage between hash size and collision difficulty, alongside techniques to expand the search space.",
      "There are discussions on the self-referential property of hash functions, its implications, and its connection to Bitcoin mining. Also mentioned are the potential risks of brute forcing hashes on SSL, signing, and Bitcoin."
    ],
    "points": 266,
    "commentCount": 128,
    "retryCount": 0,
    "time": 1694426930
  },
  {
    "id": 37471048,
    "title": "In Germany, 27 are in 'preventive detention' b/c they might do climate protests",
    "originLink": "https://mastodon.energy/@Sustainable2050/111039159882536261",
    "originBody": "mastodon.energy, Mastodon destekli merkeziyetsiz sosyal ağın bir parçasıdır. We are a server dedicated to professional and academic individuals and organizations working on energy transition policy, infrastructure, technology, journalism, and science. YÖNETİCİ: mastodon.energy @admin SUNUCU İSTATİSTİKLERİ: 338 etkin kullanıcılar Daha fazlasını öğrenin mastodon.energy: Hakkında · Profil dizini · Gizlilik politikası Mastodon: Hakkında · Uygulamayı indir · Klavye kısayolları · Kaynak kodu görüntüle · v4.1.6 Geri Kees van der Leun @Sustainable2050@mastodon.energy In the German state of Bavaria, dozens of people are in 'preventive detention' because they might otherwise engage in climate protests, specifically around the car industry exposition IAA in Munich. Apparently possible for a month there... https://www. zeit.de/gesellschaft/zeitgesch ehen/2023-09/letzte-generation-bayern-praeventivhaft-gewahrsam Letzte Generation: 27 Klimademonstrantinnen in Bayern präventiv in Haft Im Vorfeld der Autoausstellung IAA hat die Polizei… ZEIT ONLINE 10 Eyl 2023 08:18 · · Tusky · 331 · 154 2g Kees van der Leun @Sustainable2050 39 now: https:// climatejustice.social/@Aufstan dLastGen/111029506167884374 Letzte Generation (@AufstandLastGen@climatejustice.social) Climate Justice Social 1 2g Jan Wildeboer @jwildeboer@social.wildeboer.net @Sustainable2050 Can be extended to 60 days. Was originally announced as ultimate measure against terrorists. So now the authorities in Munich are trying hard to construct a case to make climate activists a criminal organisation. 1+ 2g Jan Wildeboer @jwildeboer@social.wildeboer.net @Sustainable2050 Disclaimer: I live in Munich since 20+ years and have been closely following this topic since more than a year. 1 1g Sofie @Sofie@subversive.zone @jwildeboer I am too. 60 days? WTF! I am thinking two months. @Sustainable2050 0 2g Mina @Mina@swiss-talk.net @jwildeboer I truly hope, this preventive arrest gets declared unconstitutional by a federal court. Whilst it makes some sense to detain known violent football hooligans for the duration of a certain match, it is completely out of proportion when it comes to prevent the exercise of the democratic right to protest. It is a measure of a totalitarian state. Nothing else. @Sustainable2050 1+ 2g adipoeserPursch @adipoeserPursch@swiss-talk.net Well, we'll see. I hope so. https:// climatejustice.social/@Aufstan dLastGen/111030955952164470 @Mina @jwildeboer @Sustainable2050 0 2g * Jan Wildeboer @jwildeboer@social.wildeboer.net @Mina @Sustainable2050 A measure by a city that fames itself for being open and tolerant, but reacts with a totalitarian attitude if you dare protest against cars. Munich. The irony of history. Remember that we also have a city ordnance that makes carrying superglue an offence with a 1000€ fine for certain people. #Sekundenklebertransportverbot Which inspired me to #OpenCarrySuperglue 0 1g vinay @vinay@veganism.social @jwildeboer @Sustainable2050 India showing the way to the world in fascism - We've had a law on the books since 1967 (called Unlawful Activities (Prevention) Act (UAPA), grimly evocative of thoughtcrime) in the name of combating international terrorism that has been used by the #fascist #Modi government to crush dissent and criticism. It allows detention of up to 180 days, but many have languished in jail for years, and the Supreme Court has been sitting on legal challenges to the constitutionality of the law https:// lawandotherthings.com/explaine r-constitutional-challenges-to-uapa/ Explainer: Constitutional challenges to UAPALaw and Other Things Law and Other Things 0 2g Aurochs @aurochs@todon.eu @Sustainable2050 Meanwhile in Greece... 0 2g Flo @desperadoduck@chaos.social @Sustainable2050 To be honest, things are not looking good here in Bavaria. The bavarian vize prime minister just turned out to be a Nazi: https://www. theguardian.com/world/2023/aug /28/bavaria-deputy-leader-accusations-antisemitic-pamphlet-hubert-aiwanger As a reaction to this, his polls have even improved in the upcoming vote: https://www. ksta.de/politik/aiwanger-parte i-bei-15-prozent-freie-waehler-legen-in-erster-umfrage-nach-flugblattaffaere-zu-640852 And now they arbitrarily imprison people who use their democratic right to protest, and openly call them terrorists. I'm starting to feel slightly uncomfortable here. Bavaria’s deputy leader faces accusations over antisemitic pamphlet The Guardian 1 1g Dizzy @BubblegumYeti@mastodon.social @desperadoduck @Sustainable2050 what the fuck? 0 2g xtri @xtri@mastodon.social @Sustainable2050 Minority report 0 2g Christian Brull @brull_christian@mastodon.green @Sustainable2050 Beim Lesen des Artikels bekam ich #AIDA Werbung zu sehen, mit dem Slogan \"Ein Sommer, der nie endet\". Passt doch. Fühle mich, wie in einem Paralleluniversum. #klimakatastrophe 0 2g hanscees @hanscees@social.sargasso.nl @Sustainable2050 @glynmoody Een goed bericht om #climateEmergency #climateprotest bij te zetten 0 2g Jules @julesbl@mastodon.me.uk @Sustainable2050 well that sucks, hope their courts overturn this and also it will, hopefully, have the opposite of the intended effect 0 1g FIAR Light @LightFIAR@med-mastodon.com @Sustainable2050 OMG. @annaleen ! Quite on topic this thread. And of course, THESE are the REAL terrorists, killing people and planet for profit. 1 1g Comm Radio Environment Network @oneloveoneplanet@spore.social @LightFIAR @Sustainable2050 @annaleen thanks this is useful 0 1g LittleFrank @LittleFrank@mas.to @Sustainable2050 this has been happening in the UK for years now. Even planning to protest is a crime, as is politely holding a sign saying \"not my king\" in case you offend Charles. https:// news.sky.com/story/climate-act ivists-pre-emptively-arrested-ahead-of-mondays-protests-11828302 Climate activists pre-emptively arrested ahead of Monday's protests Sky 0 1g Nick Kocharhook @k9@tech.lgbt @Sustainable2050 Holy moly: “This form of deprivation of liberty is all the more problematic because the protesters are not threatened with imprisonment if they are convicted of a blockade. The corresponding procedures regularly only end with fines.” 0 1g Al @mral@mastodon.sdf.org @Sustainable2050 And I thought Germany was a democracy. https://www. zeit.de/gesellschaft/zeitgesch ehen/2023-09/letzte-generation-bayern-praeventivhaft-gewahrsam 'preventive detention' sounds like what the #GOP in the USA would do. Please dont give them any ideas. Letzte Generation: 27 Klimademonstrantinnen in Bayern präventiv in Haft ZEIT ONLINE 0 1g Boerps @Boerps@nrw.social @Sustainable2050 https://www. spiegel.de/panorama/niederland e-2400-festnahmen-von-klima-aktivisten-bei-autobahnblockade-in-den-haag-darunter-viele-minderjaehrige-a-ee405dc5-2c67-451d-b174-1706a605696e Autobahnblockade in den Niederlanden: 2400 Festnahmen von Klimaaktivisten – darunter viele Minderjährige DER SPIEGEL 1 1g Kees van der Leun @Sustainable2050 @Boerps Yes, not preventive, but when they were blocking the road. All but 1 released on the same day. 0 1g darreninthenet @darreninthenet@dice.camp @Sustainable2050 how is that even remotely compatible with the ECHR..? 0 1g Sofie @Sofie@subversive.zone @Sustainable2050 Two Month, This is unbearable. Possible since the new Police Tasks Act 2018. The reason for this intensified repression was the violent protests and riots at the G20 summit in Hamburg in 2017. So they took that as justification. That was very convenient for them. Bayern it was at first. 0 1g aburka @aburka@hachyderm.io @Sustainable2050 Well this is extremely dystopian. 0 1g Comm Radio Environment Network @oneloveoneplanet@spore.social @Sustainable2050 when we think that the law and police exist increasingly to protect business interests this all makes sense. It will get worse. We need to be funding the lawyers who refuse to take part in this. 0 16s Fuzzbizz @Fuzzbizz@urbanists.social @Sustainable2050 Germany really seems like a bad place. 0 15s Vinni @specificprotagonist@tech.lgbt @Sustainable2050 \"Originally these laws were created to prevent terrorist attacks.\" (quote from the article) No, that's a lie. They were created to do exactly what they're currently doing. 0 12s frandroid jin jiyan azadî @frandroid@kolektiva.social @Sustainable2050 Is there a solidarity effort to send them mail or something? 0 3s Matteo Bertini @naufraghi@mastodon.uno @Sustainable2050 In #Italy the government is lowering the age at which you can be prosecuted ~as an adult. I have no proof, but this seems a strong power against new generations. I see not so distant a 12ys old doing something strong against the #climate #inaction. 0 Keşfet Yerel Federe Profilleri veya etiketleri izlemek, gönderileri beğenmek, paylaşmak ve yanıtlamak için giriş yapın. Başka bir sunucudaki hesabınızla da etkileşebilirsiniz. Giriş yap Hesap oluştur ŞU AN GÜNDEMDE #technology Son 2 gündeki 31 kişi #sustainability Son 2 gündeki 28 kişi #heatpumps Son 2 gündeki 8 kişi",
    "commentLink": "https://news.ycombinator.com/item?id=37471048",
    "commentBody": "In Germany, 27 are in &#x27;preventive detention&#x27; b&#x2F;c they might do climate protestsHacker NewspastloginIn Germany, 27 are in &#x27;preventive detention&#x27; b&#x2F;c they might do climate protests (mastodon.energy) 253 points by raybb 16 hours ago| hidepastfavorite340 comments fabian2k 15 hours agoThis is is a state law, not a federal one. As far as I understand it is limited to 2 months. Just a clarification, not a justification. It was a somewhat controversial law, and I think those cases clearly show why. Those laws always get justified with terrorism, and now they&#x27;re jailing people that block traffic.I don&#x27;t think such laws should exist, and we should do better there. Unfortunately I don&#x27;t expect that with the Bavarian politic landscape this will happen on the legislative way. reply tfourb 15 hours agoparentAlso might be worth mentioning that the Bavarian state police law that these arrests are based on is actively challenged in court and there arrests could become part of that case. reply JAlexoid 15 hours agorootparentI expect that this law is going to either be restricted by german courts, or ECHR&#x2F;CJEU. reply AbrahamParangi 12 hours agoparentprevI can&#x27;t be alone in thinking that jailing people who obstruct traffic and jailing people who we believe intend to obstruct traffic are two totally different matters. reply c4mpute 12 hours agorootparentUsually that believe stems from the fact that those people explicitly announced they would do it again. And again. After being sentenced. In front of a judge.https:&#x2F;&#x2F;www.merkur.de&#x2F;deutschland&#x2F;kleber-aktivisten-letzte-g... reply AbrahamParangi 11 hours agorootparentI would still rather have them sentenced for the crimes they’ve committed - even if sentenced harshly due to their unrepentant disposition - than for the crimes they may commit in the future.We are all hypothetical criminals and I would prefer that the state not have that freedom to lock people up. reply somsak2 7 hours agorootparentI don&#x27;t think most people have claimed they will commit a crime in the future. Not necessarily for climate protests, but in many cases in the US we do this same thing too.https:&#x2F;&#x2F;www.bostoncriminaldefenselawyers.com&#x2F;threat-to-commi...https:&#x2F;&#x2F;ravellawfirm.com&#x2F;blog&#x2F;can-someone-go-to-jail-for-thr...https:&#x2F;&#x2F;www.law.cornell.edu&#x2F;uscode&#x2F;text&#x2F;18&#x2F;373 reply satellite2 15 hours agoparentprevHasn&#x27;t Germany ratified the European Convention on Human Rights? Those are definitely breaching the above and could easily be considered as fascist laws. This should be a fairly easy trial. reply laserdancepony 3 hours agoparentprevI do believe it is reasonable to hold repeat offenders. And I hope this law will be upheld when tried. These people do not understand democratic dialogue and so I have no pity for them. reply tomohawk 15 hours agoparentprevBlocking traffic is so much more than merely stopping cars.It prevents people for exercising many of their rights. This is at least freedom of movement, but depending on why a person is traveling, it may prevent them from getting medical attention, being employed, seeing loved ones, and many other things.This sort of nonsense is aimed at overturning civil society.It seeks to use kinetic means to achieve political goals.It may be petty terrorism, but it is terrorism none-the-less. reply fabian2k 15 hours agorootparentThere is a fundamental difference between killing people, placing bombs and gluing yourself to a road. If your definition of terrorism includes all of these, it&#x27;s useless. reply TylerE 15 hours agorootparentNot really hard to come up with situations where this actually kills people. Someone in an ambulance getting delayed in getting to the hospital, just for a start. reply DoughnutHole 15 hours agorootparentTrue of infinitely many forms of protest.If the teamsters strike hospitals miss drug shipments and people die. Farming protests can lead to food supply chain disruptions. Transport strikes cause economic disruption which could theoretically lead to deaths.That’s not what terrorism is.Terrorism requires terrorising people through violence and intimidation. Not standing on a highway. reply seoulmetro 10 hours agorootparentSo you&#x27;re saying that silently disconnecting all power stations of a country via software is not terrorism? Is it an attack to you at all? Or is it just a protest too? Cyberterrorism is a big thing. Where is the violence or intimidation in manipulating software?Terrorism is a broad term but it is rarely used for its lower end as its also a term used as a tool to scare people. The idea that it mandates violence is outdated. Violence was the means to terrorize but it no longer is. reply DoughnutHole 56 minutes agorootparent> So you&#x27;re saying that silently disconnecting all power stations of a country via software is not terrorism?This terrorises people. It causes mass fear and panic, and will cause pretty immediate loss of life. All people have good reason fear for the safety of them and their loved ones in the case of a catastrophic grid failure.This is not true of blocking a highway. It’s an economic disruption. The response of those opposed to the action is one of anger and frustration. Society at large does not fear for their safety because people are occasionally blocking highways, unlike in a mass terrorist campaign.Cyberterrorism as a term is applied too liberally, a direct result of governments wanting to expand their powers under the guise of combating terrorism. Software attacks that immediately threaten life and limb (eg attacks on health systems, major damage to critical infrastructure) can be argued to be cyberterrorism. Not every software attack is of that magnitude. reply yread 13 hours agorootparentprevThere are surprisingly few ambulance rides that would result in a death if they encountered a 5 minute delay. Half the time they are empty and if they are not empty they first stabilize the patient and then bring them to hospital relatively stable. Ambulance is really more like a hospital on wheels than a fast taxi with space for a stretcher reply munk-a 12 hours agorootparentprevSports games kill people in this manner all the time - if a football game is letting out and causing a traffic jam we don&#x27;t consider that to be manslaughter. And common sources of traffic like that provide a much higher widespread effect than protests (which can usually be routed around by emergency services - and which will often voluntarily disassemble for emergency health services). reply soerxpso 11 hours agorootparentThe difference is that a sports game is generally not being organized by a group that&#x27;s trying to use those consequences as an intimidation tactic to get what they want. I could say, \"accidents with explosives at fireworks shows accidentally kill people sometimes,\" but there would still be a difference between putting on a fireworks show and bombing a mall. reply terminus 8 hours agorootparentprevYou could come up with a scenario, sure. Bad in law though. [1]Another scenario you could come up with is a future climate catastrophe, where millions die and&#x2F;or are displaced because of this global boiling era. Incidentally, which is the protest thought crime that is being prosecuted.[1] Legally there&#x27;s a world of difference between proximal causes and proximate causes. (Neighborhood vs causally related.) reply turquoisevar 7 hours agorootparentprevHow about we stop making up hypothetical situations to justify authoritarian acts by the state, violence or worse, death, and stick to the facts of the matter?If protests actually cause deaths, we can always prosecute the people causing said death as manslaughter or negligent homicide. Until then it’s just a protest, guaranteed in many countries as a civil right. reply mylons 15 hours agorootparentprevif your definition excludes people from blocking necessary resources for modern life you are a terrorist reply bmicraft 14 hours agorootparent> Necessary resources for modern life> carsMaybe they should&#x27;ve take the subway then? Because \"Klimakleber\" usually only operate in the city reply woodruffw 15 hours agorootparentprevYour freedom of movement doesn&#x27;t entitle you drive a car, and the history of protest is soaked in examples of protestors effectively blocking specific forms of transportation to make a point. reply tomohawk 15 hours agorootparentIf people want to make a point, they can vote, they can petition their government and representatives, they can run for office, and they can speak.Resorting to kinetic means throws all of that out the window.You want to make a point, and be heard? Stop committing crimes and taking other people&#x27;s rights away. reply woodruffw 15 hours agorootparentYou don&#x27;t have a right to drive a car. It&#x27;s a privilege, as indicated by your drivers&#x27; license.You&#x27;re entitled to be upset when someone blocks your car. But framing it as a civil rights issue rather than a practical one (and calling someone blocking your car \"kinetic\") makes you come across as un-serious. reply c4mpute 15 hours agorootparentFreedom of movement is a fundamental right in Germany. Your freedom to move the car everywhere, and without qualification is of course limited for the safety of everyone. But driving places is part of your personal freedom, which has to be weighed against somebody else&#x27;s freedom to protest. reply varjag 15 hours agorootparentprevIf you&#x27;re on a bus you&#x27;re just as much stuck in the traffic as if you&#x27;re driving, what kind of outlandish argument is that. reply woodruffw 15 hours agorootparentBeing stuck in traffic isn&#x27;t a violation of your civil liberties. reply varjag 15 hours agorootparentFreedom of movement is a civil liberty, but maybe not where you live. reply woodruffw 15 hours agorootparentThis is a profound misunderstanding of civil liberties. Being inconvenienced by another person doesn&#x27;t violate anything.If the government were to install roadblocks and check your identity card before letting you leave your town, that would violate your freedom of movement. If a local private militia did the same thing, it would be as well. But being slightly delayed by a bunch of environmentalists blocking a specific form of transit doesn&#x27;t meaningfully violate anything.The counterstatement here would be \"the state has the right to forcefully remove anybody who slightly inconveniences me\"; it should be obvious why this would be a gross violation of civil liberties. reply varjag 15 hours agorootparentThis is a useless distinction when the distances dictate pretty much this only mode of transportation: nobody&#x27;s going to march 40km on foot unless their lives depend on it.The counterstatement here would be \"the state has the right to forcefully remove anybody who slightly inconveniences me\"; it should be obvious why this would be a gross violation of civil liberties.There is a whole slew of laws and regulations dealing with people who inconvenience others on purpose. reply munk-a 12 hours agorootparent> nobody&#x27;s going to march 40km on foot unless their lives depend on it.Freedom of movement specifically exists for when \"your lives depend on it\" - it is a vital right to preserve and the freedom to make that 40 km walk has saved countless lives over the centuries. replykelnos 15 hours agorootparentprevIf people who wanted change always avoided breaking laws during their protests, there would be a lot less positive change int he world. You might want to read up on the history of protest, and, specifically, civil disobedience. reply OGWhales 15 hours agorootparentprevWhile voting should be done, it is not always effective&#x2F;possible. An obvious example to bring up is the suffragist, since they were not allowed to vote.The point of protesting in a manner that is truly disruptive is to force the problem to be dealt with. This concept seems to allude many, to them the only acceptable form of protest is one that is entirely ignorable. I’m not sure we would have many of the important freedoms we have today without people choosing to be disruptive in this manner you find unacceptable. reply rob74 2 hours agorootparent\"Voting is not always effective\" is true especially in Bavaria, where the CSU has perfected populism to the point that they have managed to stay in power basically since the current Federal Republic of Germany exists (with a brief interruption from 1954 to 1957) - if they don&#x27;t get more than 50% of the Landtag seats, they can pick and choose their coalition partner, and they have already excluded a coalition with the Green party, because other parties (FDP, Freie Wähler) are more pliant. reply c1sc0 13 hours agorootparentprevGood reading on this is “How to blow up a pipeline by Andreas Malm” … the disruptions we see right now are pretty mild & maybe this preventive detention is an attempt to reel in the more extreme activists before they do something truly disruptive? reply crooked-v 15 hours agorootparentprevYou&#x27;re unironically repeating the same kind of rhetoric used against Martin Luther King Jr and Gandhi when their protests happened to mildly inconvenience people in power. reply tppiotrowski 11 hours agorootparentprevSome would argue that a car highway prevents right of movement for pedestrians and cyclists.I get what you&#x27;re saying but you&#x27;re very narrowly trying to define right of movement to make your argument and without your narrow definition it falls apart. reply reso 15 hours agorootparentprevHow would this theory have worked in e.g. the 1960s civil rights movement. reply ryan93 15 hours agorootparentprevIf you don&#x27;t have a right to drive a car you also don&#x27;t have a right to stand in the public road either. reply woodruffw 15 hours agorootparentNobody claimed the protestors aren&#x27;t breaking traffic laws. Protestors typically break laws, often peacefully[1], to make their point.[1]: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Greensboro_sit-ins reply anigbrowl 15 hours agorootparentprevIt seeks to use kinetic means to achieve political goals.Kinetic means things being in motion. Throwing rocks is kinetic, taking up space or forming a barricade is not. reply crooked-v 15 hours agorootparentprev> overturning civil societyWell, if you define \"civil society\" to mean \"society where everyone is subject to absolute milquetoast civility at all times\", then sure. reply munk-a 12 hours agorootparentprevThis is a really deep misunderstanding of what freedom of movement means - and if this qualified as interrupting freedom of movement then there&#x27;d be violations every time we needed to fill a pothole. There is no right to convenient movement - just to movement at all. reply aequitas 13 hours agorootparentprevThis is not restricting freedom of movement. Merely inconveniencing. But the bar is pretty low when you see the reaction you get from the driver behind you if you overtake with “only” 130km&#x2F;h on the autobahn, instead of 150+ km&#x2F;h like they do. reply justnotworthit 13 hours agorootparentprevIt&#x27;s false imprisonment against civilians to achieve political ends. But good luck trying to convince a comment section of the immorality of that. reply AndyMcConachie 15 hours agorootparentprevDriving cars is so much more than just driving cars. The practice of driving cars is one of the major practices that is leading to the destruction of our planet&#x27;s ability to support our life. reply INTPenis 15 hours agoprevIt&#x27;s kinda funny to me when I see the police drag protesters away from these industrial sights that they occupy. Because if we are to believe climate research then some of these industries are literally damaging the living space for all humans. In some cases the police should be hauling the exeutives away, not the protestors.But the regular police can&#x27;t be expected to do such deep investigations based on scientific data, so instead they end up protecting the interests of large corporations by hauling regular concerned citizens away. It&#x27;s quite a bizarre state of events. reply dauertewigkeit 15 hours agoparentYeah, well life is not so simple. Everyone would like to see a green energy transition, but we still need energy to power our everyday life and we need it also at a reasonable price. Protesting without providing alternatives is futile and counter-productive. reply INTPenis 12 hours agorootparent>Protesting without providing alternatives is futile and counter-productive.I hear what you&#x27;re saying, but please don&#x27;t say that. The alternative is to just accept unchecked capitalism destroying our environment. So no, protesting is not futile and counter-productive. It&#x27;s absolutely necessary to ensure that people remember what we&#x27;re trying to change, while we change it. reply OkayPhysicist 10 hours agoparentprevThat&#x27;s their job. Police exist as armed enforcement of the status quo, and the status quo is that rich people make the rules and everybody else suffers the consequences. reply randomNumber7 7 hours agorootparentIt doesn&#x27;t really make sense, because in a democrazy the rich people are not the majority. But it pretty much looks like it none the less^^ reply roamerz 14 hours agoparentprevLast I checked a car industry expo is not against the law. Disrupting or legitimately threatening a lawful activity is. These people are properly in custody and serving their cause by generating less CO2 in the process.Seems like a win-win. reply timeon 14 hours agorootparentI wonder if police acts in same way if, for example, traffic is blocked by protesting tractors or trucks. reply roamerz 13 hours agorootparentOr slashing tires in the name of protecting the world from ICE? reply skeaker 14 hours agorootparentprevSeems you&#x27;re missing the point of the comment you&#x27;re replying to. You are focused on it presently being legal when the question is, \"Should it be legal?\" reply roamerz 13 hours agorootparentYup I should have quoted.. Police generally haul away those who are breaking the law. I interpreted the comment as Police should be making a determination outside the law on who to arrest.>> In some cases the police should be hauling the executives away, not the protestors. reply dfxm12 15 hours agoparentprevThe police exists to protect capital, not regular folks like us. reply huijzer 15 hours agorootparentI think sweeping statements like this might seem fair in the context of this article, but are actually harmful to democracy.A fundamental right in liberal societies, for better or worse, is that of property rights. Yes, some people have a large amount of property so police will try to protect that large amount of property, but the police will also protect your property. More generally, police will protect you if you someone tries to physically attack you. We shouldn’t take this for granted since autocratic regimes care much less about these principles and will take away your property or physically harm you if they feel like it. reply dauertewigkeit 14 hours agorootparentTo say that the police will protect you is not accurate. The police are a preventative institution. They try to maintain order and reduce the incidence of crimes and act as a deterrent for those who would otherwise commit a crime. But they aren&#x27;t a condom around violence. If somebody wants to hurt you, they can, and you&#x27;re mostly on your own. They will only be brought in to investigate the case later, and maybe catch the perpetrator. It is kind of funny how we Europeans are brought up with this illusion of safety, believing that the police are some kind of superhero characters that will spring to action the second before we get knifed or shot. reply satellite2 14 hours agorootparentThe illusion of safety prevents people getting armed to their teeth and as such participate to their safety.https:&#x2F;&#x2F;m.youtube.com&#x2F;watch?v=07o-TASvIxY reply JAlexoid 14 hours agorootparentprev> how we Europeans are brought up with this illusion of safetyThat&#x27;s not exclusive to Europeans. But also - many Europeans aren&#x27;t particularly fond of this delusion. reply ryan93 14 hours agorootparentprevIn the US there are tens of thousands of violent criminals in prison. The police were integral to many of those investigations or arrests. reply rpgwaiter 9 hours agorootparentPlease look at the proportion of Americans in prison compared to the rest of the world, then realize that the rest of the world manages to maintain law and order without holding 25% of the entire world&#x27;s prison population reply JAlexoid 15 hours agorootparentprevYep, most people forget this fact. Police is explicitly there to protect property.Sometimes they do protect people, but that is typically an exception reply siva7 15 hours agoprevThat’s very concerning. This bill came to life to prevent terrorist attacks like 9&#x2F;11 but is now being abused in bavaria to jail climate protesters who could disturb the biggest automotive fair in the world. reply aaomidi 15 hours agoparentHonestly insanity because everyone warned this would happen. reply superfrank 15 hours agorootparentThe law is garbage and needs to go. I&#x27;m not defending it in the slightest.Tangentially, saying \"everyone warned this would happen\" as a criticism of something is almost always hindsight bias or survivorship bias. There are plenty of things that \"everyone\" says will happen that never happen and for the ones that do happen, \"everyone\" tends to overstate how certain they were about it being the only possible outcome. reply aaomidi 13 hours agorootparentNot really. This was clear.I’m not going to listen to Joe down the street saying Obama is gonna start putting people into FEMA camps.I will however listen to civil right experts that explicitly warned against state overreach. reply dfxm12 15 hours agorootparentprevWhat is the value of everyone here wrt to voters? It makes you wonder what other policies the politicians who championed the \"jail you for any reason under the guise of terrorism\" policy also advocated for to get people to vote for them. reply usrusr 13 hours agorootparentIt&#x27;s a party running on regional identity, policy isn&#x27;t really involved in voter decisions. They are in (regional) power almost as long as the CCP. reply josefresco 15 hours agoprevReminds me of this: Dozens face RICO charges over Atlanta police center protestshttps:&#x2F;&#x2F;www.reuters.com&#x2F;legal&#x2F;dozens-face-rico-charges-over-... reply joemazerino 6 hours agoparentHardly relevant. Antifa shot at police, threw Molotovs and cut arborist ropes endangering the workers.https:&#x2F;&#x2F;thepostmillennial.com&#x2F;breaking-over-60-stop-cop-city... reply rob74 15 hours agoprevSpecifically: in Bavaria. Which is, of course, in Germany, but also a bit of a \"state within a state\", ruled by one party (the CSU) since the beginning of time, er, of the Federal Republic of Germany, and where things like this, which would cause much more outrage elsewhere, can and do happen. reply bowsamic 15 hours agoparentBavaria has really insane police overreachEDIT: I&#x27;m being downvoted for this? They literally have total police surveillance, all the Germans here in Hamburg talk about it all the time reply tpmx 15 hours agorootparenthttps:&#x2F;&#x2F;news.ycombinator.com&#x2F;newsguidelines.htmlPlease don&#x27;t comment about the voting on comments. It never does any good, and it makes boring reading. reply user_7832 15 hours agorootparentWouldn&#x27;t it depend on the context though? If someone&#x27;s being downvoted for something correct but unpopular, is that okay as per site guidelines? reply bowsamic 15 hours agorootparentprevOkay, and who are you? If dang has a problem with it, he can tell me, else, stop mini moddingEDIT: Thanks for going through and downvoting all my recent comments reply randomNumber7 7 hours agoparentprevResearch \"gustl mollath\" of you wanna know what scary things can happen in bavaria. reply renewiltord 15 hours agoparentprevThis is the place which famously required wind turbines to be 10H the distance from a settlement for a height H. reply Erwin 13 hours agorootparentThe Danish Church is allowed to veto buildings of wind turbines if they were within the 28x the height of the turbine. This is quite a long distance if you consider the 160m tall 14MW Siemens (though I think that may be offshore only).There are more than 2000 churches in Denmark. Only the minister of the interior could override that veto. reply tpmx 15 hours agorootparentprevThat sounds sane to me, honestly. reply bmicraft 13 hours agorootparentFor other countries, maybe. But Germany doesn&#x27;t really have any spot devoid of any settlement reply tpmx 13 hours agorootparentSo then use nuclear power. Oh wait, you can&#x27;t because there was an tsunami in Japan.Germany: \"oh well, we&#x27;ll increase burning clean coal, but create some crazy roadmap that we&#x27;ll be carbon free in a few decades or so\"Germany needs to get its shit together, energy-wise. You are a disgrace in the union, honestly. With your economical development and technical know-how levels you should be at the forefront. reply c4mpute 12 hours agorootparentWe had technical know-how. Past tense. Then technology became evil incarnate.Nowadays we are scared of everything, ignorant of any kind of science. All policy and all public outrage is purely based on ideology and wishful thinking. If one kind of wishful thinking fails, we do not reconsider, we double down or replace by another, even weirder kind of wishful thinking.Basically, we are back to a pre-renaissance way of thinking. We are back in the dark ages.And I&#x27;m honestly scared of that. reply randomNumber7 7 hours agorootparentI think its based on the fact, that if you start arguing with moral, logic doesnt matter anymore. reply randomNumber7 7 hours agorootparentprevI can tell you that this really tilts me as a german.Our politics is all wishfull thinking and ideology, but arguing with the laws of thermodynamics isnt really working...And I&#x27;m defenitely neither right wing, old, nor climate sceptic replyandrewla 15 hours agoprevOn the face of it, this sounds very bad. I can&#x27;t find confirmation that this is happening outside of the statements of the \"letzte generation\" group itself [1], and the article states as much.The statement from the Munich police [2] says that protesters were taken into custody for their acts, namely blockading traffic. The length of the detention was apparently extended by the district court, but the statement does not give a reason for it. Presumably it&#x27;s connected to the belief that they will continue to carry out similar acts if released.I&#x27;m a bit conflicted here; if someone is being detained pre-trial for a crime, then \"they are going to crime again\" is a totally valid reason to hold them without bail pending trial. But it&#x27;s not clear whether that is what is happening here.Although I am writing from a US perspective, I don&#x27;t think I&#x27;m saying anything that is really specific to US law; this is more my general feelings around the limitations of police authority and how it intersects with civil liberties.I don&#x27;t know if my understanding is correct, but I can&#x27;t find direct evidence that the \"preventative detention\" law is actually being applied here -- I don&#x27;t see any evidence of stormtroopers raiding people&#x27;s houses and taking them into custody; just people who have already committed (minor) crimes being detained past the point of what some people would consider reasonable.[1] https:&#x2F;&#x2F;letztegeneration.org&#x2F;blog&#x2F;2023&#x2F;09&#x2F;liebe-und-wut-brie...[2] https:&#x2F;&#x2F;www.polizei.bayern.de&#x2F;aktuelles&#x2F;pressemitteilungen&#x2F;0... reply user_7832 15 hours agoparent> I&#x27;m a bit conflicted here; if someone is being detained pre-trial for a crime, then \"they are going to crime again\" is a totally valid reason to hold them without bail pending trial. But it&#x27;s not clear whether that is what is happening here.Not a lawyer, but doesn&#x27;t this depend on whether or not it is a violent crime? Someone who may murder again should be treated differently than someone who may shoplift again. reply andrewla 13 hours agorootparentNot speaking to law, but in principle this seems like a case-by-case decision that (in the US) I would expect a judge to make. I would expect a competent judge to weigh the societal cost of the crime vs the probability of re-committing it vs the rights of the accused to a presumption of innocence.For violent crimes it swings pretty hard on the societal cost of the crime (but maybe be mitigated if the crime was one of passion or if the motive was clear and not likely to result in a re-commission).For jaywalking it swings pretty hard in the other direction.For crimes where there is a victim but no violence, it would depend on the specifics of the case in question. reply dfxm12 15 hours agorootparentprevLegally, this depends on jurisdiction. From the standpoint of what&#x27;s better for society, I agree with you. reply rewmie 15 hours agoparentprev> The length of the detention was apparently extended by the district court, but the statement does not give a reason for it.I don&#x27;t think that that&#x27;s what happened. The newspiece states quite clearly that the suspects were kept in jail as a preventative measure, in complete accordance with Germany&#x27;s regional law.The controversial part was that arguably the length of the preventive jail stay contrasts with the jail terms that the suspects are facing, and other regional courts determined shorter preventive jail terms.I think that this is an issue where the court had to draw a line in the sand within the boundaries specified by the law. The court had a group of people known for conducting criminal acts and determined that the likelihood that they would continue their criminal activity if they would be released was almost certain. The court had to make a call, and had to choose between being responsible for allowing criminals to repeat their crimes, or ensure they wouldn&#x27;t by keeping them in preventive jail. reply loupol 14 hours agorootparentFrom news article :> Diese Form des Freiheitsentzuges ist umso problematischer, da den Protestierenden, sollten sie für eine Blockade verurteilt werden, keine Haft droht. Die entsprechenden Verfahren enden regelmäßig lediglich mit Geldstrafen.The crime they might have committed usually doesn&#x27;t even result in jail time, only fines. Hence why such long detention seems especially unjustified. reply andrewla 13 hours agorootparentThe article lays out a factual description of the detention law, and lays out the description of the so-far detained members of the group, but fails to connect the two. Nothing in the police report indicates that the law was applied, just a reference to the district court extending the detention period, but no link or reference to the specifics of whether the district court applied the law.I don&#x27;t know if the German press is held to different standards than the US press, but in the US this would set off red flags for me because it makes a very strong implication without explicitly stating it and provides no evidence for the implied connection. reply c4mpute 12 hours agorootparentprev> Die entsprechenden Verfahren enden regelmäßig lediglich mit Geldstrafen.This is plain wrong. Repeat offenders in this matter have been sentenced to jail time, in excess of the two months of possible preventative arrest: https:&#x2F;&#x2F;www.merkur.de&#x2F;deutschland&#x2F;kleber-aktivisten-letzte-g... reply andrewla 13 hours agorootparentprevI find it less clear what exactly the article is alleging.It refers to a police practice, and says that a judge can extend it further, but the press release says that the police did not apply this practice. And no information is given about what the substance of the district court&#x27;s decision was.But all that said, my initial read on the article, \"put a total of 27 supporters of the group in prison\" is that the police are grabbing innocent people and putting them in preventative detention, but that does not appear to be supported by the article. Rather they are being held for minor crimes (which I don&#x27;t think anyone is contesting that they committed) and being kept there (the article says \"prison\" but I don&#x27;t know whether Germany has the same distinction at the US between prison and jail&#x2F;pre-trial detention). reply banannaise 16 hours agoprevAsking because my context as an American may not apply: If an American were jailed for the maximum 60 days, then they would almost certainly be fired from their job for non-attendance and become 30+ days late on all of their bills since you cannot pay bills from jail. This includes car payments and&#x2F;or rent, which can result in repossession&#x2F;eviction proceedings being filed.Is the situation for short-term prisoners similar in Germany? reply recvonline 15 hours agoparentYour employer is not allowed to fire you if are in jail for less than 2 years. You also can&#x27;t evict someone from their home because of jail. And the government might be paying your landlord for your time in jail as well (depending on the time etc.). It&#x27;s complicated, but basically, Up to 6 months, all fine on all ends.Germans don&#x27;t have car payments usually. They pay for the car in cash, if they don&#x27;t have enough, they buy a smaller car :) reply jupp0r 15 hours agorootparent47% of new cars are financed in Germany [1][1] https:&#x2F;&#x2F;de.statista.com&#x2F;statistik&#x2F;daten&#x2F;studie&#x2F;1065113&#x2F;umfra.... reply recvonline 15 hours agorootparentThat&#x27;s new cars. Which is mostly what employers buy for their employees. It&#x27;s 35% alltogether.Just wanted to highlight the different mindset. I am a German living in Canada with my family. The mindset is very different. Based on feeling, 70% of Canadians I know have car debt, whereas I know one person in my German friend circle who took out a loan. It&#x27;s just not very common to take on debt for cars. reply onetimeuse92304 15 hours agorootparentprevI have noticed that in the US people have much more tolerance for debt. Even relatively poor people in the US are much more likely to buy a new car (or even multiple of them!) than in most of the Europe.For example, the proportion of financed new cars to all new cars sold is 84% in US vs 47% in Germany.But that does not say anything how expensive are the cars, how expensive compared to income, how long they are being used or what is the proportion of new cars sold to used cars sold.In Europe people tend to use the cars for longer after they buy them new and then the cars tend to be used for longer after they are sold used.Also, in Europe people tend to buy smaller cars. And, historically, we preferred cars that use less fuel which means a lot of older cars are still very viable compared to older US cars. reply TylerE 15 hours agorootparentIn the US at least it has often (although not at present) been true that the interest rate on a new car loan with good credit is less than one could return from relatively safe investments. Thus the financially smart thing to do was often to finance the car, even if you could buy it outright.Too much debt is a bad thing, but so is being excessively debt averse.I would also say, historically, a dollar now is worth a lot more than a dollar 50 years from now, and your quality of life is probably better, too.I see lots of people from my parents generation who saved their whole life… and now they have money but nothing to do as their health doesn’t permit the sort of travel (or outdoor activity, or whatever) they wanted while a 20 or 30-something. reply onetimeuse92304 14 hours agorootparent> Thus the financially smart thing to do was often to finance the car, even if you could buy it outrightI think the financially smart thing is to avoid debt as much as possible.Also, if you absolutely need to take on debt and decided to buy a car, the financially smart thing to do would be to buy as cheap a car as possible. But that&#x27;s not what really is happening, isn&#x27;t it?The reality is that taking debt changes how you think and make decisions and has far more reaching consequences than just the financial cost of the debt. reply TylerE 13 hours agorootparentTaking on debt at 3% so you can stick the money into a index fund reliably returning 5%... is what is smart.This sort of knee-jerk debt avoidance on principle is not smart. reply onetimeuse92304 12 hours agorootparentFirst of all, buying a car so that you can drive your ass around is very different from sticking those borrowed money into an index.Second, there exists no index fund that can reliably return 5%. Borrowing money to put it in a financial instrument is called leverage and is a quick way to get poor, not rich (and I know a bit about it because I work with financial risk for a pretty large, well known bank).Third, for some reason (and, do explain this if you can), people are not storming banks to borrow at 3% to then go to a brokerage house to buy a supposedly reliable index. Please, show me ONE person who got rich this way... I guess not. You see, this is not how people get rich... people get rich mostly by earning a bunch of money and then not losing it. You know, not losing it is kinda important part of getting rich.In fact, there is lots of people interested in how people actually get rich. And funny thing, nobody gets rich by repeatedly borrowing money and buying index funds. BECAUSE IT DOESN&#x27;T WORK.Fourth, the act of taking debt changes how people think. I also know something about it because for large part of my life I had a lot of debt. Wonderful things happened to me after I paid it all. And while most of it might be in your head, the results are very real. reply fragmede 13 hours agorootparentprevThe avoidance of as much debt as possible is an irrational, emotional attachment to avoiding debt. Excessive amounts of debt is also financially unsound to collect, but the financially prudent thing is some debt, after which you end up with money, or equivalent, than if you not had taken on that debt. reply beowulfey 15 hours agorootparentprevMy impression of Germany is people are generally very anti-debt. Credit cards were barely used when I visited back in 2019 (although that changed by the time I went back in 2022) reply Xylakant 15 hours agorootparentThe primary reason credit cards were rarely used is because Germany already had an electronic payment system (Maestro, formerly eurocheque), so there was no need and credit cards often came with a fee. Online shopping and a huge push by Visa&#x2F;Mastercard to replace maestro changed this to some extend. reply gumballindie 15 hours agorootparentprev> Germans don&#x27;t have car payments usually.They do actually :-)https:&#x2F;&#x2F;www.mckinsey.com&#x2F;industries&#x2F;automotive-and-assembly&#x2F;...\"In Germany, while customers purchase 50 percent of stock cars through financing, they buy 35 percent via lease-based products and additional services.\" reply sho_hn 15 hours agorootparentprev> Germans don&#x27;t have car payments usually.There&#x27;s a lot of leasing. reply jacquesm 15 hours agorootparentThat&#x27;s corporate, mostly. But this is changing a bit, there are more private lease constructs but they are quite expensive compared to just owning the car. reply iamthirsty 15 hours agorootparent> That&#x27;s corporate, mostly.Stats would be nice. reply jacquesm 15 hours agorootparenthttps:&#x2F;&#x2F;bdl.leasingverband.de&#x2F;en&#x2F;newsroom&#x2F;press-releases&#x2F;sin...https:&#x2F;&#x2F;www.ibisworld.com&#x2F;germany&#x2F;industry&#x2F;car-rental-leasin...And many other industry publications. Private lease is a very small fraction, but it is growing. Same picture in most of Western Europe, in Eastern Europe it is very variable from one country to another. reply dotancohen 15 hours agorootparentprevYou do know that stats are the easiest way to lie, yes? reply TylerE 15 hours agorootparentNo, the easiest way to lie is “just trust me bro” reply mertbio 15 hours agorootparentprevYes but most of the time your company pays and then they deduct from your salary. reply almostnormal 15 hours agorootparent1% of the purchase value is taxed, regardless of usage (company car could be used only for private purposes). That way the same cost for the employer leads to a bigger car (than if bought with taxed income) for the employee and less money for the government.And a happy car industry, of course, being able to sell bigger cars. reply cooper_ganglia 15 hours agorootparentprevWell that just sounds like taking a relaxing 6-month vacation from work while the law-abiding taxpayers pay your rent. Meanwhile, your employer and landlord are forced by the government to accept the employment and housing of someone with a criminal history?I&#x27;m usually all for protecting the little guy over the corporate entity, but that sounds like n awful deal for everyone involved except the criminal. reply JanSt 14 hours agorootparentWell you prefer punishment, Germany prefers reintegration. Destroying a persons life is a pretty good way to keep a criminal criminal. reply sho_hn 15 hours agoparentprevIt&#x27;s complicated, and the law leaves a lot of wiggle room. In principle, it can be a valid reason to end an employment relationship from the employer side if someone is unable to perform their work due to being in jail. However there&#x27;s a lot of hoops to jump through for the employer - the absence has to be of \"significant length\", the employer has to be able to show they deeply looked into it when they came to this conclusion, they need to consult with the employee on it, they may have to look into alternative solutions to fill the gap, etc. As a guideline, if the absence is expected to be two years or longer, much of this is no longer expected by the employer.I think most employers would not get away with firing someone in this case. reply nvahalik 15 hours agoparentprev> maximum 60 daysIn the US, political prisoners have been jailed for years without trial. 60 days would be a major respite. reply bsimpson 15 hours agorootparentWe have a constitutional right to a speedy trial.That right can be waived to give the defense time to prepare, and it isn&#x27;t always enforced for non-citizens detained abroad (e.g. Guantanamo), but I&#x27;m unaware of anything similar to the article happening in the US. reply BurningFrog 15 hours agorootparentIn theory we have that right.In practice, 98% of criminal cases in the federal courts end with a plea bargain.https:&#x2F;&#x2F;www.npr.org&#x2F;2023&#x2F;02&#x2F;22&#x2F;1158356619&#x2F;plea-bargains-crim... reply ceejayoz 15 hours agorootparentWe have the right to a speedy trial and a the right to accept a plea bargain. You can decline a plea bargain and demand a speedy trial; the limits are defined by law. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Speedy_Trial_Act(As with other rights, these rights sometimes require active defense by civil rights organizations, nor are they completely absolute.) reply BurningFrog 15 hours agorootparentFew people choose this because of the \"trail penalty\".If you&#x27;re found guilty in a trial, you get a 2-4 times longer sentence than the plea deal would have given.So the theoretical right to a trial remains, but exercising that right is heavily penalized. To me that means the right is for practical purposes no longer exists. reply ceejayoz 15 hours agorootparentSure, that&#x27;s why it&#x27;s a deal. You say penalty, they say bargain. Both are true. For folks who&#x27;ve genuinely committed big-boy crimes, a plea bargain is great; for falsely accused innocents it presents an unpleasant dilemma at times.My being able to opt to voluntarily testify doesn&#x27;t mean the right to remain silent doesn&#x27;t exist. We&#x27;d have no rights by your definition. reply BurningFrog 14 hours agorootparentYou can think of it that way if you want, sure.Another angle is that plead bargains are necessary to put as many people in jail as we do.The judicial system would completely break down if it needed to have 50x as many trials. reply ceejayoz 14 hours agorootparent> The judicial system would completely break down if it needed to have 50x as many trials.Yes. I&#x27;d argue that&#x27;s not universally or even mostly a good thing. reply joshuamorton 15 hours agorootparentprevNote this only applies to federal trials, not state trials (where the vast majority of crimes are prosecuted). reply ceejayoz 15 hours agorootparentIt&#x27;s often defined at the state level, too. Here in NY, prosecutors are required to be ready to go within six months (felony) or 90 days (misdemeanor): https:&#x2F;&#x2F;www.nysenate.gov&#x2F;legislation&#x2F;laws&#x2F;CPL&#x2F;30.30The right exists whether or not your state has legislation defining a timeframe, too. reply joshuamorton 13 hours agorootparentYeah, absolutely the constitutional right exists, but it&#x27;s often less well defined than the federal version, which is very clear and well followed. reply thephyber 15 hours agorootparentprevWe still have that right.The nuance is the US court system allows additional punishment if a defendant chooses to go to trial. Also, plea bargaining usually involves lots of prosecutor bluffing before they have to show discovery which is the same time they can “throw the book at the defendant” (overload the charges beyond what they can actually prove to a jury).It’s also worth mentioning that the speedy trial can sometimes come with strings attached (as Georgia’s statute which has been recently discussed ad nauseum in the cases of 2 of the 19 2020-electoral-college-RICO defendants) reply l33t7332273 15 hours agorootparentprevI’m not following what that has to do with a speedy trial. reply nvahalik 15 hours agorootparentprevSee: January 6th. There are still many people in jail who haven&#x27;t been to trial. reply jeffbee 15 hours agorootparentA person who is in jail awaiting trial for attempting to overthrow the government of the United States is not a \"political prisoner\". reply ipaddr 15 hours agorootparentIn many cases they would be if they subscribed to a political ideology and committed acts because of them.In this case overthrowing is actual a protest that went out of control because of lax security. A real overthrow attempt would need to involve heavy weapons. Protesters didn&#x27;t even have butter knives. reply l33t7332273 14 hours agorootparent> In this case overthrowing is actual a protestOnly for some of the people involved. However, there were certainly people there attempting an actual overthrow[1][1] https:&#x2F;&#x2F;www.theguardian.com&#x2F;us-news&#x2F;2022&#x2F;jan&#x2F;14&#x2F;oath-keepers... reply sethrin 15 hours agorootparentprevThose aren&#x27;t \"political prisoners\", they&#x27;re merely normal criminals, but there&#x27;s so many of them that the justice system is having a hard time dealing with it. There are only so many federal judges and prosecutors. reply thephyber 15 hours agorootparentprevThey are not political prisoners. They committed federal crimes while live-streaming it and the government has presented the evidence. It just so happens that the amount of evidence they generated while committing crimes overloaded the DOJ’s capacity to collect and organize it (both prerequisites for discovery by the defendants before they can build their defense).There have been a few defendants who have successfully challenged the speed of the trial and courts have let them off. It’s far more likely that the DOJ attorneys are simply overwhelmed with the prosecution than they are purposefully persecuting the arrested.> According to the George Washington Program on Extremism, the FBI has arrested 940 people in connection to January 6. Of those, 43 were convicted, 481 pleaded guilty, and 382 are still waiting for trial. Most of the people waiting are out on bail. [1]It so happens that the defendants all committed crimes on the same day, causing a backlog in prosecution work. It also happens that DC is a strange jurisdiction that requires coordination between federal officers of different departments (Capitol Police, Parks Police, Secret Service, etc) in a town that must get all funding passed through Congress, which is functionally broken most of the year.Terrible example of time-to-trial problems in the US, which is actually a significant issue, even in well funded jurisdictions.[1] https:&#x2F;&#x2F;newrepublic.com&#x2F;article&#x2F;170991&#x2F;cpac-january-6-riot-p... reply joshuamorton 15 hours agorootparentprevhttps:&#x2F;&#x2F;www.thecity.nyc&#x2F;2022&#x2F;8&#x2F;17&#x2F;23310771&#x2F;why-some-spend-ye...Pretrial detention can often happen for years, it&#x27;s one of the issues that makes guilty pleas so insidious. Even if you are innocent, wanting to get your day in court can require you to spend months in jail, so a guilty plea can actually be the more economical outcome. reply bsimpson 15 hours agorootparentI appreciate the context link.It&#x27;s worth noting that one of the examples was someone changing his lawyer repeatedly. I don&#x27;t believe the right to a speedy trial is violated if you&#x27;re the one that causes your own delay. reply banannaise 15 hours agorootparentprevI&#x27;m referring to the maximum length of detention under the German law being used (if I&#x27;m reading things right). I am aware that the US has some pretty serious problems that are at least somewhat related, but I&#x27;m trying not to digress into that. reply skrause 15 hours agorootparent> I&#x27;m referring to the maximum length of detention under the German law being used (if I&#x27;m reading things right).It&#x27;s not a German law but a state law. Some states only allow 4 days, Berlin only 2 days: https:&#x2F;&#x2F;de.wikipedia.org&#x2F;wiki&#x2F;UnterbindungsgewahrsamOf course it&#x27;s Baravia which allows the (by far) longest detention with two months. reply formerly_proven 15 hours agorootparentprevThis is outside criminal procedure, which is a federal matter. Since it&#x27;s not a criminal proceeding, criminal courts don&#x27;t have jurisdiction, and the rights you have in criminal proceedings do not apply. This is a state administrative matter instead. Legally speaking, this solitary detention is not even a punishment. reply znpy 15 hours agorootparentprevIt seems that GP has deleted their comment before anyone else could reply.I&#x27;ll report it here, verbatim, as i still have it open in another tab:-----Are you talking about US citizens?I&#x27;m unaware of that in any recent decades, and I assume you&#x27;re talking about recent history.More complicated cases take longer to prepare for trial, but can you point to a single example of a US citizen jailed for political purposes where their trial has clearly been delayed for political reasons?-----and here is what i wanted to reply:> I&#x27;m unaware of that in any recent decadeshttps:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=xuAAPsiD768 - \" The secret US prisons you&#x27;ve never heard of beforeWill Potter\" reply pc86 15 hours agorootparentJails and prison are different. reply morkalork 15 hours agoparentprevNo idea, just wanted to chime in with \"you may beat the rap, but you can&#x27;t beat the ride!\" reply IMTDb 15 hours agoparentprevMost payments are done using SEPA mandates. The money automatically leaves your account, but you still get a piece of paper with the details.I don’t remember paying a single bill manually for the past 3 years at least. Credit card is paid in full at the end of the month as well automatically. reply pc86 15 hours agorootparentWhich all comes grinding to a halt pretty quickly when you stop getting paid because you&#x27;re in jail.I&#x27;m not sure about Germany specifically, but in the US the vast majority of people live paycheck-to-paycheck regardless of income bracket. Most are 2 weeks away from starting to have failing bill payments. reply Xylakant 15 hours agorootparentThe rules about not paying employees for absences are a bit more difficult in Germany. Voluntary unannounced absence or unpaid vacation would be the simple cases, but involuntary absences don’t entitle the employer immediately to withhold payment, at least not for most employees on a fixed term contract. Things get more involved for workers that get paid by the piece. Freelancers would probably be the most hard hit here.This would pretty clearly be an involuntary absence - these folks are not even accused of committing a crime. reply c4mpute 15 hours agorootparentAbsence is reason to withhold payment in Germany, you can only expect continued payment if you are absent because you are ill (and then only for a certain period). There are some provisions like having to pay out leftover holidays and overtime before stopping payments altogether, but payment is contingent on really working in general.Note that this is different from ending employment: If you are in jail, only an extended length of absence (usually 2 years) or a work-related crime is reason for dismissal. If you are in jail for 23 months you&#x27;ll keep your job usually, you are just not getting paid. reply Xylakant 15 hours agorootparentBGB 616: https:&#x2F;&#x2F;www.gesetze-im-internet.de&#x2F;bgb&#x2F;__616.html> Der zur Dienstleistung Verpflichtete wird des Anspruchs auf die Vergütung nicht dadurch verlustig, dass er für eine verhältnismäßig nicht erhebliche Zeit durch einen in seiner Person liegenden Grund ohne sein Verschulden an der Dienstleistung verhindert wird.The key terms here are “verhältnismäßig nicht erhebliche Zeit” and “ohne Verschulden”. That means that if you’re absent a relatively short time (usually compared to the duration of the employment and the notice period) and without being at fault for the absence, you get paid.There’s a lot of interpretation here: for example if your bus is late, you’re responsible (you could have taken an earlier bus), if there’s an announced strike, you’re still at fault - you knew before etc. The cause must also lie in your person specifically - if you’re stuck in traffic with hundreds of other employees due to an accident, the paragraph does not apply. If you’re missing out on work because you were involved in that accident, it does.But being imprisoned without having committed a crime is very unlikely to be considered a fault of the employee.Your work contract or collective bargaining agreement may modify or specify where this paragraph is applicable. No legal advice, not a lawyer,… reply c4mpute 14 hours agorootparent> But being imprisoned without having committed a crime is very unlikely to be considered a fault of the employee.I would (without being a lawyer and without having a case to cite) suspect that in those cases it would be considered to be the fault of the employee. In many, if not all cases, they had prior arrests, indictments and some were even found guilty, yet announced further blockades. I guess to a judge, that should make it their fault.> Your work contract or collective bargaining agreement may modify or specify where this paragraph is applicable.That might very well be the case, since actually many protesters are being employed as protesters: https:&#x2F;&#x2F;www.stern.de&#x2F;gesellschaft&#x2F;letzte-generation--so-viel... reply Xylakant 13 hours agorootparentYou have to be very careful with the word suspect here. No crime has been committed, not even alleged. The allegations are that the arrested may in the future cause disruptions - it’s currently even unclear whether these acts are crimes, misdemeanors or even public demonstrations and as such protected by law and the constitution. Legal opinions and court decisions are all over the place.The jail time is even more problematic given that the acts that the imprisoned may commit in the future are not punishable by prison time in practically all cases.(As a side note: I would also be extraordinarily careful citing an article in the Stern, which cites allegations that the Welt published, without having at least a second source that confirms it) reply c4mpute 12 hours agorootparentMost reasons in §14PAG for preventative arrest include a crime or misdemeanor that has been committed and will likely be repeated, or the proven announcement or planning of such an offense. So most will be suspects in the literal sense, otherwise they wouldn&#x27;t be in preventative arrest: http:&#x2F;&#x2F;www.lexsoft.de&#x2F;cgi-bin&#x2F;lexsoft&#x2F;justizportal_nrw.cgi?x...Road blockades are very often judged to be coercion, \"Nötigung\", a crime according to §240 StGB. Repeat offenders in this matter have been sentenced to some jail time: https:&#x2F;&#x2F;www.merkur.de&#x2F;deutschland&#x2F;kleber-aktivisten-letzte-g...Further sources for your side note: https:&#x2F;&#x2F;www.merkur.de&#x2F;welt&#x2F;verdienst-klima-krise-kleber-geha... https:&#x2F;&#x2F;www.businessinsider.de&#x2F;wirtschaft&#x2F;letzte-generation-... https:&#x2F;&#x2F;www.sueddeutsche.de&#x2F;wirtschaft&#x2F;letzte-generation-akt... https:&#x2F;&#x2F;www.magdeburger-news.de&#x2F;?c=20221228093058Oh, and the best source, their own wiki: https:&#x2F;&#x2F;wiki.letztegeneration.org&#x2F;de&#x2F;%C3%B6ffentlich&#x2F;allgeme... replysabjut 15 hours agoparentprevDo you really pay you bills manually each month? When regular payments (like rent) are not debited directly from my account, I set up an auto transfer that sends out rent to my landlord at the 1st day of each month.How does this work in the US? reply kelnos 15 hours agorootparentIt... depends.Personally, I have everything automated. Including one incredibly dumb thing: I have to pay my homeowners&#x27; association dues (I live in a small condo building, so we have shared expenses) by check, so I have my bank mail a check to their bank. It&#x27;s incredibly dumb that I can&#x27;t easily set up an automated electronic bank transfer, but at least I can automate mailing a paper check.US government agencies can also be annoying about this. For example, the city&#x2F;county of San Francisco does not offer a way to automatically pay property taxes, which are billed twice a year. (My mortgage lender pays mine for me via an escrow account that gets funded along with my automatic monthly mortgage payment.)But a lot of people in the US are un- or under-banked, and don&#x27;t always have access to automation, if the people&#x2F;orgs they have to pay support any kind of automation at all. Many landlords (especially those who cater to lower-income folks) will only accept cash or check. Many people who have to pay them don&#x27;t have an online bill-pay system. And even many who could automate things, don&#x27;t, because their finances are precarious enough that they will sometimes choose to skip a credit card payment, or pay their rent late, etc., and they&#x27;ll make these decisions month-to-month.If many people in the US were in jail for two months, after the first month (of not working, thus not getting paid) they wouldn&#x27;t have enough money in their bank account to cover all their monthly bills. An unfortunate amount of people here live paycheck-to-paycheck.Also consider that there&#x27;s a lot of overlap between people who have unstable finances and people who are more likely to get caught up in the justice system, regardless of their innocence or guilt. reply inglor_cz 15 hours agoparentprev\"and become 30+ days late on all of their bills since you cannot pay bills from jail\"Do Americans have to authorize all their recurring payments every month again and again? I certainly never paid such bills \"one by one\"; I set up a regular monthly payment and it would be done automatically on the Nth day of a month. reply cableshaft 15 hours agorootparent60% of Americans live paycheck to paycheck, so this wouldn&#x27;t matter. If they&#x27;re not making money in jail they can&#x27;t pay their rent, even if they have autopay set up.https:&#x2F;&#x2F;ir.lendingclub.com&#x2F;news&#x2F;news-details&#x2F;2023&#x2F;60-of-Amer... reply thfuran 15 hours agorootparentprevSome people choose not to set up automatic payments, and the percentage of people who are living paycheck to paycheck or nearly so is high enough that, even among those who do, probably a significant percentage would see the second month&#x27;s payments fail if they were set up using a bank draft or debit card rather than a credit card. reply banannaise 15 hours agorootparentprevSome bills can&#x27;t be autopaid either easily or at all, particularly utility bills. For those that can be autopaid, many people don&#x27;t have them on autopay because of potential disruptions when living paycheck-to-paycheck. If you have to choose between food and rent, you better not have the rent on autopay, or you&#x27;ve accidentally made your choice. reply eddtests 15 hours agorootparentprevI lived in America for two years and everything was automated reply znpy 15 hours agoparentprev> become 30+ days late on all of their bills since you cannot pay bills from jailcan&#x27;t americans bind the utilities to their checking account? i (european) can do that. the bills are paid automatically from my balance (the same where i receive my salary). the web portal from my bank can lists all the entities allowed to pay bills from my balance, and i can revoke any of them unilaterally (in that case i&#x27;d have to go back to pay the bills one by one, manually). reply Blackthorn 15 hours agorootparentThey can but that&#x27;s generally not the problem. You aren&#x27;t getting paid while you&#x27;re in jail, so those payments are likely to bounce (Americans often live paycheck to paycheck). reply SirMaster 15 hours agorootparentWhy not bind them to their credit cards then?All my bills go to credit cards and I even get 2% cash back on them all that way too.I guess you will run into your credit limit that way eventually too if you are behind on payments for it. reply matricaria 10 hours agoparentprevThe people glueing themselves to the street don’t have any other job. They get payed to do exactly this. reply throw74848 15 hours agoparentprevIt is almost impossible to fire long term employees in Germany. But getting proper employment is very difficult for this reason. Most people are on yearly contracts, part time jobs etc... reply Xylakant 15 hours agorootparentThis is just false, plain and simple. I’ll just take one of your statements and refute it, because the other parts are so broad and generalizing that you’ll just come around and make other shit up:The share of part-time employment in Germany was 7.4% of all employment contracts in 2021. Nothing significant changed since then. https:&#x2F;&#x2F;www.destatis.de&#x2F;DE&#x2F;Themen&#x2F;Arbeit&#x2F;Arbeitsmarkt&#x2F;Qualit... reply sho_hn 15 hours agorootparentprev\"Most people\" is seriously wrong, statistically, but it&#x27;s a significant number. reply throw74848 15 hours agorootparentMost new employees and new job openings, would be correct formulation. German job market is very static. reply Xylakant 15 hours agorootparentPlease provide a citation. In 2022, about 30% of new hires had a term limit. The peak was in 2004, with about 54% at a time when very few positions were available.https:&#x2F;&#x2F;doku.iab.de&#x2F;arbeitsmarktdaten&#x2F;Befristungen_bei_Neuei...I already cited the share of term limited contracts above.It’s not surprising that term limited contracts are a significant chunk of the Job offerings, even if they are a small share of the total contracts - a job posting that must be renewed annually will appear every year for the same position, while an unlimited contract only opens up when a replacement must be found or a new position is created. Another cause is that a lot of companies use a limited contract as a trial period and later convert to an unlimited contract at renewal time.It is absolutely true that some sectors suffer from having a huge chunk of limited contracts (academia for example) and that there’s abuse (auxiliary teachers only being employed during the term and made redundant during vacations), but generalizing this to the entire German job market is neither warranted nor helpful. reply sawmurai 13 hours agorootparentThis is a good demonstration of how much more work it is to refute bogus statements than it is to make them. replyexpertentipp 15 hours agorootparentprevAbsolutely untrue. Source: was fired from indefinite employment contract in Germany. If they hate you and start throwing at you Abmahnung, Aufhebung, and Kundigung, you need a lawyer immediately and the pile of papers and letters starts growing exponentially. reply pelasaco 15 hours agoparentprev> Is the situation for short-term prisoners similar in Germany?Probably none of those kids have a Job, so no worries. reply mylons 15 hours agoparentprevi hope you go to jail in a german prison because you supported nuclear power reply imp0cat 15 hours agorootparentNah, you can buy a filter in Germany that goes between your wall socket and appliance. The device makes sure that only \"good\" electricity (ie. the kind that was generated by your preferred source) powers your appliances.I wish I was kidding. reply marcc 15 hours agorootparentGot a link? I&#x27;m not sure how this would even work, but if you aren&#x27;t kidding, I&#x27;m curious to read the marketing. reply mylons 15 hours agorootparentprevit’s wild how isaac asimov saw the future history societal decline. reply croc_socks 16 hours agoprevProtest or vandalism? I don&#x27;t think destroying property especially art, businesses is a good way to get people on your side. reply burkaman 15 hours agoparentNeither, \"preventative detention\" means this is not a response to any specific action. reply c4mpute 12 hours agorootparentIt may be a response to specific circumstances like carrying blockade gear, announcements made by the people in question or past crimes: https:&#x2F;&#x2F;www.gesetze-bayern.de&#x2F;Content&#x2F;Document&#x2F;BayPAG-17 reply almostnormal 14 hours agorootparentprevI want to believe that there was a \"specific action\". An explicit announcement to block a road &#x2F; airport &#x2F; whatever.Unfortunately, it is cheaper for the gonvernment to detain people than to send police to prevent it shortly before it is going to happen.Also, the ruling party in Bavaria is mainly controlled by the opinions people exchange in pubs over a couple of beers (one beer being a quarter gallon), and there common sense isn&#x27;t considered that much. reply anigbrowl 15 hours agoparentprevNo art has been destroyed, it all sits behind glass so it&#x27;s just a matter of cleaning&#x2F;replacing the frame for the painting. And much as I love art, I think throwing food or paint at it is a good reminder that while you can make more art you can&#x27;t bring back lost species or ecosystems. reply raverbashing 15 hours agoparentprevIf anyone LSO&#x2F;LG have earned the \"reputation\" for destructive or disrupting stuntsI actually do think they&#x27;re indirectly being financed by the oil industry (LSO head figures go around in private jets) to antagonize and create a bad (but not unrealistic) caricature of the climate protestors. And of course there&#x27;s plenty of people willing to play the rolesGreta looks like the serious grownup compared to LSO reply sinkwool 15 hours agorootparentNever attribute to malice that which can be adequately explained by stupidity. reply wiz21c 15 hours agorootparentprevWhat is LSO&#x2F;LG ? reply raverbashing 15 hours agorootparentLet&#x27;s Stop OilLetzte Generation reply nrvn 5 hours agoprevCovid-19 lockdown proved what is deemed to be an uncomfortable truth: the one and only source of negative climate effects is us. 8 billion people is too much for that planet to handle. In 1900 there was around 1,000,000,000 and it was already too much.We are among the most populous mammals on earth.Sorry for those romantic individuals who think they can fight with a “protest”. reply woodpanel 15 hours agoprevI’m somewhat in disbelief that there’s actually a state within the German federation that hasn‘t forgotten the terror of the RAF, which the „Letzte Generation“ ticks all the boxes of becoming too, for they are of the same ilk: pampered upper class kids in an astroturfed cult.https:&#x2F;&#x2F;www.eugyppius.com&#x2F;p&#x2F;activism-agency-and-the-escape-f...? reply matricaria 10 hours agoprevWhy is this on HN? This violates a lot of the guidelines.- Not the original source - It’s on national news, one of the biggest newspapers - Off topic reply xyst 15 hours agoprevThis state will jail people for potential terror acts. yet won’t do anything about the actual terror brought upon by the O&G and auto industry through their dangerous products and by products (in the case of cars, micro plastics in the form of tire wear particles, brake dust, and of course car emissions if ICE).Millions die every year due to man made climate change yet governments jail these people.This world is fucked m8 reply l33t7332273 14 hours agoparentI’m unsure about your claim of millions of annual deaths.What are the main causes of these deaths? reply c1sc0 5 hours agorootparentDeaths attributed to air pollution by fossil fuel alone are in the millions. reply l33t7332273 5 hours agorootparentIs that per year?If so, what is the actual cause? Suffocation? Cancer? reply dauertewigkeit 14 hours agoparentprevGermany is currently bankrupting itself and possibly destroying its economy to go forward with the green transition. You need a reality check. I actually don&#x27;t believe that we could do more than we are already doing. reply ryan93 15 hours agoparentprevMillions??? Also the people who release the co2 from those products are consumers. Consumers(i.e. everyone) is not gonna vote to convict themselves of doing a yearly holocaust. reply itishappy 14 hours agorootparentConsumers also bought and leaded fuel and arsenic insolation. Many of us are capable of updating our assessment of the dangers around us. reply snehk 3 hours agoprevThey don&#x27;t do climate protests. They harass people and destroy property.Next time I break the law I&#x27;ll just say I did it in the name of human rights and then complain when I don&#x27;t get to do whatever I want. reply matricaria 10 hours agoprevI think the main reason they Bavarian government is doing this is because we have an election this fall. They government parties would otherwise lose a lot of votes as the majority of the population disagrees with those „protesters“. reply waihtis 15 hours agoprevGood. These idiots are a net harm to the climate change cause. The only thing they have managed is accelerated resentment towards pro climate activities.It is fully possible I have a naive interpretation of their goals and perhaps they&#x27;re just looking for an excuse to be the biggest twats possible. reply sho_hn 15 hours agoparent> The only thing they have managed is accelerated resentment towards pro climate activities.I&#x27;m not so sure about that. I see a fair number of people who got woken up to how serious things are by these protests as well. Before they saw this kind of thing on the news, it didn&#x27;t strike them as particularly real. It&#x27;s a \"sign of the times\" for them. reply lowkey_ 15 hours agorootparentHow have they expressed that? How has it changed their minds?I&#x27;d be genuinely amazed at the personality of a person who goes \"Wow! They must be disrupting my day for a very important reason. Let me look up and better research their cause,\" versus \"Oh f**, I&#x27;m going to be late to my appointment. What&#x27;s going on? Oh, these idiots are blocking the street.\"If you&#x27;re going to interrupt my life based on some future, uncertain scientific reasoning, especially the lives of everyday working-class people who can&#x27;t afford to spend their day blocking streets instead of working, it would turn me off to your cause, and that&#x27;s the only sentiment I&#x27;ve heard from my friends.Maybe we&#x27;re wrong for that, but I&#x27;m curious how others would respond. reply c1sc0 5 hours agorootparentIt definitely would be better digested by the general population if their actions avoided targeting the working class, like they did recently with blocking private jets. reply sho_hn 15 hours agorootparentprevI think there&#x27;s plenty of people who are surprised that some people take the climate situation as seriously enough that they would organize and do this, especially when others chime in with \"you should expect more of this, the coming decades will see a lot of things destabilize\". I&#x27;ve not encountered much anti-activism sentiment, at most a \"they have a point, but it&#x27;s the wrong way to do it\".I&#x27;ve not seen anyone leave their gasoline engine on idle on their behalf to spite them. reply bonzini 15 hours agorootparentprevIn Italy they threw paint at statues, damaging them because they thought \"washable\" paint would be easily cleaned with water. Whereas it&#x27;s the kind that most thoroughly repels it. That&#x27;s not the way to get random people&#x27;s sympathy. reply kelnos 15 hours agoparentprevEven if their methods are counterproductive, no one deserves to be jailed for things the state thinks they might do.Thoughtcrime and Minority Report-style policing is unjust and contrary to the principles of a free society. reply ivan_gammel 14 hours agorootparentIt’s not exactly that. This group (as a whole, maybe not the specific people) committed to continue their actions and people from it released in the past were participating in blockades again. It’s definitely not a Minority Report-style prediction of what they could do based on affiliation, personality etc.Besides, it’s not just blocking highways or streets. They blocked runways in airports too - imagine what could happen if a plane with failed engine could not land because of them. reply AnnikaL 12 hours agoparentprevObnoxious people have rights too. reply aaomidi 15 hours agoparentprevSo you’re happy that the state can arrest anyone for months because they dont like your speech?Wild reply lowkey_ 15 hours agorootparentSpeech is not the same as blocking traffic. You have every right to your speech, but you don&#x27;t have a right to force me to stay and listen to it. reply aaomidi 13 hours agorootparentSo arrest them when they do that?These people haven’t been charged with anything. It’s “preventative”. reply waihtis 5 hours agorootparentTaking preventative action against known bad operators is morally the right option. reply aaomidi 5 hours agorootparentCharge them with the conspiracy to do a crime then?But wait you can’t, cause that won’t actually hold up in any actual court.“Bad operators” - they’re doing more for the climate than the rest of us are. reply waihtis 5 hours agorootparentThey&#x27;re literally the \"thoughts and prayers\" of climate change except they&#x27;re also disturbing the public and destroying property. replyjkingsbery 15 hours agoprevI don&#x27;t know much German, so I can&#x27;t read the original article.It would be helpful to know if by \"they might otherwise engage in climate protests,\" the people in question had planned to just say things but otherwise stay out of the way, or if rather the people in question had made public their plans to break laws (like blocking traffic, which many climate protesters have been doing lately). In the one case there is no crime, and governments shouldn&#x27;t be detaining people just in case they commit a crime later. In the other case, even if someone isn&#x27;t a terrorist, planning on breaking the law is itself a crime, and it&#x27;s not \"preventative detention.\" reply roywiggins 15 hours agoparentThey haven&#x27;t been convicted of anything, they&#x27;re being detained anyway. This is not the same as pre-trial detention, if Google Translate is a remotely accurate rendering of the linked article:\"Legally, this police approach is called preventive detention because it is not detention for a crime that has been committed. The police laws of the different states allow this for different lengths of time. In Bavaria, up to one month in prison is permitted, which may be extended by a judge for a maximum of another month.The so-called preventive or preventive detention is very controversial. The relevant laws were originally created to prevent terrorists from carrying out attacks. However, this form of detention is now also permitted in the case of the “imminent commission or continuation of an administrative offense of considerable importance for the general public,” as the Bavarian police law states. Lawsuits against this have so far been rejected in Bavaria. However, a final clarification about the legality of this approach is still pending.\" reply jimnotgym 15 hours agoprevIs the real crime here something about upsetting BMW? The German car lobby remains strong I see reply onionisafruit 15 hours agoprevIs there an English language article about this? reply andrewstuart 15 hours agoprevIt’s the beginning of the climate revolution.It’s going to be real ugly I can tell you that for sure.The children have no future. The old have accumulated ownership of pretty much everything.A generation with nothing to lose.EDIT no climate future reply googlryas 15 hours agoparentThe interesting thing about old people is they tend to die, and bequeath their properties to their children. reply michaelteter 15 hours agorootparentBut their children tend to think and act as the parents did, especially when they are insulated from reality by wealth. reply nickserv 15 hours agorootparentprevThere&#x27;s a good chance Brexit would not have happened if the vote was done today, simply because of old people dying off (most over 65 voted for, most under 35 voted against).It does look like a lot of climate legislation is facing similar situations, where the boomer generation is voting opposite to younger generations.In both cases it&#x27;s frustrating because the younger generations are the ones that will have to deal with the consequences of laws they did not agree with. reply itishappy 13 hours agorootparentprevProperty and politics.Property tends to go to descendants, but politics affect all. reply c1sc0 13 hours agorootparentprev… to their children who won’t have much use for said property because of how fucked up their situation has become as a direct consequence of how that property was earned in the first place … reply googlryas 12 hours agorootparentYou are either extremely misinformed about climate change, or are intentionally being melodramatic. reply c1sc0 5 hours agorootparentThat’s exactly how many in that generation feel, let down & angry, which makes their actions easy to understand. reply barrysteve 15 hours agorootparentprevWe replaced expansionist policy with children inheriting wealth.It&#x27;s not a soothing platitude for the next generation, that the most they can work towards is inheriting their father&#x27;s achievements.Let&#x27;s be honest, if we&#x27;ve come this far down the &#x27;argument heirarchy&#x27; for growth and expansion, we know things are bad. reply mistermann 15 hours agorootparentprevTrue, but what of those who do not have wealthy parents? reply aunty_helen 15 hours agorootparentprevNow you’re catching on reply marcusverus 15 hours agoparentprevThe fact that the old own much, much more than the young isn’t a bad thing—it’s evidence that the economy is a wealth-creation machine which works quite well. A 60 year old has been working 4x years longer than a 30 year old. The average dollar a 30 year old saved between 20-30 has, by the time they’re 30, grown for five years to ~$1.30 (assuming historical S&P returns), while the average dollar a 60 year old saved from 20-30 has grown for 35 years to ~$7.20. Any system where the old didn’t own much more than the young would be a nightmare.> A generation with nothing to lose.That’s what they said about millennials. Now the average millennial is 34, has kids and owns their home. Isn’t it just the pits when the system turns your would-be revolutionaries into homeowning parents with a stake in the success and stability of the system? Maybe it’s oppressing them through prosperity? reply kelnos 14 hours agorootparent> Now the average millennial [...] owns their homeI found this suspect, and looked up some stats[0]. It&#x27;s hard to tell exactly, since the age groups don&#x27;t fall on generational boundaries. But it does seem like ~50% of millennials own a home.However, the more concerning trend is that rates of home ownership have declined across all age groups since 2009[1]. In particular, the age of the average homeowner increased by 10 years between 2001 and 2019.[0] https:&#x2F;&#x2F;ipropertymanagement.com&#x2F;research&#x2F;homeownership-rate-...[1] https:&#x2F;&#x2F;ipropertymanagement.com&#x2F;research&#x2F;homeownership-rate-... reply marcusverus 12 hours agorootparentThe homeownership rate was high in ‘09 because of the real estate bubble. Homeownership rates are fine from a historical perspective[0] and are trending up.[0] https:&#x2F;&#x2F;fred.stlouisfed.org&#x2F;series&#x2F;RHORUSQ156N reply bad_user 15 hours agoparentprev> The children have no future. The old have accumulated ownership of pretty much everything.This is in general a myth. If you look at millennials or gen-z, ownership at their age isn&#x27;t any different from the boomer generation. And it&#x27;s still the best time to be born in.We can all agree that climate change is a problem to be solved, but \"the old\" can remember plenty of doomsday scenarios that never happened, including past predictions that global warming would destroy the world by year 2000.In the meantime, activists that prevent people from going to work, or that destroy property, are just jerks IMO. reply anigbrowl 15 hours agorootparentpast predictions that global warming would destroy the world by year 2000This is a bullshit conservative trope. I&#x27;m 53 and no such prediction was ever advanced as a basis for policymaking. Just because someone might have made such a hyperbolic prediction in a TV show or magazine doesn&#x27;t mean it ever had widespread currency in the scientific or policy community.Please stop poisoning the well. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Poisoning_the_well reply bad_user 12 hours agorootparentThe world has a long history of bad predictions. Search for example for the predictions made with the advent of the first Earth Day, 1970.Some predictions were more accurate than others, which led to effective policies, so for example, thankfully, we still have an ozone layer and we haven&#x27;t started a nuclear war yet.Not sure what \"poisoning the well\" is supposed to mean here. I was replying to someone that predicts some sort of violent revolution. For what, I can only guess. reply GaggiX 15 hours agorootparentprevYeah this is what I believe, I&#x27;m very young and I imagine that the parent post is talking about my generation but I cannot really stand with these people, they, for example, rally against nuclear energy, it just show how performative these protests are in reality, and how they do more harm than good. Also of course vandalizing properties has given them a certain reputation. reply failuser 15 hours agoparentprevThe wealth is skipping a generation. That would be a very strange age&#x2F;role reversal. reply barrysteve 15 hours agoparentprevWe have to walk away from the old ways, no doubt. reply SahAssar 15 hours agoprevThe linked site in the toot almost certainly violates the GDPR since it requires either payment or tracking consent to access. Requiring payment is fine, but forced consent is not. reply fuzzbazz 13 hours agoparentI don&#x27;t think so, the GDPR requires to ask for consent but nobody is being forced to press the \"I consent\" button. Additionally I&#x27;d guess the website of a German newspaper of record is not breaking the law. reply SahAssar 12 hours agorootparentIt most probably is. See a similar case recently in Germany: https:&#x2F;&#x2F;www.iubenda.com&#x2F;blog&#x2F;understanding-consent-and-cooki...And there is absolutely a great number of major European news and media companies willingly ignoring the GDPR. Most people even remotely interested know this. reply jansan 15 hours agoprevThere is very little sympathy with them by the common people. They have really overdone it with sabotaging common people&#x27;s everyday life and calling it a \"peacful protest\". By that logic locking them away for a few days can also be described as peaceful. reply Simulacra 12 hours agoprevIn a situation where a person in continually causing a disruption to the lives of others - in some cases infringing on their rights - then preventive detention may be the only remedy. reply bsimpson 16 hours agoprevSeems appropriate on 9&#x2F;11 to read about anti-terrorism laws being used to impinge on regular people&#x27;s civil liberties. reply Lennart4711 15 hours agoparentGerman here. In the article it says the law is there to prevent terrorism. But 9&#x2F;11 isn&#x27;t such a big deal here in Germany (except maybe for traveling). The problem is that those people can be detained for \"bevorstehenden Begehung oder Fortsetzung einer Ordnungswidrigkeit von erheblicher Bedeutung für die Allgemeinheit\" - \"imminent commission or continuation of a misdemeanor of substantial public concern.\" So they are arrested to prevent misdemeanors which only come with a fine or a super short jail time.IMO the real reason for this is to protect the automotive industry which is a large part of the German economy reply WatchDog 15 hours agoparentprevCan’t read the source article, we’re anti terror laws used for these arrests? Or have German police long had these sort of powers?I guess their activities fall under some weak definition of terrorism, intimidation against civilians in pursuit of political aims. reply bsimpson 15 hours agorootparentI don&#x27;t have the article open anymore, but yes it did say they were being detained under laws originally written to target terrorists. reply 80 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Mastodon.energy is a server tailored to professionals and academia, focused on discussions about energy transition initiatives including policy, infrastructure, technology, journalism, and science.",
      "The platform's recent discussions revolve around the preventative detention of climate activists in Bavaria, Germany, who may protest at the car industry exposition IAA in Munich.",
      "The detention, which can last up to 60 days, has been criticized by members on the server who have drawn parallels with similar cases in other countries, viewing it as an attempt to criminalize climate activism."
    ],
    "commentSummary": [
      "The post discusses various topics including the incarceration of individuals in Germany due to participation in climate protests.",
      "It also highlights the debates on the efficiency and acceptability of disruptive protests, and concerns about police prioritization and potential misuse of power.",
      "Additional issues include discussions on employment practices, generational wealth, home ownership, and preventive detention and trial delays in the context of climate change activism."
    ],
    "points": 253,
    "commentCount": 339,
    "retryCount": 0,
    "time": 1694455259
  },
  {
    "id": 37465972,
    "title": "The right to data ownership is the only way to take on Big Tech",
    "originLink": "https://www.telegraph.co.uk/business/2023/09/11/right-data-ownership-big-tech-google-meta-competition/",
    "originBody": "Jump to content UK NEWS WEBSITE OF THE YEAR News Sport Business Opinion Ukraine Money Royals Life Style Travel Culture Puzzles Subscribe now Free for one month Log in Alex Economy Companies Markets Tech COMMENT The right to data ownership is the only way to take on Big Tech Competition enforcement by nations has had little impact – it’s time to experiment with capitalism ANDREW ORLOWSKI 11 September 2023 • 11:00am Today, giant technology companies are more powerful than any nation state. Their whims set the political agenda.... Related Topics Big tech, Artificial Intelligence, Google, Silicon Valley 48 To continue reading this article ... Try The Telegraph free for 1 month Unlock this article, plus unlimited access to our website and exclusive app with a Digital Subscription. Cancel anytime. START YOUR FREE TRIAL Already a subscriber? Log in Advertisement More stories The ‘deluded’ new way young women are justifying unbridled spending Irish fan ‘abducted and gang raped’ by three men after watching Rugby World Cup match ‘My state pension is £150 a week – why do so many others get more?’ Why Freddie Flintoff’s Top Gear crash could plunge the BBC into another crisis Man who invoked Dad’s Army with ‘stupid girl’ comment guilty of sexism Antiques Roadshow expert asks guests whether they would repatriate ancestor’s African artefacts More from Business iPhone 15 launch today: Release date, price, and new features By Matthew Field 12 Sep 2023, 11:04am Google antitrust lawsuit 2023: The tech giant heads to court as Biden cracks down on monopolies By James Titcomb 12 Sep 2023, 10:21am Aldi and Lidl lose ground to British supermarkets in fierce price war By Hannah Boland 12 Sep 2023, 8:00am Live Markets Record wage growth ups chance of interest rate rise next week – latest updates By Chris Price 12 Sep 2023, 8:00am British businesses are terrifyingly exposed to the Chinese threat MATTHEW HENDERSON 12 Sep 2023, 7:00am Shares in this packaging company deliver value despite post-pandemic tumble By Russ Mould 12 Sep 2023, 6:00am More from The Telegraph Record wage growth ups chance of interest rate rise next week – latest updates Exoplanet 120 light years from Earth hints at possible life and rare oceans Politics latest news: Angela Rayner vows to strengthen trade unions if Labour wins election HMRC’s latest blunder is exactly why it is losing our trust ‘Rishi Sunak needs a new tailor and King Charles’ suits require more pressing’ Rugby fans unite in outrage over ‘butchered’ World Cup anthems",
    "commentLink": "https://news.ycombinator.com/item?id=37465972",
    "commentBody": "The right to data ownership is the only way to take on Big TechHacker NewspastloginThe right to data ownership is the only way to take on Big Tech (telegraph.co.uk) 231 points by timthorn 22 hours ago| hidepastfavorite175 comments DrScientist 20 hours agoIn reality isn&#x27;t this really quite simple - it&#x27;s the theft of privacy. Data is the concrete thing of course, and therefore potentially useful to then put a legal framework around - but in the end it&#x27;s really about the right to privacy.The loss of privacy is done by clever joining of the dots - each individual data point in itself is often not that important. It&#x27;s the activity - the joining of the dots - back to a person - which is the stalking like behaviour - that&#x27;s the problem.Ie the activity you need to regulate is the connecting of the dots back to a real world person.Let&#x27;s call it the &#x27;Digital Stalking Act&#x27; reply hooby 19 hours agoparentWhy not call it \"The right to privacy\"?Come to think of, we should even add that to the declaration of human rights!Wait a minute... reply DrScientist 19 hours agorootparentAs is often the case with these things - declaring high level rights is easy - practical enforcement is the hard part. reply jgeada 17 hours agorootparentHard in this forum frequently means technically hard, but I think in this context you mean \"politically hard\". I do not think there is a major technical problem, at the core the easiest solution is to just stop collecting arbitrary data on everyone. The issue is that the people with money and power do not want to give up control of the data they have on everyone else.It is very hard to make someone understand this if their income and power depends on not understanding it. reply DrScientist 16 hours agorootparentI meant legally hard to define.Some data is important to collect - I expect my bank to keep a record of my financial transactions! I just don&#x27;t want them to sell them on, or use them for services I didn&#x27;t sign up for.And an &#x27;opt-out&#x27; system isn&#x27;t sufficient - it needs to be an opt-in system. An opt in system that isn&#x27;t by a forced game of yes&#x2F;no bingo - it has to be one where the customer has to take the initiative.You don&#x27;t get bombarded with extra stuff being put into your basket at the supermarket checkout and then asked a series of 20 questions about whether you want to take the extra things. You shouldn&#x27;t with digital services either.Now the hard part is that legal definition between what&#x27;s the data reasonably required for the service and what&#x27;s taking the piss.I&#x27;m arguing one way to define that is whether the data use involves joining dots between transactions in a way that&#x27;s not required for the immediate transaction or service. reply hooby 4 hours agorootparentprevEnforcement of the right to privacy works (more or less) for offline privacy invasions.I believe the problem might rather be, that there&#x27;s a lack of clearness and awareness when it comes to how privacy does apply to online matters.Even technically knowledgeable people are often caught completely off guard by how much you can actually glean and deduce from very limited data. Most people wouldn&#x27;t believe how revealing some seemingly innocuous data can be, when you collect enough of it. reply jimmySixDOF 16 hours agorootparentprevI call bollocks on that, enforcement is a matter of breaking free of regulatory capture just long enough to implement a system. I am not in the thick of this discussion but think of the Number Portability legislation that carriers were forced (through enforcement) to implement and extend that right of ownership model to our data and digital identities so you can not be deplatformed by AI on a filter whim walled off from years of family photo uploads. We should have our own individual terms of service provisions that these platforms have to negotiate and agree in triplicate to before monitizing personally identifiable information to data brokers for hire. reply DrScientist 25 minutes agorootparentWhile I agree change requires determined action to overcome vested interests and inertia - I don&#x27;t think that doesn&#x27;t mean it isn&#x27;t hard.Laws are all about balancing interactions between parties. If you lived on your own there would be no need for laws.Laws police the space between people - where your right to freely do X, impinges on someone&#x27;s elses right to be free of y.Agreeing and defining that balance in a legally enforceable way is often not so easy as it first appears.But let&#x27;s be clear - I&#x27;m not using it as an excuse not to try. reply pesfandiar 17 hours agoparentprevHow could this be detected and enforced though? Rely on self-reporting?Let&#x27;s say we outlaw surveillance tools (e.g. customer data platforms). Wouldn&#x27;t this give an advantage to the big tech since they can covertly roll their own? reply dotancohen 17 hours agorootparentnext [–]> How could this be detected and enforced though? Rely on self-reporting?Presumably, the existence of such laws would preclude much of the larger companies from trying. Then, for the smaller companies, how is real-world stalking detected and enforced? Whatever that is, it might be a good start. reply seydor 17 hours agoparentprevPeivacy has been used as a distraction to distract from the main issue which is indeed the copyright of user&#x27;s data. The internet is unique in history with laws like art 230 , which allow certain companies to coopt other people&#x27;s work without paying for it on a mass scale. reply rambambram 19 hours agoparentprevIndeed, the right to ownership is a right to a right. Besides, I already have that right, that&#x27;s what ownership means.If a right that I have is violated, then there&#x27;s only one thing left. \"Possession is nine-tenths of the law\", they say, so keep your data for yourself, privately offline, if you care about it. reply DrScientist 19 hours agorootparentI get your point about not letting stuff leak in the first place - but some of that is impossible.If you buy something from a shop with anything other than cash ( some places have started no accepting cash ) - then you leave a trace as part of that transaction. Heck if you walk into a shop and pay with cash, the person at the till still sees you and may remember.Visiting web pages properly anonymously is far from trivial - it&#x27;s not as simple as refusing cookies.The problem is the selling on of that data, and the joining of the dots across large bodies of data where the sum is often greater than the parts. I would argue it&#x27;s the act of trying to build a picture of you, as oppose to the incidental accumulation of data.Kinda like the difference between people seeing you walking on the public street ( you are giving away your image and location data ), and you being followed everywhere by a stalker.At some point it crosses the line from the unavoidable, to the unpleasant. reply 13of40 18 hours agorootparentI wonder how fast they would come up with a reason to shut you down if you set up an anonymous drop shipping proxy for Amazon. 10% markup but with the guarantee that your PII never goes anywhere unless someone comes by with a warrant. reply DrScientist 18 hours agorootparentIsn&#x27;t that the issue? That the individual data point isn&#x27;t worth the 10% markup - but the accumulated ( across multiple sources ) picture that&#x27;s the problem.That&#x27;s why I&#x27;m proposing regulating joining up of the dots, rather than collection of each of the dots ( one is inevitable, the other is not ). reply trinsic2 18 hours agorootparentprevDon&#x27;t they still have those privacy payment systems? I remember back in the day using PrivateBuyer. It was an autonomous credit card like payment system. reply DrScientist 17 hours agorootparentIf you have a package there is still a delivery address.Though with the Amazon collection points - depending on your willingness to travel - you could effectively anonymise that already without the need for a third party. reply l33t7332273 19 hours agorootparentprev>you being followed everywhere by a stalkerIsn’t it legal to quietly follow someone on the street? reply DrScientist 18 hours agorootparentDepends where you live and the context.For an example see:https:&#x2F;&#x2F;www.met.police.uk&#x2F;advice&#x2F;advice-and-information&#x2F;sh&#x2F;s... reply l33t7332273 18 hours agorootparentI was thinking about US law in particular. reply somethingwitty1 17 hours agorootparentNo it may not be legal. If you continually follow someone, silent or not, it could cause a reasonable person to fear for their safety or to experience emotional distress. There is nuance to this, but just the act of continually following someone can be stalking (even if you never engage with them). reply l33t7332273 16 hours agorootparentFearing for your safety or being in emotional distress is not illegal. replymonksy 15 hours agoparentprevI&#x27;m not sure if you can call it theft of privacy. That&#x27;s a super abstract thing. Your personal data has \"no value\" (Outside the monetary punishments that come with HIPPA violations.. which gives PII value in the healthcare space).Weirdly enough, personal info has no financial value (it&#x27;s not something that be taxed, nor could it be sued for the loss of).. yet there are entire organizations and businesses that profit off of it.(This is US centric.. under the GDPR you have rights which effectively give strong value attached to it.. unfortuantely thats only protected via enforcement actions) reply GenericDev 15 hours agoprevHell yeah brother! It&#x27;s our data, we should own it.How come I can \"buy\" a movie on Amazon prime, but I can&#x27;t download it to any device I want?How come I can only stream on spotify and not purchase digital albums?Our rights have eroded so quickly and so deeply that people forget one of the biggest selling points of the original iPods was carrying around YOUR music.Everything is a subscription. You&#x27;ll own nothing, and like it.It&#x27;s our data, it&#x27;s our privacy. We should be able to own and control both. reply pjerem 15 hours agoparentTo be honest, I’m more and more going back to piracy for this exact reason. Most of the time, it’s the only option to truly own an unlocked sequence of bytes in a standard format.It’s such a shame. I’d gladly pay for movies if they gave you some DRM free file but as afaik, this still doesn’t exists. reply thedaly 13 hours agoparentprevHow can I drive in a car without having my data about my sex life sold to the highest bidder?https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37443644 reply andrewxdiamond 15 hours agoparentprevIronicly everything you’ve listed here is an example of companies expressing their rights to control their data. You don’t own music or movies, they aren’t your data.Data rights are for data about you and your behavior. If you retained copyright over all the data you produce by existing, you would be on the same level as companies today reply bobbruno 13 hours agorootparentWhile your point is valid, we’ve had (maybe for lack of a feasible alternative, but still), for many decades, the option to purchase a physical copy of media that was under our sole control and available for as long as the media itself lasted. We still have these options, but there is a clear preference of companies to sell a “subscription”, where our access to the content can be removed due to reasons completely out of our control.I can see a possible future where actually purchasing a permanent, non-revocable access to some content will not be an option anymore. When you consider the practices that some of these companies have, of “vaulting” content or removing access to it due to cost or tax reasons, I am not so much in favor of laws that protect their IP or copyright anymore. At least, not unconditionally. reply andrewxdiamond 12 hours agorootparentThe problem you talk about is real, for sure. But it is nothing to do with owning _your data._Your problem is much more aligned with right to repair rather than data ownership&#x2F;privacy efforts.It’s important that people know what they’re advocating for and understand the fundamentals of what the problem is. Confusing this problem with another problem only muddies the conversation and gets nothing done. reply JoeAltmaier 15 hours agorootparentprevExcept when you&#x27;ve paid for it? Then it&#x27;s your data. This is not rocket science. reply andrewxdiamond 15 hours agorootparentYou didn’t pay for the right to own those movies, you paid a small fee for a license to consume their data within the bounds of the contract they laid out.No one here is trying to outlaw Copyright, which is the mechanism that lets companies do as OP says; limit you from downloading their data.Data sovereignty is not at all related to streaming movies or music and this comment confuses people who are curious to what the effort really is about. reply EMIRELADERO 15 hours agorootparentCopyright regulates distribution, not consumption. What people mean by \"own\" is to own a digital file of the content that can be viewed at any time, anywhere, as long as the onus on keeping backups&#x2F;moving the file around is on the consumer. reply andrewxdiamond 14 hours agorootparentIf I share a private picture with you by showing you the image on my phone, do you now have a legal right to force me to give you a copy of that picture? reply EMIRELADERO 13 hours agorootparentNo. That&#x27;s not an accurate analogy however. reply biogene 15 hours agorootparentprevLegally speaking, unless you have a work-for-hire type contract with the artist, you don&#x27;t have an ownership claim. You purchased a digital &#x27;ticket&#x27; that lets you view the artwork according to someone else&#x27;s terms and conditions. reply biogene 15 hours agoparentprevDigital media goods are more akin to buying tickets, rather than actual albums. We always had subscriptions for stuff like TV, so I don&#x27;t know what the erosion is here. Even today, you have options for entertainment that don&#x27;t involve a subscription.Anyway, as far as s&#x2F;w is concerned the problem is not subscriptions, I believe its the symptom. The root cause is the lack of a sustainable model to fund mainstream&#x2F;retail software development. You can find small&#x2F;medium businesses that don&#x27;t sell subscriptions, but for e.g. there is no counter to companies like Adobe. Devs want to work for \"successful\" software companies with high-pay, perks and benefits, and all \"successful\" software companies sell subscriptions. reply EMIRELADERO 15 hours agorootparent> Digital media goods are more akin to buying tickets, rather than actual albums. We always had subscriptions for stuff like TV, so I don&#x27;t know what the erosion is here. Even today, you have options for entertainment that don&#x27;t involve a subscription.The point of contention is that people want to own digital files of the content they pay for. It&#x27;s as simple as that. They don&#x27;t want to be subject to any licensing terms besides the limits that are natively placed upon them by copyright law itself. reply biogene 14 hours agorootparentI agree about the contention, the counter point that I&#x27;m making is that nothing has changed or eroded. I believe that art works can have ownership claims, and that intellectual property is real.Assuming a work-for-hire type contract, you own the stuff you paid someone to create. Then YOU can do whatever you want with it including licensing it or selling digital tickets or copying it to a thousand different devices or distributing it for free. reply EMIRELADERO 13 hours agorootparentI don&#x27;t think that people who complain about those things are saying IP isn&#x27;t \"real\" or that they should get free media. Their (and my) point is that the practice of trying to put DRM (and licensing terms in general) into consumer products and IP goods that are meant to be experienced&#x2F;viewed is a predatory and unethical practice. Copyright law allows for a balanced level of control over the works at issue, but the companies want more than that so they lock them behind contracts of dubious enforceability and essentially try to remove the rights consumers traditionally held over copies of media they purchased.Whether they can legally do it is a currently pending issue (see Andino v. Apple) but the main point is that even if they could, it&#x27;s still wrong.Might doesn&#x27;t make right. reply biogene 13 hours agorootparent>Whether they can legally do it is a currently pending issue (see Andino v. Apple) but the main point is that even if they could, it&#x27;s still wrong.This is incorrect. There is absolutely no question at all about the legality of copyright or of the rights afforded to the owner by it. This lawsuit is over the use of the word \"buy\" and about terms of service on a specific content platform.>Their (and my) point is that the practice of trying to put DRM (and licensing terms in general) into consumer products and IP goods that are meant to be experienced&#x2F;viewed is a predatory and unethical practice. Copyright law allows for a balanced level of control over the works at issue, but the companies want more than that so they lock them behind contracts of dubious enforceability and essentially try to remove the rights consumers traditionally held over copies of media they purchased.Thankfully, there are tens of thousands of talented artists all over the world who will take your money and create artworks for you. This continues to be the case, so what rights of yours have been taken away; Its not clear to me. reply EMIRELADERO 11 hours agorootparent> Thankfully, there are tens of thousands of talented artists all over the world who will take your money and create artworks for you. This continues to be the case, so what rights of yours have been taken away; Its not clear to me.That does not negate the fact that most popular culture nowadays is locked behind DRM and terms that are on top of the normal copyright protection Congress devised for rightsholders.According to most content and software production&#x2F;distribution companies, people shouldn&#x27;t even own individual copies, but licenses to those. This is even in the case where the average consumer would ordinarily see it as a purchase of a copy outright. There&#x27;s a very clear line between a subscription service that provides access to movies on a time-limited basis in exchange for a monthly payment and a virtual store \"selling\" digital goods, using terminology on its UI that deceives consumers, such as \"Buy\" buttons. replynuancebydefault 15 hours agoparentprevI find owning a copy of something a bit rediculous. When I watch a film or listen to a song, I would be glad to pay a small fee for the entertainment, rather than paying for the full rights of the film or song, which could be a million times more expensive. Compare it to going to a theatre. Owning a dvd, blue ray or cd does not bring joy, only more stuff that at some point in time would get thrashed. reply bobbruno 13 hours agorootparentAs the owner of a collection of over 1K CDs and several hundred DVDs and Blu-ray, I find that your last sentence should be expressed as your opinion, not fact. Particularly because you started the paragraph with “I find”, and then switched to not using it. reply atomicUpdate 15 hours agoparentprevThis comment isn’t related to what the article is talking about at all. They aren’t referring to data you’re “purchasing”, but data you’re generating.You can still purchase physical media and do what you want with it, within reason. The cheaper option is to stream it, but you lose owning it forever as a compromise. This seems like an option most people enjoy having, due to the popularity of Netflix and Spotify. reply datadrivenangel 20 hours agoprevData ownership sounds great but is incoherent as a concept as we get lower down the IP to information spectrum.Intellectual Property has strong protections under copyright law. If I copyright a photo, or publish a book of my web browsing history, I can sue the pants off anyone who attempts to use it with permissions outside of fair use. The protections are strong, and the enforcement mechanisms are strong (though expensive).Automated information collection (data), does not have strong permissions, because there is a fundamental blurring of system logs and user tracking. It is necessary to know what external systems are interacting with your systems to ensure system integrity and availability (can&#x27;t IP ban without knowing IP addresses). So there is obviously legitimate collection and usage of this data. Not to mention weak enforcement mechanisms for privacy. So weak protections, weak enforcement (and enforcement is still expensive). reply jart 16 hours agoparentThis comes so close to speaking the truth. Take the thought to its logical conclusion. I think of online services like I think of my local bodega. You can&#x27;t run a store if it&#x27;s illegal for you to see or have any knowledge about the people who walk into your store. No store owner ever said, \"I have a legitimate need of being able to see the people who walk into my store, just so I can prevent theft, and I immediately forget about all my customers after 48 hours.\" Store owners want to be able to develop relationships with the people who walk into their stores. That requires getting to know the person. Finding out what things they like. So they can make sure their shelves are stocked with their favorite things. And that&#x27;s basically all tech companies want. When people talk about privacy in this context, it comes across to me like someone who doesn&#x27;t want anyone to know they&#x27;ve visited the local porn store. Not that far from the truth if we consider how consumers used the web during its first decade of history. The web has evolved since then but that culture stuck and turned into policy. Tech is profoundly anti-social by default, and the only way that tech companies can be successful (e.g. Twitter, Facebook) is by overcoming that to create spaces where people can know the people they&#x27;re interacting with online. So when people say they don&#x27;t think tech companies should be able to have knowledge or information about people, what they&#x27;re really saying is they don&#x27;t want tech companies to be successful. reply akavel 15 hours agorootparentWhen I visit a bodega, the bodega owner looks me in the eye, and I can look them back in the eye. They can develop a relation with me, and I can with them. If instead I enter a bodega where all the walls are one-way mirrors, where I can only interact with the hidden bodega owner by putting my money in a slot then waiting to receive goods through another slot, and an unspecified number of bodega employees are watching, analyzing, tracking, drawing, and recording my every move while they themselves are hidden behind the mirrors, I&#x27;m not that fine about this. See also probably \"power imbalance\" or something like this. reply butokai 19 hours agoparentprevYour suggestion of publishing a book with one&#x27;s browsing history really sounds interesting. Did anybody try something along these lines? I had never thought about privacy as part of the same spectrum as IP protection. reply pulvinar 16 hours agoparentprevA problem is that facts are not copyrightable, in the US anyway[0]. You can copyright your browsing history book but anyone can use the facts in it or even republish them in a different format with their own copyright.[0] Feist Publications, Inc. v. Rural Tel. Serv. Co., 499 U.S. 340 (1991) reply seydor 17 hours agoparentprevIt doesn&#x27;t have protection because the law did not protect it, and indeed the law protects the big tech, up until today.It&#x27;s not incoherent reply Genghis_Khan 21 hours agoprevLet&#x27;s decompose \"our\" data just a bit: data that we ourselves intentionally create (e.g., pictures we take, documents we write) and the observations of others about our activities (e.g., server logs, transaction data). The former seems (!) straightforward to address, while the latter seems fraught. After all, if I own all data about my comings and goings, then so does a corrupt politician his. If we go too far in restricting the recording and sharing of our observations about others, however automatic they may be, we might accidentally spring a speech-stifling genie. reply layer8 19 hours agoparentRights always have to be balanced against each other, as they often are conflicting. This is true in general, and nothing new here.The right to own the data about your personal private life exists in Germany, for example, where it is called “informational self-determination”: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Informational_self-determinati...“This basic right warrants in this respect the capacity of the individual to determine in principle the disclosure and use of his&#x2F;her personal data. Limitations to this informational self-determination are allowed only in case of overriding public interest.” reply n4r9 20 hours agoparentprev> After all, if I own all data about my comings and goings, then so does a corrupt politician his.Surely laws can differentiate between private and public domain? I&#x27;m able to store private documents in my house without anyone knowing about it. So is Donald Trump. But he can&#x27;t legally keep classified state documents there indefinitely. Perhaps if he was more discreet about it he wouldn&#x27;t have been caught. But there&#x27;s a clear distinction in the law either way. reply cm2012 19 hours agoprevData privacy is one of the least important issues of our day. People (especially on HN) foam at the mouth about it but are unable to produce specific harms Google and Meta ad tracking creates. reply rendall 18 hours agoparentMust I \"produce specific harms\" before I have the right not to consent to my data collection? Isn&#x27;t \"I don&#x27;t like it\" enough?Metadata analysis can deduce quite a lot about you. Your sexual predilections or your political or religious outlook, for instance. Who you spend time with and where you spend it and what you do when you are together, for another. Who you care about, who they care about, who they spend time together with...Not only do you have to trust that the people who have access to this data about you will use it only to advertise to you, but you also have to trust everyone who will ever have access to this data in the future, too.You might dismiss that there is any inherent risk to total strangers knowing intimate details about you, but I personally think the risk of this is a \"specific harm\".I think your stance is a version of \"I do nothing wrong, therefore I have nothing to hide, therefore surveillance is nothing to worry about\". With respect, it&#x27;s naive. reply cm2012 17 hours agorootparentThat&#x27;s why I say it&#x27;s a low priority issue. Could there be an issue in the future? Possibly. Are privacy laws like GDPR worth the economic and other harms? Probably not. The amount of wasted programmer hours alone has far overcome the negative impacts of big tech ad tracking.Neither real life or the internet are anonymous. We live with other people. But Google and Meta in particular have an amazing 15 year track record of basically never leaking user data. Various national governments have been much worse in this regard. reply TheIronMark 15 hours agorootparentMeta literally allowed their data to be used by Cambridge Analytica in a fashion that likely swayed the 2016 US election.EDIT: Well, this was certainly wrong. I&#x27;m leaving this up as a testament to not double-checking my assumptions. reply cm2012 14 hours agorootparentLiterally every part of this sentence is wrong which shows the state of this discourse.1) CA created their own data with quizzes on FB that people filled out and gave to CA. Even if you banned ad tracking sending people surveys and quizzes is still legal. The FB network only made the quizzes more viral.2) The CA data was 100% useless for ad targeting and had no impact on the Trump campaigns (any professional advertisers can tell you this, it&#x27;s not controversial). The big election interference impact was Russia leaking the DNC emails and other hacked stuff to string along the Hillary emails newsline. reply TheIronMark 14 hours agorootparentIt&#x27;s fair to say Meta didn&#x27;t give the data, but they provided a platform that allowed CA to develop the app which gathered the data. On the topic of data privacy, that&#x27;s a bad step by Meta. reply cm2012 14 hours agorootparentAt the time the programmer zeitgeist was calling FB evil for having a walled garden and not sharing data. Them opening up the API was applauded by the tech industry and HN (look up the archives). And it still has nothing to do with FB privacy efforts today which is just light years beyond where it was in 2012. reply rendall 15 hours agorootparentprevYou downplay the risk, but don&#x27;t really address it head on. There is data out there about you and your family. Recall the tendency of human beings to arbitrarily discriminate or even perpetrate genocide. Hopefully, there will never be a legal framework requiring Google nor Meta (nor any of the literally thousands of data tracking companies) to hand over this data to powerful organizations who intend harm to you or your descendents, but if it came to that, hopefully Google, Meta and every one of the thousands of data tracking companies do the right thing and withhold data that could identify you as a suspect political minority and predict your movements.Maybe there&#x27;s something more mundane and relatively benign. Employment or benefits withheld because of your tendency to procrastinate and watch 80s action films. Your grand niece is canceled because you held views considered problematic by her generation.Your only argument against this seems to be that it&#x27;s unlikely. Perhaps, but that&#x27;s argument from personal incredulity, not an argument that it won&#x27;t happen. I would love for you to walk me through a rock solid argument that it cannot possibly happen.Or, you know, we could establish a legal framework and social convention now whereby you can demand data about you and your dependents be collected only with your informed consent and deleted at will, just to not have to ever need to cross that bridge. reply cm2012 14 hours agorootparentGovernment risk from Meta and Google is meaningless. The ISPs have all the same data anyway.Also all the data is out there and me and my family in a million databases. Just like in the 80s with the yellow books. reply renewiltord 17 hours agorootparentprev> Must I \"produce specific harms\" before I have the right not to consent to my data collection? Isn&#x27;t \"I don&#x27;t like it\" enough?Of course you must. I don&#x27;t like it when people fart near me, but I don&#x27;t have a \"right to not consent to farting near me\". Some people \"don&#x27;t like it\" when other people look at them in public, but they don&#x27;t have a \"right to not be looked at in public\". reply lcnPylGDnU4H9OF 17 hours agorootparentThey did still manage to clear this bar in their comment.> You might dismiss that there is any inherent risk to total strangers knowing intimate details about you, but I personally think the risk of this is a \"specific harm\".It would be interesting to discuss the merits of this idea. Call center employees are often heavily restricted in their access to user data for the precise reason that specific harms -- stalking, fraud, etc. -- actually occur. reply srcreigh 19 hours agoparentprevThe opportunity cost of the advertising industry is incalculable. Entire industries are snuffed because kingpin ad networks can make a few dollars per year per person by having a free app with ads in that space. Less choice for the consumer, less competition, lower quality. reply jraby3 19 hours agorootparentThere are pretty clear benefits to some advertising.Email, YouTube, calendar, maps are all incredibly useful services we are lucky to have.There needs to be a line or safeguard as well as an option to pay a reasonable price for these free services to keep your data safe. YouTube is unfairly overpriced for the ad free option as are most of these free services. reply rollcat 17 hours agorootparentEmail and calendar were doing perfectly fine before pervasive online tracking.Have you checked OpenStreetMaps? It may lag behind Google or Apple for things like shop opening hours, but I&#x27;d choose it 11 out of 10 times over anything else when going hiking in the mountains. Feels like every stone is marked.YouTube? This one is a tough call. It was generating losses for a decade, maybe a decade and a half. Perhaps it should&#x27;ve been a publicly funded service.If you enjoyed this comment, please like and subscribe. reply fangorn 18 hours agorootparentprevMaybe it&#x27;s nothing, or maybe it&#x27;s freudian, but email existed before Google, so did calendar. Youtube was an acquisition. Maps, well, there are great alternatives now that do not require anal-probe-level surveillance to find an address or a route.Just publicly fund the services that are useful to people. If \"government\" (i.e. us) can pay for a square for people to meet at, why not \"digital spaces\"?And if someone&#x27;s thinking \"but government will use this data to surveil people!\" - this ship has sailed, they have access to everything that&#x27;s not e2ee, and even that&#x27;s not guaranteed.Government is practically the only body that can be expected to follow laws and act with people&#x27;s best interest in mind. Some governments even do, just need a non-dystopian one...And yes, there&#x27;s commercial space in government&#x2F;local authority-operated places. That&#x27;s fine, just make sure to boot those that decide to install the equivalent of cameras and microphones on their storefront. reply cscurmudgeon 17 hours agorootparent> Youtube was an acquisitionAnd the relied on VC money before that. It wasn&#x27;t self-sustaining financially. reply srcreigh 18 hours agorootparentprevThe greatest loss of the 21st century is how far behind we are in all the industries you list. Not to mention news.The option to pay today’s kingpin isn’t any recompense. reply JohnFen 17 hours agorootparentprev> Email, YouTube, calendar, maps are all incredibly useful services we are lucky to have.None of which require advertising. reply pulpfictional 15 hours agorootparentprevThat needs money, not advertising. reply cm2012 16 hours agorootparentprevWhat you&#x27;re saying is: people prefer free products with ads and that annoys you because you prefer paying for products without ads. That&#x27;s not a moral issue. reply JohnFen 17 hours agoparentprev> Data privacy is one of the least important issues of our dayTo you. To others, it&#x27;s one of the most important.> but are unable to produce specific harms Google and Meta ad tracking creates.I think that some harms have been articulated repeatedly. And I would argue that just being under constant surveillance is, itself, a harm.But, really, this is irrelevant in terms of the principle involved. Even if it were 100% harmless, that doesn&#x27;t mean anything at all in terms of the fact that we should all have the ability to live our lives without having someone constantly spying on us. Human rights don&#x27;t stop being rights in the absence of particularlized, articulable harms. reply ActorNightly 16 hours agorootparent>To others, it&#x27;s one of the most important.Its only really important to a very small minority of the population. The rest of the people say they want privacy, but have absolutely zero clue on what that actually implies and take active steps to worsen their privacy in lieu of using the latest smartphone or smartphone app. reply lcnPylGDnU4H9OF 15 hours agorootparent> Its only really important to a very small minority of the population. The rest of the people say they want privacyThis argument is absolutely a No True Scotsman. Just because they don&#x27;t Truly Want privacy doesn&#x27;t mean they&#x27;re not expressing that they want privacy. reply ActorNightly 15 hours agorootparentOne of the more important lessons I have learned in life is that what people want are expressed through their actions, which are often not the same as what is expressed through words. People may desire or want privacy, but they don&#x27;t care about it enough to not use devices and software.For example, if you do something so benign as use an Iphone, you don&#x27;t care about privacy. Monitor all the network traffic that iPhone sends back to apple if you want to see why. Apple absolutely tracks all the stuff that you do on your device. Thats not privacy. reply nonrandomstring 14 hours agorootparent> One of the more important lessons I have learned in life is that what people want are expressed through their actions, which are often not the same as what is expressed through words. People may desire or want privacy, but they don&#x27;t care about it enough to not use devices and software.I have learned the exact opposite. That people&#x27;s actions are often their unwanted expressions of what they abhor and truly do not want in their soul. Take any addict for an example.Guess it all depends on how you see the mind-body and your deeper knowledge of human psychology.You do seem to delight in the \"stupid masses\" perspective. But maybe that hides your compassion - perhaps compassion that most people&#x27;s relation to technology is one of victimhood, learned helplessness in the face of colossal free-for-all cargo-cult of exploitation, dressed up as \"choice\" and backed by the total failure of the rule of law to protect them.Anyway, just something we might consider before pronouncing on \"what people &#x27;care&#x27; about\". reply lcnPylGDnU4H9OF 15 hours agorootparentprevIf someone buys an iphone specifically because they believe the privacy marketing from Apple, certainly they are choosing privacy with their actions and they happen to be misinformed. reply cm2012 16 hours agorootparentprevI don&#x27;t buy that \"constant surveillance\" from big tech is a harm, I think it&#x27;s dramatized language for something quite banal. Which is why I want to see actual harms before being against it! There are many benefits to society from effective advertising. reply lcnPylGDnU4H9OF 15 hours agorootparentI fail to see how these statements are dissimilar with regard to specific examples.> I would argue that just being under constant surveillance is, itself, a harm.> There are many benefits to society from effective advertising.It&#x27;s not difficult for me to imagine abuses that could possibly occur given constant surveillance similar to how it&#x27;s not difficult for me to imagine benefits that could possibly arise with targeted advertising.But since we&#x27;re not imagining and are instead providing examples: what are some actual benefits to targeted advertising? What benefit(s) should I expect to see from this targeting and where can I go to see this benefit? reply cm2012 14 hours agorootparentWith no targeted advertising:1) you will still get ads, it&#x27;s just lowest common denominator teeth whitening and weight loss that anybody can buy.2) it would be much harder to subsidize entertainment that relies on ads.3) New and emerging businesses rely on ads much more than category leaders to be heard of. Worse ads means a more powerful incumbent advantage. reply lcnPylGDnU4H9OF 14 hours agorootparentThank you. I think your question can be similarly answered.With constant surveillance:1) individuals are incentivized to avoid expressing themselves in ways which their overseers dislike, especially if an expression draws punitive measures;2) a particularly vulnerable person could be worried about being extorted with information that&#x27;s discovered about them causing some pervasive increase in stress;3) otherwise innocuous information about a person might indicate a Bad Thing which is only considered Bad well after the fact but might still be used against them in some social setting. reply0xbadcafebee 16 hours agoparentprevAnd on the other hand, private data is something nearly nobody talks about. Actually sensitive data about you is not handled in anything approaching a systematic and careful way, and that&#x27;s the data that gets exposed in massive leaks that we should be caring about. But rather than talk about that, people talk about not wanting cookies, because they&#x27;re more creeped out by that than having to change their social security number. reply loteck 17 hours agoparentprevFortunately many smart folks can anticipate major systemic issues that threaten to create exponential and devastating societal harms, and start working on them as early as possible.Would the following statement be you, in 1980? \"Climate change is one of the least important issues of our day. The few people who care about it are unable to produce specific harms burning coal and oil creates.\"(Downvoted for the inflammatory mouth foam comment, FYI.) reply abdullahkhalids 17 hours agoparentprevWhat is the specific harm if someone takes naked pictures of me without consent? Just the loss of my dignity as a human being. That&#x27;s an abstract non-economic loss.My data is my own data. Someone using it, along with dark art individual ad targeting methods to influence my preferences, is also the loss of my dignity as a human being. All humans deserve to be free of such coercive manipulation.The fact that big economic firms are the ones doing this, is doubly problematic because our \"democratic\"-capitalistic systems are to a fairly high degree one-dollar-one-vote systems. reply criddell 17 hours agoparentprevGoogle has handed over user data to Hong Kong authorities. Chances are Meta and Apple have as well. It&#x27;s possible that the Chinese government has never sought information on individuals for political reasons but I wouldn&#x27;t trust that to be true.If you were in China, would you feel comfortable clicking on a pro-democracy ad running on Meta? Wouldn&#x27;t just the fact that Meta determined you were a good candidate for that ad bother you? reply cm2012 17 hours agorootparentGoogle and Meta are both banned in China because they wouldn&#x27;t give the party everything it wanted. Not to mention your ISP has all the same info (with more detail!) and also will give it to the government. reply criddell 14 hours agorootparentYou&#x27;re making my point better than I did. The unregulated collection of data on people will lead to real harm.If all that data couldn&#x27;t lead to real harm, then Google and Meta would have no problem handing it over to whatever authority wants it. reply cm2012 14 hours agorootparentThat doesn&#x27;t follow and is very stretched logic. reply criddell 13 hours agorootparentIf companies that track everything we do online were to start freely sharing this information with governments around the world, do you think it would lead to real harm?The answer is clearly yes. Therefore users should have control over the data that a company collects about them and their activities. replylewhoo 18 hours agoparentprevSpoken like a true salesman. reply sparrowInHand 19 hours agoprevI dont think that Big Tech can be \"taken on\" anymore. Its everchanging automatable behaviour, that is capable to exploit all systems through the smallest oversight.You would need to criminalize a mindset - \"parasitic intent\". reply elric 21 hours agoprevIsn&#x27;t this what Tim Berners-Lee&#x27;s Solid Project is trying to solve? It&#x27;s an interesting nut to crack.https:&#x2F;&#x2F;solidproject.org&#x2F; reply suckitsam 20 hours agoparentI feel like these kinds of solutions can necessarily only protect boring data - my phone number, date of birth, favorite color, and mother&#x27;s maiden name.I can&#x27;t see how I could ever get the interesting&#x2F;profitable&#x2F;problematic data (my location history, my neighbor&#x27;s doorbell videos of me, call records, purchase history at Target, and which ads I click on) into something like that. reply j45 19 hours agorootparentExcept this guy already had doubt towards his little www project once.Beginning with your own data and metadata is very different than data about you. reply suckitsam 19 hours agorootparentYeah, I&#x27;m just not sure personal data is actually The Problem.Sure, ̶b̶a̶n̶k̶ ̶r̶o̶b̶b̶e̶r̶i̶e̶s̶ ̶a̶n̶d̶ ̶u̶n̶d̶e̶t̶e̶c̶t̶e̶d̶ ̶f̶r̶a̶u̶d̶ Identity Theft is a Bad Thing, and this would seemingly minimize the number of SQL dumps my birthday and SSN appears in, but that isn&#x27;t exactly The Data that Big Tech feeds off of. reply j45 13 hours agorootparentData you create by your usage of computers is generally yours.Where that data is content and the interactions themselves, it&#x27;s also different. replylefstathiou 19 hours agoprevRandom opinion here: I don&#x27;t think privacy safeguards will have material impact on big tech and on the whole. They own the platforms we engage on and can thus channel engagement with or without privacy guards in place.I think the only solution to this, and I personally don&#x27;t care to implement it so just discussing this intellectually, is to disallow M&A. These firms have reached such scale that they can overpay significantly for every next generation platform (that could eventually compete against them) and protect the moat. Otherwise we we will only see shakeups when paradigm shifts occur, only to see the companies leading the shake ups get acquired... OpenAi comes to mind as the only credible threat to Google in recent years, only to see it get swallowed by MSFT.Its difficult for any company to be at the bleeding edge of innovation forever, so they must be prevented from acquiring all innovation forever. reply ianburrell 16 hours agoparentGoogle doesn&#x27;t sell private data to others. They sell ads and targeting ads. I can believe that Meta sells data but it is likely they have the same model. I don&#x27;t think data privacy would affect their business since sales would be small part of revenue.Data ownership wouldn&#x27;t help with Google or Meta because they would put assignment in the user agreements. The same as they do for copyrighted content. The difference is that they might have to specify if the data gets sold.The companies that would be affected are data brokers. Honestly, I think the focus on Google and Meta hides all the companies that are actually selling data, really private data like location. reply dcow 19 hours agoparentprevThe article is suggesting the solution is to shift the conversation to data ownership from privacy controls. Are you bucketing data ownership in with privacy controls and dissenting, or just making a tangential comment? reply lefstathiou 18 hours agorootparentSorry I typed this on my commute so I didnt flush it out. What I believe (and didnt say) is that data ownership and privacy controls are important issues to individuals, but are not meaningful drivers of ongoing performance and market control of big tech. I don&#x27;t believe their power lies in their access to my data, it lies in their control over the infrastructure I used to earn my living, engage with the world, etc.Thus, to mitigate their control (assuming you want to), I believe we need to look to solutions that garner competition. MSFT collects rent on the corporate enterprise via Azure, they own corporate documentation via Office, they own the corporate code repository via Github, and they own the corporate identity via LinkedIn. reply olah_1 18 hours agoprev“The people who can destroy a thing, they control it.”The problem with solutions like Nostr is that users don’t own their data. Relay operators do. Once you post data to a relay, you are giving ownership to them. They decide if it lives or dies, not you. reply dack 17 hours agoparentthis is why users should just have their own relay and we should make it easy to do that reply olah_1 16 hours agorootparentAgree. A cheap home device that you can plug in would be very cool.Note that this is at odds with a school of thought in Nostr that says each different niche app or niche interest should use a different relay.Your suggestion would be a different way of thinking. Primarily one that is focused on maximizing different event kinds for each niche use case rather than having less event kinds and more single-purpose relays. reply pentae 19 hours agoprevI always wonder about what do service providers do when the person who&#x27;s data you&#x27;ve collected is a bad actor such as someone abusing the service, committing credit card fraud or running a bot network? They too can just submit a request on all your fraud data and have it deleted?And if the answer is \"well in those cases you can make an exception\" well where is the line drawn, and how? reply oneepic 16 hours agoprevOn everything related to data privacy and Big Tech, I must admit I&#x27;m mentally blocked on one point. How do most people think of this? I&#x27;m not sure most Americans, for example, know or care about this topic. There are broadly related topics they care about though, like not getting hit by fraud.Is there a simple argument that most people would understand and agree with? I would think that&#x27;s a better place to start for making a change.The other argument is, if it&#x27;s too complex for most people, then a gov agency could regulate it (like most people want to enjoy water without worrying about the source), but that&#x27;s a giant can of worms for other reasons. I&#x27;m not trying to start a discussion on that topic. reply 3c0 21 hours agoprevthe thing is, even if you \"own\" your data you still need to give it to companies to use their product. unless everyone runs software locally, in which case the majority of the populace needs to learn how to use devices rather than falling for the trashy \"itjustworks™\" chromebooks and convenience devices that milk them for data profits whilst appearing cheaper and better to integrate into their lives.especially with google - you cant run services like theirs locally really, and even if you request your data, you cant ever really find out how they use it or what they have done with it. its the illusion of ownership. data isnt ownable. its simply transferable. reply MrJohz 21 hours agoparentThat&#x27;s pretty much the whole point of the data ownership concept in the EU, though - force these companies to tell you exactly what they&#x27;re using, and exactly how they&#x27;re using it.I don&#x27;t really think there&#x27;s a feasible alternative. Most people don&#x27;t have the means, time, or knowledge to self-host all of the tools they use, and as a consumer, I can&#x27;t really tell how a company is going to use the data I give them. In cases like that, the only solution is regulatory structure. reply n4r9 21 hours agoparentprevI guess there&#x27;s two things going on here. Firstly, whether the company takes the data with your full knowledge and consent. Secondly, whether they use it in a transparent (or at least ethical) manner.For the first of these, I quite like how on Android now the user has great control over what data is made available to which apps. The app needs to explicitly request access to camera, location, files etc... . You can toggle this on or off at will, and specify that it can only read the data while the app is active. I can imagine having regulation which enforces this type of privacy control for all tech service providers.The second is much harder, because it&#x27;s difficult to know what the company is doing behind closed doors. However we can at least check telemetry and demand that it is minimal and anonymised where appropriate. We can also apply much harsher penalties to companies that flout the rules.Of course, all of this relies on government that acts in the genuine interest of its people and without hands in industry back pockets. We can but hope. reply pierat 19 hours agorootparent> For the first of these, I quite like how on Android now the user has great control over what data is made available to which apps. The app needs to explicitly request access to camera, location, files etc... . You can toggle this on or off at will, and specify that it can only read the data while the app is active. I can imagine having regulation which enforces this type of privacy control for all tech service providers.And the Android stock permissions are laughable and a pure joke.Go look at Xposed Framework, and you&#x27;ll find ways to unwind every permission, either direct deny, or \"make fake data\" plugins. There&#x27;s even fake contact plugins, GPS faker plugins, you name it.Google only implemented the worst-of-worse deny permissions, because doing a good job would be against their interests. reply n4r9 19 hours agorootparentI&#x27;m sure there are plenty of ways to improve how Android does it, I was just using it as an example that I&#x27;ve had personal experience with. I&#x27;m not sure if the ability to make fake data is an essential part of owning one&#x27;s data, but would be interested to hear arguments for it. reply bobsmith432 21 hours agoparentprevMaybe the only way to fix this is to use the route you named, make people host locally and make technology harder to use. reply j45 19 hours agorootparentI’m not sure what is linking the two here for you.People seem to host their own data locally on their phones just fine reply Supermancho 19 hours agoprevFrom the byline: Competition enforcement by nations has had little impact. This doesn&#x27;t \"take on\" big tech in terms of antitrust. Giving a platform with hundreds of billions of dollars another hoop to jump over (which any competition would also then need to include) is an inconvenience, to further solidify their market hold. reply DrScientist 19 hours agoparentA good point - large incumbents often welcome complex regulation - as they act as a significant barrier to new entrants.However you could argue that companies like Google or Facebook were new entrants into the advertising market and unfairly competed with traditional players by breaking existing norms ( around privacy or taking editorial responsibility for promoted content ).Or the gig economy type of companies like Uber ignored existing employment law.Sometimes it&#x27;s just about enforcing existing expected standards in new situations to create a level playing field.If you set the regulation at the level of what, and leave the how up to the companies - then you leave scope for competition and innovation in how to achieve the objective. reply karaterobot 16 hours agoprev> But advocates of strong competition law also have a problem. Very often, the authorities are all bark, and no bite – and the European Union is one of the worst offenders in this regard.In other words: legislation has failed, it&#x27;s time for more legislation.My observation is that most people don&#x27;t care about their data being used by Big Tech. Not as much as they care about short term convenience, momentary distraction, long-term addiction, or the catastrophic possibility that they may miss out on something popular. The way to \"take on\" Big Tech would be for people to change their real preferences for what Big Tech offers. In practice, this would mean not using Google, Meta, Twitter, Instagram, TikTok, Amazon, and so on. That&#x27;s it, that&#x27;s the option. Failing that (which is the contingency we should expect) nothing, including legislation or regulation, will have the effect you want it to have. We keep getting what we ask for and then wringing our hands over it. reply mushbino 15 hours agoprevThings like this would be much easier to accomplish if tech workers unionized. We don&#x27;t necessarily need it for compensation, although many could benefit, but having a say in what we build is incredibly important. reply Aerroon 18 hours agoprevYour browser&#x2F;smartphone is voluntarily sending over the data.You could argue that MS&#x2F;nvidia are doing shady things with telemetry on Windows&#x2F;gpu drivers, but most of the data collection happens on websites.\"Hello, we would like permission to use your data for advertising.\"\"Ok\" reply kelseyfrog 18 hours agoparentExactly! It&#x27;s not unlike Netflix voluntarily sending me the data for a movie which I should be able to copy and share at my leisure. reply throwawaycities 19 hours agoprev\"Privacy is necessary for an open society in the electronic age. ... We cannot expect governments, corporations, or other large, faceless organizations to grant us privacy ... We must defend our own privacy if we expect to have any. ... Cypherpunks write code. We know that someone has to write software to defend privacy, and ... we&#x27;re going to write it.\" Eric Huges, A Cypherpunk’s Manifesto (1993)https:&#x2F;&#x2F;acypherpunksmanifesto.eth.limoThis war was lost a long time ago. Capitalism isn’t the answer, capitalism is the reason both the tech industry and legal industry paved the way for data, privacy, traffic and owned by big tech for them to solely monetize. People and their data are being farmed to work and create value for others and most are paid less than enough to keep food on their table and a roof over their head, once they no longer produce value they are shipped to the glue factory. It’s not a bug of capitalism, it’s a feature and big tech has optimized for it with data. reply greenie_beans 18 hours agoprevi&#x27;ve not been able to use instagram on a web browser for a few weeks. i think it&#x27;s because i don&#x27;t share much data with them.help! https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37422389 reply skilled 21 hours agoprevhttps:&#x2F;&#x2F;archive.ph&#x2F;o2Fqo reply pjmlp 20 hours agoprevIt turns out that the general public rather have AOL and Compuserve, than public distributed computing. reply j45 19 hours agoparentUsers wanting to be used lol. Let’s mail out cds while we’re at it. reply PCalvanelli 16 hours agoprevTechnically speaking, how do you ascribe ownership of bits to an individual? reply specialist 20 hours agoprevI am my data, my data is me. I own myself, of course. So I also own any and all data about me.The constitutional right to privacy (sovereignty over oneself) is the start. This article&#x27;s notion of price setting is derived from the right to privacy.--I&#x27;d love to hear any and all proposals about determining the price of demographic data.Surely, the Big Tech companies do this already. Analyzing current accounting practices is terrific place to start.One interesting proposal for price setting is to treat warehousing demographic data (on the corporate balance sheet) as a liability vs an asset. The idea being to proactively manage risk (of the inevitable data leaks, ransomeware, etc), right? reply heresie-dabord 18 hours agoparent> determining the price of demographic dataThe value of the data is determined by=1= the bid&#x2F;auction system, the owner of which controls the starting price and the access=2= the bidders, who pay to gain access to something that they believe has value or can generate value=3= the high-probability predictability of the behaviour of the surveilled demographic=4= for any data that does not meet the threshold for 3) , the ability of the owner to mine and refine it for a future 3) reply l33t7332273 18 hours agoparentprev>So I also own any and all data about meIf I see you on the street and write in my diary: “Saw specialist on the street today.” You’d like the law to consider me a thief?Indeed, I think this is absurd because the premise that you are your data is absurd. Your data is not a person; it cannot feel pain or be damaged or compelled to action.You are no more your data than you are the clothes you choose to wear. reply heresie-dabord 17 hours agorootparent> If I see you on the street and write in my diary: “Saw specialist on the street today.”Are you a private individual, or a corporation (or agent thereof) that will use information specifically about me to earn profit without acknowledging your use of my data and compensating me?If you are a private individual, say hello. If you are a corporation or agent thereof, do not collect without my permission. reply l33t7332273 16 hours agorootparentI don’t think there’s anything wrong with using your data without compensating you. If I sell my diary, you aren’t owed a cent. reply specialist 18 hours agorootparentprevI grant you permission to document our encounters for your personal use, in perpetuity. Such transactions are common enough that society will formalize such arrangements, minimizing transaction costs (overhead).But should you ever decide to write a book about me, I want my cut.> Your data is not a person...Correct. My data and myself are the same person. Legally.Consider: You impersonate me for the purposes of seizing my property. You have everything necessary to prove to my bank that you are me. How is a bank to know otherwise? For all practical purposes, to the bank, you are me.How then is my data not me?--Identity theft is now a growth industry.Do you have any proposals for mitigating these crimes?Ditto surveillance, behavioral advertising, profiling, stalking.How does our society rebalance the scales to mitigate these problems?Formalizing our individual right to privacy, universal personal sovereignty is my proposal. It&#x27;s the cornerstone of life, liberty, and pursuit of happiness for society in our new era. Necessary, but not sufficient, of course. reply l33t7332273 16 hours agorootparent>How then is my data not me?Knowing your PII is not a crime, and it shouldn’t be.Identity theft is not a crime. In fact, there is no such thing. You’re still you. I can’t steal your identity.The crime is fraud.Making material misrepresentations about who I am by pretending to be you to obtain credit is the crime.>It&#x27;s the cornerstone of life, liberty, and pursuit of happiness for society in our new era.It’s really not. We have all of these now without data privacy. reply specialist 13 hours agorootparent> Knowing your PII is not a crime...Correct. We&#x27;re talking civil law, not criminal.If you use my PII without my consent, I&#x27;m suing you in court. Abuse the rights of many and you could be facing a class action lawsuit.> We have all of these now without data privacy.What are your thoughts on the other social pathogens? Behavioral ads, profiling, etc.I&#x27;m curious: In your view, do people have the right to privacy?Or are you more in the McNealy&#x2F;Zuck&#x2F;Schmidt camp? \"There is no privacy. Get over it.\" reply l33t7332273 12 hours agorootparentYou gave a criminal example, hence my discussion of what was illegal.Regardless, the right to privacy, much like the rights to speech and to bear arms is complicated and can’t be easily captured.I believe people have a right to privacy, but I also believe there is nothing wrong with me seeing you outside, writing this fact down in my diary, and selling it without your permission. replydatavirtue 20 hours agoparentprevAccounting methods&#x2F;practices are private. You just get to see the income statement and balance sheet that is produced from this voodoo. Perfect example: Kroger is taking the full charge for their opioid settlement in a single year but future investors and managers will be burdened with the actual payments for decades (tax law allows this). This is the thought process baked into these accounting methods that you normally are not privy to. Bonuses for me now, pain for you later.https:&#x2F;&#x2F;www.baldwin.senate.gov&#x2F;news&#x2F;press-releases&#x2F;challenge... reply j45 19 hours agorootparentYour bank balance is private.Accounting methods and practices are not private, they are standardized.Where it comes to your own money personal or business, you get to see all of the chart of accounts, ledgers, etc. reply datavirtue 10 hours agorootparentIf they are using cash I know exactly what&#x27;s going on by looking any balance sheet or income statement. If they are accrual I have no idea what lies beneath the surface. Everyone is on accrual. For a public company you get a balance sheet and income statement. Good luck. You have to audit them and all of their subsidiaries. But you can&#x27;t because you don&#x27;t have access to any of the books. It just leaves everything open to \"creative accounting.\" It has been a proven vector of corruption and high crimes.Recently (pre-pandemic) the guy that cracked Madoff released an analysis of GE claiming that they have been cooking their books for years--outright accusing them of fraud. GE and their media sycophants denied it adamantly. Story goes away without any proof whatsoever. Maybe the guy is nuts? I&#x27;m suspicious. Day traders LOVE GE for the ups and downs. They bought at $9 and now the stock is $132. In that case no one cares if the books are cooked as long as they can ride the wave.Feel free to read about Enron on Wikipedia. There are plenty of case studies and the world will keep producing more. reply passwordoops 17 hours agoprevThe way to fight big tech is to actually enforce existing anti-monopoly laws, like what Lina Khan is trying to do at the FTC reply kmeisthax 19 hours agoprev>But in the spirit of experimentation, should we not try the one thing we have not actually tried online yet – capitalism?Garbage quote. The Internet has been largely an ancap[0] wet dream. Rules are enforced by unaccountable corporations wielding monopoly power and one-sided contracts and enforcing laws through summary judgment and tattooing \"POOR IMPULSE CONTROL\" on people&#x27;s heads. The only thing we&#x27;re missing is the 3D Internet and ancient Babylonian computer viruses.The EU already implemented data ownership, it&#x27;s called GDPR. The points where it differs from a vanilla property right are there specifically because tech companies have already made data \"too cheap to meter\". If you just build a property right around data, the tech companies will just say \"your data is the price of admission to a free service\", and people will accept that because...- Monopoly status is a form of power equivalent to that of government[1]- People on the business end of power have no negotiating leverageThis is how dragnet surveillance became legalized in America[2]. SCOTUS argued that if you tell someone where to send a message or connect a call, that information has no expectation of privacy. AT&T would then go and put EULA roofies[3] into everyone&#x27;s phone service that let them sell your phone numbers. Government and private surveillance coevolved from there into the privacy nightmare we have today. In order to fix this we need to change the starting conditions.Also...>Academics and the digital NGOs, a familiar looking blob, hate the prospect, in part because it leaves them with a diminished political role, if any at all.I&#x27;m not sure what this is supposed to mean beyond the usual right-wing knock against civil libertarians and people with well-rounded educations.[0] Short for \"anarcho-capitalist\", which is a contradiction in terms for reasons that should already be evident from everything else I already said.[1] Conversely, government is just a monopoly on the legitimate use of force.[2] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Smith_v._Maryland[3] A colorful term Louis Rossmann uses to refer to contractual clauses you&#x27;d never agree to but for your lack of negotiating power. reply Karunamon 15 hours agoparentpeople will accept [paying with their data to access a free service] because monopoly status is a form of power equivalent to that of governmentSort of agreed, but monopoly status is the status of having no meaningful competition, which company&#x2F;service does this apply to?The other problem is that ~nobody can articulate a way that this \"data for access\" arrangement has actually harmed, or even so much as inconvenienced them. reply kmeisthax 6 hours agorootparentIt&#x27;s a very specific and weird kind of monopoly enabled not by being the only meaningful competitor but by being the trusted intermediary everyone else uses. As the operator of a centralized communication network the monopoly is on your ability to contact friends who choose to use their services. In other words, the network effect. While you and your friends can use other services, that still requires you all agree on not just leaving one service, but moving to another service.This might sound like a contrived example, but a significant portion of my extended family uses Facebook and only Facebook to communicate as a group. Since I have zero desire to see any more of my data fly up Mark Zuckerberg&#x27;s asshole, I very rarely use Facebook, and as a result I am practically dead to a good chunk of my extended family. If I do want to contact them, it is on Mark&#x27;s terms: I must use his client software, which contains as much spyware as Apple and Google will allow. There is no negotiation, just a choice between capitulation or detachment.The reason why I consider this to be a monopoly is the same reason why I consider, say, Comcast or the United States government to be monopolies. Technically speaking, there are alternatives to cable companies and your national government, but to access them, you need to move, subject yourself to immigration formalities, etc. Messaging apps work the same way. Look at how many people are continuing to stay on Twitter despite Elon Musk radically changing the functionality and political editorialization of the site to be complete garbage. Even mechanically identical services like Threads, Bluesky, or Mastodon have yet to eclipse it because there is no interoperability between them and Twitter[0].[0] FWIW literally every Mastodon instance I federate with already blocks Threads despite federation merely being a planned feature that doesn&#x27;t even exist yet. The reasoning behind that is... complicated. reply benkillin 18 hours agoprevI have not read the featured article, but based solely on the headline I have this to contribute: check out Veilid. [Veilid](https:&#x2F;&#x2F;veilid.com) was featured at DEFCON 31, and has this to say on their index page:\" Veilid allows anyone to build a distributed, private app. Veilid gives users the privacy to opt out of data collection and online tracking. Veilid is being built with user experience, privacy, and safety as our top priorities. It is open source and available to everyone to use and build upon.Veilid goes above and beyond existing privacy technologies and has the potential to completely change the way people use the Internet. Veilid has no profit motive, which puts us in a unique position to promote ideals without the compromise of capitalism.\" reply mempko 15 hours agoprevWe should own our data. But another way to take on big tech is just to break them up into small tech. Good old fashion monopoly busting. Sometimes old tools still work in the modern world. reply lossolo 17 hours agoprevThere should be a standardized API so people can easily move their data from one provider to another, proving that they are person X on platform Y and transferring all their content (tweets, posts, videos, etc.) with just a few clicks using OAuth. It&#x27;s technically possible and would make changing platforms easy, making entry of new participants in the market a lot easier. reply tomjen3 19 hours agoprevNo. What we must have is the right of interoperability. If a service has both a server and client then it needs to be considered a defecto monopoly unless it allows any other client access to its servers.It doesn’t solve any problem for me that I can download my Facebook messages, I need to be able to choose any messenger app to write to my friends.Basically, bring back pidgin. reply cm277 21 hours agoprevArgh... not even. We don&#x27;t own the power or water meters that serve our house, nor do we get shares&#x2F;equity in our water&#x2F;power consumption. While these are services that are actually critical for survival and most of them are actual monopolies, the power&#x2F;water utilities don&#x27;t make insane amounts of profit, they don&#x27;t have market caps in the trillions and they don&#x27;t have the most lobbyists in DC&#x2F;Brussels. You know why? because they are regulated and taxed.But no, we don&#x27;t mention these words around advertising, or providing internet access or the main computing&#x2F;communication channels for ~80% of the world population (smartphones&#x2F;social media). Why not? are they somehow special? more important than power or water?FFS, I dont want to own or manage my data any more than I want to think about how many liters of water or KWh I am going to consume today. I want these companies to be brought down to size and become part of the democratic polity, not unelected dynasts over life and industry. reply lifeisstillgood 21 hours agoparentYes. But. even regulation needs a framework to think about how to regulate.And personal data makes an excellent framework, and saying I own data about me is a good way to make the ownership and control relevant, and allows lots of different approaches. It&#x27;s feasible to imagine most (western) countries agreeing \"data about a person or their digital actions\" being something that can be put into their laws.It&#x27;s hard to imagine everyone agreeing \"this regulatory body will oversee data\"The EU was first out the gate, and it&#x27;s enrolling but heading towards restrictions on all usage then allowances for medical and academic research (you publish, you were allowed) and restrictions on personalised advertising.It&#x27;s going to get messy, but I think DuckDuckGo has the right balance - if I search for \"trainers for old men\" Inwill get adverts for that. But they won&#x27;t \"remember\" my search the next time. Honestly I will be amazed if the conversion rates for DuckDuckGo and Google are different enough to justify the suck that is internet advertising today. reply cm277 20 hours agorootparentI don&#x27;t disagree, but I think the idea of owning your personal data is a red herring and&#x2F;or a stalling tactic. The GDPR and its equivalents were a necessary first step, but I dont see how privacy can stop the market abuses and the rentier behaviors of the FAANGs. Privacy is great, claiming your legal rights over your data is great, but at a market&#x2F;economy level it&#x27;s probably a net plus for larger companies that can be compliant and&#x2F;or work around its restrictions.So, instead of talking endlessly about data ownership and micro-transactions and god knows what else we&#x27;ve been arguing for (checks notes) 30 years, we could just ask to regulate the tech giants. Cap their rentier rates (30% on the app stores? really), their monopoly behaviors (you are both the largest ad server and the auctioneer? really?), etc, etc, etc-freaking-etera. reply lifeisstillgood 17 hours agorootparentI think regulation (as in \"PG&E is regulated by some federal agency\") is the red herring. Firstly other utilities have by comparison outrageous specific territorial limits, making them clearly subject to one governments regulatory efforts. Facebook has spent years crying out again and agains saying \"tell us what the fucking regulations are and we will code them\". No one can answer of course because a) we as a society have not worked out what this all means, b) even if we did we would not get all the governments to agree c) even if they did can you imagine one multi-national regulator with powers over facebook, google, apple ? That&#x27;s the CEO job Inwant reply specialist 20 hours agorootparentprevIf you think banning behavioral advertising, reselling demographic data, or whatever, is an easier lift than adapting accounting practices to accommodate every human&#x27;s right to privacy -- sign me up!But I&#x27;d like to think we can walk and chew gum at the same time. Fundamental shifts in the social contract (caused by disruptive technologies) impact all sorts of stuff. We shouldn&#x27;t limit ourselves to quick fixes. reply j45 19 hours agorootparentprevHow would regulating the tech companies result in data ownership? reply cm277 19 hours agorootparentIt won&#x27;t, nor would the inverse happen, i.e. data ownership won&#x27;t \"take on the tech companies\". That&#x27;s what the TFA argues, that data ownership is the ONLY way to reduce the power of the tech companies. And what I am saying is that a) it&#x27;s not the only way, in fact there are much better&#x2F;easier&#x2F;proven ways, b) that just creating this false dichotomy distracts from the need for regulation and at best delays regulation or at worst it actually benefits the tech monopolies (because large companies can work under&#x2F;with privacy regulations better than startups).Not arguing against privacy, at all. But saying that privacy, which is a hard problem to figure out at scale, is the only way to regulate the FAANGS, just distracts and delays. We can walk and chew gum at the same time. reply j45 19 hours agorootparentAgreed.Not sure why the OP is bringing up both as if they’re related or connected. reply garba_dlm 19 hours agorootparentprevthe problem is that digital assets (including data, code, mp3, mp4.... anything digital) can be had (owned) by multiple parties at the same timeand there are no &#x27;frameworks&#x27; with which to think about this in a good way that doesn&#x27;t result in a few having advantage over everybody else. but this is a philosophical and political issue, not a technical one reply lifeisstillgood 17 hours agorootparentI think the music industry lawyers have fairly strong ideas over who owns a digital asset :-) reply garba_dlm 17 hours agorootparentwhich is why the whole of the &#x27;academic global institution&#x27; which in commercial terms is just a big chunk of \"big publishing industry\" is also in a state of revolution (see the z-lib and sci-hub legal battles: in India, and in Argentina; as well as the \"cross-russian border\" aspects which are tainted by real hot-open war at this moment) reply robertlagrant 21 hours agoparentprev> You know why? because they are regulated and taxed.That&#x27;s not why. It&#x27;s because they don&#x27;t have global reach, they don&#x27;t scale better than anything in history to that customer base, and aren&#x27;t now one of the primary ways people interact with the world.It&#x27;s because they do one thing well, and there isn&#x27;t loads of innovation happening in them, so they can be state-owned (or very close) and it doesn&#x27;t matter. reply cm277 21 hours agorootparentTrue, but conversely if they don&#x27;t do their job well, the utilities can kill people. Or if they werent price-regulated, they could charge whatever they wanted, hurting both life and the economy.I get the trillion-dollar caps; what I don&#x27;t get is why aren&#x27;t mere cento-billion market caps enough, why can&#x27;t we have regulation and lower prices and as-good services with less exploitation of the commons. reply robertlagrant 19 hours agorootparentWhat does \"enough\" mean in this context? A cap is just the total number of shares multiplied by the price of the last-traded share. Do you want to limit the maximum price a share may be sold for? What does that do for anyone? reply andsoitis 20 hours agoparentprev> Why not? are they somehow special? more important than power or water?They are less important than power or water and, which is one of the reasons why they are able to make more profit. reply sophacles 19 hours agorootparentIt&#x27;s becoming harder and harder to arrange for power and water (and jobs to pay for them) without the Internet.Sure, looking at cat pictures or whatever isn&#x27;t that important, but as things continue to become online only, your argument becomes less and less valid.Imagine how you&#x27;d move to a new town across the country in 2023: how do you find real estate without the Internet? How do you know who to call to set up power and water, how do you find thier number? Most of the ways i can think of involve someone looking up stuff on the Internet for you...Half the time when I call any of these places, trying to make use of some drive time, they just tell me to go do ot on the website since the csr can&#x27;t do it for me anyway.The only time I&#x27;ve been able to reach a human at the mortgage servicing company is when I switched banks and flu bed the new account number... they were sure to call to let me know the payment failed, but the csr couldn&#x27;t help me fix that problem, just tale the corrected info for the one payment.It&#x27;s utterly absurd to think that something so important to the function of our society is subject to the whims of scumbags at Comcast and att. If the Internet broke for more than a day or two, I&#x27;m pretty sure it would be catastrophic at levels similar to the power grid going down for more than a day or two. reply pierat 19 hours agorootparent> Imagine how you&#x27;d move to a new town across the country in 2023: how do you find real estate without the Internet?Worse yet, is how realtors are NOT equipped to even say \"what internet services are available at this place\".Recently, our realtor has been in business, and was stunning on everything other than \"what internet providers service this address\". She would have to submit a query to the seller.I showed her the FCC broadband dashboard, which has its own fraudulent data issue (not directly their fault, but their fault for not forcing ISPs who lie to follow through).We turned down a really nice place that only had DSL that may be reconnected... we couldn&#x27;t confirm since the Telco was actively spinning down DSLAM circuits in the whole area.The place we&#x27;re at now has FTTH and is served by a local ISP, not crapcast (the ones who lied the most in the FCC dashboard).But again, your point is well made -much of our communication was split between online and seeing houses. About 1&#x2F;2 each.The bright side: she listened to my comments about how to determine broadband and is now incorporating that with buyers agent with others. (She told me recently she knows no other realtors who do that locally). reply bell-cot 20 hours agoparentprev> ...nor do we get shares&#x2F;equity in our water&#x2F;power consumption...If you have a local municipal water or power utility, then you effectively do have shares&#x2F;equity.(And if your municipality is competent in managing their Water Dept. or Power Dept., you probably have better service than a for-profit private utility would provide. Sadly... municipal governments are frequently allergic to that \"competent\" stuff.) reply traceroute66 20 hours agoparentprev> nor do we get shares&#x2F;equity in our water&#x2F;power consumptionWell, to be fair, most utility companies are publicly traded, so you could if you want....And if you have a pension pot from current&#x2F;prior employment, then the pension pot almost certainly has some utility shares somewhere in it, because the utilities pay reasonably reliable dividends, which is the just sort of thing you need for a pension. reply totetsu 19 hours agoparentprevSome places that didn’t sell off their assets give their residents token water or power utility dividends reply elric 20 hours agoparentprev\"Smart\" energy meters are being rolled out in many places. Give it a few years until that data is being sold to Google so they can serve you more relevant ads depending on much water you&#x27;re using. reply dfxm12 20 hours agoparentprevRegulation and taxes have since become bad words politically, mostly from a concerted effort among conservative media. The lobbyists help as well :). Inertia is keeping older utilities in check, but it should be pointed out that the Business Roundtable lobbyist group specifically requested Trump to deregulate the clean water act (which he signed some executive orders about), so the lobbying efforts & preventing regulation isn&#x27;t limited to big tech...Elizabeth Warren & Lindsey Graham recently talked about introducing some regulation around big tech, so do look into who supports or opposes this effort. reply j45 20 hours agoparentprevPower and water are a physical good that you take delivery on. It’s the same substance delivered to everyone. It doesn’t seem like the best analogy.The meter simply measures how much is delivered to you.Data conversely is specifically information only about you, and often created by you.Owning the rights to your data is very different than managing it, or having it used.It is not impossible to design mechanisms for services to manage your own data and not misuse it.It’s ok if thinking data ownership isn’t important to you - it doesn’t mean it isn’t important or lacks values if you don’t see value in it.For example there would be some who are directly and very gainfully employed in using peoples data and might not want people to own their data.Data ownership isn’t hard, since licensing and drm is possibility for the few and not the many. reply verisimi 20 hours agoparentprev> the power&#x2F;water utilities don&#x27;t make insane amounts of profitThey do make insane profits. And mostly all they are doing is acting as a middle man for the consumer to the energy generator - it is an entirely parasitic role adding no meaningful value, when the infrastructure is in place.They really shouldn&#x27;t make profit at all - of all things that should be provided at cost to citizens, and special rates charged to businesses, this is it. reply jtode 21 hours agoparentprevTHANK you. reply datavirtue 20 hours agoprev [–] I like that data is not own-able. If I own data, corporations can own data. Not cool. reply esafak 19 hours agoparent [–] They do own data. reply teddyh 16 hours agorootparentAnd it is, indeed, not cool. reply datavirtue 11 hours agorootparentprev [–] How? By keeping it locked away? That&#x27;s their only protection. If it gets out of the gate they have no claim. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The article discusses the rising power of giant technology companies, implying they have become more influential than nation states in setting the political agenda.",
      "The author argues that competition enforcement by governments has been largely ineffective in checking the dominance of these tech giants.",
      "It is suggested that ensuring data ownership rights could be the only effective means to counter the influence of Big Tech and experimenting with capitalism might be necessary."
    ],
    "commentSummary": [
      "The central discussion points in the article involve the significance of data ownership, concerns regarding privacy, and the influence of major tech corporations.",
      "Concerns are raised about the lack of individual control over personal data, the monopolistic practices of companies, and the potential dangers of data accumulation and misuse.",
      "Recommendations include development of legal frameworks, regulation of tech giants, and enhancement of transparency along with user control over data, acknowledging the need for better data collection and privacy mechanisms."
    ],
    "points": 231,
    "commentCount": 175,
    "retryCount": 0,
    "time": 1694433728
  },
  {
    "id": 37469920,
    "title": "WiFi can read through walls",
    "originLink": "https://news.ucsb.edu/2023/021198/wifi-can-read-through-walls",
    "originBody": "Skip to main content University of California, Santa Barbara Arts Science & Tech Society & Culture Campus & Community Events More SUBSCRIBE Mostofi Lab’s latest research makes significant progress in imaging still objects with WiFi, by exploiting the interaction of the edges with the incoming waves using the Geometrical Theory of Diffraction (GTD). This further enables the first demonstration of WiFi reading through walls. SCIENCE + TECHNOLOGY September 11, 2023 Wifi can read through walls Sonia Fernandez Researchers in UC Santa Barbara professor Yasamin Mostofi’s lab have proposed a new foundation that can enable high-quality imaging of still objects with only WiFi signals. Their method uses the Geometrical Theory of Diffraction and the corresponding Keller cones to trace edges of the objects. The technique has also enabled, for the first time, imaging, or reading, the English alphabet through walls with WiFi, a task deemed too difficult for WiFi due to the complex details of the letters. For more details on this technology, check their video at https://www.youtube.com/watch?v=pvqL3gqGDeM “Imaging still scenery with WiFi is considerably challenging due to the lack of motion,” said Mostofi, a professor of electrical and computer engineering. “We have then taken a completely different approach to tackle this challenging problem by focusing on tracing the edges of the objects instead.” The proposed methodology and experimental results appeared in the Proceedings of the 2023 IEEE National Conference on Radar (RadarConf) on June 21, 2023. Image Photo Credit Courtesy Mostofi Lab To showcase the capabilities of the proposed pipeline in imaging complex details, the researchers have shown how WiFi can image the English alphabet, even through walls This innovation builds on previous work in the Mostofi Lab, which since 2009 has pioneered sensing with everyday radio frequency signals such as WiFi for several different applications, including crowd analytics, person identification, smart health and smart spaces. “When a given wave is incident on an edge point, a cone of outgoing rays emerges according to the Keller’s Geometrical Theory of Diffraction (GTD), referred to as a Keller cone,” Mostofi explained. The researchers note that this interaction is not limited to visibly sharp edges but applies to a broader set of surfaces with a small enough curvature. “Depending on the edge orientation, the cone then leaves different footprints (i.e., conic sections) on a given receiver grid. We then develop a mathematical framework that uses these conic footprints as signatures to infer the orientation of the edges, thus creating an edge map of the scene,” Mostofi continued. Image Photo Credit Courtesy Mostofi Lab Sample imaging in non-through-wall settings: Their method can image details of letter P in ways not possible before. More specifically, the team proposed a Keller cone-based imaging projection kernel. This kernel is implicitly a function of the edge orientations, a relationship that is then exploited to infer the existence/orientation of the edges via hypothesis testing over a small set of possible edge orientations. In other words, if existence of an edge is determined, the edge orientation that best matches the resulting Keller cone-based signature is chosen for a given point that they are interested in imaging. “Edges of real-life objects have local dependencies,” said Anurag Pallaprolu, the lead Ph.D. student on the project. “Thus, once we find the high-confidence edge points via the proposed imaging kernel, we then propagate their information to the rest of the points using Bayesian information propagation. This step can further help improve the image, since some of the edges may be in a blind region, or can be overpowered by other edges that are closer to the transmitters.” Finally, once an image is formed, the researchers can further improve the image by using image completion tools from the area of vision. “It is worth noting that traditional imaging techniques result in poor imaging quality when deployed with commodity WiFi transceivers,” added Pallaprolu, “as the surfaces can appear near-specular at lower frequencies, thus not leaving enough signature on the receiver grid.” The researchers have also extensively studied the impact of several different parameters, such as curvature of a surface, edge orientation, distance to the receiver grid, and transmitter location on the Keller cones and their proposed edge-based imaging system, thereby developing a foundation for a methodical imaging system design. \"We have then taken a completely different approach to tackle this challenging problem by focusing on tracing the edges of the objects instead.\" In the team’s experiments, three off-the-shelf WiFi transmitters send wireless waves in the area. WiFi receivers are then mounted on an unmanned vehicle that emulates a WiFi receiver grid as it moves. The receiver measures the received signal power which it then uses for imaging, based on the proposed methodology. The researchers have extensively tested this technology with several experiments in three different areas, including through-wall scenarios. In one example application, they developed a WiFi Reader to showcase the capabilities of the proposed pipeline. This application is particularly informative as the English alphabet presents complex details which can be used to test the performance of the imaging system. Along this line, the group has shown how they can successfully image several alphabet-shaped objects. In addition to imaging, they can further classify the letters. Finally, they have shown how their approach enables WiFi to image and read through walls by imaging the details and further reading the letters of the word “BELIEVE” through walls. They have furthermore imaged a number of other objects as well, showing that they can capture details previously not possible with WiFi. Overall, the proposed approach can open up new directions for RF imaging. Image Photo Credit Courtesy Mostofi Lab From left to right: Ph.D. student Anurag Pallaprolu; former Ph.D. student Belal Korany and Professor Yasamin Mostofi More information about the project can be found at https://web.ece.ucsb.edu/~ymostofi/WiFiReadingThroughWall Additional information about Mostofi’s research is available at http://www.ece.ucsb.edu/~ymostofi/. Mostofi can be reached at ymostofi@ece.ucsb.edu. Media Contact Sonia Fernandez Senior Science Writer (805) 893-4765 sonia.fernandez@ucsb.edu Share this article Download Printable PDF About UC Santa Barbara The University of California, Santa Barbara is a leading research institution that also provides a comprehensive liberal arts learning experience. Our academic community of faculty, students, and staff is characterized by a culture of interdisciplinary collaboration that is responsive to the needs of our multicultural and global society. All of this takes place within a living and learning environment like no other, as we draw inspiration from the beauty and resources of our extraordinary location at the edge of the Pacific Ocean. Related Stories Image SEPTEMBER 11, 2023 Experimental physicist David Weld to investigate the role of feedback and measurement in quantum systems Image SEPTEMBER 6, 2023 The current landscape of women’s health — and how it might be improved Image AUGUST 30, 2023 Immersive research experiences translate into an inspiring summer for undergraduate students Image AUGUST 30, 2023 UC Santa Barbara quantum scientists to conduct NSF-funded research to pursue quantum-scale sensor technologies Copyright © 2023 The Regents of the University of California. All Rights Reserved. PrivacyTerms of Use AccessibilityWebmaster Explore All News Arts Science & Tech Society & Culture Campus & Community Events About Contact Us For Media Public Affairs & Communications Connect Facebook Twitter Vimeo YouTube UCTV RSS",
    "commentLink": "https://news.ycombinator.com/item?id=37469920",
    "commentBody": "WiFi can read through wallsHacker NewspastloginWiFi can read through walls (ucsb.edu) 229 points by geox 17 hours ago| hidepastfavorite160 comments woodrowbarlow 14 hours agoPSA: Nokia is out there pitching a vision for what 6G mobile networks will look like, and they&#x27;re pitching this as a _feature_ of the media.Nakia wants 6G devices to act as 3D imaging clients, and for network operators to have access to a realtime, 3-dimensional visualization that can see right through walls.this was literally used as a plot point in one of the batman movies a decade ago to highlight how dangerously invasive tech can be.https:&#x2F;&#x2F;www.nokia.com&#x2F;about-us&#x2F;newsroom&#x2F;articles&#x2F;nokias-visi...https:&#x2F;&#x2F;www.bell-labs.com&#x2F;institute&#x2F;blog&#x2F;building-network-si...> A very exciting innovation that 6G will bring to the table would be its ability to sense the environment. The ubiquitous network becomes a source of situational awareness, collating signals that are bouncing off objects and determining type and shape, relative location, velocity and perhaps even material properties. With adequate 6G solutions for privacy and trust, such a mode of sensing can help create a “mirror” or digital twin of the physical world in combination with other sensing modalities. reply reaperman 6 hours agoparent> this was literally used as a plot point in one of the batman movies a decade ago to highlight how dangerously invasive tech can be.In the movie Charlie’s Angels (2000) the supervillain technology allowed them to track the locations of the vast majority of people on the planet in realtime.The real world has already jumped the shark for many different fictional supervillain doomsday technologies. reply b3orn 53 minutes agoparentprevIt&#x27;s not just Nokia, basically everyone working on 6G proposoals is working on this under the name joint communication and sensing. reply conradev 10 hours agoparentprevMy understanding is that the 3D imaging is somewhat inherent to how the protocol operates: higher frequency data over a wider band of frequencies means they can locate you more precisely.Cell phone network operators need to know your location in order to route traffic to the correct tower in order to reach you, and that is not changing anytime soon. Same principle for WiFi beamforming. reply femto 6 hours agorootparentIt&#x27;s deeper than that. You can&#x27;t have advanced communications without gleaning the information needed to form a 3D image.To get maximum data throughput, modern communications systems measure how the channel (ie. environment) changes the radio signals and then reverses those changes in the receiver. (search term: channel estimation). So it&#x27;s inherent that a modern communications system is modelling its environment. A primary way communications systems become better is to increase the sophistication of their environment model.Once the model becomes sophisticated enough, the only difference between a radar and a communication system is which information you choose to extract: the information the environment imprinted&#x2F;modulated on the radio signal&#x2F;carrier (ie. the model of the environment) or the information the transmitter imprinted&#x2F;modulated on the radio signal&#x2F;carrier (ie. the message). The first is radar, the second is communications. There is no technical reason why you can&#x27;t extract both. reply uoaei 6 hours agorootparentThis is not a technical question but a moral one in the face of such surveillance apparatuses as exist today.A pen can be both a writing implement and a deadly weapon. But until someone decides to use it as a deadly weapon, it&#x27;s not one. Luckily we don&#x27;t typically hear people explaining the anatomy of soft tissues in the human neck when talking about pens. reply jack_pp 5 hours agorootparentExcept you can&#x27;t mass kill people with pens. Or you can&#x27;t hijack someone else&#x27;s pen and kill them. You can mass surveil people with this tech and you can be sure it will be used that way sooner or later. reply deafpolygon 4 hours agorootparentSooner, most likely. reply femto 5 hours agorootparentprevAgree. Hence the qualification that there is no technical reason why the information can&#x27;t be extracted. Any barriers are non-technical.The problem is that this information is inherent to a communications system. It can&#x27;t be separated. Communications is pervasive, so channel information is pervasive. How does one control something that is pervasive?It&#x27;s a Catch-22: Do we implement a surveillance apparatus to prevent people from accessing the channel information that can be used to build a surveillance apparatus? reply ClumsyPilot 5 hours agorootparent> Do we implement a surveillance apparatus to prevent people from accessing the channel informationthats the wrong question - simply remove all barriers that prevent consuners from inspecting inner working if their devices, and attach large statutory compensation in case a consumer privacy is violated. reply hoseja 29 minutes agorootparentprevKilling people isn&#x27;t a typical side-effect of normal usage of pen, unless you want to go into comparing might with swords. reply judge2020 7 hours agorootparentprevNot just to the correct tower, but also for adaptive beamforming. reply darkclouds 9 hours agorootparentprevI had an app that ran on Android about a decade ago, which let the user ignore some of the cell masts, so you could not be triangulated, it let you stick to just communicating with the cell mast of your choice.Dont know if its still around. reply thaumasiotes 7 hours agorootparentprev> Cell phone network operators need to know your location in order to route traffic to the correct tower in order to reach you, and that is not changing anytime soon.But that&#x27;s obviously false. They can know which tower to route your traffic to by the simple fact that that&#x27;s where your traffic came from.They know where you are because you broadcast simultaneously to all of their towers, but that&#x27;s not something they need. reply selectodude 7 hours agorootparentThat assumes a stationary target. As cell sizes shrink due to higher frequencies, the need to anticipate where you are and where you&#x27;re going goes up. reply wahnfrieden 14 hours agoparentprevUS govt and military give a lot of money to Nokia reply Scanner771 13 hours agorootparentNokia has NSA rooms in their R&D offices. It&#x27;s creepy. reply wolverine876 12 hours agorootparentThey revealed that publicly? (Do you work for Nokia? (or the NSA?)) reply anon____ 9 hours agorootparentI think it&#x27;s a misunderstanding. I found a couple of articles mentioning both Nokia and NSA, but here NSA stands for \"Non-Standalone 5G network\".Here&#x27;s a press release, for example: Nokia selected by Dedicado for 5G NSA network in Uruguay (https:&#x2F;&#x2F;www.nokia.com&#x2F;about-us&#x2F;news&#x2F;releases&#x2F;2022&#x2F;12&#x2F;08&#x2F;noki...)And a Linkedin profile (he must have a room in the office): Yuriy Pavlov - NSA Infrastructure Information Systems Manager. Nokia. (https:&#x2F;&#x2F;www.linkedin.com&#x2F;in&#x2F;yuriy-pavlov-1969904) reply antoineMoPa 12 hours agorootparentprevIf he does, he probably does not anymore. reply 37469920away 12 hours agorootparentprevWhat&#x27;s even creepier is that parent company also owns Github. reply rgblambda 12 hours agorootparentMicrosoft purchased Nokia&#x27;s Devices & Services division, and rebranded it as Microsoft Mobile. Nokia then pivoted to telecommunications infrastructure and IoT. So there&#x27;s no longer a relationship between the two companies. reply ianburrell 9 hours agorootparentAlso, the Nokia smartphone brand is licensed to HMD Global. reply darkclouds 9 hours agorootparentprevYeah someone at Microsoft thought they could get Windows CE to run on the popular Nokia 3210. &#x2F;s reply seanp2k2 12 hours agorootparentprevahh, the golden days when the smartphones that mattered ran Symbian and we thought Elop was going to be our Elon. reply harry8 8 hours agorootparentN900 ran linux and it mattered reply Yajirobe 12 hours agorootparentprevMicrosoft? reply jacobwilliamroy 11 hours agoparentprevI had a discussion with my church group about this and it was absolutely fascinating. On the one hand they welcomed the ubiquitous observation and judgement of all people, because they thought that would make it easier to control people&#x27;s behavior. But also someone pointed out that is what the anti-christ would do. In the end there wasn&#x27;t any real consensus on whether or not mass surveillance was good or bad. reply seabass-labrax 11 hours agorootparentDid the church group not already believe there to be an entity capable of ubiquitous observation and judgement of everyone, that as an added bonus happens to be entirely benevolent? I&#x27;m not sure how any human-made competition in this department could be beneficial. reply wkat4242 5 hours agorootparentThis is indeed a big paradox in organized religions.When I was young my parents wanted me to learn about religions so I could make my own choice about which to follow. But I was constantly like \"wtf how does this make sense???\". And disruptive in class :) They had to take me out of Sunday school.Another thing I never understood is predestination in calvinist religions, which are big in Holland. They believe it&#x27;s already decided whether you go to heaven or hell, regardless of your actions during your life.So how would you live your life? Personally I&#x27;d go for maximum enjoyment because whatever happens is already decided. But no, they&#x27;re very strict and regimental in general. Never understood why. But of course I did only have Sunday school for a short while :) reply ben_w 2 hours agorootparent> Another thing I never understood is predestination in calvinist religions, which are big in Holland. They believe it&#x27;s already decided whether you go to heaven or hell, regardless of your actions during your life.> So how would you live your life? Personally I&#x27;d go for maximum enjoyment because whatever happens is already decided. But no, they&#x27;re very strict and regimental in general. Never understood why. But of course I did only have Sunday school for a short while :)I heard about the predestination thing well before I heard of Newcomb&#x27;s paradox, but now I realise this is basically the same as \"one box, or both boxes?\" reply canadiantim 11 hours agorootparentprevThat&#x27;s terrifying that people thought it was potentially good reply quickthrowman 11 hours agorootparentprevWhy do your fellow congregants want to control the behavior of others? Why can’t they just focus on their own lives and their own community instead of what other people outside of their community are doing? reply db48x 6 hours agorootparentYou may not be paying attention. A decent slice of the population wants the government to control everything, all of the time. These people are all around you, all of the time, no matter where you are. reply haswell 6 hours agorootparentprevNot OP, and I can only speak for the circles I grew up in, but some churches are full of deeply traumatized people. I think some of the authoritarian tendencies have roots in a deep desire&#x2F;need to regain some kind of feeling of control in their lives, and here’s this group of people that meets every week who provides a level of comfort and community while offering a gospel that can both satisfy that need while making people feel righteous in the process.I don’t want to doxx myself so I’ll keep the details vague, but both of my parents came from disturbing environments and were subject to things that would universally be understood as deeply traumatic. I think they’re good people, but very very confused, and their fundamentalism was a product of the degree of unresolved trauma&#x2F;dysfunction in their lives and their need to impose some kind of order on their circumstances.Not all churches look this way. Mine sure did. Almost everyone had a story. Thankfully I escaped the bubble. But not without consequence. Through no fault of my own, I was indoctrinated into a belief system that I then had to spend decades and counting unwinding and unlearning. I mention this because a lot of people want to focus on other people’s lives because that’s what they were taught to do. People were born into beliefs they didn’t choose.None of which is to excuse the behavior. But I’ve seen up close where it comes from. reply SamPatt 6 hours agorootparentThanks for sharing your story. Mine is similar. Always interesting to see someone else take this life path. reply beardedwizard 10 hours agorootparentprevThis assumes quite a bit about the group. Is it wrong to discuss topics like this and share different views? Why do you want to control this groups private discussions? reply vore 10 hours agorootparentI don&#x27;t think the parent is controlling the discussion, or really even saying it&#x27;s wrong to discuss this and share their views. But, by the same token, the parent is also allowed to express their concern about people who do hold these views here. reply quickthrowman 9 hours agorootparentprevYou are correct that I am making assumptions, I’m assuming this group wants to control the behaviors of people outside of their religious group which may not be the case.I don’t want to control their discussion, it’s fine to discuss things and share different views. I want to understand why a group of people would welcome a panopticon because it would make people easier to control. reply HWR_14 7 hours agorootparentprevWhy should they control the behavior of people in their congregation? I associate controlling the members of your own community with cults. reply mc32 10 hours agorootparentprevI think they implied observing the behavior of fellow congregants not outsiders. Not sure if that makes it any better. But I think that’s what the poster meant.That said it is definitely what any competent authoritarian would want. reply akomtu 9 hours agorootparentprevLast time it was the end of the Aries age, when Nero played the role of the antichrist. Today we&#x27;re approaching the of the end of the Pisces&#x27; age, and Nero 2.0, fixed and engrossed, will be equipped with brain reading devices (the future of neuralink), machine intelligence and human-like machines. Thinking in private will be possible only at the abstract level, as all the internal monologue will be carefully recorded and analyzed. He will rise to power on the wings of nihilist technocrats, and will institute the law for those who want to be free, and freedom for those who want to be free from the law. reply Spivak 14 hours agoparentprevWell, because it is a feature. It&#x27;s really cool and I already have ideas for projects I want to do with it. An omnidirectional way to map an entire space that doesn&#x27;t have the limitations of or require cameras is incredible. And one that I can potentially use to map myself as I walk around. It&#x27;s basically the end game of motion controls.The popularity will explode the moment someone makes a commercial where someone is cooking with something messy and using their phone without ever touching it.It&#x27;s the people who make or break it. \"This technology is too dangerous and must be destroyed, but hold on I need to use it first because it&#x27;s really useful\" doesn&#x27;t feel like the strongest condemnation. reply YakBizzarro 14 hours agorootparentThe only result will be that the router of my neighbor, provided by his ISP, will happily reports the inside of my apartment. Sorry, I can be excited for a radar-based controller for a console, but as part of wifi, I can&#x27;t really find any legit use reply solardev 13 hours agorootparentBeamforming around moving (or even static) obstacles? Integrated motion sensing with fewer false positives for smart bulbs, doorbells, whatever? Or more realistically, your TV can make sure you don&#x27;t skip the commercials. I probably wouldn&#x27;t use that stuff myself either, but it&#x27;s interesting to think about.Why would I care that my neighbor knows we&#x27;re home and moving around? If they really wanna creep on us, they can already use IR cameras or audio amplification or laser mics or whatever. reply rfrec0n 12 hours agorootparentWalls of homes are usually insulated enough to make an IR camera useless unless it&#x27;s inside the home. It would be good for identifying cracks that heat can seap through though. Surveillance by laser microphones can easily be mitigated by curtains or blinds. Both of those also require the person spying to intentionally use them to spy. There is no legal commercial device that could prevent your neighbor&#x27;s Xfinity Hotspot from selling what you do in your own home to Facebook&#x2F;Google to use to target you with ads. reply OkayPhysicist 12 hours agorootparentIt would come off as a bit paranoid, but chicken wire would block wifi signals. reply rightbyte 12 hours agorootparentIt is commonly used for older plastered facades. Maybe there will be a resurgence. reply sroussey 9 hours agorootparentIt’s used for stucco as well, which is everywhere. reply buran77 13 hours agorootparentprev> If they really wanna creep on us, they can already use IR cameras or audio amplification or laser mics or whatever.There&#x27;s always a more sophisticated way to do something bad. Why would that be a good reason to lower the bar for doing it? reply try_the_bass 12 hours agorootparentThis is the first time I&#x27;ve seen someone use this question in defense of privacy, instead of against it. reply bippihippi1 9 hours agorootparentprevsurveillance into private places is illegal. you can&#x27;t film in someone&#x27;s window, you can&#x27;t wifi vision through someones walls. whether or not that is prevented from happening by manufacturers and that the law is enforced depends on a lot of things reply ipaddr 7 hours agorootparentYou can take infrared photos currently of someone&#x27;s house and use that in court reply Spivak 14 hours agorootparentprevI, maybe naively, assumed this capability will also comes to handhelds but yeah if it&#x27;s only for stationary APs then it&#x27;s kinda lame. reply AnthonyMouse 11 hours agorootparentprevThe problem is not that you can buy a device that does this. The problem is that they&#x27;ll put it in devices you can&#x27;t easily avoid buying, don&#x27;t control the firmware of or which have an abominable security record.It&#x27;s fine if I can take live 3D radar images of the inside of my bedroom. Not fine if someone else can. reply throw0101c 16 hours agoprevThis is not (completely) new. 2019 paper entitled \"Passive Radar based on 802.11ac Signals for Indoor Object Detection\":* https:&#x2F;&#x2F;ieeexplore.ieee.org&#x2F;document&#x2F;8904842There is an IEEE Working Group to create an extension for &#x27;active radar&#x27;:> IEEE 802.11bf will enable stations to inform other stations of their WLAN sensing capabilities and request and set up transmissions that allow for WLAN sensing measurements to be performed, among other features. WLAN sensing makes use of received WLAN signals to detect features of an intended target in a given environment. The technology can measure range, velocity, and angular information; detect motion, presence, or proximity; detect objects, people, and animals; and be used in rooms, houses, cars, and enterprise environments. The targeted frequency bands are between 1 GHz and 7.125 GHz (MAC&#x2F;PHY service interface) and above 45 GHz (MAC&#x2F;PHY).* https:&#x2F;&#x2F;standards.ieee.org&#x2F;beyond-standards&#x2F;ieee-802-11bf-ai...Presentation on the extension and Wi-Fi sensing:* https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=I3GmgO9biH87&t=5m10s reply andrewtesting44 16 hours agoparentIt is novel in terms of using physically accurate models such as edge diffraction to localize edges instead of the object as a whole. Most narrowband radar based imaging approaches consider extended objects as a collection of omnidirectional point scatterers, which may not be the most optimal representation.... reply erikerikson 16 hours agoparentprevYes, I have met technologists who claimed to be working on the tracking of people in their homes using Wi-Fi. There are great uses such as elder health monitoring (i.e. not fallen and can&#x27;t get up) but others too... reply godelski 16 hours agorootparentI remember seeing some presentations about WiFi gait recognition too. Quick google turned up this __2016__ paperhttps:&#x2F;&#x2F;dl.acm.org&#x2F;doi&#x2F;10.1145&#x2F;2971648.2971670 reply pmontra 13 hours agoparentprevThis is from 2013 https:&#x2F;&#x2F;dspace.mit.edu&#x2F;handle&#x2F;1721.1&#x2F;82183 reply solardev 16 hours agoprevMan, I&#x27;d settle for wifi that just lets me internet through walls reliably. reply stronglikedan 16 hours agoparentMy simple 5yo, non-wifi6 router gets me a reliable signal through at least two walls, so I would imagine any somewhat modern router would meet your requirements. reply solardev 16 hours agorootparentIn all seriousness, it depends on your frequency used, building materials, national limits on WiFi output power (which some routers&#x2F;firmwares respect more than others), etc.5 GHz in particular has trouble passing through concrete and metal. If you have a small wood house or apartment it often isn&#x27;t an issue, but if your office has a lot of concrete and steel, etc. it could be problematic. Those enterprise mesh networks exist for a reason :)https:&#x2F;&#x2F;blog.ibwave.com&#x2F;a-closer-look-at-attenuation-across-...https:&#x2F;&#x2F;help.keenetic.com&#x2F;hc&#x2F;en-us&#x2F;articles&#x2F;213968869-Wi-Fi-... reply doubled112 15 hours agorootparentThe metal mesh in some plaster walls seemed to cause a lot more signal drop than I expected in one place I lived.5GHz was basically a no go. It wasn&#x27;t a huge loss since few devices were running it back then. reply NoZebra120vClip 15 hours agorootparentWhen I was in high school, my parents hired some contractors to put an addition on the family home and do some improvements in most of the rooms.So the most arduous part of the whole job appeared to be the demolition to start with. They started pounding into the thick plaster walls, and revealed a thick mesh of solid steel reinforcement. Of course, that took ages to take out, wherever they had to deal with such a wall.And you know what? I was absolutely appalled by the chintzy material that went in to replace it. They just brought this drywall, you know, and I got to touch it and examine it, and I couldn&#x27;t believe how flimsy it was, when compared to the reinforced plaster they&#x27;d just taken out. I mean, like, there were cost and time considerations, but it seemed like a travesty to me. Like we were sacrificing half of our solid, valuable home for a mere facsimile in the other parts.Today, the WiFi is fairly bad. My dad only has the one router in a distant corner of the den. I don&#x27;t know how reception is directly upstairs, where his bedroom is, but the downstairs bedroom can barely keep a signal going at the best of times.That home renovation was happening around 1988, so possibly too early to really think of putting Ethernet in every room, but my dad would&#x27;ve been the dad to do it. reply vel0city 14 hours agorootparentSure, the drywall is flimsier than the plaster walls you had before but they are way easier to work with, make modifications to, and repair. And for normal usage, they&#x27;re plenty reliable. The walls themselves shouldn&#x27;t be a part of what makes the house \"solid\", that&#x27;s the job of the framing behind the plaster or drywall. reply samus 14 hours agorootparent> The walls themselves shouldn&#x27;t be a part of what makes the house \"solid\", that&#x27;s the job of the framing behind the plaster or drywall.It&#x27;s actually a fairly recent trend to not build load-bearing walls anymore and instead really on a skeleton. Walks can very well be constructed to be load-bearing. But, as you indicate, the resulting building would be more difficult to modify. reply throw0101c 14 hours agorootparentprev> They just brought this drywall, you know, and I got to touch it and examine it, and I couldn&#x27;t believe how flimsy it was, when compared to the reinforced plaster they&#x27;d just taken out.Exactly what are you getting by having the &#x27;less flimsy&#x27; plaster and what are you losing with the &#x27;flimsy&#x27; drywall? (I ask this as someone with three uncles that work in construction&#x2F;renos.) reply kenhwang 12 hours agorootparentThe biggest benefit I&#x27;ve noticed with plaster walls is the soundproofing. There&#x27;s more layers of much denser material.My walls are 1 inch of plaster with metal lath (vs the typical 1&#x2F;2 thickness for drywall), on top of traditional wood slat lath, then insulation and studs. Typically if you have construction old enough for lath and plaster walls, they might also have independent studs per side, further isolating sound transfer.It&#x27;s also less porous and doesn&#x27;t hold water like drywall, making it quite mold resistant. replykenhwang 15 hours agorootparentprevMy very modern many antenna WiFi6 router has a very hard time going through even one wall. Turns out metal lath and plaster walls do a very good job of blocking radio signals. reply whiddershins 14 hours agorootparentwooden lath and plaster the same. I assume it is the plaster, not the lath. reply Aardwolf 2 hours agoparentprevBut not through the neighbors walls preferably to not interfere with each other&#x27;s wifi strength... reply system2 10 hours agoparentprevuse 2.4g + mesh. better yet, yet ubiquiti unifi dishes (3 would suffice for 2000sqf house). reply solardev 5 hours agorootparentI just ended up dragging a long ethernet cable along the wall. Gigabit that&#x27;s always reliable... wifi never feels even remotely as fast or stable. reply system2 4 hours agorootparentSame here, working on cat7 for the entire house. reply nighthawk454 16 hours agoprevRelated:2013 - gesture recognition from Wi-Fi https:&#x2F;&#x2F;wisee.cs.washington.edu&#x2F;2013 - see through walls with Wi-Fi https:&#x2F;&#x2F;people.csail.mit.edu&#x2F;fadel&#x2F;papers&#x2F;wivi-paper.pdf2023 - dense pose estimation from Wi-Fi https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2301.00250 reply pcthrowaway 15 hours agoprev&#x27;read&#x27; is misleading. It&#x27;s determining what letters are represented by 3-dimensional letters.It can&#x27;t read 2-dimensional print on paper. Now that would be a massive (and terrifying) accomplishment reply rgblambda 11 hours agoparentYeah it was kind of misleading&#x2F;clickbaity that they worded it that way. I guess they wanted to highlight how sharply they could image the room. reply tomxor 14 hours agoprevSomewhere.. Someone.. Who wrote down their wifi password, on their fridge, with giant 3d magnetic letters, is shitting themselves right now.&#x2F;jkInteresting paper though, I wonder what non-infosec applications it might have. reply ambrose2 14 hours agoparentWhat about a QR code that guests can scan to log into your WiFi without typing an explicit password. reply ericbarrett 13 hours agorootparentUnless I&#x27;m misunderstanding you, this already exists: https:&#x2F;&#x2F;qifi.org&#x2F;Format is described on the page if you want to do it manually.Of course the plaintext password is still encoded in the QR code data, so it&#x27;s not very secure, but great for home guests. reply netrus 13 hours agorootparentOn my Android Samsung Galaxy, when I want to know the password of a saved Wifi, I generate a share-QR, screenshot it, and have a QR scanner scan the picture to extract the password. It drives me nuts, the password is clearly not secure&#x2F;protected, still the UI will only give me the QR code, not the plaintext. PLEASE tell me I am just too stupid to find the right menue! reply peterleiser 11 hours agorootparentYeah, it&#x27;s annoying. On my Samsung phone I have a \"save image\" option, which I can then view the photo in Google photos which has the Google lens option that will show the password. reply Hikikomori 8 hours agorootparentprevOn my pixel I get both qr and password. reply judge2020 7 hours agorootparentprevI prefer https:&#x2F;&#x2F;mywifisign.com&#x2F;en for the modern-esque background and verbiage. reply Obscurity4340 12 hours agoparentprevHey! This happens &#x2F;s reply brian-armstrong 16 hours agoprevYou ever finish working on something and then think to yourself, \"damn, I just created something incredibly evil\"? reply judge2020 16 hours agoparent3-letter agencies have reportedly been using RF for similar purposes for almost a decade https:&#x2F;&#x2F;www.usatoday.com&#x2F;story&#x2F;news&#x2F;2015&#x2F;01&#x2F;19&#x2F;police-radar-.... reply brian-armstrong 16 hours agorootparentSo we agree it is evil then reply zaat 14 hours agoparentprevI was working on a IT consolidation project in a remote country branch, replacing the old systems with those of the global IT infrastructure and a new local server managed by the global IT team. When I finished my work I was standing in the small servers room with the local IT admin, he said something that disclosed he felt there was nothing important for him to do anymore. The move was the right path for the business. I felt terrible. reply thomastjeffery 14 hours agoparentprevHow many steps removed is a bad actor from making it themselves?Usually, we can&#x27;t rely on things simply not being invented, so we do the next best thing: invent it, and use the invented thing to learn how to manage the risk that thing introduced. reply flangola7 14 hours agorootparentThat&#x27;s not secund best. You can not invent it in the first place too. We have intentionally throttled recombinant DNA research for decades. reply upwardbound 7 hours agorootparentYou can also make it illegal, like private-sector research into nuclear bomb development. reply COGlory 14 hours agorootparentprevWhat recombinant DNA research do you believe is not being done? reply rightbyte 12 hours agoparentprevI accidentally created a 200 loc bossware with PythonCV that reported if I was in-front of my computer&#x27;s webcam to a dashboard with videofeed, for a sales meeting with Microsoft were we were supposed to show we could do stuff. I shit you not. I was so proud that I could encircle my face with a square that I didn&#x27;t consider the obvious use case for it. reply user_7832 15 hours agoparentprevEthics really should be mandatory for anybody making&#x2F;designing anything. Some unis do fortunately have mandatory ethics courses depending on your programme. reply pokeymcsnatch 4 hours agorootparentEthics is (often?) required in engineering curriculum, but it&#x27;s mostly along the lines of \"don&#x27;t lie about work you didn&#x27;t do then charge for it\". There&#x27;s nothing that touches on only using your powers for good. Like building &#x27;autonomous&#x27; cars then letting them loose in public before they&#x27;re proven, or building out algorithms designed to get people addicted to rage bait, or building in planned obsolesce, or building a device that uses WiFi to map out a private domicile without the occupant&#x27;s knowledge.Engineering ethics courses all boil down to \"don&#x27;t lie about stuff\", not \"think about the potential consequences of what you&#x27;re building\". reply no_time 4 hours agorootparentprevBold of you to assume that anyone will care about what they heard in ethics class when presented with the opportunity to get rich and powerful. reply dogman144 14 hours agoprevAlready exists in prod. At a meetup several years ago, it was demonstrated that you could track a person’s location in an adjacent room by triangulating Wi-Fi interference.I’m not into RF so this is a bit imprecise, but it took like a RPi with GNU radio, a second router, and some code to diff the signals into a location.The demos were compelling, you could see a heatmap of a user waving and so on. This is a product already sold. reply zerd 13 hours agoparentThe page, paper and video say that as well. The difference here is that this is tracing still objects. reply madars 16 hours agoprevVery impressive! Famous previous work captured moving objects and did gesture recognition through the walls https:&#x2F;&#x2F;people.csail.mit.edu&#x2F;fadel&#x2F;wivi&#x2F;project.html but this new research can capture still objects.UCSB paper: https:&#x2F;&#x2F;ieeexplore.ieee.org&#x2F;stamp&#x2F;stamp.jsp?tp=&arnumber=101... (\"Analysis of Keller Cones for RF Imaging\") reply Feegorg 10 hours agoprevOne of my customers referred me to this thread. We have been developing our NED Passive Radar technology for 5 years now, and have field deployable, vehicle mountable, drone mountable, and pocket sized, rechargeable passive radar RF datalogging systems you can use to locate and identify devices of interest, such as drones, cell phones, wifi and bluetooth devices. You can image the environment in 3D via ambient RF emissions using our spherical antenna arrays. Basically right now our systems log raw RF signals from SMA connected antenna arrays to a micro SD card in .csv format, or you can stream it realtime via the usb port to a computer and use our python library. We have model with 4 RF ports that senses from 2 MHz to 10 GHz, and a second model with 10 ports that senses up to 84 GHz. They are quite affordable also. Its great to see the interest in this area, if you would like more info or want to try what we have come up with contact us at www.xadite.com reply macawfish 11 hours agoprev\"Integrated sensing and communications\". This is what 5G&#x2F;6G+ are all about. This is what powers \"internet of things\", \"smart cities\" and \"total sensor fusion\". This is why The Five Eyes cautioned legislators about Huawei 5G infrastructure.https:&#x2F;&#x2F;link.springer.com&#x2F;book&#x2F;10.1007&#x2F;978-981-99-2501-8https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=aaaLl_5kUQEhttps:&#x2F;&#x2F;www.youtube.com&#x2F;@integratedsensingandcommun7276 reply r00fus 17 hours agoprevImpressive. Now how do we defend against malicious use of this POC? reply swader999 16 hours agoparentThis is what I use: YShield RF Shielding Paint - 5L Bin - HSF54 - Blocks Wifi, Smart Meters, Cell Phones, Etc. https:&#x2F;&#x2F;a.co&#x2F;d&#x2F;csJJslD reply dylan604 15 hours agorootparentgood lord. that&#x27;s cool, but wow would that be expensive. did you only use this on the exterior walls of the house? how much primer did it take to get the paint to match the rest of the walls? also, what about windows? reply swader999 15 hours agorootparentI did it inside my bedroom, ceiling and all walls because we are fairly close to a cell tower. The rf meter I have went from 3000-5000 down to 7-10. I can&#x27;t type the symbols in my phone for the units. Better sleep for sure since doing that a couple of years ago.Windows we used film, curtains shielded too. Two coats primer. Put copper stripts to ground as well on walls before paint. Didn&#x27;t do floor so some rf gets in and out which is ok actually, you can create a focusing effect if you aren&#x27;t careful about it. reply flemhans 14 hours agorootparentDo you sleep better because you&#x27;re not on your phone so much? I&#x27;ve heard that you should avoid screens in bed. reply swader999 12 hours agorootparentI don&#x27;t seem to wake up as much in the middle of the night reply dylan604 12 hours agorootparentso what is it about radio waves that you feel is disrupting? my only reference to this is the Chuck McGill character from Better Call Saul reply swader999 11 hours agorootparentOh man, that&#x27;s a rabbit hole. I always slept better at my parents cabin. They eventually got wifi and I stopped noticing any difference. Then tried an emf shielded top and it worked really well. Then did the paint on the walls of bedroom.If you want science, it&#x27;s tough, nobody is going to fund it and it&#x27;s harder and harder to find a control group.There&#x27;s studies of dubious quality if you Google emf and sleep. reply d2049 6 hours agorootparentprevA couple questions —Could you link to the film you used, and also the curtains?Did this at all block your ability to use your own cellphone? reply yomlica8 15 hours agorootparentprevHow well does this work? Always sounded to good to be true to me. reply orbital-decay 14 hours agorootparentThe paint itself probably works well if it&#x27;s conductive - it&#x27;s just a simple Faraday shield. The problem is with testing. For example most Faraday pouches and bags turn out to be snake oil upon testing, as they let the signal out through some discontinuities, even though the mesh itself works perfectly and most of the time you don&#x27;t have the signal. reply surfingdino 14 hours agorootparentprevDo I sense a future asbestos-like scandal brewing here? reply CyberDildonics 13 hours agorootparentWhat evidence are you basing that on? reply akira2501 4 hours agoparentprevNoise&#x2F;Jamming. Signal&#x2F;Timing Spoofing. Environmental Spoofing. Also anyone using it paints a giant target on their back. These are all true of any active signal imaging system.Somewhat related but I always thought a cool warfare device would be a grenade that contains an inflatable \"soldier\" with a built in heat signature. Toss them around for IR imaging spoofing.Anyways.. reply IshKebab 15 hours agoparentprevI would start by not building your password out of giant metal letters. reply r00fus 11 hours agorootparentI was thinking of plain old spying by identifying presence of people, perhaps enough characteristics to determine who it is. reply dinkleberg 14 hours agorootparentprevHow else am I supposed to keep track of it? reply aarong11 16 hours agoparentprevLeave the microwave running reply RajT88 15 hours agorootparentBuild a detector which can differentiate from normal traffic and a \"scan\" like this.Wire up an RPI to a motor which reorients a 2.4ghz parabolic dish, first discovering the direction and elevation which best picks up the signal from the \"scanner\". Then, engage the old microwave emitter you&#x27;ve hooked up to the dish.You will like as not fry their equipment. Bonus: the attacker may never have children. reply samus 14 hours agorootparentThat&#x27;s the best part of it: the technique seems to be passive. reply RajT88 11 hours agorootparentFry everything then. reply ranting-moth 16 hours agorootparentprevWouldn&#x27;t you need two microwaves for each axis (XYZ), facing opposite direction? So six microwaves in each room. You have to remove the door switch because you need to leave them running 24&#x2F;7. reply dylan604 15 hours agorootparentlet&#x27;s not be silly. just put it in the attic so each room is covered centrally. you may need a higher wattage microwave though. reply ranting-moth 13 hours agorootparentMine is around 800w. Would a single 1600w be as good in the attic centre as two 800w evenly spaced? reply dylan604 11 hours agorootparentThis all makes me wonder on the efficiency of the original idea. if you have 6 microwaves oriented in each of the directions of an XYZ plane, there would be the assumption that the coverage would be radiating out so there are no gaps in coverage. You could then rotate the rig, but that gets complicated for all 3-axis to rotate. But if you&#x27;re rotating, then why not just one for each axis. Also, is the axis pointing at the ground even necessary to radiate?So now we have to consider the wattage of a rotating system, and how fast does it need to rotate so the time not directly being radiated doesn&#x27;t cause gaps in coverage. There&#x27;s a lot of variable to cover here. replychaosbolt 16 hours agoparentprevTinfoil reply FirmwareBurner 17 hours agoparentprevAsk the Amsish reply lawlessone 14 hours agorootparenti don&#x27;t think being unaware protects you. reply marqueewinq 2 hours agoprevIt would be awesome to see the applications of that to assist blind people &#x2F; replace vision altogether reply mattw2121 17 hours agoprevHopefully we aren&#x27;t documenting company&#x2F;government secrets with letter blocks that you purchase at Hobby Lobby. reply kristopolous 16 hours agoparent\"oh look there&#x27;s the FBI guys again. Go get the giant foam typewriter letters from the back room. \" reply dylan604 15 hours agorootparentat least they a decent enough to drive around with SSID labeled \"FBI Surveillance Van\", so you just need to have an RPi scanning available SSIDs, and enable the SCIF-activate button when the van approaches reply mcbishop 12 hours agoprevCould one use case be: Precisely identifying framing members (studs, rafters) behind stucco, thick lath & plaster, and roof shingles? That would be super valuable for construction work. reply Animats 15 hours agoprevOutline detection of metal objects at distance should be good for remote gun detection. reply greentext 12 hours agoprevWhat are the health implications of this? Isn&#x27;t that like an x-ray?Any good research out there on WiFi, cellular and RF in general? reply localdegen 11 hours agoparenthttps:&#x2F;&#x2F;www.dia.mil&#x2F;FOIA&#x2F;FOIA-Electronic-Reading-Room&#x2F;FileId...This is from the DIA but was acquired via a FOIA request so I don&#x27;t know how valid it is. I would probably start looking at the references first. reply RobotToaster 4 hours agoprevSo is there an open source implementation of this yet? reply iamnotsure 3 hours agoprevOnly when no one is watching. reply beardyw 16 hours agoprevWow, can I fulfill me dream of living in a 1984 style dystopia? reply hinkley 10 hours agoparentGet your ass to Mars. reply HWR_14 7 hours agorootparentBecause Mars will be more or less of a dystopia? reply trilbyglens 15 hours agoprevCool another way to strip away peoples privacy. reply rkwasny 16 hours agoprevWhat did they use as a receiver? how RX Grid was build? reply rkwasny 16 hours agoparentDetails are here: https:&#x2F;&#x2F;web.ece.ucsb.edu&#x2F;~ymostofi&#x2F;WiFiReadingThroughWall reply DrThunder 15 hours agoprevThis isn&#x27;t really that different from sonar is it? reply gonzo41 10 hours agoprevYou know, we don&#x27;t have to create a tech dystopia. It&#x27;s a choice. We do have some agency. reply blobbers 16 hours agoprev [–] Stupid question as someone who worked on wifi for many many years: What is the point of this? How is this remotely useful? There are tons of better technologies to use?Let me guess, this thing puts the wifi into some constant transmit mode and measures loss rates as it passes through objects, and scans in some pattern, measuring loss rates at the other side.Is this just packet based radar? Is this a cute way of saying \"using the 5GHz band to scan through walls when you have a receiver on the other side of your object\"?Here&#x27;s the thing: different materials absorb &#x2F; reflect radio waves with different characteristics. You could just as easily make these letters out of a completely different material that doesn&#x27;t remotely resemble a letter and it could look exactly like a letter.How is this useful? And why is wifi the medium to do it. You can&#x27;t just do this with a regular old driver. Your normal driver will be selecting antennas, adjusting rates for loss rates. This is clearly a dedicated radio with some open source driver that they&#x27;ve hacked to do this.Ugh. This just seems like a dumb waste of time. This isn&#x27;t even a passive radar, as it requires there to be a receiver on the other side. There is no bouncing back of signals.\"It does not require any prior RF data for training a machine learning system for RF sensing.\" Yes, but it does require very specific material characteristics that it is trying to detect at fixed distances. Namely edge keller cones on specific materials, and hoping that other materials don&#x27;t replicate similar patterns. reply stagger87 15 hours agoparentYes, essentially radar. Wifi is the medium because you already have a router in your home.This sort of capability is being introduced into the newest WLAN standards and is being promoted as the next step towards smart homes and devices. The idea being that a standard router can be used to detect human presence, and therefore do things like turn on&#x2F;off lights, HVAC, etc. This might make even more sense in the commercial space.This would be as far as I&#x27;m aware the first attempt at doing something like this without additional hardware (mounted sensors). It should in theory lower the barrier to entry even further.There are higher frequency variations of this that could in theory do things like detect breathing. Some people are talking about it being like the new lifeline button or baby monitor.How well it&#x27;s implemented will ultimately determine it&#x27;s usefulness IMO. reply kenhwang 15 hours agoparentprevOh, hey, I knew someone who helped with research on this while I was at UCSB over a decade ago.From the way they described the goals of their research, it wasn&#x27;t so much using WiFi as radar with specially flashed router drivers doing emitting and receiving, that&#x27;s just a research convenience.The whole point is to passively detect objects using already existing WiFi signals. It&#x27;s easy enough to figure out where the router is, and if the router is regularly noisy enough, the idea is they would have enough data to work with.The research results from a decade ago was able to pinpoint and uniquely identify humans and weapons. Not hard to guess how that could be useful to the DoD. reply sgirard 15 hours agoparentprevI would love to be able to image elements inside a wall cavity: studs, pipes, ductwork, electrical lines. I don&#x27;t know if it&#x27;s possible with this technique, but maybe someday these ideas will lead to something like an x-ray for building structures. reply kenhwang 14 hours agorootparentYou&#x27;re describing a modern off the shelf studfinder. Those already use magnets, radar, and ultrasound to detect studs, pipes, and wires. reply gweinberg 13 hours agorootparentI&#x27;ve got a stud detector and it works like crap. But it&#x27;s pretty old, maybe new ones are better. reply reaperman 6 hours agorootparentProject Farm has a nice review and demo of many studfinders at different price points.[0]0: https:&#x2F;&#x2F;youtu.be&#x2F;sWMJhfMPWn4?si=pA--ZqeMaK_y8hfo reply andrewtesting44 16 hours agoparentprevJust to clarify, the receivers are on the same side as the transmitters reply KeplerBoy 15 hours agorootparentWe call this a monostatic radar. reply Fabricio20 14 hours agoparentprevOne use that personally springs to mind, is if this technology is developed enough, SWAT&#x2F;Rescue teams could use this to find where people are inside buildings. No need for letter-reading precision, just good enough to be easily deployable on-site and work well enough to find where people&#x2F;bodies (big masses of water?) roughly are. reply jdjdjdjdjduuuu 13 hours agoparentprev [–] Hack your internet and see everything in your house could be one use? replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Researchers at the University of California, Santa Barbara, have devised a technology that images still objects, including reading the English alphabet through walls, using WiFi signals.",
      "The technique leverages the Geometrical Theory of Diffraction and the Keller cones for tracing object edges, ensuring high-quality imagery.",
      "The team has rigorously tested this technology, expressing confidence in its potential to pioneer new avenues in Radio Frequency (RF) imaging."
    ],
    "commentSummary": [
      "This summary delves into discussions and potential technologies related to the 6G mobile network, Wi-Fi surveillance, load-bearing constructions, and object detection using Wi-Fi signals.",
      "Privacy concerns and possible misuse of technologies emerge as significant themes throughout these discussions.",
      "There is an emphasis on the futuristic potentials and challenges tied to these tech fields."
    ],
    "points": 229,
    "commentCount": 160,
    "retryCount": 0,
    "time": 1694450709
  },
  {
    "id": 37471354,
    "title": "Blood pressure should be measured lying down: study",
    "originLink": "https://newsroom.heart.org/news/high-blood-pressure-while-lying-down-linked-to-higher-risk-of-heart-health-complications",
    "originBody": "Skip Navigation Skip to main content Heart Attack And Stroke Symptoms Volunteer Donate Search Newsroom News Media Access Policies & Resources Multimedia Resources Connect With Us Newsroom Search News Releases High blood pressure while lying down linked to higher risk of heart health complications Categories: Heart News, Scientific Conferences & Meetings, Stroke News & Brain HealthPublished: September 07, 2023 High blood pressure while lying down linked to higher risk of heart health complications American Heart Association Hypertension Scientific Sessions – Abstract 452 Facebook Twitter LinkedIn Email Print Research Highlights: An analysis of data from a long-running study of more than 11,000 adults from four diverse communities in the United States has found that adults who had high blood pressure while both seated upright and lying supine (flat on their backs) had a higher risk of heart disease, stroke, heart failure or premature death compared to adults without high blood pressure while upright and supine. Adults who had high blood pressure while lying supine but not while seated upright had similar elevated risks of heart attack, stroke, heart failure or premature death as adults who had high blood pressure in both supine and upright positions. The increased risk of heart disease, stroke, heart failure or premature death did not differ by the type of blood pressure medication used among participants. Embargoed until 6:30a.m. CT/7:30 a.m. ET Thursday, Sept. 7, 2023 BOSTON, Sept. 7, 2023 — People who had high blood pressure while lying flat on their backs had a higher risk of heart attack, stroke, heart failure or premature death, according to new research to be presented at the American Heart Association’s Hypertension Scientific Sessions 2023, to be held Sept. 7-10, 2023, in Boston. The meeting is the premier scientific exchange focused on recent advances in basic and clinical research on high blood pressure and its relationship to cardiac and kidney disease, stroke, obesity and genetics. The autonomic nervous system regulates blood pressure in different body positions; however, gravity may cause blood to pool when seated or upright, and the body is sometimes unable to properly regulate blood pressure during lying, seated and standing positions, the authors noted. “If blood pressure is only measured while people are seated upright, cardiovascular disease risk may be missed if not measured also while they are lying supine on their backs,” said lead study author Duc M. Giao, a researcher and a 4th-year M.D. student at Harvard Medical School in Boston. To examine body position, blood pressure and heart health risk, the researchers examined health data for 11,369 adults from the longitudinal Atherosclerosis Risk in Communities (ARIC) study. The data on supine and seated blood pressure was gathered during the enrollment period, ARIC visit 1, which took place between 1987–1989. Participants had their blood pressure taken while briefly lying down at a clinic. The average age of participants at that time was 54 years old; 56% of the group self-identified as female; and 25% of participants self-identified as Black race. Participants in this analysis were followed for an average of 25 to 28 years, up through ARIC visit 5, which includes health data collected from 2011-2013. The researcher’s findings included: 16% percent of participants who did not have high blood pressure — defined in this study as having top and bottom blood pressure measures greater than or equal to 130/80 mm Hg — while seated had high blood pressure while lying supine (flat on their backs), compared to 74% of those with seated high blood pressure who also had supine high blood pressure. In comparison to participants who did not have high blood pressure while seated and supine, participants who had high blood pressure while seated and supine had a 1.6 times higher risk of developing coronary heart disease; a 1.83 times higher risk of developing heart failure; a 1.86 times higher risk of stroke; a 1.43 times higher risk of overall premature death; and a 2.18 times higher risk of dying from coronary heart disease Participants who had high blood pressure while supine but not while seated had similar elevated risks as participants who had high blood pressure while both seated and supine. Differences in blood pressure medication use did not affect these elevated risks in either group. “Our findings suggest people with known risk factors for heart disease and stroke may benefit from having their blood pressure checked while lying flat on their backs,” Giao said. “Efforts to manage blood pressure during daily life may help lower blood pressure while sleeping. Future research should compare supine blood pressure measurements in the clinic with overnight measurements.” The study’s limitations included that it focused on adults who were middle-aged at the time of enrollment, meaning the results might not be as generalizable to older populations, Giao said. Note: Giao presents Seated And Supine Blood Pressure And Risk Of Cardiovascular Disease And Mortality From The Atherosclerosis Risk In Communities Study at 2:15 p.m. ET on Saturday, Sept. 9, 2023, Presentation #071; Abstract #452 Background: The Atherosclerosis Risk in Communities (ARIC) study is an ongoing, community-based cohort of 15,792 adults in the United States enrolled from 1987-1989 to investigate the causes for atherosclerotic disease (plaque or fatty buildup in the arteries). ARIC study participants were ages 45–65 years at the start of the study and from rural areas in the U.S. (Forsyth County, North Carolina, and Washington County, Maryland) and urban areas: Minneapolis and Jackson, Mississippi. The research and data from the ARIC clinical visits — including hospital record abstraction, ECG tracings, and physician and coroner questionnaires, as well as death certificate data — have led to discoveries and guidelines surrounding atherosclerosis, heart disease, kidney disease, diabetes, stroke and cognitive decline. The 2017 ACC/AHA Guideline for the Prevention, Detection, Evaluation, and Management of High Blood Pressure in Adults classifies hypertension as having top and bottom numbers greater than or equal to 130/80 mm Hg, which was the definition of hypertension used in this study. Co-authors and their disclosures are listed in the abstract. The study was funded by the National Institutes of Health. Statements and conclusions of studies that are presented at the American Heart Association’s scientific meetings are solely those of the study authors and do not necessarily reflect the Association’s policy or position. The Association makes no representation or guarantee as to their accuracy or reliability. The Association receives funding primarily from individuals; foundations and corporations (including pharmaceutical, device manufacturers and other companies) also make donations and fund specific Association programs and events. The Association has strict policies to prevent these relationships from influencing the science content. Revenues from pharmaceutical and biotech companies, device manufacturers and health insurance providers and the Association’s overall financial information are available here. Additional Resources: Available multimedia is on right column of release link https://newsroom.heart.org/news/high-blood-pressure-while-lying-down-linked-to-higher-risk-of-heart-health-complications?preview=3a007402d06b4cd7cbc3c53acb93b5f5 Program abstracts online at embargo AHA news release: If blood pressure rises upon standing, so may risk for heart attack (March 2022) AHA news release: Blood pressure rising at night linked to doubling risk of death in adults with diabetes (Sept. 2021) AHA news release: Abnormal blood pressure levels while sleeping increase risk of heart disease (November 2020) Follow AHA/ASA news on X (formerly known as Twitter) @HeartNews #Hypertension23 ### About the American Heart Association The American Heart Association is a relentless force for a world of longer, healthier lives. We are dedicated to ensuring equitable health in all communities. Through collaboration with numerous organizations, and powered by millions of volunteers, we fund innovative research, advocate for the public’s health and share lifesaving resources. The Dallas-based organization has been a leading source of health information for nearly a century. Connect with us on heart.org, Facebook, X or by calling 1-800-AHA-USA1. For Media Inquiries and AHA Expert Perspective: AHA Communications & Media Relations in Dallas: 214-706-1173; ahacommunications@heart.org John Arnst: 214-706-1060; John.Arnst@heart.org For Public Inquiries: 1-800-AHA-USA1 (242-8721) heart.org and stroke.org Related Images Previous Slide Next Slide High blood pressure Blood pressure reading copyright American Heart Association Download (1.9 MB) This link is provided for convenience only and is not an endorsement of either the linked-to entity or any product or service. CLOSE PROCEED National Center 7272 Greenville Ave. Dallas, TX 75231 Customer Service 1-800-AHA-USA-1 1-800-242-8721 Contact Us Hours Monday - Friday: 7 a.m. – 7 p.m. CT Saturday: 9 a.m. - 5 p.m. CT Closed on Sundays Tax Identification Number 13-5613797 About Us About the AHA/ASA Annual Report AHA Financial Information International Programs Latest Heart and Stroke News AHA/ASA Media Newsroom Careers Get Involved Donate Now Make a Memorial Gift Ways to Give Advocate Volunteer Go Red For Women ShopHeart ShopCPR Our Sites American Heart Association American Stroke Association CPR & ECC Professional Heart Daily More Sites AHA Careers Privacy Policy Medical Advice Disclaimer Copyright Policy Accessibility Statement Ethics Policy Conflict of Interest Policy Linking Policy Whistleblower Policy Whistleblower Policy Content Editorial Guidelines Diversity Suppliers & Providers State Fundraising Notices Cookies Settings ©2023 American Heart Association, Inc. All rights reserved. Unauthorized use prohibited. The American Heart Association is a qualified 501(c)(3) tax-exempt organization. *Red Dress ™ DHHS, Go Red ™ AHA ; National Wear Red Day® is a registered trademark. American Heart Association, Inc. uses information collected through cookies to improve your experience on our websites, analyze how it is used, and show personalized content, including advertisements. By clicking “Accept All Cookies”, you agree to the storing of cookies on your device to enhance site navigation, analyze site usage, and assist in our marketing efforts. Cookies Settings Accept All Cookies",
    "commentLink": "https://news.ycombinator.com/item?id=37471354",
    "commentBody": "Blood pressure should be measured lying down: studyHacker NewspastloginBlood pressure should be measured lying down: study (heart.org) 227 points by Vaslo 16 hours ago| hidepastfavorite181 comments TechBro8615 14 hours agoI think the bigger issue with measuring blood pressure is that, aside from diagnosed diabetics, it&#x27;s a measurement done infrequently and at mostly arbitrary times. Your blood pressure reading on the day of a doctor&#x27;s appointment, right after you&#x27;ve driven to the appointment, made your way through the intake pipeline, and finally sat down in the chair, is not representative of its reading during a typical day in your life. Other factors like recency of coffee or alcohol consumption, exercise and sleep, all combine to make blood pressure a fairly variable statistic with limited diagnostic power when it&#x27;s only measured infrequently.Regardless of whether you&#x27;re lying down, standing up, or sitting in a chair, it would be beneficial to take more frequent blood pressure readings, throughout the day and during typical routines, than it would to only take them every time you visit the doctor. This seems like common sense, and you can even buy blood pressure sensors for $20 on Amazon, but how many people take their blood pressure on a regular basis? Once you&#x27;re a diagnosed diabetic, then maybe you start measuring it every day - but wouldn&#x27;t it be better to start such a habit before you become diabetic? After all, if you&#x27;re continuously measuring a variable then you can notice patterns and anomalies, and take steps to mitigate them - possibly avoiding becoming diabetic before it&#x27;s too late.It seems the limiting factor is sensor technology, which is obviously lacking compared to wearable sensors for tracking heart rate. Any health-conscious person with an Apple Watch or similar wearable device can easily track their pulse throughout the day. But no similarly accurate and seamless sensor exists for measuring blood pressure (as far as I know?), so nobody measures it as frequently as they do their pulse. Once we have the technology to accurately and passively measure blood pressure throughout the day, preventive medicine will become much easier, and people will have a better feeling for how their blood pressure responds to small changes in their environment and lifestyle. reply llm_nerd 14 hours agoparentI suffer from hypertension (which pushed as high as 170&#x2F;120) and went through a period where I was measuring my blood pressure many times a day to try to essentially hack what the problem was to try to find a natural solution.What I learned is that, for me,-salt intake had zero impact-coffee had no impact-stress level had almost no impact-alcohol had no impact-exercise &#x2F; activity levels had no impactThe single and only controllable factor I could find, short of drugs, was that if I was cold my blood pressure spiked significantly. I had much higher BP in the winter than in the summer, and could improve it by wearing layers, gloves, etc.My body decided to go full ham on blood pressure and it was destroying my kidneys. I would be constantly annoyed by the sound of my own heartbeat doing things like trying to sleep.Telmisartan + Caduet (which is amolodipine + lipitor) and now my blood pressure averages 100&#x2F;60. And courtesy of the lipitor my cholesterol and triglycerides dropped 60%, from high to normal. Many thanks to the very brilliant people who work in that field and developed those drugs.Anyways, thanks for coming to my TED talk on the magic of modern medicine. reply sph 11 hours agorootparentMmm.. I have been measuring my blood pressure for 5 years, twice a day, and I can&#x27;t say I agree with you.- Coffee increases systolic by 15 mmHg for 6 hours, so does smoking.- Lisdexamphetamine (I am diagnosed ADHD) decreases BP by 10 mmHg- Good sleep for 5+ consecutive days decreases BP. One day isn&#x27;t enough.- Rebound hypertension when forgetting my BP meds is a thing. +10 mmHg the next day.- Low carb diet decreases BP steadily after the first week or so, especially if your metabolism is out of whack (understandable due to the deleterious effect of fructose on nitric oxide production)- Amateur BP readings (wrong time of day, single measurement, not relaxed enough) can add 30 mmHg easily. Readings taken at the GP&#x27;s office are worthless for this reason. My advice is measure every 3 minutes until your BP measurement stabilises. The correct reading is the lowest. Sometimes you need 15 minutes to reset to baseline.- Also important is the delta between systolic and diastolic. Mine is around 40 mmHg, if it&#x27;s higher than that, it&#x27;s an indicator of a stress peak (bad sleep, bad day, overwhelmed) that usually resolves after a couple days. reply llm_nerd 11 hours agorootparentMany people have very different responses to stimuli: Some people see a spike from salt. Many don&#x27;t. Some see a spike from coffee, while others actually see a decline! I merely gave my own personal observations from my own rigorous monitoring&#x2F;hacking regime. I found no \"do this and improve nn mmHg\" simple solution, beyond the stated observation about avoiding coldness. I have zero reason to disbelieve your own observations about your own carbon machine, however.Some people will be like me, many others won&#x27;t, but the real lesson is that there are no hard and fast quick fixes. reply mint2 6 hours agorootparentIsn’t being cold leading to an increase in blood pressure a well known physiological reaction to cold temps, that will spike BP but not be the under lying cause? reply sph 11 hours agorootparentprevCertainly, but I&#x27;d like to see the methodology of your experiments if you&#x27;re able to say that a stimulant like coffee doesn&#x27;t do anything, nor exercise. It might not do anything in the short term, but I dare you to drink 3x your daily coffee intake and see if you can&#x27;t see any change, or to increase&#x2F;quit your fitness routine and whether it doesn&#x27;t do anything over a year.I have tracked by BP over 50 kg of weight change, and BP correlates really nicely with fitness level, stress, etc. even though trends are visible over months, not hours.There certainly are no quick fixes, apart from taking a BP pill (I take telmisartan+amlodipine, the latter replacing a diuretic that made me drier than the Sahara desert) reply gaetgu 10 hours agorootparentprevI&#x27;m sorry—30 mmHg?Maybe I am misunderstanding, or there is something wrong with my own knowledge, but \"30 mmHg\" added to systolic seems extremely high.I am currently an EMT-B student here in the United States, and taking vital signs like blood pressure is our bread and butter. We practice it several times a week, on different people with different body types and different blood pressure baselines. Anything more than ±4 mmHg in a manual reading is terrible accuracy, and anything like +30 mmHg probably comes from someone who doesn&#x27;t know how to use the equipment.But again, maybe there is something I am missing. If there is I&#x27;d love to be educated and hear about it! reply mkoryak 3 hours agorootparentprevI think the problem is that you&#x27;ve been measuring YOUR blood pressure, but you should have been measuring OPs blood pressure.Maybe if you did that, you wouldn&#x27;t disagree so much? reply xxpor 10 hours agorootparentprevLisdexamphetamine decreased your BP? That&#x27;s pretty wild. I specifically have to take by BP before my doctor&#x27;s appointments to monitor it from going too high. This seemed like SOP for my doc. reply cko 6 hours agorootparentIf something increases heart rate, sometimes the body will vasodilate to compensate. reply seba_dos1 3 hours agorootparentprevStimulants can act tranquilizing for some ADHD people. reply vjk800 3 hours agorootparentprev> - Also important is the delta between systolic and diastolic. Mine is around 40 mmHg, if it&#x27;s higher than that, it&#x27;s an indicator of a stress peak (bad sleep, bad day, overwhelmed) that usually resolves after a couple days.Is this universally true or just you? Is there any source for this? My diastolic pressure is always in the normal numbers while my systolic pressure is borderline high, resulting in a pretty high delta (50-60 mmHg). Sometimes I also get numbers in the normal range for systolic pressure, but maybe 75% of the time it&#x27;s a bit high. reply vrc 9 hours agorootparentprevPulse pressure, systolic-diastolic, is far more important clinically than I realized.https:&#x2F;&#x2F;www.ncbi.nlm.nih.gov&#x2F;books&#x2F;NBK482408&#x2F;# reply throwitawayfam 4 hours agorootparentprevDo you have a favorite device you use? I&#x27;ve been considering getting something \"smart\" to auto log my BP. reply k12sosse 10 hours agorootparentprev> Lisdexamphetamine (I am diagnosed ADHD) decreases BP by 10 mmHgVyvanse saved my life. reply eddy_chan 12 hours agorootparentprevThanks for sharing publicly. May I ask if the Caduet has any side effects? I&#x27;m going through a similar issue. I know that my problem is alcohol, being overweight and middle age (40+). I&#x27;m also on Telmisartan which takes it down from 170&#x2F;100 to about 135&#x2F;85 on a good day which is still too high for my liking. I might try asking the doc for dual therapy on my next visit and Caduet sounds like a good candidate. My cholesterol also on the high side just outside of normal range! I know I need to lose 20-25lbs but I can&#x27;t see it happening because of a combo of dad&#x2F;work life. reply llm_nerd 12 hours agorootparent>I know that my problem is alcohol, being overweight and middle ageThe middle-aged part for sure, but I don&#x27;t drink, I&#x27;m an ideal weight and have a mid to high level of fitness -- high cholesterol and a super high BP before medication. Sometimes it just be the way it is.Caduet comes with a list of warnings, primarily courtesy of the Lipitor (atorvastatin) component. Periodic bloodwork is necessary to make sure there isn&#x27;t liver damage occurring, etc. I&#x27;ve endured zero side effects of any sort, and my bloodwork has been stellar. With a 10&#x2F;20 caduet (which means 10mg amlodipine &#x2F; 20mg atorvastatin) my triglycerides fell from 2.63 to 1.06, cholesterol from 6.33 to 3.64, LDL from 4.23 to 2.2.Was super surprised at the scale of the improvements. reply pipes 8 hours agorootparentprevHydration is a big part too: I have venesections done every two week or so as a treatment for hemochromatosis. I.e. They take 450ml blood and dump it.If my blood pressure is low before hand, the nurses get me to drink two jugs of water, blood pressure goes up to normal range with in minutes. Same before they let me drive home.This has turned out to be a really useful tip for me life in general. If I&#x27;m feeling shit, I now suspect low blood pressure and force myself to drink two or three pints of water. It usually results in me feeling much better reply robocat 5 hours agorootparent> venesections I.e. They take 450ml blood and dump it.Blood letting - wow!> Haemochromatosis Haemochromatosis is an inherited condition where iron levels in the body slowly build uphttps:&#x2F;&#x2F;www.nhs.uk&#x2F;conditions&#x2F;haemochromatosis&#x2F; reply aantix 12 hours agorootparentprevWhat&#x27;s your potassium level?Potassium relaxes the walls of the blood vessels. It&#x27;s a counterbalance to sodium.Doctors will say 3.5 is fine, but there are several studies demonstrating that as you approach 4.5, the risk of cardiac events drop.Doctors get very tense about potassium supplementation in fear of hyperkalemia.But the RDA for potassium use to be ~4200mg. I&#x27;m guessing most don&#x27;t remotely approach the new or old RDA.If you&#x27;re taking potassium sparing medications, things are further complicated. K levels would have to be checked more often.I supplement with potassium citrate. My blood pressure has normalized. reply llm_nerd 12 hours agorootparent4.5 mmol&#x2F;L. Coincidentally just got a blood test six days ago (this is in Canada and Lifelabs lets you see your own results). I don&#x27;t go out of my way to consume potassium at this point, but my potassium has been 4.5 steady for all the tests I&#x27;ve gotten over the past year. My sodium has been rock solid at 139 mmol&#x2F;L as well.I didn&#x27;t add it as one of my listed items, but I did try supplementing with potassium before starting with medication and for me it wasn&#x27;t beneficial, though it certainly would be for people with deficiencies. reply aantix 12 hours agorootparentprevHyperaldosteronism.If someone has a consistently low potassium level, you should see an endocrinologist and get tested for Hyperaldosteronism.Surplus aldosterone causes the body to retain more salt, which in turn increase blood pressure.Consistently low potassium, early onset of hypertension, taking three or more BP medications (one of which is a diuretic), all red flags.Hyperaldosteronism should be pursued.I had my left adrenal gland taken out to address it. reply hwillis 12 hours agorootparentprevPotassium and sodium are also excreted together, so decreasing sodium&#x2F;increasing potassium typically results in beneficial impacts on the other.> Doctors get very tense about potassium supplementation in fear of hyperkalemia.Supplementing with potassium is not recommended because it&#x27;s not very effective. 99 mg of potassium citrate gives you only 38 grams of potassium- *you need ~100 pills to get your daily value!* You will see much better results from changing your diet to include more potato (note: 1&#x2F;4 of the potassium is in the skin), beans, and spinach (although a lot of spinach- 10oz has as much as a large potato). One large potato can give you 900 mg of potassium. reply sph 11 hours agorootparentBeans are not recommended if your goal is normalising electrolytes and micro-nutrients. Phytic acid in beans messes with your micronutrient absorption, in other words you absorb fewer than if you abstained from beans (or any other vegetable high in phytates). Quite counterproductive if you&#x27;re trying to figure out the correct dosage of supplements.Same with nuts and other seeds. Fine, in moderation. Phytic acid literally is a chemical countermeasure to stop animals from eating the next generation of a plant.Oxalic acid, abundant in spinach, is another fun one. reply tchaffee 9 hours agorootparentSoaking the beans and discarding that water before cooking them greatly reduces the phytic acid. Beans are excellent for health. You just have to follow the traditional methods of prepping them. reply aantix 12 hours agorootparentprev>not recommended because it&#x27;s not very effectiveMy guess is that it&#x27;s effective for those that are chronically K deficient, through Hyperaldosteronism or some other condition.That would still be four large potatoes a day, to hit the original RDA. Every day.I buy it in powder form to get the high levels needed. https:&#x2F;&#x2F;www.bulksupplements.com&#x2F;products&#x2F;potassium-citrate-p...Agree, the dosing on tablets are ridiculously low.Eating several large potatoes, bananas, avocados every single day sounds miserable. reply jupp0r 11 hours agorootparentprevGP mentioned taking Telmisartan, which is potassium sparing and one should be careful with potassium supplementation while taking it. reply aantix 11 hours agorootparentAgree. That&#x27;s why I noted>If you&#x27;re taking potassium sparing medications, things are further complicated. K levels would have to be checked more often. reply BaculumMeumEst 13 hours agorootparentprevWow, that sounds like quite an ordeal. Glad you landed okay! I had no idea medication could have that strong of an effect.I also have been checking my levels a little obsessively, unsuccessfully trying to find ways to drop them. And like you, I noticed that I spike during cold weather. I’m probably particularly sensitive because I have very low body fat. reply manmal 13 hours agorootparentYou probably tried potassium chloride&#x2F;bicarbonate already? reply BaculumMeumEst 12 hours agorootparentI just tried upping dietary potassium with more bananas and avocados and reducing sodium, haven’t looked in to potassium chloride&#x2F;bicarbonate reply ungruntled 13 hours agorootparentprevMyself being someone who suspects that they have high blood pressure (based on infrequent measurement), would you mind sharing if you had any recurring symptoms (outside of hearing heartbeat) when your blood pressure was at its peak? reply llm_nerd 13 hours agorootparentMy initial decision to seek treatment was recurring massive migraines that would wake me up in the middle of the night and last for hours. I had known that I had high blood pressure but didn&#x27;t really track it closely at all, always attributing the few really high readings I did get to white coat syndrome (which is a very real, but it also can be an easy dismissal as well). During one of those migraine sessions I hopped on Amazon and ordered a unit.It came and I was sure it was defective because it kept measuring 170+ &#x2F; 120+, which seemed impossible. A few days later I stopped by a pharmacy with one of the big units, and it read the same thing. So I visited my doctor.He put me on 5mg of amolodipine and it did very close to nothing. Then it was upped to 10mg and still little benefit. It was the addition of telmisartan that completely changed everything for me. The effect was overwhelming.It&#x27;s hard for me to really identify the symptoms because I lived with it, I suspect, for many years. It was my norm. I will say this: at my current blood pressure I constantly feel way more relaxed, physically. Like my body doesn&#x27;t feel in a constant fight state. reply ungruntled 13 hours agorootparentThanks. This is very helpful to me. I have weekly migraines. I never thought to attribute it to high blood pressure.For the record, my blood pressure is not nearly as high, but its typically 140&#x2F;85 as infrequently measured. I’ve never measured during a migraine, but I will now. reply hwillis 12 hours agorootparentdizziness can also be a symptom. reply infradig 10 hours agorootparentprevMy story exactly. Chronic headaches before, not one since (over 4 years). reply rapfaria 13 hours agorootparentprevPain on the back of the head constantly, specially at the end of the day.Been on Olmesartan since then and couldn&#x27;t be happier reply zy0n911 10 hours agorootparentThis exact symptom literally happened to me a couple of months ago. It was the kinda pain that started in one shoulder and rounded itself up into my head and front temple, and it _always_ started in the early evening.After doing a bit of research I got myself a monitor, and sure enough my readings one between 150-170&#x2F;90ish. I&#x27;m also a type 1 diabetic to add to it. reply runako 11 hours agorootparentprevIf you suspect you have high blood pressure, please have yourself checked by a medical professional. Hypertension is known as the \"silent killer\" due to its frequent lack of symptoms. reply hedora 9 hours agorootparentprevSo, my heart was pounding and erratic at night, and my blood pressure would spike at random intervals.The root cause was that I moved to a 2000’ higher elevation, and was dehydrated.Since winter air is lower humidity, I suggest you drink two extra pints of water per day, spread across three-four sittings.Will it work? Probably not. But, I’d give it an over 10% chance, and it will cost you nothing. reply itissid 13 hours agorootparentprev> I would be constantly annoyed by the sound of my own heartbeat doing things like trying to sleep.Wait what? explain more please. reply llm_nerd 13 hours agorootparentPulsatile tinnitus (didn&#x27;t know this name before but just looked it up), which is when blood pressure is so high that in quiet you hear your own heartbeat and the whooshing of blood in your veins. reply hwillis 12 hours agorootparentprevEver run real hard and felt your heartbeat in your ears? Like that but always. It can also happen if you have valve or other heart defects that cause enlargement, but that isn&#x27;t loud in your ears. It&#x27;s just so loud in your chest that you can hear it. Sometimes other people can as well. reply hwillis 13 hours agorootparentprevRaynauds? reply llm_nerd 13 hours agorootparentSecondary Raynaud&#x27;s absolutely. In any below room temperature setting my fingers would be incredibly cold to the point of being debilitating. I ended up being a glove wearer in situations where it looked pretty goofy.This has dramatically improved&#x2F;disappeared under the medication listed above. reply xattt 13 hours agorootparentAmlodipine is a calcium-channel blocker which lowers blood pressure by promoting systemic vasodilation. This would have a beneficial side effect of counteracting idiopathic vasoconstriction caused by Raynaud syndrome.If the drug is taken with food (when drug absorption is highest), some folks will develop edema in their legs for several hours. reply url00 13 hours agorootparentprevWow, it sounds so familiar to myself! I have all the same symptoms and went down the path of testing BP and blood glucose with similar results. How did you get the doctor to prescribe the drugs? Or was it a pretty straightforward diagnosis? reply hwillis 13 hours agorootparentDefinitely does not sound straightforward given all the things they tested and excluded. It also very atypical and medicating specifically for this would be unusual. That said it sure sounds like it perfectly treats the root problem.If you have symptoms like Raynauds and POTS (note that POTS can be hard to demonstrate, so may be less convincing to a doctor) then Amlodipine or similar may be helpful. If you take it and you feel lightheaded when standing up, or have trouble with exercise or fatigue, you probably don&#x27;t need it and it isn&#x27;t good for you.You may have more consistently high blood pressure rather than transient spikes if you don&#x27;t have POTS, or if you don&#x27;t react immediately to cold temperatures. In that case an angiotensin blocker like Telmisartan may help. It can take weeks to become effective, vs Amlodipine should show effects in just a few days.If you have high blood pressure then just telling your doctor you want Amlodipine or something will probably be enough- convincing insurance will be harder. Amlodipine can be used off-label for Raynauds. If you don&#x27;t have particularly high blood pressure and haven&#x27;t systematically tried to exclude causes it will be harder to convince your doctor. They might let you try it for a bit to see if it helps, and the generic isn&#x27;t too expensive. reply llm_nerd 13 hours agorootparentprevTo add to the great reply by hwillis, I just went to my doctor with a concern about my blood pressure and he prescribed amlodipine with follow-up bloodwork to make sure there aren&#x27;t other factors. When the amlodipine wasn&#x27;t effective he upped the dose with another set of bloodwork, and then he added telmisartan and lipitor (coupling it in with the amlodipine for convenience) given cholesterol issues with my bloodwork.There are a lot of different blood pressure medications (like a ridiculous array of options) and I let my doctor decide. There are side effects but I have suffered zero of them, and now that the blood pressure is under control my bloodwork across the board has been improving significantly. replyButtons840 14 hours agoparentprevWhat you say is true, but at the end of the day blood pressure readings in the flawed doctor&#x27;s office setting are still correlated with medical outcomes.I just want to speak against a trend people have to dismiss bad medical news by finding excuses. \"The blood pressure reading doesn&#x27;t count because I was nervous in the doctors office\"; it&#x27;s true, but the guidelines have probably accounted for that. \"That medical study doesn&#x27;t apply to me because it was done on the general population, but the general population is overweight and I&#x27;m not\"; \"that study doesn&#x27;t apply to me because I do yoga, they didn&#x27;t study people who do yoga\"; etc.I know it&#x27;s hard, I&#x27;m in the middle of excusing some bad medical news of my own right now, trying to decide what&#x27;s best for me.Medicines have risks, untreated conditions have risks, choose your risk, but don&#x27;t live in denial that the risk exists. reply anonuser123456 13 hours agorootparent>but the guidelines have probably accounted for thatThey have not. The guidelines are against controlled studies with strict protocols on how to take the measurement.To know your blood pressure relative to the guidelines, you want to be as close to the guideline protocols and possible. That can be a 20&#x2F;10 point difference or more.The average physicians office doesn’t follow those protocols unless you deviate significantly. e.g you walk in with 140&#x2F;90 and they aren’t going to bother. 160&#x2F;95 and they will recheck you with more care given to the proper measurement technique.This isn’t to say one should dismiss the numbers when taken properly; I’m just pointing out that calibration is necessary. reply nomel 12 hours agorootparentI&#x27;m a nervous person. There have been several times where they had to recheck, because my rate was so high. My watch says my resting rate is 40 to 50 lower. Whatever protocols probably didn&#x27;t have me in mind. reply Buttons840 12 hours agorootparentWe&#x27;re talking about blood pressure. Does your watch measure blood pressure?I think this might be an example of what I was talking about: you think blood pressure guidelines might not apply to you because of something your watch says. reply nomel 10 hours agorootparentMy point was to give an example of situational sensitivity. My pulse is easiest&#x2F;the most fun to see, because it&#x27;s...on my watch. See [1]. And, they loosely don&#x27;t apply, which is why I&#x27;ve been told to take measurements at home, before coming in, with an automated cuff. The measurements in the office are not useful.[1] https:&#x2F;&#x2F;my.clevelandclinic.org&#x2F;health&#x2F;diseases&#x2F;23989-white-c.... reply taneq 11 hours agorootparentprevIt’s called white coast hypertension, I don’t think of myself as particularly nervous but I get this too. I’ve had blood pressure readings in various medicals etc. from 145-160&#x2F;90, and endured several stern lectures about salt and exercise and alcohol. Finally did a 24 hour ambulatory test and I’mso nobody measures it as frequently as they do their pulse. Once we have the technology to accurately and passively measure blood pressure throughout the dayIt&#x27;s surprisingly tricky. The way a BP cuff works (the auscultatory method[1]) is that the pressure is continuously decreased and you listen for the sound of a pulse. When the cuff pressure is higher than your systolic (peak) pulse, bloodflow is blocked and you don&#x27;t hear a pulse. When the cuff pressure is lower than your diastolic, the cuff is no longer blocking bloodflow at all, and the pulse suddenly becomes much quieter because it&#x27;s not restricted. It&#x27;s only between the two pressures that you hear it extra clearly.So the problem with a sensor is that you can&#x27;t just measure pressure against the skin. At minimum, it really should actually impede a large artery. You can squeeze the arm as tight as you like but if the brachial artery is not affected then your measurement will be very poor.You can do fancy computer vision etc to look at special veins&#x2F;arteries, and coupled with some demographic assumptions you can infer somewhat accurate measurements- but they really miss out on outliers, which is really a lot of the point of taking measurements. This also generally will require an upper arm strap or something, and be fairly tight. Not great to wear alwaysAt some point, I think we will probably see implantable blood pressure monitoring. We do something similar with implantable glucose monitors- which need regular replacement, unfortunately. BP probably wouldn&#x27;t. Problem is that direct pressure measurement is usually done by tapping off an artery- something that will never be routine. You&#x27;d want to do some combination of acoustic and pressure measurement, and it&#x27;d need to be calibrated from a base station regularly.[1]: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Blood_pressure_measurement#&#x2F;me... reply joshvm 1 hour agorootparentMaybe a related question, but how good a proxy is cuff pressure for a gold standard method that measures inside an artery? Whenever I&#x27;ve had BP measured for clinical studies (not focused on BP specifically) they used a mix of cuff and continuous fingertip sensors depending on the activity. reply krzat 43 minutes agorootparentprevContinous measurement of body temperature, blood pressure and heart rate via implant could be enormously helpful to health for so many reasons... reply TechBro8615 12 hours agorootparentprevI wonder if there are methods that could take advantage of natural movements throughout the day, where your body naturally emulates what the cuff forces it to do. For example, when you transition suddenly from sitting to standing, is it possible for a sensor to measure some proxy metric that, combined with an accelerometer, can be used to infer blood pressure? If there is some method like this, even if it has large margins of error, maybe cumulative measurements could converge on a fairly accurate reading?(I&#x27;m not a medical professional nor do I know much about sensing, or even really the basics of how blood pressure is measured or what it indicates.) reply jkingsman 13 hours agorootparentprevWorth mentioning that BP is about arterial, not venous pressure. Venous pressure is an order of magnitude lower than arterial pressure; usually 0-10mmHg. reply hwillis 13 hours agorootparentty, edited. oopsies! reply alphanumeric0 12 hours agorootparentprevYes, the most accurate method is via arterial catheter. It&#x27;s basically a needle directly into the artery. reply boringuser2 12 hours agorootparentprevI&#x27;m confused.The technology already exists and is approved by the EU.https:&#x2F;&#x2F;aktiia.com&#x2F; reply hwillis 11 hours agorootparentPhotoplethysmogram devices like this measure blood volume. That works great for your heart rate. It is pretty terrible for your blood pressure. In theory they measure the speed an artery expands as blood passes.1. Since they can&#x27;t measure blood flow, only volume, they can&#x27;t tell if your BP is low or if they just aren&#x27;t centered on an artery. They can&#x27;t measure diastolic, only the difference between systolic and diastolic.2. Since they don&#x27;t know the flow, they can&#x27;t even guess the size of the artery, so they&#x27;re basically just guessing how much it should be expanding. They also have to know how tall you are to even get close.3. They measure the derivative of the increase in volume to try to correlate that with blood pressure. That&#x27;s very variable with the specific artery and the condition of the artery- there&#x27;s a lot of (primarily age) variance in artery elasticity.Papers indicating accuracy should be subject to high scrutiny. The device basically starts out by guessing that you&#x27;re healthy and normal for your age and height. If you take a bunch of people that are healthy for their age and height (most people), the device will perform very well. It will also be practically useless.If you have ideopathic large swings in blood pressure, like POTS, or fainting, or migraines, a device like this can give you a bit of warning. It will not give you accurate readings or track long-term changes, and those issues are made much worse because of opaque calibrations etc.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Photoplethysmogram reply boringuser2 11 hours agorootparentDo you think the EU regulatory agencies haven&#x27;t properly accounted for the claims made by the makers of this device?It looks very promising and it is clinically approved.Your theory craft seems to check out, but they could have proprietary technology that Huawei is yet to clone&#x2F;rip-off, so it&#x27;s not a well-known methodology. Funnily enough, they actually tested some of their algorithms in China based on their papers, so maybe it is just a matter of time.That being said, if you have industry inside knowledge, that&#x27;s a little different. reply hwillis 8 hours agorootparent> Do you think the EU regulatory agencies haven&#x27;t properly accounted for the claims made by the makers of this device?Exactly what regulation do you think applies to this device? Do you think it&#x27;s an approved medical device? reply boringuser2 6 hours agorootparent>Aktiia Bracelet G1 has been CE-marked under the Medical Device Regulation (EU)2017&#x2F;745 as a class IIa medical device.I&#x27;m not trying to embarass you, I was just genuinely curious if you had any special knowledge. replylm28469 1 hour agoparentprev> Once we have the technology to accurately and passively measure blood pressure throughout the day, preventive medicine will become much easier, and people will have a better feeling for how their blood pressure responds to small changes in their environment and lifestyle.With 70% of the population being overweight or obese and on a dog shit diet I very much doubt that.We already know what we do is bad, we know how to fix it, virtually no one does it. If people can&#x27;t be arsed to even walk 30 min a day I don&#x27;t think they&#x27;ll care about continuously monitoring their blood pressure. You can track your pulse continuously with ultra cheap gadgets and it&#x27;ll tell 50%+ of the population their heart is in bad shape, nobody caresThe best preventative medicine is your lifestyle, if you wait for symptoms you already failed your body and are 10+ years late to the party reply _ph_ 14 hours agoparentprevYou are so right. Earlier this year I had to spend a week in hospital and they took a variety of measurements every day. It was interesting to see how much variation there was, especially in blood pressure. But one thing was especially interesting, pulse. As I was wearing my Apple watch, I had the values for blood and blood oxygene before they took them. And with pulse, you could clearly see with the graph, how much systematic variation there was. So their single measurement was not great. Best example, the last measurement was taken before I was about to be released, awaiting the doctors sign-off visit. Of course my pulse was off. But the doctor was quite interested to see my pulse for the last couple of hours.People underestimate how valuable a medical tool the Apple watch already is and how game-changing it can get if they manage to extend the sensor suite - as you say, blood pressure, perhaps also body temperature and glucose level.Another fun fact from the visit, they did monitor glucose level and one morning they did so directly after waking me up. Which caused the nurse to run to get me an early breakfast as it was very low. Not as if I hadn&#x27;t known for decades, that I need a slow start and at least a small bite for breakfast to get into gears... reply hedora 9 hours agorootparentI recommend Apple Watches, but if money is an issue, or you just dislike Apple, Amazfit has some nice offerings like this band:https:&#x2F;&#x2F;www.amazon.com&#x2F;Amazfit-Fitness-Monitoring-Tracking-R...Some of the reports it produces are superior to Apple Health (it measures stress, a proprietary overall health score, and I prefer its sleep monitoring analysis).It’s $39. The 15-25 day battery life claim assumes you disabled most of the functionality.Insert privacy disclaimer here. reply ipqk 14 hours agoparentprev> Your blood pressure reading on the day of a doctor&#x27;s appointment, right after you&#x27;ve driven to the appointment, made your way through the intake pipeline, and finally sat down in the chair, is not representative of its reading during a typical day in your life.This is a known thing called White Coat Syndrome reply Gibbon1 14 hours agorootparentThat&#x27;s actually different. The stress of being at the doctors causes blood pressure to elevate vs more mundane things like running, walking, driving stress. The difference is someone without white coat syndrome will have a lower blood pressure reading at the end of the doctors visit. reply pixl97 14 hours agorootparentHonestly I think in most US cities the driving stress would drive ones BP far higher. I know one time just right before I got to the Drs office some one almost ran into me, I mean just missed, and my BP was way high still. reply atahanacar 9 hours agoparentprevTracking your blood pressure randomly throughout the day will not be meaningful in any way, just like tracking your pulse isn&#x27;t meaningful. It will only be annoying, as blood pressure measurement is a mechanical process, unlike heart rate measurements which can be done optically or electrically.>right after you&#x27;ve driven to the appointment, made your way through the intake pipeline, and finally sat down in the chair, is not representative of its reading during a typical day in your life.So? It is taught pretty early in med school that before measuring the vitals, you should let the patient rest while you take their story, and ask questions related to things that might change the measurements (did you walk here? did you walk up the stairs? did you drink coffee? did you smoke etc.). And if you still want more measurements throughout the day for various reasons, you can just use holter.>all combine to make blood pressure a fairly variable statistic with limited diagnostic power when it&#x27;s only measured infrequently.[citation needed]If you are hypertensive, non of the things you&#x27;ve mentioned will matter. Your blood pressure will be high regardless, and it will still be caught. In addition, you can&#x27;t just diagnose with a single reading anyways.It is funny to read comments regarding medicine on HN. reply redox99 13 hours agoparentprevAt least in my country, to diagnose you with high BP they&#x27;d have you wear a holter monitor for 24 hours. reply readthenotes1 13 hours agorootparentThat&#x27;s standard in the US as well. reply vonnik 12 hours agoparentprevFwiw, OMRON produces high-quality blood-pressure monitors for consumers.https:&#x2F;&#x2F;omronhealthcare.com&#x2F;blood-pressure&#x2F;Even these, though, tend to overestimate your actual blood pressure, sometimes by as much as 10 points.But having one in the home makes it easy to take several readings throughout the day, since each one hardly lasts a minute. reply frereubu 1 hour agorootparentDoctors in the UK use Omron monitors. reply smartbit 7 hours agorootparentprevA few years ago their Bluetooth apps didn’t require registration, now the do. So now you’d need to keep track of the measurements yourselves, e.g. using a spreadsheet. Can not recommend Omron anymore. reply zwieback 14 hours agoparentprevYeah, I have a machine and unless I take measurements very frequently (different times of day, etc.) it&#x27;s really hard to make sense of the numbers. You really need to get a long term chart to weed out the noise.I&#x27;ve been getting much better readings at the doctors but then I realized I always ride my bike there, sit in the waiting room for a while and then get a low reading. Not representative! reply gryfft 14 hours agorootparentI&#x27;ve been using Google Fit to track my blood pressure over time. I&#x27;ve been measuring every other day. The charts really are helpful.The biggest correlation with my blood pressure is how regular my sleep is. Once I started militantly waking and sleeping on a set schedule, the numbers came down. They seem to spike for a few days if my sleep gets messed up badly somehow.I also have been trying to standardize my measurement: same time of day, after sitting quietly alone for five minutes. reply _ph_ 14 hours agorootparentprevI am not sure, while the values obtained this way might require calibration, it sounds like very controlled conditions to me. The exercise should bring your body into a very controlled state, beyond the physical load very relaxed. So after a short rest, this should be a good time to get reliable readings. But I am not a doctor. reply zwieback 14 hours agorootparentYeah, agreeed, and I think the BP is a bit lower because I&#x27;m warmed up and then rested a bit. My worst BP is in the mornings after getting up and sitting and drinking coffee. reply Someone 12 hours agoparentprev> Once we have the technology to accurately and passively measure blood pressure throughout the day, preventive medicine will become much easierHow? Do we have any idea what we would do with that data? AFAIK, all treatments we currently have aren’t suited for treating short-duration spikes in blood pressure (do they even need treatment? I wouldn’t know).Also, why would we need preventive medicine for most people with hypertension? https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Hypertension#Prevention:“The 2004 British Hypertension Society guidelines proposed lifestyle changes consistent with those outlined by the US National High BP Education Program in 2002 for the primary prevention of hypertension:- maintain normal body weight for adults (e.g. body mass index 20–25 kg&#x2F;m2)- reduce dietary sodium intake to I have to drop nearly dead and only then will I go to doctors&#x27; for diagnosis and treatment.This is a healthcare issue specific to your country. It is not a problem of \"not enough measurements\".Regarding using tech like smartwatches for blood pressure measurement, it is currently not possible. They aren&#x27;t measuring your blood pressure, they are simply correlating optical data like pulse transit time with your blood pressure, which is mostly inaccurate. If you have to calibrate every now and then using actual bp measurements, then you already have enough data and don&#x27;t need your smartwatch. reply jliptzin 12 hours agoparentprevAre you confusing blood pressure and blood sugar? My boyfriend is type 1 diabetic, he measures his blood sugar multiple times a day, but I have never seen him measure his blood pressure. reply hwillis 12 hours agorootparentNo- diabetes can have very negative long term impacts on your small blood vessels, particularly in your kidneys. Changes in blood pressure from vascular damage all over your body can be a signal that nephropathy (kidney disease) is not far away. It takes years to accumulate. reply m463 12 hours agoparentprevI have a garmin watch and one wonderful thing it does is show me my resting heart rate, which is a nice indication of my level of fitness (and correlates with good sleep, sickness, etc)It also does nice things like a detailed check of my sleep, how I&#x27;m acclimatizing to altitude when visiting the mountains, the number of steps I walked and pulse-ox.I don&#x27;t know how these correlate to what blood pressure tells you, but I blood pressure will be directly measured in the same way in a few years. reply serial_dev 13 hours agoparentprevPeople mentioned the white coat syndrome, but that&#x27;s not the only issue.I am not nervous when they measure my blood pressure, but I might have been late to my doctors appointment, so of my 25 min walk to the doctor, I was running half of it. I had non-optimal blood pressure values at the doctor, because I was running not to miss the appointment, and as I arrived, I had to immediately go get my BP checked.After the incident, I religiously measured my BP at home various times a day for a week and my numbers looked okay. reply BaculumMeumEst 13 hours agorootparentI was late to an optometrist appointment a few weeks back. Sprinted up six flights of stairs and into the office. The literal second I got in they called my name and immediately measured BP. The tech looked like they were going to shit themselves. reply shepherdjerred 9 hours agoparentprevOne easy way to check your blood pressure more regularly is to donate blood!At least in the United States, you&#x27;ll get your pulse, blood pressure, and iron levels all checked. Additionally, your blood will be tested for some infectious diseases like HIV.Lots of free testing, and you also get to help someone out! reply Angostura 9 hours agoparentprevI&#x27;m in the UK with hypertension. My GP surgery sends me a text message every 6 months or so, asking for a week&#x27;s readings morning and evening, using a home blood pressure monitor - the message includes a link to submit readings.Gets rid of most of my white coat hyper tension reply tguvot 12 hours agoparentprevtake a look at aktiia. tracks blood pressure through the day. currently under trials in usa to get fda approvalm but you can buy it from eu reply inglor_cz 14 hours agoparentprevThere is a device called \"holter\" that you wear for a day and it measures your BP repeatedly, even during the night.https:&#x2F;&#x2F;my.clevelandclinic.org&#x2F;health&#x2F;diagnostics&#x2F;16330-24-h...I have worn a holter several times. I had better results than in a doctor&#x27;s office. It seems to be a classical case of white coat syndrome. reply scythe 13 hours agoparentprevOne time a doctor at the on-campus clinic looked at my blood sugar reading said I might be prediabetic. This was an early-morning appointment at a time in my life when I wasn&#x27;t very used to that and had rushed out of my dorm while scarfing down a bagel that had been hastily topped with the only thing in the cabinet that was in a squeeze bottle — honey!No blood test over the next decade showed even a hint of elevated blood sugar. reply atahanacar 9 hours agorootparentThat is exactly why you need fasting blood glucose for diagnosis of diabetes. reply moffkalast 13 hours agoparentprev> it would be beneficial to take more frequent blood pressure readings, throughout the day and during typical routines, than it would to only take them every time you visit the doctorIt would be, if the most reliable way to get BP data wasn&#x27;t to apparently violently compress the upper arm until it physically hurts and leave it like that for a minute. How people can do that on any kind of regular basis completely escapes me, and I&#x27;m not convinced it&#x27;s not actively harmful. The wrist monitors are tolerable but seem to be very sensitive to wrist height. reply nelblu 11 hours agoprevI have white coat hypertension and probably also some borderline hypertension, and my readings are off the chart (or used to be). I really hated the first doctor who diagnosed it, he straightaway gave me prescription (don&#x27;t get me started on the whole prescription business in the US). I never picked the prescription.I decided to work on it and see if I can \"fix it naturally\". I did 2 main things : first one was extremely easy (for me), I dropped more than 29kgs (approx 60lbs) which was 34% of my body weight over more than 15 years (techinally the first 20 kg was pretty quick, last 9 kg took a few years and experimenting with food and eating habits). Secondly, I started practising meditation. That&#x27;s a hard one, takes me a lot of effort but I&#x27;m doing it quite consistently now.Anyway, I barely check my blood pressure now and last I checked it was 118&#x2F;75. I can&#x27;t emphasize how important it is to eat well and live a stress free life to keep your heart healthy. Of course it worked for me because mine was just borderline high (on the best days it used to be 135&#x2F;85), it won&#x27;t work if you have severe hypertension but there&#x27;s no harm in trying, it will definitely drop a few points on the meter and your heart will thank you. reply nine_k 10 hours agoparentI&#x27;m unironically applauding you, Mr. Superhero.Most people though, even being technically capable of similar feats, are not in a position to do so, because of the time and attention expenditures required. Rebuilding large chunks of your life to accommodate for a new lifestyle is the harder the more other people depend on you. Keeping your resolution for many years also.becomes harder. reply shepherdjerred 10 hours agoparentprevKudos to you! Both weight loss and meditation are not something that everyone can do, though.I&#x27;m not sure of your circumstances. I&#x27;m pretty lucky being young, single, and having no kids, so maybe I could manage a similar feat in your position.I don&#x27;t think it&#x27;s the norm, though, which maybe is why medication is the default. reply aradox66 3 hours agorootparentMeditation is accessible to anyone willing to try. Five minutes a day is enough. Free resources abound for guided meditations and arbitrarily in-depth instruction. reply jonhohle 9 hours agorootparentprevWhat is preventing most people from losing weight? Eating less calories than what is expended during the day will result in weight loss (caloric deficit). Walking around the house, breathing, and sleeping consumes 1500-2000 calories&#x2F;day. Eat less than that. No medication required.Caloric deficit is the only way to lose weight. If you hear someone say, “No! You need to exercise and reduce calories!” That’s just burning the candle from both ends - increasing caloric requirements and decreasing caloric intake (e.g. caloric deficit). There are good reasons to do exercise, but it’s not strictly required for weight loss.(Consult a medical professional before beginning any weight loss routine, etc., etc.) reply arcanemachiner 9 hours agorootparent> What is preventing most people from losing weight?You don&#x27;t have a bad habit you need to \"just\" stop doing?Everybody&#x27;s got a monkey or two on their back. reply jonhohle 8 hours agorootparentI absolutely agree, 100%. I was responding in the context of things life is too busy for. I didn’t want to imply that it could “just” be done, only that it takes no time or resources.It certainly takes willpower and it sucks for several weeks while the body adjusts, and when a treat sounds really good (come on, you earned it!). It takes breaking snacking habits and requires social trade offs. It’s completely unmotivating to weigh more when the previous day was hard to stick with the plan. Plain popcorn can’t compare to movie theater butter flavored topping. reply shepherdjerred 7 hours agorootparentprev> What is preventing most people from losing weight?For me, in the past, it has been that food is a comfort that I seek when I&#x27;m stressed&#x2F;bored&#x2F;anxious. Weight loss is just CICO, but the solution is not always as simple as the equation. reply CPLX 9 hours agorootparentprev> weight loss and meditation are not something that everyone can do, thoughWhy not? Serious question not an attack.Outside of catatonic states and so on what would make those things impossible? reply shepherdjerred 7 hours agorootparentI didn&#x27;t mean to say it&#x27;s impossible. I mean that it would require a great deal of effort for some people, though, depending on their finances, mental&#x2F;emotional state, responsibilities, etc. reply susiecambria 8 hours agorootparentprevLife, especially a stressed one. Making life changes takes a lot of mental energy and some folks don&#x27;t have it to spare. reply feyman_r 9 hours agoparentprevCongratulations on this accomplishment! Having attempted and regained some weight back during the pandemic, I appreciate how hard it is to make lifestyle changes.Question: what kind of meditation has helped you the most? reply idoubtit 15 hours agoprevThe original media release[^1] is much clearer, with a 3 points abstract followed by a detailed summary. I don&#x27;t know if this derived article was written by a human or by an AI, but I think it&#x27;s junk like this that contributes to makes the web a mess of noise and echo.[^1]: https:&#x2F;&#x2F;newsroom.heart.org&#x2F;news&#x2F;high-blood-pressure-while-ly... reply dang 15 hours agoparentChanged from https:&#x2F;&#x2F;studyfinds.org&#x2F;measuring-blood-pressure-wrong&#x2F; above. Thanks!Submitters: \"Please submit the original source. If a post reports on something found on another site, submit the latter.\" - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;newsguidelines.html reply giantg2 12 hours agoprevWe also need people who are knowledgeable on how to take blood pressure. Seems like half the time the nurse uses a machine and has that thing cranked up to 200mm so they don&#x27;t have to redo it if the patient is high. No shit my blood pressure is elevate - I can feel my pulse get stronger because my arm isn&#x27;t getting any blood flow.Similar thing with my petite old grandma. Always measured high if an unknown person did it because they would overinflate. But when someone would just put it 20 over her previous known good reading, then her blood pressure was fine.But nobody cares. In, out, get paid. reply ac2u 10 hours agoparentSame.... when the machine hurts like hell... and there&#x27;s the awkward pause while it decides to re-inflate.. you know you&#x27;re in for a high reading. reply hinkley 10 hours agorootparentThose cuffs are so fucking tight I&#x27;m certain that&#x27;s spiking my blood pressure.Try measuring my BP while pinching me, don&#x27;t be surprised what you get. reply Gys 15 hours agoprev> Sixteen percent did not have high blood pressure — a reading greater than 130&#x2F;80 mm Hg — while seated. However, these same people did show high blood pressure when researchers measured their BP while lying flat on their backs. reply NotGMan 1 hour agoprevMy blood pressure went from ~145&#x2F;95 to ~120&#x2F;75 just be lowering carbs&#x2F;sugar drasticaly.Salt has zero effect for me, I ate ~15g + salt and it had zero effect on blood sugar.Carbs though...oh boy.. It may take a month or two for the change to become noticable. reply Gualdrapo 14 hours agoprevI don&#x27;t know about you but getting somewhat concise readings for my blood pressure at several facilities has been difficult in here.When I went to the medical exams to get my drivingllicense one year ago I was told my blood pressure was a bit high - maybe due to the nervousness of being checked, but it was better to ask my doctor - both of my parents suffer from high blood pressure.So I did. He told me my blood pressure was high and gave me that famous table to fill up with daily readings for two weeks.My sister (physiotherapist) has a sphygmomanometer at home but she will scream at me to be perfectly still and seated for at least 5 minutes before doing the reading - and it _always_ was 120&#x2F;80.Went several days to a nearby pharmacy and they gave me a little chair to be sat for 10 minutes before standing up and going to a small cubicle where they did the measurement with an electronic sphygmomanometer. Measurements there always were fairly inconsistent and above 131&#x2F;87 - going up to 150&#x2F;87.Also went to several other points to get my blood pressure measured and they always had a different method and (unsurprisingly) yielded different results. But for some reason when they measured with analogic&#x2F;traditional sphygmomanometers, the measurements always were lower compared with electronic ones.Fortunately could afford a decent electronic sphygmomanometer for myself and started doing my own measurements, which are fluctuating between 117&#x2F;77 and 122&#x2F;82. reply gaetgu 10 hours agoparentThis is an interesting point. I know for sure that I have been taught in school to never trust the electronic BP machines, since they can be pretty far off for some (but not all) people.Instead, using a sphygmomanometer is much more likely to give accurate results.Anecdotally, I always have a super weird initial blood pressure reading when I go to the doctor and they use the electric machine (one time it was 112&#x2F;95), but when it is rechecked with a sphygmomanometer it tends to level out at somewhere around 130&#x2F;85. reply hedora 9 hours agorootparentIf you have a portable meter, you can always take it to the doctor and do a back-to-back or simultaneous reading.You will probably find that your blood pressure varies more over a 10 minute window than the difference in readings between the two meters. reply pixl97 14 hours agoparentprevWhen you say you went to the pharmacy and doctors office, did you drive?BP level seems to highly correlate with the environment you&#x27;re in, stressful driving can bring it up and keep it high for a while. reply Mobil1 13 hours agoprevAny disparity between interarm BP—especially when large and persistent—should prompt consideration of diseases known to be the cause: coarctation, dissection, or aneurysm of the thoracic aorta; Takayasu (pulseless) disease; and various types of intra- and extra-arterial obstruction in an upper extremity.1,9,11,23,24 These diagnostic considerations become much more likely if the arm with the lower BP also has a grossly diminished radial pulse. reply TrackerFF 11 hours agoprevWhen I first stared measuring at home, I&#x27;d get these crazy variations. The first time I measured, I wasclose to driving to the ER, as I had something like 150&#x2F;110 3-4 times in a row. \"Fortunately\" the measurements were done pretty poorly - I was sitting in a slouched chair, my arm &#x2F; measurement point was way too low, and a bunch of other things.I redid the measurements after reading the manual, sitting straight up, feet on ground, measuring at heart level, etc. Suddenly I got 100&#x2F;110 over 80&#x2F;85, and while that wasn&#x27;t ideal, it obviously calmed me down a good bit. reply nmz 15 hours agoprevI went to a cardiologist and was tested while lying down. This was an extensive test though. reply GoodOldNe 10 hours agoprevThis is an oral presentation by a medical student at a meeting. I wouldn&#x27;t change your life or approach to ASCVD risk reduction based on it. reply iancmceachern 2 hours agoprevI like their domain, very cool reply Blammar 12 hours agoprevAm I correct in interpreting this study that your recorded BP should be the MAX of sitting BP and supine BP? reply clumsysmurf 14 hours agoprevSeems like it might also be important to check the difference in pressure between the two armshttps:&#x2F;&#x2F;www.uclahealth.org&#x2F;news&#x2F;why-you-should-have-your-blo... reply mongol 12 hours agoprevI have low blood pressure, and it has caused me to faint, twice. I was fortunate to not hurt myself severly, but it was close. But it feels like the blood pressure is a symptom of something else. But no answers yet. reply cableshaft 15 hours agoprevWell....that sucks. Maybe I don&#x27;t have normal blood pressure.Doctors never test me lying flat. Closest I&#x27;ve gotten is laying at an angle in a hospital bed.I&#x27;m a middle-aged heavyset guy as well, so I know I&#x27;m at greater risk for these things. reply Aurornis 15 hours agoparentAn at home blood pressure cuff is relatively cheap if you’re concerned about it. reply lowercased 14 hours agorootparentSeconded. Got one and tested myself a couple times a day for a few weeks. I&#x27;m not necessarily sure it&#x27;s &#x27;accurate&#x27;, but having repeated readings from same device, same arm, same position, same times of day seemed to at least show consistency and identify when things were out of whack (a couple times). Got one for about $25. reply squeaky-clean 11 hours agorootparentI was able to bring mine to my cardiologist appointment to double check I was using it correctly and then to check the results against the one in-office. Mine also cost about $25 at CVS. reply bpoyner 14 hours agoparentprevI&#x27;ve only once had a doctor test my blood pressure lying flat. I had a suspected GI bleed and he wanted to see the difference between flat and sitting up. Then he called up the hospital and got me a spot reserved in the ICU. reply Broken_Hippo 14 hours agoparentprevMy doctor&#x27;s office sent me home with a monitor for 24 hours. It tested every 15 minutes during the day and every 30 minutes during the night. I generally went about my day at home and eventually even slept.This seems pretty normal in Norway - but I don&#x27;t think it was in the US (Am from the US, father had heart problems). Perhaps your doctor would be able to do something similar, though. reply WWLink 14 hours agorootparentYea they do that in the US as well. But not very often. reply Mobil1 13 hours agoprevA recent study confirms a link between different arm-to-arm blood pressure and an increased risk for heart attack, stroke and death. reply beefman 10 hours agoprevSurely clinics will update their practices in light of this new information. reply cm2012 14 hours agoprevI hate getting my blood pressure taken. It feels invasive when the coil squeezes my arm. I&#x27;ll do it but only when necessary. reply technofiend 12 hours agoparentIt always stresses me the fark out because the machine squeezes the cuff to the point it&#x27;s painful. My best blood pressure readings are always done manually. It&#x27;s quantum blood pressure: by measuring it you changed the outcome. reply hwillis 13 hours agoparentprevinvasive? reply goostavos 13 hours agorootparentI&#x27;m with this OP. I absolutely cannot stand it. I have no good \"logical\" reason for why, but it&#x27;s the most stressful part of the doctors office for me. I&#x27;ve been as high as 170 at the doc due to sheer stress of getting the measurement taken. I&#x27;ve tried \"exposure therapy\" by just doing it at home every day, multiple times per day. It never stopped being stressful.I&#x27;ve also fainted during a blood draw. I wish I wasn&#x27;t this guy... but alas. I am begrudgingly this guy. reply Ductapemaster 11 hours agorootparentI have the same set of experiences. It is incredibly frustrating to both myself and my doctors since I have a family history of high blood pressure, and it is impossible for me to get a baseline measurement. Only time I have ever had normal blood pressure is when I was in the best shape of my life a decade ago, and was considerably more relaxed due to life circumstances — but I distinctively remember not being afraid during the measurement, rather than feeling any different with regards to my overall health.Also I&#x27;ve fainted, or almost fainted, in an array of circumstances related to needles. My experiences range from moderately humorous to dangerous (I fainted after my first COVID shot at the wheel of my car...thankfully I knew it was coming and put it in park just in time).Don&#x27;t feel too bad about being \"that guy\" — while the experience is incredibly personally uncomfortable, it&#x27;s actually fairly common. I&#x27;ve just resorted to always having someone with me who knows what may happen and informing all the people involved about my history. Not fun, but it keeps me safe. reply cm2012 13 hours agorootparentprevYes, it makes me feel trapped. reply genman 13 hours agorootparentThis description actually kind of makes sense.What could help (or could have no effect) is taking the blood pressure with the electronic device. There nobody could be next to you (entrap you) and you would have a complete control over the strap - you could take it off any time you felt uncomfortable if you just wanted to.I have an electronic meter at home and I use it time to time to check my pressure. I can be much more relaxed and I indeed usually lay down first. reply hwillis 12 hours agorootparentprevHmm, fair enough. It is possible to measure BP at the ankle (while lying down, legs flat), although it is usually higher. If you do want to test it yourself, that&#x27;s an option. Your doctor probably won&#x27;t really want to bother but it&#x27;s certainly worth asking if you think that would be more comfortable. reply myshpa 11 hours agoprevhttps:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=Ig_ZWdpriC4How to Lower Blood Pressure Naturally with Lifestyle Changeshttps:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=fZc5Is98yDcHealthiest Foods for Your HeartDr. Neal Barnard reply atahanacar 9 hours agoprevComments are full of disinformation. Don&#x27;t take medical advice from HN. reply somsak2 4 hours agoparentany specifics that you can provide? in general I&#x27;m pretty skeptical of this idea that only medical professionals are useful for such information, but I&#x27;d like to hear concrete examples you have reply atahanacar 2 hours agorootparentPlease see my other replies in this thread for some examples. I wanted to correct every false information but realized it was almost all comments that were either missing some nuances or clearly incorrect.Human body is a combination of multiple very complex systems. These are so complex that you can&#x27;t even begin to grasp the complexity without diving pretty deep. Majority of non-MDs (especially non-MD health workers like nurses ironically - Dunning Kruger maybe?) heavily underestimate the knowledge required to graduate medical school.This complexity of human body brings with it lots of tiny nuances. So much and so tiny that even specialists with decades of experience can miss them. Add to this the mechanisms we still don&#x27;t completely understand, you get the perfect recipe for \"dangerous bad advice from non-medical professionals\".Some of the misinformation is a direct health hazard, like claiming \"your body can get rid of what it doesn&#x27;t need so your salt intake is not an issue\". Some of them aren&#x27;t directly harmful to your health but damages the healthcare, either by breaking the trust like \"blood pressure measurement during visits is incorrect and leads to misdiagnosis\", or by putting extra pressure to spend healthcare resources unnecessarily like \"measuring your bp during the day is useful\".If you want to do any further reading on any of these problems I mentioned, especially the last one which is hard to grasp and counterintuitive, I can link you some resources.Edit: by MD I mean also DO for Americans. reply wing-_-nuts 15 hours agoprevTLDR: Doctors need to check blood pressure while the patient is laying down.I do wonder about recent changes that suggest anything beyond 120 &#x2F; 80 is above &#x27;normal&#x27;. You would think that something like blood pressure would be highly regulated in the body but it varies throughout the day, month and year.They also say that salt is seriously bad for high blood pressure but I find little effect for myself personally. I do wonder how much sensitivity varies from person to person. reply btilly 15 hours agoparentSensitivity varies by a lot. https:&#x2F;&#x2F;www.heart.org&#x2F;en&#x2F;news&#x2F;2021&#x2F;04&#x2F;26&#x2F;salt-sensitivity-ma...I&#x27;m at the extreme end of sensitivity. If I want my blood pressure medications to work, I need to eat something like half the recommended daily allowance of salt. Let&#x27;s just say, eating out is a challenge. reply squeaky-clean 11 hours agorootparentIt&#x27;s so hard to find good store-bought snacks that are low sodium too. Even if there is a low-sodium version, the flavors are just \"lightly salted\" or \"hint of salt\". That&#x27;s not a flavor... reply btilly 11 hours agorootparentThe phrase to look for is \"no salt added.\"I either prepare my snacks, or just have fresh fruits and vegetables. reply squeaky-clean 6 hours agorootparentYeah that&#x27;s what I do, but I&#x27;d love to be able to buy some low sodium spicy chips or something. reply Aurornis 15 hours agoparentprev> They also say that salt is seriously bad for high blood pressure but I find little effect for myself personally. I do wonder how much sensitivity varies from person to person.You’d be shocked at how much salt some people consume. A little bit with your vegetables or steak isn’t going to move the needle, but some processed foods have unbelievable amounts of sodium relative to how they taste.Salt definitely impacts blood pressure. Salt supplements are used with good effect in certain conditions of low blood pressure&#x2F;volume. reply croes 15 hours agorootparentAccording to thishttps:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37355083Sodium isn&#x27;t the problem reply pdonis 14 hours agorootparentI think a better take would be: sodium isn&#x27;t the only possible problem. reply btilly 15 hours agorootparentprevMost would be shocked at how much salt they consume.That healthy prepackaged salad option at the grocery store? Often has more salt than a burger! reply wing-_-nuts 15 hours agorootparentI mean, I make my salads to be both nutritious AND tasty, and yeah, salt&#x27;s an important part of that. I&#x27;m not eating just raw veggies with a light sprinkle of balsamic reply btilly 13 hours agorootparentAnd if I ate like you do, I&#x27;d wind up in the hospital. Again.We&#x27;ve discovered that humans respond really well to a particular mixture of sugar, fat and salt. Basically every prepared food has about the same mix of those three. That mix is lethal for me.In the case of salads they do that by using the veggies as a salad dressing delivery mechanism. If I can&#x27;t add the oil and vinegar myself, I can&#x27;t eat the salad. reply black6 14 hours agorootparentprevSalt is water soluble and your body peepees and sweats out what it doesn&#x27;t need. Most people don&#x27;t consume too much sodium; they consume too little water and don&#x27;t get enough exercise. reply atahanacar 9 hours agorootparent>Salt is water solubleYeah, and that&#x27;s what makes salt increase your bp. More salt in blood = more water retention = more volume = higher bp. reply SirMaster 15 hours agoparentprevTechnically 80 diastolic is considered hypertension stage 1 under the current guidelines.https:&#x2F;&#x2F;www.heart.org&#x2F;en&#x2F;health-topics&#x2F;high-blood-pressure&#x2F;u...The highest you can be and be considered \"normal\" is 119&#x2F;79.Elevated is 120-129&#x2F; You would think that something like blood pressure would be highly regulated in the bodyCounterpoint: a 6&#x27; (1.83 m) tall column of blood has a pressure of 142 mmHg at the bottom- higher than your normal blood pressure. When you change posture from prone to sitting to standing, your blood pressure is basically swinging 100%. Hell, the diastolic blood pressure at your feet is almost double what your arms are at.Plus, the oxygen consumption of various body parts is hugely variable. More oxygen requires more blood and more blood requires more pressure. With that kind of variance all over your body it&#x27;s not a shock that it&#x27;s also generally pretty variable. reply UncleOxidant 15 hours agoparentprev> but it varies throughout the day, month and year.yep. I&#x27;ve taken my BP laying down and it&#x27;s generally lower than when I&#x27;m sitting up, but then again, I usually do that after going to bed, blood pressure is generally going to be lower at night so maybe I&#x27;m just noticing that difference vs during the day. reply zingababba 15 hours agoparentprevSalt absolutely does not matter for me. I eat a ridiculous amount of salt. Caffeine on the other hand == day long 10-20 point increase in my systolic BP regardless of if I&#x27;m using chronically or not. Ultimately one of the primary reasons I quit caffeine. reply Try1275 15 hours agorootparentDo you drink decaf? reply zingababba 14 hours agorootparentI don&#x27;t :) reply nradov 13 hours agoparentprevThe issue with salt and blood pressure is not so much the quantity but rather the osmolality. You can mitigate the effects by drinking more water.https:&#x2F;&#x2F;peterattiamd.com&#x2F;rickjohnson2&#x2F; reply umeshunni 15 hours agoprev [–] Saved you a click: Our findings suggest people with known risk factors for heart disease and stroke may benefit from having their blood pressure checked while lying flat on their backs replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The new research presented at the American Heart Association's Hypertension Scientific Sessions 2023 links high blood pressure while lying down to an increased risk of heart-related conditions and premature death.",
      "The study, which incorporated data from over 11,000 adults, found that individuals with high blood pressure, either when seated or lying down, faced the highest risks. However, even those who had high pressure only when lying were at comparable risk levels.",
      "The type of blood pressure medication taken did not impact the level of risk. Therefore, researchers suggest blood pressure should be measured while lying flat on the back for a more accurate assessment of cardiovascular disease risk."
    ],
    "commentSummary": [
      "The discussions revolve around blood pressure management and monitoring, which include experiences with medications, lifestyle changes, and devices for blood pressure measurements.",
      "Participants engage in debates about the frequency and accuracy of blood pressure readings and discuss the external factors that can impact these readings such as stress and physical activity.",
      "The importance of professional medical consultations, the perception of misinformation in online discussions, and the caution needed in following non-medical advice are underscored. For instance, lying down when checking blood pressure is recommended for individuals with specific risk factors."
    ],
    "points": 226,
    "commentCount": 181,
    "retryCount": 0,
    "time": 1694456458
  },
  {
    "id": 37468342,
    "title": "Webb Discovers Methane, Carbon Dioxide in Atmosphere of K2-18B",
    "originLink": "https://www.nasa.gov/goddard/2023/webb-discovers-methane-carbon-dioxide-in-atmosphere-of-k2-18b/",
    "originBody": "Skip to main content Search NASA.gov Topics Missions Galleries NASA TV Follow NASA Downloads About NASA Audiences Latest Related Webb Discovers Methane, Carbon Dioxide in Atmosphere of K2-18 b 20 hours ago Webb Detects Water Vapor in Rocky Planet-Forming Zone 2 months ago Webb Rules Out Thick Carbon Dioxide Atmosphere for Rocky Exoplanet 3 months ago NASA’s Webb Takes Closest Look Yet at Mysterious Planet 4 months ago Webb Finds Water Vapor, But From a Rocky Planet or Its Star? 4 months ago NASA’s Webb Measures the Temperature of a Rocky Exoplanet 6 months ago NASA’s Webb Spots Swirling, Gritty Clouds on Remote Planet 6 months ago Webb Telescope Sep 11, 2023 Webb Discovers Methane, Carbon Dioxide in Atmosphere of K2-18 b This artist’s concept shows what exoplanet K2-18 b could look like based on science data. K2-18 b, an exoplanet 8.6 times as massive as Earth, orbits the cool dwarf star K2-18 in the habitable zone and lies 120 light-years from Earth. A new investigation with NASA’s James Webb Space Telescope into K2-18 b has revealed the presence of carbon-bearing molecules including methane and carbon dioxide. The abundance of methane and carbon dioxide, and shortage of ammonia, support the hypothesis that there may be a water ocean underneath a hydrogen-rich atmosphere in K2-18 b. Credits: Illustration: NASA, CSA, ESA, J. Olmsted (STScI), Science: N. Madhusudhan (Cambridge University) Download the full-resolution, uncompressed version and supporting visuals from the Space Telescope Science Institute. A new investigation with NASA’s James Webb Space Telescope into K2-18 b, an exoplanet 8.6 times as massive as Earth, has revealed the presence of carbon-bearing molecules including methane and carbon dioxide. Webb’s discovery adds to recent studies suggesting that K2-18 b could be a Hycean exoplanet, one which has the potential to possess a hydrogen-rich atmosphere and a water ocean-covered surface. The first insight into the atmospheric properties of this habitable-zone exoplanet came from observations with NASA’s Hubble Space Telescope, which prompted further studies that have since changed our understanding of the system. K2-18 b orbits the cool dwarf star K2-18 in the habitable zone and lies 120 light-years from Earth in the constellation Leo. Exoplanets such as K2-18 b, which have sizes between those of Earth and Neptune, are unlike anything in our solar system. This lack of equivalent nearby planets means that these ‘sub-Neptunes’ are poorly understood, and the nature of their atmospheres is a matter of active debate among astronomers. The suggestion that the sub-Neptune K2-18 b could be a Hycean exoplanet is intriguing, as some astronomers believe that these worlds are promising environments to search for evidence for life on exoplanets. \"Our findings underscore the importance of considering diverse habitable environments in the search for life elsewhere,\" explained Nikku Madhusudhan, an astronomer at the University of Cambridge and lead author of the paper announcing these results. \"Traditionally, the search for life on exoplanets has focused primarily on smaller rocky planets, but the larger Hycean worlds are significantly more conducive to atmospheric observations.\" The abundance of methane and carbon dioxide, and shortage of ammonia, support the hypothesis that there may be a water ocean underneath a hydrogen-rich atmosphere in K2-18 b. These initial Webb observations also provided a possible detection of a molecule called dimethyl sulfide (DMS). On Earth, this is only produced by life. The bulk of the DMS in Earth’s atmosphere is emitted from phytoplankton in marine environments. Spectra of K2-18 b, obtained with Webb’s NIRISS (Near-Infrared Imager and Slitless Spectrograph) and NIRSpec (Near-Infrared Spectrograph), display an abundance of methane and carbon dioxide in the exoplanet’s atmosphere, as well as a possible detection of a molecule called dimethyl sulfide (DMS). The detection of methane and carbon dioxide, and shortage of ammonia, support the hypothesis that there may be a water ocean underneath a hydrogen-rich atmosphere in K2-18 b. K2-18 b, 8.6 times as massive as Earth, orbits the cool dwarf star K2-18 in the habitable zone and lies 120 light-years from Earth. Credits: Illustration: NASA, CSA, ESA, R. Crawford (STScI), J. Olmsted (STScI), Science: N. Madhusudhan (Cambridge University) Download the full-resolution, uncompressed version and supporting visuals from the Space Telescope Science Institute. The inference of DMS is less robust and requires further validation. “Upcoming Webb observations should be able to confirm if DMS is indeed present in the atmosphere of K2-18 b at significant levels,” explained Madhusudhan. While K2-18 b lies in the habitable zone, and is now known to harbor carbon-bearing molecules, this does not necessarily mean that the planet can support life. The planet's large size — with a radius 2.6 times the radius of Earth — means that the planet’s interior likely contains a large mantle of high-pressure ice, like Neptune, but with a thinner hydrogen-rich atmosphere and an ocean surface. Hycean worlds are predicted to have oceans of water. However, it is also possible that the ocean is too hot to be habitable or be liquid. \"Although this kind of planet does not exist in our solar system, sub-Neptunes are the most common type of planet known so far in the galaxy,\" explained team member Subhajit Sarkar of Cardiff University. “We have obtained the most detailed spectrum of a habitable-zone sub-Neptune to date, and this allowed us to work out the molecules that exist in its atmosphere.” Characterizing the atmospheres of exoplanets like K2-18 b — meaning identifying their gases and physical conditions — is a very active area in astronomy. However, these planets are outshone — literally — by the glare of their much larger parent stars, which makes exploring exoplanet atmospheres particularly challenging. The team sidestepped this challenge by analyzing light from K2-18 b's parent star as it passed through the exoplanet's atmosphere. K2-18 b is a transiting exoplanet, meaning that we can detect a drop in brightness as it passes across the face of its host star. This is how the exoplanet was first discovered in 2015 with NASA’s K2 mission. This means that during transits a tiny fraction of starlight will pass through the exoplanet's atmosphere before reaching telescopes like Webb. The starlight's passage through the exoplanet atmosphere leaves traces that astronomers can piece together to determine the gases of the exoplanet's atmosphere. \"This result was only possible because of the extended wavelength range and unprecedented sensitivity of Webb, which enabled robust detection of spectral features with just two transits,\" said Madhusudhan. \"For comparison, one transit observation with Webb provided comparable precision to eight observations with Hubble conducted over a few years and in a relatively narrow wavelength range.\" \"These results are the product of just two observations of K2-18 b, with many more on the way,” explained team member Savvas Constantinou of the University of Cambridge. “This means our work here is but an early demonstration of what Webb can observe in habitable-zone exoplanets.” The team’s results were accepted for publication in The Astrophysical Journal Letters. The team now intends to conduct follow-up research with the telescope's MIRI (Mid-Infrared Instrument) spectrograph that they hope will further validate their findings and provide new insights into the environmental conditions on K2-18 b. \"Our ultimate goal is the identification of life on a habitable exoplanet, which would transform our understanding of our place in the universe,\" concluded Madhusudhan. \"Our findings are a promising step towards a deeper understanding of Hycean worlds in this quest.\" The James Webb Space Telescope is the world's premier space science observatory. Webb is solving mysteries in our solar system, looking beyond to distant worlds around other stars, and probing the mysterious structures and origins of our universe and our place in it. Webb is an international program led by NASA with its partners, ESA (European Space Agency) and the Canadian Space Agency. Media Contacts: Laura Betz NASA's Goddard Space Flight Center, Greenbelt, Md. laura.e.betz@nasa.gov Hannah Braun Space Telescope Science Institute, Baltimore, Md. hbraun@stsci.edu Last Updated: Sep 11, 2023 Editor: Isabelle Yan Tags: Astrobiology, Exoplanets, Goddard Space Flight Center, James Webb Space Telescope, Universe Read Next Related Article National Aeronautics and Space Administration Page Last Updated: Sep 11, 2023 NASA Official: Brian Dunbar No Fear Act FOIA Privacy Accessibility Office of Inspector General Office of Special Counsel Agency Financial Reports Contact NASA",
    "commentLink": "https://news.ycombinator.com/item?id=37468342",
    "commentBody": "Webb Discovers Methane, Carbon Dioxide in Atmosphere of K2-18BHacker NewspastloginWebb Discovers Methane, Carbon Dioxide in Atmosphere of K2-18B (nasa.gov) 222 points by wfurney 19 hours ago| hidepastfavorite120 comments v8xi 18 hours agoIn Nick Lane&#x27;s Oxygen: The Molecule that Made the World, he talks about the importance of both methane and carbon dioxide and how they exist at the extremes of a complex metabolic oxidation-reduction cycle. Methane stores a lot of chemical energy in its C-H bonds which can be burned directly, or metabolized through repeat oxidation events to ultimately form CO2, which plants utilize with the help of the sun to form more CH bonds before ultimately breaking down into methane again. Hence, an exoplanet with both molecules in its atmosphere is a promising candidate in the search for life. reply behnamoh 17 hours agoparentI wonder what life looks like on a planet which is over 8 times more massive than the Earth. Do animals have spines at all on a planet with almost 8g gravity? Does life even get to evolve into complex systems like animals under this much gravity? How about plants? Do they grow up or spread out instead?If one day we get a visitor from this planet, they&#x27;ll jump on our planet the same way human astronauts jumped on the Moon. reply pdonis 16 hours agorootparentThe planet&#x27;s surface gravity is not 8 g. Surface gravity goes like mass over radius squared, and the planet&#x27;s radius is 2.6 times Earth&#x27;s, so the surface gravity will be 8 &#x2F; (2.6)^2, or only about 1.2 times that of Earth. reply thot_experiment 6 hours agorootparentJuuuuusssttt barely below the limit to be able to launch chemical rockets into space (IIRC it&#x27;s ~1.3g) reply rayrey 5 hours agorootparentLol.Seeing that response and then your username reply adolph 13 hours agorootparentprevThat is if density remains constant. If the planet were 8x mass but with same radius, gravity would be 8 g, or 8 × 9.795 m&#x2F;s^s. Earth mass: 5.97×10^24 kg, 6378.137 km yields 9.795 m&#x2F;s^2 8x mass: (8×5.97)×10^24 kg, 6378.137 km yields 78.36 m&#x2F;s^2All calculations: https:&#x2F;&#x2F;www.wolframalpha.com&#x2F;input?i=surface+gravity+calcula... reply pdonis 12 hours agorootparent> That is if density remains constant.No, the calculation I made did not assume constant density. I just used the direct Newtonian formula for surface gravity and plugged in the known mass and radius of the planet. (You could also use that known mass and radius to calculate the average density. But you don&#x27;t need to do that to calculate the surface gravity.)> If the planet were 8x mass but with same radiusBut we know it isn&#x27;t. We know the planet&#x27;s radius is 2.6 times the Earth&#x27;s radius. That&#x27;s stated in the article. reply mr_toad 10 hours agorootparentprev> If the planet were 8x mass but with same radiusThat’s not possible for normal stable matter. The Earth’s density is about 5g per cubic centimetre. Iron is 7.8g per cubic centimetre. Osmium is the densest stable element at 22.6g per cubic centimetre. reply lovecg 17 hours agorootparentprevNote that 8 times more massive doesn’t mean it has 8 times surface g, unless it’s exactly the same radius as the Earth. If the planet is larger you’re further away from the center of gravity.For example, the Earth is 10 times more massive than Mars, but only has 2.6 times surface g. reply jdblair 16 hours agorootparentprevThe classic sci-fi \"Mission of Gravity\" explores what life would be like on a rapidly rotating planet where one experiences 3g at the equator and 700g at the poles.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Mission_of_Gravity reply everyone 13 hours agorootparentThanks for that! I need a new novel to read, just downloaded it! reply alexpotato 16 hours agorootparentprevThe book Dragon&#x27;s Egg has a species living on a neutron start with millions of G&#x27;shttps:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Dragon%27s_Egg reply dylan604 17 hours agorootparentprevThe gravity question is one I&#x27;ve pondered myself as a thought exercise. There&#x27;s been discussions on how far up a plant can draw water as the defining limit to how tall a tree could grow. Some discussions as well on how tall an animal could grow based on how high blood could be pumped up. Which is a direction different from the structural support and sizes that I find interesting. reply adriand 11 hours agorootparentI can imagine an intelligent species on a high-G planet scratching their “heads” and wondering, as they surveil Earth, how anything could possibly survive on such a low-G planet. reply dylan604 10 hours agorootparentlike humans trying to determine how to survive on moon bases or Martian colonies? reply gizmo686 17 hours agorootparentprevGravity is more relevant for land based life. However, we know from Earth that complex life can evolve in oceans. reply mulletboy 1 hour agorootparentprevCan anyone recommend a good book on exoplanets speculative biology, flora & fauna, etc? reply wheels 16 hours agorootparentprevGravity is only about 1.25 g, according to Wikipedia. Density matters. The earth and Saturn have about the same surface gravity. reply OkayPhysicist 10 hours agorootparentComparing rocky planets, density doesn&#x27;t really matter at all. The range of possible densities for rocky planets is tightly constrained. What matters is the fact that surface gravity scales sub-linearly with regards to a planets mass. M = 4&#x2F;3*pi*r^3*d r = (4&#x2F;3*pi*d&#x2F;M)^(-1&#x2F;3) a = GM&#x2F;r^2 a = GM(4&#x2F;3*pi*d&#x2F;M)^(2&#x2F;3) a = G(4&#x2F;3*pi*d)^(2&#x2F;3) * M^(1&#x2F;3) reply joshlemer 16 hours agorootparentprevIt would be really cool to run an experiment like this. Have some population of rats living in a large enclosure that is held in a large centrifuge for decades and see how they evolve. reply kemmishtree 6 hours agorootparentJust put e. coli in an ultracentrifuge and do a few hundred generations of serial passaging and see what evolves, for starters. You could do this pretty cheaply without waiting decades or killing mammals. Apparently e. coli can proliferate happily at almost half a million g... https:&#x2F;&#x2F;phys.org&#x2F;news&#x2F;2011-04-bacteria-extreme-gravity.html#.... reply watersb 17 hours agorootparentprevI wonder how much of an outlier we may be, shuffling around on dry land, when most of the biosphere of our planet is in the ocean.Higher gravity certainly means higher pressure gradient, more pressure per vertical meter of ocean. And high pressure affects protein structure.It&#x27;s life, but not as we know it. reply 0xfaded 17 hours agorootparentprevAssuming roughly comparable density to earth, the surface gravity would only be 2g reply BurningFrog 11 hours agorootparentprevThe g force isn&#x27;t that important for this.Assuming life develops in an ocean, like we did, organisms in water are essentially weightless, regardless of the g force. reply fmobus 16 hours agorootparentprevI think 8g would be pretty hard to escape from, at least with chemical rockets. reply ericbarrett 13 hours agorootparentEarth&#x27;s surface gravity is really on the edge of what&#x27;s feasible for chemical rockets; IIRC the limit is around 1.4g. Though as other commenters have mentioned, it&#x27;s possible to have a much more massive planet that&#x27;s also got a larger radius and thus has comparable surface gravity.Some fun trivia—the planet Kerbin from Kerbal Space Program is the opposite case. It has a radius of 600km, versus Earth&#x27;s 6378km, but is exactly 1 Earth g on the surface. This implies it&#x27;s over 10x as dense. reply ethbr1 4 hours agorootparentTo expand, isn&#x27;t that limit \"the most efficient possible chemical rockets, launched from sea level\"?I.e. air-breathing aircraft + chemical rockets would work, as would other exotic solutions reply colechristensen 16 hours agorootparentprevAs others have mentioned it wouldn&#x27;t be 8 g. Life would be smaller. There would be speed differences. A lot of optimums and limits depend on how volume scales against area. Like the biggest terrestrial animals are limited a characteristic dimension (height or length) x being proportional to femur area x^2 being proportional to mass x^3. Mass grows proportional to x^3, femur strength (area) grows proportional to x^2, so you have a limit on how big a thing can be when you run out of available femur strength.Higher gravity means this upper limit will be smaller. All sorts of similar scaling things will change optimum points for structural and energy reasons. reply thelittleone 17 hours agorootparentprevPerhaps they&#x27;re gas like. reply littlestymaar 13 hours agorootparentprevIn addition to what others have said about the fact this planet doesn&#x27;t have 8g at its surface, at 8g you could still have many lifeforms that exists on earth, but only the small ones. Gravity grows roughly as the cube of your size (because your volume does), but bones resistance only get n² (because it&#x27;s the surface that counts), so the bone resistance &#x2F; weight ratio is inversely proportional to your size. reply julienchastang 18 hours agoparentprevThanks for the book recommendation. Added to reading list. reply perihelions 14 hours agoprevWhat an unintuitive and sketchy-looking Bayesian model. They only have 11 chemicals in the database they&#x27;re matching that messy IR spectrum against: 6 reasonable ones, and 5 bullshit ones that are only there because theory papers suggested that they&#x27;d be biomarkers of alien life. And, fit to just those 11 chemicals, the best-fit includes one of the bullshit ones (dimethyl sulfide, (CH₃)₂S).https:&#x2F;&#x2F;stsci-opo.org&#x2F;STScI-01HA2G716KS9YGAGVY1WBVFJ8Y.pdfIs this approach, like, sane? I&#x27;m not a Bayesian statistics expert. reply kjkjadksj 1 hour agoparentA true Bayesian I don’t think would use evidence for life on earth as the silver bullet for life elsewhere. They’d at least set up a model that considers all possible planets in the entire universe and test to see if these putative signatures even give you the power to identify earth as a life holding planet with confidence. reply julienchastang 18 hours agoprevOn this topic, I just finished reading \"A Very Short Introduction to Planetary Systems\"[0] by Raymond T. Pierrehumbert. He devotes a good portion of the book to exoplanet atmospheres. It is one of the best science books I&#x27;ve read. Pierrehumbert really has a knack for explaining complex material clearly and concisely. I really recommend it.[0] https:&#x2F;&#x2F;global.oup.com&#x2F;academic&#x2F;product&#x2F;planetary-systems-a-... reply nofitty376 16 hours agoprevThat spectrum is so noisy. How can they infer the blue fit from the (noisy) white points? The data look almost consistent with flat (no detection). And even if there is a detection, it looks like many other models could potentially fit the data... reply gus_massa 15 hours agoparent[I&#x27;m not an expert is spectroscopy, but let me guess.]The bump at 4.3um looks real, and it seams to be an standard absorción of CO2. https:&#x2F;&#x2F;www.quora.com&#x2F;Does-CO2-absorb-all-infrared-frequenci...The bump at 1.2, 1.4 and 2.4um looks real. I found this showing a peak for CH4 at 2.325um. http:&#x2F;&#x2F;www.astrochem.org&#x2F;data&#x2F;CH4H2O.php[Sorry for the sources, but I&#x27;m not an expert is spectroscopy.]My guess is that they assumed something likea% * CH4 + b% * CO2 + c% * H2O + othersand get the best fit for a%, b%, c%, ... using the white points. Later, using these numbers they draw the blue line.The peak for DMS is not clear for my untrained eye, so I can&#x27;t guess what they did there. (Perhaps it&#x27;s just the best fit.) It would be nice to see the a graph of the blue line they guessed with DMS and a superimposed red line with and atmosphere with an alternative atmosphere where the DMS is replaced with something uninteresting (N2? H2O? More CH4? I have no idea what is uninteresting here.) reply bigbillheck 15 hours agoparentprev> How can they infer the blue fit from the (noisy) white points?By having a detailed model, and modern probabilistic techniques:The planet’s terminator is modelled as a plane-parallel atmosphere in hydrostatic equilibrium, with uniform chemical composition. The chemical abundances and pressure-temperature (P-T) profile are free parameters in the model. The retrieval framework follows a free chemistry approach, whereby the individual mixing ratio of each chemical species is a free parameter.... Our canonical model comprises of 22 free parameters overall: 11 corresponding to the individual mixing ra- tios of the above chemical species, 6 for the P-T profile, 4 for the clouds&#x2F;hazes and 1 for the reference pressure Pref , defined as the pressure at a fixed planetary radius of 2.61 R⊕. The Bayesian inference and parameter estimation is conducted using the MultiNest nested sam- pling algorithm (Feroz et al. 2009) implemented through PyMultiNest.(Sections 2.4 and 3.1 from https:&#x2F;&#x2F;stsci-opo.org&#x2F;STScI-01HA2G716KS9YGAGVY1WBVFJ8Y.pdf)> And even if there is a detection, it looks like many other models could potentially fit the data...Name three. reply gus_massa 13 hours agorootparentCan I help the GP?In the paper they analyze 3 models, \"no offset\", \"offset\" and \"offsetx2\". It&#x27;s strange that they get better fit for CO2 and CH3 en the \"offsetx2\" model, but in that model the DMS disappears. So there it at least one model.Also, they analyze common molecules like CO2, CH4, H2O, NH3 and biologically interesting molecules like CH3-S-CH3 (DMS), HCN, CH3-Cl. From the discussion in the paper it looks like the CH3- part is important, so I&#x27;d like to see a brute force search with everything that is in https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Atmosphere_of_Titan and has a methyl group, like CH3-CCH, CH3-CN. My Chemistry and Astronomy is no so good, so I&#x27;d like to add CH3-OH, CH3-NH2, CH3-SH, CH3-CHO and a few more from https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;List_of_interstellar_and_circu... I removed the ones that are big or has too many oxygen (like CH3-COOH). reply nextaccountic 6 hours agorootparentprevwhat means planet&#x27;s terminator? reply thenickdude 4 hours agorootparentThe boundary between daytime and nighttime [0][0]: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Terminator_(solar) reply fritzo 16 hours agoparentprevRight, show a posterior distribution not some hallucinated point estimate. reply V1ndaar 15 hours agorootparentCheck out the paper and not a PR piece [0].[0]: https:&#x2F;&#x2F;stsci-opo.org&#x2F;STScI-01HA2G716KS9YGAGVY1WBVFJ8Y.pdf reply sgt101 18 hours agoprevGosh - imagine that place!I wonder how old this world is, and how stable its enviroment is&#x2F;has been. Complex animal life took 3.5 bn years to emerge on Earth, of course that&#x27;s a meaningless data point by itself but intuitively for this place to have an ecosystem or complex life it needs to be old.Still, even without this what a wonderful and weird environment. reply svachalek 15 hours agoparentSingle cell life appeared on Earth almost instantly after the planet cooled down enough to allow it. I don&#x27;t think it&#x27;s clear that any progress was being made over the next few billion years. One day the right mutation happened and boom, fancy life everywhere. With our data sample of one, I don&#x27;t think it&#x27;s clear if it was extraordinarily bad luck it took that long to happen, or extraordinarily good luck it ever happened at all. reply fbdab103 5 hours agorootparentEukaryotic cell is such a bonkers insane development, I definitely lean towards the impossibly lucky scenario. There was no need for that to be the origin story of a mitochondria like organelle (https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Symbiogenesis), but that&#x27;s what we think we have.That being said, there was an experiment (https:&#x2F;&#x2F;www.pnas.org&#x2F;doi&#x2F;full&#x2F;10.1073&#x2F;pnas.1115323109) which was able to select single cellular organisms to \"become multicellular\" in a rapid amount of time ( Complex animal life took 3.5 bn years to emerge on Earth,How certain are we it took that long (the first time)? reply delta_p_delta_x 18 hours agorootparentThe fossil record. There is little evidence of very complex animal life before about 541 million years ago, which is when the Cambrian explosion begun. reply TheBlight 17 hours agorootparentGiven the surface of the planet is such a dynamic environment, I wonder how much evidence we should expect even if it did exist.See also: https:&#x2F;&#x2F;www.scientificamerican.com&#x2F;article&#x2F;could-an-industri... reply Rebelgecko 17 hours agorootparentThere&#x27;s quite a few fossils showing single-celled organisms from 3+ billion years ago. I imagine if more complex life existed the fossils could&#x27;ve survived reply no_wizard 16 hours agorootparentprevWhen you say very little, do you mean none, or there is some questionable evidence?I&#x27;m genuinely curious reply dudinax 15 hours agorootparentBefore \"modern\" life evolved in the pre-cambrian era, there was the Ediacaran life forms that were complex multicellular life, but died out millions of years before the Cambrian explosion.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Ediacaran_biota reply tracedddd 18 hours agorootparentprevNot certain at all, it’s based on last universal common ancestor estimates(LUCA) and supported by (lack of) fossil record. reply no_wizard 15 hours agorootparentIts possible there is a good explanation for why there would be no strong fossil record[0] for an advanced civilization preceding us.>When it comes to direct evidence of an industrial civilization—things like cities, factories, and roads—the geologic record doesn’t go back past what’s called the Quaternary period 2.6 million years ago. For example, the oldest large-scale stretch of ancient surface lies in the Negev Desert. It’s “just” 1.8 million years old—older surfaces are mostly visible in cross section via something like a cliff face or rock cuts.While I think its highly unlikely (I mean less than 0.00001% possible) the means in which we would could even detect it are complicated[0]: https:&#x2F;&#x2F;www.theatlantic.com&#x2F;science&#x2F;archive&#x2F;2018&#x2F;04&#x2F;are-we-e... reply wolverine876 17 hours agorootparentprev> it’s based on last universal common ancestor estimates(LUCA) and supported by (lack of) fossil record.I thought the Cambrian Explosion&#x27;s fossil record was pretty sizeable - in fact, it&#x27;s named after the place where the fossil layer was first discovered. I didn&#x27;t know it was related to a common ancestor. Are you thinking of something else or am I missing something major? reply edgyquant 14 hours agorootparentYes but we’re talking about before the Cambrian reply wolverine876 12 hours agorootparent?>>> Complex animal life took 3.5 bn years to emerge on Earth,>> How certain are we it took that long (the first time)?> Not certain at all, it’s based on last universal common ancestor estimates(LUCA) and supported by (lack of) fossil record.Do you mean, there&#x27;s little evidence of pre-Cambrian absence? Absence of evidence is some evidence of absence, in this case.But how does LUCA fit into this question? reply sgt101 31 minutes agorootparentI think we can see where different complex animals split in their evolutionary tree - so humans and starfish split a long way back. Then we use a standard mutation clock to estimate how long ago that was. If all complex animals split from simple animals an estimated 700m years ago... replykaycebasques 18 hours agoprevIt&#x27;s mind-bendingly cool that people can figure out the composition of an atmosphere without actually being close to that atmosphere.Had not heard of dimethyl sulfide before. That&#x27;s a good keyword to know. reply dghughes 17 hours agoparentFor emission spectroscopy has been a thing since 1859 when Gustav Kirchhoff figured it out but for stellar emission spectroscopy it was Joseph von Fraunhofer in early 1800s? Although 1866, Pietro Angelo Secchi may have also discovered stellar emission spectroscopy 1848.An amazingly long time ago. reply julienchastang 18 hours agoparentprevFrom a single pixel of light! Indeed mind blowing. reply treyd 16 hours agorootparentThat&#x27;s somewhat misleading though. It&#x27;s not really a pixel in that there&#x27;s much more information available than, basically, 3 integers between 0 and 255. There&#x27;s 4 instruments on the telescope that collect 4 different chunks of IR spectra, and there&#x27;s very precise and granular intensity values for light received around any given wavelength. Much more detail than a \"pixel\" has in the typical sense we use them.It&#x27;s not a lot of information, not nearly enough to identify surface features on an exoplanet, but it&#x27;s very useful data if you&#x27;re trying to identify likely chemical composition of bodies or how hot clouds of gas are. reply kjkjadksj 1 hour agorootparentIf you were at such distance from the earth, what would be resolvable? reply saltcured 9 hours agorootparentprevIt&#x27;s a crude analogy, but I like to tell people that a spectroscope is more like a highly directional microphone to listen to molecules than it is like any normal camera... reply finite_depth 17 hours agoparentprevThis is an easier problem than it probably seems. Atmospheres are relatively low-density gas, which means they produce an absorption spectrum - a chemical fingerprint that identifies most atoms and molecules quite reliably. It&#x27;s such a good fingerprint that it was used to discover several chemical elements, most notably helium (observed in the Sun&#x27;s spectrum before it was known on Earth). reply Jeff_Brown 18 hours agoprevIn case you wondered too, this is 124 light-years from us. reply Aachen 17 hours agoparentWow, that&#x27;s really close so far as these things go. With the nearest star being 4ly, this can be reached with essentially the same tech level if we&#x27;d want to visit that with a rover or generational ship one day reply mcv 31 minutes agorootparent> this can be reached with essentially the same tech levelI&#x27;m not so sure about that. I mean, at the moment both are impossible, but it&#x27;s much easier to imagine traveling 4ly than 124ly. 4ly can be reached in a single lifetime if you accelerate a shop to .9c, which is technically possible. 124ly is going to be a multigenerational undertaking no matter what. The 248y communication lag is also a much bigger obstacle than an 8y lag.I think once you can travel 124ly, you can travel 1000+ ly. You need to be completely self-sufficient and you&#x27;re going to lose contact with home anyway. If you send a robot, you&#x27;re not going to hear from that robot again in centuries, if ever. reply hungryforcodes 17 hours agorootparentprevWe&#x27;d need some fast tech for sure. However, what is also interesting is that the light from it is only 124 years old. So the planet is still very similar today probably. reply BoiledCabbage 17 hours agorootparentprevWhat&#x27;s also crazy is if we did send a rover over there to hunt for life, and they found it, we&#x27;d have to wait 125 years to hear the result.We all sit around knowing to listen to the skies sometime in October of 2185 to hear if the rover found life within the first month of its landing.If we ever send a team to live there, we&#x27;d hear broadcasts of their lives from 125 years prior. A real portal in time - so cool. reply jandrese 16 hours agorootparentEven worse if we are still limited by Newtonian dynamics it will take thousands of years for a probe to reach there. The rocket equation is a harsh mistress. In practical terms we will never visit that world without completely upending physics as we know it. reply holoduke 15 hours agorootparentWe just need a 1g rocket. Will take only a few days to get there. Life on earth will be 1000 years ahead once we are back though. reply jandrese 12 hours agorootparentThe problem is when you work out the math on rocket that can sustain 1G for multiple days with any Earthly isp you realize the math just doesn&#x27;t work. Even if you go nuts and plug in a number like 1 million seconds (our best chemical rockets are more like 450 seconds) for the isp it is still nowhere close to feasible using only the mass of our solar system.As long as you are stuck flinging mass out of the back of your rocket to accelerate you don&#x27;t get to go anywhere outside of our solar system. reply lapama 47 minutes agorootparentWhat about that strage propulsion system announced by caltech a few years back? Sorry really I have no more knowledge. reply kjkjadksj 1 hour agorootparentprevDyson proposed a fusion pulse propulsion system in the 1960s that was estimated at 70000 isp. Maybe 1m wouldn’t have been that far off from the limits of these crafts if test ban treaties didn’t kill their development. reply mr_toad 8 hours agorootparentprevA beamed core proton-antiproton rocket could produce millions of ISP and allow accelerations of up to 0.7C, using relativistic mesons as the reaction mass. It is entirely theoretical though.https:&#x2F;&#x2F;ntrs.nasa.gov&#x2F;api&#x2F;citations&#x2F;20200001904&#x2F;downloads&#x2F;20... reply coffeebeqn 15 hours agorootparentprevHow do you get the rover there? It would take thousands of years. Or maybe millions of years? With the current tech reply pg_bot 10 hours agorootparentIf you&#x27;re traveling as fast as voyager 1, it would take over 2 million years to get there. reply NoMoreNicksLeft 14 hours agorootparentprevOrion drives can get up to some respectable fraction of the speed of light. Just need a billion or so 1-kiloton nukes. No biggy. No worries about sneaking up on them and startling them either. reply floxy 12 hours agorootparent\"Roundtrip Interstellar Travel Using Laser-Pushed Lightsails\"https:&#x2F;&#x2F;citeseerx.ist.psu.edu&#x2F;viewdoc&#x2F;download?doi=10.1.1.10... reply NoMoreNicksLeft 3 hours agorootparentOk, but let&#x27;s bring along some nukes anyway, just for giggles. reply polishdude20 17 hours agorootparentprev2185? Not 2273? reply billforsternz 4 hours agoprevI picked up a random book in the science section of the city library today and opening it to a random page I started reading about an exciting \"goldilocks\" exoplanet discovery from 2015. Apparently this was the first exo-planet which had a positive spectroscopic identification of water in the atmosphere. It was a rocky world, 2 billion years old, 8 times Earth&#x27;s size (mass?), on a 33 day orbit around a red dwarf. K-something-or-other. The book said the really exciting discoveries will happen when Webb comes online in 2021. The link is down, but someone mentions this planet is 8 x Earth size down thread. I wonder if it&#x27;s the same planet? reply truculent 1 hour agoparentI think this is supposedly a Hycean (ocean + hydrogen atmosphere) planet, rather than rocky. Unless those categories aren’t exclusive. reply cout 18 hours agoprev> These initial Webb observations also provided a possible detection of a molecule called dimethyl sulfide (DMS). On Earth, this is only produced by life. The bulk of the DMS in Earth’s atmosphere is emitted from phytoplankton in marine environments.Given a sufficient quantity of reactants&#x2F;reagents, could DMS be produced via a natural process, or is this a sufficiently unfavorable reaction that it&#x27;s unlikely? reply kjkjadksj 1 hour agoparentIt is produced industrially without needing life. I’m not sure why its the alleged smoking gun if theoretically if the conditions are right and the reaction is catalyzed it will go on without needing a lifeform.2 CH3OH + H2S → (CH3)2S + 2 H2O reply marcosdumay 16 hours agoparentprevI don&#x27;t think anybody knows enough to tell you what kinds of reactions happen on planet-wide environments without an oxidizing atmosphere. reply kjkjadksj 1 hour agorootparentChemist certainly do. Reactions are carried out at specific atmospheric conditions. E.g. oxygen may well be purged. reply nickhalfasleep 18 hours agoprevScientists using Webb may be able to present some surprisingly strong evidence that we are not the only life bearing planet in the galaxy. reply jug 17 hours agoparentYeah, not sure about the sensitivity, if it&#x27;s particularly good conditions here but at least this data set looks like it gives remarkably little room for false positives and quite highly detailed. I thought it would push JWST a bit harder but this looks promising. Even a novice can read out the evidence for various molecules in that graph? So, if only we&#x27;d find an exciting result soon! reply lofaszvanitt 17 hours agoprev120 light years away. Time to get the ufo tech out already. reply no_wizard 16 hours agoparentis Faster Than Light travel even possible? I&#x27;m asking in a serious way.I have always read that its impossible, at least within our current knowledge.the only semi-plausible theory I&#x27;ve ever heard is that Blackholes might one day yield some way of traveling quickly across the universe but nobody has shown anything substantiated around that or anything else. reply coldpie 14 hours agorootparentFTL travel being impossible is basically the one thing where I completely irrationally reject the science :) It&#x27;s just too depressing for me to accept. There&#x27;s gotta be a loophole. There&#x27;s just gotta be... reply blackoil 7 hours agorootparentIt&#x27;s super easy, barely an inconvenience. Bend space time to create a wormhole. reply svachalek 15 hours agorootparentprevThere&#x27;s no realistically plausible solution I&#x27;ve ever heard of, that is, ones that don&#x27;t require millions of years of setup and entire stars worth of energy production. But that&#x27;s with our current understanding of physics. While our current models seem nearly perfect and therefore nearly complete, there was a time they thought that about Newtonian physics. Perhaps some detail we need to understand dark matter or dark energy could spring the whole field wide open again. reply edgyquant 12 hours agorootparent> While our current models seem nearly perfect and therefore nearly completeI’m not sure this is the case. Basically every physicist I’ve met thinks we’re in for another general relativity and that a unified theory will be a lot different than the multitude of theories we have now reply floxy 12 hours agorootparentprevNot a lot of help for interstellar travel, but I believe that most of the mass in the visible universe is traveling away from us at faster than the speed of light.https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;astro-ph&#x2F;0011070v2.pdf reply shepardrtc 9 hours agorootparentprevYou can&#x27;t go FTL through spacetime. But some math shows that it might be possible to warp spacetime around you and propel you to somewhere faster than it would take light going through spacetime. reply lofaszvanitt 14 hours agorootparentprevThe ufos have to come from somewhere, right? reply coldpie 14 hours agorootparentYeah, flawed lenses and windows, and unreliable witnesses. No need for FTL there. reply NoMoreNicksLeft 14 hours agorootparentprevIt&#x27;s quite simple really. All we need is fast-as-light technology.If you get in a ship and travel to Alpha Centauri at the speed of light, the travel seems instantaneous to you. But the people you leave behind think you&#x27;ve been gone 8 years when you return.So instead, I propose that when the ship launches, we also propel the rest of the universe in the opposite direction also at the speed of light. Then, when the astronaut is scheduled to return, we propel the entire universe at the speed of light back to its original location.All of reality undergoes time dilation. And the trip is basically instantaneous for all involved†.† Note: This form of FTL is mildly costly in regards to energy expenditure. reply 7373737373 16 hours agoparentprevUnfortunately humanity has not yet understood the potential that is out there, and is too busy fighting over the limited one here on Earth. reply skywal_l 18 hours agoprevSeems to be down. This page seems to work: https:&#x2F;&#x2F;webbtelescope.org&#x2F;contents&#x2F;news-releases&#x2F;2023&#x2F;news-2... reply rbanffy 12 hours agoprevUgh. If my napkin math is right, it&#x27;s about 2G&#x27;s for the same density as Earth.Very unpleasant planet. reply divbzero 14 hours agoprev> \"Our ultimate goal is the identification of life on a habitable exoplanet, which would transform our understanding of our place in the universe,\" concluded Madhusudhan.What sort of observation or measurement would allow us to identify life on an exoplanet? reply gus_massa 13 hours agoparentA lot of O2. As far as we know, the only source of a lot of O2 in the atmosphere are photosynthetic bacteria-like. So it will be a clear sign of life.There are some more subtle cases, like the one discussed in this paper. reply wfurney 18 hours agoprevhttps:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20230911143418&#x2F;https:&#x2F;&#x2F;www.nasa.... reply jncfhnb 16 hours agoprevSuppose a planet like this had non intelligent megafauna life. How could we detect this? reply dudinax 15 hours agoparentOne way is to build bigger telescopes and hope its not too cloudy. reply floxy 12 hours agorootparent\"Direct Imaging of an Exoplanet with a Solar Gravity Lens (1 Km Resolution)\":https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1802.08421...and an excellent video on the topic:https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=NQFqDKRAROI reply ZunarJ5 18 hours agoprevThis feels like a big deal. The website seems to be getting hammered as it is working on and off. reply willis936 18 hours agoparentWhat makes it feel like a big deal? Carbon, oxygen, and hydrogen are extremely abundant. Those molecules are relatively low energy combinations of the elements. I would be surprised to not find them in the atmospheres of big rocky planets. reply bilekas 18 hours agorootparentApperantly it seems to be the presence of \" dimethyl sulfide \". It seemingly only produced, on earth at least, by life. So using us as a baseline it seems pretty interesting.> DMS is generated by the degradation of dimethylsulfoniopropionate, which is present in many species of marine algae and plants, including dinoflagellates and coccolithophores reply JackFr 17 hours agorootparentAfter getting sucked in by the phosphine on Venus hype, I refuse to get hurt again. . . reply ZunarJ5 17 hours agorootparentprevYes, this is it! reply bayesianbot 18 hours agoprev404 not found, did they maybe remove the article for some reason? reply fritzo 15 hours agoprevPaywalled paper: https:&#x2F;&#x2F;www.nature.com&#x2F;articles&#x2F;s41550-019-0878-9Preprint: https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1909.05218Figure 2 pp. 14 of the preprint shows much more plausible error bounds on the curve fit. That press release \"best fit\" curve is merely an artist&#x27;s conception. reply V1ndaar 15 hours agoparentNope, that is the old paper about Hubble measurements of the same planet.The preprint of the Webb based paper is here [0] from here [1].[0]: https:&#x2F;&#x2F;stsci-opo.org&#x2F;STScI-01HA2G716KS9YGAGVY1WBVFJ8Y.pdf[1]: https:&#x2F;&#x2F;webbtelescope.org&#x2F;contents&#x2F;news-releases&#x2F;2023&#x2F;news-2... reply biggestlou 12 hours agoprevI’m still looking for intelligent life on this planet reply swader999 17 hours agoprev [–] Nice to know we aren&#x27;t the only ones struggling with CO2. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "NASA's James Webb Space Telescope has detected methane and carbon dioxide in the atmosphere of the exoplanet K2-18 b, reinforcing the possibility that this planet may harbor a water ocean beneath its hydrogen-rich atmosphere.",
      "These findings suggest that K2-18 b could potentially host life, aligning with the current theories proposing the planet as a Hycean exoplanet, a type considered favorable for extraterrestrial life.",
      "In addition to methane and carbon dioxide, the telescope's observations hint at dimethyl sulfide, a molecule generally produced by life, further asserting the potential for life on K2-18 b."
    ],
    "commentSummary": [
      "NASA's James Webb Space Telescope detected methane and carbon dioxide in the atmosphere of exoplanet K2-18b, indicating potential signs of life.",
      "The distance to the exoplanet makes communication challenging, taking an estimated 124 years, highlighting the difficulties of interstellar travel and current propulsion system limitations.",
      "The detection of dimethyl sulfide is mentioned as an additional potential sign of life on exoplanets, although some experts maintain a skeptical viewpoint."
    ],
    "points": 222,
    "commentCount": 120,
    "retryCount": 0,
    "time": 1694444642
  },
  {
    "id": 37467077,
    "title": "9/11 in Realtime",
    "originLink": "https://911realtime.org:443/",
    "originBody": "File Edit Help 9:13:30PM ET TV Tuner News Audio Controls Timeline Settings Controls « ‹ Play Pause › » H: M: S: AM PM GO News Ticker ALL NEWS ITEMS FROM HISTORYCOMMONS.ORG 2:13:0AM - Flight 11 Makes Its Last Communication with Air Traffic Control The last routine communication takes place between air traffic control and the pilots of Flight 11 at 8:13 and 29 seconds. Boston Center air traffic controller Pete Zalewski is handling the flight, and instructs it to turn 20 degrees to the right. Pilot John Ogonowski immediately acknowledges the instruction, but seconds later he fails to respond to a command to climb to 35,000 feet. Zalewski repeatedly tries to reach the pilot over the next ten minutes, even using the emergency frequency, but gets no response . Audio Player WINS-1010 WINS NEWS 13:30 1:00:56 Unmute TV Tuner Channel Guide - Click a TV channel below to enlarge CNN WTTG WJLA NEWSW AA11 WORLDNET GLVSN BBC WRC WUSA Timeline of Events 7:45:00 AM American Airlines Flight 11 is pushed back from Gate B32 at Logan International Airport. 8:13:52 AM Air Traffic Control tries to contact Flight 11 twice with routine instructions, but receives no reply. 8:46:40 AM American Airlines Flight 11 crashes into the north face of the 1 World Trade Center (North Tower). 8:49:34 AM CNN first broadcasts pictures from near the World Trade Center, the first images most Americans see of the disaster. 9:02:57 AM United Airlines Flight 175 crashes into the south face of the Tower World Trade Center (South Tower). 9:31:00 AM President Bush, in Florida: an “apparent terrorist attack on our country.” 9:37:46 AM American Airlines Flight 77 crashes into the western side of The Pentagon and starts a violent fire. 9:59:00 AM 2 World Trade Center (South Tower) collapses, 56 minutes after the impact of Flight 175. 10:03:11 AM Flight 93 crashes 80 miles (129 km) southeast of Pittsburgh, Pennsylvania. 10:07:00 AM Flight 93 crashs the in a Somerset County, PA, field 10:28:22 AM 1 World Trade Center (North Tower) collapses, 1 hour and 42 minutes after the impact of Flight 11. 10:50:19 AM Five stories of part of the Pentagon collapse due to the fire. 12:39:00 PM Senator John McCain calsl the attack an \"act of war\" on CNN 1:04:00 PM President Bush heightns miltary, airs pre-recorded address 2:30:00 PM New York Mayor Rudy Giuliani holds a press conference 5:20:33 PM The 47-story 7 World Trade Center collapses 7:24:00 PM Members of Congress join on the capitol steps to sing \"God Bless America\" 8:30:50 PM President Bush addresses the nation from the Oval Office 9/11 in Realtime About 9/11 in Realtime The time is currently 9:13:30PM ET 9/11 in Realtime is a multimedia experiment for teachers, with the purpose of helping their students truly understand and absorb the events of September 11, 2001. We've collected media--video, audio and other items--available from the days before and after the September 11 attacks, synchronized them together and built a tool to help students be immersed in the events of the day. THE FOLLOWING WEBSITE MAY CONTAIN VISUALS, AUDIO AND OTHER CONTENT THAT SOME VIEWERS MAY FIND EXTREMELY DISTURBING. THIS TOOL IS INTENDED TO BE USED ALONGSIDE A CAREFULLY RESEARCHED AND APPROPRIATE CURRICULUM. For questions regarding this project, please email Robbie Byrd. POWER ON",
    "commentLink": "https://news.ycombinator.com/item?id=37467077",
    "commentBody": "9&#x2F;11 in RealtimeHacker Newspastlogin9&#x2F;11 in Realtime (911realtime.org) 216 points by smohnot 20 hours ago| hidepastfavorite145 comments ilc 19 hours agoI was working in the airline industry when this happened.My girlfriend (now wife) and I had just started on the way into work, we signaled each other over to the side of the road, and talked for a few moments... and I headed in to work.I was in shock for weeks. I was ontop of the towers but 2 months before that, and possibly one of the best pictures of the two of us was taken there.... I&#x27;ve been there. I know that place. I have roots in that city.But I wasn&#x27;t surprised as many Americans were. I knew this was very possible, though most of the scenarios I&#x27;d heard were far more grizzly than what happened. (Involving nuclear material and small planes.)I always thought the Iraq war was a pile of shit, as were most of the actions taken quickly after that day.Taking off our shoes, and the TSA are an awful legacy of an awful day. The terrorists did win. They encouraged us to give away our freedoms for safety theater.So we did.This site is proof... they won. reply elromulous 18 hours agoparentThey encouraged us to give away our freedoms for the illusion of safety. reply ilc 18 hours agorootparentUpdated my comment to reflect that. I agree with you. reply blackfawn 9 hours agoparentprevTechnically we have Richard Reid, the \"shoe bomber\" to thank for having to remove footwear, from an attempt which happened later the same year: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;American_Airlines_Flight_63_(2...But your point is still valid! reply bloomingeek 20 hours agoprevI&#x27;m retired from American Airlines, September 9th,2001 we were vacationing with our children in Florida. I tried to talk my wife into staying an extra day and fly home on the 11th. Thankfully she talked me into going home on the 10th as planned.We got home late from the airport and everybody slept in on the 11th except me. I was messing around in the garage when my wife hollers at me to come look at the tv. At first we couldn&#x27;t figure out if it was real, then it sunk in. I called a co-worker who was on shift, he said everyone was in shock.I started feeding tapes into my VCR, about eight of them. I&#x27;ve never watched them. reply antomeie 19 hours agoparentThank you for sharing your story! It is always interesting to hear different perspectives from these events.Regarding your VCR tapes. I understand it may be difficult for you to watch, but I encourage you to get them digitalized soon, while you still can. Perhaps even upload them in full length online somewhere for other people to look at. reply jcranmer 19 hours agorootparentIf what is recorded is a news channel, the Web Archive already has the major news channel&#x27;s coverage of 9&#x2F;11 available for free: https:&#x2F;&#x2F;archive.org&#x2F;details&#x2F;911&#x2F;day&#x2F;20010911 reply antomeie 19 hours agorootparentThank you for this! Really interesting. I&#x27;m having a look at it now.Although my initial thought was that it would be great if there was a way to watch the entire day (for one news station) in one clip, rather than have to click on multiple 30 seconds videos. reply Someone 18 hours agorootparentThat’s what this site is, isn’t it? replybtown 19 hours agoprevHere is a compilation of recordings of the moment the second tower was hit - by which time both news cameras and amateur cameras were focused on the towers.https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=7YLm3pkAiJQSo much of the world as we know it now can be traced back to this day, and perhaps this moment above any others - the moment we gained an innate knowledge that something sinister was going on, a deep feeling of fear, anger, and vulnerability awakening in the American populace with an immediacy that had perhaps never been felt in the country&#x27;s history.I vividly recall being a middle school student, seeing friends being pulled out of the classroom one by one, knowing that something horrifying was happening, not knowing details, not knowing whether I would be next, eventually understanding with dawning horror that some of my classmates had family members who would never come home. An entire generation felt this pain.It&#x27;s really important that projects and video archives like the OP exist so people understand not just the statistics, but the fundamental shift of people&#x27;s worldviews that happened that day. reply workfromspace 14 hours agoparentThere&#x27;s a newer version from the same channel with 50 different views: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=7hApRZ_7v2ASo shocking and heartbreaking... reply swozey 20 hours agoprevThis stuff is so difficult for me to watch again, I was a senior in HS.Reading IRC logs from back then is also really interesting. And Nanog had a really interesting slideshow&#x2F;powerpoint deep dive on the infrastructure outages that occurred. And of course the SomethingAwful thread that&#x27;s been posted before. https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=7990991RE: this specific site.. interesting UX&#x2F;UI choice. I was hoping I could click the times in Timeline of Events and be sent straight there but it seems like I have to put times specifically in the Controls section. Anyway, this is neat. reply Rebelgecko 17 hours agoparentI always thought the leaked pages from 9&#x2F;11 were an interesting way of viewing the timeline. Starts with a lot of business messages, some sexting, and some automated IT messages.[1]The at 8:46 you see the first sign of something wrong, a smattering of errors about how the Cantor Fitzgerald API was down, and the butterfly effect the outage had on other systems. The computers were chatting about how something was wrong ahead of any people.[1] https:&#x2F;&#x2F;911.wikileaks.org&#x2F;files&#x2F;messages_2001_09_11-08_45_20... reply IKantRead 18 hours agoparentprevI was a sophomore in college, it was strange because people didn&#x27;t have smart phones and many people didn&#x27;t have cell phones. I remember class starting and a student said, very calmly after receiving a text message about, \"oh, that&#x27;s weird it says an airplane in the world trade center\". We all assumed it was just a small private Cessna plane that must of accidentally bumped into the one of the towers, and then class began as usual.My roommates and I spend the next week completely glued to the television. Which is why this interface is particularly great for capturing that feeling, but it is tough to rewatch. reply jack_codes 19 hours agoparentprevI was in the Army on a training exercise in Louisiana preparing to go to Kosovo. We were in a flight unit (helicopters) and loading up a convoy to the airfield. We got the call over the radio about it and thought, at first, that is was part of the training exercise. We get to the airfield, setup comms, and get chatter about it not being an exercise. Since they grounded the birds pretty much all week we basically stayed glued to the tv in the hangar for the duration.It was an odd time since we were technically in peace time and suddenly thrown into this situation. A year later (Mar. &#x27;03) we were watching jets fly over Iraq on tv while we preparing for a funeral detail for one of our Blackhawk pilots.Still hard to believe it&#x27;s now so long ago. reply swozey 19 hours agorootparentI was 6months from MEPS. My Major dad told me to GTFO. I&#x27;d planned on going Army my entire life. That threw a real wrench in my plans. Thankfully I was able to get out of it since I hadn&#x27;t signed at MEPs yet.I lived in Norfolk VA and IIRC we had 3-5 carriers moored. They all dispersed away from the shipyard when it happened. 20-25k Navy just vanished from town. reply glawre 20 hours agoparentprevDo you have a source for the Nanog powerpoint? That sounds really interesting. reply swozey 19 hours agorootparentI&#x27;ve dug this up 2-3 times since 2001 and I always have a nightmare of a time finding it. I&#x27;m not finding it anywhere right now. I&#x27;m pretty sure it was a Nanog report but I could be wrong there, it was very thorough and a lot of slides.Best I can do right now is the Nanog mail list that day&#x2F;week... https:&#x2F;&#x2F;archive.nanog.org&#x2F;mailinglist&#x2F;mailarchives&#x2F;old_archi... reply keepamovin 19 hours agoparentprevI relate: was also a senior. I had an English final that morning, I think. Earth shifted. It was an overwhelming experience seeing it happen on TV. reply sanderjd 19 hours agorootparentI was a junior. I went to a boarding school and one of those weird memories that sticks with you is that I was unsure whether or not to go to my classes. No cell phones and pretty primitive email system, so it just wasn&#x27;t clear. I went to one at like 9:30 (central time) and nobody was there, so that was when I realized \"oh this is one of those nothing-is-normal-now things\". reply dehrmann 18 hours agorootparentprevI was a senior. I grew up on the west coast, never been to New York, but my English teacher was from New York. She knew she&#x27;d lost friends that day, but not which ones. She held it together, but it really added a personal connection to what would have just been a horrifically impactful event on TV. reply caseysoftware 19 hours agoprevI didn&#x27;t find out this story until years later but still amazes me every time I see it.. regular people stepping up and saying \"I have to help\"Tom Hanks narrates the epic story of the 9&#x2F;11 boatlift that evacuated half a million people from the stricken piers and seawalls of Lower Manhattan.https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=18lsxFcDrjo reply settrans 19 hours agoprev@rsync&#x27;s story from 9&#x2F;11 is an excellent illustration of the event and absolutely worth the read: https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20041208005336&#x2F;http:&#x2F;&#x2F;www.cultde... reply Aeolun 16 hours agoparentThat was indeed a really good read. reply zug_zug 18 hours agoprevThere&#x27;s something so emotional and compelling about the spectacle of shared tragedy (even smaller ones like oceangate).However there&#x27;s always a reminder in the back of my mind that what makes our heart leap is very poorly correlated with what things ought to scare us.I don&#x27;t know if it&#x27;s possible to \"Reprogram\" one&#x27;s heart to worry less about very high-visibility low risk things (like air travel, or terrorism in the US) and care more about statistically probable ones that SHOULD scare us (heart disease and such), but I wish it were.https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=DwKPFT-RioU does a great job of giving a sense of what the proportions are of relative tragedies in terms of loss of life. reply konschubert 15 hours agoparentTraffic deaths reply tekla 19 hours agoprevI was a kid living in the Bronx that day.I remember parents picking their kids up for no explained reason, the fucking TV cart showing the news, and going outside and seeing the smoke plume and the air smelling like burnt shit.Several kids in my class had parents who died on 9&#x2F;11 reply wizerdrobe 18 hours agoparentThe TV cart…That’s probably the memory for many (most?) grade schoolers, isn’t it?Was in a gifted and talented class that morning, we had the budget for a dedicated TV in the corner that stayed on all day with a global map showing the time and the position of sunlight moving over the globe. The administrators had a master controller that switched all the TVs in all the classrooms over to the news at the same time. Have little memory of the actual news but do remember having an old, stern southern lady (the kind that would paddle you if she still could) suddenly crying quietly as we watched the news that day.That and our similarly elderly main teacher setting time aside the day before the invasion of Iraq to talk about the seriousness of going to war and what it meant for families. How she remembers her town before Korea and Vietnam.With hindsight I wonder why Afghanistan just didn’t get talked about in the same seriousness as the invasion of Iraq. Afghanistan just kind of quietly happened, but the build up to Iraq just held more weight. reply mrguyorama 15 hours agorootparent>With hindsight I wonder why Afghanistan just didn’t get talked about in the same seriousness as the invasion of Iraq.If you weren&#x27;t for war you were violently shouted down as unamerican and undemocratic and unpatriotic. It&#x27;s a simple as that. This applied to US senators just as much as it applied to average americans. \"Our country is under attack and we are at war\" was the hammer used to suppress any argument, especially the one talking about how Bush clearly wanted a war even before the attack. reply epiccoleman 18 hours agoprevI was in 4th grade when this happened. A relatively normal morning quickly turned into a bunch of kids sitting in class watching the news.My memories of the day itself are hazy. I was too young to really understand, of course.It&#x27;s pretty harrowing to watch the footage up to the second impact. The sudden change in tone from somewhat detached coverage of something we were yet to understand is really something. The shock of the newscasters when that second plane hit. Crazy how easy it was to see that second impact with all the cameras turned on the building.I didn&#x27;t expect my heart to pound the way it is from watching this. Chilling stuff. reply tfandango 19 hours agoprevI was laid off at the time so I watched this happen live on TV. Later I delivered meals-on-wheels while listening on the radio and discussing with all the folks I was taking meals to that day. So surreal. I remember thinking it was a terrible accident until the other tower was hit, then total disbelief that they fell.Then a month later I went to work in a quarter-scale (I think) replica of one of the twin towers (BOK Tower, Tulsa, OK) and one of our clients was almost completely wiped out on 9&#x2F;11. The few remaining employees were trying to rebuild the company and we were trying to help them by hosting the little thing we had sold them. All of their backups were also in the tower. Really sad. reply dave84 20 hours agoprevI&#x27;m a bit lost, changing the timeline doesn&#x27;t seem to correspond to the events or coverage of them. Anyone know what I&#x27;m doing wrong? reply keepamovin 20 hours agoparentI think you need to \"start it off\" by pushing \"Go\" on the Controls window after you set a time. That seemed to then line everything up. Note that the Menu Bar time widget does not reflect the Timeline time tho! reply dave84 20 hours agorootparentOK, the menu bar was throwing me off... makes no sense. Thanks. reply tobr 19 hours agorootparentI think some of the time stamps, but not all, are adapted to the local time zone. Very confusing user interface overall, it’s trying something very ambitious but not succeeding on the execution. reply rconti 18 hours agorootparentprevyeah, I have no idea what&#x27;s going on with the time. There is a 2 hour delta between the time in the box where I hit \"go\" and the \"current time\" on the menu bar. I&#x27;m on the west coast so it would make sense if it was a 3 hour difference, or a 0 hour difference, but 2 makes no sense to me.Unless it was a DST change? But the 2007 change only happened for the start in March. reply alkonaut 20 hours agoparentprevDon&#x27;t get it either. But setting a time and hitting \"go\" seems to adjust the streams to the right time. But it doesn&#x27;t \"tick\" when playing for some reason. reply yreg 19 hours agoparentprevI don&#x27;t understand why there&#x27;s static noise instead of broadcast all the time. Is it a buffering animation and does the server have troubles keeping up? reply shmatt 19 hours agorootparentI think its a mix of buffering + skipping to real time. It&#x27;s not a classic buffer because the clock has to keep ticking reply HumblyTossed 17 hours agoprevThe US was so complacent in their idea that nobody would ever attack them that even commentators live on air speculated that some sort of navigation error might have caused it. Even after the second plane hit. reply afavour 17 hours agoparent> The US was so complacent in their idea that nobody would ever attack themI don&#x27;t think that&#x27;s true. There was an attempt to bring down the WTC in 1993 after all!Authorities were taken by surprise by the method of attack. Hardly surprising since it hadn&#x27;t been done before. Up until that point a hijacked flight almost always meant a ransom attempt, so you didn&#x27;t shoot the plane down, you got them to land and began negotiations.It&#x27;s really easy to look back in hindsight and say authorities should have done X but there really was a great deal of uncertainty. It&#x27;s not even clear what could have been done about the second plane. reply HumblyTossed 17 hours agorootparentNone of that is even what I&#x27;m talking about. The people watching it, in real time, commenting on it, didn&#x27;t even speculate that it could be an attack. Even after the second plane. That&#x27;s complacency. reply snypher 15 hours agorootparenthttps:&#x2F;&#x2F;youtu.be&#x2F;2ZwwCNoPa1wPossible terrorist attack was mentioned by on air reporting before the second plane hit. reply jihadjihad 15 hours agorootparentprevIt&#x27;s not complacency, it&#x27;s professionalism, and there are several counterexamples to your claim on the linked page. reply mhh__ 20 hours agoprevhttps:&#x2F;&#x2F;youtu.be&#x2F;9tKbZJ-NENo?si=RUe1-2n6Fw2sVOw0D-day Radio broadcasts in real time. reply keepamovin 20 hours agoprevThat&#x27;s incredible! What an amazing project.The classic Macintosh desktop is also very well done. Does anyone know the source code for the desktop used?I found the projects in the \"About\" open source notices section of the desktop. It uses:- https:&#x2F;&#x2F;github.com&#x2F;robbiebyrd&#x2F;platinum which itself is based on:- https:&#x2F;&#x2F;github.com&#x2F;npjg&#x2F;classic.css- https:&#x2F;&#x2F;github.com&#x2F;ticky&#x2F;classic-scrollbars for the scroll-bars reply mdaniel 18 hours agoparent> The classic Macintosh desktop is also very well doneTwo things, in my opinion: trying to be whimsical and \"fun\" for such a grave topic is disrespectful, and I don&#x27;t understand what value appropriating Apple&#x27;s logo and the \"finder face\" in the corner add to the 9&#x2F;11 retrospective experienceSo, fine, maybe I&#x27;m just not happy-go-lucky enough to appreciate why this needs to be a classic Macintosh theme, but I am 100% positive that this experience doesn&#x27;t need those branding elements to reenact 9&#x2F;11 anythings reply keepamovin 5 hours agorootparentSo you’re judging other people’s reactions to the event? I don’t think we should do that. It doesn’t make you right. People are going to have diverse ways of responding and processing it. We should be tolerant and accepting of that.What we should not be tolerant of is people who judge other people first, and try and make them wrong. I think you can express your own feelings on this, without imposing on others like that.It’s important to have clarity about how you feel, including what you feel about other people’s reactions, and accept it. When you observe yourself reacting to someone else’s response, rather than making it about them being wrong and judging them, focus on how you feel, and ask yourself why you feel that way. reply barrysteve 1 hour agorootparentHe&#x27;s judging the experience of a website.What&#x27;s it got to do with other people&#x27;s reactions?He&#x27;s expressing an interpretation, not a feeling. reply gnicholas 18 hours agorootparentprevIMO this doesn’t seem disrespectful, more like an attempt at authenticity. For those who used computers at that time, it will remind them of what it was like, and for younger people, it helps communicate the era (before you were born, but post-GUI) that 9&#x2F;11 happened in. reply nobody9999 17 hours agorootparent>IMO this doesn’t seem disrespectful, more like an attempt at authenticity. For those who used computers at that time, it will remind them of what it was like, and for younger people, it helps communicate the era (before you were born, but post-GUI) that 9&#x2F;11 happened in.I mostly agree with you. However, I visited Las Vegas and stayed at the New York, New York casino hotel a few months after the towers came down and noted the \"memorials\" people put up on the outside of the casino. Which, as a native NYer who worked across the street from the WTC (and walked through it pretty much every work day for many years beyond that) for more than three years, really pissed me off even though I realized that people wanted to show their support -- I found it a disgusting display.I still live in NYC and to this day I avoid the area around ground zero whenever I can. Not because I&#x27;m afraid, but because it&#x27;s still painful to think about all those dead people in a place that was so familiar to me.As such, I understand GP&#x27;s feelings. The events of that day shouldn&#x27;t be made light of given all the innocent people (and not just in NYC, but in Washington, DC and Shanksville, PA as well) who died needlessly. And each of us processes&#x2F;deals with that differently. reply Hammershaft 18 hours agorootparentprevIt&#x27;s useful to situate younger people in a historical context. reply gnicholas 18 hours agoparentprevMy first reaction was “wasn’t OS X out when 9&#x2F;11 happened?”. But I understand that many people were running OS 9.x at the time, since it was only 6 months after the OS X launch date. reply suckitsam 19 hours agoprevThere was a video I saw once several years ago that claimed to sync up ATC audio and flight radar of commercial and military traffic, but I haven&#x27;t been able to find it since despite a couple cursory searches here and there.IIRC, it was a custom animation&#x2F;overlay like they use in documentaries and newscasts, not a screenshot of FlightAware or anything.Any chance anyone knows what I&#x27;m talking about and has a link? reply jihadjihad 18 hours agoparentI&#x27;d be interested in seeing that as well. The only thing I can think of that is similar is the interactive Apollo 11 in Real Time: https:&#x2F;&#x2F;apolloinrealtime.org&#x2F;11&#x2F; reply Olphs 19 hours agoprevHmm the times are somehow all messed up, current time shows 4:xx PM, the timeline shows things happening from 2:xx AM, and the controls show 8:xx AM reply bayesianbot 19 hours agoprevI just love these real time real life retrospectives, yesterday I thought I&#x27;m not going to spend time watching these again but here I am.. Any other good ones around? I&#x27;ve watched the Estonia[0] a few times (easier as a Finn), I think I&#x27;ve seen one about the 2004 Tsunami one but can&#x27;t seem to find it (or might remember wrong), and Apollo 13[1] as well.edit: On second thought I don&#x27;t think the tsunami one might make that much sense, probably was just a collection of videos and news captures.[0] https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=V5tbah19qo8 [1] https:&#x2F;&#x2F;apolloinrealtime.org&#x2F;13&#x2F; reply mariojv 17 hours agoprevIt&#x27;s a little shocking how different the pre-9&#x2F;11 mindset was. At 9:07am on CNN, the reporter speculates that perhaps there was an issue with electronic navigation equipment that would have led two planes to hit the towers. reply ramoz 20 hours agoprevPretty cool. FYI The upper right clock seems off by 1 hour (using the time control seems to work or I don&#x27;t understand how time works) reply flir 16 hours agoprevThere was a piece of footage shown on British TV. Street scene, camera tilted slightly upwards, and something flashes across the screen from top-left to bottom-right. Fast, just a few frames. Never saw it again (admittedly I didn&#x27;t look very hard).Don&#x27;t suppose anyone knows what I&#x27;m talking about, do they? Would be nice to know it&#x27;s not a false memory. reply 542458 19 hours agoprevWow, this is wildly stressful to watch, even all these years later. reply ChrisArchitect 19 hours agoparentDamn, yeah, I gave it a shot and it&#x27;s rough.I just happened to be home a bit later than usual and was watching the morning news just like this that day, so this is pretty much how I experienced the towers being hit live. Eerie. reply linsomniac 19 hours agoprevI had a fairly weird 9&#x2F;11 realtime experience. I had pulled an all-nighter and ended up going to sleep right around the time this all started happening. So I went to sleep blissfully unaware, and then was woken up by my wife. Within 30 seconds of being woken up I learned: \"4 planes were hijacked. They were flown into the World Trade Center. The WTC collapsed.\"I kept waiting for the punchline, but then realized it wasn&#x27;t coming... reply ShakataGaNai 18 hours agoparentSomething similar from my side. Was in college, on the West Coast, and had no early classes so I was still asleep. It wasn&#x27;t until the girlfriend&#x27;s family called her and woke her up - that we found out something was wrong. They were on the East Coast and her father was flying that day (just ended up grounded and stuck for a few days). But I don&#x27;t think we woke up until 8 or 9am PST, Noon East... so by the time we were awake it was \"over\". Totally surreal to wake up to something like that.I don&#x27;t think anyone at the entire College did anything but watch the News channels, even though there wasn&#x27;t anything \"new\", for the next 2 days. reply sophacles 18 hours agorootparentOne of my college housemates barged into my room and woke me up with \"dude you need to turn on your tv\". \"What channel?\" \"It doesn&#x27;t matter...\".TV warms up in time to see a replay of the second plane hitting.I was groggy and said \"woah good effects... what movie is this?\".The guy (who was rarely serious) looked me in the eye and said \"this is real\".The world changed that day, in ways we&#x27;re still figuring out. reply qingcharles 10 hours agoprevDoes anyone else remember how the Internet died that day?There was so much traffic from everyone trying to check the news that every major news site went practically offline.The only way to find out what was happening was to find a TV. Lucky I was working with a friend to install a touch-screen PC in his car. We&#x27;d added a TV tuner to the system too. We raced to the underground car park and pulled the car out onto the street and sat there watching the news unfold on his 7\" widescreen. reply afavour 17 hours agoprevFor anyone in or near NYC, I can recommend a trip to the 9&#x2F;11 museum. I expected it to be some flag wavey exercise in \"patriotism\" but there&#x27;s a section inside where the events of the day progress as you walk through. Even as someone who knows all about the events it was absolutely chilling to walk through. reply anshumankmr 15 hours agoprevI was four when this happened, and what I remember is being in my grandparents house watching it unfold on the news while being on the other side of the world, not sure if it is a real memory or a figment of my imagination, but my parents did tell me the attack did profoundly disturb me.It truly does feel weird that people a few years younger than me didn&#x27;t watch it happen live and even I was one of those people who was too young to truly comprehend what the hell was going on, except for developing a massive feeling of anger against the perpetrators. reply jihadjihad 19 hours agoprevI haven&#x27;t seen this site before, this is very well done. I was in middle school at the time at a camp away from school, so I never saw the broadcast until later in the afternoon. Extremely stressful to watch the time period between the coverage of the damage from the first plane and the second plane hitting the South Tower. It really captures that nearly extinct feeling of switching between channels frantically to keep up with the coverage. reply gigatexal 19 hours agoprevI was there. Not in NYC but as I was eating my Honey Nut Cheerios before early morning (530-6ish am pacific time) JV basketball and watching the news (cuz I was a nerd in high school) I watched it all go down in real-time. It’s still a harrowing experience to this day. reply postalex 18 hours agoprevvery cool site, thank you. I didn&#x27;t have TV that day, all I knew was from cnn and nytimes and fevered word-of-mouth, but years later I had a chance to dive into the various digital archives (including https:&#x2F;&#x2F;archive.org&#x2F;details&#x2F;911)—and what a remarkable time capsule they are. one result of that was this, a channel-browsing glimpse of America just before it happenedhttps:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=IMVTB2aVUg0 reply yabbs 11 hours agoprevWhat about the part where afghan, I mean Iraqi, I mean Saudi passports come fluttering down.22 year old long con. reply ChrisArchitect 19 hours agoprevSome previous discussion from 2021: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=28492719 reply davidw 19 hours agoprevUgh, once was enough for me. Remembering it is important, reliving it is too much.This quote from Lincoln is pretty pertinent to some things that have happened since:> At what point then is the approach of danger to be expected? I answer, if it ever reach us, it must spring up amongst us. It cannot come from abroad. If destruction be our lot, we must ourselves be its author and finisher. As a nation of freemen, we must live through all time, or die by suicide.Commonly reported as \"America will never be destroyed from the outside. If we falter and lose our freedoms, it will be because we destroyed ourselves\" reply hattmall 20 hours agoprevThe best I&#x27;ve heard is the Howard Stern broadcast. reply self_awareness 19 hours agoprevI appreciate the overall Mac look and feel, but I don&#x27;t understand what&#x27;s going on in this UI.I&#x27;m clicking some video, but it won&#x27;t start, something else starts playing, Picture in Picture starts up, I need to close it, clicking Play won&#x27;t play the video, instead it starts automatically 10 seconds later, then it stops, snowy screen pops up, etc. reply 37469920away 11 hours agoprevSo cool. An episode of I Dream of Jeannie is on WTTG at 11 AM. reply bowsamic 19 hours agoprevDoesn&#x27;t seem to work for me in any browser reply lacoolj 18 hours agoprevthis is a very educational and well-made retelling with compiled live events. I&#x27;m glad someone has done this reply Balgair 14 hours agoprevAdding my memories:My little brother woke me up that morning. Said that the Twin Towers were falling down. It was just the start of my sophomore year in high school in the SF Bay area. My first real indication that everything was going bad was that the T.V was on. Mom never allowed it on in the mornings before school.I managed to get out of bed and get downstairs in my underwear and was just able to see the second plane hit. Mom&#x27;s face went grey. Dad was in the kitchen. Mom said the magic word that told everyone in the family that things were officially bad:\"Oh ... fuck\"Mom never cursed. I remember looking at my siblings, we were more in shock that Mom even knew curse words. Then we all got pulled into the kitchen too.It didn&#x27;t help that Grandpa was dying in Tuscon. Lots of strokes from years of smoking. Mom and my aunt were planning on going that day to Arizona, but, very obviously, we knew that wasn&#x27;t going to be by plane now. There were a lot of calls back and forth on the landline in trying to figure out how they were going to get down there.The T.V. was reporting all kinds of crazy stuff too. The pentagon, something in Pennsylvania. We just watched and tried to eat breakfast.Mom and Dad, bless them, had no idea what to do either. So they managed to get all the cash and valuables in the house and split it up five ways, a portion for each of us. It was a lot of money and jewellery. I remember getting a solid silver elephant, about three inches across, that Dad had gotten for Mom some year. I never did bring myself to actually counting it. Dad shoved all the cash into our backpacks. We figured that going to school wouldn&#x27;t be a bad idea. My High school and my sibling&#x27;s schools were all around the same place, right next to the police station.Dad brought me into the garage, gave me his 1911 and a spare loaded magazine. It was so heavy and cold. He showed me how to turn the safety off. How to press the magazine release. How to slide it back to cock it and pull the bullet out. I remember thinking that those bullets were really big. Told me:\"You&#x27;re a man now. Whatever happens, you are responsible for your siblings. Don&#x27;t use this unless you have no other choice.\"We put it in the bottom of my backpack with all the cash. I remember thinking that I was a real gangster now.We all agreed that we&#x27;d meet up in Tuscon at my Uncle&#x27;s place in exactly one year if everything went to hell. I had no idea what the address was, but I said I&#x27;d get my siblings there no matter what. We said goodbye to Mom. She went and pick up my aunt and and they drove to Tuscon. Managed to see Grandpa just before he died that day. They must have driven crazy fast to have made it in time.School was a blur. Mostly just watching the TVs on carts or up in the corner of the room. Some teachers tried teaching, that was pointless, we all knew it. But we had no better ideas either.Dad picked us up from school that day. Another strange event, it was always Mom that picked us up. He said we were going to have apple pie and hot dogs for dinner, because that was more American. We only had hot dogs because Dad can&#x27;t bake. I don&#x27;t remember giving Dad back the pistol, but must have.Went to scouts that night with the whole family. A lot of people brought the whole family to scouts that night. I remember one of the kid&#x27;s Dads talking about his friends in NYC. He started to well up, but fought it back. We all knew it was because he thought that us kiddos couldn&#x27;t be seeing him cry too, needed to stay tough in the chaos. It was alright though, we all understood. Later on, one of his sons, a few years younger than me, joined the Marines. He died in Iraq. They said his head exploded like a Gallagher watermelon when the sniper&#x27;s bullet hit. Another kid in the troop, about the same age, &#x27;cleaned his gun wrong&#x27; on Paris Island because he couldn&#x27;t handle the Marines. Lost a few people in my graduating class too. My best friend&#x27;s cousin died in Afghanistan. The family have always blamed Bush for that.I remember Grandpa&#x27;s funeral. He was a colonel or somesuch in the Air Force. So we got to have the funeral on the Air Base there in Arizona really soon afterwards. I remember all the guns pointed at our heads as we drove on to the base. Having to weave through all the barricades. He manged to get a spot in Arlington, one of my uncles pulled some strings and got Grandpa a place. I didn&#x27;t go to the internment, but there was a 14 gun salute, my Mom said. A real honor, I&#x27;m told.One of my older cousins on my Mom&#x27;s side decided to up and drive to Ground Zero to help out. He was helping dig through the debris for a while. He never talked about going out there and helping though.My Uncle, the one that pulled the strings for Grandpa&#x27;s internment, was near the Pentagon that day, had to walk through the smoke to get back home. He said it was really bad smelling because they used horse hair for insulation in the Pentagon.I always put up the flag on 9&#x2F;11, for Grandpa and for everyone else and for all my friends that died because of what it kicked off. It&#x27;s not much, but it&#x27;s something.I don&#x27;t know how to end this. I just wanted to share some of what happened to me that day and in the time afterwards. Thanks for reading. reply somsak2 12 hours agoprevtimestamps at right need to be clickable. reply civilitty 19 hours agoprevI was in elementary school on the West Coast at the time so by the time I was getting ready for school, one of the towers had already collapsed and I woke up to apocalyptic scenes on television that I first thought was a massive earthquake. In class, no one said a single thing about what had just happened which made me feel like I was going crazy.It still makes me feel sick to this day what happened afterwards. I was too young to really understand the implications but even as a child, the march to war felt so very wrong. reply sanderjd 18 hours agoparentI wouldn&#x27;t say \"even as a child\", I would say \"especially as a child\". In my experience, this was a far more common experience among those of us who were not yet adults at the time, than among the adults. I have long felt that it is the greatest generational dividing line in the US. I was about half way through high school at the time, and the prevailing perspective of the march to war seems to be very different among even those just a few years older and in college at the time, than among myself and people near my same age and younger.I do think I understand it better now that I have my own children. I can imagine my fear for them driving me to supporting things that struck me as mindless vengeful insanity at the time.I hope I&#x27;ll never have to find out how I would react now to a tragedy like this. reply marssaxman 18 hours agorootparentI was 25 then, but it seemed like mindless vengeful insanity all the same. The entire national character seemed to change, almost overnight, in a bleak and awful way; I felt like I was standing in the surf while a powerful wave receded, water and sand and gravel all rushing away around me, while I remained in place. I have felt like a foreigner here ever since, still a citizen but no longer an American. reply sanderjd 18 hours agorootparentYeah. But would you say that your view was the prevailing one among people your age? Or, as I think you&#x27;re implying, that you were more the odd one out, including amongst your peers?Because unless I&#x27;m assuming wrong, I think your experience is in line with what I said.My experience was different than yours though. It wasn&#x27;t until I started mixing with more \"grown ups\" during college that I realized that actually the prevailing view among people even just a little older than me seemed to be in favor of the war, whereas the view I was familiar with from my own crowd of people my age was the opposite. And as I have talked to more and more people over time, I have continued to feel that this is basically correct about the prevailing view by age at that time. reply marssaxman 17 hours agorootparentSure, I&#x27;m not trying to disagree, but to share the sympathetic experience I had on the other side of that generational divide.My view certainly was not the prevailing one, as polls showed and Bush&#x27;s re-election proved; but my peers at the time were a bunch of musicians, artists, activists, nerds, and weirdos, living in a big coastal city, so I was not alone in opposing the wars. Part of the horror of that experience was the dawning realization that we lived in a tiny, fragile bubble, and nothing we could do had any influence whatever on the mess being made outside it. reply sanderjd 4 hours agorootparentYep! I did think this is what you meant, but wasn&#x27;t entirely sure, and was interested in your perspective. replyMobil1 19 hours agoprevOnce upon a time on September 11, 2001, a dedicated journalist named NJ Burkett found himself at the heart of one of the most tragic events in modern history—the terrorist attacks on the World Trade Center in New York City.NJ Burkett, a seasoned reporter for ABC7 New York, was known for his expertise and compassion in delivering news to the public. On that fateful morning, he, along with his talented photographer, Marty Glembotzky, were assigned to cover the breaking news near the Twin Towers.As they rushed towards the scene, little did they know that they would soon find themselves in the midst of chaos and devastation. With cameras rolling and a sense of urgency in their hearts, NJ and Marty began reporting from just below the burning towers.The initial shock of the situation radiated through NJ as he absorbed the enormity of the unfolding events. However, his professionalism kicked in, and he focused on relaying accurate information to his viewers, fully aware of the immense responsibility he held.But as fate would have it, just as NJ was delivering his report, the unthinkable happened—the first tower began to collapse. The once towering icon was now crumbling down before their eyes, spewing debris and smoke into the sky.In an instant, the scene turned into a frenzy of panic and confusion. NJ and Marty, with their journalistic instincts, quickly grasped the severity of the situation. With bravery and determination, they managed to make split-second decisions that would save their lives.In the midst of the chaos, they navigated through the smoke-filled streets, struggling to breathe, their hearts pounding with adrenaline. Embracing their training and experience, NJ and Marty found a way to safety, escaping the collapsing tower just in the nick of time.Although physically unharmed, the emotional toll was immeasurable. NJ Burkett and Marty Glembotzky had witnessed firsthand the sheer devastation of the attacks and the tragedy that befell countless innocent lives.In the years that followed, NJ Burkett continued to report on the aftermath of 9&#x2F;11, covering the stories of resilience, healing, and unity that emerged from the rubble. His dedication to journalism and the compassion he showed towards the survivors and victims&#x27; families exemplified the spirit of hope in the face of unimaginable tragedy.The events of 9&#x2F;11 forever changed the lives of those who experienced it, including NJ Burkett and Marty Glembotzky. Their bravery, resilience, and commitment to delivering accurate news became a testament to the strength of the human spirit in the face of adversity.And so, their story remains a reflection of the countless individuals who demonstrated courage and humanity on that unforgettable day—reminding us of the importance of journalism in providing a voice and telling the stories that matter most. reply dividuum 15 hours agoparentYoutube link: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=oCPVNLLo-mI reply causi 20 hours agoprevIf you want to get a handle on how the War on Terror started and how everybody felt about it, I highly recommend listening to some of the live radio shows from that morning, such as the Howard Stern show. You look back now and question how we could&#x27;ve let it get so out of hand, but watching people react to it in real time takes you right back to the emotions it triggered. I don&#x27;t think I&#x27;ve ever felt that degree of collective fury before. That week, many of the people I know would&#x27;ve been happy to launch nuclear weapons at every population center in Afghanistan and the capitals of every nation that&#x27;d so much as looked at the United States funny in the previous ten years. reply sneak 20 hours agoparentIt seemed like overreactions to me at the time, and it seems like overreactions to me now.I was 18 at the time and I was already old enough to know that you don&#x27;t make big decisions when tired, angry, or stressed.What&#x27;s the point of checks and balances and the rule of law if they all go out of the window as soon as an adversary does something bad enough to make enough of us sufficiently angry? Those aren&#x27;t laws and rules or balances (or values) if they get tossed aside simply because of a spike in anger or fear or both. reply ilaksh 20 hours agorootparentThe reasons we engaged in those extensive Middle East campaigns were strategic, just like they have always been for hundreds of years.The events of that day were (coincidentally) the perfect motivation for the campaigns.https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Great_Game reply bufordtwain 19 hours agorootparentprev\"Everybody has a plan until they get punched in the mouth.\" -Mike Tyson reply sneak 19 hours agorootparentCall me crazy, but if our entire machinery of government can&#x27;t function well enough to control itself internally to preserve human rights better than Mike Tyson, maybe we should toss the whole thing out and start over. reply shepherdjerred 17 hours agorootparentThe purpose of a government has not historically been to preserve human rights reply seanw444 13 hours agorootparentWe literally wrote a document explaining what the government is not allowed to do, for that reason. Yet they still do those things anyways. Not enough people care, either. replysanderjd 19 hours agoparentprevI remember the feeling extremely clearly. And I still remember that feeling extending to the beginning of the war in Afghanistan, which I thought seemed justified and right.But I just as clearly remember how confused, frustrated, and just so disillusioned with the wisdom of my elders (I was still a teenager at this time) I felt when they were all so gung ho about invading Iraq, which clearly at the time had absolutely nothing to do with 9&#x2F;11.The debate nowadays always seems to hinge on this question of whether they lied about the WMD thing or were \"just\" mistaken about it. But from my perspective living through that time as a young person, that WMD thing was not the problem, the problem was this mass fearful hysteria that our leaders (either cynically or because they were themselves in the grips of that hysteria) were able to use to get overwhelming popular support for an unrelated invasion, essentially just out of peoples feelings of righteous anger and spite.It isn&#x27;t just ugly in hindsight, it was ugly ugly ugly then, in the moment. reply jrmg 18 hours agorootparentThe BBC has an excellent series about this time, available as a podcast: https:&#x2F;&#x2F;www.bbc.co.uk&#x2F;programmes&#x2F;m001k0ch&#x2F;episodes&#x2F;downloads reply cout 18 hours agorootparentprevI know next to nothing about geopolitics, but I always figured the the conflicts in Iraq and Afghanistan had something Iran since it&#x27;s sandwiched between them. reply peterleiser 18 hours agorootparentYes. Search for the phrase “Everyone wants to go to Baghdad. Real men want to go to Tehran” to see what folks were saying at the time . reply peterleiser 18 hours agorootparentprevI encourage people to read about Project for the New American Century (PNAC). 9&#x2F;11 gave PNAC and the neoconservatives the optimal opportunity to implement their stated objectives. reply sanderjd 18 hours agorootparentWhat makes you think I didn&#x27;t know &#x2F; read about it at the time?All the comments here mentioning the neoconservative desire for regime change in Iraq predating 9&#x2F;11 seem to imply that it was an obscure thing that people weren&#x27;t very aware of at the time.But that isn&#x27;t true at all. It was broadly understood and frequently discussed. It&#x27;s just that people were so generally scared, pissed off, and ready for vengeance against whoever, that nobody cared. (Not literally nobody, but I think I recall that the war had like 70% or 80% support, with strong majorities in both major parties.)This is why I started out my adulthood libertarian-curious, because both parties and huge majorities of voters seemed insanely interventionist to me. But things have reordered a huge amount since then. (Basically everyone came around to my view of the war, in hindsight.) reply peterleiser 17 hours agorootparentHi. I figured you did know &#x2F; read about it at the time, actually. I think we have the same viewpoint. I was just using your insightful comment to encourage other folks to read about PNAC for historical context. I don&#x27;t want anyone to pretend to forget, or younger folks not to know, what got us into the last 20 years of forever war. reply sanderjd 17 hours agorootparentFair! reply giraffe_lady 18 hours agorootparentprevYeah like, is everyone forgetting how fucking insanely racist that moment was in the US. Brutal nasty racism, it was utterly foul and EVERYWHERE just completely normalized in every venue.Unreal everyone is pretending to have been taken in by the \"war on terror\" kayfabe at the time. I knew 15-year-olds who clocked the whole thing as an opportunistic political scam. The correct stance is contrition and repentance. All these stories about what kinds of cereal people were eating that day disgust me. We killed tens of thousands, destabilized and destroyed entire countries, created millions of refugees with these stories as the excuse. reply next_xibalba 20 hours agoparentprevWell said.I was a sophomore in high school at the time. Sometime in the late morning, after both towers had been hit and it was clear that it was a terrorist attack, all the classroom TVs were turned on and tuned to the news. I distinctly recall the palpable fear and fury. A fellow student said to me, in a fit of gallows humor, \"Get your gun, son. We&#x27;re going to war.\"It did feel as though there was some legitimacy to Afghanistan (of course, even that ended up being folly), but Iraq, which didn&#x27;t happen until the Spring of &#x27;03, always felt tenuous.Of course, all of it turned out to be a catastrophe, most especially for Iraqis and Afghans.My personal pet conspiracy theory is that the U.S. leadership realized that the U.S. homeland was not defensible against asymmetric attacks of this nature. They needed to create an external beacon for the jihadists–a theater in which the U.S. military would be the target and the aggressor, not soft targets. And so they chose Iraq, with its dormant sectarian divisions being a perfect cauldron to which those enemies would be drawn. reply sanderjd 19 hours agorootparentI still think the initial campaign in Afghanistan was not a mistake.But I think after that, we let the military continue running the show there for way too long and never took the diplomatic mission seriously enough. reply causi 17 hours agorootparentYou can&#x27;t change the soul of a people by force or even by diplomacy. If you look at every nation whose culture reformed after, say, losing in WW2, their behavior during and leading up to that war was relatively different from their norms. Germany&#x27;s genocidal imperialism was a result of the first world war and the terms of the treaty which ended it. Japan turned imperialist because European colonialism made them decide it was either become an imperial power or get swallowed up. Both nations could revert to relative normalcy after the war.Afghanistan has been a tyrannical theocracy that uses religion to treat its citizens like dirt while being repeatedly invaded by outsiders for damn near eight hundred years. There is no fixing that, especially not in a couple of decades. reply civilitty 19 hours agorootparentprev> My personal pet conspiracy theory is that the U.S. leadership realized that the U.S. homeland was not defensible against asymmetric attacks of this nature. They needed to create an external beacon for the jihadists–a theater in which the U.S. military would be the target and the aggressor, not soft targets. And so they chose Iraq, with its dormant sectarian divisions being a perfect cauldron to which those enemies would be drawn.Interesting conspiracy theory! Especially considering that the resulting mess caused a massive refugee crisis and a spike of terrorism in Europe. Even if it didn&#x27;t keep the terrorist mired in the Middle East, it redirected the violence towards our allies, thus maintaining the general casus beli. reply ilaksh 20 hours agoparentprevThat was the intended effect. This is the context: https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;PropagandaWar is strategic. But soldiers won&#x27;t kill for strategic reasons. They will fight when given an ethical basis. The objective truth never provides this. reply adrianmonk 19 hours agorootparentIntended by who? Are you saying the US government knew it meant war and had the foresight (and bandwidth) to arrange a coordinated propaganda campaign on the spot?People just being naturally angry seems like a simpler and perfectly sufficient explanation. We humans are pretty much hardwired to respond like that: when we believe we&#x27;ve been wronged, a special brain mode kicks in that pushes us toward taking action (ideally a constructive one, but brain hardware doesn&#x27;t enforce that). reply enterprise_cog 19 hours agorootparentWhat a coincidence that raw anger led to enabling the plans of the Project for a new American century. reply adrianmonk 18 hours agorootparentThe sun coming up in the morning enables plans to generate solar power, but the sun doesn&#x27;t require our intervention. reply enterprise_cog 18 hours agorootparentSo the planes hitting the towers were as natural as the sun rising in the morning? What? reply adrianmonk 18 hours agorootparentSomeone suggested that Americans got angry after 9&#x2F;11 because of propaganda. I&#x27;m saying they got angry because that happens naturally when your country is attacked. replymc32 19 hours agorootparentprevYou can feed them hashish or whatever and turn people into berserkers. Also, in mercenaries people do it for other reasons.Anyhow, when you look at the elated reaction from people in some areas of the world when it happened, one can see why people might react to that reaction with seething vengeance in mind. reply enterprise_cog 19 hours agorootparentYou can see the ignorance of the people in this country from that anger. Those people celebrating were on the receiving end of American terrorism abroad. reply mc32 18 hours agorootparentSometimes —but in many cases people in areas unaffected directly by American policy were celebrating as if they felt a tribalistic attachment perhaps to the aggrieved.You&#x27;re arguing that two wrongs make a right and in such argument the stronger party will win. reply enterprise_cog 18 hours agorootparentI’m not arguing that two wrongs make a right. I’m saying actions have consequences. And how could you possibly know those people celebrating we’re not affected by US policy and military exploits? replyswozey 20 hours agoparentprevI don&#x27;t have the time to dig around for examples but reading IRC logs (which I mention in another comment) is really ... interesting. I haven&#x27;t read them in years but I remember the vitriol toward Muslims being absolutely astonishing. But it was ye olde 2000s.. reply civilitty 19 hours agorootparent> I haven&#x27;t read them in years but I remember the vitriol toward Muslims being absolutely astonishing. But it was ye olde 2000s..Not only has the vitriol not gone away, the targets have vastly expanded. Go read the worldnews subreddit coverage of the war in Ukraine, for example: lots of talk about \"Russian scum\" and other dehumanization of the enemy upvoted to the top. reply cmrdporcupine 18 hours agorootparentI also see it from the other line -- lots of people who&#x27;ve taken the bus so far to the right that they talk about Putin as a hero fighting against our \"degenerate\" western leaders.It&#x27;s pretty dark out there in popular discourse right now. reply cmrdporcupine 19 hours agorootparentprevIt never went away. The religious right in the US and others discovered a wellspring of motivational energy (for their regular causes) that they could get out of people by pointing fingers at Islam, and they have never really let it go.It comes and go in waves, but it&#x27;s pretty crazy what an appeal to an old bogeyman can get you; at the time, George Bush talking about a \"clash of civilizations\" and appealing to old Crusades era mythos of east vs west, orient vs \"western civilization\" etc. was incredibly \"successful\" at accomplishing the goals that Rumsfeld and Cheney and others had set out for their regime.The Bush&#x2F;Cheney regime inherited a largely liberal, tolerant, and centrist populous from the Clinton years. The general zeitgeist and political atmosphere from back then looks so civilized and calm compared to now. And they leverage 9&#x2F;11 to stir up a whole different scenario afterwards that has never stopped accelerating. The xenophobic far right has been in steady ascendancy ever since.To this day, if there&#x27;s a shooting in a mall or whatever, you&#x27;ll hear people immediately jump to the jihadist explanation, even when it&#x27;s clear that the bulk of terrorist type violence in North America doesn&#x27;t actually take this form -- it&#x27;s usually far right &#x2F; white supremacist in inspiration, just as it was before 9&#x2F;11 (e.g Timothy McVeigh, etc.)I&#x27;m an atheist and no lover of any organized religion, including Islam, but it was dark and depressing to watch at the time and it continues to be depressing to see people manipulated on these terms. reply havblue 12 hours agorootparentMany speculate that groups need a common enemy to maintain their identity. Obviously, communism and terrorism are recent examples. But what are our common enemies now? The New Atheists decried religion for years but frankly, I think the religious right is dead. Many consider new atheism movement to be dead as well. So we currently only have the other party to blame. reply havblue 19 hours agoparentprevHoward Stern is definitely a cautionary tale for how an irreverent anti-establishment hero just becomes exactly what he would have hated starting off. reply pjc50 19 hours agoparentprevIt was obvious to me, a Brit, that there would be massive American retaliation against whichever country was linked to this - and I said so in the office where we had all broken off work to crowd round the TV or refresh news websites. Then a second plane hit.(I incorrectly guessed it was the PLO responsible)> That week, many of the people I know would&#x27;ve been happy to launch nuclear weapons at every population center in Afghanistan and the capitals of every nation that&#x27;d so much as looked at the United States funny in the previous ten years.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Project_for_the_New_American_C...There was (and still is in some quarters) a huge desire for revenge against Iran. A side effect of Republicans going full Qanon is that they no longer care about the middle east at all, and the PNAC lot fade into history. reply no_wizard 19 hours agorootparentI remember talking about PNAC at a debate session of all things in high school. Our debate club was pretty big and well known in our schoolThe teachers that ran it shut me down, saying I was peddling conspiracy theories about PNAC influence and the wars in Iraq and Afghanistan, this was 2008&#x2F;2009.I&#x27;m still, based on research I&#x27;ve done since, convinced that PNAC had a huge influence on George W. Bush and Dick Cheney in particular, and the white house at the time more generally. Ultimately I believe this is why they pursued the wars in Iraq and Afghanistan, was due to the ideas espoused by this group reply pjc50 19 hours agorootparentYou were absolutely correct; it was as close as possible to publishing a manifesto saying \"here&#x27;s how we&#x27;re going to launch a war in the middle east\" and then doing it as you&#x27;ll ever see. The same clearly identifiable people were involved all over the place. reply peterleiser 17 hours agorootparentExactly. PNAC wasn&#x27;t conspiracy theory at all. It wasn&#x27;t even an \"open secret\": They had a website, the signatories were public, many of the signatories were in the Bush W. administration. PNAC was discussed often on all the talking head political shows. It became the plan after 9&#x2F;11.I think some people a decade or so later thought it was a conspiracy theory because they thought it implied 9&#x2F;11 was done, or allowed to happen, on purpose in order to begin the regime changes outlined in the plan.But with PNAC this was their world view and plan, and 9&#x2F;11 allowed them to move forward. Wrong plan, right time. reply no_wizard 16 hours agorootparentprevIn retrospect, what I think was happening was teachers were afraid of other parents (many, many of which would be classified as conservative republicans) getting upset at them. The debate club was a big deal in my school and parents were actively involved with many aspects.I think they saw headache and shut me down the easiest way possible.Its really unfortunate, however I do think this was the main driver reply sanderjd 19 hours agorootparentprevI still remember the short period of time when it wasn&#x27;t clear someone had done it on purpose, or the slightly longer period of time when it wasn&#x27;t clear who had done it.Sadly, it would have been much better for the country and the world, if it had been a domestic group of some kind. Still really bad, but not as bad. reply blamazon 19 hours agoprevThere are so many incredible stories of heroism from this day, but, I will highlight that of Rick Rescorla. [1]After 1993, before 9&#x2F;11:> Feeling that the authorities lost legitimacy after they failed to respond to his 1990 warnings, he concluded that employees of Morgan Stanley, which was the largest tenant in the World Trade Center, could not rely on first responders in an emergency and needed to empower themselves through surprise fire drills, in which he trained employees to meet in the hallway between stairwells and go down the stairs two by two to the 44th floor. Rescorla&#x27;s strict approach to these drills put him into conflict with some high-powered executives, who resented the interruption to their daily activities, but he nonetheless insisted that these rehearsals were necessary to train the employees in the event of an emergency. He timed employees with a stopwatch when they moved too slowly and lectured them on fire emergency basics.On 9&#x2F;11:> When a Port Authority announcement came over the P.A. system urging people to stay at their desks, and before United Airlines Flight 175 would strike the South Tower at 9:03 A.M., Rescorla ignored the announcement, grabbed his bullhorn, walkie-talkie and cell phone, and began systematically to order the roughly 2,700 Morgan Stanley employees in the South Tower to evacuate, in addition to the employees in WTC 5, numbering around 1,000.> After successfully evacuating almost all of Morgan Stanley&#x27;s 2,700 employees, he went back into the building. When one of his colleagues told him he too had to evacuate the World Trade Center, Rescorla replied, \"As soon as I make sure everyone else is out.\" He was last seen on the 10th floor of the South Tower, heading upward, shortly before its collapse at 9:59 A.M., 56 minutes after being struck by United Airlines Flight 175. A total of 13 Morgan Stanley employees died in the September 11 attacks, including Rescorla, his deputies Wesley Mercer and Jorge Valezquez, and security guard Godwin Forde, who had collectively stayed behind to help others.[1] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Rick_Rescorla reply Lord-Jobo 19 hours agoparentA true, no bullshit, hero. I was never a boyscout, but &#x27;be prepared\" is a motto I try to stand behind. reply xeonmc 18 hours agoparentprevVideo interview of him before 9&#x2F;11:https:&#x2F;&#x2F;vimeo.com&#x2F;441396612 reply reducesuffering 17 hours agorootparentHe predicted it happening so eloquently too. What an outstanding exemplar hero. reply sanderjd 18 hours agoparentprevThank you for that story.Do you know of a book that covers the event from this angle? I&#x27;m totally tapped out on the usual treatment of the event focused on geopolitics before and after it, but I would like to read in long form about the actions of the actual people there and nearby that day. reply blamazon 18 hours agorootparentI&#x27;m not immediately aware of a solid consolidated book on this regard, it&#x27;s a bit scattered to my knowledge over many journalistic articles and oral histories. If anyone else has a recommendation I am interested as well.Anyhow, a good place to start on researching this topic might be the 9&#x2F;11 Tribute Memorial and Museum&#x27;s YouTube channel where they have some clips from survivor accounts[1], many of these individuals you can google their names and find articles from the time period, for example Stanley Praimnath and Brian Clark. [2] The 9&#x2F;11 Museum also holds many more oral histories, and transcripts. [3] One account that sticks with me is from a Reddit user that fled lower Manhattan on an abandoned bicycle. [4] There are similar stories in the comments of that post.I do actually have a book recommendation I have read but it&#x27;s more about what happened in the months after the events of 9&#x2F;11: \"American Ground: Unbuilding the World Trade Center\" [5][1] https:&#x2F;&#x2F;youtube.com&#x2F;playlist?list=PLqCjsbFgQNH7awCj8Q-PJa9Kb...[2] https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20070827041945&#x2F;http:&#x2F;&#x2F;archives.c...[3] https:&#x2F;&#x2F;www.911memorial.org&#x2F;learn&#x2F;resources&#x2F;oral-histories[4] https:&#x2F;&#x2F;old.reddit.com&#x2F;r&#x2F;IAmA&#x2F;comments&#x2F;zpxyv&#x2F;i_submit_this_e...[5] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;American_Ground reply esotericimpl 18 hours agorootparentprevhttps:&#x2F;&#x2F;www.newyorker.com&#x2F;magazine&#x2F;2002&#x2F;02&#x2F;11&#x2F;september-11th...This is the greatest article written for an actual 9&#x2F;11 hero. reply alwinaugustin 18 hours agoprevNo idea how to use this site. It is showing some random footage. reply gs17 15 hours agoparentYou might be a bit early in the timeline. You&#x27;ll have to wait&#x2F;fast-forward a bit. reply Freebytes 18 hours agoparentprevI love the concept, but the user interface could certainly use some work. reply gala8y 16 hours agoparentprevI think it does not work the way it was intended. reply shanghaikid 20 hours agoprevnext [3 more] [flagged] nickthegreek 20 hours agoparentWhat is trying to be funny? reply DrBenCarson 20 hours agoparentprevIs it meant to be? reply novia 19 hours agoprev [–] \"Real time\" but they don&#x27;t have it in the EST timezone... replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The document summarizes the events on September 11, 2001, encompassing the last communication of Flight 11 with air traffic control, the plane crashes into the World Trade Center and the Pentagon, and the structural collapse of the towers.",
      "It also sheds light on President Bush's reaction alongside various media briefings and addresses throughout the day.",
      "A new initiative \"9/11 in Realtime,\" a multimedia experiment, is introduced to aid students in comprehending the events of that day."
    ],
    "commentSummary": [
      "The summaries encompass varied discussions and personal experiences linked to the 9/11 attacks, involving stories from individuals directly affected.",
      "The topics range from the long-term impact on society and civil liberties, debates concerning complacency, speculation about the attacks, to the role of journalism and public reactions.",
      "As consequences of the attacks, discussions also include the invasion of Afghanistan and Iraq, racial tensions, violence, propaganda, and the transformation of the United States' political climate."
    ],
    "points": 216,
    "commentCount": 145,
    "retryCount": 0,
    "time": 1694439485
  },
  {
    "id": 37472994,
    "title": "uBlock-Origin – 1.52.0",
    "originLink": "https://github.com/gorhill/uBlock/releases/tag/1.52.0",
    "originBody": "Skip to content Product Solutions Open Source Pricing Search or jump to... Sign in Sign up gorhill / uBlock Public Notifications Fork 2.8k Star 37.4k Code Issues 13 Pull requests 1 Actions Projects Wiki Security Insights Releases 1.52.0 1.52.0 Latest Compare github-actions released this 1.52.0 c0df544 Commits to master since this release Commits since last release To install the stable build: Firefox: Review pending uBO works best on Firefox. Chromium: Review pending (25%) Edge: Install from Microsoft Store: https://microsoftedge.microsoft.com/addons/detail/odfafepnkmbhccpbejgmiehpchacaeak The Microsoft Store version of uBO is published by Nicole Rolls Opera: Review pending Fixes / changes Add json-prune-xhr-response and trusted-replace-xhr-response scriptlets Use globalThis instead of self in scriptlet helper Add json-prune-fetch-response scriptlet Position reload icon in logger as per feedback Re-factor extra args for set-constant scriptlet Use Unicode version of hostnames in element picker Disallow trailing CSS universal selector unless properly separated Fix/improve xml-prune scriptlet Improve xml-prune scriptlet Put uBO's icon in nav bar by default Properly serialize CSS combinators according to position in selector Improve no-xhr-if scriptlet Improve no-xhr-if scriptlet Use non-normalized URL for reload/report operations Add commented keywords to googlesyndication_adsbygoogle.js scriptlet Improve fingerprint2.js scriptlet Nothing can come after action operator in procedural cosmetic filters Add trusted-replace-fetch-response scriptlet Harden spoof-css scriptlet Support negated pattern for stack test in scriptlets Fix looking up clickable URLs in code viewer Fine tune logging capabilities of json-prune scriptlet Add stackNeedle argument to json-prune scriptlet Improve remove-class behavior Add visual hint for filtered out rows in firewall pane Add $currentISODate$ to trusted-set-local-storage-item scriptlet Eliminate case-sensitivity from values in set-cookie scriptlet Assets 6 Footer © 2023 GitHub, Inc. Footer navigation Terms Privacy Security Status Docs Contact GitHub Pricing API Training Blog About",
    "commentLink": "https://news.ycombinator.com/item?id=37472994",
    "commentBody": "uBlock-Origin – 1.52.0Hacker NewspastloginuBlock-Origin – 1.52.0 (github.com/gorhill) 211 points by archo 14 hours ago| hidepastfavorite67 comments freedomben 13 hours agogorhill is a hero and legend to me. One of the most important players in making the modern web.I&#x27;m still holding out hope that either he or someone else picks uMatrix back up. It&#x27;s such an incredible tool, and I&#x27;m worried about the day when it no longer works. reply frogelos 13 hours agoparentPersonally i use AdNauseam but if i click on uBlock button and then select \"more\" twice i get similar interface to uMatrix. Are there any features lacking in there compared to uMatrix? reply squarefoot 13 hours agorootparent> Are there any features lacking in there compared to uMatrix?uMatrix had a much better UI which allowed finer granularity and immediate feedback when blocking this or that for a given site. reply somat 11 hours agorootparentprevCan you actually do anything with that display? As a fellow refuge from umatrix. I would love some of umatrix functionality there.So to test if I was remembering correctly I just played with the ublock expanded list a bit. You can click on some things(but not everything) and the color changes(sometimes). but I still could not figure if it is just a status display or if it can be used a a tool. As far as I can tell most of ublocks power is hidden inside scripts with no real ui. reply Yujf 4 hours agorootparentWith that display you can totally block or allow (sub-)domains on the current website (or all websites) so it does have some power, but it is not as powerful as the the scripts which allow much more granularity reply amaranth 13 hours agoparentprevWasn&#x27;t uMatrix dropped because at this point it&#x27;s just a more powerful UI to do the same things uBlock Origin lets you do? reply Zuiii 7 hours agorootparentYes, and that&#x27;s exactly why other people including myself still use it. reply contact9879 13 hours agorootparentprevThat was my understanding. reply Dwedit 13 hours agoparentprevAs far as I&#x27;ve seen, the most recently committed fork of uMatrix is this one:https:&#x2F;&#x2F;github.com&#x2F;nicolaasjan&#x2F;nuTensorWhy not just use the final release of uMatrix? Because it has a bug where it can delete your logon cookies when you navigate to another site. It also has bugs where the wrong rule is applied for a particular request (it picks the action defined for a different site). reply 8bitsrule 3 hours agoparentprev>gorhill is a hero and legend to me.I wish a had an 8x10 I could gold-frame, to hang over my desk. reply contact9879 13 hours agoparentprevWhat does uMatrix have that uBlock Origin doesn&#x27;t provide? reply pmontra 13 hours agorootparentThe UI is many orders of magnitude better. uMatrix vs uBlock Origin is a textbook case. UbO&#x27;s matrix is the masochist&#x27;s teapot in the cover page of The Design of Everyday Things https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;The_Design_of_Everyday_Things uMatrix is a teapot with the handle where it should be.If uMatrix will stop working I&#x27;ll install NoScript. I&#x27;ll keep using UbO for ads and cosmetic filtering. reply sebzim4500 13 hours agorootparentHow so? I think uBO has a pretty nice UX for what I want to do.Especially like the element picker UI, where you can independantly control what element you want in the hierarchy and also how specific the selector should be. reply pmontra 6 hours agorootparentThe element picker is wonderful and I use it a lot especially on my phone but the part that reimplemented uMatrix is a huge and inexplicable regression. reply Zuiii 7 hours agorootparentprev> How so? I think uBO has a pretty nice UX for what I want to do.I&#x27;m happy for you but I think uBO has a horrible UX for what I want to do. reply drewmol 13 hours agorootparentprevYou use both(UbO and uMatrix)? I didn’t realize uMatrix dev had been discontinued until just now, but between Brave shields and uMatrix I do a lot of clicking just to get stuff to work properly when browsing. Do you have to toggle&#x2F;config uBlock often? reply pmontra 6 hours agorootparentI use Firefox. I don&#x27;t know what&#x27;s a Brave shield.I use uMatrix + uBO on desktop and NoScript + uBO on mobile.I use uBO&#x27;s UI mainly for the element picker. The part that reimplemented uMatrix is too hard to understand and to use, hence my comment about the teapot that pours tea from above the handle.I&#x27;m using NoScript on my phone because it has a better UI for that. I use uMatrix on my desktop because it&#x27;s better than NoScript. I don&#x27;t use uMatrix on my phone because it&#x27;s not available on mobile. I would if it was. reply drewmol 3 hours agorootparentSorry, I could have been more clear. Brave is a browser with a feature called Shield, an anti-tracking feature, a click of the icon disables it&#x2F;reloads page. So my workflow is up to 3 clicks if I just want to disable everything, which I do when I&#x27;m in a hurry sometimes.I was wondering how often you had to interact with uBO mostly, which was answered in sibling comment.I&#x27;m switching back to an android phone, mostly for a better browsing experience, so I&#x27;ll try Firefox&#x2F;NoScript+uBO combo. I&#x27;m using uMatrix everywhere else(except on iOS) but no uBO, I thought uMatrix covered everything uBO does but I guess not so I&#x27;ll try both.Also, I believe some versions of nightly Firefox (on mobile) can support uMatrix, IIRC.Thanks for the breakdown! reply Yujf 4 hours agorootparentprevIf you rely on default config uBO just works, but if you go furthur in blocking things (or add third party filters) tinkering may be required for certain webpages (or a lot depending on how hard you go) reply drewmol 3 hours agorootparentGreat that&#x27;s what I was looking for, I&#x27;ll try combining the two. reply wtallis 13 hours agorootparentprevA better UI for fine-grained control over what kind of requests get blocked. reply freedomben 13 hours agorootparentExactly. Say I want to block cookies, media, and XHR requests on the current site as well as on a linked 3rd party site (like cloudfront), but allow css, scripts, and frames? In uMatrix such a configuration is trivial. In uBO AFAICT you&#x27;re probably gonna have to write the rules manually. The grid UI in uBO doesn&#x27;t get that granular, just \"network request\" level. reply idonotknowwhy 11 hours agoprevThe internet without this, it&#x27;s unusable. Same with YouTube and sponsorblock reply k12sosse 10 hours agoparentTo be fair it depends on what you watch. Not everybody who puts things on YouTube is so hard done by they need to tell you about the latest VPN or razor every 20 minutes. As far as YT premium goes, and the fact there are ads in the free tier - the best way to demonstrate how there are costs associated with their business model is.. at least for this audience:You wouldn&#x27;t pirate factorio, would you? reply soultrees 4 hours agorootparentI did when I was broke and depressed and trying out new games. Got so hooked on it, that I ended up buying myself and a few copies for friends. But the quality of the game is what converted from being a pirate, but it didn’t stop me from being a pirate in the first place.The difference is the value adding behaviour added by factorio vs the rent-seeking behaviour from every other game. reply metaphor 6 hours agoprevThought it was curious that this was released 4 days ago, but a spot check of the Firefox Add-Ons downstream[1] still reflects 1.51.0 updated on the same day (2023-07-19) as its GitHub release[2].Then I saw:> Firefox: Review pendingMozilla just seriously backlogged or is there a more nuanced story here?[1] https:&#x2F;&#x2F;addons.mozilla.org&#x2F;en-US&#x2F;firefox&#x2F;addon&#x2F;ublock-origin...[2] https:&#x2F;&#x2F;github.com&#x2F;gorhill&#x2F;uBlock&#x2F;releases&#x2F;tag&#x2F;1.51.0 reply DedlySnek 5 hours agoparentuBlock Origin is a recommended extension and according this page[1], Recommended extensions undergo full code review by staff security experts to provide a strong additional security check.[1] - https:&#x2F;&#x2F;blog.mozilla.org&#x2F;en&#x2F;products&#x2F;firefox&#x2F;extensions-addo... reply lucb1e 13 hours agoprevAnything in particular the submitter (u&#x2F;archo) is excited about? reply ireallywantthat 13 hours agoprevWhat if we implemented ublock origin in native code from Browser&#x27;s side instead of implementing it as extension? Will there be performance, efficiency and memory improvements? reply brucethemoose2 13 hours agoparentYes, see https:&#x2F;&#x2F;github.com&#x2F;uazo&#x2F;cromiteBut the history of minimalistic Chromium forks is kinda sad, as they seem to get little attention and maintaining them requires a ton of work. They tend to burn out, like the dev of Bromite did. reply pvg 13 hours agoparentprevThat&#x27;s more or less the goal of DeclarativeNetRequest in Chrome&#x2F;manifest v3 and similar facilities in Safari. reply dewey 13 hours agorootparentI somehow doubt the goal of the people behind Chrome is to make ad-blocking performance better. reply scq 13 hours agorootparentThat is their stated goal.> There’s been a lot of confusion and misconception around both the motivations and implications of this change, including speculation that these changes were designed to prevent or weaken ad blockers. This is absolutely not the goal. In fact, this change is meant to give developers a way to create safer and more performant ad blockers.-- https:&#x2F;&#x2F;blog.chromium.org&#x2F;2019&#x2F;06&#x2F;web-request-and-declarativ... reply wtallis 12 hours agorootparentImplementing DeclarativeNetRequest is mostly about making (simple) blocking perform better. Instituting unrealistically low limits on the number of rules that can be registered is not; if anything, the new APIs should have been enabling much larger filter lists than are currently in widespread use through the old APIs. reply pvg 13 hours agorootparentprevIt&#x27;s not a particularly difficult thing to assess technically. reply stonogo 12 hours agorootparentprevIt achieves \"efficiency\" by dropping functionality and limiting rule counts. There are mitigations. Extensive discussion here: https:&#x2F;&#x2F;github.com&#x2F;uBlockOrigin&#x2F;uBlock-issues&#x2F;issues&#x2F;338 reply dharmab 11 hours agoparentprevOrion blocks ads natively and also supports adblock extensions: https:&#x2F;&#x2F;blog.kagi.com&#x2F;orion-features reply yjftsjthsd-h 13 hours agoparentprevI think Brave claims to be doing something like that? reply seanw444 13 hours agoparentprevThe answer is almost certainly yes. But I wonder if the APIs it uses are already fast enough that doing so would yield negligible benefits? reply brucethemoose2 13 hours agoprev> uBO works best on Firefox.Those looking for performant adblocking in Chrome should also check out Cromite:https:&#x2F;&#x2F;github.com&#x2F;uazo&#x2F;cromiteIts a resumption of Bromite for Android&#x2F;Windows, hence the adblocking and tracking protection is far less limited since its native, not an extension.Of course, YMMV with lone Chromium fork devs. reply ploum 13 hours agoparentThose looking for adblocking should not use Chrome at all. If Chrome is really needed, it should be in its own container without any personal data.Adblocking in chrome is like smoking cigarettes with filters because \"it’s better for my health\".No, it’s not.For people knowledgeable enough to read HN, there’s no excuse to still use Chrome as a daily driver. reply hot_gril 12 hours agorootparentThe Chrome users don&#x27;t care so much about being tracked. They just don&#x27;t want to see ads. reply brucethemoose2 12 hours agorootparentThe dilemma for me is that Firefox is extremely slow on Android. Doubly so with adblocking and dark mode extensions.I don&#x27;t want the tracking, and I am certainly not going to install vanilla Chrome, but the performance deficit is a big compromise. reply ploum 1 hour agorootparentThen it means that, yes, you accept being tracked to browse the web a bit faster.Imagine the situation: your computer is slow and someone promises you to make it faster in exchange of knowing everything about what your computer is doing. Would you accept?Well, you did.I’m not pointing the finger at you. We are all doing compromises. I’m just saying that if you don’t want to be tracked but want all the benefits of being tracked then, really, you want being tracked.Also, Firefox being slow on Android doesn’t seem mandatory (it works really well for me). The fact that you didn’t look to solve this issue is yet one more confirmation that, yes, you agree to be tracked.Making choices is about the sacrifices we are ready to make for that choice. If there’s no sacrifice, there’s no choice. reply hot_gril 12 hours agorootparentprevIf you&#x27;re worried about tracking, isn&#x27;t Google&#x27;s OS already a non-starter? reply brucethemoose2 12 hours agorootparentLineageOS and derivatives are much more reasonable.Again, its a compromise, and I dont trust it with everything. reply paulryanrogers 7 hours agorootparentprevFirefox is slow at what? reply brucethemoose2 12 hours agorootparentprevThe customized forks are lightyears better than vanilla Chrome.Still, you have a point, and this feature in particular is quite telling:> internal firewall to block all unauthorised calls made from the browser patch (issue 147) reply gkmcd 12 hours agorootparentprevFirefox on Android&#x27;s URL bar still, in 2023, does not understand IPv6 addresses. So, unfortunately, there are still reasons to use Chrome. I use the Bromite f-droid repo but it hasn&#x27;t had a new build since 2022. I&#x27;d like to see this project take off! reply stathibus 12 hours agorootparentprevAds pay for the internet. reply e2le 12 hours agorootparentMy CPU is not free real estate for any site to abuse as they see fit. reply brucethemoose2 12 hours agorootparentprev99% of what goes through my browser is either SEO trash, social media attention baiting, a straight up scam, paywalled, or something ethically questionable from Big Tech.AP News served me malware in an ad.I whitelist good reporting and cool&#x2F;niche sites, but things worth whitelisting are increasingly rare. Whatever discomfort I felt using an adblocker before is long gone. reply hightrix 12 hours agorootparentprevAdvertisers poisoned the well.All ads must be blocked. reply stonogo 12 hours agorootparentprevSomeone should inform my ISP. reply paulryanrogers 7 hours agorootparentAds pay for the other end of the web, the part most folks are looking for, yet dont want to micro-pay every site they land on. reply deadmutex 12 hours agoparentprevHow quickly do they patch any new security issues? What&#x27;s their track record here? reply brucethemoose2 12 hours agorootparent> How quickly do they patch any new security issues?Its more like patched Chromium rather than a hard fork. It stays in sync with upstream.As for the patches themselves, they don&#x27;t seem risky to me. Enhanced security is an explicit goal. But I am no expert.> What&#x27;s their track record here?Uazo helped maintain Bromite (a longtime staple on Android). Now that the main Bromite maintainer is MIA, they just forked it....So the track record is not very long, no. reply jacooper 13 hours agoparentprevJust use brave reply brucethemoose2 13 hours agorootparentTheres a list of small things I don&#x27;t like about Brave, including the ad-replacement business model and the rewards things.I prefer \"simple\" forks that stick closer to Chromium, and Cromite is basically that. reply jacooper 11 hours agorootparentThey dont replace any ads. Brave ads are silent notifications, which are optional. reply hot_gril 12 hours agorootparentprevBrave used to edit links to insert their own referral codes. They only stopped when they were caught. That&#x27;s like browser hijacking behavior, so I&#x27;m gonna stay far away. reply archo 14 hours agoprevuBlock Origin – Wiki : https:&#x2F;&#x2F;github.com&#x2F;gorhill&#x2F;uBlock&#x2F;wiki reply jononomo 8 hours agoprev [–] Is there an equivalent to uBlock-Origin for Safari? reply newscracker 4 hours agoparentThere&#x27;s nothing that offers all these features and is free. But if you&#x27;d like to try Orion browser by Kagi [1], you can install uBlock Origin and many other web extensions for it on Mac, iOS and iPadOS. A paid alternative that is similar (at least for blocking specific elements) is AdGuard [2].[1]: https:&#x2F;&#x2F;browser.kagi.com&#x2F;[2]: https:&#x2F;&#x2F;adguard.com&#x2F; reply morjom 4 hours agoparentprevI think ublock lite got released on Safari recently. reply mega3000 4 hours agoparentprev [–] AdGuard, Wipr, 1Blocker reply mega3000 4 hours agorootparent [–] Paired with dns blocker (pihole, nextdns) or local firewall (littlesnitch) replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "This post discusses the most recent release of uBlock, an open-source software.",
      "The content provides installation instructions for varying browsers to accommodate the stable build of this new release.",
      "It outlines a comprehensive list of rectifications and modifications incorporated in this update, making it a potential point of interest for tech enthusiasts."
    ],
    "commentSummary": [
      "The article highlights the release of uBlock-Origin version 1.52.0 and the subsequent user feedback.",
      "There is ongoing user discussion comparing uBlock-Origin and uMatrix, along with voiced concerns about uBlock-Origin's limitations.",
      "Pending browser support review for Firefox and alternatives to uBlock-Origin for the Safari browser are also topics of interest in the article."
    ],
    "points": 209,
    "commentCount": 67,
    "retryCount": 0,
    "time": 1694463223
  },
  {
    "id": 37470801,
    "title": "MGM is down, cybersecurity attack ongoing",
    "originLink": "https://www.casino.org/news/mgm-resorts-suffers-cybersecurity-attack-system-outage-reported/",
    "originBody": "The World's Online Gaming Authority Since 1995 News Home Commercial Gaming Sports Betting Vital Vegas Tribal Gaming Legislation More News Crime & Scandals Share this: FEATURED — MGM Resorts Suffers Cybersecurity Attack, System Outage Reported Posted on: September 11, 2023, 07:08h. Last updated on: September 11, 2023, 10:57h. Devin O'Connor @CasinoorgDevinO Expertise: Asia Pacific Gaming, Commercial Gaming, Legislation, Politics. MGM Resorts International has been targeted by a cybersecurity attack, an official with the Las Vegas-based casino giant tells Casino.org. MGM Resorts has suffered a cybersecurity incident that has taken much of the casino company’s IT systems offline. Many details remain clear at this early juncture of the investigation. (Image: Casino.org) Brian Ahern, MGM’s executive director of communications, issued a statement Monday morning relaying that the casino company has been hit with an unknown attack. Ahern issued the company statement through a Gmail address, as employees do not currently have access to their company email because of the cyber incident. MGM Resorts recently identified a cybersecurity issue affecting some of the Company’s systems. Promptly after detecting the issue, we quickly began an investigation with assistance from leading external cybersecurity experts,” the company statement read. “We also notified law enforcement and took prompt action to protect our systems and data, including shutting down certain systems. Our investigation is ongoing, and we are working diligently to determine the nature and scope of the matter,” the release added. At this point, it’s unclear if the cybersecurity incident involves a ransom demand or even if the attackers are in communication with MGM officials. MGM is Nevada’s largest employer and operates the most casinos on the Las Vegas Strip. What We Know As the cybersecurity issue was only recently detected, specifics of the attack at this juncture remain unknown. But early this morning, social media users began posting information relaying technical glitches within the company’s operations. Several MGM Rewards customers shared screenshots of notices showing that their mobile apps have gone offline. “MGM Rewards is undergoing maintenance, and digital keys are currently unavailable. Please see the Front Desk for assistance,” read one such notice. Social media users say there are problems throughout MGM’s Las Vegas casinos. The cyber event reportedly took credit card machines, ATMs, and ticket-in ticket-out machines offline. The cybersecurity event is impacting at least all of MGM’s Las Vegas operations. The company’s website’s landing page informs customers that its online reservation systems are currently unavailable. The outage, however, is apparently affecting MGM’s regional casinos, too. MGM National Harbor’s website is offline, as are the websites for Borgata in Atlantic City, MGM Grand Detroit, MGM Springfield in Massachusetts, Beau Rivage in Mississippi, Empire City Casino in NYC, and MGM Northfield Park in Ohio. China Operations MGM is one of the six commercial casino operators in Macau, the only place under China’s control where casinos are allowed. As of early afternoon on Monday, it appears the cybersecurity event in the US hasn’t impacted MGM’s Macau casinos. MGM — through its subsidiary, MGM China Holdings — owns and operates MGM Macau and MGM Cotai. MGM Resorts’ last major cybersecurity event came in 2019 when personal information on 30 million guests was shared publicly on an online instant messaging platform called Telegram. MGM confirmed in early 2020 that it was the victim of a data attack from a Russia-based hacking group. While names, telephone numbers, and birthdates were stolen, the attack did not include seizing sensitive financial, credit and debit card, or password information. Most Popular FEATURED — MGM Resorts Suffers Cybersecurity Attack, System Outage Reported Devin O'Connor — September 11, 2023 VEGAS MYTHS RE-BUSTED: Howard Hughes Left $156M to a Dude Who Once Gave Him a Lift Corey Levitan — September 1, 2023 VEGAS MYTHS RE-BUSTED: Linq Garage Illustrates Flooding Corey Levitan — September 8, 2023 Latest Casino News Financial Legislation Poker Tournaments Famous Players Sports Mobile Gaming Rumors iGaming Crime & Scandals Live Casinos Features More from Casino.org Got a tip for our reporters? Get in Touch Last Comments ( 6 ) Write a comment Steve Simmons September 11, 2023 What's the over / under on how many millions per second they are losing? Lamar Scrotum September 11, 2023 Likely Russian attack … University or Michigan was hit with a similar attack (they pulled the plug on a number of systems) Frank Paulson September 11, 2023 NO company expects for something this horrible to happen. I am sure they are doing everything and anything to get issues resolved. Please quit complaining! Karl September 11, 2023 It's Jeff Morgan's personal 9/11. Jeff Morgan September 11, 2023 I was waiting over an hour at the MGM in Ohio and no one was even in site to pay anyone. They had over half the machines lit up waiting for someone to show up. There was maybe two people walking around. I left over a $300 credit because I could not wait all day for them. This is ridiculous. Mary Reilly Parsons September 11, 2023 People should be notified as they enter casinos. MGM making money on small amts customers leave in machine rather than wait for someone to give them cash. In Sprfld Mass only 4 employees working to give cash. They should shut down. We've been waiting nearly an hour to get cashed out. Related News Articles Gambling Sites Hit By Denial of Service Attacks Originating in US – Report Erik Gibbs — July 19, 2023 Gateway Casinos Say Ontario Properties Suffered ‘Cybersecurity Incident’ Devin O'Connor — April 18, 2023 Nevada Gaming Commission Approves New Regulations to Thwart Cyberattacks Corey Levitan — December 23, 2022 MGM Resorts CEO Bill Hornbuckle Traveling to Japan to Sign Final Development Docs Devin O'Connor — September 11, 2023 Most Popular Barstool Sports Layoffs Begin After Dave Portnoy Resumes Control Devin O'Connor — September 5, 2023 L.A. Rams Wide Receiver Cooper Kupp Seeks Second Opinion on Injury Pauly McGuire — September 6, 2023 VEGAS MUSIC ROUNDUP: Ed Sheeran Cancels Stadium Gig, Aguilera Residency Coming NYE Corey Levitan — September 9, 2023 Fanatics Unveils Jersey Drop Promo for New Sportsbook Clients Todd Shriber — September 1, 2023 New Hampshire Casino Co-Owner Quits Study Commission, Allegations of Wrongdoing Surface Ed Silverstein — September 3, 2023 Most Commented Las Vegas Strip Likely to Lose Casino Royale Corey Levitan — August 4, 2023 — 29 Comments Louisiana Margaritaville Casino Site of Apparent Racial Attack — Video Ed Silverstein — August 15, 2023 — 16 Comments VEGAS MYTHS RE-BUSTED: Elvis Was a Straight-Up Racist – Mary J. Blige, Quincy Jones, Chuck D Weigh In on a Persistent Controversy Corey Levitan — August 18, 2023 — 10 Comments Maroon 5’s Adam Levine Huffs Out of Scheduled Cosmopolitan Las Vegas Club Appearance Corey Levitan — August 16, 2023 — 7 Comments VEGAS MYTHS RE-BUSTED: Las Vegas is in Imminent Danger of Running Out of Water Corey Levitan — August 11, 2023 — 7 Comments Most Read First NFL Slot Machine Hits US Casino Floors Corey Levitan — August 31, 2023 DON’T BE TOO CRUEL: A.I. Predicts How Elvis Would Look Today Corey Levitan — September 2, 2023 Similar Guides On This Topic BetMGM ReviewBetMGM Promo Code Casino.org is the world’s leading independent online gaming authority, providing trusted online casino news, guides, reviews and information since 1995. Contact Us Get Listed About Us Meet the Team Editorial Guidelines Careers More News Aaron Rodgers Suffers Serious Injury in Debut for New York Jets MGM Must Disclose Ransomware Demand if it Pays One Court Denies Redo in Florida Sports Betting Case Caesars Sportsbook Shows Live Betting Advantage, Says Analyst Ed Sheeran Crashes Las Vegas Wedding to Serenade Newlyweds More from Casino.org About Casino.org Home Casino.org Blog Casino Guides Best Online Casinos Online Gambling Sites Online Casino Bonuses No Deposit Bonuses Free Spins Casinos Casino Reviews Online Casino Games Online Slots Progressive Jackpot Slots Online Roulette Online Blackjack Video Poker Online Poker Free Casino Games Mobile Casinos Android Casinos iPhone Casinos Local Casino Finder Guide to US Gambling Ages Country Casino Guides UK Canada India New Zealand Worldwide Online Casinos Country Casino Guides កម្ពុជា។ Argentina Australia Azərbaycan Bahamas Belgique België Bermuda Bolivia Brasil Brunei Cameroun Canada Canada (Français) Chile Colombia Costa Rica Cyprus Côte-d Ivoire Deutschland Ecuador Eesti El Salvador English España Ghana Guatemala Honduras Hrvatska India Indonesia Ireland Italia Kenya Kuwait Latvija Liberia Liechtenstein Lietuva Luxembourg Luxemburg Macau Magyarország Malaysia Malta Moldova México Nederland New Zealand Nicaragua Nigeria Norge Panama Paraguay Perú Philippines Pilipinas Polska Portugal Puerto Rico República Dominicana România Schweiz Seychelles Shqipëria Singapore Slovenija Slovensko South Africa Sri Lanka Suisse Suomi Sverige Svizzera Sénégal Tanzania Trinidad and Tobago Türkiye UAE Uganda United Kingdom Uruguay Vasco Venezuela Việt Nam Zambia Zimbabwe Ísland Österreich čeština Ελλάδα Беларусь България Македонија Србија Точикистон Україна Қазақстан Հայաստան الأردن الإمارات العربية المتحدة البحرين الجزائر الكويت المغرب المملكة العربية السعودية تونس دولة قطر سلطنة عمان لبنان مصر پاکستان नेपाल বাংলাদেশ ประเทศไทย မြန်မာ საქართველოს ኢትዮጵያ 加拿大 台湾 日本語 대한민국 Follow us: Home Terms of Service Privacy Policy Sitemap Problem Gambling Casino.org website is certified by: Copyright © 1995-2023, Casino.org, All Rights Reserved We use cookies. By continuing to browse the site you are agreeing to our use of cookies. Learn more. OK",
    "commentLink": "https://news.ycombinator.com/item?id=37470801",
    "commentBody": "MGM is down, cybersecurity attack ongoingHacker NewspastloginMGM is down, cybersecurity attack ongoing (casino.org) 184 points by codex_irl 16 hours ago| hidepastfavorite99 comments bsimpson 15 hours agoTitle should be \"MGM Resorts Suffers Cybersecurity Attack, System Outage\" (following HN norms), or at least include \"Resorts.\" MGM Resorts was spun out of the movie studio in like the 70s. reply basch 8 hours agoparentMGM is basically a defunct rights holding company. It’s made 5 movies in the last decade, including 2 Addams Family, 2 Max (dog movies), and a GI Joe, and the Addams Family movies were really Made by Universal. It’s also a name slapped on some other streaming app.If I heard the name referring to a current company, I would think hotels&#x2F;casinos&#x2F;sportsbooks first. That said, the title could still be better. reply aquova 7 hours agorootparentI don&#x27;t really know where you&#x27;re getting this number. By my count they&#x27;ve made about three dozen films this decade, including a James Bond film and Creed III. reply downrightmike 5 hours agorootparentprevFurther proof: They have StarGate and aren&#x27;t doing jack with that at all. reply dharmab 3 hours agorootparentThere&#x27;s a new Stargate series in development. There&#x27;s promotional stuff happening at &#x2F;r&#x2F;stargate reply system2 4 hours agorootparentprevWhile Star Trek releasing new series every year including cartoons, Stargate didn&#x27;t release anything. It has so much potential and large fanbase (myself included). reply bettercallsalad 7 hours agorootparentprevDid not Amazon at some point buy or thought about buying up some of their business? reply BryantD 6 hours agorootparentYep. Amazon bought MGM Holdings in March, 2022. The studio is the only meaningful portion of that.They’re no longer considered a major U.S. studio but they release 8-10 films a year. reply babyshake 6 hours agorootparentprevYes, because I remember thinking that we would eventually be getting a bloated James Bond extended universe of shows (like Star Wars and Marvel) because of it. reply sschueller 14 hours agoparentprevAgreed, I thought it had something to do with the on going actors and writers guilds strike. reply dylan604 13 hours agorootparentI thought maybe it was hacking to get content. So at least the title instilled a bit of curiosity even if it wasn&#x27;t the story I had imagined from just the headline reply photonthug 4 hours agoprevMaybe most of the LED displays are run by the same IT department. So if I were an evil genius, this latest attack would be only the first salvo of bewildering hijinks perpetrated in the service of a multistep heist. The ultimate goal: rickroll the entire city after hijacking The Sphere ( https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=sLCeYV0SV8k&ab_channel=Billi... ) reply dafelst 8 hours agoprevI was at the Park MGM is Las Vegas yesterday and was unable to use the app or the automated checkout kiosks, though aside from the front desk being more busy than usual during checkin and checkout, nothing in particular seemed amiss. reply netsharc 14 hours agoprevOcean&#x27;s 0x11? I wonder if it&#x27;s just an attack against their email servers or a bigger one, how networked are their operations? If we believe the urban legends about how casinos operate, there&#x27;s probably interesting conversations a cyber-attacker could find. reply mickdarling 14 hours agoparentI was disturbed to hear from people first hand in Vegas saying it was making the ATMs inoperable. No details on how inoperable, like if it is just certain banking features or everything. The ATMs should not be effected in the same kind of attack that would take down the website and booking systems. Those should all be separate. reply plasticsoprano 14 hours agorootparentCasino floor ATMs aren&#x27;t just ATMs. They are also ticket redemption machines and therefore have to connect to the MGM network to redeem. I&#x27;d imagine the whole machine shutdown for security reasons if network connection is lost. reply mickdarling 13 hours agorootparentYes, I think that MGM has actively shut everything down, rather than some massive hack that has effected all these separate systems.Best guess is that with the F1 races coming soon with what is expected to be the largest cashflow through Vegas ever, that MGM Resorts IT found issues in an audit in preparation for that massive event, found anomalies, and pulled the rip cord to shut everything down till they could sort out what systems were actually hit.That is materially different than a massive hack effecting all these various systems though. reply plasticsoprano 13 hours agorootparentMGM has acknowledged it&#x27;s an attack [1] and certain vegas gossip sites have stated that Caesars was hit last hit last week but was able to keep it better under wraps.1. https:&#x2F;&#x2F;www.reviewjournal.com&#x2F;business&#x2F;casinos-gaming&#x2F;mgm-re... reply mickdarling 13 hours agorootparentRight, they say almost exactly what I said above.\"MGM Resorts recently identified a cybersecurity issue affecting some of the Company’s systems. Promptly after detecting the issue, we quickly began an investigation with assistance from leading external cybersecurity experts,”\"We also notified law enforcement and took prompt action to protect our systems and data, including shutting down certain systems.\"The systems are down due to MGM shutting them down, not the active attack shutting things down. reply imglorp 13 hours agorootparentprevWhile there&#x27;s something to be said for ransomware targeting casinos, \"because that&#x27;s where the money is,\" that might also attract the wrong attention, and not all from the government. They might wish it was only from the government.https:&#x2F;&#x2F;www.politico.com&#x2F;news&#x2F;2022&#x2F;01&#x2F;14&#x2F;russia-colonial-pip... reply andy800 10 hours agorootparentCasino-based attacks aren&#x27;t really because the casino has a lot of money around. 1) they have large, very detailed databases with extensive customer records (photos of drivers licenses, for example) that can are desirable on black markets 2) easy attack vector -- heavily dependent on a variety of vendor software and systems that are way out of date, run by weak, underpaid and often uninformed IT staffs unaware of some basic security vulnerabilities 3) being customer-facing and highly-regulated, casino companies are typically heavily incented to simply pay the ransom rather than face regulatory scrutiny and consumer distrust (and to restore cash flow, and because the soft IT teams probably didnt make comprehensive backups...) reply Karellen 11 hours agorootparentprevI can imagine the galaxy-brain planning session where our perps are coming up with their next target. They rule out robbing international drug cartels and black-market arms dealers, because while those orgs do have a lot of cash on hand, they don&#x27;t want to get on the wrong side of violent organised crime gangs....so they decide to hit casinos instead!expanding-brain-starfield.gif reply wolverine876 12 hours agorootparentprev> Best guess is that with the F1 races coming soon with what is expected to be the largest cashflow through Vegas ever, that MGM Resorts IT found issues in an audit in preparation for that massive event, found anomalies, and pulled the rip cord to shut everything down till they could sort out what systems were actually hit.That is quite a guess! reply dboreham 14 hours agorootparentprevPossibly the ATMs get network connectivity via a path that has either been affected by the attack directly or shut down as a precaution. reply wintogreen74 12 hours agorootparentI don&#x27;t believe these are typical bank ATMs but specific to MGM that manage all the casino games (ex: pay-outs, loyalty, etc) as well, so would be tied into any MGM systems. reply IAmGraydon 13 hours agorootparentprevIt’s entirely possible that these systems were hacked separately. reply lucisferre 14 hours agoparentprevI think you meant 0x0B. reply _joel 14 hours agorootparentbeat me to it, unless I&#x27;ve missed a few movies since! reply petemir 13 hours agorootparentActually it would be 0x0E, 0x0B, 0x0C, and 0x0D already happened. reply jjkaczor 14 hours agoparentprevVery networked - but their email servers are now likely cloud-based SaaS. reply zie 12 hours agorootparent;; ANSWER SECTION: mgmresorts.com. 300 IN MX 10 mgmresorts-com.mail.protection.outlook.com.Outlook handles their email. reply mixdup 14 hours agoparentprevalmost certainly just a random&#x2F;typical ransomware attack, not a specific target at them because they&#x27;re a casino reply abathur 14 hours agoprevTake w&#x2F; requisite salt, but per Daily Mail [1]:> Thousands of guests at MGM Resorts in the Las Vegas strip have been locked out of their hotel rooms after the company was hit with a cyber attack, according to reports.> MGM Resorts International has about 48,000 rooms on The Strip. The company&#x27;s properties include Mandalay Bay, the Bellagio, Luxor and MGM Grand, among others.> The outage, first detected on Sunday night, has affected company emails, reservations, booking, room keys and casino slot machines.[1]: https:&#x2F;&#x2F;www.dailymail.co.uk&#x2F;news&#x2F;article-12505921&#x2F;MGM-Resort... reply OscarTheGrinch 55 minutes agoparentSo it would be the perfect time to assemble a team of misfits and attempt a madcap heist? reply lainga 14 hours agoparentprevHow do those hotel door locks work? When I had an apartment with a tap keyfob, it was battery-operated and the fob seemed to be programmed for that specific lock, so I thought they could work offline. reply napoleongl 14 hours agorootparentThese days the locks are online so that you can block a lost keycard from the front desk. Previously you had to open the lock with a never keycard than the lost one to make the lost one inoperable. That works kinda fine in a small hotel but not when you 48000 rooms with millionaires in them. reply foota 12 hours agorootparentFwiw you could probably build this in a way that it continues to operate without internet. This creates a new attack vector (disable the internet and you can&#x27;t revoke access) but that&#x27;s probably acceptable given the physical attacks possible. reply amenghra 12 hours agorootparentEach key gets a revision number. When the first set of keys are created, they get revision number 0. The lock records a high water mark of the revision numbers it has seen. Only keys matching the water mark get to unlock the door.When you want to revoke a key, you re-issue a new set with a higher revision number. When the guest checks out, you issue the next revision number to the next guest, effectively disabling the previous set.You do all this as a fallback when the network fails. This way, you can still disable keys in real-time when people checkout of their room. reply nijave 9 hours agorootparentDoes this use something like asymmetric keys so door can verify a key came from the issuing system or is there still some online&#x2F;network portion?Assuming it does use asymmetric keys to prevent someone from creating counterfeit access cards, there would still be a window (if the network is unavailable) where the old key would continue to work until a new key is scanned the first time on the door lock? reply themerone 11 hours agorootparentprevI think this is similar to how most hotel locks work. reply ryukoposting 6 hours agorootparentCurrently at a reasonably-priced hotel in the boonies. Extended my stay the other day and they had to re-issue the keys. The keys must be aware of the reservation period, and the locks must be aware of the current wall-clock time. Finding a way to tamper with the RTC in the lock could blow up the whole system. Or, you know, a crowbar. reply foota 1 hour agorootparentI don&#x27;t think a crowbar attack will work in this case, I doubt you&#x27;ll be able to get the lock to talk. &#x2F;s replydarkclouds 9 hours agorootparentprevSame tech they use for staff in mental health hospitals and wards, but strangely noone hacks the mental health hospitals. reply alwaysrunning 12 hours agorootparentprevI did a project several years ago for mgm that involved BT, player cards, key systems, wifi, etc and I can confirm they hotel locks are controlled centrally for various reasons. reply willcipriano 12 hours agorootparentI would&#x27;ve thought it would get sent messages like:And it would keep track internally so that if the central system went down it could still function with already issued keys until it is fixed. reply TylerE 12 hours agorootparentSuch a system seems like it would be incredibly fragile to local attack - and this is one case where you can&#x27;t just assume \"physical access means you&#x27;ve already lost\". reply willcipriano 12 hours agorootparent> physical access means you&#x27;ve already lostI agree, thats why I figured if you can get away with fooling around with a lock, some wires and a laptop in the hallway, you can probably pick the backup key more discreetly. reply caol 13 hours agorootparentprevMGM hotel rooms can be unlocked with smartphone NFC tap. You don&#x27;t even need to visit the front desk to check in, just log in to the app. But if you can&#x27;t open the app you can&#x27;t get in your room. I&#x27;m guessing the front desk can issue keys to a guest in the event they lost their phone or something, but if the network is down for the front desk too then they might not be able to issue keys. reply bee_rider 13 hours agorootparentWe often make fun of IOT and unnecessary app stuff, but these features 1000% make sense. reply mason55 10 hours agorootparentThe problem is it works badly. You have to open the app which has to load and then you can get access to your key. But if you’re on an elevator then you might not have service and the app won’t load and then you can’t get to your key to use the elevator. Or worse if you don’t have great service in the corridor.It needs to work in a way where the key is saved to your phone so it can be accessed quickly and offline. reply nijave 9 hours agorootparentAfaik the HID Global app saves a key in the OS key store (at least on Android) and uses the locally stored key with NFC so you just need network access to enroll a key. Not sure what vendor&#x2F;app these things use (maybe it&#x27;s all in house) reply lotsofpulp 9 hours agorootparentprevI would have thought apple&#x2F;google wallet already have an API for this. reply mcpherrinm 5 hours agorootparentSome hotel chains like Hyatt support nfc keys in Apple Wallet. Because whatever microcontroller runs that is low-power, it can continue working after your phone battery is (nearly) dead too.I know other locks use Bluetooth from an app which isn’t supported by Apple Wallet. replywolverine876 12 hours agorootparentprevI was wondering the same. It would be an extreme fire hazard if a power or computer outage made the doors unopenable - especially because a fire could and likely would cause an outage. reply StevenXC 11 hours agorootparentI once was stuck in my hotel room due to a malfunction in the inside door handle, which was an annoying way to discover that the latch wasn&#x27;t even mechanical on that side. reply squeaky-clean 11 hours agorootparentI work in \"access control\" and that could probably get that hotel in a loooot of trouble with the fire marshal. reply callalex 10 hours agorootparentprevWhat country was that in? reply gymbeaux 12 hours agorootparentprevYou can get from your room to the parking lot without a key at the MGM Grand. I’m sure it’s the same for all others per I assume the fire code. reply vel0city 7 hours agorootparentprevThe doors can always open out they just lock to not allow in. In a fire nobody needs a key to leave, but they might need a key to get back in. reply wolverine876 4 hours agorootparentWhat if the fire is in the hallway, or your kids are in the room? reply MathMonkeyMan 11 hours agorootparentprevpresumably you can still open them from the inside reply wombat-man 14 hours agorootparentprevYours is probably meant to work indefinitely. I guess hotels look at the card id and see if you have access at that moment. reply _joel 14 hours agorootparentprevApartment? I assume your home? The upkeep of locks in a hotel is a bit more involved, as customers lose keys and they need to be reset for the next room guest (for larger hotels, at least) reply glitchc 14 hours agorootparentprevIn a modern hotel with tap cards, all the locks are wired to a central system. reply gymbeaux 12 hours agoparentprevOver the years, MGM has bought up hotel-casinos on the Strip, and now they own most of ‘em. If you’re staying on the Strip, odds are it’s an MGM hotel. reply squeaky-clean 11 hours agorootparentIf it&#x27;s not MGM it&#x27;s Caesar&#x27;s. And both MGM and Caesar&#x27;s are owned by VICI Properties. reply andy800 11 hours agorootparentThe companies themselves are not owned by VICI, the land and properties are, and Caesars and MGM (and other casino operators) pay VICI rent. reply lotsofpulp 10 hours agorootparentThe margins are amazing:https:&#x2F;&#x2F;www.macrotrends.net&#x2F;stocks&#x2F;charts&#x2F;VICI&#x2F;vici-properti...https:&#x2F;&#x2F;www.macrotrends.net&#x2F;stocks&#x2F;charts&#x2F;VICI&#x2F;vici-properti...https:&#x2F;&#x2F;www.macrotrends.net&#x2F;stocks&#x2F;charts&#x2F;VICI&#x2F;vici-properti...Wonder if VICI assets are protected from having underfunded pensions of casino employee unions. reply reducesuffering 11 hours agorootparentprevhttps:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Vici_Properties#PropertiesInsane. Who is competing with them on the Las Vegas Strip? Just Blackstone with Bellagio, Cosmo, and Aria? Those investors have the power to have practically all properties on the strip not compete with each other. reply andy800 11 hours agorootparentMGM operates all 3 of those reply sjm-lbm 10 hours agorootparentprevWynn is still independent (I think). That&#x27;s the only one I can think of, though. reply borski 11 hours agorootparentprevOr Caesar&#x27;s. reply OscarTheGrinch 4 hours agoparentprevSo it would be the perfect time to assemble a team of misfits and attempt madcap heist? reply swozey 10 hours agoparentprevGood god, 48 THOUSAND rooms?? reply spdustin 13 hours agoparentprevThat story literally copied&#x2F;pasted from 8NewsNow [0][0]: https:&#x2F;&#x2F;www.8newsnow.com&#x2F;news&#x2F;local-news&#x2F;mgm-resorts-release... reply AlotOfReading 12 hours agorootparentThey almost certainly got the story from the same wire service rather than copying from each other. reply codex_irl 16 hours agoprevRelated discussion https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;vegas&#x2F;comments&#x2F;16fz1d3&#x2F;mgm_has_been... reply nhggfu 5 hours agoprevlots of igaming hacks of late.other notables: Australia&#x27;s crown resorts was hacked a while back (March 2023) https:&#x2F;&#x2F;gamblingindustrynews.com&#x2F;news&#x2F;australia&#x2F;crown-potent...Last week stake.com was hacked https:&#x2F;&#x2F;gamblingindustrynews.com&#x2F;news&#x2F;technology&#x2F;stake-com-4... (apparently by Lazarus group according to FBI https:&#x2F;&#x2F;www.fbi.gov&#x2F;news&#x2F;press-releases&#x2F;fbi-identifies-lazar... ) reply RyanAdamas 14 hours agoprevDoes somebody have a magnetron? reply karaterobot 15 hours agoprevThe linked article is down, here&#x27;s an archive https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20230911174437&#x2F;https:&#x2F;&#x2F;www.casin...Though the article itself says details are scant, so it&#x27;s just going to be speculation. I&#x27;d love to know what happened though. reply Animats 12 hours agoprevAlmost all news available is an echo of the press release. Not much real info. reply hnburnsy 6 hours agoprevRumors that Ceasars was hit last week...https:&#x2F;&#x2F;www.casino.org&#x2F;vitalvegas&#x2F;mgm-resorts-receives-colos... reply VFIT7CTO77TOC 10 hours agoprevReminds me of https:&#x2F;&#x2F;money.cnn.com&#x2F;2015&#x2F;02&#x2F;27&#x2F;technology&#x2F;security&#x2F;iran-ha... reply tunnuz 15 hours agoprevMakes me think of the Sony hack by the Lazarus Group. reply nosmokewhereiam 14 hours agoparentAllegedly due to the release of a movie. I&#x27;d assume this MGM resort is extortion&#x2F;DOS....which doesn&#x27;t eliminate them. Recent visits and timing would be impeccable.Every day they are down is $$$$$$ reply monksy 10 hours agoprevThis is the same group that brought in face recognition, and needlessly detailed data keeping on every customer and we&#x27;re expected to trust them .. right? reply tpmx 14 hours agoprevI&#x27;m currently rewatching the Las Vegas (2003) NBC TV series (the one with James Caan, Josh Duhamel, James Lesure, Molly Sims, Nikki Cox, Vanessa Marcil etc). Feels on-brand; like every second ep is about some fantastic heist.It&#x27;s worth rewatching as a guilty pleasure, IMO. Feels quite alien compared to current fare. It&#x27;s dumb but well-crafted, fun and glitzy and never takes itself too seriously. I miss that kind of show.Surprisingly high production values for the time. It&#x27;s available in 1080p with decent quality, somehow. reply toast0 11 hours agoparentHDTV (ATSC) was available in 1998 in the US[1]; consumer uptake wasn&#x27;t much until close to the shutdown of analog broadcasting, but it was out there. NBC broadcasts in 1080i, so it&#x27;s not terribly surprising that they recorded it in a way that would look good on 1080p. I can&#x27;t find anything saying exactly how it was recorded, but it wasn&#x27;t uncommon to film in 1080p&#x2F;24 and broadcast with 3:2 pulldown. That kind of content will look great as 1080p obviously; but if it was recorded at 1080i, a professional deinterlacing will look pretty good too.[1] https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20140924040947&#x2F;http:&#x2F;&#x2F;www.highbe... reply thakoppno 6 hours agorootparentHDTV (ATSC) is a technology that has influenced my life in pretty serious ways. My first tuner was a Sony SAT-HD100[0] in 2001. Witnessing the transition into digital TV through my VGA port, in retrospect, taught me tons about how technology adoption, development, and standardization actually works in the real world.[0] https:&#x2F;&#x2F;www.crutchfield.com&#x2F;S-9Pd3SuUnpX0&#x2F;p_158STHD100&#x2F;Sony-... reply jdofaz 10 hours agorootparentprevI think I started watching that show because it was in HD reply therealcamino 9 hours agoparentprevI don&#x27;t know anything about this particular show, but lots of programs were shot on film, and could just be scanned at higher resolution once HD video standards existed. reply FearNotDaniel 3 hours agorootparent> justUnfortunately there&#x27;s a lot of post-production steps that take place between the original film and the finished show. Since the 90s&#x2F;noughties many of those steps take place in digital systems after the film has been scanned at the chosen resolution. Here&#x27;s some detail specific to Babylon 5 and HD conversion, for example:https:&#x2F;&#x2F;www.engadget.com&#x2F;2018-06-22-babylon-5-digital-video-... reply plasticsoprano 14 hours agoparentprevEd Deline would never allow such as thing. Mike would most certainly be on it. reply bigbillheck 14 hours agoprev [–] If they&#x27;re going to shut something down, better a casino than anywhere else. reply allenrb 12 hours agoparent [–] Was just coming here to say it: And nothing of value was lost. reply andy800 10 hours agorootparent [–] Your opinion is valid, however I&#x27;m currently on a plane heading there, likely a third of the passengers won&#x27;t be able to check into their hotel. Same with dozens of planes. Kinda sucks for them. reply dylanz 9 hours agorootparentI live in Vegas and it also sucks for all the local MGM employees that are getting called in to have to deal it. That said, I hope things get figured out and your trip goes well! reply andy800 8 hours agorootparentI&#x27;ll be fine, thanks. The context from allenrb is that casinos have no value to society, so that eliminating them (and therefore all the related jobs) is not a loss to anyone. That includes the employees you are referring to in your comment, and without much regard for the people heading there for a vacation. reply allenrb 10 hours agorootparentprev [–] That will suck for sure. Hopefully they’ll be handing out some form of compensatory goodies to make up for it a bit. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "MGM Resorts International has suffered a cybersecurity attack causing a disruption to their system, affecting various IT assets such as mobile apps, credit card machines, and reservation systems.",
      "The specifics of the attack including the possibility of a ransom demand are yet to be clarified.",
      "Neither the company's operations in Macau, China are impacted by this incident nor is it the first of such occurrences, as MGM Resorts underwent a similar data attack in 2019."
    ],
    "commentSummary": [
      "MGM Resorts is currently experiencing a system outage due to a cybersecurity attack which has impacted services such as their app, ATMs, and kiosks.",
      "The details and consequences of the attack are still being investigated, however, it is speculated that it could be linked to the upcoming F1 races happening in Las Vegas.",
      "The company is working with specialists and law enforcement to handle this issue, but the incident has already caused considerable disruption for both guests and staff, causing worries about compensation for those affected."
    ],
    "points": 184,
    "commentCount": 99,
    "retryCount": 0,
    "time": 1694454257
  },
  {
    "id": 37465185,
    "title": "Removing garbage collection from the Rust language (2013)",
    "originLink": "http://pcwalton.github.io/_posts/2013-06-02-removing-garbage-collection-from-the-rust-language.html",
    "originBody": "pcwalton pcwalton's blog Home Removing Garbage Collection From the Rust Language Patrick Walton · June 2, 2013 I've been floating ways to simplify the memory management story in Rust around the core team lately. Memory management is a contentious topic, since we've worked hard to get to the current state of things, and with the push toward stability lately, there is a (quite reasonable!) resistance to any changes at this state. Still, I think the current memory management story in Rust is worth revisiting, as the current state of things may cause us problems down the line. Working with Dave Herman and Niko Matsakis, I've formulated a fairly concrete proposal at this point. The basic idea is to remove garbage collection from the core language and relegate it to the standard library, with a minimal set of language hooks in place to allow for flexible, pluggable automatic memory management. This post is designed to explain the \"why\", not the \"how\"—I'm leaving the concrete details of the proposed system to a future blog post or mailing list discussion. Rather, this explains the issue that I see with the current system. I think that the garbage collection story as it stands in Rust is not quite ideal, for three reasons: familiarity, simplicity, and flexibility. I'll cover each in turn. Familiarity One of the most common questions almost every Rust beginner asks is \"when do I use managed pointers, and when do I use owned pointers?\" Or, more simply, \"what are all these ~ and @ symbols everywhere?\" Having worked on Rust for many years now, I've seen several reasons for the difficulty. Chief among them are: The difference between the stack and the heap is a difficult concept to grasp for many programmers used to languages like Java that don't make such a distinction. This is, unfortunately, a fundamental difficulty of working in a systems language. There's little that can be done about this without taking control of allocation out of the hands of the programmer. Doing that, however, would compromise the goals of the language—in low-level, performance-critical programming, being able to precisely control whether allocations occur on the stack or on the heap is crucial. The sigils make the code unfamiliar before the concepts are learned. Unlike the rest of the punctuation in Rust, ~ and @ are not part of the standard repertoire of punctuation in C-like languages, and as a result the language can seem intimidating. One of the benefits of keywords is that they are self-documenting in a way that punctuation is not. This could be fixed by switching to keywords, which I prefer for this reason; however, syntactic beauty is in the eye of the beholder and so I won't lose sleep over this not changing if the community prefers the current syntax. There are two heaps, not just one, so beginners are confused as to which one to allocate into. This is a result of the \"minimize sharing by default\" philosophy of the concurrency system. However, the concurrency system has been part of the library rather than the language for several years now, so this seems somewhat out of place. Programmers don't know which to use, since some operations are available with ~ and some operations are available with @. Actually, we were confused on this point for a long time as well—it wasn't clear whether ~ or @ would become dominant. We debated for a long time which to present first, ~ or @. However, as the language and community evolved, and coding standards became more settled, a clear winner emerged: the owning pointer ~. In practice, the rule has been that programmers should use ~ to allocate in all circumstances except when they have no way of knowing precisely when the object in question should be freed. Point (4), to me, is the most critical. The rule that emerged—~ over @—should not be surprising, in retrospect, as it is how systems software has been developed for decades. The key insight that was missing is that the owning pointer ~ is just the Rust equivalent of malloc and free. For many, probably most C programs, malloc and free are just fine (assuming you use them correctly, of course); each heap allocation is allocated in just one place and destroyed in just one place. Only when the lifetimes of objects become very complex do C and C++ programmers resort to manual reference counting to determine when an object should be freed (and many, perhaps most, C programs never get there). This is the role that has emerged for @ in Rust programs: @ is a replacement for manual reference counting in C programs. The kobject system in the Linux kernel, the GObject system in glib, and so forth, are the C equivalents of @ in Rust. The key point here is that these are very specialized use cases in C, and @ has been relegated to a similarly marginal role in idiomatic Rust code. We thought for a while that many Rust programs would use @ extensively and that it would ease the learning curve for those not used to destructor-based memory management and references. This has not, however, been the case in practice. In reality, since the libraries all use owning pointers (~), Rust programmers have to learn them quickly anyhow. And once Rust programmers learn how to use ~ effectively, they quickly find @ relegated to a marginal role, if it's used at all. ~ has so many advantages: deterministic allocation and destruction, interaction with the standard library, freedom from GC marking pauses, simpler semantics, appendability where vectors and strings are concerned, and sendability across tasks. I think we're better off teaching ~ as the go-to solution for most programs and relegating @ to a specialized role. @ has its use cases, to be sure; large, event-driven C++ programs use reference counting for a reason. But those use cases are specialized. Beginners should not be asking \"should I use ~ or @?\" The answer is almost always ~. In this regard relegating @ to a library is just the natural conclusion of this approach. I feel that what beginners should be taught is that ~ is the way to allocate in Rust, and letting an ~ owning pointer go out of scope is the way you free in Rust. This is what we should be teaching in the language tutorial. As beginners become more comfortable with this and explore the libraries, they will learn about ways to achieve more dynamic memory management: tracing garbage collection with the Gc type, reference counting with the Rc type, and thread-safe reference counting with the Arc type. But by building only ~ into the language, we can reduce confusion by, in effect, making the language more opinionated. Simplicity Although Rust didn't start out that way, one of the most interesting applications of Rust has been very low-level programming, even down to the level of kernels. The interest in this application of Rust was something of a surprise to us, but in hindsight it makes perfect sense. Low-level control over memory management isn't something that most applications software, especially on the server side, wants; most of that software has migrated over to languages like Java, Ruby, and JavaScript that trade control and performance for convenience by making memory management automatically, and dynamically, managed by the runtime. The remaining class of software, most of which is written in C and C++, is software that must manage memory manually in order to achieve some combination of performance, simplicity, and/or the ability to self-host. The prospect of using a new language for this class of software, which includes OS kernels, game engines, and browser engines among others, is what is fueling the growth of the nascent Rust community. It might be possible to create a language that presents only a simple, fully automatic memory management system at first, and which surfaces the machinery of safe manual memory management* only when the programmer requires it for maximum performance. This would ease the learning curve, as programmers would be able to write many, perhaps most programs without ever learning how to manage memory at all. However, at this point I don't think that this language exists yet, and in particular I don't think Rust is that language. There are basically two problems here: (1) ~ owning pointers are everywhere in Rust, from the standard library to the built-in macros, making learning about them a necessity from the get-go; and (2) it is basically impossible to program Rust without at least a cursory understanding of references (a.k.a. & pointers) and their lifetime semantics; even vec::each() uses references. Despite the fact that this might seem like a negative result, I actually think it's quite positive for the project. It helps to define the project's scope. I don't think automatic memory management in Rust is ever going to be as convenient as memory management in, say, Ruby or Java, and that's OK! The same level of control that adds cognitive overhead to memory management in Rust compared to other languages also makes Rust able to go where few other industry languages have. This space, I think, is where Rust can really shine. In short, I think that Rust as a language should focus on roughly the same application domain as C++ does.† Important to this effort is to have as small of a runtime as possible, just as C++ does, leaving higher-level abstractions to libraries. And, in fact, we are almost there already. The only runtime support that compiled Rust programs require are a small set of \"language items\", which are magic functions or traits written in Rust that are known to the compiler. Looking at the set of language items, and disqualifying legacy items that will be removed soon such as annihilate and log_type, there are just a few categories: Operator traits, like Add and Sub. These are analogous to operator+, operator-, and so forth in C++. Memory primitives, like str_eq. These are somewhat legacy at this point and probably could be converted to LLVM intrinsics like memcmp without much trouble, especially after dynamically sized types happens. In any case, in most C++ compilers memcmp and friends are builtins. Failure: fail and fail_bounds_check. This is analogous to throw in C++, although a Rust program that doesn't want to use stack unwinding might want to use abort instead (which would be like -fno-exceptions) or do something more elaborate like the Linux kernel's \"oops\" functionality. Allocation primitives malloc and free. These have direct C++ equivalents: operator new and operator delete. Garbage collection primitives. Of these, the only language items that don't have direct C++ equivalents are the garbage collection primitives. If those were eliminated, then Rust as a language would be every bit as freestanding as C++ is. In terms of suitability for kernel and embedded development, Rust would be on truly equal footing. In summary: (1) all Rust programmers have to know how ~ and & work, despite the presence of @; (2) the only additional runtime primitives that Rust exposes and C++ doesn't are those related to @. Flexibility When it comes to memory management, there are obviously many different strategies: stack allocation, heap allocation with malloc and free, arena allocation, and garbage collection. What's less well known is that even among garbage collection, there are many different approaches, each with advantages and disadvantages. There's thread-local GC, thread-safe GC, incremental GC, generational GC, reference counting, thread-safe reference counting, deferred reference counting, ulterior reference counting—the list goes on and on. (For a good survey of automatic memory management techniques and how they relate to one another, check out \"A Unified Theory of Garbage Collection\" by Bacon et al.) A program that wants to maximize performance among some axis (latency versus throughput) and remain safe with objects with complex lifetimes may have reasons to choose one or the other. Specifically, there's the perennial debate between reference counting and tracing garbage collection. Many applications are better with tracing GC because of the increased throughput it provides and straightforward handling of cycles, and many applications are better with reference counting because of implementation simplicity, cache behavior, mostly-incremental operation, and promptness of deallocation. It makes sense for applications to be able to choose between the two. Even more important is the tradeoff between thread-safe and thread-local garbage collection: concurrent garbage collection is practically always more expensive than thread-local garbage collection, so it makes sense for programs to restrict concurrent GC (including atomic reference counting) to be used only when needed. Integrating multiple tracing garbage collectors or cycle collectors into one system is a hard problem, and I don't think Rust is going to really solve it. However, integrating reference counting into a garbage collected system is straightforward, as long as cycles are not created (and in Rust we can forbid the creation of such cycles through clever use of the type system). In practice this seems to work well: we typically use thread-local tracing GC for data with complex lifetimes within one task, and we use thread-safe reference counting for data that must be shared between tasks. Equally important is the ability to integrate with external garbage collection systems (usually reference counted ones). This is a problem that is often overlooked, but is terribly important for client software such as mobile apps and browser engines. On Windows, apps must integrate with the reference-counted COM system in order to use DirectX and other APIs. On the Mac and on iOS, apps have to integrate with Objective-C and the closely-related Core Foundation, also reference-counted systems. On Linux, GNOME apps have to integrate with GObject, again a reference-counted system. On Android, apps have to integrate with the garbage-collected Dalvik subsystem via the JNI. All of this requires that the memory management system in the language be deeply flexible. Because of this, I'm suspect of blessing any particular form of automatic memory management in the core language. In Rust, the @ type is not only blessed with special syntax, but is eligible for borrowing and other operations in a way that user-defined types aren't. Although Rust provides the facilities needed to build practically all the other forms of garbage collection, as well as those needed to integrate with external GC systems in a safe way, the resulting smart pointers feel second-class compared to @. A systems language designed to work in a diverse set of environments should have the flexibility to create memory management abstractions that feel first-class. Conclusion For these three reasons—familiarity, simplicity, and flexibility—I'd like to propose removing @ pointers from the language and replacing them with a small set of hooks allowing the same functionality to be implemented as a library and on user-defined types. We would ship tracing GC as part of the standard library and make it just as powerful and convenient as it is today (except for the @ syntax). We'd gain a flexible set of abstractions, make the language easier to learn, and make Rust into a truly freestanding language environment. * Note that the safe qualifier here disqualifies manually-built free lists in garbage-collected languages, as these manually-built free lists provide no protection against errors like double \"frees\", leaks, and danging pointers. (They're significantly worse than true manual memory management anyhow; the GC still has to trace through objects in arenas at mark time, copy the objects within out into the tenured generation when they survive a minor collection, write barrier the objects, and so forth.) † Note that I don't mean you shouldn't write Web frameworks and Web sites in Rust: in fact, I think Rust would be a fantastic language for many classes of Web server software, especially that which must scale to the highest loads and squeeze every ounce of performance out of the servers on the racks. Share: Twitter, Facebook",
    "commentLink": "https://news.ycombinator.com/item?id=37465185",
    "commentBody": "Removing garbage collection from the Rust language (2013)Hacker NewspastloginRemoving garbage collection from the Rust language (2013) (pcwalton.github.io) 178 points by mattrighetti 1 day ago| hidepastfavorite201 comments orf 23 hours agoRust has had an interesting and probably pretty unique story, moving from a GC’d language with a runtime + green threads[1] to what it is today.They are treading a line that is uniquely difficult to tread, and I think it’s mostly working. Async is still a bit of a mess but it seems that’s because it’s inherent to the constraints they had to impose on themselves.It’s kind of cool that I can use Async stuff in embedded devices[1] and a web app, even if I do get frustrated with mind-numbing Async issues from time to time.1. https:&#x2F;&#x2F;github.com&#x2F;rust-lang&#x2F;rfcs&#x2F;pull&#x2F;2302. https:&#x2F;&#x2F;embassy.dev&#x2F; reply ekidd 22 hours agoparent> even if I do get frustrated with mind-numbing Async issues from time to time.A noticeable portion of async issues come from the fact that a lot of people use Tokio&#x27;s multithreaded async runtime. Tokio allows you to mix async and native theads, which is both a virtuoso technical accomplishment and also a bit ridiculous.If you use Tokio&#x27;s single-threaded runtime, things get simpler.The remaining async challenges are mostly the usual \"Rust tax\", turned up to 11. Rust wants you to be painfully aware that memory allocations are expensive and that sharing memory in a complex concurrent system is risky.In sync Rust, the usual advice is \"Don&#x27;t get too tricky with lifetimes. Use `clone` when you need to.\"In async Rust without native threads, the rules are something like:1. Boxing your futures only costs you a heap allocation, and it vastly simplifies many things.2. If you want a future to remain around while you do other stuff, have it take ownership of all its parameters.Where people get in the most trouble is when they say, \"I want to mix green threads and OS threads willy-nilly, and I want to go to heroic lengths to never call `malloc`.\" Rust makes that approach look far too tempting. And worse, it requires you to understand and decide whether you&#x27;re taking that approach.But if you remember \"Box more futures, own more parameters, and consider using a single-threaded runtime\" then async Rust offers some pretty unique features in exchange for a pretty manageable amount of pain.Also, seriously, more people should consider Kotlin. It has many Rust-like features, but it has a GC. And you don&#x27;t need to be constantly aware of the tradeoffs between allocation and sharing, if that&#x27;s not a thing you actually care about. reply ReactiveJelly 21 hours agorootparentMaybe I should try smol instead of Tokio. I&#x27;m guessing a lot of libraries are made to fit with Tokio, but I imagine for a typical desktop app, a multi-threaded runtime is total overkill. Plus I could just run multiple runtimes if I want.Like I suppose if I needed a blocking task that was also async, I could send that to a thread pool and then internally spawn a worker async runtime. It&#x27;s a thinker. reply swsieber 19 hours agorootparentA single threaded Tokio runtime still has a separate thread pool for heavy tasks. Maybe block_on? I can&#x27;t remember where I read that tho.Edit: not block_on, but spawn_blocking. See https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;rust&#x2F;comments&#x2F;16ebdi1&#x2F;comment&#x2F;jzy7f... reply eska 20 hours agorootparentprevNo need to switch. Just change the tokio flags reply masklinn 1 hour agorootparentThat does not actually do anything. All Tokio APIs which demand Send closures on the MT runtime still do on the ST runtime, because the runtime flavour is not part of the API. reply Klonoar 20 hours agorootparentprevOr, you know, that single threaded runtime that OP just mentioned. ;P reply masklinn 19 hours agorootparentprev> If you use Tokio&#x27;s single-threaded runtime, things get simpler.A major issue when dealing with the tokio runtime is Send bounds requirements, I don’t think the single-threaded runtime changes anything because these are API-level issues. You can use spawn_local to avoid migrations but you can do that on the multithreaded runtime just as well.And then a lot of tools and libraries which get layered over tokio (or assume a tokio environment) will require send futures anyway. reply phamilton 19 hours agorootparentLocalSet does not require Send. https:&#x2F;&#x2F;docs.rs&#x2F;tokio&#x2F;latest&#x2F;tokio&#x2F;task&#x2F;struct.LocalSet.htmlEDIT: Sorry to join in the multiple responses. Clarity for others: \"current_thread\" by itself does not relax Send, and many libraries aren&#x27;t configurable to make everything use LocalSet. reply masklinn 16 hours agorootparentI mentioned spawn_local, which is basically the same feature as localset (you can only spawn_local within the scope of a localset). reply necubi 16 hours agorootparentprevThat&#x27;s incorrect, the Send bounds are only there in the multithreaded runtime (because it might need to Send a task across threads). The single threaded runtime will never do that, so its futures don&#x27;t need to be Send.Somewhat relatedly, a major (early) stumbling block for me with the multithreaded runtime was trying to keep references across await points. While boxing them is always an option, things also got much easier when I realized that while &T is only Send if T is sync, _&mut T is send if T is send_. reply masklinn 16 hours agorootparent> That&#x27;s incorrectIs it?> the Send bounds are only there in the multithreaded runtime (because it might need to Send a task across threads).Tokio is interacted with using free functions which dynamically look up the current runtime, they could not have a different signature even if tokio had different runtime types, which it does not.> The single threaded runtime will never do that, so its futures don&#x27;t need to be Send.Please do point to the ?Send spawn (not spawn_local) which supposedly exists for the current_thread runtime. You can&#x27;t even spawn_local at the toplevel of the current_thread runtime. reply bryanlarsen 18 hours agorootparentprevUnless I&#x27;m mistaken, switching to a single threaded tokio runtime made Send requirements go away for me. reply veber-alex 18 hours agorootparentChanging the type of runtime doesn&#x27;t change the API at all.Even in a single threaded runtime spawn requires Send and you need to use LocalSet + spawn_local for !Send futures. reply bryanlarsen 18 hours agorootparentI wasn&#x27;t using spawn. It&#x27;s an I&#x2F;O bound program with a big select! loop at it&#x27;s core. Rust spit out errors about Send and I made them go away by switching to flavor = \"current_thread\". reply masklinn 16 hours agorootparentWould be nice if you could find it again, because from what I know of tokio I&#x27;d assume you made other unrelated changes which fixed the issue: tokio only has one runtime type, the flavour&#x27;s effects are internal, the top-level future (run by Runtime::block_on) is always !Send, but from that you can only run Send futures (via spawn and spawn_blocking), unless you create a LocalSet.current_thread doesn&#x27;t even create an implicit LocalSet, if you try to `spawn_local` from the top-level of a current_thread runtime you get a panic, exactly like a multi_thread runtime. reply veber-alex 18 hours agorootparentprevWhat&#x27;s the problem with Send bounds? So you use Arc instead of Rc. reply masklinn 18 hours agorootparentThe main problem is that for a future to be send, everything held across an await point has to be Send. Which is quite constraining and annoying, especially because this often does not play well with trait objects or `impl Trait` as people will commonly not think to add trait extra trait bounds.And of course it&#x27;s an accumulation of trait bounds on everything, which makes for a downgrade in readability. reply aeturnum 16 hours agorootparentprev> If you use Tokio&#x27;s single-threaded runtime, things get simpler.I don&#x27;t do a lot of low level work, but coming out of Elixir &#x2F; Erlang I would expect a greenlet system to manage the # of threads based on the hardware its running on. I.e. not single threaded or \"you manage the threads too\" but \"a standard piece of code spreads your greenlet processes between N managed hardware threads where N is determined by hardware + settings.\" Is that not a thing that the Rust async libraries support? reply ekidd 22 minutes agorootparentElixir&#x2F;Erlang is actually a really interesting case, because:1. It has a garbage collector, and2. It relies even more heavily on immutable data than Rust.This means that the Beam VM can seamlessly move green threads around CPUs and preempt them at arbitrary points, all without breaking code. You never need to know who \"owns\" something, and you never need to worry about another process mutating it while you&#x27;re looking at it. The Beam VM is amazing.Tokio operates under different constraints: There&#x27;s no garbage collector, ownership can be \"lent\" to other code, and mutable state exists in a carefully controlled fashion. Despite this, Tokio absolutely supports spreading green threads across all your CPUs and moving them as needed using a work-stealing scheduler (IIRC). But this only works if all your closures are `Send` (safe to move between CPUs). And any closure that outlives the creating code must generally be `&#x27;static` (it does not refer to references borrowed from its creator&#x27;s scope).Oh, and Rust keeps trying create and manage your async & multithreaded processes without trying to allocate heap memory at all. Unless you explicitly ask it to allocate memory. Which you often should.It is totally possible to make your closures `Send + &#x27;static`. I maintain several production Rust programs which do that, no problem. But doing so requires understanding a moderate amount of Rust and paying a \"cognitive tax\" by making a bunch of extra decisions about how to represent things. And I think that cognitive tax is a unwise tradeoff for many problems and teams. But I&#x27;m still very happy with my async Rust projects, because they get a lot of value out of fast, memory-efficient async code. reply watermelon0 15 hours agorootparentprevBy default, Tokio uses multi-threaded runtime, but you can force it to use the single-threaded one: https:&#x2F;&#x2F;docs.rs&#x2F;tokio&#x2F;latest&#x2F;tokio&#x2F;attr.main.html#current-th... reply seabrookmx 15 hours agorootparentprev> consider KotlinOr C#. C# has async&#x2F;await (it originated there) and does have a multithreaded event loop, but due to having GC is just a lot easier to work with than Rust+Tokio.If you&#x27;re in the \"don&#x27;t colour my function\" camp, GoLang is also worth throwing in the mix. reply CharlieDigital 14 hours agorootparentC# is probably what most teams want but don&#x27;t know it. - Language is very, very similar to TypeScript. If you&#x27;re already doing TS on the backend with Node (or even JS), it&#x27;s a very small lift to C# - Very rich standard libraries and first party libraries; reduces the need to import a bunch of third party code - .NET minimal web APIs are very similar to Express now and perhaps even easier since you don&#x27;t need to import anything to get a microservice up and running - .NET AOT with .NET 8 will dramatically improve the cold-start for use cases like serverless functions (I find the cold start already pretty good with .NET 7 on Google Cloud Run with the CPU Boost feature turned on). - C# has a lot of functional features as a result of F# - Compiles fast and has hot reload via `dotnet watch` - Provides access to low level primitives where extra performance is needed reply seabrookmx 13 hours agorootparent100%.> NET AOT with .NET 8 will dramatically improve the cold-startDon&#x27;t get your hopes up on AOT. It still has lots of limitations, reflection being a big one. ASP.NET initialization relies heavily on reflection so it will be a while before we can have AOT compiled, HTTP microservices.> I find the cold start already pretty good with .NET 7 on Google Cloud RunThanks for the tip! We&#x27;re mostly using GKE but have a few services on Cloud Run that might benefit. Do you use the \"always allocate CPU\" option? We&#x27;re seeing some memory creep we suspect would be solved by giving the GC cycles when a request isn&#x27;t in flight. reply CharlieDigital 11 hours agorootparentnext [–]> ASP.NET initialization relies heavily on reflectionYes; the first thing I tried when .NET 7 went RTM was switch my web API over to AOT only to have it hang during build..NET 8 AOT is specifically focused on ASP.NET; they&#x27;ve switched over many of the reflection paths to use source generation instead. I have hopes that some time during the .NET 8 lifecycle or .NET 9 horizon, we&#x27;ll see full support: https:&#x2F;&#x2F;learn.microsoft.com&#x2F;en-us&#x2F;aspnet&#x2F;core&#x2F;fundamentals&#x2F;n... > Do you use the \"always allocate CPU\" option?With the CPU Boost option, the cold start is really, really good. Whether you need a warm instance is up to your own threshold for latency on cold starts. I generally avoid using \"always allocate CPU\" because I&#x27;m cheap.The magic of Google Cloud and Cloud Run is really that you don&#x27;t need to be always on. reply o11c 12 hours agorootparentprevDon&#x27;t forget: - unlike Java, C# supports value types so you can avoid gratuitous overhead or ugly code when all you need is a simple wrapperIt&#x27;s still painful when you need strict ownership though, except for the limited case of an object allocated directly on the stack. reply anacrolix 6 hours agorootparentprevAnd Haskell. The only 2 languages I know that got this right. reply bluejekyll 21 hours agorootparentprev> Tokio allows you to mix async and native theads, which is both a virtuoso technical accomplishment and also a bit ridiculous.Can you describe what issues you’re referring to? I use the multi-threaded Tokio runtime, I’ve not noticed any overhead with that in terms of development vs. single threaded. Also, multi-threaded async runtimes are generally what you want to make sure you don’t have any single tasks blocking others that could make progress in parallel. reply danenania 19 hours agorootparent\"Also, multi-threaded async runtimes are generally what you want to make sure you don’t have any single tasks blocking others that could make progress in parallel.\"Is there an advantage to multi-threaded async if you&#x27;re IO-bound? If you want a bunch of concurrent system calls or network requests it seems like single-threaded async can handle that pretty nicely ala Node.js. reply toast0 18 hours agorootparentDepends on your load, but many I&#x2F;O bound loads are bigger than what you can do in a single thread. reply foooorsyth 21 hours agorootparentprevIf you&#x27;re counting on people to drop down into a single-threaded runtime when using async constructs, you&#x27;ve really lost the mark. Parallelism is the user&#x27;s goal most of the time, right? Perhaps in web context to avoid runaway thread spawning and slow loris attacks it&#x27;s not (the main selling point of node.js), but otherwise people want to go fast.>Also, seriously, more people should consider Kotlin.I like Kotlin, but I find its coroutine machinations to be far more confusing that just plain threads (over which Java already had&#x2F;has some nice quality of life abstractions). And debugging broken Kotlin coroutine code is hell. You will not get a normal-looking stack trace when things go wrong. reply proto_lambda 20 hours agorootparentThe main goal of using async for me is to not have to handle all the IO wait state machines myself. It does a pretty good job of that, and as long as my program consists of a bunch of tasks concurrently waiting for IO to finish, a single thread is perfectly fine. reply felipellrocha 11 hours agorootparentprevTake the browser. It gets an incredible amount of performance out people’s devices even though 99% of javascript is bound to a single thread. The way they accomplish that is via their asynchronous architecture. So, not always. reply biorach 19 hours agorootparentprev> Parallelism is the user&#x27;s goal most of the time, right?I&#x27;m not sure you&#x27;re right about that. reply foooorsyth 17 hours agorootparentIn the general sense? Probably not. In the context of Rust users? It certainly begs the question: why use Rust if you aren&#x27;t going for speed? Just write it in Node&#x2F;Go&#x2F;JVM-lang if performance doesn&#x27;t matter and you just want an event loop that looks like threads. reply masklinn 22 hours agoparentprev> moving from a GC’d languageRust was never actually a GC’d language. It had a smart pointer called Gc (and before that @), but that was only ever implemented as refcounting (according to the changelogs some preliminary work had been done towards a precise GC but AFAIK there was no followup).This is in large part why it was dropped: it was technically redundant with Arc, and could give users the wrong impression, and could always be added back later if that made sense. reply pornel 20 hours agorootparentThe original design by Graydon envisioned a real GC, but one per task&#x2F;actor instead of global, with limited message passing between threads.http:&#x2F;&#x2F;venge.net&#x2F;graydon&#x2F;talks&#x2F;intro-talk-2.pdf reply masklinn 19 hours agorootparentMaybe but that was never actually a thing. It was not even a thing which got moved away from like type states or internat iterators, it never was. reply aidenn0 14 hours agorootparentprevIf that&#x27;s what had been created, I&#x27;d have been all over it like butter on toast. reply kaba0 12 hours agorootparentThere is pony or erlang that does something similar. reply aidenn0 12 hours agorootparentPony is already on my list of things to look at; you just bumped it up a couple of spaces. reply pjmlp 22 hours agorootparentprevTechnically from CS point of view, refcounting is a GC implementation algorithm. reply ryukoposting 21 hours agorootparentYes, but does that make circa-2013 Rust a \"garbage collected language?\" It seems to me that when we talk about GC&#x27;ed languages, we&#x27;re talking about languages where the heap is managed implicitly.If I understand it right, @ is explicitly invoked by the user, but the implementation is embedded within the language. With Arc&#x2F;Rc, there are Deref&#x2F;Drop implementations somewhere in the stdlib that do the reference counting. reply masklinn 22 hours agorootparentprevI fail to see what that has to do with anything, unless you’re asserting that current rust is GC’d on the back of arc existing. reply bmacho 16 hours agorootparentRust as a language is not GC&#x27;d, but has a refcounted (that is, GC&#x27;d) pointer type if you want&#x2F;need it. reply pjmlp 21 hours agorootparentprevIt has to do everything with the wording on your comment that kind of makes the usual lay man distinction between GC and refcounting, nothing to do with Arc, as using it is manual work anyway. reply Zambyte 19 hours agorootparentprevThe point of a garbage connector is to simulate infinite memory[0], which is the point of Arc. So current Rust has GC :)[0] https:&#x2F;&#x2F;octodon.social&#x2F;@cwebber&#x2F;110815313802832972 reply flohofwoe 20 hours agorootparentprevRefcounting is also just (dumb and slow) garbage collection though. reply masklinn 19 hours agorootparentThe main point is that rust was never a ref counted langage, it had a purportedly GC’d opt-in pointer type.And while refcounting has lower throughput than more advanced forms of garbage collection, it has a much higher reactivity &#x2F; lower memory overhead, and it integrates much better with other methods of resource management. reply rcarr 22 hours agoparentprevFor anyone interested there was a big discussion on async in rust a few days ago. Rust is on todo list to learn but I found reading some of these comments quite interesting:https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37435515 reply mplanchard 22 hours agorootparentNote also this rebuttal: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37448460As someone who works with async rust professionally, I wouldn’t let takes like the one you posted dissuade you. My personal opinion is that async rust is easier to work with than in most other languages because of the extra concurrency guarantees that rust gives you. There are some rough edges, but not nearly as many as the link you posted suggests. reply rcarr 12 hours agorootparentI wasn&#x27;t, I actually didn&#x27;t even read the attached article only the HN comments who seemed to mainly disagree with the article and mentioned quite a lot about the different approaches to async in Rust. I really want to learn it but prioritising up-skilling my DevOps capabilities at the minute so it will have to be next year. reply mplanchard 8 hours agorootparentGlad to hear it! I am ~2.5 years into my professional Rust career, ~4.5 years into working with the language, and it&#x27;s still my favorite. It&#x27;s certainly not the only great language out there, but it&#x27;s definitely one of them. reply littlestymaar 22 hours agorootparentprevThis exactly.Sure Async Rust requires you to learn a few new things, but the blog post is mostly a rant from someone not very familiar with the topic (like what you&#x27;d expect from something called “ is a bad language” TBH). reply sbt567 22 hours agoparentprevIs there any other languages that let you use async on embedded&#x2F;bare metal? I think Rust could learn from them. Especially on the ergonomics side. Otherwise, what Rust might currently do is blazing a trail through a forest. reply jamesmunns 18 hours agorootparentFrom a net-effect standpoint, Rust&#x27;s implementation of async&#x2F;await is fairly similar to protothreads, which were used even on smaller AVR and MSP430 targets where rtos threads weren&#x27;t practical.That being said, protothreads were implemented using wildly cursed C macros, and offered none of the safety guardrails that Rust has, nor the ergonomics, and had some insane constraints, like \"you can&#x27;t use local variables at all, only statics\" because like rust, they were stackless coroutines that meant you would have no control of the stack across await points.If you were VERY CAREFUL, you could get the same lightweight concurrency with almost the same fundamental model. Woe be on you if you ever had to debug though.edit - here&#x27;s a look at how protothreads were expanded: https:&#x2F;&#x2F;dunkels.com&#x2F;adam&#x2F;pt&#x2F;expansion.html reply kaba0 18 hours agorootparentprevWhat should it learn? If you combine async with Rust’s nested lifetimes, you get quite a bit of complexity from the borrowchecker, period. There is not much else to it. reply SeenNotHeard 17 hours agorootparentprevVala offers async&#x2F;yield and compiles down to native code (after being transpiled to C): https:&#x2F;&#x2F;wiki.gnome.org&#x2F;Projects&#x2F;Vala&#x2F;Tutorial#Asynchronous_M...More info: https:&#x2F;&#x2F;vala.dev&#x2F; reply marcosdumay 18 hours agorootparentprevThere is no other language that does what Rust is trying to do. But that is not \"using async on embedded&#x2F;bare metal\", this one is easy, jut use a garbage collector. reply brabel 17 hours agorootparentHm, I think Pony did try doing what Rust is doing, with an even more advanced system for \"borrows\" (there&#x27;s several types of borrow, not just two): https:&#x2F;&#x2F;www.ponylang.io&#x2F;Also, Vale is on the way: https:&#x2F;&#x2F;vale.dev&#x2F;And D is also working on it: https:&#x2F;&#x2F;dlang.org&#x2F;blog&#x2F;2019&#x2F;07&#x2F;15&#x2F;ownership-and-borrowing-in... reply FpUser 19 hours agorootparentprev>\"Is there any other languages that let you use async on embedded&#x2F;bare metal?\"So you do not know if there are and what kind and other important details.>\"I think Rust could learn from them.\"Yet you think reply chrismorgan 22 hours agoprevIt’s worth noting, given the aspirational conclusion, that @T managed pointers were actually equivalent to Rc, since they were only ever implemented with reference counting without cycle collection. (This would have changed had they stayed in the language, but winds changed instead.) The standard library doesn’t ship tracing GC, and it’s still not altogether clear how it would be best to do it. https:&#x2F;&#x2F;manishearth.github.io&#x2F;blog&#x2F;2021&#x2F;04&#x2F;05&#x2F;a-tour-of-safe... is useful further reading. I think it’s fair to say that the “ship tracing GC as part of the standard library” ship has sailed, but power and convenience could still warrant language&#x2F;standard library features to support it, though I doubt anything will ever happen, or at least in the next decade. The focus of the language shifted and was clarified quite a lot between the time of this article and even Rust 1.0 just under two years later. reply bunderbunder 20 hours agoprevWhat I increasingly want to see is a language where a garbage collector is optional in the main executable, but not (directly) available to library code.Because I want to have a language that I can use to write lean libraries that are available to any language with a C FFI, and that can be linked directly by AOT-compiled languages, without getting into a horrible quagmire of dueling heaps and copying. But I also want to have proper functional and asynchronous programming, and generally just to not have to manually fuss with memory in the higher-level code.Python and C&#x2F;C++&#x2F;Rust&#x2F;Cython&#x2F;etc extensions kindasorta achieves this, and it&#x27;s a huge factor in the language&#x27;s ascendance in scientific computing applications. Game development has a long history of achieving a similar effect by embedding Lua or Lisp. But I think that it might be more pleasant to have it formalized and baked into a single language. reply yjftsjthsd-h 19 hours agoparentI&#x27;m reminded of wuffs, which only allows writing libraries and explicitly doesn&#x27;t support allocateing memory, requiring the calling program to provide memory. It seemed like a nice separation of concerns in my non-expert view. (And then wuffs compiles to C, which is nice for interoperability) reply cpeterso 5 hours agorootparentI hadn’t seen wuffs before. Interesting approach to writing safe libraries:Wuffs is not a general purpose programming language. It is for writing libraries, not programs. Wuffs code is hermetic and can only compute (e.g. convert \"compressed bytes\" to \"decompressed bytes\"). It cannot make any syscalls (e.g. it has no ambient authority to read your files), implying that it cannot allocate or free memory (and is therefore trivially safe against things like memory leaks, use-after-frees and double-frees).https:&#x2F;&#x2F;github.com&#x2F;google&#x2F;wuffs reply AndrewDucker 19 hours agoparentprevPossibly Rust needs a GC wrapper type, which makes everything it contains garbage collectable. And then you could be bare metal, except when you want to not be. reply zozbot234 19 hours agorootparentThere are a number of efforts along these lines, the most interesting is probably Samsara https:&#x2F;&#x2F;github.com&#x2F;chc4&#x2F;samsara https:&#x2F;&#x2F;redvice.org&#x2F;2023&#x2F;samsara-garbage-collector&#x2F; which implements a concurrent, thread-safe GC with no global \"stop the world\" phase. replyvaylian 23 hours agoprevAnd only 2 years later Rust 1.0 was released with a borrow checker (which is not mentioned in the blog post). I think one of the reasons why Rust turned out to be so well-designed is that Rust has a very open development approach where people with many different experiences can share their wisdom. Many other languages follow the design of a few people, but Rust is really a language of the internet community. reply brabel 23 hours agoparentI don&#x27;t agree. Before Rust 1.0 the community was really, really tiny. I don&#x27;t have numbers but it was really a few people discussing the design issues... it was not like now where you literally have thousands of people with different incentives trying to force their views on things, which makes development go much slower than in the pre-1.0 days.I think the lesson is that, as with any software, having an open discussion between people who are on the same page about things and have similar incentives (with room for disagreements, as the initial author of Rust had plenty of) is greatly beneficial, without a doubt... but once you start getting people with polar opposite views on things, each backed by a substantial faction behind them, things start getting messy. I&#x27;m not saying this has happened in Rust, just that it&#x27;s not a case the more people, the merrier. reply lagniappe 20 hours agorootparentI&#x27;m sure it&#x27;d be different for everyone reading this, but for me this story reinforces my hunch that the BDFL model moves faster and satisfies more people, in the sense that its hard to design by committee and harder to satisfy everyone. reply tensor 20 hours agoparentprevI don&#x27;t feel that Rust is actually well designed. The borrow checker and lack of GC makes it well suited to the tasks that traditionally one would use C or C++ for, and it is definitely safer than those language.But in terms of overall design it doesn&#x27;t feel very cohesive, and priority is put in odd places. For example, error handling is an area where people almost always resort to 3rd party libraries. That, to me, having to rely on third party libraries for such basic features is a sign of a serious design flaw. Meanwhile, \"clever\" things like zero cost map and filter are prioritized and in the language for a long time.Overall it feels like a language that prioritizes \"clever\" features at the expense of boring but basic needs. Also any criticism is met with hostility rather than accommodation.It&#x27;s a fine language, but I can&#x27;t say that I love it. reply Klonoar 19 hours agorootparent> For example, error handling is an area where people almost always resort to 3rd party libraries.IME people mostly resort to those libraries just to avoid verbosity, since implementing error types is frankly boring and macros&#x2F;etc make it a non-issue.Some have neat context-attachment functionality that can be useful as well, though I&#x27;ve personally never needed it. reply rhodysurf 20 hours agorootparentprevI would consider error handling in rust my favorite of all the lanuages i use by a long margin, im not sure how it would be improved. Python I have to try catch, JS i have to try catch, C++ i have to try catch, Go I need more boilerplate than rust. Swift is close to rust, but without the Map Error logic its less ergonomic. reply tensor 20 hours agorootparentAn incredibly typical scenario is that a function makes several calls that each have their own error. E.g. maybe initialize the database and a web server.If you want this function to return an error that encompasses any of the sub-error types you are forced to write the most incredible amount of boilerplate that I&#x27;ve ever seen in a language. You need to define a composite error type and then implement all the required traits for it.I&#x27;m not sure how some people avoid this situation, but it&#x27;s an incredibly common scenario and the only reasonable solution is to use a library like anyhow. Defining your own errors is also heavily boilerplate prone giving rise to things like thiserror.Why these third party libraries are not made into first class language features is beyond me, but it is an example of very poor design and is typical of what I mean. Rust implemented a solid error handling core, but then just didn&#x27;t bother with the things that would make the error handling actually good. Fancy over pragmatic. reply thinkharderdev 18 hours agorootparentI don&#x27;t understand what you would include in the std lib exactly. Defining error types is just defining regular types with domain-specific error information. Macros to make that less verbose seems like the exact sort of thing you would want to be implemented in third-party libraries. reply tensor 16 hours agorootparentExcept as a newcomer to the language, I didn&#x27;t know about anyhow or thiserror and spent an immense amount of time figuring out how to solve this problem, and writing all the boilerplate. This is not pragmatic and not ok.I would say a language like Go is well designed in that it has an overall design philosophy and you can see that throughout the language, including in the limitations which are often intentionally chosen. One part of their philosophy that I really appreciate is their intention to make the language pragmatic in industry settings, and making typical things obvious to newcomers is a huge part of that.Even if your solution is macros (which may be ok, but can also make the underlying generated code more opaque), it should be part of the standard library and part of the language manual. Making things the \"officially approved way of handling a problem\" has benefits beyond newcomers too, it gives the entire language more consistency resulting in a far more cohesive design. reply thinkharderdev 14 hours agorootparent\"The\" solution is not macros. The solution is what is provided by the language. If you are calling a bunch of different functions that return different error types then you either have to map them manually (using map_err) or you can create your own error type and implement From to automatically lift into your own error type. I agree that it is a lot of boilerplate which is why there are good libraries for generating the boilerplate with macros. But the underlying mechanism is not really obscure. It is covered quite well in the rust book (https:&#x2F;&#x2F;doc.rust-lang.org&#x2F;book&#x2F;ch09-02-recoverable-errors-wi...). replyzanellato19 18 hours agorootparentprev> Meanwhile, \"clever\" things like zero cost map and filter are prioritized and in the language for a long time.This is because of what the language is trying to do. Providing map and filter with zero is a priority 0. I think people think Rust had more development manpower than it actually had. Java&#x2F;C# (and I would bet Go) have had significantly more money poured into them than Rust. reply scoopr 22 hours agoparentprevI would like to link Graydon&#x27;s post on how the language turned out in his view, as it seems relevant: https:&#x2F;&#x2F;graydon2.dreamwidth.org&#x2F;307291.html reply faitswulff 23 hours agoparentprev> I think one of the reasons why Rust turned out to be so well-designed is that Rust has a very open development approach where people with many different experiences can share their wisdom.Probably also why Rust has such highly publicized drama, as well. The drama is out in the open, too. reply mhh__ 22 hours agorootparentRust seems to attract people prone to drama (I have been privy to much private open source drama but nothing like what I see from rust in the open, at a glance at least) reply bachmeier 17 hours agoparentprev> Rust has a very open development approach where people with many different experiences can share their wisdomInteresting take, but as someone that drifted away from Rust with the publication of the linked blog post, and wrote their last meaningful code in the language a year later, it does not describe my experience. YMMV, but compared to other languages, I&#x27;d say as a first approximation that they had no interest in comments from outside the inner circle. reply qalmakka 23 hours agoprevThe fact they&#x27;ve managed to bring safety to the masses without a GC is arguably the #1 reason for Rust&#x27;s success. This has been a good move. reply dgb23 14 hours agoparentThis claim is a bit too broad based on my limited understanding. Please correct me if I&#x27;m wrong:First, Rust is not actually a memory safe language. It makes writing memory safe code easy and nudges you towards writing \"unsafe\" code in specific places. This is a good thing and many get away with not requiring programmer asserted safety. But it&#x27;s also important to note that ultimately it relies on it.Second, The borrow checker seems to primarily check that you&#x27;re doing RAII properly. In a sense it answers the question of:\"What if we get the predictable nature of stack allocated memory for the heap?\"Clever, but that leads to a proliferation of lifetime annotations (which are part of your types) and makes code very brittle and rigid if spelled out as is. Because every lifetime that is encoded that way, has to fully cover the scope that encloses all of its usage. And if that weren&#x27;t enough, it also infects almost every data structure that is some way composed of references.There seems to be multiple ways of dealing with this issue that I&#x27;ve come across when learning the language:1. Avoiding pointer references whenever possible and using self-managed vector&#x2F;slice&#x2F;hashmap references.2. Introducing GC via reference counting.3. Cloning.4. Macro or trait abstraction.When we&#x27;re doing 1, we don&#x27;t gain much utility from the borrow checker.When doing 2&#x2F;3 we would be better served if we used a language with a battle hardened and optimized GC runtime.I&#x27;ve seen 4 in some cases, but never looked like it&#x27;s \"bringing safety to the masses\". The whole API around traits and macros is very rich, very sophisticated and very subtle.I would rather phrase it as: \"Rust brings ML&#x2F;functional concepts to C++ programmers and it explores a new space of compiler optimizations based on that.\"However the Rust _community_ does bring these concepts to the masses. They have written excellent books and recorded multi hour long videos explaining and exploring the language and making this all accessible. reply steveklabnik 13 hours agorootparentBy the standard of your “first,” no language is a memory safe language. They all must rely on unsafety in the implementation of their runtimes in the same sense that Rust builds safe abstractions on top of unsafe code, and many even offer FFI, which is conceptually similar to calling an unsafe function. reply titzer 12 hours agorootparentMost memory safe languages lack enough power to implement their own runtime systems (except in an extremely inefficient way), because so many languages ultimately rely on an implementation in another unsafe language that has access to machine capabilities. Implementing the runtime system in the language itself is a black art that requires an unsafe dialect or extension. E.g. all the Java-in-Java VMs sneak dialect features in through intrinsic classes like \"Pointer\" and such that are recognized by their own extended compilers. reply gwbas1c 19 hours agoparentprev> The fact they&#x27;ve managed to bring safety to the masses without a GC is arguably the #1 reason for Rust&#x27;s success. This has been a good move.That&#x27;s an understatement. Rust doesn&#x27;t require a framework &#x2F; runtime. Unlike NodeJS, Python, Java, C#, ect; when you ship a Rust program, it has no external requirements.More important: Because Rust can create libraries that adhere to the C calling convention, you can create libraries that you can call from NodeJS, Python, Java, C#, ect. The fact that those systems have a heavyweight runtime (with GC) makes it very hard to create a library in one environment and call it from the other.I do think there&#x27;s room for an \"R2\" that is semantically identical, but designed to be easier to understand. Probably the biggest room for improvement is using generics for things like RC, ARC, Mutex. I&#x27;d rather use something like keywords; and leave generics for user-defined types. This way, when trying to understand what something \"is,\" the \"how the memory is tracked\" is semantically different from \"what the struct is.\" (Even though under the hood they are the same thing.) reply thinkharderdev 18 hours agorootparent> using generics for things like RC, ARCThere is an unstable feature for \"box syntax\" which both allows you to construct a `Box` as let foo = box a (instead of let foo = Box::new(a)) but also to use box as a keyword in pattern matches to deref the box automatically. So struct Foo { value: Box };let Foo { value: box Bar } (in which case value is bound to a &Bar) which was really nice.It got subsumed into a more generic \"deref patterns\" project which doesn&#x27;t seem to be going anywhere but I hope it does because it makes the language much more ergonomic IMO. reply SkiFire13 16 hours agorootparentThe `box` syntax to create `Box`es has been removed because it was broken. The initial idea was to have it initialize the value directly in the heap, but that never worked for function calls. The `box` pattern instead remained as it was still useful to have (really unfortunate for the perma-unstable status though). reply thinkharderdev 15 hours agorootparentAh didn&#x27;t realized it had been removed. I gave up on it after it became clear it was never going to make it into stable rust. I do hope deref patterns gets some traction though as it could really be a nice feature. reply TylerE 16 hours agoparentprevI push back, strongly, on the notion that Rust in it&#x27;s current state is \"for the masses\". reply raincole 23 hours agoprevI think it&#x27;s quite unfortunate that there isn&#x27;t a language with1) Rust&#x27;s type system or something as expressive 2) C#-level performance 3) GC by default 4) Ecosystem that is as big as RustThe closest thing seems to be TypeScript (weirdly). reply dcuthbertson 22 hours agoparentExcuse my ignorance (I have only just started learning Rust), but why is GC by default desirable? If a programming language can tell when a variable goes out of scope, or its lifetime ends and use that information to automatically release allocated memory, then why is having a garbage collector important? Does Rust (as a result of not having GC) put restrictions on the kind of code you can write, or force one to write code in such a way that it&#x27;s difficult to reason about? reply nu11ptr 22 hours agorootparentYes, it has a borrow checker which restricts some valid code and occasionally makes you jump through hoops and write in a different style.Also, a garbage collector that is state of the art (bump allocation, generational, and compacting) is faster overall typically (throughput-wise, but with less predictable latency) than naïve Rc&#x2F;Arc all over the place (due to usage of \"free list\" allocator and counter bumps). That isn&#x27;t to say blisteringly fast Rust isn&#x27;t possible to write, and in fact it is pretty easy to write by avoiding Rc&#x2F;Arc except where necessary and using the stack with the borrow checker, but this entails a writing style that is more \"low level\" and thus takes a bit more thinking. reply HankB99 22 hours agorootparentIANAGCE (I am not a GC expert.) I thought there were potential costs to using GS.1. Interrupting the program to sweep, resulting in unpredictable performance.2. Possibility that a circularly linked group of variables could be impossible to sweep, resulting in memory leaks.3. Need to check reference counts (along with bounds checks) that degrade performance.Lack of GC (and bounds checking) are factors that make C&#x2F;C++ performant and then lead to the kind of bugs that result in programs that don&#x27;t do what they&#x27;re supposed to do (and at worst, result in security vulnerabilities.)I thought a key goal of Rust was to fix these problems without sacrificing performance. reply nu11ptr 21 hours agorootparent> 1. Interrupting the program to sweep, resulting in unpredictable performance.See my comment regarding \"less predictable latency\" (although new advances are making for much more predictable latency - see some of the work done in Java GCs for example)> 2. Possibility that a circularly linked group of variables could be impossible to sweep, resulting in memory leaks.That is not possible in a precise tracing collector, only in reference counting (Rc&#x2F;Arc)> 3. Need to check reference counts (along with bounds checks) that degrade performance.I think you are referring to reference counting again. Both Rust and C++ have reference counting types as an add on.State of the art tracing collectors don&#x27;t collect&#x2F;check dead objects, they compact live ones, and often don&#x27;t use reference counting directly. Most objects die young.> Lack of GC (and bounds checking) are factors that make C&#x2F;C++ performant and then lead to the kind of bugs that result in programs that don&#x27;t do what they&#x27;re supposed to do (and at worst, result in security vulnerabilities.)Replace \"performant\" with \"predictable performance\"> I thought a key goal of Rust was to fix these problems without sacrificing performance.Rust, like C&#x2F;C++, wants you to be able to predict performance and latency and without the baggage of a runtime. Nothing more than trade offs - neither is better or worse. GCs often do perform better with the trade off of latency predictability, but as always it depends on use case as to what is appropriate. Rust likely made the right choice for its domain. reply kaba0 18 hours agorootparentprevWhat kind of GC do you talk about here? (RC is also a GC algorithm, but you seem to mix some of its shortcomings with that of trading GCs).1) this is generally true, but many part of this can be done concurrently, and if we want to improve latency at the cost of some throughput than there are low-lat GCs that maximize the pause times (it is basically independent from the heap size), so in practice you have similar interrupts as you would from the OS alone.2) this is not a problem with tracing GCs, only with refcounting (most well known is Python, ObjC and Swift for this perhaps). You can still leak memory everywhere by e.g. storing them in a huge list forever, though, but that is a much rarer and easy to debug bug.3) this is again only true for RC, and it is the reason why it is slower than tracing GCs, especially when it is multithreaded and the increment&#x2F;decrement has to be an atomic operation. reply dcuthbertson 22 hours agorootparentprevThanks for that explanation! I&#x27;m going to have to dive into Rc&#x2F;Arc [0]. Reference counting built into the standard library is really interesting. Several years ago I wrote a Windows kernel minifilter and reference counting is used a lot by anything that interacts with the filter manager. RC was very helpful to ensure the minifilter didn&#x27;t leak memory when it was unloaded.[0]: https:&#x2F;&#x2F;doc.rust-lang.org&#x2F;std&#x2F;sync&#x2F;struct.Arc.html reply Someone 18 hours agorootparentprev> If a programming language can tell when a variable goes out of scope, or its lifetime endsWhether a variable goes out of scope is trivial in many languages. The problem is with determining whether the lifetime of a value ends.For example: func foo(items, moreItems) { b = new bar() if coinflip() { items.append(b) } if coinflip() { moreItems.append(b) } &#x2F;&#x2F; ‘b’ goes out of scope here, but its value &#x2F;&#x2F; may live on inside ‘items’ and&#x2F;or moreItems &#x2F;&#x2F; and will have to be destroyed when it’s no &#x2F;&#x2F; longer stored in either. }In general, once you allow for dynamic allocation and references that can be copied (so that multiple objects ‘know’ of the allocated object), it can be very difficult to determine exactly when the last reference to such an object ceases to exist. reply mhh__ 22 hours agorootparentprevWith a GC you can basically write whatever you want with reckless abandon and because it&#x27;s cleaned up at runtime, it&#x27;s mostly kosher.Without a GC (i.e. rust), in order to be able to make guarantees about things that it cannot determine at compile time (this is a mathematical impossibility) it restricts the set of programs you can write. reply kaba0 18 hours agorootparentprev> Does Rust (as a result of not having GC) put restrictions on the kind of code you can writeDepending on what you mean by kind: yes. That is, Rust does limit your code’s architecture to a subset that is fine for most things, but not everything. reply BenoitP 22 hours agoparentprevJava?* Type system is even accidentally Turing complete* Very good perf, but language doesn&#x27;t help by being indirection-friendly. Value types will help a lot.* SOTA GCs* Ecosystem big* Cheap threads now. Don&#x27;t do async! Just block.* Structured concurrency soonish reply masklinn 22 hours agorootparent> Type system is even accidentally Turing completeA turing complete type system is easier to stumble into than to avoid.That doesn’t mean the type system is expressive. Turing tarpits are turing complete by definition, and nobody would call Thue, Iota, or the average OISC expressive. reply kaba0 18 hours agorootparentprevOr if someone really want to play around with types: Scala, especially Scala 3. People can’t even say that it is not nullsafe, as it is. reply Zambyte 17 hours agorootparentI haven&#x27;t used Scala since 2. Did something change related to null with 3? Can you no longer use null? I know it has the Option type which can be used to safely represent nullable values, but that is (or at least was) in addition to, rather than in replacement of null. reply kaba0 17 hours agorootparentIt has a compiler flag which will remove the null value from most type’s sets, that is a String will never contain null, if you want it to be nullable you have to write `StringNone` (or Null? Something like that). reply chris_nielsen 23 hours agoparentprevNot trying to be cheeky, but why not c#? Has pts 2, 3 and 4. For pt 1, what in Rusts type system are you looking for? reply raincole 22 hours agorootparent> Not trying to be cheeky, but why not c#?C# is my main language. I consider it a very good all-round language.Rust&#x27;s type system has some advantages over C# tho, for example Sum Type, Option (C# has ? but it was added later so you need to be careful when interacting with old code, kinda like TypeScriptJavaScript to a lesser extent), exhaustive enum, etc.Another thing I don&#x27;t like about C# is the runtime startup time which prevents me from using it for command line tools (Yes I prefer static typed languages even for \"scripting\"). I think Go has proven that you can have both GC and extremely fast startup time. reply neonsunset 21 hours agorootparentCould you try a few sample scenarios for a CLI tool written in C# with the following publish options?JIT: dotnet publish -c release -o publish -p:PublishSingleFile=true -p:PublishTrimmed=trueAOT: dotnet publish -c release -o publish -p:PublishAot=trueEither one has really good startup time (below ~100ms and 20-30ms respectively depending on what you do), compact binary size and require no external dependencies. Just like in Go except without all shortcomings of Go :)p.s.: AOT on macOS requires .NET 8 preview (will be released in November) reply raincole 20 hours agorootparentInteresting, I remembered I&#x27;ve tried something similar to your JIT example but maybe my memory is playing tricks on me. I&#x27;ll try these again later reply cb321 15 hours agorootparent20 milliseconds? On my 7 year old Linux box, this little Nim program https:&#x2F;&#x2F;github.com&#x2F;c-blake&#x2F;bu&#x2F;blob&#x2F;main&#x2F;wsz.nim runs to completion in 109.62 +- 0.17 microseconds when fully statically linked with musl libc on Linux. That&#x27;s with a stripped environment (with `env -i`). It takes more like 118.1 +- 1.1 microseconds with my usual 54 environment variables. The program only does about 17 system calls total, though.Additionally, https:&#x2F;&#x2F;github.com&#x2F;c-blake&#x2F;cligen makes decent CLI tools a real breeze. If you like some of Go&#x27;s qualities but the language seems too limited, you might like Nim: https:&#x2F;&#x2F;nim-lang.org. I generally find getting good performance much less of a challenge with Nim, but Nim is undeniably less well known with a smaller ecosystem and less corporate backing.EDIT: I make only observations here, not demands. Another observation on the same machine is `python-3.11.5 180x slower may not matter much for one-off commands keyed-in by and watched by humans, but that may not be all that matters. E.g., some people might `find . -printxargs -n1 cmd`. Almost everything almost always \"all depends\". (On a whole lot. E.g., only @raincole can elaborate on his use cases and what might be missing from the Nim ecosystem.)EDIT: Also, it&#x27;s misleading to bundle Nim with C and C&#x27;s many & storied footguns. While \"low-level\" is somewhat subjective and you can opt-in to go as low as C (if you so desire), most Nim code is as high-level as Python or C# with various choices in automatic memory management, and the language has very high-level capabilities. E.g., Nim has user-defined operators like Julia. Want to add `=~` or `~` for regex pattern matching? No problemo. In that aspect, Nim is arguably higher-level than C#. replyReleaseCandidat 20 hours agorootparentprev> C# is my main language.Then the answer is F#. OCaml has everything except the big ecosystem. Haskell has a way bigger Ecosystem than OCaml, but is still not comparable to Rust. reply kirse 14 hours agorootparentprevRust&#x27;s type system has some advantages over C#Pick up some F# then. Both can interop, I&#x27;ve built many things in a combo of the two languages, plus it&#x27;ll make you a better C# developer and your type system power greatly increases. Be careful though you might not want to go back to C#. reply digibeet 22 hours agorootparentprevRuntime startup might be a fixed issue soon for smaller CLI programs. Correct me if I&#x27;m wrong, but I believe they are working on (and it is already available with a compiler option) to compile your C# program ahead of time (C# AOT). reply MrBuddyCasino 22 hours agorootparentprevTried Kotlin native?- sum types via sealed classes (not great, admittedly)- enum \"when\" expressions are exhaustive- option type via built-in nullable types (honestly the superior solution) reply madeofpalk 19 hours agorootparentprevC#&#x27;s type system is nowhere near as expressive. Lack of sum types&#x2F;discriminated unions and pattern matching&#x2F;type refinement. reply tazjin 23 hours agorootparentprevI don&#x27;t know C#, so maybe it has these, but it&#x27;s unlikely:- absence of null pointers- proper sum types which can be statically checked for exhaustiveness- statically controlled mutability (yes, borrow-checking is still useful if you have a GC!)Also no exceptions, but that&#x27;s not a type system feature. reply seabrookmx 15 hours agorootparentC# calls the first one \"nullable reference types.\" When that build option is enabled, all types are non-nullable by default, and you can make them optionally nullable by declaring them like \"MyClass? cls = null;\"The compiler will ensure you check for null before de-referencing a nullable type. reply tazjin 12 hours agorootparentHow does this interact with third-party dependencies you use? In my experience, most gradual typing things break down at that boundary. reply John23832 22 hours agorootparentprevThen what about F#? reply jen20 23 hours agorootparentprevSum types, which can only be approximated in C# via records, and no exceptions, which is even a problem for F#. reply EwanToo 22 hours agoparentprevI expected someone to write a rust-based scripting language which tightly integrated with rust itself.In reality, it seems like the python developers and toolchain are embracing rust enough to reduce the benefits to a new alternative.https:&#x2F;&#x2F;github.com&#x2F;PyO3&#x2F;pyo3 reply masklinn 22 hours agoparentprevOne issue with GC’d language and the associated promiscuity is it’s quite hard to mix with affine or even linear types. Yet those turn out to be quite handy. reply ThomasTJdev 23 hours agoparentprevNim-lang fits 1, 2 and 3! And in a couple of years the ecosystem is up to level ;) reply faewjpofiajwifa 21 hours agorootparentNim doesn&#x27;t have sum types and pattern matching, which are an essential part of an expressive type system. It also appears to have `nil` be a valid value for most types by default? reply cb321 17 hours agorootparentThis comment is misleading &| misinformed.Sum types are built-in [1] for formal parameters. `nil` is only for `ref|ptr` types. In much code you can just use stack allocated value types and there is neither GC concern nor nil concern, but there is also a mode to help: https:&#x2F;&#x2F;nim-lang.github.io&#x2F;Nim&#x2F;manual_experimental_strictnot...Nim has an easy-ish to use Lisp-like syntax macro system where you just receive & process an AST. So, to do the rest you can make libraries adding the feature without relying upon upstream compiler: such as https:&#x2F;&#x2F;github.com&#x2F;beef331&#x2F;sumtypes for variables with sum types or pattern matching libs like https:&#x2F;&#x2F;andreaferretti.github.io&#x2F;patty&#x2F;https:&#x2F;&#x2F;github.com&#x2F;alehander92&#x2F;gara. reply sa-code 23 hours agoparentprevMojo could potentially fill this gap in a year. They still have a long way to go, but they&#x27;re working on traits and sum types right now reply thelittlenag 19 hours agoparentprevScala&#x27;s type system is about as expressive as it gets in mainstream languages. By virtue of running on the JVM it is GC&#x27;d and has Java&#x2F;C#-like performance. And the ecosystem of Scala implemented libraries is huge. reply indeyets 23 hours agoparentprevF# probably? reply skrebbel 22 hours agorootparentYeah GP’s points 1 through 4 seem like they could be on an F# pitch deck. It’s an ML with full access to the .net ecosystem and the .net VM’s speed and stability. reply mxz3000 21 hours agorootparentwe have a massive mixed c# and f# codebase at work.F# is not magical. Yes it&#x27;s an ML, but frankly, C# is better in every way, to the point we&#x27;re slowly moving away from F# entirely.The main reason is perf, it&#x27;s really easy to shoot yourself in the foot with performance in c# (e.g. huge allocations, accidentally evaluating seqs twice, etc). Also IDE support for F# sucks when you get to the hundreds of project solutions like we have.For side projects, sure use F#. For everything else, stick with C#. reply lysecret 23 hours agorootparentprevYes wanted to comment that as well. reply nu11ptr 22 hours agoparentprevI think #1 needs to be expanded to imply what it DOESN&#x27;T have as well:1. No null pointers 2. No exceptions reply fweimer 22 hours agoparentprevWhat do you consider Rust&#x27;s relevant properties in this context? Traits? Inner object references? Associated types and constants? Compilation tending towards monomorphization?C++&#x2F;CLI covers some of these aspects, but I haven&#x27;t used it and don&#x27;t know how large the vcpkg ecosystem is. reply qalmakka 23 hours agoparentprevD (Dlang) checks 3 of those marks. If you like cursed things, Vala isn&#x27;t that bad... reply losvedir 22 hours agoparentprevHa, I feel exactly the same. I asked HN about it a year ago[0], and there was some interesting discussion.[0] https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=32984776 reply manicennui 15 hours agoparentprevOCaml probably has everything but 4. reply manicennui 15 hours agorootparentAlso just remembered that F# exists, which is probably exactly all of that and runs on the CLR like C#. reply cmrdporcupine 22 hours agoparentprevSounds like you want OCaml (or StandardML but OCaml is more \"active\")Since, as I feel it, Rust was&#x2F;is started as an attempt to bring roughly the ML (Hindley-Milner) type system to the area of `systems` (non-garbage collected) development.In the early days of Rust I thought of it as type inference & algebraic data types meets C++ (now kiss!). But then the borrow checker stuff went in there and it took a different turn.And I think you&#x27;d be surprised by how large the OCaml package community is.People who work in Rust would likely find OCaml very familiar after a week or two of hacking.The other option is Swift, but it&#x27;s pretty ghetto-ized into the Apple ecosystem. reply AndreasHae 22 hours agoparentprevKotlin ticks all of your boxes, plus you benefit from the vast ecosystem of the JVM. reply richbell 22 hours agorootparentIt&#x27;s unfortunate that Kotlin lacks pattern matching, especially now that Java has it. I can only hope that the release of the new compiler will spur further language features. reply simonkagedal 15 hours agorootparentWhat kinds of pattern matching that Java now has is Kotlin missing? reply richbell 14 hours agorootparentAt the moment Kotlin only has smart casts and exhaustive type checking (e.g., making sure you didn&#x27;t forget a switch case). It doesn&#x27;t let you destructure records, add guards to cases, etc.https:&#x2F;&#x2F;www.infoq.com&#x2F;articles&#x2F;pattern-matching-for-switch&#x2F; reply rwmj 22 hours agoparentprevOCaml or F#? reply evntdrvn 20 hours agoparentprevF# reply loeg 20 hours agoparentprevOCaml? reply wizwit999 17 hours agoparentprevyes something like kotlin + go would be excellent reply corethree 19 hours agoparentprevHaskell has a better type system. In fact rusts type system is derived from ML languages ...Tons of languages have better type systems. reply nvm0n2 22 hours agoparentprevIsn&#x27;t Rust&#x27;s type system mostly about not having GC? What specific type system features are you looking for outside of borrow checking? Macros?Probably the closest would be Kotlin. It has the huge JVM ecosystem, it uses GC, programs run fast, they can be compiled to native binaries using at least two different native compilers (kotlin&#x2F;native and graalvm). The type system is fairly expressive, albeit not quite as much as TypeScript. It makes up for it with just being a much cleaner and more logical language in general, as it didn&#x27;t inherit much historical baggage.There&#x27;s also a compiler plugin API which is maybe the closest equivalent of macros. It&#x27;s not really documented or stable in Kotlin 1.x, they&#x27;re fixing that for Kotlin 2, but there are already a bunch of useful plugins that add various features via compile-time generation and reflection. reply veber-alex 22 hours agorootparent> Isn&#x27;t Rust&#x27;s type system mostly about not having GC? What specific type system features are you looking for outside of borrow checking? Macros?1. ADTs with exhaustive pattern matching2. No exceptions3. Zero cost generics4. Traits5. No nulls6. No inheritance reply fweimer 22 hours agorootparentRust has exceptions. They are used throughout the standard libraries to report some errors, and as far as I can tell, they are deeply ingrained into the default testing framework.As a rule of thumb, languages that loudly claim not to have exceptions actually use them in some way (see POSIX C, Perl, Go). reply TwentyPosts 21 hours agorootparentSaying that Rust \"has exceptions\" is dishonest. What matters isn&#x27;t whether they technically exist, but if and how they&#x27;re used.In idiomatically written Rust you will never obtain an exception&#x2F;panic (unless there is a bug), and exceptions are not used for control flow. This is not the case in Java or C++ or many other languages. reply skitter 20 hours agorootparentprevIn JRE terms, Rust doesn&#x27;t have Exceptions, but it has Errors. reply masklinn 22 hours agorootparentprev> Isn&#x27;t Rust&#x27;s type system mostly about not having GC? What specific type system features are you looking for outside of borrow checking?Sun types, affine types, traits. reply frankreyes 22 hours agoprevRust just took C++ std::unique and std::shared ptr and made those integrated directly in the language, and the only option for allocation. Which is awesome.It would be nice to see if we can have a sub set of C++ that forces us to only use std::make_unique or std::make_shared calls. reply proto_lambda 22 hours agoparent> Rust just took C++ std::unique and std::shared ptr and made those integrated directly in the language, and the only option for allocationNot really. Both Box and Rc&#x2F;Arc are first and foremost library features implemented using the equivalent of malloc() and free(). Box is a bit special due to its deref semantics, but other than that, there&#x27;s nothing stopping you from implementing them or something else yourself. reply frankreyes 22 hours agorootparentThanks, never wrote Rust so I&#x27;m just guessing. What else there is, besides static type checks? Is there a runtime side too? reply proto_lambda 21 hours agorootparentThere is no runtime (other than init&#x2F;exit handling). The main thing that provides memory safety without a GC is the borrow checker, which is a language feature and independent of the smart pointer types in the standard library. reply UncleMeat 22 hours agoparentprevYou can already write a very very very simple linter that bans use of the \"new\" keyword. Rust did quite a bit more to make this ergonomic than just force you to use smart pointers. reply dang 15 hours agoprevDiscussed at the time:Removing garbage collection from the Rust language - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=5811854 - June 2013 (130 comments) reply jxf 22 hours agoprevEarly Rust was really incomprehensible to me, and it&#x27;s unquestionably better than it once was from an ergonomics and ecosystem perspective. The ~ and @ sigils everywhere were verging on Perl! reply cmrdporcupine 22 hours agoparentI actually think removing ~ was a mistake.a) A lot of code ends up littered with Box anyways, which frankly isn&#x27;t any more readable since \"Box\" doesn&#x27;t tell you anything until you already know what it is and once you do it&#x27;s just verbosity.b) As I understand it, Box gets \"special treatment\" by the compiler&#x2F;type system, so pretending it&#x27;s just a pure standard library component is a bit obfuscatoryc) Heap allocation and heap pointers are first class citizens in other languages, why wouldn&#x27;t they be so in Rust? reply veber-alex 18 hours agorootparent> b) As I understand it, Box gets \"special treatment\" by the compiler&#x2F;type system, so pretending it&#x27;s just a pure standard library component is a bit obfuscatoryThere is a strong desire to stop that and have Box be a normal std type, the main thing that is blocking this at the moment is that Box has special deref magic that is not possible to implement with surface level rust syntax (even with nightly features). reply mjw1007 20 hours agoprevHere are some notes on the later history of GC in Rust:RFC 256, 2014-09. https:&#x2F;&#x2F;rust-lang.github.io&#x2F;rfcs&#x2F;0256-remove-refcounting-gc-...Includes « I (and I think the majority of the Rust core team) still believe that there are use cases that would be well handled by a proper tracing garbage collector. »https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=8312327 A core developer says« I wouldn&#x27;t be so quick to give up on GC support yet! \"We have a plan!\" But I don&#x27;t think we&#x27;ll have it in for Rust 1.0. And it&#x27;s true that, even if we never do get it to work in a satisfactory way, the language works just fine without it. »By 2015-04 (\"Fearless Concurrency\"), \"Memory safety without garbage collection.\" is a \"key value proposition\" (this isn&#x27;t quite the same as saying \"we never want Garbage Collection\", of course).2016-08 https:&#x2F;&#x2F;manishearth.github.io&#x2F;blog&#x2F;2016&#x2F;08&#x2F;18&#x2F;gc-support-in-... « Recently we (Felix, Niko, and I) have been working on getting compiler-level GC support for Rust. »2018-10 withoutboats has a research garbage collector as a library: https:&#x2F;&#x2F;boats.gitlab.io&#x2F;blog&#x2F;post&#x2F;shifgrethor-i&#x2F; The intro post includes « I do not expect we will ever “add GC to Rust” ».2021 summary of options: https:&#x2F;&#x2F;manishearth.github.io&#x2F;blog&#x2F;2021&#x2F;04&#x2F;05&#x2F;a-tour-of-safe... reply gabereiser 16 hours agoprev>\"The sigils make the code unfamiliar before the concepts are learned. Unlike the rest of the punctuation in Rust, ~ and @ are not part of the standard repertoire of punctuation in C-like languages, and as a result the language can seem intimidating.\"It&#x27;s still intimidating with lifetimes and Arc> like idioms. Still, it&#x27;s blazingly fast (tm). I wonder what Rust would be like if the GC was kept in like in Go. reply kaba0 15 hours agoparent> I wonder what Rust would be like if the GC was kept in like in Go.It would be one of the litany of managed languages that doesn’t significantly differ in anything from each other, and we would have no reason to be hyped about. reply gabereiser 14 hours agorootparentHype is subjective but I do welcome a safer C++. reply yencabulator 16 hours agoprev> remove garbage collection from the core language and relegate it to the standard library, with a minimal set of language hooks in place to allow for flexible, pluggable automatic memory management.They did part one, but not part two... reply Alifatisk 16 hours agoprevWould adding the GC back make the syntax easier to read and remove all those special characters like the way lifetime is handled? reply steveklabnik 16 hours agoparentEven if in theory it would, Rust&#x27;s commitment to backwards compatibility would mean that those things could not be removed.You&#x27;re asking for a different language. reply dingi 22 hours agoprevI&#x27;m pretty sure that Rust is a great language for low level stuff, the domain of C&#x2F;C++. Try to shoehorn it to do more higher level stuff (i.e: vast majority of software developed today), And you&#x27;ll be fighting battles with the language at each step. For those use cases, Java, JavaScript, Python et al will reign supreme for many years to come. Most of the time, GC stalls are the least of your problems. reply binary132 22 hours agoprevcall me crazy, but I found old-style Rust, runtime and all, much more appealing. reply fleventynine 18 hours agoparentThen choose from one of the countless garbage-collected languages with sum types and a runtime; Rust is successful because it&#x27;s offering us systems programmers something unique. reply timeon 19 hours agoparentprevRust has other nice features but I started with Rust not in spite of borrow checker but because of it. Without borrow checker why would one choose Rust? I would choose from large pool of GC-languages. reply jedisct1 22 hours agoparentprevYou&#x27;re not alone. reply unsolved73 23 hours agoprev [–] One of the biggest mistake, in my opinion.Especially with async which complicates lifetimes a lot. reply eftychis 23 hours agoparentI (also like sibling comments) respectfully disagree.Rust is aimed and focused as a safe C or a sane C++ substitute, and is meant to intermingle with both. It is not an application \"high\" level language. You can use it as such, which is great. For anything you would use C or C++ you can use Rust instead. As a cryptographer I find that great.Regardless of all the lack of latency or other control -- beyond fine tuning -- a garbage collected language makes critical memory choices we want to make instead. There are times we want to swap or use our own memory allocator, never mind having to add a garbage collector in the mix. (There is a good number of languages that scratch that itch, and you can likely link and use your C&#x2F;Rust code with them.)As far as async: also respectfully disagree. Async is sugar for here is a Future. If you want to poll it locally you can. You can scope it also. If you want to use a cross thread work stealing algorithm you can. But you need like memory management to consciously make these design decisions. This is similarly why a lot of things are not built in in C. reply nu11ptr 23 hours agoparentprevThey wanted a systems language. A GC would be very appropriate for much of the code I write, but would not have been for an OS kernel. Green threads removed as well. I admit the GC version with green threads I would have preferred, but again, not appropriate for the domain they wanted. I still want my halfway between Go and Rust language. reply ynik 22 hours agorootparentA GC-free systems language isn&#x27;t just for OS kernels. Rust&#x27;s main use case was to replace C++ components in firefox. This wouldn&#x27;t have been possible with a language that brings along its own GC, as Firefox already has a JS GC. Multiple garbage collectors in the same process are a quick way to madness, especially if you have reference cycles stretching across multiple GC heaps. This also comes up when writing Python extension modules, base libraries that are meant to be usable across languages, etc...This is part of why Rust is so successful -- it&#x27;s the first real alternative for this space since C++ came along. For most application development, it&#x27;s better to use a garbage collected language. But in the application space there is a much bigger choice of languages already available, Rust wouldn&#x27;t have been a big deal over there. reply tikkabhuna 22 hours agorootparentprevI do wonder why there hasn&#x27;t been more exploration in a series of languages that have a very similar style and toolchain but have different audiences. It would be great to have Rust, Rust with a GC, and then some sort of interpreted language that has a similar syntax. When jumping between languages I feel like half the battle is overcoming muscle memory. reply 0cf8612b2e1e 20 hours agorootparentThis is my dream. An interpreted language, implemented in Rust which essentially boxes all data and can do message passing to the host language. This would then give a somewhat plausible upgrade path to port the interpreted code into Rust bit by bit as required.The interpreted language even be slower than Python, so long as the escape hatch to Rust was simple and safe enough to implement the interfaces. reply j1elo 22 hours agoparentprevI heard this brilliant summary in a video from ThePrimeagen:In Rust, lifetimes color your types, like async colors your functions.It is a great condensed summary of what makes lifetimes a great difficulty of async Rust. It&#x27;s a language that has the function coloring that is typically introduced by async (likewise in JavaScript), and on top of that the typesystem itself gets colored by lifetime annotations. You can have a well written and working program... then due to some new need or refactoring, wanting to add a &#x27;static somewhere will cause it all to break down.It&#x27;s part of the language, nothing bad with that. But it is an extra layer of difficulty that needs to be mastered. To me it shows that Rust might only be the initial step towards future programming languages where this kind of issue doesn&#x27;t lean so much on developer knowledge. reply rcarr 22 hours agorootparentCan you post a link to this video? Sounds interesting reply j1elo 22 hours agorootparentWasn&#x27;t sure, but found it!https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=p-tb1ZfkwgQ&t=340s(in case it doesn&#x27;t work: on the 5:40 mark) reply rcarr 12 hours agorootparentThanks! reply qalmakka 23 hours agoparentprevA GC would have made Rust yet another Dlang, which is pointless because Dlang has existed for a way longer time. reply silon42 20 hours agorootparentOr more realistically, another JVM language.I actually wouldn&#x27;t mind a subset of Rust that targets the JVM. reply raverbashing 18 hours agorootparentprevSo why Dlang has not gotten as popular as rust or go? reply qalmakka 14 hours agorootparenta. it never had a real corporate backer, until it was too late (and Rust already stole all of its mindshare) b. It had a garbage collector, which meant that realistically it could not replace C++. Or rather, it could but you basically had two different Dlangs - one with GC and classes, and one without. It was arguably not necessary, because people already had GC languages that were fast enough and worked for their needs, and those who needed speed were better served by C++, which arguably isn&#x27;t that bad of a language if you know how to use it.Rust is arguably the first real contender to C++&#x27;s reign because it really brings to the table features you&#x27;d be a fool to pass on. D was nice, but it was not worth the switch. Eliminating whole classes of bugs instead is. reply nickpp 16 hours agorootparentprevLack of a big corporate backer is my best guess. reply nercury 23 hours agoparentprevWith GC rust would have been just another slightly different language. reply Shorel 23 hours agoparentprevThen you can use D lang. reply dystroy 23 hours agoparentprevRust noob here. Can you please explain how removing &#x27;~&#x27; and &#x27;@&#x27; by moving the GC to a library makes async harder ? reply BenoitP 22 hours agorootparentLifetimes complicated. Having a proof of them at compile time is difficult. You can&#x27;t prove everything for starters. A lot of patterns are just a no-go. Why not defer that to the runtime, and just observe which variables stick around (that&#x27;s GC)IO complicated. The cycle of doing code then waiting for IO is wasteful (sequentially you waste millions of CPU cycles waiting for the network to answer back). To max out usage of your hardware resources you could just aggregate IO requests with your compiler. Switching back and forth between code that uses IO, as IO request come back (that&#x27;s async)Problem is: switching back and forth between code that uses IO is recklessly hard wrt coming up with a proof of the lifetimes of the variables.And a language&#x2F;runtime _needs_ to have the trifecta of compiler&#x2F;GC-or-memory-management&#x2F;memory-model coherent and within the runtime.compiler&#x2F;GC-or-memory-management: the GC-or-memory-management needs to know who writes, who owns, who readsGC-or-memory-management&#x2F;memory-model: you need to know when and how you can read your writes, what are the rulesmemory-model&#x2F;compiler: you&#x27;ll be managing memory barriers so that you can cram together sequences of writes that are compatible, for maximal performanceThis trifecta dependence is foundation to a language&#x2F;runtime, and a change to one affects the others quite deeply. Changing the compiler (bringing async here) affects the other ends and you can&#x27;t do that when GC-or-memory-management is all over the place (as a lib, or god forbid in user hands)I&#x27;m afraid async is just something unaffordable for a language that wants to be that close to the metal. And even then, async is just a bandaid for a costly threading IO model.----Come over to the dark side of Erlang, Go, and Java. We have small threads now. You can just block like there is no tomorrow, and the runtime will have a cheap back and forth. You can just forget about the lifetimes, as the GC will sweep after you (and concurrently, outside of the critical allocation path). Forget it all my friend. Java is love, Java is life. reply yccs27 23 hours agorootparentprevI suspect GP only read the title and not the article. A Java-style GC might make async code easier, but that never existed in Rust. reply arghwhat 23 hours agorootparentprevRather than those operators and how GC is done, I think the key aspect is how much easier async is in other languages that have easy automatic memory manage without ownership through garbage collection. Go and JavaScript&#x2F;Dart are good examples.But such models would also take away everything that makes Rust... Rust. reply baq 23 hours agorootparentprevit&#x27;s not the things that were removed, it&#x27;s the things you have to add to the source now to make it work within the limits of the borrow checker.in the simplest case, you&#x27;d add Arc everywhere @ used to be. reply api 23 hours agoparentprev [–] Rust is a language for writing the GC, runtime, OS kernel, etc. reply pjmlp 22 hours agorootparent [–] And?Plenty of GC enabled system programming languages have achieved similar feats, with bigger outcome than Rust has managed to on the desktop space, e.g. Xerox Workstations, across Smalltalk, Intelisp-D and Mesa&#x2F;Cedar.Redox is still not as feature rich as Mesa&#x2F;Cedar was on the Dorado in 1981.https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=z_dt7NG38V4By the way Go, D, Eiffel, Nim, Common Lisp, Scheme, some JVM implementations are bootstrapped, meta-circular, with their own GC implemented on them. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The author advocates for eliminating garbage collection from the Rust language, citing complications with familiarity, simplicity, and adaptability in its current memory management system.",
      "They suggest prioritizing owning pointers and confining reference counting to a specific role, which would simplify the understanding of memory management for beginners while still providing options for dynamic memory management.",
      "The author highlights Rust's potential in low-level programming and posits that it could be a suitable choice for high-performance web server software."
    ],
    "commentSummary": [
      "The discussion revolves around multiple aspects of Rust programming language, such as the elimination of garbage collection, balancing between single and multi-threaded runtimes, and advantages of Rust's asynchronous architecture.",
      "The features including the use of generics and the \"box syntax\" are addressed, and the implication of Rust's nonexistent garbage collection on code writing is scrutinized.",
      "There are comparative examinations of Rust with other languages and their type systems, along with mentions of the Redox operating system and languages having garbage collectors."
    ],
    "points": 178,
    "commentCount": 200,
    "retryCount": 0,
    "time": 1694427784
  },
  {
    "id": 37467607,
    "title": "X sues Calif. to avoid revealing how it makes “controversial” content decisions",
    "originLink": "https://arstechnica.com/tech-policy/2023/09/x-sues-calif-to-avoid-revealing-how-it-makes-controversial-content-decisions/",
    "originBody": "SKIP TO MAIN CONTENT BIZ & IT TECH SCIENCE POLICY CARS GAMING & CULTURE STORE FORUMS SUBSCRIBE SIGN IN \"REBRANDING CENSORSHIP\" — X sues Calif. to avoid revealing how it makes “controversial” content decisions X decried law's \"draconian financial penalties,\" up to $15K per violation per day. ASHLEY BELANGER - 9/8/2023, 2:45 PM Enlarge Bloomberg / ContributorBloomberg 264 WITH Today, Elon Musk's X Corp. sued to block California's content moderation law, AB 587. In its complaint, filed in a US district court in California, X Corp. is seeking a preliminary and permanent injunction stopping California Attorney General Robert Bonta from enforcing the law. AB 587 passed in September 2022, requiring social media platforms to submit a \"terms of service report\" semi-annually to California's attorney general, providing \"a detailed description of content moderation practices used\" and \"information about whether, and if so how, the social media company defines and moderates\" hate speech or racism, extremism or radicalization, disinformation or misinformation, harassment, and foreign political interference. Under the law, social media platforms must also provide information and statistics on any content moderation actions taken in those categories. Enter your email to get the Ars Technica newsletter Join Ars Technica and Get Our Best Tech Stories DELIVERED STRAIGHT TO YOUR INBOX. SIGN ME UP By signing up, you agree to our user agreement (including the class action waiver and arbitration provisions), our privacy policy and cookie statement, and to receive marketing and account-related emails from Ars Technica. You can unsubscribe at any time. In X's complaint, the company accused California of trying to dictate X's terms of service and compel \"controversial disclosures about how X Corp. moderates content on its platform.\" The law stipulated that all platforms were required to start collecting data for their first terms of service report covering content moderation during the third quarter of 2023 and submit those reports to Bonta by January 1, 2024. Platforms could be found violating the law for failing to post terms of service about content moderation, missing a deadline to submit a terms of service report, or materially omitting or misrepresenting information about content moderation. Any platform violating the law risks fines—which X described as \"draconian financial penalties\"—up to $15,000 per violation per day. In its complaint, X Corp. argued that AB 587 violates the First Amendment by compelling \"companies like X Corp. to engage in speech against their will\" and \"impermissibly\" interfering \"with the constitutionally protected editorial judgments of companies.\" X Corp. said that if the court did not block the law, California could pressure companies \"to remove, demonetize, or deprioritize constitutionally protected speech that the state deems undesirable or harmful.\" \"The State of California touts AB 587 as a mere 'transparency measure' under which certain social media companies must make their content moderation policies and statistics publicly available,\" X's complaint said. But, X alleged, the state's \"true intent\" is \"to pressure social media platforms to 'eliminate' certain constitutionally protected content viewed by the state as problematic.\" Advertisement X Corp. alleged that AB 587 violates other laws, including the Dormant Commerce Clause—\"failing to restrict its extensive reporting requirements to information about Californians\"—and Section 230 of the Communications Decency Act—which grants platforms immunity from liability for “any action voluntarily taken in good faith to restrict access to or availability of material that the provider or user considers to be obscene, lewd, lascivious, filthy, excessively violent, harassing, or otherwise objectionable, whether or not such material is constitutionally protected.” \"Because AB 587 imposes liability on such actions if they are taken without the required disclosures, AB 587 is preempted by the broad immunity afforded by Section 230,\" X's complaint said. Ars could not immediately reach X for comment. Bonta's office said: “While we have not yet been served with the complaint, we will review it and respond in court.” The author of AB 587, California assemblymember Jesse Gabriel, released a statement saying that the law \"is a pure transparency measure that simply requires companies to be upfront about if and how they are moderating content. It in no way requires any specific content moderation policies—which is why it passed with strong, bipartisan support. If Twitter has nothing to hide, then they should have no objection to this bill.” But tech groups and policy experts echoed X's concerns over AB 587. Adam Kovacevich, the CEO of the tech industry policy coalition Chamber of Progress, said that \"requiring companies to give their content moderation playbook to scammers and conspiracists is a bad idea.\" “Even if you don't like anything about Elon Musk’s leadership of X, it’s clear that requiring tech platforms to publish a detailed blueprint of how to work around content moderators will have negative consequences for users online,\" Kovacevich said. \"Letting platforms set their own editorial standards also leaves consumers with more choices about what kind of platforms they spend time on.” Netchoice, a group representing tech companies and trade associations, has called AB 587 \"the Golden State’s new online censorship law.\" In a statement about X Corp.'s lawsuit, Netchoice said that the law would force companies to submit \"intrusive\" and \"often impossible to comply with\" disclosures \"about constitutionally protected editorial decisions.\" Netchoice's director of litigation, Chris Marchese, said that the court should enjoin AB 587 to protect free speech online. “The First Amendment prohibits the government from regulating lawful speech—directly or indirectly,\" Marchese said. \"States cannot avoid this prohibition by rebranding censorship as ‘transparency’ requirements.\" READER COMMENTS 264 WITH ASHLEY BELANGER Ashley is a senior policy reporter for Ars Technica, dedicated to tracking social impacts of emerging policies and new technologies. She is a Chicago-based journalist with 20 years of experience. Advertisement Promoted Comments MechR “Even if you don't like anything about Elon Musk’s leadership of X, it’s clear that requiring tech platforms to publish a detailed blueprint of how to work around content moderators will have negative consequences for users online,\" Kovacevich said. And requiring governments to publish their laws gives people a detailed blueprint of how to work around criminal charges. September 8, 2023 at 10:00 pm Channel Ars Technica SITREP: F-16 replacement search a signal of F-35 fail? Footage courtesy of Dvids, Boeing, and The United States Navy. SITREP: F-16 replacement search a signal of F-35 fail? Sitrep: Boeing 707 The F-35's next tech upgrade US Navy Gets an Italian Accent SITREP: DOD Resets Ballistic Missile Interceptor program SITREP: DOD's New Long-Range Air-to-Air Missile Aims to \"Outstick\" China Army's New Pistol Has Had Some Misfires Army's Next (Vertical) Lift En Route SITREP: President Trump's Missile Defense Strategy Hybrid Options for US's Next Top Fighter The Air Force’s Senior Citizen Chopper Can’t Retire Yet Ars Live #23: The History and Future of Tech Law Police re-creation of body camera evidence - Pueblo, COArs Technica Visual Labs body camera software with the Dos Palos PDArs Technica He knew his rights; he got tased anyway More videos ← PREVIOUS STORY NEXT STORY → Related Stories by Taboola Sponsored Links Get fully automated optimization suggestions itonsearch.com Learn More Tommy Chong: The Horrifying Truth About CBD Tommy Chong's CBD Watch Now Tom Brady's 3 Kids Were By His Side During Special Patriots Ceremony E! Online Harry Potter Actress Amazes Fans After 20 Years Healthy George Yellowstone Discontinued - Effective Immediately StreetInsider.com Nicole Kidman: 1 Vitamin, No Spots thehealthnetworks - Seratopical Learn More CCPA Notice Today on Ars STORE SUBSCRIBE ABOUT US RSS FEEDS VIEW MOBILE SITE CONTACT US STAFF ADVERTISE WITH US REPRINTS NEWSLETTER SIGNUP Join the Ars Orbital Transmission mailing list to get weekly updates delivered to your inbox. Sign me up → CNMN Collection WIRED Media Group © 2023 Condé Nast. All rights reserved. Use of and/or registration on any portion of this site constitutes acceptance of our User Agreement (updated 1/1/20) and Privacy Policy and Cookie Statement (updated 1/1/20) and Ars Technica Addendum (effective 8/21/2018). Ars may earn compensation on sales from links on this site. Read our affiliate link policy. Your California Privacy RightsYour Privacy Choices The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Condé Nast. Ad Choices",
    "commentLink": "https://news.ycombinator.com/item?id=37467607",
    "commentBody": "X sues Calif. to avoid revealing how it makes “controversial” content decisionsHacker NewspastloginX sues Calif. to avoid revealing how it makes “controversial” content decisions (arstechnica.com) 176 points by isaacfrond 20 hours ago| hidepastfavorite348 comments dahwolf 14 hours agoNo matter where you stand, I think it&#x27;s good that this is happening. The CA law might be overreaching whilst Twitter might be too lax. Hopefully a head-to-head brings clarity on an important topic.With the CA law, EU regulation, app store policies and the like, a pretty powerful net is cast around the topic of speech. Specifically about speech that is technically legal yet considered unwelcome.It&#x27;s tempting to let judgement be clouded by a hate for Musk, but it&#x27;s a topic worthy to think about more deeply beyond just X.It&#x27;s also revealing how this legislation only targets Big Tech. From a pragmatic point of view, this makes total sense. But it also shows that this legislation isn&#x27;t based on first principles. It&#x27;s a panicky patch on an open wound, not the definitive say on free speech. reply charles_f 19 hours agoprev> X Corp. argued that AB 587 violates the First Amendment by compelling \"companies like X Corp. to engage in speech against their will\" and \"impermissibly\" interfering \"with the constitutionally protected editorial judgments of companies.\"Ok genuine question there: are companies considered the same as people when it comes to US Constitution? Does a company have free speech and the right to bear arms? reply rgbrenner 18 hours agoparentCourts have said: Companies are just groups of people. So a person, employed by Twitter, has the same free speech rights as anyone else. If you force a company to take certain actions, a person in the company must perform that action... and forcing that person to take certain actions may be a violation of that person&#x27;s rights. reply MiguelX413 18 hours agorootparentSo companies being required to file for taxes and put nutrition facts on their food products violates the rights of certain people within those companies? reply rgbrenner 18 hours agorootparentRe: nutrition facts see the Zauderer test. The Hudson test is related.Here&#x27;s a flowchart: https:&#x2F;&#x2F;publichealthlawcenter.org&#x2F;sites&#x2F;default&#x2F;files&#x2F;resour...And then you can look up the cases to see the logic behind them. reply woodruffw 18 hours agorootparentIn particular, the Zauderer test allows the state to compel commercial speech if doing so is \"reasonably related to the State&#x27;s interest in preventing deception of customers[1].\" It&#x27;s obviously up for debate, but I think one could make a strong argument that Twitter&#x27;s content policies pass this test.(More generally, however: there&#x27;s lots of compelled commercial speech that doesn&#x27;t fit into this flowchart. Taxes, commercial permits, leases, etc. I think one could make a strong argument that this law is strictly logistical in nature and represents no more of a 1A risk than Twitter&#x27;s commercial leases do.)[1]: https:&#x2F;&#x2F;supreme.justia.com&#x2F;cases&#x2F;federal&#x2F;us&#x2F;471&#x2F;626&#x2F; reply gpm 18 hours agorootparentprevWould requiring an individual file taxes or disclose nutrition facts on food products they are selling violate their rights?If not, then no... reply charles_f 18 hours agorootparentprevYeah that&#x27;s the philosophical dilemma here reply rhyme-boss 18 hours agorootparentprevThat seems logically incoherent (for a court to say). An individual can leave a company if they don&#x27;t want to take those actions. reply sebzim4500 18 hours agorootparentI think it would be more logically incoherent if a group of people magically lost their rights because they got together to make a company. reply rhyme-boss 18 hours agorootparentIt&#x27;s a voluntary arrangement that they can leave. Certain activities come with responsibilities and restrictions, *in the interest of protecting everyone else&#x27;s rights. reply whatwhaaaaat 18 hours agorootparentNo our constitutional rights are not predicated on our actions or speech having no impact on society. On the contrary our rights are so that we may impact society as we see fit.This is such a dangerous line of thought I almost don’t believe it.Users original comment mentioned impact on society. reply rhyme-boss 18 hours agorootparent- You give up your first amendment rights when you sign non-disclosure agreements.- You give up your second amendment rights when you enter a school or hospital.- You give up privacy rights when you go through security screenings.- You give up rights to a law suit when you sign a liability release at a climbing gym. reply whatwhaaaaat 17 hours agorootparentThis is word for word talking points of the recent NM gov gun deceleration.User also modified his original comment from “impact on society” to nothing to “in the interest of others rights”. Also all word for word with the current blitz on constitutional rights.Interesting reply Jensson 16 hours agorootparent> This is word for word talking points of the recent NM gov gun deceleration.I was interested and tried to google that word for word, only thing that showed up was this thread. So it isn&#x27;t word for word the same. reply Caligatio 18 hours agorootparentprevShould power companies be allowed to disconnect power (i.e. moderate) to entities that disagree with their ideals?I&#x27;m not necessarily arguing X&#x2F;Twitter is in the same league as a power company but this line of thought has many precedents. reply whatwhaaaaat 17 hours agorootparentYes you are right it does. Namely the twitter files! Having this argument after all of the revelations in the twitter files is down right hilarious. reply shadowgovt 16 hours agorootparentTwitter Files mostly demonstrated a big tech company doing big tech company moderation. It wasn&#x27;t the bombshell people make it out to be. reply whatwhaaaaat 15 hours agorootparentThe twitter files showed that factions in the government were directly requesting individual posts be removed from a private platform.This is highly revelational and currently being litigated with the most recent decision that it was in fact unconstitutional. reply Caligatio 4 hours agorootparent> the most recent decision that it was in fact unconstitutional.This is not really what the decision states. The government can request all it wants but it cannot partake in \"threatening, pressuring, or coercing social-media companies in any manner to remove, delete, suppress, or reduce posted content of postings containing protected free speech\".I&#x27;m personally OK with the government requesting things to be moderated; I&#x27;m not OK with the aforementioned methods if the request isn&#x27;t backed by law. reply shadowgovt 14 hours agorootparentprev> This is highly revelationalI guess to anyone who hadn&#x27;t had experience with moderating a popular social media platform or talked to anyone who has. Was that really so shocking?> it was in fact unconstitutionalNice of the government to step up to the plate and give those of us who&#x27;ve been on the corporate side of this some guidance, for once. Most of what companies get from Congress and the Court is radio silence on the topic (ironically, I suspect, so the government isn&#x27;t credibly accused of violating a corporation&#x27;s First Amendment rights by telling them how they can and cannot moderate). So it&#x27;s nice for the courts to step up and tell companies that the thing the executive said they had to do, no, they don&#x27;t have to do; that&#x27;ll be helpful moving forward. reply whatwhaaaaat 13 hours agorootparentYeah well the court told the Biden admin they specifically cannot do exactly what you are saying would be “nice”.Missouri v biden reply fluidcruft 18 hours agorootparentprevLet me warm up some popcorn for when Twitter tries to claim they cannot lose their business license because the State has no power to compel them to file their annual report since doing so violates their employee&#x27;s 1A rights. reply atoav 18 hours agorootparentprevSo how do you jail a corporation when they comitted a crime?If you don&#x27;t they are not a person.If that discrepancy doesn&#x27;t feel unjust to you should do some soul searching maybe and maybe look at other places where corporation profit from their \"personhood\" without ever having to experience the negatives of actually being one. reply Nasrudith 17 hours agorootparentHow do you jail a political party? reply atoav 17 hours agorootparentYou don&#x27;t. They are not a person.I didn&#x27;t come up with the totally bonkers idea of declaring some organizational entity a person, so don&#x27;t expect me to defend the logical conclusions stemming from it. reply adhesive_wombat 18 hours agoparentprevIf they get benefits, maybe they can have the downsides like being arrested, imprisoned, and even executed. reply pickingdinner 13 hours agoparentprev> engage in speech against their willX or musk&#x27;s will? If X has a \"say\" on a \"speech platform\" that&#x27;s a major power imbalance.Not that X&#x27;s speech is this or that, but that it shouldn&#x27;t exist on it&#x27;s own. Musk or anyone may speak on behalf of X, but if there is no \"on behalf of\" there should be no speech there.Speech as in, to put forth opinion, ideology, values or anything beyond simply being silent and letting everyone else (users, which includes those who may speak on behalf of) speak. reply erellsworth 18 hours agoparentprevYes they are, more or less. https:&#x2F;&#x2F;www.pbs.org&#x2F;newshour&#x2F;nation&#x2F;corporations-people-doct... reply dehrmann 18 hours agoparentprevThe term you&#x27;re looking for is \"corporate personhood.\" reply ssalka 18 hours agoparentprevSeems like possibly a corollary from Citizens United reply declan_roberts 18 hours agoprevAll X has to do is make controversial content decisions the same way the other social media companies do: at the behest of our intelligence agencies and opaque government-funded \"partners\"! reply rnk 18 hours agoparentI can&#x27;t tell if you are kidding in thinking that&#x27;s what has been happening. The twitter files turned out to be a kind of huge exaggeration. The govt wasn&#x27;t really controlling twitter, there was a big exaggeration of what happened. reply sangnoir 17 hours agorootparent> The twitter files turned out to be a kind of huge exaggeration.\"Twitter Files\" was hyped as ushering an new era of radical transparency on Twitter moderation. If you take that on face value, it is ironic Twitter is now refusing to be transparent about reporting its moderation (or lack thereof).If you do not take it on face value, then it appears to have been a score-settling exercise motivated by animus against the previous management. reply sarcasmatwork 16 hours agorootparentprevYou&#x27;re not paying attention then.https:&#x2F;&#x2F;nclalegal.org&#x2F;2023&#x2F;07&#x2F;victory-federal-judge-rules-bi...https:&#x2F;&#x2F;www.politico.com&#x2F;news&#x2F;2023&#x2F;07&#x2F;05&#x2F;government-appeals-...https:&#x2F;&#x2F;www.nbcnews.com&#x2F;politics&#x2F;white-house&#x2F;court-eases-cur... reply Karunamon 17 hours agorootparentprevIt was enough control for a judge to outright bar a number of government agencies and people from communicating with any social media company on moderation matters, and then another judge to uphold that bar. reply bandyaboot 16 hours agorootparent> and then another judge to uphold that bar.Technically it was a panel of 3 5th circuit judges. This is the same circuit which believes that for government to, in any way, \"induce\" a social media platform into negatively affecting the reach of user content, is likely a violation of the first amendment. This would presumably include merely calling out a post and essentially saying \"hey I think this violates your policies, could you take a look?\". Simultaneously, they believe it&#x27;s a-ok for the government of Texas to expressly dictate social media moderation policies via legislation. When conservative-aligned plaintiffs bring lawsuits in the 5th circuit, they are able to win at each level of the federal court system without ever having to convince a single person that isn&#x27;t politically aligned with them. reply camdat 16 hours agorootparentprevThe requirements for an injunction are much lower than an actual ruling.The party must just show that they have a possibility of winning the case and that granting temporary relief will not cause additional harm to the plaintiff.To use that as proof that the defendant will win is ridiculous. reply Karunamon 16 hours agorootparenta possibility of winning the caseThe actual term used is \"likely to prevail\".Injunctions are not handed out willy-nilly, and the actual wording in the injunction should give you pause:\"The officials have engaged in a broad pressure campaign designed to coerce social-media companies into suppressing speakers, viewpoints, and content disfavored by the government\"Nobody said anything about \"proof that the defendant will win\". I said said that several judges have found evidence of unconstitutional pressure being applied. Please do not misrepresent a plain statement of fact. reply camdat 14 hours agorootparentThankfully, we just heard back from 5th Circut Appeals that the injunction was likely a significant overstep and was overturned.https:&#x2F;&#x2F;storage.courtlistener.com&#x2F;recap&#x2F;gov.uscourts.ca5.214... replymindslight 17 hours agoparentprevThis is myopically true while ignoring the large amount of influence coming from the business world itself, which inevitably just creates a partisan flamewar. Tying all the badness up in a tidy bag labeled \"government\" is just another method of control. reply lalaland1125 19 hours agoprevX should lose here. Governments have a long-standing right to force companies to disclose information that is important to consumers. reply solardev 19 hours agoparentI think there is a pretty good case to be made here that AB 587 is unconstitutional and violates the 1A. Other states have made similar laws and those are being challenged up to the Supreme Court. I bet this one will too unless California overturns it. https:&#x2F;&#x2F;www.concordlawschool.edu&#x2F;blog&#x2F;news&#x2F;california-social...Not a Twitter user or a Musk fan, so not defending them. But it&#x27;s hard for me to see how this law wouldn&#x27;t chill speech... reply fluidcruft 18 hours agorootparentI&#x27;ve mentioned this before, but the speech of Twitter users isn&#x27;t Twitter&#x27;s speech. So it seems laughable for them to claim this affects their speech whatsoever. Add to that the fact that Twitter (and all social media) are absolutely not interested in making their user&#x27;s speech their own and being responsible for it.There&#x27;s not even any compelled speech argument that Twitter is being forced to speak about something it does not want to. Twitter is a corporation, not a person. It has no right to exist and can have its business license revoked.Now, if Twitter does want to make each Twitter user&#x27;s speech its own speech, then maybe Twitter might have grounds to make a 1A stand. But as is Twitter and all social media absolutely do not want to be held responsible for what they publish so, frankly, they can pound sand.It would be different if Twitter were considered similar to a newspaper where Twitter acted as editor and could be held accountable for what they publish. But they will fight that tooth and nail. reply denton-scratch 18 hours agorootparent> So it seems laughable for them to claim this affects their speech whatsoever.AFAICS the proposal doesn&#x27;t require them to moderate Twitter users in any way; it requires Twitter to state publicly and clearly what their moderation policies are. But arguably stating its moderation policies is \"compelled speech\".Thing is, there&#x27;s plenty of compelled speech going on, including food labelling laws. There&#x27;s precedent (although I understand US law doesn&#x27;t have \"precedent\" as such, just appeals to successive senior courts). reply PeterisP 15 hours agorootparentThe tricky thing here is whether Twitter is required to have explicit and clear moderation policies that actually determine the decisions they are likely to take or whether their (constitutionally protected!) right to moderation includes the right to moderate absolutely arbitrarily, and if compelled to publish their policies, then just truthfully state that each decision might be solely determined by the mood of whoever decides that day? reply fluidcruft 18 hours agorootparentprevYeah, exactly. There&#x27;s no 1A territory here. The idea that a commercial business cannot be regulated and compelled by a State to produce a mere reporting of its relevant business activities is completely bonkers. reply kjksf 17 hours agorootparentIt would be even more bonkers if government could regulate without any restrictions.Can California demand that a restaurant provides daily report on how often each employee washes their hands and fine them $15k per day if they don&#x27;t or provide incorrect information?Per your simplistic argument it would be bonkers if California could create such law. It&#x27;s a mere reporting of its relevant business activity.To me it would be bonkers if California could create such onerous regulation.In law analogies only get you so far. I&#x27;m pretty sure that things like food labeling were challenged in courts and were found to not violate 1st amendment but the onerous requirements California tries to impose here are not even close to use them as some kind of precedent. reply fluidcruft 17 hours agorootparentThere are always consequences to regulations and practical restrictions seen at the ballot box. If the reporting is justifiable and required of all restaurants, then... so be it? If the People are unconvinced that it&#x27;s necessary or they don&#x27;t like it and think the government is out of touch, we throw the bums out. The very real risk of losing of power is what keeps them from passing the sorts of \"ridiculous\" regulations you are proposing. reply plorkyeran 15 hours agorootparentprevI don&#x27;t see why California should not be able to pass such a law? It&#x27;d be a really dumb law but the constitution does not try to forbid bad overly onerous laws as long as they aren&#x27;t specifically targeted at one person. reply mindslight 17 hours agorootparentprevThe sine qua non of corporations is compelled speech. A corporation can&#x27;t exist without articles of incorporation &#x2F; corporate charter and it needs written policies for basically everything it does to keep the corporate veil intact. reply solardev 18 hours agorootparentprevI haven&#x27;t looked at this in a bit, but I thought that companies are exempt from their users&#x27; speech only if they don&#x27;t make editorial decisions (and Twitter does, like reddit or HN or Slashdot). Am I mistaken? reply function_seven 17 hours agorootparentEDIT: I replied to this before refreshing and seeing sibling replies. So I guess all I have to add is another link.On the contrary, Section 230 is what allows platforms to make some editorial decisions without thereby assuming liability for all user-generated content.Before 230, what you said was true.I like this explanation: https:&#x2F;&#x2F;www.techdirt.com&#x2F;2020&#x2F;06&#x2F;23&#x2F;hello-youve-been-referre... reply solardev 16 hours agorootparentIt&#x27;s a good explanation, and more readable than the Wikipedia! Thanks for that. reply bbatsell 18 hours agorootparentprevThat is something oft-repeated in conservative circles without a shred of basis in law. In fact, Section 230(c)(2) of the CDA does the exact opposite. It was written to explicitly _grant_ immunity when companies moderate in good faith.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Section_230 reply solardev 18 hours agorootparentOK, thank you for the correction! I&#x27;ll read it and learn more. reply zimpenfish 18 hours agorootparentprevCompanies are allowed to moderate their platforms under Section 230.https:&#x2F;&#x2F;www.theverge.com&#x2F;2019&#x2F;6&#x2F;21&#x2F;18700605&#x2F;section-230-inte... reply solardev 18 hours agorootparentThank you! reply rgbrenner 19 hours agorootparentprevThe Texas and Florida laws are not equivalent to the CA law:Texas HB 20 prohibits the censorship of content based on viewpointFlorida SB 7072 ... prohibits platforms from removing certain types of accounts.So both laws require companies to engage in a type of speech. The CA law does no such thing: it just requires companies to disclose their policy and how it was applied. reply dylan604 18 hours agorootparentIf these \"laws\" are deemed valid under protection from the first amendment, then why are the laws necessary anyways? Why not just go after the offender for violating the first amendment? reply bcrosby95 18 hours agorootparentMaybe I&#x27;m misunderstanding what you&#x27;re saying, but only the government can violate the 1st amendment, not companies or individuals.Note that that doesn&#x27;t mean a company cannot violate a law with a basis in free speech. The 1st amendment isn&#x27;t the only law when it comes to this - this is where state laws step in. reply dylan604 17 hours agorootparent>only the government can violate the 1st amendmenthow do you figure this to be true? reply jonas21 17 hours agorootparentUh... because that&#x27;s literally what the First Amendment says?Congress shall make no law respecting an establishment of religion, or prohibiting the free exercise thereof; or abridging the freedom of speech, or of the press; or the right of the people peaceably to assemble, and to petition the Government for a redress of grievances.The 14th amendment later extended this to apply to state governments as well - but still only governments. reply dylan604 17 hours agorootparentBut a social platform can very much violate someone&#x27;s first amendment rights. Which is what all of this hubbub is about. So we&#x27;re saying that because we&#x27;ve said specifically gov&#x27;t can&#x27;t, we then now have to go back and make a law that says \"neither than corporations, other citizens, and any other party\" kind of legally worded something? reply solardev 16 hours agorootparentThere might be a misunderstanding here? The Bill of Rights (the first ten amendments) specifically applies to limiting the powers of the federal government. It doesn&#x27;t grant rights to individuals, it takes away powers from Congress. It doesn&#x27;t protect you against other citizens, but against government overreach.A company can&#x27;t violate someone&#x27;s free speech (or other rights) because it&#x27;s not the government. It literally isn&#x27;t under the purview of the amendments. If it does something illegal, that is become that act is made illegal under some other code, not because of the bill of rights. They can be prosecuted for criminal or civil violations, but it wouldn&#x27;t be a constitutional issue unless the government is the one doing it.If a social media site wants to silence you, too bad. If the government wants to silence you, that&#x27;s a big deal.https:&#x2F;&#x2F;uwm.edu&#x2F;free-speech-rights-responsibilities&#x2F;faqs&#x2F;wha...https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;United_States_Bill_of_Rights(Edit: However, your argument isn&#x27;t unheard of. Here&#x27;s one opinion from the American Bar Association arguing the same thing -- that the 1A ought to apply to privately run public forums too: https:&#x2F;&#x2F;www.americanbar.org&#x2F;groups&#x2F;crsj&#x2F;publications&#x2F;human_r...) reply shadowgovt 16 hours agorootparentprevWe&#x27;d have to make that law if we wanted to put that constraint on corporate speech, yes. The fact government can&#x27;t kick you out of the public square for questioning government doesn&#x27;t mean I, a homeowner, can&#x27;t kick you out of my living room for questioning my taste in home decoration (or that Altria, a cigarette company, can&#x27;t remove you from their property for yelling to all and sundry in their lobby that cigarettes cause cancer, even if it&#x27;s true).It&#x27;s not clear such a law is wise. ¿Cui bono? for tying private forum&#x27;s hands against kicking Nazis, white supremacists, nation of Islam, Patriot Front, Proud Boys, etc. off their website? reply mindslight 15 hours agorootparentThe fundamental problem is the US&#x27;s negative framing of rights. A negative framing that is only in terms of the de jure government, to avoid logical contradiction. This leads to the perverse winner-take-all argument that corporate censorship is itself protected corporate speech. A positive framing of the right to free speech would allow for a logically-imperfect yet equitable balance between the interests of individuals&#x27; speech and corporate speech. reply bcrosby95 13 hours agorootparentNote that the negative framing does not necessarily limit other laws to have an affirmative framing, for example see the Pruneyard case:https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Pruneyard_Shopping_Center_v._R...> This holding was possible because California&#x27;s constitution contains an affirmative right of free speech which has been liberally construed by the Supreme Court of California, while the federal constitution&#x27;s First Amendment contains only a negative command to Congress to not abridge the freedom of speech. This distinction was significant because the U.S. Supreme Court had already held that under the federal First Amendment, there was no implied right of free speech within a private shopping center.[4] The Pruneyard case, therefore, raised the question of whether an implied right of free speech could arise under a state constitution without conflicting with the federal Constitution. In answering yes to that question, the Court rejected the shopping center&#x27;s argument that California&#x27;s broader free speech right amounted to a \"taking\" of the shopping center under federal constitutional law.I generally believe that companies that enter spaces that previously afforded \"users\" first amendment protection should have similar laws to protect the free speech of users in said privately owned \"spaces\".But that would require new laws. reply shadowgovt 13 hours agorootparent> I generally believe that companies that enter spaces that previously afforded \"users\" first amendment protection should have similar laws to protect the free speech of users in said privately owned \"spaces\".What spaces are those? From where I sit, we went from BBSes (where the admin controlled the signal) to self-hosting (where the user controlled the signal, unless it was so onerous that an ISP cut service) to cloud-hosting (where a company controls the signal).The ideal free speech world where people just spoke their minds online is a fantasy borne more out of lack of interest to regulate than power to regulate. Remember, the original network was a \"network of peers\" where most users were not pseudonymous; their academic or military sponsors could cut their access.The network has never had anything like absolute free speech. Communication over the network has always been an affair involving at least two parties who must agree on the transmission of signal. reply bcrosby95 12 hours agorootparent> What spaces are those?Town square. Snail mail. You&#x27;re thinking very 2020s&#x2F;technical here. reply shadowgovt 11 hours agorootparentIn the town square, the government can&#x27;t remove you but a fellow citizen can just stand there and scream \"NOOOOPE!\" to everything you say, over and over again. And the local grocer is allowed to turn you away as a result of those things you were screaming in the town square earlier about their daughter.Snail mail is a great example, but the burden of proof is on those who think the Internet should work the same to justify why a model baked into federal Constitutional requirements should be used to justify de facto nationalization of private infrastructure. Now, if somebody wanted to put the tax dollars up for the federal government to build out \"the people&#x27;s Internet,\" regulated with something akin to first Amendment protections for transiting the network and rights to privacy, I certainly wouldn&#x27;t be against it. reply solardev 14 hours agorootparentprevHow would a similar situation play out in other countries? My understanding is that the US already has some of the strongest free speech protections despite this (compared to the UK and EU especially). Are there countries, at least ones with strong rule of law, that do this differently and grant individuals rights inalienable by anyone? reply mindslight 14 hours agorootparentI don&#x27;t know that there is an existing country with stronger protections for free speech than the US, and it is true we do take that for granted. My point is that the negative framing in terms of the de jure government has reached its limits, with those seeking control essentially reinventing governance through \"private\" entities with \"voluntary\" agreements that in reality aren&#x27;t so private or voluntary.It&#x27;s quite tempting to cheer for autocratic corporate power when it appears to be doing things that you find favorable, but the wind can shift on a dime. reply shadowgovt 14 hours agorootparentprevIn general, the corporate liberty to choose who to signal boost and what signal to drop isn&#x27;t even a speech question; it&#x27;s a freedom-of-the-press or freedom-of-association question. The fact someone said something to me (or to a company) compels neither of us to repeat it like a parrot. Similarly, the things I post here are not my own and dang can decide to drop this whole post (or the whole thread) if he wants; the fact I run a Mastodon node doesn&#x27;t imply I have to peer to anyone, de-peer from anyone, or allow anyone&#x27;s scribblings to traverse my node, &c.The Internet is a network; communication on a network implies (at least) bipartite agreement. Either side of the conversation has veto over the signal. reply solardev 14 hours agorootparentI think the ambiguity of having speech, religion, and press all rolled into one short paragraph is part of why we&#x27;ve historically struggled so much with the 1A.I wish we could just scrap the Constitution and start over with a version controlled and annotated wiki of rules written in everyday language.Our legal framework is so undemocratic (maybe even anti-democratic) and unable to address any of the major challenges of modern society... sigh. End rant. reply mindslight 14 hours agorootparentprevYour comment is just describing the winner-take-all negative framing environment in a more colorful manner, while willfully ignoring where the abstraction falls apart. For example leaning on the idea that communication requires a \"bipartite\" agreement is a bit rich when the sheer majority of web communication involves at least three parties.FWIW you can apply your argument to an ISP to make the argument that it&#x27;s right for them to arbitrarily censor as well. reply shadowgovt 13 hours agorootparent> at least three partiesThat&#x27;s just two bipartite agreements end-to-end. I could technically have said an n-ary agreement, with the freedom to select multiple paths, for more accuracy; I figured \"bipartite\" encompassed all the relevant nuance.> FWIW you can apply your argument to an ISP to make the argument that it&#x27;s right for them to arbitrarily censor as well.Yes and. ISPs generally do have that liberty and do employ it when they deem it necessary (see Hurricane Electric cutting ties with IncogNET for doing business with KiwiFarms, various ISPs cutting user accounts for piracy, AUP, or TOS violations, etc.). The backstop against that behavior is generally that they&#x27;re leaving money on the table if they don&#x27;t provide as many people as much service as their system capacity permits. But in general, legally or morally, nobody is entitled to more access than showing up at the public library to use a community kiosk (and if you do that and look at porn, they can ban you too). reply mindslight 7 hours agorootparent\"Bipartite\" most certainly does not encompass all the nuance, and actually functions to confuse. In a scenario of two parties, one wanting to communicate and the other one wanting to not listen, it&#x27;s quite clear that the second party is not obliged to listen.Whereas these three (or more) party situations are exactly what we&#x27;re discussing here - where two endpoint parties are trying to communicate yet there is a third party in the middle playing the position of censor. This is the entire crux of the matter.When you say that ISPs do have the liberty to censor, are you speaking positively or purely descriptively? Because what I see is a description of our traditional values that had been previously serving to foster an open society, but have now fallen apart with companies scaling to own much larger portions of markets, prying into what should be the business of their customers, and colluding with each other to create unavoidable de facto governmentesque power. If you really don&#x27;t see the problem with an ISP censoring, then how about the electric company?Also the idea of companies being incentivized to not unjustly deny service because they&#x27;d be leaving business on the table is blatantly fallacious. reply solardev 18 hours agorootparentprevThe states don&#x27;t have the time and money to go after millions of individuals, so they try to curtail it at the provider side instead. Also to send a message. A lot of it is just political virtue signaling.(edit: sorry, I misread the parent. Individuals cannot violate the 1A, only governments can) reply Chabsff 18 hours agorootparentprevIt&#x27;s necessary because some (let&#x27;s face it, X) social media companies are suspected of lying (aka engaging in fraud) to consumers by claiming that they are taking aggressive action against hate speech while not actually doing so.Sure, they could just take them to court for that fraud and get that information via discovery, but just compelling companies to publicly disclose the info bypasses all that and puts the decision making back into the hands of the consumers. And what is more American than that? reply solardev 18 hours agorootparentprevIANAL, but I think it&#x27;s a slippery slope that may fall too close to prior restraint. It is specifically asking a private entity to report on what it considers hate speech (which itself is still 1A protected), etc.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Prior_restraint?wprov=sfla1 reply rgbrenner 18 hours agorootparentReporting on actions is the same as prohibiting an action? Please elaborate on how this works. reply solardev 18 hours agorootparentHaving a published content moderation policy would presumably mean that companies are expected to abide by it, which limits their editorial freedoms. Asking a company to be consistent in its approach to speech is still a restriction on its speech. Most people and companies are hypocritical and self-serving when opportunities arise, but that&#x27;s still protected.Maybe the reporting law doesn&#x27;t itself prohibit a company from acting against its published terms, but it sure creates a database that could easily be weaponized against them by a future law or unchecked executive order. reply rndmize 18 hours agorootparentThis is a leap. If they publicly espouse some sort of policy and don&#x27;t adhere to it, it makes them look hypocritical - but I don&#x27;t see how this limits their editorial freedoms. They can change the policy, or actually adhere to it.> Maybe the reporting law doesn&#x27;t itself prohibit a company from acting against its published terms, but it sure creates a database that could easily be weaponized against them by a future law or unchecked executive order.I mean, I guess? I feel like the same could be said for laws that require worker injury reporting. If at some point in the future it&#x27;s decided that there should be some regulation around moderation policies (and this seems increasingly inevitable) it would be useful to have some actual data to work off. reply SAI_Peregrinus 16 hours agorootparentThe moderation policy could even be \"whatever the moderator feels like on a given day\". That might get them negative publicity, but it&#x27;s a policy, and satisfies the law. reply solardev 15 hours agorootparentYes, but realistically, what&#x27;s going to happen the moment they post a policy like that? The media jumps on them, (more) advertisers pull out, etc. That wouldn&#x27;t have happened if they weren&#x27;t compelled to publish these content decisions upfront. reply PopAlongKid 18 hours agorootparentprev> it sure creates a database that could easily be weaponized against them by a future law or unchecked executive order.Which is clearly not \"prior restraint\". reply solardev 16 hours agorootparentIt might be close enough to be considered a chilling effect? It&#x27;s ultimately up to debate by high-powered lawyers. I don&#x27;t think ANY 1A issue is ever clear-cut...It&#x27;s often the case that if a law were to have the potential to chill speech that would otherwise be expressed or not expressed (and I think this law falls under that category), it&#x27;s open to questioning at leasthttps:&#x2F;&#x2F;www.mtsu.edu&#x2F;first-amendment&#x2F;article&#x2F;897&#x2F;chilling-ef...I don&#x27;t know how this will ultimately turn out... maybe California will win, but it&#x27;s at least unclear enough to be worth a legal debate, I think? replyharpooniker 19 hours agorootparentprevHow would it restrict speech? reply solardev 18 hours agorootparentI think it would have a chilling effect on social media providers who will have to think \"how will our policies and practices look to California\" (and other states with similar laws). If they have to report the changes every year, it basically strongly pressures a company to report that they are following whatever is politically correct at the moment. It&#x27;s a slippery slope that approaches&#x2F;enables prior restraint.IMO only and IANAL. reply rgbrenner 18 hours agorootparentThe law has no penalties for the policy you implement. So AB 587 isn&#x27;t restraining any speech. If CA passes another law that uses the information to restrain speech, then that law may be unconstitutional. But AB 587 doesnt become unconstitutional by imagining all the ways it could be used unconstitutionally. reply jonas21 17 hours agorootparentThat&#x27;s not how the Supreme Court has ruled in the past. If a law makes people reluctant to exercise their first amendment rights because of the ways in which it can be used against them in the future - then it has a \"chilling effect\" and can be unconstitutional even if the law itself has no penalties.In Lamont v. Postmaster General [1], the Supreme Court struck down a law requiring the recipient of Communist propaganda to state that they consented to receive it before it would be delivered. There was no penalty for doing so, but the court rule unanimously that it \"imposes on the addressee an affirmative obligation which amounts to an unconstitutional limitation of his rights under the First Amendment.\"[1] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Lamont_v._Postmaster_General reply solardev 18 hours agorootparentprevIt&#x27;s a pretty broad judgment call, isn&#x27;t it? If it effectively chills speech, it could be a 1A issue. I guess it&#x27;s up to the SC to interpret.Thr lawsuit itself points out that, if nothing else, the California bill forces companies to editorialize on what speech is considered hateful etc. under California&#x27;s guidelines. That categorization itself is a modern politicized process (especially in polarized states, deep blue or deep red) and different from older 1A protections. That wasn&#x27;t my argument, but is part of the lawsuit. reply kelseyfrog 18 hours agorootparentprevThe reality is that not doing it is also a slippery slope with greater incline. Avoiding one slope jeopardizes another. reply harpooniker 18 hours agorootparentprevHow would it show they are following what it politically correct?For example if they ban a post for something that would be reflected but if they don&#x27;t that&#x27;s not shown reply solardev 18 hours agorootparentSorry, could you please rephrase that? Didn&#x27;t quite catch it? reply moralestapia 19 hours agorootparentprev>Even if you don&#x27;t like anything about Elon Musk’s leadership of X,From TFA.>Not a Twitter user or a Musk fan,From your comment.It sucks that the level of debate all over the place, including this forum full of people who are more educated than average, has fallen so low that the (extremely simple to grasp) concept of ad hominem is out of place and one has to write such disclaimers frequently in order to bring an argument into a discussion. reply dragonwriter 18 hours agorootparentOne of of the two “disclaimers” you cite is an common attempt to reinforce one’s own an argument by painting it as a statement against bias, which is a subtle form (positive) ad hominem, not an attempt to avoid ad hominem and focus on pure rational argumentation. reply denton-scratch 18 hours agorootparent\"Slippery slope\" and \"ad hominem\" are the names of fallacies. A fallacy is a defective step in logical reasoning.Hearers shouldn&#x27;t be persuaded by fallacies; they&#x27;re deployed in persuasive speech because (a) many people aren&#x27;t familiar with logic, and find them persuasive, or (b) because the speaker isn&#x27;t familiar with logic, or (c) because the speaker is out of logical arguments, but is still determined to win the argument.Or some combination of the three. reply solardev 18 hours agorootparentprevI think it&#x27;s only human, no? That we even have a fancy Latin phrase for it suggests it&#x27;s a phenomenon that&#x27;s been with us for a while, and that the ancients and the greats and the geniuses alike have had to work to keep in check.I know I certainly had to hold that impulse in check, myself. At first I was like \"Oh god, what shenanigans is that guy up to now.\" And then I read the article and realized wait, this guy I dislike might actually have a point this time.I say that not to be protective, really, but to point out that I think they may have a case here even though I find their entire operation suspect. reply Bjartr 19 hours agoparentprevI agree, this seems fairly cut and dry. People are jumping past the law as written to downstream actions that become feasible for the state if the law exists. This required reporting isn&#x27;t the problem to attack though, it&#x27;s those downstream actions.Now perhaps (probably) there should be a mechanism in place to stop the gov&#x27;t from even getting this far, but, AFAIK, such a mechanism does not yet exist and it&#x27;s certainly not the first amendment. reply mcpackieh 19 hours agoparentprevIs there precedent for the government requiring traditional newspapers to submit reports like this explaining their editorial processes and priorities? reply empath-nirvana 19 hours agorootparentSure, let&#x27;s treat Twitter like a traditional newspaper, which would mean they&#x27;d be legally liable for all the content they \"publish\". I think given that they&#x27;re monetizing extremist content, that&#x27;d be a really smart legal play for them. reply InitialLastName 19 hours agorootparentprevDo traditional newspapers claim to be legally exempt from liability for the content they publish&#x2F;don&#x27;t publish? reply mcpackieh 19 hours agorootparentDoes that mean no? reply maxwell 19 hours agorootparentAre you asserting the network formerly known as Twitter is a publisher (in the legal&#x2F;technical sense)? reply mcpackieh 19 hours agorootparentI am asking if there is any legal precedent for the government forcing any traditional publisher to explain what legal speech they choose or refuse to publish. If a newspaper decided they want to publish a bunch of letters sent to them by the public (as they do), is there precedent for the government compelling the newspaper to explain the basis by which they choose which letters to publish or forbid?I think this is a case of \"it&#x27;s different because computers\", and this wouldn&#x27;t fly if it were a traditional publisher putting ink on paper. reply rewmie 18 hours agorootparent> I am asking if there is any legal precedent for the government forcing any traditional publisher to explain what legal speech they choose or refuse to publish.Either you&#x27;re failing to understand the question, or you&#x27;re trying to be disingenuous about it.Newspapers editorialize their content. Elon Musk&#x27;s Twitter is not, and is claiming to have no control over what content third parties publish throught their service.However, Elon Musk&#x27;s Twitter is also manipulating the contents that third parties publish through their service by means of moderation&#x2F;censorship and boosting.Given they claim they hold no editorial control over what goes through their pipes but still manipulate the content, they have a responsibility to demonstrate that they are not liable for that content by specifying exactly which rules they enforce and how they enforce them.Do you understand the difference between assuming responsibility over the content, and claiming that they are not liable for the content they distribute because they don&#x27;t pick and choose what goes through their pipes? reply slt2021 16 hours agorootparent>Twitter is also manipulating the contentsare they rewording or rephrasing tweets? If users can still see original tweet content, why do you call it \"manipulate its contents\" ?I just posted \"hello world\" and my tweet appeared as-is. Did not experience manipulating by Twitter at all reply maxwell 16 hours agorootparent\"by means of moderation&#x2F;censorship and boosting\" reply rewmie 15 hours agorootparentprev> If users can still see original tweet content (...)It was already well established that they can&#x27;t. For example, when Elon Musk&#x27;s Twitter was already caught shadow-banning people posting pro-Ukraine content, and when Elon Musk open-sourced some of the original Twitter&#x27;s code, people found out that it hardcoded settings to ban discussions on Russia&#x27;s invasion of Ukraine.Past HN discussion on Musk&#x27;s censorship of the invasion of Ukraine:https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=35519224 reply slt2021 15 hours agorootparentit did not ban discussions, the algorithm was for ranking tweets in timeline.because you cannot fit all trillions of tweets into everyone&#x27;s timeline - by definition some tweets will have to be chosen over the overs.if a user posted something about Ukraine, his tweet would still show up in his follower&#x27;s timeline for \"Following\", just not Featured (For You) and not always. Mind you I follow this topic and my feed (For You) is like 50% of tweets covering Ukr-Rus war updates. So I never feel any censorship for the war from titter.it is not censorship, because if you follow a user you would still see tweets in its original content without any altering reply rewmie 15 hours agorootparent> it did not ban discussions, the algorithm was for ranking tweets in timeline.Not really. Twitter was hardcoded to downrank discussions on Russia&#x27;s invasion of Ukraine, and is now shadow-banning pro-Ukraine users but strangely not pro-Russia.Nevertheless, the whole point is that Elon Musk&#x27;s Twitter needs to specify how it&#x27;s censoring tweets, as they cannot claim they don&#x27;t editorialize while actively suppressing and censoring discussions that contrasts with their personal preferences. Russia&#x27;s invasion of Ukraine is a mere example on the broad editorial reach of Elon Musk&#x27;s Twitter, and one where Elon Musk himself was already caught red-handed supporting the invaders. reply slt2021 11 hours agorootparentDo the same standards apply to zuck and fb feed? to instagram feed? to linkedin feed? reply EdSchouten 19 hours agorootparentprevRegardless of what the answer to your question is, X is not a newspaper. reply mcpackieh 19 hours agorootparentIn principle they have the same constitutional rights as newspapers. Unless a double standard is being applied \"because computers\", which is what I am teasing out. The courts are better about upholding the First Amendment when there is ink being put on paper, because that&#x27;s something which is well established and understood. As soon as computers get involved, people get this idea that old rules no longer apply \"because computers\".This is why the book PGP Source Code and Internals was published; because ink on paper makes the matter clear cut. reply wgjordan 18 hours agorootparentThe so-called &#x27;double standard&#x27; in AB-587 (defining &#x27;social media platform&#x27;) is entirely consistent with the existing federal &#x27;double standard&#x27; set up a quarter-century ago by Section 230, which makes providers of &#x27;interactive computer services&#x27; immunity from liability for content moderation decisions. This bill can be seen as oversight layered on top of those existing content-moderation liability protections.If you want to tilt at &#x27;because computers&#x27; windmills, Section 230 is the real target. reply Volundr 18 hours agorootparentprevThe difference isn&#x27;t \"because computers\", the difference is that Twitter claims it has no editorial control over the content published on its platform while a newspaper claims complete editorial control. That&#x27;s a huge functional difference. reply rewmie 18 hours agorootparentprev> In principle they have the same constitutional rights as newspapers.This sort of pointless truism means nothing at all. The crux of the matter boils down to the common carrier status, and whether companies can be held liable for the content being handled through their service. If a social media company editorializes the content it distributes, it&#x27;s liable for each and any consequence of distributing it. Simple as that. reply function_seven 17 hours agorootparent> If a social media company editorializes the content it distributes, it&#x27;s liable for each and any consequence of distributing it. Simple as that.My apologies if I am misinterpreting your statement here, but this feels like a misunderstanding of section 230.https:&#x2F;&#x2F;www.techdirt.com&#x2F;2020&#x2F;06&#x2F;23&#x2F;hello-youve-been-referre... reply freejazz 19 hours agorootparentprevThere&#x27;s precedent for the government to force various different types of organizations to disclose information in the public interest. Newspapers don&#x27;t partake in any of the activities that this disclosure rule addresses, so I don&#x27;t think a court will find it to be a relevant comparison, because it has nothing to do with the kinds of activities the government is trying to regulate. reply whartung 18 hours agorootparentI don&#x27;t know about that.Newspapers enforce editorial policy over their opinion columns and things like which letters to publish. This law sounds like, if it actually applied to them, which is doesn&#x27;t, they would need to submit a report about why they didn&#x27;t allow \"Letter from Aunt Ethel\" to be published. What criteria did they use in not allowing it to be published, etc.Why did they publish \"Letter from Uncle Frank\" instead.Simply, they need to enumerate their internal editorial policies.And I can see it argued that editorial policies are political speech. We all know magazines or publications and websites that represent a political philosophy, what articles they publish, how the articles are worded, etc. That&#x27;s everywhere. \"Why didn&#x27;t you allow XXX to be published? Because we don&#x27;t like the point of view of XXX!\"And part of having a political philosophy and the speech rights around it is that you should be allowed, should be \"free\" that is, to not say anything at all! When you start getting \"have you stopped beating your wife\" questions, you should be allowed to say \"no comment\". Compelled speech is not freedom of speech. Publishing in detail your moderation policies and activities is arguably compelled release of a political philosophy. Now, does a Corporation have such a right? Today, it&#x27;s hard to say. If a Corporation apparently has the right to impact elections (economically) that implies it has a political position and perhaps that the detailing of that position (or not) should be a protected. IANAL.The big problem here is this shouldn&#x27;t be an issue. How many websites have a privacy policy of \"We&#x27;re going to gather everything we can from you, and sell it to the highest bidder. If we could get your DNA, we&#x27;d sell that too.\"That should be a perfectly viable \"privacy policy\". If X has to publish \"yes, the exact details\" of how they moderate extreme speech, maybe they&#x27;ll just publish \"we don&#x27;t\" and leave it at that. Which, of course, brings even more, indirect, scrutiny.In the end, there&#x27;s no good answer to this question. Every answer any service would publish, is the \"wrong answer\". reply freejazz 16 hours agorootparentBut Twitter isn&#x27;t a newspaper engaging in editorial decisions. It is a massive online communications platform that is moderating posts, most often, on an automated basis. I don&#x27;t think there&#x27;s any actual support for your comparisons at all.>Simply, they need to enumerate their internal editorial policies.I think you are confused, Twitter already publishes it&#x27;s moderation policies, this is a report on to what extent they stay true to that. Your argument would maybe make more sense in a context where a newspaper had to provide a report on its editorial decisions (which obviously go well beyond the letters to the editor section). But that really only actually serves to the emphasize the huge difference between editing and moderating.>In the end, there&#x27;s no good answer to this question. Every answer any service would publish, is the \"wrong answer\".I don&#x27;t think you are engaging in this topic with any honest, especially if this is the conclusion you are coming to. As far as I can tell the only wrong answer to the report would be if it was not accurate about the information it stated or was incomplete. There seems to be nothing as regards to judging whether or not a moderation system is good or bad, or \"does the right thing\". Let alone something so politically pointed as what you suggested. reply the_optimist 19 hours agorootparentprevOP analysis is specious at best. This is why you shouldn’t ask non-lawyers for legal opinions.Lol at the aggressive partisan downvoting. Sorry you feel compelled to such anti-Musk right-think, either sock accounts or a display of hackery. Either way, very stoopid. reply kergonath 19 hours agorootparentI was going to write that I hope Musk does not get any advice from HN. But then he gets it from Twitter so who knows… reply sneak 19 hours agoparentprevI disagree. This seems like a blatant 1A violation by the state:> AB 587 passed in September 2022, requiring social media platforms to submit a \"terms of service report\" semi-annually to California&#x27;s attorney general, providing \"a detailed description of content moderation practices used\" and \"information about whether, and if so how, the social media company defines and moderates\" hate speech or racism, extremism or radicalization, disinformation or misinformation, harassment, and foreign political interference. Under the law, social media platforms must also provide information and statistics on any content moderation actions taken in those categories.All of the things listed, with the exception of foreign political interference, are protected expression. This is the government trying to outsource censorship. reply woodruffw 19 hours agorootparentThe law does not appear to mandate any particular form of expression by Twitter, other than filing paperwork that documents their intended policies. Notably, it doesn&#x27;t seem to require Twitter to have any particular policies around extremism; only that, if they have such policies, they should be made transparent to the public.I&#x27;m not aware of a legal case in which a private entity has successfully made the \"compelled speech\" argument against government paperwork; that kind of argument is more typically associated with \"the IRS is unconstitutional because it compels me to file taxes\"-style legal crankery. reply Guvante 19 hours agorootparentprevThat isn&#x27;t Twitter&#x2F;X&#x27;s argument though.Their argument is producing the document is forced speech.That argument is not aligned with any precedent. The government absolutely has the right to compel you to talk about your internal actions.Your argument is effectively slippery slope falacy given the government is tracking not enforcing action here. reply Chabsff 19 hours agorootparentprevThe law doesn&#x27;t compel any form of moderation though. All it does is require transparency. How is that censorship? reply sneak 19 hours agorootparentI&#x27;m sure the government&#x27;s interest in what is or isn&#x27;t censored, or how, is purely academic. That&#x27;s why they had the report to to the attorney general&#x27;s office and not the state university.Pretty nice business you got there. Shame if something were to happen to it. reply Chabsff 19 hours agorootparentThe reports are to sent to the attorney general who has to make them publicly available to everyone, including the universities.That being said, the fact remains that you are presenting the law as if it was was you expect the next step to be, which is misleading at best. reply empath-nirvana 19 hours agorootparentprevAre you just sort of generally objecting to the enforcement of laws and regulations or do you have a specific problem with this one. reply growse 19 hours agorootparentprevHow is this different to any other sort of regulation? reply rangerelf 19 hours agorootparentprevI disagree. \"X\" does those things as part of a profit generating enterprise; if those things affect the greater population then they absolutely should be disclosed. And before someone says \"What about Meta? What about Google? What about Youtube?\" Yep, them too. They should all disclose the basis of their moderation decisions. Because they&#x27;re used to steer public opinion. Because it&#x27;s been demonstrated that they have been used to manipulate public perception to the detriment of groups of people. Because people have died from misinformation. reply reaperman 17 hours agorootparentI find it&#x27;s important to avoid \"is&#x2F;ought\" fallacies. I&#x27;m not sure my warning actually applies here -- this seems like a properly complicated legal topic and especially whenever something has a lot of contemporary relevance, there&#x27;s a lot of unexpected flexibility in which precedents are considered vs. ignored. But it&#x27;s a good rule of thumb to follow nonetheless. reply jellicle 19 hours agorootparentprevWhich part of the First Amendment says corporations have a right not to disclose how they run their business? reply LanceH 19 hours agoparentprevHow quickly the sides have flopped on this one. reply HelloMcFly 18 hours agorootparentThe US political Left has wanted visibility into content moderation since at least the 2010s, so the idea that somehow this is \"flip-flop\" is disingenuous. The US political Right has wanted this information too, at least until they felt they had one of their own pulling the levers. Keep in mind that nothing about this policy mandates any content be posted or removed, nor does it impact X&#x27;s ability to ban or not ban anyone they want for content they post (laws from Florida and Texas cannot claim the same). reply perihelions 18 hours agoprevThe Washington Post quoted an expert as saying this law, A.B. 587, is \"likely to be struck down as unconstitutional\". This back in 2022 when the law passed—before Elon Musk attached himself to this story and polarized everyone.https:&#x2F;&#x2F;www.washingtonpost.com&#x2F;technology&#x2F;2022&#x2F;09&#x2F;13&#x2F;califor... (\"New California law likely to set off fight over social media moderation\") reply hnburnsy 17 hours agoparentMight be interesting to see if WaPo posts an article that slants in favor of the bill now that Musk is against it. That article was quite neutral, IMO. reply mrguyorama 17 hours agorootparentNewspapers pretty regularly have articles on multiple sides of an issue, though sometimes one viewpoint is relegated to the opinion section.Crucially however, \"this law is unconstitutional for reason Q\" does not mean that \"Musk says making their business codify their moderation is against free speech\" is correct. reply r721 19 hours agoprevMike Masnick&#x27;s opinion:>Elon Musk Files Really Strong 1st Amendment Challenge To California’s Terrible Social Media ‘Transparency’ Lawhttps:&#x2F;&#x2F;www.techdirt.com&#x2F;2023&#x2F;09&#x2F;08&#x2F;elon-musk-files-really-s... reply digging 19 hours agoparentI don&#x27;t know who Masnick is but the loaded headline tells me I shouldn&#x27;t care. So, should I? reply DashAnimal 19 hours agorootparentMike Masnick is probably one of the most critical people of Elon. You&#x27;ve may have read one of his articles prior, perhaps in the early days when Elon bought Twitter. His analysis of Elon&#x27;s obligations to purchase Twitter, criticism of Elon&#x27;s approach to content moderation (and lack of understanding), it&#x27;s all been pretty good and legally sound.The fact that he is praising Elon here says something. reply freejazz 19 hours agorootparentWhether or not he&#x27;s critical of Elon has no bearing on his legal analysis reply MichaelDickens 18 hours agorootparentIn theory, where people are perfect reasoners, it doesn&#x27;t. Realistically, people tend to form opinions that fit the narratives they want. If someone who normally takes one side of a politicized issue instead takes the other side, that suggests that the case for the other side is particularly compelling because it compelled this person to switch sides. reply freejazz 18 hours agorootparentI&#x27;m more interested in his qualifications in legal analysis to come to his conclusion that Musk&#x27;s challenge is strong, and frankly, I don&#x27;t really think his opinions on Musk have a strong bearing there. Especially given the fact that I don&#x27;t think there is a reasonable legal basis to say the challenge is strong. So him being against Musk has gotten me nowhere in this. reply r721 19 hours agorootparentprevTech&#x2F;legal blogger:https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Techdirthttps:&#x2F;&#x2F;www.nytimes.com&#x2F;2023&#x2F;07&#x2F;29&#x2F;technology&#x2F;mike-masnick-t...He&#x27;s usually quite critical of Musk, so it&#x27;s a newsworthy thing that he supported him in this case. reply shafyy 18 hours agorootparentprevMasnick is a long-time and respected tech blogger with a good legal knowledge as far as I can tell. He&#x27;s article are usually pretty fact-based and well-informed. And as others have said, he&#x27;s usually pretty critical about Musk. So yes, I think his opinion on this matter is to be taken seriously. reply perihelions 18 hours agoparentprevIt&#x27;s not really so much \"Mike Masnick&#x27;s opinion\" as \"Masnick explaining his TechDirt colleague&#x27;s, Eric Goldman&#x27;s, opinion\".Eric Goldman is a \"leading expert in the fields of Internet Law\" [0]. His assessment of this bill&#x27;s constitutionality is probably a good one. The Washington Post cited it in one of their stories [1], and quoted the part where he says it&#x27;s \"likely to be struck down as unconstitutional at substantial taxpayer expense\".[0] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Eric_Goldman[1] https:&#x2F;&#x2F;www.washingtonpost.com&#x2F;technology&#x2F;2022&#x2F;09&#x2F;13&#x2F;califor... reply perihelions 18 hours agoprev65 additional comments here:https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37442998 (\"X challenges California’s new transparency law as unconstitutional (techcrunch.com)\") reply whywhywhywhy 18 hours agoprevFrom the definition in the bill how a \"Social media platform\" is defined has no requirement to userbase, so wouldn&#x27;t every Mastodon server and small self hosted message board have to submit to this too or face fines?https:&#x2F;&#x2F;leginfo.legislature.ca.gov&#x2F;faces&#x2F;billTextClient.xhtm... reply hnburnsy 17 hours agoparent>22680. This chapter shall not apply to a social media company that generated less than one hundred million dollars ($100,000,000) in gross revenue during the preceding calendar year. reply hnburnsy 17 hours agorootparentI think that this would be this list, not sure about jurisdiction...RedditPinterestSnapTikTokXLinkedInWeChatYoutubeMeta reply hnburnsy 17 hours agorootparentTwitch? reply faeranne 17 hours agorootparentI don&#x27;t think Twitch fits the other definitions, 22675(e)(2)(b) probably could be argued to not fit with Twitch. reply jmyeet 17 hours agorootparentprevSo, before too long even Twitter won’t be affected. reply faeranne 17 hours agoparentprevI was about to type up a message about how this affects private services too, buuuuut... section 22680 pretty summarily removes self hosted instances. I doubt any of them are making $100,000,000 profit per year. reply hnburnsy 17 hours agoprevThis feels like the NSA, hey citizens we aren&#x27;t capturing the content of your phone calls, just the metadata around your phone calls. reply charles_f 19 hours agoprevNot that I am a particular fan of Twitter, and I think forcing some transparency per how you moderate content is quite a good idea - but doing that at a state level is annoying. Every nation already has its own rules and laws, which quite makes sense for physical goods, but is much harder to track for software. The US should at least have one unified rule when it comes to these topics. I understand it&#x27;s not really the way legislation is usually determined, but look at GDPR: even Europe (which is not a country) managed to do it in a centralized way. reply kjksf 16 hours agoparentThis is actually one of Twitter legal arguments against this law: section 230 explicitly gives companies ability to moderate user submitted content as they please.By putting additional restrictions on moderation activities (the requirement to report to government how they are moderating) this state law contradicts the federal law and the way things work, federal law wins.We will have to wait to see if the judge &#x2F; juries agree with this argument, but that&#x27;s one of the reasons Twitter believes this law should be eliminated. reply candybar 15 hours agorootparentThis is legally nonsensical - nothing about Section 230 precludes any further restriction on moderation by another entity. Section 230 is and has always been about the act of moderation not specifically creating liability for the carrier of user-generated content - nothing about Section 230 grants the publisher any specific right not to be subject to further moderation at another level.The first amendment angle is a stronger argument, but unfortunately for X, it&#x27;s also extremely weak and would require overriding decades of precedence and essentially create a crisis - there are far more onerous regulations in place that are still relied upon in a way that having them constitutionally challenged would be extremely damaging. reply candybar 15 hours agoparentprevI think this is a good take - the legal theories mentioned in this thread (1st amendment, Section 230) seem mostly baseless, but this doesn&#x27;t seem like appropriate legislation at the state-level either way. I don&#x27;t know enough about the commerce clause restrictions on state regulations, but I do wonder if that comes into play given that moderation policies will almost always have interstate and international commerce implications. reply lovecg 16 hours agoprevText of the law: > (3) A statement of whether the current version of the terms of service defines each of the following categories of content, and, if so, the definitions of those categories, including any subcategories: (A) Hate speech or racism. (B) Extremism or radicalization. (C) Disinformation or misinformation. (D) Harassment. (E) Foreign political interference.I like to imagine what this would look like if the other side was in charge. Say Russia or Florida for that matter. (In case of Russia, one doesn’t have to imagine).> (3) A statement of whether the current version of the terms of service defines each of the following categories of content, and, if so, the definitions of those categories, including any subcategories: (A) LGBT propaganda. (B) Woke ideology. (C) Harassment of religious freedoms.Not so hard to see how complying with this law would be compelled speech, is it now? Whether one says yes or no, you’re implicitly agreeing that these categories are real things. You can’t quite say “I disagree with the law as written” unless you sue, which is what’s happening here. reply woodruffw 16 hours agoparent> you’re implicitly agreeing that these categories are real thingsYou have this the wrong way around: these things have legal definitions in both state and federal law, and your \"agreement\" is not a mandatory condition.Put another way: the state of California is not interested in whether you think hate speech is real. The suit doesn&#x27;t hinge on that at all; it hinges on whether the government can compel corporate speech that amounts to a disclosure of internal policies. Which it can, for the same reason that the government can compel businesses to do their taxes, file permits, and disclose their political contributions. reply lovecg 16 hours agorootparentThis seems to be at least part of the complaint if I’m reading it right:> AB 587 thus mandates X Corp. to speak about sensitive, controversial topics about which it does not wish to speak in the hopes of pressuring X Corp. to limit constitutionally-protected content on its platform that the State apparently finds objectionable or undesirable. This violates the free speech rights granted to X Corp. under the First Amendment to the United States Constitution and Article I, Section 2, of the California Constitution.As for the precedent,> Which it can, for the same reason that the government can compel businesses to do their taxes, file permits, and disclose their political contributions.My understanding is that what can be compelled is pretty limited (e.g. facts in advertising, ingredients, etc.), it’s not a blanket precedent for the state to ask you to produce anything at any time. reply woodruffw 15 hours agorootparent> AB 587 thus mandates X Corp. to speak about sensitive, controversial topics about which it does not wish to speak in the hopes of pressuring X Corp. to limit constitutionally-protected content on its platform that the State apparently finds objectionable or undesirable.Except that it doesn&#x27;t: being compelled to produce evidence of your policies (which the law doesn&#x27;t even require exist) isn&#x27;t the same thing as being compelled to adopt a position. The law stipulates the former, not the latter.As a framing: when the EPA compels a corporation to produce an environmental impact statement, they&#x27;re not compelling the corporation to assume a position on the environment or anthropogenic climate change. Being asked to produce internal policies on hate speech, etc. similarly doesn&#x27;t compel any particular opinion on Twitter&#x27;s part.> My understanding is that what can be compelled is pretty limited (e.g. facts in advertising, ingredients, etc.), it’s not a blanket precedent for the state to ask you to produce anything at any time.We&#x27;re talking about factual materials that neither party disputes. Every state in the US has a complex web of transparency laws that compel companies to produce all kinds of information for reasons of public interest; this case is no different.Examples: Salary & pay transparency laws, board and LLC transparency laws, etc. reply PeterisP 14 hours agoparentprevNo matter what your opinion is on these categories, \"A statement of whether the current version of the terms of service defines each of the following categories of content\" is a quite straightforward question - what do your terms of service say? How can you get from that to \"implicitly agreeing that these categories are real things\"? If your ToS mentions them, then you say yes, if it doesn&#x27;t mention them, then you say no.Saying \"The currently active terms of service document (attached) does not define &#x27;woke ideology&#x27; as a separate category of content\" is a simple factual statement, and it does not imply anything that you didn&#x27;t already write in that terms of service agreement; I see nothing wrong with companies being compelled to provide an answer to this - it is relevant factual information about the product they&#x27;re distributing to people in California; the companies do not have a constitutional right to keep all their internal documents secret, they can be compelled by law to disclose them. reply hirundo 19 hours agoprevThey&#x27;re required to spell out their moderation policy and provide details on how it&#x27;s enforced, but the law does not appear to put constraints on the policy. So it would seem to be consistent with the law to have a policy like We moderate depending on our values and feelings as we experience them at the time, and we do not strive for consistency in these judgments and they may change depending on how well our moderators have slept the night before or how the air pressure affects their sinusitus.That would seem to comply with the law while enabling the social network to maintain maximum flexibility. reply jsight 19 hours agoparentI don&#x27;t think that would comply with the reporting requirements. And it sounds like their real concern is that it&#x27;d provide a way to use those reporting requirements, and the discretion as to what consitutes good faith compliance, to pressure the company into taking actions.There also appears to be a real free speech issue here that is at least somewhat related to litigation that has occurred regarding editorial freedom of the press. reply orra 19 hours agoparentprevThat&#x27;s clearly not a real policy. You can&#x27;t trick a court with such obvious deception.In particular, moderators have bosses, and nobody can believe moderators can do what the hell they want without their manager having a say.> while enabling the social network to maintain maximum flexibility.In other words, giving the employees absolute discretion isn&#x27;t normally what you would consider giving the company (owners&#x2F;directors) flexibility. reply adrr 19 hours agorootparentThat’s why they are fighting it. They don’t want to put that Musk is the moderation policy. reply bluescrn 19 hours agorootparent&#x27;It&#x27;s a private company, they can ban&#x2F;block&#x2F;censor whoever&#x2F;whatever they want&#x27;Pre-Musk, wasn&#x27;t that always the standard standard response to criticism of activism-driven social media censorship? reply adrr 18 hours agorootparentCalifornia just requires transparency of the policies. They just need to put in writing that free speech absolutist Musk is responsible for all the moderation of policies like censuring the account that tracked his plane with public data. reply tzs 18 hours agorootparentprevSo? That&#x27;s still the standard response.All this bill is doing is saying that the company has to state what their rules for this are. reply sebzim4500 17 hours agorootparentSounds like the rules are \"We do whatever Musk wants. He&#x27;s an unusual guy\". reply rgbrenner 19 hours agorootparentprevThere&#x27;s definitely at least one moderator at Twitter that uses that policy. reply michaelt 18 hours agorootparentprev> That&#x27;s clearly not a real policy.Of course not - a HN posts are hardly long enough to contain the real policy which would undoubtedly be many pages long. hirundo is posting a hypothetical, exaggerated example.But Twitter could have a policy that gave them great leeway to make arbitrary decisions, by stating things like:* We use automated systems, which ensure a timely response and let us stay on top of many millions of tweets per day. However, these automated systems occasionally err in both taking down reasonable content and leaving up unreasonable content. We are constantly improving these systems, but with x00 million tweets per day some errors are inevitable.* Bright line rules are not always possible in moderation. For example, we would generally not censor images of Michelangelo&#x27;s David, the Venus de Milo, or napalm girl, despite a general policy of not showing genitals or female-presenting nipples.Similarly, a post might be parody, sarcasm, exaggeration for comic effect, or otherwise acceptable. For example, we might allow NWA&#x27;s 1988 hit protest song \"Fuck tha Police\", or a tweet by Donald Trump threatening nuclear war with North Korea, despite a general prohibition on calls to violence.Decisions are made by our moderation teams on a case-by-case basis, following the vague subjective guidelines found in appendix A* We hire our moderation workforce from around the globe valuing diversity and multiple perspectives and timezones blah blah therefore details that may be obvious to some audiences may sometimes be overlooked by our moderation teams* The fact a tweet has been reported by a large number of people does not necessarily mean it will be blocked, as some more visible accounts may attract more flags proportional to their larger audience. Twitter also suffers from organised &#x27;downvote rings&#x27; which systematically flag posts by their political opponents, hoping to reduce the reach of those posts. We may ignore such reports, when we detect them.* Content moderation is interlinked with spam, astroturfing and bot accounts. For example we may block posts about buying cheap viagra, despite it not being extreme content or hate speech.* Our automated systems may identify accounts as suspected bot or spam accounts based on heuristics that may not be obviously related to our moderation policies. Even a newly opened account that has never sent a single tweet or followed a single person may be blocked.* The ever changing spam environment, the ever-changing language used by Twitter users, and the cat-and-mouse game with people who&#x27;d like to not be moderated mean the guidance given to our moderators changes on a daily basis. This document is a snapshot and our actions in the past and in the future may be inconsistent with it.* We are committed to helping users stay safe and control their twitter experience, through options like Unfollow, Filter Notifications, Show Less Often, Mute, Block and Report.Expand with a few more pages of waffle and voilà, you have a policy that doesn&#x27;t actually pin you down to taking any particular action in any particular situation. reply cornholio 19 hours agoparentprevSince the moderation practices that must be disclosed also cover things like hate speech or harassment and other generally illegal speech, then the platform can&#x27;t simply answer in that fashion, because the court will issue a default judgment against the \"social media company that has not made a reasonable, good faith attempt to comply\", as per AB 587.Also, the \"feelings\" of the moderators imply human moderators exist and are the norm. This might not be true and you would be submitting false information for an AI-heavy moderation pipeline. reply sneak 19 hours agorootparentHate speech and most speech that falls under the category presently described by social media users in 2023 as \"harassment\" is decidedly not illegal, and is in fact protected expression.Threats are not protected, but the vaguely defined concept of \"hate speech\" that is not already-illegal direct threats of violence isn&#x27;t really a thing.This seems to be a common misconception. If it were violent threats, which are illegal, people would just call it that. When people say \"hate speech\" they are attempting to promote censorship of otherwise-legal expression that most of society nevertheless finds repugnant. reply Guvante 19 hours agorootparentYou are mixing many different viewpoints here and it is diluting whatever point you were making.Harassment has a legal definition and so a law referring to it is not \"as described by social media users\"...You then decide by fiat that the entire thing is pointless because of how you feel which ignores the very real problems on social media of exactly the kinds of messaging you claim this isn&#x27;t about. reply edgyquant 17 hours agorootparentprev“Hate speech,” is not a real thing or illegal under US law reply JoeAltmaier 17 hours agorootparentWrong, and wrong. Plenty of definitions that make it a &#x27;real thing&#x27;. And plenty of ways it&#x27;s being enforced across the US. reply coding123 17 hours agoprevI have a feeling Elon is working with people in IT to \"block\" CA from accessing the Twitter and X domain names.- Not implement it juuuuust yet, but probably a 2 day test coming for sure. reply isaacfrond 20 hours agoprevIn light of the recent ruling by the Fifth Circuit that the White House overstepped 1st Amendment on social media [0], I suppose Musk has a good case.[0]: https:&#x2F;&#x2F;www.nytimes.com&#x2F;2023&#x2F;09&#x2F;08&#x2F;business&#x2F;appeals-court-fi... reply nimbius 19 hours agoparentthese are two completely separate cases.The US 5th Circuit Court of Appeals ruled that certain administration officials – namely in the White House, the surgeon general, the US Centers for Disease Control and Prevention, and the Federal Bureau of Investigation – likely “coerced or significantly encouraged social media platforms to moderate content.”What California wants is clarification and explanation of the moderation process as it applies to X. a product disclosure like this is common in nearly every other consumer product in the US. Prop 65 for example routinely mandates this sort of disclosure for lead or cadmium content in a product.The reason musk specifically does not want to disclose this information is because the moderators were all sacked a year ago...i think California knows this.https:&#x2F;&#x2F;www.cbsnews.com&#x2F;news&#x2F;elon-musk-twitter-layoffs-outso... reply seafoam 19 hours agorootparentIt is not a question of what California wants. California is attempting to coerce. X is arguing that CA&#x27;s coercion violates both the 1st amendment and Section 230. Glad to engage further if you or others want to address the merits of those arguments. No need to impugn intent onto specific individuals. reply rgbrenner 19 hours agorootparentAll laws are coercive. That&#x27;s how laws work. So I don&#x27;t even know what your first statement is trying to get at.$15k&#x2F;day -- 5M&#x2F;year -- on companies over $100M in gross revenue (much less the several billion generated by Twitter) is not more coercive than many other laws. The penalties for some laws go up to and including death... so this is definitely within the typical range of penalties.The law requires disclosing your policy and how you applied it. Musk is out on a limb if he&#x27;s claiming that giving stats on what actions were taken is the same as the action itself. reply renlo 19 hours agorootparentprev> Prop 65 for example routinely mandates this sort of disclosure for lead or cadmium content in a product.The dangerous (overt?) implication you&#x27;re making is that some speech is \"poisonous\" and the government needs to step in and make sure the people aren&#x27;t being \"poisoned\" reply DSMan195276 19 hours agorootparentNo? All they&#x27;re requiring is clarification on what moderation (if any) is happening. This is almost the opposite of what you&#x27;re describing, that more moderation you do the harder such clarifications become - if you do none then there&#x27;s nothing to disclose.Of course, arguably most people _want_ some minimum level of content moderation, so whether it&#x27;s beneficial to do more or less content moderation is up to the company, they just have to disclose it. reply justapassenger 18 hours agorootparentprevYes, some speech is totally illegal, under 1st amendment.Telling a bank teller “give me all the money, now!” is illegal. Telling a hit man “go kill that person who owes me money” is also illegal. reply jasonjayr 19 hours agorootparentprevShouting \"Fire\" in a crowded theater should be protected by the 1A ?That&#x27;s dangerous, and the law should rightly restrict that reply hellojesus 19 hours agorootparentIt is protected. See Brandenburg vs. Ohio.\"\"\" The Court in Brandenburg, in a per curiam opinion, held that Ohio&#x27;s Syndicalism law violated the First Amendment. According to the Court, \"constitutional guarantees of free speech and free press do not permit a State to forbid or proscribe advocacy of the use of force or of law violation except where such advocacy is directed to inciting or producing imminent lawless action and is likely to incite or produce such action. \"\"\"https:&#x2F;&#x2F;supreme.findlaw.com&#x2F;supreme-court-insights&#x2F;brandenbu... reply madeofpalk 19 hours agorootparentprevThe law does not restrict that. \"Shouting fire in a crowded theatre\" is a myth. Anyone parroting this immediately outs themselves as lacking even the most basic knowledge of first ammendment.The court case where that quote came from was overturned 54 years ago!https:&#x2F;&#x2F;www.techdirt.com&#x2F;tag&#x2F;fire-in-a-crowded-theater&#x2F;https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=jTsPgiUoBKAhttps:&#x2F;&#x2F;www.theatlantic.com&#x2F;national&#x2F;archive&#x2F;2012&#x2F;11&#x2F;its-tim... reply jasonjayr 19 hours agorootparentI was not aware of that court case, but that is enlightening. I have much learning to do.But based on reading through the report at the findlaw article in a sibling comment, (in my opinion) I think it&#x27;s a pretty dangerous precedent, and definitely a pillar of the breakdown of modern political discourse. reply pelorat 19 hours agorootparentprevI think it is, you will get charged for something else, like inciting panic. reply shadowgovt 19 hours agorootparentprev\"The act of shouting fire when there are no reasonable grounds for believing one exists is not in itself a crime, and nor would it be rendered a crime merely by having been carried out inside a theatre, crowded or otherwise.\"https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Shouting_fire_in_a_crowded_the... reply mcpackieh 18 hours agorootparentprevYour other responses have correctly explained why you&#x27;re wrong but I just want to add a little bit more context: \"Shouting fire in a crowded theater\" was a euphemism by Justice Holmes to describe the act of protesting the draft.It did not come from a case about a theater and a human stampede as many naturally assume. It came from a case about a war protestor being arrested for telling people they should resist the draft (decidedly political speech.) reply tzs 18 hours agorootparentprevInstead of Prop 65, look at it as like nutritional labeling rules. There is no implication in having to list e.g. how much protein is an a serving of your product means that protein is dangerous. reply cratermoon 19 hours agorootparentprev> some speech is \"poisonous\"Yes, this kind of speech is called &#x27;perlocutionary&#x27; and is dicussed in international human rights law, https:&#x2F;&#x2F;revistaselectronicas.ujaen.es&#x2F;index.php&#x2F;TAHRJ&#x2F;articl... reply Eisenstein 19 hours agorootparentprevExcept that this is about disclosing how a corporation removes speech, not about the government removing speech from anyone. reply PartiallyTyped 19 hours agorootparentprevInformation hazards exist. There is precedence.> Words can kill, a Massachusetts Juvenile Court judge decided last Friday, when he found 20-year old Michelle Carter guilty of involuntary manslaughter in the 2014 suicide of her then-boyfriend, Conrad Roy III.[1] https:&#x2F;&#x2F;www.yahoo.com&#x2F;now&#x2F;2017-06-22-you-may-be-jailed-for-t... reply jonhohle 19 hours agorootparentprevLast I checked, content moderation can’t cause cancer or birth defects. reply DanHulton 19 hours agorootparentYes, but if you&#x27;re not being pedantic for the sake of scoring points, all the aforementioned things are capable of causing significant harm if mishandled, so it&#x27;s still quite relevant. reply jonhohle 17 hours agorootparentHaving a post arbitrarily or even maliciously being removed from a social media platform being equated to physical harm is an extremely absurd, out of touch, pampered, and privileged position.Mishandling of heavy metals can cause lifelong affects not just to those handling them, but to anyone in the vicinity.[0] it’s estimated that 1M people die per year from lead poisoning[1].Content moderation cannot directly cause any physical harm. If you consider indirect physical harm related to all social media (which I’d have more sympathy toward), it would not come close to the affects of heavy metals and other substances known to the state of California to cause cancer, birth defects, or other reproductive harm.0 - https:&#x2F;&#x2F;amp.theguardian.com&#x2F;world&#x2F;2009&#x2F;aug&#x2F;20&#x2F;china-children...1 - https:&#x2F;&#x2F;www.who.int&#x2F;news&#x2F;item&#x2F;23-10-2022-almost-1-million-pe... reply hellojesus 19 hours agorootparentprevBut the government isn&#x27;t allowed to regulate the speech based on harm unless that harm would result from lawless action which is also incited by the speech and probable to happen based on the speech. reply mrguyorama 17 hours agorootparentPeople should really be more considering this as \"Truth in advertising\" type law. This isn&#x27;t about whether Twitter follows it&#x27;s policies as written, as you would be hard pressed to convict any company for merely not following it&#x27;s own rules for something that isn&#x27;t illegal (allowing inflammatory speech on your platform, or even signal boosting such speech), but more at requiring companies be honest about how they moderate their consumer participation.This law is so consumers can make educated choices about the platforms they want to use. reply shadowgovt 19 hours agorootparentprevWhat is the significant harm caused by mishandled content moderation?... for that matter, what does it mean for content moderation to be \"mishandled?\" reply cratermoon 19 hours agorootparent> What is the significant harmStochastic terrorism. reply jonhohle 17 hours agorootparentIs not the same as actual terrorism. reply DanHulton 7 hours agorootparentIrrelevant, though, as it still causes harm, which is the original differentiator. reply shadowgovt 17 hours agorootparentprevThat&#x27;s a very good point and I have no arguments with it.Unfortunately, nothing about the California law really addresses it. The Fifth Circuit Court decision regarding coercion of social media sites will bind to the states via the Fourteenth Amendment, so California can&#x27;t really enforce anything if they disagree with a company&#x27;s moderation policy.That means the law reduces to perfunctory data collection, and it doesn&#x27;t really tell consumers anything that logging into the site and going \"Gee, this site sure is full of white supremacists advocating stochastic terrorism and nobody does anything about it\" wouldn&#x27;t tell them. replyPartiallyTyped 20 hours agoparentprevHow is the state of California related to the WH?I don&#x27;t understand why anyone would downvote this. Can&#x27;t people ask questions these days? Especially questions that prompt significant discussions and clear the climate and misconceptions some of us have? reply edgyquant 20 hours agorootparentThey are both under the jurisdiction of the US federal court system. Something applying to the white house means it applies to individual states as well. reply ericmay 20 hours agorootparentI&#x27;m not sure that is necessarily true, but the essence of your point I think stands which is that it&#x27;s likely that based on past outcomes that California could face a similar result as the case you are referring to. reply parineum 19 hours agorootparent> I&#x27;m not sure that is necessarily trueIf the case was decided on 1st amendment grounds, it&#x27;s absolutely true. reply thfuran 20 hours agorootparentprevFifth circuit Court doesn&#x27;t have jurisdiction over California. reply heywhatupboys 19 hours agorootparentNo, but circuit courts have long established precedence, especially in matters reply jcranmer 19 hours agorootparentLiterally not in this case. Circuit courts establish binding precedence in their circuit, but not elsewhere. Out-of-circuit opinions can be used for persuasive evidence, but there is absolutely nothing that requires the 9th Circuit (which includes California) to listen to what the 5th Circuit says. Especially when the 5th Circuit is disagreeing with every other circuit to have considered the matter. [I haven&#x27;t read the opinion in this case to know what it&#x27;s asserting, but I do know that every opinion I did read on whether or not the government urged COVID-19 moderation qualified as unconstitutional state action concluded that the plaintiffs hadn&#x27;t met their showing that it did.] reply ofjcihen 20 hours agorootparentprevNot a lawyer but if that’s the case, could California say “Fine, but Twitter can no longer do business in California”?Edit: not necessarily saying they should, I’m just wondering if they can.Edit 2: Looks like the most they could do is make it harder for social media companies in general to do business. If they were perceived as targeting Twitter then they could have grounds to sue.Based on 20 minutes of reading so grain of salt applies. reply infamouscow 20 hours agorootparentprevThe bill of rights is a list of restrictions on the government i.e., laws the governments must follow. reply dabraham1248 19 hours agorootparentUmm, the bill of rights is a set of restrictions on the _federal_ government. The last one is explicitly a statement that the states can do a lot of things that the federal government _can&#x27;t_.There is the supremacy clause, but goodness knows where that would end up here. _Everything_ involving real money or power seems to make it to the supreme court these days, and who knows what the political landscape will look like by the time it does (yes, I am asserting that the supreme court has become more political than it used to be, _and_ that it used to be pretty political...). reply pdonis 19 hours agorootparent> the bill of rights is a set of restrictions on the _federal_ governmentThe First Amendment as it is literally worded is, since it specifically says \"Congress shall make no law...\". But the rest of the amendments have no such restriction; they just say certain things shall not be done, period. Given the Supremacy Clause, that means those provisions should apply to all levels of government, not just federal. (Granted, the courts originally did not interpret them that way, but IMO they should have.)That said, current jurisprudence, regardless of the literal wording of the bill of rights, is that they apply to the States, even the First Amendment. IIRC most Supreme Court decisions along these lines have cited the Fourteenth Amendment. reply sseagull 19 hours agorootparentprev> Umm, the bill of rights is a set of restrictions on the _federal_ government. The last one is explicitly a statement that the states can do a lot of things that the federal government _can&#x27;t_.Taken literally, yes. But legally, many (but not all) for the rights have been &#x27;incorporated&#x27; to apply to the states. This includes First Amendment.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Incorporation_of_the_Bill_of_R... reply afthonos 19 hours agorootparentprevThe bill of rights was extended to the states via the privileges and immunities clause if the 14th amendment. reply Turing_Machine 18 hours agorootparentprev> Umm, the bill of rights is a set of restrictions on the _federal_ government.That hasn&#x27;t been the case since the ratification of the 14th Amendment way back in 1868.All persons born or naturalized in the United States, and subject to the jurisdiction thereof, are citizens of the United States and of the State wherein they reside. No State shall make or enforce any law which shall abridge the privileges or immunities of citizens of the United States; nor shall any State deprive any person of life, liberty, or property, without due process of law; nor deny to any person within its jurisdiction the equal protection of the laws.Courts have repeatedly held that the Bill of Rights does apply to the states, by means of this so-called \"due process clause\" in the 14th Amendment.Edit: changed \"incorporation clause\" to \"due process clause\", as that seems to be the name under which it is more generally known. reply Zigurd 19 hours agorootparentprevCommercial speech is regulated. That might not make a lot of sense in a time when \"money is speech.\" But that&#x27;s not a problem the people created. reply perihelions 19 hours agorootparentIf Twitter solicits you to purchase Twitter Blue, that&#x27;s Commercial Speech. If Twitter bans your account for praising Hitler, that&#x27;s [Twitter exercising] political speech: Twitter would be protected by the First Amendment. The mere fact Twitter is a commercial, monetized service doesn&#x27;t trigger a Twitter-wide First Amendment exception—any more than, say, the New York Times being a for-profit corporation opens the door for the feds to censor its political columns. Even if they&#x27;re behind a paywall.Commercial Speech is a narrow carve-out for \"advertisements and solicitations\". It&#x27;s not applicable to Twitter moderation. reply PeterisP 15 hours agorootparentSure, but Twitter banning (or not banning) your account for praising Hitler is political speech, however, Twitter stating \"we are&#x2F;aren&#x27;t a platform for free speech\" or \"our moderation will&#x2F;won&#x27;t ban your account for praising Hitler\" is commercial speech similar to it soliciting you to purchase Twitter blue, it&#x27;s a statement about the media service they&#x27;re offering as part of their business, and that&#x27;s something that can be reasonably compelled.The law does not make any requests about how Twitter should moderate things, it asks for information about how Twitter does moderate things. First amendment protection should ensure that government is prohibited to impose restrictions if a company says they will&#x2F;won&#x27;t ban accounts for praising Hitler, however, the people certainly have the right to take action in response to that, and the government has the right to compel Twitter to disclose to these people truthful information about their media product.If they have a policy document stating \"posts which contain more than three letters &#x27;z&#x27; shall be deleted\", they have a right to moderate this way if they wish - however, do they have a constitutional right to keep that policy document secret from the public? The way I see it, laws are permitted to regulate the disclosure of company policies. reply Zigurd 18 hours agorootparentprevThere is a good argument that company policies about product use is commercial speech. \"Here take this opioid, we have funded studies that say it won&#x27;t hurt you\" got regulated pretty hard. \"We think the &#x27;woke mind virus&#x27; is worse than capital-F Fascism and will moderate that way\" is very much about Twitter&#x27;s product. reply perihelions 17 hours agorootparentAnything about \"woke\" and \"fascism\" is constitutionally protected political speech. This is an easy call. reply delfinom 20",
    "originSummary": [
      "Elon Musk's X Corp. has sued to hinder California's content moderation law, AB 587, which mandates social media platforms to submit a service report detailing their content moderation practices to the state attorney.",
      "X Corp. claims the law infringes on the First Amendment and imposes extensive financial penalties for non-compliance.",
      "Concerns about the law's potential to negatively impact online users and restrict free speech have been raised by tech groups and policy experts."
    ],
    "commentSummary": [
      "There is an ongoing debate regarding the rights of companies, specifically social media platforms like Twitter, related to free speech and content moderation.",
      "Key points discussed include whether companies should have similar rights as individuals under the US Constitution, the effects of government regulation on free speech, and the clarity of content moderation practices.",
      "The debate also includes potential ramifications of censorship and legal challenges of applying state laws to social media platforms."
    ],
    "points": 176,
    "commentCount": 347,
    "retryCount": 0,
    "time": 1694441704
  },
  {
    "id": 37466302,
    "title": "Intuitively Understanding Harris Corner Detector",
    "originLink": "https://comsci.blog/posts/intuitive-harris",
    "originBody": "ML and robotics notes About Intuitively Understanding Harris Corner Detector Sep 11, 2023 If you ever tried to learn how the Harris corner detection algorithm works, you might have noticed that the process is not intuitive at all. First, you start with an energy function, approximate it using Taylor approximation, get a matrix from that, then find the eigenvalues of that matrix, etc. But when you come to the final implementation, it is rather simple and seems easier. If you are like me, this is not intuitive at all. But today I will present you a much easier way to understand how the Harris corner detection algorithm works. Let’s start with understanding what is a corner. We can simply think of it as a connection of edges. For two edges to be able to connect, they sure need to be not parallel, so looking at a corner, we should see that edges moving in different directions (they would be parallel if they moved in the same directions): Figure source: https://www.cse.psu.edu/~rtc12/CSE486/lecture06.pdf So it is obvious that the gradients of the image Ix and Iy will both be active in the corner region. We know that adding Ix2 and Iy2 shows the regions with change in x or y directions (which is the basis of the all edge detection algorithms). So one thing that comes to mind is multiplying the Ix2 and Iy2 so that we will only see regions on the image that have a change in both x and y directions at the same time, just like corners! Let’s start implementing this. First, let’s find a pretty basic image that will have lots of corners inside it. import cv2 import matplotlib.pyplot as plt # wget https://logowik.com/content/uploads/images/bbc-america9038.jpg -O assets/bbc.jpg img = cv2.imread(\"assets/bbc.jpg\", cv2.IMREAD_GRAYSCALE) plt.imshow(img, cmap=\"gray\") Now we can start finding the gradient of this image using the Sobel operator: Ix = cv2.Sobel(img, ddepth=cv2.CV_32F, dx=1, dy=0) Iy = cv2.Sobel(img, ddepth=cv2.CV_32F, dx=0, dy=1) Okay, we are there now. Let’s plot the Ix2Iy2, we are expecting it to give us regions with both x and y directions: plt.imshow(Ix**2 * Iy**2, cmap='gray') As you can see, we are kind of not successful, because this shows us the both corners and edges that move along in both x and y directions. But we need to get rid of the edges. If you carefully look at this resulting image, you will notice that corners are either isolated like the top left corner of the B logo, or they are at the end of these edges. Maybe we can’t get rid of the edges directly, but if somehow we can remove the corners from Ix2Iy2, we can subtract it from the original Ix2Iy2 and get only the corners. Actually, we can get rid of the corners. Since the corners are isolated in this image, applying a Gaussian blur will decrease the intensities of the corners a lot! Let’s see this: corners_suppressed = cv2.GaussianBlur(Ix**2 * Iy**2, ksize=(0, 0), sigmaX=1) plt.imshow(corners_suppressed, cmap='gray') We can even do a better job of removing the corners by applying the blur before squaring. Because square will increase the intensity of isolated corners, making it less affected by the blur. So we can instead do: corners_suppressed = cv2.GaussianBlur(Ix* Iy, ksize=(0, 0), sigmaX=1) ** 2 plt.imshow(corners_suppressed, cmap='gray') Now that we have the corners mostly suppressed image, we can try subtracting this from the Ix2Iy2 and get only the corners. Let’s try it: plt.imshow(Ix**2 * Iy**2 - corners_suppressed, cmap='gray') That doesn’t seem to work, but the reason is clear. Edges of the Ix2Iy2 have different intensity than corners_suppressed, since corners_suppressed has been blurred. We want them to have the same intensity in edges so that they cancel the edges when they are subtracted. We can make the edges of Ix2Iy2 similar intensity to edges of corners_suppressed by applying Gaussian blur to Ix2 and Iy2 seperately before multiplying them. We will apply the blur to squared gradients to make sure the corners are less affected by the blur. Ix_squared = cv2.GaussianBlur(Ix**2, ksize=(0, 0), sigmaX=1) Iy_squared = cv2.GaussianBlur(Iy**2, ksize=(0, 0), sigmaX=1) corners = Ix_squared * Iy_squared - corners_suppressed plt.imshow(corners, cmap='gray') Yes! We successfully get the corners of the image. Now if we look at the data inside the corners matrix, you will notice that corners have extremely large values and other parts have smaller values. Let’s threshold it: corners[corners < corners.max() / 5] = 0 corners[corners != 0] = 255 plt.imshow(corners, cmap=\"gray\") Okay, let’s plot these points as circles in our image: new_img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB) for i in range(img.shape[0]): for j in range(img.shape[1]): if corners[i][j] == 255: cv2.circle(new_img, (j, i), radius=2, color=(255, 0, 0), thickness=-1) plt.imshow(new_img, cmap=\"gray\") plt.show() And with this, we have implemented the Harris corner detection algorithm and we haven’t talked about things like fitting ellipses, Taylor series approximation, or any of that stuff. This implementation is equivalent to the other implementations of this algorithm. Here is the full code: import cv2 import matplotlib.pyplot as plt # wget https://logowik.com/content/uploads/images/bbc-america9038.jpg -O assets/bbc.jpg img = cv2.imread(\"assets/bbc.jpg\", cv2.IMREAD_GRAYSCALE) Ix = cv2.Sobel(img, ddepth=cv2.CV_32F, dx=1, dy=0) Iy = cv2.Sobel(img, ddepth=cv2.CV_32F, dx=0, dy=1) corners_suppressed = cv2.GaussianBlur(Ix* Iy, ksize=(0, 0), sigmaX=1) ** 2 Ix_squared = cv2.GaussianBlur(Ix**2, ksize=(0, 0), sigmaX=1) Iy_squared = cv2.GaussianBlur(Iy**2, ksize=(0, 0), sigmaX=1) corners = Ix_squared * Iy_squared - corners_suppressed corners[corners < corners.max() / 5] = 0 corners[corners != 0] = 255 new_img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB) for i in range(img.shape[0]): for j in range(img.shape[1]): if corners[i][j] == 255: cv2.circle(new_img, (j, i), radius=2, color=(255, 0, 0), thickness=-1) plt.imshow(new_img, cmap=\"gray\") plt.show() Hopefully, you now understand how this algorithm works and enjoy the process. Subscribe Anil Zeybek anil.zeybek98@gmail.com Tutorials and implementations of machine learning and robotics algorithms.",
    "commentLink": "https://news.ycombinator.com/item?id=37466302",
    "commentBody": "Intuitively Understanding Harris Corner DetectorHacker NewspastloginIntuitively Understanding Harris Corner Detector (comsci.blog) 176 points by anilz 21 hours ago| hidepastfavorite8 comments arketyp 20 hours agoI remember the eigenvector analysis of the original paper [1] wasn&#x27;t terribly inaccessible. I think an alternative title for this blog post could be \"Intuitively Understanding the Harris Corner Detector Optimizations\".[1] https:&#x2F;&#x2F;citeseerx.ist.psu.edu&#x2F;document?repid=rep1&type=pdf&d... reply glitchc 20 hours agoprevI had to write one for an interview many moons ago. It&#x27;s a fun little exercise. reply ur-whale 14 hours agoprev [–] PSA : The Harris Corner detector, while interesting to understand if you like linear algebra, is not exactly what you&#x27;d call state of the art in the feature detection layer of computer vision. reply DougMerritt 14 hours agoparent [–] Yes? What is the state of the art? reply michaelt 11 hours agorootparentThe most widely used algorithms for classical feature detection today are \"whatever opencv implements\"In terms of tech that&#x27;s advancing at the moment? ML techniques. https:&#x2F;&#x2F;co-tracker.github.io&#x2F; if you want to track individual points, https:&#x2F;&#x2F;github.com&#x2F;matterport&#x2F;Mask_RCNN and its descendents if you want to detect, say, the cover of a book. reply anilz 12 hours agorootparentprevActually, it is a part of the ORB algorithm and ORB is especially used a lot in visual SLAM applications. reply jhoydich 13 hours agorootparentprev [–] I believe the SIFT algorithm is most commonly used. Harris struggles when features change in scale between images, whereas SIFT does not. Harris can be outfitted with a Laplacian pyramid to overcome the scale issue though. reply mathisfun123 13 hours agorootparent [–] which is funny since SIFT is basically just as ancient. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The article provides a straightforward understanding of the Harris corner detection algorithm's operation.",
      "It distinctly presents how gradient calculations, Gaussian blur, and thresholding techniques are implemented in the algorithm.",
      "The developed code can identify corners in an image without the use of complex mathematical computations or approximation techniques."
    ],
    "commentSummary": [
      "The discussion centers on the Harris Corner Detector, a fundamental algorithm in computer vision for recognizing distinct features.",
      "While not the most advanced, the Harris Corner Detector is still utilized in specific applications, for instance, visual Simultaneous Localization And Mapping (SLAM).",
      "Other algorithms including Scale-Invariant Feature Transform (SIFT) and Machine Learning (ML) techniques that are progressing in the feature detection domain were also discussed."
    ],
    "points": 176,
    "commentCount": 8,
    "retryCount": 0,
    "time": 1694435754
  },
  {
    "id": 37474066,
    "title": "YouTube-dl fork with additional features and fixes",
    "originLink": "https://github.com/yt-dlp/yt-dlp",
    "originBody": "Skip to content Product Solutions Open Source Pricing Search or jump to... Sign in Sign up yt-dlp / yt-dlp Public Sponsor Notifications Fork 4.6k Star 55.8k Code Issues 1.1k Pull requests 198 Discussions Actions Projects 5 Wiki Security 1 Insights yt-dlp/yt-dlp master 3 branches 76 tags Go to file Code Latest commit bashonly [ie/zoom] Extract duration … 66cc64f Git stats 21,945 commits Files Type Name Latest commit message Commit time .github Release 2023.07.06 devscripts [cleanup] Misc fixes test [tests] Add tests for socks proxies (#7908) yt_dlp [ie/zoom] Extract duration .editorconfig [docs] Add an .editorconfig file (#3220) .gitattributes [docs] Minor improvements (#3309, #3343) .gitignore [cleanup] Misc CONTRIBUTING.md [docs] Misc improvements CONTRIBUTORS [docs] Update collaborators Changelog.md [cleanup] Misc fixes Collaborators.md [docs] Update collaborators LICENSE addedd a serious Public Domain dedication, see http://unlicense.org/ MANIFEST.in [build] Add requirements.txt to pip distributions Makefile [networking] Add module (#2861) README.md [ie/twitter] Fix retweet extraction and syndication API (#8016) public.key [build] Sign SHA files and release public key pyinst.py [pyinst] Fix for pyinstaller 5.8 pyproject.toml [cleanup] Misc requirements.txt [cleanup] Misc cleanup setup.cfg [cleanup] Misc setup.py [build] Make sure deprecated modules are added supportedsites.md Release 2023.07.06 yt-dlp.cmd [test] Convert warnings into errors yt-dlp.sh [cleanup] Misc fixes and cleanup README.md yt-dlp is a youtube-dl fork based on the now inactive youtube-dlc. The main focus of this project is adding new features and patches while also keeping up to date with the original project NEW FEATURES Differences in default behavior INSTALLATION Detailed instructions Update Release Files Dependencies Compile USAGE AND OPTIONS General Options Network Options Geo-restriction Video Selection Download Options Filesystem Options Thumbnail Options Internet Shortcut Options Verbosity and Simulation Options Workarounds Video Format Options Subtitle Options Authentication Options Post-processing Options SponsorBlock Options Extractor Options CONFIGURATION Configuration file encoding Authentication with netrc Notes about environment variables OUTPUT TEMPLATE Output template examples FORMAT SELECTION Filtering Formats Sorting Formats Format Selection examples MODIFYING METADATA Modifying metadata examples EXTRACTOR ARGUMENTS PLUGINS Installing Plugins Developing Plugins EMBEDDING YT-DLP Embedding examples DEPRECATED OPTIONS CONTRIBUTING Opening an Issue Developer Instructions WIKI FAQ NEW FEATURES Forked from yt-dlc@f9401f2 and merged with youtube-dl@42f2d4 (exceptions) SponsorBlock Integration: You can mark/remove sponsor sections in YouTube videos by utilizing the SponsorBlock API Format Sorting: The default format sorting options have been changed so that higher resolution and better codecs will be now preferred instead of simply using larger bitrate. Furthermore, you can now specify the sort order using -S. This allows for much easier format selection than what is possible by simply using --format (examples) Merged with animelover1984/youtube-dl: You get most of the features and improvements from animelover1984/youtube-dl including --write-comments, BiliBiliSearch, BilibiliChannel, Embedding thumbnail in mp4/ogg/opus, playlist infojson etc. Note that NicoNico livestreams are not available. See #31 for details. YouTube improvements: Supports Clips, Stories (ytstories:), Search (including filters)*, YouTube Music Search, Channel-specific search, Search prefixes (ytsearch:, ytsearchdate:)*, Mixes, and Feeds (:ytfav, :ytwatchlater, :ytsubs, :ythistory, :ytrec, :ytnotif) Fix for n-sig based throttling * Supports some (but not all) age-gated content without cookies Download livestreams from the start using --live-from-start (experimental) 255kbps audio is extracted (if available) from YouTube Music when premium cookies are given Channel URLs download all uploads of the channel, including shorts and live Cookies from browser: Cookies can be automatically extracted from all major web browsers using --cookies-from-browser BROWSER[+KEYRING][:PROFILE][::CONTAINER] Download time range: Videos can be downloaded partially based on either timestamps or chapters using --download-sections Split video by chapters: Videos can be split into multiple files based on chapters using --split-chapters Multi-threaded fragment downloads: Download multiple fragments of m3u8/mpd videos in parallel. Use --concurrent-fragments (-N) option to set the number of threads used Aria2c with HLS/DASH: You can use aria2c as the external downloader for DASH(mpd) and HLS(m3u8) formats New and fixed extractors: Many new extractors have been added and a lot of existing ones have been fixed. See the changelog or the list of supported sites New MSOs: Philo, Spectrum, SlingTV, Cablevision, RCN etc. Subtitle extraction from manifests: Subtitles can be extracted from streaming media manifests. See commit/be6202f for details Multiple paths and output templates: You can give different output templates and download paths for different types of files. You can also set a temporary path where intermediary files are downloaded to using --paths (-P) Portable Configuration: Configuration files are automatically loaded from the home and root directories. See CONFIGURATION for details Output template improvements: Output templates can now have date-time formatting, numeric offsets, object traversal etc. See output template for details. Even more advanced operations can also be done with the help of --parse-metadata and --replace-in-metadata Other new options: Many new options have been added such as --alias, --print, --concat-playlist, --wait-for-video, --retry-sleep, --sleep-requests, --convert-thumbnails, --force-download-archive, --force-overwrites, --break-match-filter etc Improvements: Regex and other operators in --format/--match-filter, multiple --postprocessor-args and --downloader-args, faster archive checking, more format selection options, merge multi-video/audio, multiple --config-locations, --exec at different stages, etc Plugins: Extractors and PostProcessors can be loaded from an external file. See plugins for details Self updater: The releases can be updated using yt-dlp -U, and downgraded using --update-to if required Nightly builds: Automated nightly builds can be used with --update-to nightly See changelog or commits for the full list of changes Features marked with a * have been back-ported to youtube-dl Differences in default behavior Some of yt-dlp's default options are different from that of youtube-dl and youtube-dlc: yt-dlp supports only Python 3.7+, and may remove support for more versions as they become EOL; while youtube-dl still supports Python 2.6+ and 3.2+ The options --auto-number (-A), --title (-t) and --literal (-l), no longer work. See removed options for details avconv is not supported as an alternative to ffmpeg yt-dlp stores config files in slightly different locations to youtube-dl. See CONFIGURATION for a list of correct locations The default output template is %(title)s [%(id)s].%(ext)s. There is no real reason for this change. This was changed before yt-dlp was ever made public and now there are no plans to change it back to %(title)s-%(id)s.%(ext)s. Instead, you may use --compat-options filename The default format sorting is different from youtube-dl and prefers higher resolution and better codecs rather than higher bitrates. You can use the --format-sort option to change this to any order you prefer, or use --compat-options format-sort to use youtube-dl's sorting order The default format selector is bv*+ba/b. This means that if a combined video + audio format that is better than the best video-only format is found, the former will be preferred. Use -f bv+ba/b or --compat-options format-spec to revert this Unlike youtube-dlc, yt-dlp does not allow merging multiple audio/video streams into one file by default (since this conflicts with the use of -f bv*+ba). If needed, this feature must be enabled using --audio-multistreams and --video-multistreams. You can also use --compat-options multistreams to enable both --no-abort-on-error is enabled by default. Use --abort-on-error or --compat-options abort-on-error to abort on errors instead When writing metadata files such as thumbnails, description or infojson, the same information (if available) is also written for playlists. Use --no-write-playlist-metafiles or --compat-options no-playlist-metafiles to not write these files --add-metadata attaches the infojson to mkv files in addition to writing the metadata when used with --write-info-json. Use --no-embed-info-json or --compat-options no-attach-info-json to revert this Some metadata are embedded into different fields when using --add-metadata as compared to youtube-dl. Most notably, comment field contains the webpage_url and synopsis contains the description. You can use --parse-metadata to modify this to your liking or use --compat-options embed-metadata to revert this playlist_index behaves differently when used with options like --playlist-reverse and --playlist-items. See #302 for details. You can use --compat-options playlist-index if you want to keep the earlier behavior The output of -F is listed in a new format. Use --compat-options list-formats to revert this Live chats (if available) are considered as subtitles. Use --sub-langs all,-live_chat to download all subtitles except live chat. You can also use --compat-options no-live-chat to prevent any live chat/danmaku from downloading YouTube channel URLs download all uploads of the channel. To download only the videos in a specific tab, pass the tab's URL. If the channel does not show the requested tab, an error will be raised. Also, /live URLs raise an error if there are no live videos instead of silently downloading the entire channel. You may use --compat-options no-youtube-channel-redirect to revert all these redirections Unavailable videos are also listed for YouTube playlists. Use --compat-options no-youtube-unavailable-videos to remove this The upload dates extracted from YouTube are in UTC when available. Use --compat-options no-youtube-prefer-utc-upload-date to prefer the non-UTC upload date. If ffmpeg is used as the downloader, the downloading and merging of formats happen in a single step when possible. Use --compat-options no-direct-merge to revert this Thumbnail embedding in mp4 is done with mutagen if possible. Use --compat-options embed-thumbnail-atomicparsley to force the use of AtomicParsley instead Some internal metadata such as filenames are removed by default from the infojson. Use --no-clean-infojson or --compat-options no-clean-infojson to revert this When --embed-subs and --write-subs are used together, the subtitles are written to disk and also embedded in the media file. You can use just --embed-subs to embed the subs and automatically delete the separate file. See #630 (comment) for more info. --compat-options no-keep-subs can be used to revert this certifi will be used for SSL root certificates, if installed. If you want to use system certificates (e.g. self-signed), use --compat-options no-certifi yt-dlp's sanitization of invalid characters in filenames is different/smarter than in youtube-dl. You can use --compat-options filename-sanitization to revert to youtube-dl's behavior yt-dlp tries to parse the external downloader outputs into the standard progress output if possible (Currently implemented: aria2c). You can use --compat-options no-external-downloader-progress to get the downloader output as-is yt-dlp versions between 2021.09.01 and 2023.01.02 applies --match-filter to nested playlists. This was an unintentional side-effect of 8f18ac and is fixed in d7b460. Use --compat-options playlist-match-filter to revert this For ease of use, a few more compat options are available: --compat-options all: Use all compat options (Do NOT use) --compat-options youtube-dl: Same as --compat-options all,-multistreams,-playlist-match-filter --compat-options youtube-dlc: Same as --compat-options all,-no-live-chat,-no-youtube-channel-redirect,-playlist-match-filter --compat-options 2021: Same as --compat-options 2022,no-certifi,filename-sanitization,no-youtube-prefer-utc-upload-date --compat-options 2022: Same as --compat-options playlist-match-filter,no-external-downloader-progress. Use this to enable all future compat options INSTALLATION You can install yt-dlp using the binaries, pip or one using a third-party package manager. See the wiki for detailed instructions UPDATE You can use yt-dlp -U to update if you are using the release binaries If you installed with pip, simply re-run the same command that was used to install the program For other third-party package managers, see the wiki or refer their documentation There are currently two release channels for binaries, stable and nightly. stable is the default channel, and many of its changes have been tested by users of the nightly channel. The nightly channel has releases built after each push to the master branch, and will have the most recent fixes and additions, but also have more risk of regressions. They are available in their own repo. When using --update/-U, a release binary will only update to its current channel. --update-to CHANNEL can be used to switch to a different channel when a newer version is available. --update-to [CHANNEL@]TAG can also be used to upgrade or downgrade to specific tags from a channel. You may also use --update-to(/) to update to a channel on a completely different repository. Be careful with what repository you are updating to though, there is no verification done for binaries from different repositories. Example usage: yt-dlp --update-to nightly change to nightly channel and update to its latest release yt-dlp --update-to stable@2023.02.17 upgrade/downgrade to release to stable channel tag 2023.02.17 yt-dlp --update-to 2023.01.06 upgrade/downgrade to tag 2023.01.06 if it exists on the current channel yt-dlp --update-to example/yt-dlp@2023.03.01 upgrade/downgrade to the release from the example/yt-dlp repository, tag 2023.03.01 RELEASE FILES Recommended File Description yt-dlp Platform-independent zipimport binary. Needs Python (recommended for Linux/BSD) yt-dlp.exe Windows (Win7 SP1+) standalone x64 binary (recommended for Windows) yt-dlp_macos Universal MacOS (10.15+) standalone executable (recommended for MacOS) Alternatives File Description yt-dlp_x86.exe Windows (Vista SP2+) standalone x86 (32-bit) binary yt-dlp_min.exe Windows (Win7 SP1+) standalone x64 binary built with py2exe (Not recommended) yt-dlp_linux Linux standalone x64 binary yt-dlp_linux.zip Unpackaged Linux executable (no auto-update) yt-dlp_linux_armv7l Linux standalone armv7l (32-bit) binary yt-dlp_linux_aarch64 Linux standalone aarch64 (64-bit) binary yt-dlp_win.zip Unpackaged Windows executable (no auto-update) yt-dlp_macos.zip Unpackaged MacOS (10.15+) executable (no auto-update) yt-dlp_macos_legacy MacOS (10.9+) standalone x64 executable Misc File Description yt-dlp.tar.gz Source tarball SHA2-512SUMS GNU-style SHA512 sums SHA2-512SUMS.sig GPG signature file for SHA512 sums SHA2-256SUMS GNU-style SHA256 sums SHA2-256SUMS.sig GPG signature file for SHA256 sums The public key that can be used to verify the GPG signatures is available here Example usage: curl -L https://github.com/yt-dlp/yt-dlp/raw/master/public.keygpg --import gpg --verify SHA2-256SUMS.sig SHA2-256SUMS gpg --verify SHA2-512SUMS.sig SHA2-512SUMS Note: The manpages, shell completion (autocomplete) files etc. are available inside the source tarball DEPENDENCIES Python versions 3.7+ (CPython and PyPy) are supported. Other versions and implementations may or may not work correctly. While all the other dependencies are optional, ffmpeg and ffprobe are highly recommended Strongly recommended ffmpeg and ffprobe - Required for merging separate video and audio files as well as for various post-processing tasks. License depends on the build There are bugs in ffmpeg that causes various issues when used alongside yt-dlp. Since ffmpeg is such an important dependency, we provide custom builds with patches for some of these issues at yt-dlp/FFmpeg-Builds. See the readme for details on the specific issues solved by these builds Important: What you need is ffmpeg binary, NOT the python package of the same name Networking certifi* - Provides Mozilla's root certificate bundle. Licensed under MPLv2 brotli* or brotlicffi - Brotli content encoding support. Both licensed under MIT 1 2 websockets* - For downloading over websocket. Licensed under BSD-3-Clause Metadata mutagen* - For --embed-thumbnail in certain formats. Licensed under GPLv2+ AtomicParsley - For --embed-thumbnail in mp4/m4a files when mutagen/ffmpeg cannot. Licensed under GPLv2+ xattr, pyxattr or setfattr - For writing xattr metadata (--xattr) on Linux. Licensed under MIT, LGPL2.1 and GPLv2+ respectively Misc pycryptodomex* - For decrypting AES-128 HLS streams and various other data. Licensed under BSD-2-Clause phantomjs - Used in extractors where javascript needs to be run. Licensed under BSD-3-Clause secretstorage - For --cookies-from-browser to access the Gnome keyring while decrypting cookies of Chromium-based browsers on Linux. Licensed under BSD-3-Clause Any external downloader that you want to use with --downloader Deprecated avconv and avprobe - Now deprecated alternative to ffmpeg. License depends on the build sponskrub - For using the now deprecated sponskrub options. Licensed under GPLv3+ rtmpdump - For downloading rtmp streams. ffmpeg can be used instead with --downloader ffmpeg. Licensed under GPLv2+ mplayer or mpv - For downloading rstp/mms streams. ffmpeg can be used instead with --downloader ffmpeg. Licensed under GPLv2+ To use or redistribute the dependencies, you must agree to their respective licensing terms. The standalone release binaries are built with the Python interpreter and the packages marked with * included. If you do not have the necessary dependencies for a task you are attempting, yt-dlp will warn you. All the currently available dependencies are visible at the top of the --verbose output COMPILE Standalone PyInstaller Builds To build the standalone executable, you must have Python and pyinstaller (plus any of yt-dlp's optional dependencies if needed). Once you have all the necessary dependencies installed, simply run pyinst.py. The executable will be built for the same architecture (x86/ARM, 32/64 bit) as the Python used. python3 -m pip install -U pyinstaller -r requirements.txt python3 devscripts/make_lazy_extractors.py python3 pyinst.py On some systems, you may need to use py or python instead of python3. pyinst.py accepts any arguments that can be passed to pyinstaller, such as --onefile/-F or --onedir/-D, which is further documented here. Note: Pyinstaller versions below 4.4 do not support Python installed from the Windows store without using a virtual environment. Important: Running pyinstaller directly without using pyinst.py is not officially supported. This may or may not work correctly. Platform-independent Binary (UNIX) You will need the build tools python (3.7+), zip, make (GNU), pandoc* and pytest*. After installing these, simply run make. You can also run make yt-dlp instead to compile only the binary without updating any of the additional files. (The build tools marked with * are not needed for this) Standalone Py2Exe Builds (Windows) While we provide the option to build with py2exe, it is recommended to build using PyInstaller instead since the py2exe builds cannot contain pycryptodomex/certifi and needs VC++14 on the target computer to run. If you wish to build it anyway, install Python and py2exe, and then simply run setup.py py2exe py -m pip install -U py2exe -r requirements.txt py devscripts/make_lazy_extractors.py py setup.py py2exe Related scripts devscripts/update-version.py - Update the version number based on current date. devscripts/set-variant.py - Set the build variant of the executable. devscripts/make_changelog.py - Create a markdown changelog using short commit messages and update CONTRIBUTORS file. devscripts/make_lazy_extractors.py - Create lazy extractors. Running this before building the binaries (any variant) will improve their startup performance. Set the environment variable YTDLP_NO_LAZY_EXTRACTORS=1 if you wish to forcefully disable lazy extractor loading. Note: See their --help for more info. Forking the project If you fork the project on GitHub, you can run your fork's build workflow to automatically build the selected version(s) as artifacts. Alternatively, you can run the release workflow or enable the nightly workflow to create full (pre-)releases. USAGE AND OPTIONS yt-dlp [OPTIONS] [--] URL [URL...] Ctrl+F is your friend :D General Options: -h, --help Print this help text and exit --version Print program version and exit -U, --update Update this program to the latest version --no-update Do not check for updates (default) --update-to [CHANNEL]@[TAG] Upgrade/downgrade to a specific version.CHANNEL can be a repository as well. CHANNELand TAG default to \"stable\" and \"latest\"respectively if omitted; See \"UPDATE\" fordetails. Supported channels: stable, nightly -i, --ignore-errors Ignore download and postprocessing errors.The download will be considered successfuleven if the postprocessing fails --no-abort-on-error Continue with next video on download errors;e.g. to skip unavailable videos in aplaylist (default) --abort-on-error Abort downloading of further videos if anerror occurs (Alias: --no-ignore-errors) --dump-user-agent Display the current user-agent and exit --list-extractors List all supported extractors and exit --extractor-descriptions Output descriptions of all supportedextractors and exit --use-extractors NAMES Extractor names to use separated by commas.You can also use regexes, \"all\", \"default\"and \"end\" (end URL matching); e.g. --ies\"holodex.*,end,youtube\". Prefix the namewith a \"-\" to exclude it, e.g. --iesdefault,-generic. Use --list-extractors fora list of extractor names. (Alias: --ies) --default-search PREFIX Use this prefix for unqualified URLs. E.g.\"gvsearch2:python\" downloads two videos fromgoogle videos for the search term \"python\".Use the value \"auto\" to let yt-dlp guess(\"auto_warning\" to emit a warning whenguessing). \"error\" just throws an error. Thedefault value \"fixup_error\" repairs brokenURLs, but emits an error if this is notpossible instead of searching --ignore-config Don't load any more configuration filesexcept those given by --config-locations.For backward compatibility, if this optionis found inside the system configurationfile, the user configuration is not loaded.(Alias: --no-config) --no-config-locations Do not load any custom configuration files(default). When given inside a configurationfile, ignore all previous --config-locationsdefined in the current file --config-locations PATH Location of the main configuration file;either the path to the config or itscontaining directory (\"-\" for stdin). Can beused multiple times and inside otherconfiguration files --flat-playlist Do not extract the videos of a playlist,only list them --no-flat-playlist Fully extract the videos of a playlist(default) --live-from-start Download livestreams from the start.Currently only supported for YouTube(Experimental) --no-live-from-start Download livestreams from the current time(default) --wait-for-video MIN[-MAX] Wait for scheduled streams to becomeavailable. Pass the minimum number ofseconds (or range) to wait between retries --no-wait-for-video Do not wait for scheduled streams (default) --mark-watched Mark videos watched (even with --simulate) --no-mark-watched Do not mark videos watched (default) --color [STREAM:]POLICY Whether to emit color codes in output,optionally prefixed by the STREAM (stdout orstderr) to apply the setting to. Can be oneof \"always\", \"auto\" (default), \"never\", or\"no_color\" (use non color terminalsequences). Can be used multiple times --compat-options OPTS Options that can help keep compatibilitywith youtube-dl or youtube-dlcconfigurations by reverting some of thechanges made in yt-dlp. See \"Differences indefault behavior\" for details --alias ALIASES OPTIONS Create aliases for an option string. Unlessan alias starts with a dash \"-\", it isprefixed with \"--\". Arguments are parsedaccording to the Python string formattingmini-language. E.g. --alias get-audio,-X\"-S=aext:{0},abr -x --audio-format {0}\"creates options \"--get-audio\" and \"-X\" thattakes an argument (ARG0) and expands to\"-S=aext:ARG0,abr -x --audio-format ARG0\".All defined aliases are listed in the --helpoutput. Alias options can trigger morealiases; so be careful to avoid definingrecursive options. As a safety measure, eachalias may be triggered a maximum of 100times. This option can be used multiple times Network Options: --proxy URL Use the specified HTTP/HTTPS/SOCKS proxy. Toenable SOCKS proxy, specify a proper scheme,e.g. socks5://user:pass@127.0.0.1:1080/.Pass in an empty string (--proxy \"\") fordirect connection --socket-timeout SECONDS Time to wait before giving up, in seconds --source-address IP Client-side IP address to bind to -4, --force-ipv4 Make all connections via IPv4 -6, --force-ipv6 Make all connections via IPv6 --enable-file-urls Enable file:// URLs. This is disabled bydefault for security reasons. Geo-restriction: --geo-verification-proxy URL Use this proxy to verify the IP address forsome geo-restricted sites. The default proxyspecified by --proxy (or none, if the optionis not present) is used for the actualdownloading --xff VALUE How to fake X-Forwarded-For HTTP header totry bypassing geographic restriction. One of\"default\" (only when known to be useful),\"never\", an IP block in CIDR notation, or atwo-letter ISO 3166-2 country code Video Selection: -I, --playlist-items ITEM_SPEC Comma separated playlist_index of the itemsto download. You can specify a range using\"[START]:[STOP][:STEP]\". For backwardcompatibility, START-STOP is also supported.Use negative indices to count from the rightand negative STEP to download in reverseorder. E.g. \"-I 1:3,7,-5::2\" used on aplaylist of size 15 will download the itemsat index 1,2,3,7,11,13,15 --min-filesize SIZE Abort download if filesize is smaller thanSIZE, e.g. 50k or 44.6M --max-filesize SIZE Abort download if filesize is larger thanSIZE, e.g. 50k or 44.6M --date DATE Download only videos uploaded on this date.The date can be \"YYYYMMDD\" or in the format[now|today|yesterday][-N[day|week|month|year]].E.g. \"--date today-2weeks\" downloads onlyvideos uploaded on the same day two weeks ago --datebefore DATE Download only videos uploaded on or beforethis date. The date formats accepted is thesame as --date --dateafter DATE Download only videos uploaded on or afterthis date. The date formats accepted is thesame as --date --match-filters FILTER Generic video filter. Any \"OUTPUT TEMPLATE\"field can be compared with a number or astring using the operators defined in\"Filtering Formats\". You can also simplyspecify a field to match if the field ispresent, use \"!field\" to check if the fieldis not present, and \"&\" to check multipleconditions. Use a \"\\\" to escape \"&\" orquotes if needed. If used multiple times,the filter matches if atleast one of theconditions are met. E.g. --match-filter!is_live --match-filter \"like_count>?100 &description~='(?i)\\bcats \\& dogs\\b'\" matchesonly videos that are not live OR those thathave a like count more than 100 (or the likefield is not available) and also has adescription that contains the phrase \"cats &dogs\" (caseless). Use \"--match-filter -\" tointeractively ask whether to download eachvideo --no-match-filters Do not use any --match-filter (default) --break-match-filters FILTER Same as \"--match-filters\" but stops thedownload process when a video is rejected --no-break-match-filters Do not use any --break-match-filters (default) --no-playlist Download only the video, if the URL refersto a video and a playlist --yes-playlist Download the playlist, if the URL refers toa video and a playlist --age-limit YEARS Download only videos suitable for the givenage --download-archive FILE Download only videos not listed in thearchive file. Record the IDs of alldownloaded videos in it --no-download-archive Do not use archive file (default) --max-downloads NUMBER Abort after downloading NUMBER files --break-on-existing Stop the download process when encounteringa file that is in the archive --break-per-input Alters --max-downloads, --break-on-existing,--break-match-filter, and autonumber toreset per input URL --no-break-per-input --break-on-existing and similar optionsterminates the entire download queue --skip-playlist-after-errors N Number of allowed failures until the rest ofthe playlist is skipped Download Options: -N, --concurrent-fragments N Number of fragments of a dash/hlsnativevideo that should be downloaded concurrently(default is 1) -r, --limit-rate RATE Maximum download rate in bytes per second,e.g. 50K or 4.2M --throttled-rate RATE Minimum download rate in bytes per secondbelow which throttling is assumed and thevideo data is re-extracted, e.g. 100K -R, --retries RETRIES Number of retries (default is 10), or\"infinite\" --file-access-retries RETRIES Number of times to retry on file accesserror (default is 3), or \"infinite\" --fragment-retries RETRIES Number of retries for a fragment (default is10), or \"infinite\" (DASH, hlsnative and ISM) --retry-sleep [TYPE:]EXPR Time to sleep between retries in seconds(optionally) prefixed by the type of retry(http (default), fragment, file_access,extractor) to apply the sleep to. EXPR canbe a number, linear=START[:END[:STEP=1]] orexp=START[:END[:BASE=2]]. This option can beused multiple times to set the sleep for thedifferent retry types, e.g. --retry-sleeplinear=1::2 --retry-sleep fragment:exp=1:20 --skip-unavailable-fragments Skip unavailable fragments for DASH,hlsnative and ISM downloads (default)(Alias: --no-abort-on-unavailable-fragments) --abort-on-unavailable-fragmentsAbort download if a fragment is unavailable(Alias: --no-skip-unavailable-fragments) --keep-fragments Keep downloaded fragments on disk afterdownloading is finished --no-keep-fragments Delete downloaded fragments afterdownloading is finished (default) --buffer-size SIZE Size of download buffer, e.g. 1024 or 16K(default is 1024) --resize-buffer The buffer size is automatically resizedfrom an initial value of --buffer-size(default) --no-resize-buffer Do not automatically adjust the buffer size --http-chunk-size SIZE Size of a chunk for chunk-based HTTPdownloading, e.g. 10485760 or 10M (defaultis disabled). May be useful for bypassingbandwidth throttling imposed by a webserver(experimental) --playlist-random Download playlist videos in random order --lazy-playlist Process entries in the playlist as they arereceived. This disables n_entries,--playlist-random and --playlist-reverse --no-lazy-playlist Process videos in the playlist only afterthe entire playlist is parsed (default) --xattr-set-filesize Set file xattribute ytdl.filesize withexpected file size --hls-use-mpegts Use the mpegts container for HLS videos;allowing some players to play the videowhile downloading, and reducing the chanceof file corruption if download isinterrupted. This is enabled by default forlive streams --no-hls-use-mpegts Do not use the mpegts container for HLSvideos. This is default when not downloadinglive streams --download-sections REGEX Download only chapters that match theregular expression. A \"*\" prefix denotestime-range instead of chapter. Negativetimestamps are calculated from the end.\"*from-url\" can be used to download betweenthe \"start_time\" and \"end_time\" extractedfrom the URL. Needs ffmpeg. This option canbe used multiple times to download multiplesections, e.g. --download-sections\"*10:15-inf\" --download-sections \"intro\" --downloader [PROTO:]NAME Name or path of the external downloader touse (optionally) prefixed by the protocols(http, ftp, m3u8, dash, rstp, rtmp, mms) touse it for. Currently supports native,aria2c, avconv, axel, curl, ffmpeg, httpie,wget. You can use this option multiple timesto set different downloaders for differentprotocols. E.g. --downloader aria2c--downloader \"dash,m3u8:native\" will usearia2c for http/ftp downloads, and thenative downloader for dash/m3u8 downloads(Alias: --external-downloader) --downloader-args NAME:ARGS Give these arguments to the externaldownloader. Specify the downloader name andthe arguments separated by a colon \":\". Forffmpeg, arguments can be passed to differentpositions using the same syntax as--postprocessor-args. You can use thisoption multiple times to give differentarguments to different downloaders (Alias:--external-downloader-args) Filesystem Options: -a, --batch-file FILE File containing URLs to download (\"-\" forstdin), one URL per line. Lines startingwith \"#\", \";\" or \"]\" are considered ascomments and ignored --no-batch-file Do not read URLs from batch file (default) -P, --paths [TYPES:]PATH The paths where the files should bedownloaded. Specify the type of file and thepath separated by a colon \":\". All the sameTYPES as --output are supported.Additionally, you can also provide \"home\"(default) and \"temp\" paths. All intermediaryfiles are first downloaded to the temp pathand then the final files are moved over tothe home path after download is finished.This option is ignored if --output is anabsolute path -o, --output [TYPES:]TEMPLATE Output filename template; see \"OUTPUTTEMPLATE\" for details --output-na-placeholder TEXT Placeholder for unavailable fields in\"OUTPUT TEMPLATE\" (default: \"NA\") --restrict-filenames Restrict filenames to only ASCII characters,and avoid \"&\" and spaces in filenames --no-restrict-filenames Allow Unicode characters, \"&\" and spaces infilenames (default) --windows-filenames Force filenames to be Windows-compatible --no-windows-filenames Make filenames Windows-compatible only ifusing Windows (default) --trim-filenames LENGTH Limit the filename length (excludingextension) to the specified number ofcharacters -w, --no-overwrites Do not overwrite any files --force-overwrites Overwrite all video and metadata files. Thisoption includes --no-continue --no-force-overwrites Do not overwrite the video, but overwriterelated files (default) -c, --continue Resume partially downloaded files/fragments(default) --no-continue Do not resume partially downloadedfragments. If the file is not fragmented,restart download of the entire file --part Use .part files instead of writing directlyinto output file (default) --no-part Do not use .part files - write directly intooutput file --mtime Use the Last-modified header to set the filemodification time (default) --no-mtime Do not use the Last-modified header to setthe file modification time --write-description Write video description to a .description file --no-write-description Do not write video description (default) --write-info-json Write video metadata to a .info.json file(this may contain personal information) --no-write-info-json Do not write video metadata (default) --write-playlist-metafiles Write playlist metadata in addition to thevideo metadata when using --write-info-json,--write-description etc. (default) --no-write-playlist-metafiles Do not write playlist metadata when using--write-info-json, --write-description etc. --clean-info-json Remove some internal metadata such asfilenames from the infojson (default) --no-clean-info-json Write all fields to the infojson --write-comments Retrieve video comments to be placed in theinfojson. The comments are fetched evenwithout this option if the extraction isknown to be quick (Alias: --get-comments) --no-write-comments Do not retrieve video comments unless theextraction is known to be quick (Alias:--no-get-comments) --load-info-json FILE JSON file containing the video information(created with the \"--write-info-json\" option) --cookies FILE Netscape formatted file to read cookies fromand dump cookie jar in --no-cookies Do not read/dump cookies from/to file(default) --cookies-from-browser BROWSER[+KEYRING][:PROFILE][::CONTAINER]The name of the browser to load cookiesfrom. Currently supported browsers are:brave, chrome, chromium, edge, firefox,opera, safari, vivaldi. Optionally, theKEYRING used for decrypting Chromium cookieson Linux, the name/path of the PROFILE toload cookies from, and the CONTAINER name(if Firefox) (\"none\" for no container) canbe given with their respective seperators.By default, all containers of the mostrecently accessed profile are used.Currently supported keyrings are: basictext,gnomekeyring, kwallet, kwallet5, kwallet6 --no-cookies-from-browser Do not load cookies from browser (default) --cache-dir DIR Location in the filesystem where yt-dlp canstore some downloaded information (such asclient ids and signatures) permanently. Bydefault ${XDG_CACHE_HOME}/yt-dlp --no-cache-dir Disable filesystem caching --rm-cache-dir Delete all filesystem cache files Thumbnail Options: --write-thumbnail Write thumbnail image to disk --no-write-thumbnail Do not write thumbnail image to disk (default) --write-all-thumbnails Write all thumbnail image formats to disk --list-thumbnails List available thumbnails of each video.Simulate unless --no-simulate is used Internet Shortcut Options: --write-link Write an internet shortcut file, dependingon the current platform (.url, .webloc or.desktop). The URL may be cached by the OS --write-url-link Write a .url Windows internet shortcut. TheOS caches the URL based on the file path --write-webloc-link Write a .webloc macOS internet shortcut --write-desktop-link Write a .desktop Linux internet shortcut Verbosity and Simulation Options: -q, --quiet Activate quiet mode. If used with --verbose,print the log to stderr --no-quiet Deactivate quiet mode. (Default) --no-warnings Ignore warnings -s, --simulate Do not download the video and do not writeanything to disk --no-simulate Download the video even if printing/listingoptions are used --ignore-no-formats-error Ignore \"No video formats\" error. Useful forextracting metadata even if the videos arenot actually available for download(experimental) --no-ignore-no-formats-error Throw error when no downloadable videoformats are found (default) --skip-download Do not download the video but write allrelated files (Alias: --no-download) -O, --print [WHEN:]TEMPLATE Field name or output template to print toscreen, optionally prefixed with when toprint it, separated by a \":\". Supportedvalues of \"WHEN\" are the same as that of--use-postprocessor (default: video).Implies --quiet. Implies --simulate unless--no-simulate or later stages of WHEN areused. This option can be used multiple times --print-to-file [WHEN:]TEMPLATE FILEAppend given template to the file. Thevalues of WHEN and TEMPLATE are same as thatof --print. FILE uses the same syntax as theoutput template. This option can be usedmultiple times -j, --dump-json Quiet, but print JSON information for eachvideo. Simulate unless --no-simulate isused. See \"OUTPUT TEMPLATE\" for adescription of available keys -J, --dump-single-json Quiet, but print JSON information for eachurl or infojson passed. Simulate unless--no-simulate is used. If the URL refers toa playlist, the whole playlist informationis dumped in a single line --force-write-archive Force download archive entries to be writtenas far as no errors occur, even if -s oranother simulation option is used (Alias:--force-download-archive) --newline Output progress bar as new lines --no-progress Do not print progress bar --progress Show progress bar, even if in quiet mode --console-title Display progress in console titlebar --progress-template [TYPES:]TEMPLATETemplate for progress outputs, optionallyprefixed with one of \"download:\" (default),\"download-title:\" (the console title),\"postprocess:\", or \"postprocess-title:\".The video's fields are accessible under the\"info\" key and the progress attributes areaccessible under \"progress\" key. E.g.--console-title --progress-template\"download-title:%(info.id)s-%(progress.eta)s\" -v, --verbose Print various debugging information --dump-pages Print downloaded pages encoded using base64to debug problems (very verbose) --write-pages Write downloaded intermediary pages to filesin the current directory to debug problems --print-traffic Display sent and read HTTP traffic Workarounds: --encoding ENCODING Force the specified encoding (experimental) --legacy-server-connect Explicitly allow HTTPS connection to serversthat do not support RFC 5746 securerenegotiation --no-check-certificates Suppress HTTPS certificate validation --prefer-insecure Use an unencrypted connection to retrieveinformation about the video (Currentlysupported only for YouTube) --add-headers FIELD:VALUE Specify a custom HTTP header and its value,separated by a colon \":\". You can use thisoption multiple times --bidi-workaround Work around terminals that lackbidirectional text support. Requires bidivor fribidi executable in PATH --sleep-requests SECONDS Number of seconds to sleep between requestsduring data extraction --sleep-interval SECONDS Number of seconds to sleep before eachdownload. This is the minimum time to sleepwhen used along with --max-sleep-interval(Alias: --min-sleep-interval) --max-sleep-interval SECONDS Maximum number of seconds to sleep. Can onlybe used along with --min-sleep-interval --sleep-subtitles SECONDS Number of seconds to sleep before eachsubtitle download Video Format Options: -f, --format FORMAT Video format code, see \"FORMAT SELECTION\"for more details -S, --format-sort SORTORDER Sort the formats by the fields given, see\"Sorting Formats\" for more details --format-sort-force Force user specified sort order to haveprecedence over all fields, see \"SortingFormats\" for more details (Alias: --S-force) --no-format-sort-force Some fields have precedence over the userspecified sort order (default) --video-multistreams Allow multiple video streams to be mergedinto a single file --no-video-multistreams Only one video stream is downloaded for eachoutput file (default) --audio-multistreams Allow multiple audio streams to be mergedinto a single file --no-audio-multistreams Only one audio stream is downloaded for eachoutput file (default) --prefer-free-formats Prefer video formats with free containersover non-free ones of same quality. Use with\"-S ext\" to strictly prefer free containersirrespective of quality --no-prefer-free-formats Don't give any special preference to freecontainers (default) --check-formats Make sure formats are selected only fromthose that are actually downloadable --check-all-formats Check all formats for whether they areactually downloadable --no-check-formats Do not check that the formats are actuallydownloadable -F, --list-formats List available formats of each video.Simulate unless --no-simulate is used --merge-output-format FORMAT Containers that may be used when mergingformats, separated by \"/\", e.g. \"mp4/mkv\".Ignored if no merge is required. (currentlysupported: avi, flv, mkv, mov, mp4, webm) Subtitle Options: --write-subs Write subtitle file --no-write-subs Do not write subtitle file (default) --write-auto-subs Write automatically generated subtitle file(Alias: --write-automatic-subs) --no-write-auto-subs Do not write auto-generated subtitles(default) (Alias: --no-write-automatic-subs) --list-subs List available subtitles of each video.Simulate unless --no-simulate is used --sub-format FORMAT Subtitle format; accepts formats preference,e.g. \"srt\" or \"ass/srt/best\" --sub-langs LANGS Languages of the subtitles to download (canbe regex) or \"all\" separated by commas, e.g.--sub-langs \"en.*,ja\". You can prefix thelanguage code with a \"-\" to exclude it fromthe requested languages, e.g. --sub-langsall,-live_chat. Use --list-subs for a listof available language tags Authentication Options: -u, --username USERNAME Login with this account ID -p, --password PASSWORD Account password. If this option is leftout, yt-dlp will ask interactively -2, --twofactor TWOFACTOR Two-factor authentication code -n, --netrc Use .netrc authentication data --netrc-location PATH Location of .netrc authentication data;either the path or its containing directory.Defaults to ~/.netrc --netrc-cmd NETRC_CMD Command to execute to get the credentialsfor an extractor. --video-password PASSWORD Video password (vimeo, youku) --ap-mso MSO Adobe Pass multiple-system operator (TVprovider) identifier, use --ap-list-mso fora list of available MSOs --ap-username USERNAME Multiple-system operator account login --ap-password PASSWORD Multiple-system operator account password.If this option is left out, yt-dlp will askinteractively --ap-list-mso List all supported multiple-system operators --client-certificate CERTFILE Path to client certificate file in PEMformat. May include the private key --client-certificate-key KEYFILEPath to private key file for clientcertificate --client-certificate-password PASSWORDPassword for client certificate private key,if encrypted. If not provided, and the keyis encrypted, yt-dlp will ask interactively Post-Processing Options: -x, --extract-audio Convert video files to audio-only files(requires ffmpeg and ffprobe) --audio-format FORMAT Format to convert the audio to when -x isused. (currently supported: best (default),aac, alac, flac, m4a, mp3, opus, vorbis,wav). You can specify multiple rules usingsimilar syntax as --remux-video --audio-quality QUALITY Specify ffmpeg audio quality to use whenconverting the audio with -x. Insert a valuebetween 0 (best) and 10 (worst) for VBR or aspecific bitrate like 128K (default 5) --remux-video FORMAT Remux the video into another container ifnecessary (currently supported: avi, flv,gif, mkv, mov, mp4, webm, aac, aiff, alac,flac, m4a, mka, mp3, ogg, opus, vorbis,wav). If target container does not supportthe video/audio codec, remuxing will fail.You can specify multiple rules; e.g.\"aac>m4a/mov>mp4/mkv\" will remux aac to m4a,mov to mp4 and anything else to mkv --recode-video FORMAT Re-encode the video into another format ifnecessary. The syntax and supported formatsare the same as --remux-video --postprocessor-args NAME:ARGS Give these arguments to the postprocessors.Specify the postprocessor/executable nameand the arguments separated by a colon \":\"to give the argument to the specifiedpostprocessor/executable. Supported PP are:Merger, ModifyChapters, SplitChapters,ExtractAudio, VideoRemuxer, VideoConvertor,Metadata, EmbedSubtitle, EmbedThumbnail,SubtitlesConvertor, ThumbnailsConvertor,FixupStretched, FixupM4a, FixupM3u8,FixupTimestamp and FixupDuration. Thesupported executables are: AtomicParsley,FFmpeg and FFprobe. You can also specify\"PP+EXE:ARGS\" to give the arguments to thespecified executable only when being used bythe specified postprocessor. Additionally,for ffmpeg/ffprobe, \"_i\"/\"_o\" can beappended to the prefix optionally followedby a number to pass the argument before thespecified input/output file, e.g. --ppa\"Merger+ffmpeg_i1:-v quiet\". You can usethis option multiple times to give differentarguments to different postprocessors.(Alias: --ppa) -k, --keep-video Keep the intermediate video file on diskafter post-processing --no-keep-video Delete the intermediate video file afterpost-processing (default) --post-overwrites Overwrite post-processed files (default) --no-post-overwrites Do not overwrite post-processed files --embed-subs Embed subtitles in the video (only for mp4,webm and mkv videos) --no-embed-subs Do not embed subtitles (default) --embed-thumbnail Embed thumbnail in the video as cover art --no-embed-thumbnail Do not embed thumbnail (default) --embed-metadata Embed metadata to the video file. Alsoembeds chapters/infojson if present unless--no-embed-chapters/--no-embed-info-json areused (Alias: --add-metadata) --no-embed-metadata Do not add metadata to file (default)(Alias: --no-add-metadata) --embed-chapters Add chapter markers to the video file(Alias: --add-chapters) --no-embed-chapters Do not add chapter markers (default) (Alias:--no-add-chapters) --embed-info-json Embed the infojson as an attachment tomkv/mka video files --no-embed-info-json Do not embed the infojson as an attachmentto the video file --parse-metadata [WHEN:]FROM:TOParse additional metadata like title/artistfrom other fields; see \"MODIFYING METADATA\"for details. Supported values of \"WHEN\" arethe same as that of --use-postprocessor(default: pre_process) --replace-in-metadata [WHEN:]FIELDS REGEX REPLACEReplace text in a metadata field using thegiven regex. This option can be usedmultiple times. Supported values of \"WHEN\"are the same as that of --use-postprocessor(default: pre_process) --xattrs Write metadata to the video file's xattrs(using dublin core and xdg standards) --concat-playlist POLICY Concatenate videos in a playlist. One of\"never\", \"always\", or \"multi_video\"(default; only when the videos form a singleshow). All the video files must have samecodecs and number of streams to beconcatable. The \"pl_video:\" prefix can beused with \"--paths\" and \"--output\" to setthe output filename for the concatenatedfiles. See \"OUTPUT TEMPLATE\" for details --fixup POLICY Automatically correct known faults of thefile. One of never (do nothing), warn (onlyemit a warning), detect_or_warn (thedefault; fix file if we can, warnotherwise), force (try fixing even if filealready exists) --ffmpeg-location PATH Location of the ffmpeg binary; either thepath to the binary or its containing directory --exec [WHEN:]CMD Execute a command, optionally prefixed withwhen to execute it, separated by a \":\".Supported values of \"WHEN\" are the same asthat of --use-postprocessor (default:after_move). Same syntax as the outputtemplate can be used to pass any field asarguments to the command. If no fields arepassed, %(filepath,_filename|)q is appendedto the end of the command. This option canbe used multiple times --no-exec Remove any previously defined --exec --convert-subs FORMAT Convert the subtitles to another format(currently supported: ass, lrc, srt, vtt)(Alias: --convert-subtitles) --convert-thumbnails FORMAT Convert the thumbnails to another format(currently supported: jpg, png, webp). Youcan specify multiple rules using similarsyntax as --remux-video --split-chapters Split video into multiple files based oninternal chapters. The \"chapter:\" prefix canbe used with \"--paths\" and \"--output\" to setthe output filename for the split files. See\"OUTPUT TEMPLATE\" for details --no-split-chapters Do not split video based on chapters (default) --remove-chapters REGEX Remove chapters whose title matches thegiven regular expression. The syntax is thesame as --download-sections. This option canbe used multiple times --no-remove-chapters Do not remove any chapters from the file(default) --force-keyframes-at-cuts Force keyframes at cuts whendownloading/splitting/removing sections.This is slow due to needing a re-encode, butthe resulting video may have fewer artifactsaround the cuts --no-force-keyframes-at-cuts Do not force keyframes around the chapterswhen cutting/splitting (default) --use-postprocessor NAME[:ARGS]The (case sensitive) name of pluginpostprocessors to be enabled, and(optionally) arguments to be passed to it,separated by a colon \":\". ARGS are asemicolon \";\" delimited list of NAME=VALUE.The \"when\" argument determines when thepostprocessor is invoked. It can be one of\"pre_process\" (after video extraction),\"after_filter\" (after video passes filter),\"video\" (after --format; before--print/--output), \"before_dl\" (before eachvideo download), \"post_process\" (after eachvideo download; default), \"after_move\"(after moving video file to it's finallocations), \"after_video\" (after downloadingand processing all formats of a video), or\"playlist\" (at end of playlist). This optioncan be used multiple times to add differentpostprocessors SponsorBlock Options: Make chapter entries for, or remove various segments (sponsor, introductions, etc.) from downloaded YouTube videos using the SponsorBlock API --sponsorblock-mark CATS SponsorBlock categories to create chaptersfor, separated by commas. Availablecategories are sponsor, intro, outro,selfpromo, preview, filler, interaction,music_offtopic, poi_highlight, chapter, alland default (=all). You can prefix thecategory with a \"-\" to exclude it. See [1]for description of the categories. E.g.--sponsorblock-mark all,-preview[1] https://wiki.sponsor.ajay.app/w/Segment_Categories --sponsorblock-remove CATS SponsorBlock categories to be removed fromthe video file, separated by commas. If acategory is present in both mark and remove,remove takes precedence. The syntax andavailable categories are the same as for--sponsorblock-mark except that \"default\"refers to \"all,-filler\" and poi_highlight,chapter are not available --sponsorblock-chapter-title TEMPLATEAn output template for the title of theSponsorBlock chapters created by--sponsorblock-mark. The only availablefields are start_time, end_time, category,categories, name, category_names. Defaultsto \"[SponsorBlock]: %(category_names)l\" --no-sponsorblock Disable both --sponsorblock-mark and--sponsorblock-remove --sponsorblock-api URL SponsorBlock API location, defaults tohttps://sponsor.ajay.app Extractor Options: --extractor-retries RETRIES Number of retries for known extractor errors(default is 3), or \"infinite\" --allow-dynamic-mpd Process dynamic DASH manifests (default)(Alias: --no-ignore-dynamic-mpd) --ignore-dynamic-mpd Do not process dynamic DASH manifests(Alias: --no-allow-dynamic-mpd) --hls-split-discontinuity Split HLS playlists to different formats atdiscontinuities such as ad breaks --no-hls-split-discontinuity Do not split HLS playlists to differentformats at discontinuities such as ad breaks(default) --extractor-args IE_KEY:ARGS Pass ARGS arguments to the IE_KEY extractor.See \"EXTRACTOR ARGUMENTS\" for details. Youcan use this option multiple times to givearguments for different extractors CONFIGURATION You can configure yt-dlp by placing any supported command line option to a configuration file. The configuration is loaded from the following locations: Main Configuration: The file given by --config-location Portable Configuration: (Recommended for portable installations) If using a binary, yt-dlp.conf in the same directory as the binary If running from source-code, yt-dlp.conf in the parent directory of yt_dlp Home Configuration: yt-dlp.conf in the home path given by -P If -P is not given, the current directory is searched User Configuration: ${XDG_CONFIG_HOME}/yt-dlp.conf ${XDG_CONFIG_HOME}/yt-dlp/config (recommended on Linux/macOS) ${XDG_CONFIG_HOME}/yt-dlp/config.txt ${APPDATA}/yt-dlp.conf ${APPDATA}/yt-dlp/config (recommended on Windows) ${APPDATA}/yt-dlp/config.txt ~/yt-dlp.conf ~/yt-dlp.conf.txt ~/.yt-dlp/config ~/.yt-dlp/config.txt See also: Notes about environment variables System Configuration: /etc/yt-dlp.conf /etc/yt-dlp/config /etc/yt-dlp/config.txt E.g. with the following configuration file yt-dlp will always extract the audio, not copy the mtime, use a proxy and save all videos under YouTube directory in your home directory: # Lines starting with # are comments # Always extract audio -x # Do not copy the mtime --no-mtime # Use this proxy --proxy 127.0.0.1:3128 # Save all videos under YouTube directory in your home directory -o ~/YouTube/%(title)s.%(ext)s Note: Options in configuration file are just the same options aka switches used in regular command line calls; thus there must be no whitespace after - or --, e.g. -o or --proxy but not - o or -- proxy. They must also be quoted when necessary as-if it were a UNIX shell. You can use --ignore-config if you want to disable all configuration files for a particular yt-dlp run. If --ignore-config is found inside any configuration file, no further configuration will be loaded. For example, having the option in the portable configuration file prevents loading of home, user, and system configurations. Additionally, (for backward compatibility) if --ignore-config is found inside the system configuration file, the user configuration is not loaded. Configuration file encoding The configuration files are decoded according to the UTF BOM if present, and in the encoding from system locale otherwise. If you want your file to be decoded differently, add # coding: ENCODING to the beginning of the file (e.g. # coding: shift-jis). There must be no characters before that, even spaces or BOM. Authentication with netrc You may also want to configure automatic credentials storage for extractors that support authentication (by providing login and password with --username and --password) in order not to pass credentials as command line arguments on every yt-dlp execution and prevent tracking plain text passwords in the shell command history. You can achieve this using a .netrc file on a per-extractor basis. For that you will need to create a .netrc file in --netrc-location and restrict permissions to read/write by only you: touch ${HOME}/.netrc chmod a-rwx,u+rw ${HOME}/.netrc After that you can add credentials for an extractor in the following format, where extractor is the name of the extractor in lowercase: machineloginpasswordE.g. machine youtube login myaccount@gmail.com password my_youtube_password machine twitch login my_twitch_account_name password my_twitch_password To activate authentication with the .netrc file you should pass --netrc to yt-dlp or place it in the configuration file. The default location of the .netrc file is ~ (see below). As an alternative to using the .netrc file, which has the disadvantage of keeping your passwords in a plain text file, you can configure a custom shell command to provide the credentials for an extractor. This is done by providing the --netrc-cmd parameter, it shall output the credentials in the netrc format and return 0 on success, other values will be treated as an error. {} in the command will be replaced by the name of the extractor to make it possible to select the credentials for the right extractor. E.g. To use an encrypted .netrc file stored as .authinfo.gpg yt-dlp --netrc-cmd 'gpg --decrypt ~/.authinfo.gpg' https://www.youtube.com/watch?v=BaW_jenozKc Notes about environment variables Environment variables are normally specified as ${VARIABLE}/$VARIABLE on UNIX and %VARIABLE% on Windows; but is always shown as ${VARIABLE} in this documentation yt-dlp also allow using UNIX-style variables on Windows for path-like options; e.g. --output, --config-location If unset, ${XDG_CONFIG_HOME} defaults to ~/.config and ${XDG_CACHE_HOME} to ~/.cache On Windows, ~ points to ${HOME} if present; or, ${USERPROFILE} or ${HOMEDRIVE}${HOMEPATH} otherwise On Windows, ${USERPROFILE} generally points to C:\\Users\\ and ${APPDATA} to ${USERPROFILE}\\AppData\\Roaming OUTPUT TEMPLATE The -o option is used to indicate a template for the output file names while -P option is used to specify the path each type of file should be saved to. tl;dr: navigate me to examples. The simplest usage of -o is not to set any template arguments when downloading a single file, like in yt-dlp -o funny_video.flv \"https://some/video\" (hard-coding file extension like this is not recommended and could break some post-processing). It may however also contain special sequences that will be replaced when downloading each video. The special sequences may be formatted according to Python string formatting operations, e.g. %(NAME)s or %(NAME)05d. To clarify, that is a percent symbol followed by a name in parentheses, followed by formatting operations. The field names themselves (the part inside the parenthesis) can also have some special formatting: Object traversal: The dictionaries and lists available in metadata can be traversed by using a dot . separator; e.g. %(tags.0)s, %(subtitles.en.-1.ext)s. You can do Python slicing with colon :; E.g. %(id.3:7:-1)s, %(formats.:.format_id)s. Curly braces {} can be used to build dictionaries with only specific keys; e.g. %(formats.:.{format_id,height})#j. An empty field name %()s refers to the entire infodict; e.g. %(.{id,title})s. Note that all the fields that become available using this method are not listed below. Use -j to see such fields Addition: Addition and subtraction of numeric fields can be done using + and - respectively. E.g. %(playlist_index+10)03d, %(n_entries+1-playlist_index)d Date/time Formatting: Date/time fields can be formatted according to strftime formatting by specifying it separated from the field name using a >. E.g. %(duration>%H-%M-%S)s, %(upload_date>%Y-%m-%d)s, %(epoch-3600>%H-%M-%S)s Alternatives: Alternate fields can be specified separated with a ,. E.g. %(release_date>%Y,upload_date>%Y|Unknown)s Replacement: A replacement value can be specified using a & separator according to the str.format mini-language. If the field is not empty, this replacement value will be used instead of the actual field content. This is done after alternate fields are considered; thus the replacement is used if any of the alternative fields is not empty. E.g. %(chapters&has chapters|no chapters)s, %(title&TITLE={:>20}|NO TITLE)s Default: A literal default value can be specified for when the field is empty using aseparator. This overrides --output-na-placeholder. E.g. %(uploader|Unknown)s More Conversions: In addition to the normal format types diouxXeEfFgGcrs, yt-dlp additionally supports converting to B = Bytes, j = json (flag # for pretty-printing, + for Unicode), h = HTML escaping, l = a comma separated list (flag # for \\n newline-separated), q = a string quoted for the terminal (flag # to split a list into different arguments), D = add Decimal suffixes (e.g. 10M) (flag # to use 1024 as factor), and S = Sanitize as filename (flag # for restricted) Unicode normalization: The format type U can be used for NFC Unicode normalization. The alternate form flag (#) changes the normalization to NFD and the conversion flag + can be used for NFKC/NFKD compatibility equivalence normalization. E.g. %(title)+.100U is NFKC To summarize, the general syntax for a field is: %(name[.keys][addition][>strf][,alternate][&replacement][|default])[flags][width][.precision][length]type Additionally, you can set different output templates for the various metadata files separately from the general output template by specifying the type of file followed by the template separated by a colon :. The different file types supported are subtitle, thumbnail, description, annotation (deprecated), infojson, link, pl_thumbnail, pl_description, pl_infojson, chapter, pl_video. E.g. -o \"%(title)s.%(ext)s\" -o \"thumbnail:%(title)s\\%(title)s.%(ext)s\" will put the thumbnails in a folder with the same name as the video. If any of the templates is empty, that type of file will not be written. E.g. --write-thumbnail -o \"thumbnail:\" will write thumbnails only for playlists and not for video. Note: Due to post-processing (i.e. merging etc.), the actual output filename might differ. Use --print after_move:filepath to get the name after all post-processing is complete. The available fields are: id (string): Video identifier title (string): Video title fulltitle (string): Video title ignoring live timestamp and generic title ext (string): Video filename extension alt_title (string): A secondary title of the video description (string): The description of the video display_id (string): An alternative identifier for the video uploader (string): Full name of the video uploader license (string): License name the video is licensed under creator (string): The creator of the video timestamp (numeric): UNIX timestamp of the moment the video became available upload_date (string): Video upload date in UTC (YYYYMMDD) release_timestamp (numeric): UNIX timestamp of the moment the video was released release_date (string): The date (YYYYMMDD) when the video was released in UTC modified_timestamp (numeric): UNIX timestamp of the moment the video was last modified modified_date (string): The date (YYYYMMDD) when the video was last modified in UTC uploader_id (string): Nickname or id of the video uploader channel (string): Full name of the channel the video is uploaded on channel_id (string): Id of the channel channel_follower_count (numeric): Number of followers of the channel channel_is_verified (boolean): Whether the channel is verified on the platform location (string): Physical location where the video was filmed duration (numeric): Length of the video in seconds duration_string (string): Length of the video (HH:mm:ss) view_count (numeric): How many users have watched the video on the platform concurrent_view_count (numeric): How many users are currently watching the video on the platform. like_count (numeric): Number of positive ratings of the video dislike_count (numeric): Number of negative ratings of the video repost_count (numeric): Number of reposts of the video average_rating (numeric): Average rating give by users, the scale used depends on the webpage comment_count (numeric): Number of comments on the video (For some extractors, comments are only downloaded at the end, and so this field cannot be used) age_limit (numeric): Age restriction for the video (years) live_status (string): One of \"not_live\", \"is_live\", \"is_upcoming\", \"was_live\", \"post_live\" (was live, but VOD is not yet processed) is_live (boolean): Whether this video is a live stream or a fixed-length video was_live (boolean): Whether this video was originally a live stream playable_in_embed (string): Whether this video is allowed to play in embedded players on other sites availability (string): Whether the video is \"private\", \"premium_only\", \"subscriber_only\", \"needs_auth\", \"unlisted\" or \"public\" start_time (numeric): Time in seconds where the reproduction should start, as specified in the URL end_time (numeric): Time in seconds where the reproduction should end, as specified in the URL extractor (string): Name of the extractor extractor_key (string): Key name of the extractor epoch (numeric): Unix epoch of when the information extraction was completed autonumber (numeric): Number that will be increased with each download, starting at --autonumber-start, padded with leading zeros to 5 digits video_autonumber (numeric): Number that will be increased with each video n_entries (numeric): Total number of extracted items in the playlist playlist_id (string): Identifier of the playlist that contains the video playlist_title (string): Name of the playlist that contains the video playlist (string): playlist_id or playlist_title playlist_count (numeric): Total number of items in the playlist. May not be known if entire playlist is not extracted playlist_index (numeric): Index of the video in the playlist padded with leading zeros according the final index playlist_autonumber (numeric): Position of the video in the playlist download queue padded with leading zeros according to the total length of the playlist playlist_uploader (string): Full name of the playlist uploader playlist_uploader_id (string): Nickname or id of the playlist uploader webpage_url (string): A URL to the video webpage which if given to yt-dlp should allow to get the same result again webpage_url_basename (string): The basename of the webpage URL webpage_url_domain (string): The domain of the webpage URL original_url (string): The URL given by the user (or same as webpage_url for playlist entries) All the fields in Filtering Formats can also be used Available for the video that belongs to some logical chapter or section: chapter (string): Name or title of the chapter the video belongs to chapter_number (numeric): Number of the chapter the video belongs to chapter_id (string): Id of the chapter the video belongs to Available for the video that is an episode of some series or programme: series (string): Title of the series or programme the video episode belongs to season (string): Title of the season the video episode belongs to season_number (numeric): Number of the season the video episode belongs to season_id (string): Id of the season the video episode belongs to episode (string): Title of the video episode episode_number (numeric): Number of the video episode within a season episode_id (string): Id of the video episode Available for the media that is a track or a part of a music album: track (string): Title of the track track_number (numeric): Number of the track within an album or a disc track_id (string): Id of the track artist (string): Artist(s) of the track genre (string): Genre(s) of the track album (string): Title of the album the track belongs to album_type (string): Type of the album album_artist (string): List of all artists appeared on the album disc_number (numeric): Number of the disc or other physical medium the track belongs to release_year (numeric): Year (YYYY) when the album was released Available only when using --download-sections and for chapter: prefix when using --split-chapters for videos with internal chapters: section_title (string): Title of the chapter section_number (numeric): Number of the chapter within the file section_start (numeric): Start time of the chapter in seconds section_end (numeric): End time of the chapter in seconds Available only when used in --print: urls (string): The URLs of all requested formats, one in each line filename (string): Name of the video file. Note that the actual filename may differ formats_table (table): The video format table as printed by --list-formats thumbnails_table (table): The thumbnail format table as printed by --list-thumbnails subtitles_table (table): The subtitle format table as printed by --list-subs automatic_captions_table (table): The automatic subtitle format table as printed by --list-subs Available only after the video is downloaded (post_process/after_move): filepath: Actual path of downloaded video file Available only in --sponsorblock-chapter-title: start_time (numeric): Start time of the chapter in seconds end_time (numeric): End time of the chapter in seconds categories (list): The SponsorBlock categories the chapter belongs to category (string): The smallest SponsorBlock category the chapter belongs to category_names (list): Friendly names of the categories name (string): Friendly name of the smallest category type (string): The SponsorBlock action type of the chapter Each aforementioned sequence when referenced in an output template will be replaced by the actual value corresponding to the sequence name. E.g. for -o %(title)s-%(id)s.%(ext)s and an mp4 video with title yt-dlp test video and id BaW_jenozKc, this will result in a yt-dlp test video-BaW_jenozKc.mp4 file created in the current directory. Note: Some of the sequences are not guaranteed to be present since they depend on the metadata obtained by a particular extractor. Such sequences will be replaced with placeholder value provided with --output-na-placeholder (NA by default). Tip: Look at the -j output to identify which fields are available for the particular URL For numeric sequences you can use numeric related formatting; e.g. %(view_count)05d will result in a string with view count padded with zeros up to 5 characters, like in 00042. Output templates can also contain arbitrary hierarchical path, e.g. -o \"%(playlist)s/%(playlist_index)s - %(title)s.%(ext)s\" which will result in downloading each video in a directory corresponding to this path template. Any missing directory will be automatically created for you. To use percent literals in an output template use %%. To output to stdout use -o -. The current default template is %(title)s [%(id)s].%(ext)s. In some cases, you don't want special characters such as 中, spaces, or &, such as when transferring the downloaded filename to a Windows system or the filename through an 8bit-unsafe channel. In these cases, add the --restrict-filenames flag to get a shorter title. Output template examples $ yt-dlp --print filename -o \"test video.%(ext)s\" BaW_jenozKc test video.webm # Literal name with correct extension $ yt-dlp --print filename -o \"%(title)s.%(ext)s\" BaW_jenozKc youtube-dl test video ''_ä↭𝕐.webm # All kinds of weird characters $ yt-dlp --print filename -o \"%(title)s.%(ext)s\" BaW_jenozKc --restrict-filenames youtube-dl_test_video_.webm # Restricted file name # Download YouTube playlist videos in separate directory indexed by video order in a playlist $ yt-dlp -o \"%(playlist)s/%(playlist_index)s - %(title)s.%(ext)s\" \"https://www.youtube.com/playlist?list=PLwiyx1dc3P2JR9N8gQaQN_BCvlSlap7re\" # Download YouTube playlist videos in separate directories according to their uploaded year $ yt-dlp -o \"%(upload_date>%Y)s/%(title)s.%(ext)s\" \"https://www.youtube.com/playlist?list=PLwiyx1dc3P2JR9N8gQaQN_BCvlSlap7re\" # Prefix playlist index with \" - \" separator, but only if it is available $ yt-dlp -o \"%(playlist_index&{} - |)s%(title)s.%(ext)s\" BaW_jenozKc \"https://www.youtube.com/user/TheLinuxFoundation/playlists\" # Download all playlists of YouTube channel/user keeping each playlist in separate directory: $ yt-dlp -o \"%(uploader)s/%(playlist)s/%(playlist_index)s - %(title)s.%(ext)s\" \"https://www.youtube.com/user/TheLinuxFoundation/playlists\" # Download Udemy course keeping each chapter in separate directory under MyVideos directory in your home $ yt-dlp -u user -p password -P \"~/MyVideos\" -o \"%(playlist)s/%(chapter_number)s - %(chapter)s/%(title)s.%(ext)s\" \"https://www.udemy.com/java-tutorial\" # Download entire series season keeping each series and each season in separate directory under C:/MyVideos $ yt-dlp -P \"C:/MyVideos\" -o \"%(series)s/%(season_number)s - %(season)s/%(episode_number)s - %(episode)s.%(ext)s\" \"https://videomore.ru/kino_v_detalayah/5_sezon/367617\" # Download video as \"C:\\MyVideos\\uploader\\title.ext\", subtitles as \"C:\\MyVideos\\subs\\uploader\\title.ext\" # and put all temporary files in \"C:\\MyVideos\\tmp\" $ yt-dlp -P \"C:/MyVideos\" -P \"temp:tmp\" -P \"subtitle:subs\" -o \"%(uploader)s/%(title)s.%(ext)s\" BaW_jenoz --write-subs # Download video as \"C:\\MyVideos\\uploader\\title.ext\" and subtitles as \"C:\\MyVideos\\uploader\\subs\\title.ext\" $ yt-dlp -P \"C:/MyVideos\" -o \"%(uploader)s/%(title)s.%(ext)s\" -o \"subtitle:%(uploader)s/subs/%(title)s.%(ext)s\" BaW_jenozKc --write-subs # Stream the video being downloaded to stdout $ yt-dlp -o - BaW_jenozKc FORMAT SELECTION By default, yt-dlp tries to download the best available quality if you don't pass any options. This is generally equivalent to using -f bestvideo*+bestaudio/best. However, if multiple audiostreams is enabled (--audio-multistreams), the default format changes to -f bestvideo+bestaudio/best. Similarly, if ffmpeg is unavailable, or if you use yt-dlp to stream to stdout (-o -), the default becomes -f best/bestvideo+bestaudio. Deprecation warning: Latest versions of yt-dlp can stream multiple formats to the stdout simultaneously using ffmpeg. So, in future versions, the default for this will be set to -f bv*+ba/b similar to normal downloads. If you want to preserve the -f b/bv+ba setting, it is recommended to explicitly specify it in the configuration options. The general syntax for format selection is -f FORMAT (or --format FORMAT) where FORMAT is a selector expression, i.e. an expression that describes format or formats you would like to download. tl;dr: navigate me to examples. The simplest case is requesting a specific format; e.g. with -f 22 you can download the format with format code equal to 22. You can get the list of available format codes for particular video using --list-formats or -F. Note that these format codes are extractor specific. You can also use a file extension (currently 3gp, aac, flv, m4a, mp3, mp4, ogg, wav, webm are supported) to download the best quality format of a particular file extension served as a single file, e.g. -f webm will download the best quality format with the webm extension served as a single file. You can use -f - to interactively provide the format selector for each video You can also use special names to select particular edge case formats: all: Select all formats separately mergeall: Select and merge all formats (Must be used with --audio-multistreams, --video-multistreams or both) b*, best*: Select the best quality format that contains either a video or an audio or both (ie; vcodec!=none or acodec!=none) b, best: Select the best quality format that contains both video and audio. Equivalent to best*[vcodec!=none][acodec!=none] bv, bestvideo: Select the best quality video-only format. Equivalent to best*[acodec=none] bv*, bestvideo*: Select the best quality format that contains video. It may also contain audio. Equivalent to best*[vcodec!=none] ba, bestaudio: Select the best quality audio-only format. Equivalent to best*[vcodec=none] ba*, bestaudio*: Select the best quality format that contains audio. It may also contain video. Equivalent to best*[acodec!=none] (Do not use!) w*, worst*: Select the worst quality format that contains either a video or an audio w, worst: Select the worst quality format that contains both video and audio. Equivalent to worst*[vcodec!=none][acodec!=none] wv, worstvideo: Select the worst quality video-only format. Equivalent to worst*[acodec=none] wv*, worstvideo*: Select the worst quality format that contains video. It may also contain audio. Equivalent to worst*[vcodec!=none] wa, worstaudio: Select the worst quality audio-only format. Equivalent to worst*[vcodec=none] wa*, worstaudio*: Select the worst quality format that contains audio. It may also contain video. Equivalent to worst*[acodec!=none] For example, to download the worst quality video-only format you can use -f worstvideo. It is however recommended not to use worst and related options. When your format selector is worst, the format which is worst in all respects is selected. Most of the time, what you actually want is the video with the smallest filesize instead. So it is generally better to use -S +size or more rigorously, -S +size,+br,+res,+fps instead of -f worst. See Sorting Formats for more details. You can select the n'th best format of a type by using best.. For example, best.2 will select the 2nd best combined format. Similarly, bv*.3 will select the 3rd best format that contains a video stream. If you want to download multiple videos, and they don't have the same formats available, you can specify the order of preference using slashes. Note that formats on the left hand side are preferred; e.g. -f 22/17/18 will download format 22 if it's available, otherwise it will download format 17 if it's available, otherwise it will download format 18 if it's available, otherwise it will complain that no suitable formats are available for download. If you want to download several formats of the same video use a comma as a separator, e.g. -f 22,17,18 will download all these three formats, of course if they are available. Or a more sophisticated example combined with the precedence feature: -f 136/137/mp4/bestvideo,140/m4a/bestaudio. You can merge the video and audio of multiple formats into a single file using -f ++... (requires ffmpeg installed); e.g. -f bestvideo+bestaudio will download the best video-only format, the best audio-only format and mux them together with ffmpeg. Deprecation warning: Since the below described behavior is complex and counter-intuitive, this will be removed and multistreams will be enabled by default in the future. A new operator will be instead added to limit formats to single audio/video Unless --video-multistreams is used, all formats with a video stream except the first one are ignored. Similarly, unless --audio-multistreams is used, all formats with an audio stream except the first one are ignored. E.g. -f bestvideo+best+bestaudio --video-multistreams --audio-multistreams will download and merge all 3 given formats. The resulting file will have 2 video streams and 2 audio streams. But -f bestvideo+best+bestaudio --no-video-multistreams will download and merge only bestvideo and bestaudio. best is ignored since another format containing a video stream (bestvideo) has already been selected. The order of the formats is therefore important. -f best+bestaudio --no-audio-multistreams will download only best while -f bestaudio+best --no-audio-multistreams will ignore best and download only bestaudio. Filtering Formats You can also filter the video formats by putting a condition in brackets, as in -f \"best[height=720]\" (or -f \"[filesize>10M]\" since filters without a selector are interpreted as best). The following numeric meta fields can be used with comparisons , >=, = (equals), != (not equals): filesize: The number of bytes, if known in advance filesize_approx: An estimate for the number of bytes width: Width of the video, if known height: Height of the video, if known aspect_ratio: Aspect ratio of the video, if known tbr: Average bitrate of audio and video in KBit/s abr: Average audio bitrate in KBit/s vbr: Average video bitrate in KBit/s asr: Audio sampling rate in Hertz fps: Frame rate audio_channels: The number of audio channels stretched_ratio: width:height of the video's pixels, if not square Also filtering work for comparisons = (equals), ^= (starts with), $= (ends with), *= (contains), ~= (matches regex) and following string meta fields: url: Video URL ext: File extension acodec: Name of the audio codec in use vcodec: Name of the video codec in use container: Name of the container format protocol: The protocol that will be used for the actual download, lower-case (http, https, rtsp, rtmp, rtmpe, mms, f4m, ism, http_dash_segments, m3u8, or m3u8_native) language: Language code dynamic_range: The dynamic range of the video format_id: A short description of the format format: A human-readable description of the format format_note: Additional info about the format resolution: Textual description of width and height Any string comparison may be prefixed with negation ! in order to produce an opposite comparison, e.g. !*= (does not contain). The comparand of a string comparison needs to be quoted with either double or single quotes if it contains spaces or special characters other than ._-. Note: None of the aforementioned meta fields are guaranteed to be present since this solely depends on the metadata obtained by particular extractor, i.e. the metadata offered by the website. Any other field made available by the extractor can also be used for filtering. Formats for which the value is not known are excluded unless you put a question mark (?) after the operator. You can combine format filters, so -f \"bv[height500]\" selects up to 720p videos (or videos where the height is not known) with a bitrate of at least 500 KBit/s. You can also use the filters with all to download all formats that satisfy the filter, e.g. -f \"all[vcodec=none]\" selects all audio-only formats. Format selectors can also be grouped using parentheses; e.g. -f \"(mp4,webm)[height http/ftp > m3u8_native/m3u8 > http_dash_segments> websocket_frag > mms/rtsp > f4f/f4m) vcodec: Video Codec (av01 > vp9.2 > vp9 > h265 > h264 > vp8 > h263 > theora > other) acodec: Audio Codec (flac/alac > wav/aiff > opus > vorbis > aac > mp4a > mp3 > ac4 > eac3 > ac3 > dts > other) codec: Equivalent to vcodec,acodec vext: Video Extension (mp4 > mov > webm > flv > other). If --prefer-free-formats is used, webm is preferred. aext: Audio Extension (m4a > aac > mp3 > ogg > opus > webm > other). If --prefer-free-formats is used, the order changes to ogg > opus > webm > mp3 > m4a > aac ext: Equivalent to vext,aext filesize: Exact filesize, if known in advance fs_approx: Approximate filesize size: Exact filesize if available, otherwise approximate filesize height: Height of video width: Width of video res: Video resolution, calculated as the smallest dimension. fps: Framerate of video hdr: The dynamic range of the video (DV > HDR12 > HDR10+ > HDR10 > HLG > SDR) channels: The number of audio channels tbr: Total average bitrate in KBit/s vbr: Average video bitrate in KBit/s abr: Average audio bitrate in KBit/s br: Average bitrate in KBit/s, tbr/vbr/abr asr: Audio sample rate in Hz Deprecation warning: Many of these fields have (currently undocumented) aliases, that may be removed in a future version. It is recommended to use only the documented field names. All fields, unless specified otherwise, are sorted in descending order. To reverse this, prefix the field with a +. E.g. +res prefers format with the smallest resolution. Additionally, you can suffix a preferred value for the fields, separated by a :. E.g. res:720 prefers larger videos, but no larger than 720p and the smallest video if there are no videos less than 720p. For codec and ext, you can provide two preferred values, the first for video and the second for audio. E.g. +codec:avc:m4a (equivalent to +vcodec:avc,+acodec:m4a) sets the video codec preference to h264 > h265 > vp9 > vp9.2 > av01 > vp8 > h263 > theora and audio codec preference to mp4a > aac > vorbis > opus > mp3 > ac3 > dts. You can also make the sorting prefer the nearest values to the provided by using ~ as the delimiter. E.g. filesize~1G prefers the format with filesize closest to 1 GiB. The fields hasvid and ie_pref are always given highest priority in sorting, irrespective of the user-defined order. This behaviour can be changed by using --format-sort-force. Apart from these, the default order used is: lang,quality,res,fps,hdr:12,vcodec:vp9.2,channels,acodec,size,br,asr,proto,ext,hasaud,source,id. The extractors may override this default order, but they cannot override the user-provided order. Note that the default has vcodec:vp9.2; i.e. av1 is not preferred. Similarly, the default for hdr is hdr:12; i.e. dolby vision is not preferred. These choices are made since DV and AV1 formats are not yet fully compatible with most devices. This may be changed in the future as more devices become capable of smoothly playing back these formats. If your format selector is worst, the last item is selected after sorting. This means it will select the format that is worst in all respects. Most of the time, what you actually want is the video with the smallest filesize instead. So it is generally better to use -f best -S +size,+br,+res,+fps. Tip: You can use the -v -F to see how the formats have been sorted (worst to best). Format Selection examples # Download and merge the best video-only format and the best audio-only format, # or download the best combined format if video-only format is not available $ yt-dlp -f \"bv+ba/b\" # Download best format that contains video, # and if it doesn't already have an audio stream, merge it with best audio-only format $ yt-dlp -f \"bv*+ba/b\" # Same as above $ yt-dlp # Download the best video-only format and the best audio-only format without merging them # For this case, an output template should be used since # by default, bestvideo and bestaudio will have the same file name. $ yt-dlp -f \"bv,ba\" -o \"%(title)s.f%(format_id)s.%(ext)s\" # Download and merge the best format that has a video stream, # and all audio-only formats into one file $ yt-dlp -f \"bv*+mergeall[vcodec=none]\" --audio-multistreams # Download and merge the best format that has a video stream, # and the best 2 audio-only formats into one file $ yt-dlp -f \"bv*+ba+ba.2\" --audio-multistreams # The following examples show the old method (without -S) of format selection # and how to use -S to achieve a similar but (generally) better result # Download the worst video available (old method) $ yt-dlp -f \"wv*+wa/w\" # Download the best video available but with the smallest resolution $ yt-dlp -S \"+res\" # Download the smallest video available $ yt-dlp -S \"+size,+br\" # Download the best mp4 video available, or the best video if no mp4 available $ yt-dlp -f \"bv*[ext=mp4]+ba[ext=m4a]/b[ext=mp4] / bv*+ba/b\" # Download the best video with the best extension # (For video, mp4 > mov > webm > flv. For audio, m4a > aac > mp3 ...) $ yt-dlp -S \"ext\" # Download the best video available but no better than 480p, # or the worst video if there is no video under 480p $ yt-dlp -f \"bv*[height http/ftp > m3u8_native > m3u8 > http_dash_segments ...) $ yt-dlp -S \"proto\" # Download the best video with either h264 or h265 codec, # or the best video if there is no such video $ yt-dlp -f \"(bv*[vcodec~='^((he|a)vc|h26[45])']+ba) / (bv*+ba/b)\" # Download the best video with best codec no better than h264, # or the best video with worst codec if there is no such video $ yt-dlp -S \"codec:h264\" # Download the best video with worst codec no worse than h264, # or the best video with best codec if there is no such video $ yt-dlp -S \"+codec:h264\" # More complex examples # Download the best video no better than 720p preferring framerate greater than 30, # or the worst video (still preferring framerate greater than 30) if there is no such video $ yt-dlp -f \"((bv*[fps>30]/bv*)[height30]/wv*)) + ba / (b[fps>30]/b)[height30]/w)\" # Download the video with the largest resolution no better than 720p, # or the video with the smallest resolution available if there is no such video, # preferring larger framerate for formats with the same resolution $ yt-dlp -S \"res:720,fps\" # Download the video with smallest resolution no worse than 480p, # or the video with the largest resolution available if there is no such video, # preferring better codec and then larger total bitrate for the same resolution $ yt-dlp -S \"+res:480,codec,br\" MODIFYING METADATA The metadata obtained by the extractors can be modified by using --parse-metadata and --replace-in-metadata --replace-in-metadata FIELDS REGEX REPLACE is used to replace text in any metadata field using python regular expression. Backreferences can be used in the replace string for advanced use. The general syntax of --parse-metadata FROM:TO is to give the name of a field or an output template to extract data from, and the format to interpret it as, separated by a colon :. Either a python regular expression with named capture groups, a single field name, or a similar syntax to the output template (only %(field)s formatting is supported) can be used for TO. The option can be used multiple times to parse and modify various fields. Note that these options preserve their relative order, allowing replacements to be made in parsed fields and viceversa. Also, any field thus created can be used in the output template and will also affect the media file's metadata added when using --embed-metadata. This option also has a few special uses: You can download an additional URL based on the metadata of the currently downloaded video. To do this, set the field additional_urls to the URL that you want to download. E.g. --parse-metadata \"description:(?Phttps?://www\\.vimeo\\.com/\\d+)\" will download the first vimeo video found in the description You can use this to change the metadata that is embedded in the media file. To do this, set the value of the corresponding field with a meta_ prefix. For example, any value you set to meta_description field will be added to the description field in the file - you can use this to set a different \"description\" and \"synopsis\". To modify the metadata of individual streams, use the meta_ prefix (e.g. meta1_language). Any value set to the meta_ field will overwrite all default values. Note: Metadata modification happens before format selection, post-extraction and other post-processing operations. Some fields may be added or changed during these steps, overriding your changes. For reference, these are the fields yt-dlp adds by default to the file metadata: Metadata fields From title track or title date upload_date description, synopsis description purl, comment webpage_url track track_number artist artist, creator, uploader or uploader_id genre genre album album album_artist album_artist disc disc_number show series season_number season_number episode_id episode or episode_id episode_sort episode_number language of each stream the format's language Note: The file format may not support some of these fields Modifying metadata examples # Interpret the title as \"Artist - Title\" $ yt-dlp --parse-metadata \"title:%(artist)s - %(title)s\" # Regex example $ yt-dlp --parse-metadata \"description:Artist - (?P.+)\" # Set title as \"Series name S01E05\" $ yt-dlp --parse-metadata \"%(series)s S%(season_number)02dE%(episode_number)02d:%(title)s\" # Prioritize uploader as the \"artist\" field in video metadata $ yt-dlp --parse-metadata \"%(uploader|)s:%(meta_artist)s\" --embed-metadata # Set \"comment\" field in video metadata using description instead of webpage_url, # handling multiple lines correctly $ yt-dlp --parse-metadata \"description:(?s)(?P.+)\" --embed-metadata # Do not set any \"synopsis\" in the video metadata $ yt-dlp --parse-metadata \":(?P)\" # Remove \"formats\" field from the infojson by setting it to an empty string $ yt-dlp --parse-metadata \"video::(?P)\" --write-info-json # Replace all spaces and \"_\" in title and uploader with a `-` $ yt-dlp --replace-in-metadata \"title,uploader\" \"[ _]\" \"-\" EXTRACTOR ARGUMENTS Some extractors accept additional arguments which can be passed using --extractor-args KEY:ARGS. ARGS is a ; (semicolon) separated string of ARG=VAL1,VAL2. E.g. --extractor-args \"youtube:player-client=android_embedded,web;include_live_dash\" --extractor-args \"funimation:version=uncut\" Note: In CLI, ARG can use - instead of _; e.g. youtube:player-client\" becomes youtube:player_client\" The following extractors use this feature: youtube lang: Prefer translated metadata (title, description etc) of this language code (case-sensitive). By default, the video primary language metadata is preferred, with a fallback to en translated. See youtube.py for list of supported content language codes skip: One or more of hls, dash or translated_subs to skip extraction of the m3u8 manifests, dash manifests and auto-translated subtitles respectively player_client: Clients to extract video data from. The main clients are web, android and ios with variants _music, _embedded, _embedscreen, _creator (e.g. web_embedded); and mweb and tv_embedded (agegate bypass) with no variants. By default, ios,android,web is used, but tv_embedded and creator variants are added as required for age-gated videos. Similarly, the music variants are added for music.youtube.com urls. You can use all to use all the clients, and default for the default clients. player_skip: Skip some network requests that are generally needed for robust extraction. One or more of configs (skip client configs), webpage (skip initial webpage), js (skip js player). While these options can help reduce the number of requests needed or avoid some rate-limiting, they could cause some issues. See #860 for more details player_params: YouTube player parameters to use for player requests. Will overwrite any default ones set by yt-dlp. comment_sort: top or new (default) - choose comment sorting mode (on YouTube's side) max_comments: Limit the amount of comments to gather. Comma-separated list of integers representing max-comments,max-parents,max-replies,max-replies-per-thread. Default is all,all,all,all E.g. all,all,1000,10 will get a maximum of 1000 replies total, with up to 10 replies per thread. 1000,all,100 will get a maximum of 1000 comments, with a maximum of 100 replies total formats: Change the types of formats to return. dashy (convert HTTP to DASH), duplicate (identical content but different URLs or protocol; includes dashy), incomplete (cannot be downloaded completely - live dash and post-live m3u8) innertube_host: Innertube API host to use for all API requests; e.g. studio.youtube.com, youtubei.googleapis.com. Note that cookies exported from one subdomain will not work on others innertube_key: Innertube API key to use for all API requests youtubetab (YouTube playlists, channels, feeds, etc.) skip: One or more of webpage (skip initial webpage download), authcheck (allow the download of playlists requiring authentication when no initial webpage is downloaded. This may cause unwanted behavior, see #1122 for more details) approximate_date: Extract approximate upload_date and timestamp in flat-playlist. This may cause date-based filters to be slightly off generic fragment_query: Passthrough any query in mpd/m3u8 manifest URLs to their fragments if no value is provided, or else apply the query string given as fragment_query=VALUE. Does not apply to ffmpeg variant_query: Passthrough the master m3u8 URL query to its variant playlist URLs if no value is provided, or else apply the query string given as variant_query=VALUE hls_key: An HLS AES-128 key URI or key (as hex), and optionally the IV (as hex), in the form of (URI|KEY)[,IV]; e.g. generic:hls_key=ABCDEF1234567980,0xFEDCBA0987654321. Passing any of these values will force usage of the native HLS downloader and override the corresponding values found in the m3u8 playlist is_live: Bypass live HLS detection and manually set live_status - a value of false will set not_live, any other value (or no value) will set is_live funimation language: Audio languages to extract, e.g. funimation:language=english,japanese version: The video version to extract - uncut or simulcast crunchyrollbeta (Crunchyroll) format: Which stream type(s) to extract (default: adaptive_hls). Potentially useful values include adaptive_hls, adaptive_dash, vo_adaptive_hls, vo_adaptive_dash, download_hls, download_dash, multitrack_adaptive_hls_v2 hardsub: Preference order for which hardsub versions to extract, or all (default: None = no hardsubs), e.g. crunchyrollbeta:hardsub=en-US,None vikichannel video_types: Types of videos to download - one or more of episodes, movies, clips, trailers niconico segment_duration: Segment duration in milliseconds for HLS-DMC formats. Use it at your own risk since this feature may result in your account termination. youtubewebarchive check_all: Try to check more at the cost of more requests. One or more of thumbnails, captures gamejolt comment_sort: hot (default), you (cookies needed), top, new - choose comment sorting mode (on GameJolt's side) hotstar res: resolution to ignore - one or more of sd, hd, fhd vcodec: vcodec to ignore - one or more of h264, h265, dvh265 dr: dynamic range to ignore - one or more of sdr, hdr10, dv tiktok api_hostname: Hostname to use for mobile API requests, e.g. api-h2.tiktokv.com app_version: App version to call mobile APIs with - should be set along with manifest_app_version, e.g. 20.2.1 manifest_app_version: Numeric app version to call mobile APIs with, e.g. 221 rokfinchannel tab: Which tab to download - one of new, top, videos, podcasts, streams, stacks twitter api: Select one of graphql (default), legacy or syndication as the API for tweet extraction. Has no effect if logged in stacommu, wrestleuniverse device_id: UUID value assigned by the website and used to enforce device limits for paid livestream content. Can be found in browser local storage twitch client_id: Client ID value to be sent with GraphQL requests, e.g. twitch:client_id=kimne78kx3ncx6brgo4mv6wki5h1ko nhkradirulive (NHK らじる★らじる LIVE) area: Which regional variation to extract. Valid areas are: sapporo, sendai, tokyo, nagoya, osaka, hiroshima, matsuyama, fukuoka. Defaults to tokyo Note: These options may be changed/removed in the future without concern for backward compatibility PLUGINS Note that all plugins are imported even if not invoked, and that there are no checks performed on plugin code. Use plugins at your own risk and only if you trust the code! Plugins can be of s extractor or postprocessor. Extractor plugins do not need to be enabled from the CLI and are automatically invoked when the input URL is suitable for it. Extractor plugins take priority over builtin extractors. Postprocessor plugins can be invoked using --use-postprocessor NAME. Plugins are loaded from the namespace packages yt_dlp_plugins.extractor and yt_dlp_plugins.postprocessor. In other words, the file structure on the disk looks something like: yt_dlp_plugins/ extractor/ myplugin.py postprocessor/ myplugin.py yt-dlp looks for these yt_dlp_plugins namespace folders in many locations (see be",
    "commentLink": "https://news.ycombinator.com/item?id=37474066",
    "commentBody": "YouTube-dl fork with additional features and fixesHacker NewspastloginYouTube-dl fork with additional features and fixes (github.com/yt-dlp) 169 points by bookofjoe 12 hours ago| hidepastfavorite103 comments haunter 12 hours agoThe name doesn’t do a justice, you can download from thousands of sites from all over the worldhttps:&#x2F;&#x2F;github.com&#x2F;yt-dlp&#x2F;yt-dlp&#x2F;tree&#x2F;master&#x2F;yt_dlp&#x2F;extracto... reply neurostimulant 1 hour agoparentEven when it can&#x27;t, if you can find the .m3u8 or .mpd url from the browser&#x27;s dev tool network tab, you can feed it into yt-dlp to download the video and transform it into .mp4. reply mdaniel 11 hours agoparentprevThat may have been true of \"youtube-dl\" but I think yt-dlp only evokes the site association that you&#x27;re thinking of because you already knew about youtube-dl firstAdmittedly, the fork would have been better with \"really-dl\" but here we areAlso, due to the GitHub file list truncation, you may be happier linking to the more legible(?) https:&#x2F;&#x2F;github.com&#x2F;yt-dlp&#x2F;yt-dlp&#x2F;blob&#x2F;2023.07.06&#x2F;supportedsi... reply qwerty456127 12 hours agoprevAn amazing tool adding a great deal of value to YouTube. If I could only donate to one project I would choose this. Shame on me I can&#x27;t in fact even find how do I donate to this. reply andrewia 12 hours agoparentI found the primary maintainer from the Github org. Their bio has a link to support them. https:&#x2F;&#x2F;github.com&#x2F;pukkandan which links to https:&#x2F;&#x2F;ko-fi.com&#x2F;pukkandan reply 0xcde4c3db 12 hours agoparentprevNot sure how this might (not) be presented in other contexts, but when I go to the main repository page on a desktop browser, there&#x27;s a \"Sponsor this project\" box in the rightmost layout column that links to a Markdown file with Ko-Fi and&#x2F;or GitHub Sponsor links for the individual maintainers [1].[1] https:&#x2F;&#x2F;github.com&#x2F;yt-dlp&#x2F;yt-dlp&#x2F;blob&#x2F;master&#x2F;Collaborators.m... reply mvdtnz 9 hours agoprevThis submission got catapulted off the front page within about 2 hours and no longer appears in the top 150 submission despite being fresh and having more points than 18 of the 30 items on the front page. Interesting. reply SamBam 8 hours agoparentYour comment was 20 minutes ago and this submission is at the top of HN for me. reply mvdtnz 8 hours agorootparentInteresting, it&#x27;s not for me. Is HN personalising the front page now?https:&#x2F;&#x2F;imgur.com&#x2F;a&#x2F;pLhNCqC reply dang 11 hours agoprevRelated:Yt-dlp – A YouTube-dl fork with additional features and fixes - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=28319624 - Aug 2021 (332 comments) reply TheRealPomax 12 hours agoprevBut how is this not violating the DMCA in the exact same way that the original youtube-dl was taken down over by Github? reply pseudo0 12 hours agoparentThe EFF covered this issue, it was an abuse of the DMCA.> First, youtube-dl does not infringe or encourage the infringement of any copyrighted works, and its references to copyrighted songs in its unit tests are a fair use. Nevertheless, youtube-dl’s maintainers are replacing these references. Second, youtube-dl does not violate Section 1201 of the DMCA because it does not “circumvent” any technical protection measures on YouTube videos.https:&#x2F;&#x2F;www.eff.org&#x2F;deeplinks&#x2F;2020&#x2F;11&#x2F;github-reinstates-yout... reply ls612 11 hours agorootparentThe bigger story behind this that by reinstating YouTube-dl Microsoft basically came out and said “sue us we dare you” over people peddling this legal theory and the copyright trolls blinked. reply seabass-labrax 12 hours agoparentprevThe original youtube-dl was taken down by GitHub because of the DMCA complaint, not because it violated the DMCA. It was subsequently restored by GitHub. This project is simply more actively maintained; it&#x27;s existence has nothing to do with the DMCA scandal. reply reaperman 12 hours agoparentprevyoutube-dl was generally found not to be violating DMCA because there was no relevant DRM to circumvent. It is now reinstated on github[0].It’s just poorly maintained so yt-dlp has been accepted by the community as its natural successor.0: https:&#x2F;&#x2F;github.blog&#x2F;2020-11-16-standing-up-for-developers-yo... reply TheRealPomax 12 hours agorootparentAh, that completely flew under my radar, cheers. reply NegativeK 12 hours agoparentprevYoutube-dl received a takedown request, with which Github complied with, but was later reinstated permanently.The EFF has claimed that there is no DMCA violation since there is no copyright circumvention. reply hyperhopper 12 hours agoparentprevDoes it matter if it is? reply TheRealPomax 12 hours agorootparentI can&#x27;t tell if you&#x27;re being serious, but yes of course it matters. Youtube-dl got taken down, and all its forks got taken down, so is this project different or is it gone tomorrow because its existence got broadcast on hackernews?Did it change something that made it not violate fall into the same \"this violates DMCA\" trap that youtube-dl fall into, so that it&#x27;s not susceptible to the same takedown?Because that&#x27;s interesting and worth learning about. reply rezonant 12 hours agorootparentSee elsewhere in the thread for details, but youtube-dl was restored by Github and is generally not considered to be in violation of the DMCA. You can see it on Github here: https:&#x2F;&#x2F;github.com&#x2F;ytdl-org&#x2F;youtube-dlA copyright holder abused the DMCA process to take it down the first time. reply dylan604 11 hours agoparentprevBy not including copyright content in the documentation and examples of how to use? reply tourmalinetaco 11 hours agorootparentThat’s not even a genuine problem, just an excuse the RIAA hid behind to continue being a vexatious litigant. reply dylan604 11 hours agorootparentwhile setting aside the genuineness of the problem, it was a rather poor decision on the dev&#x27;s part. there was no need to rub it in the faces. if they were so unawares of what they were doing, then it makes me wonder what other facets they were playing fast and loose with. when making a thing that you know is going to cause ripples, then it just seems much smarter to avoid handing someone else the rocks to cause the ripples. reply MallocVoidstar 12 hours agoparentprevFor one thing, youtube-dl was restored and I don&#x27;t think there&#x27;s been any further attempt to take its repo down. reply hyperhopper 12 hours agoprevAmazing tool and thankful for the project, but it&#x27;s really sad something that should just be a download button on every site, is instead a large project that has controversies, lawsuits and other issues. reply dylan604 11 hours agoparentSure, if you throw out all concerns about copyright and all of that other mumbojumbo, sure, why not just let all of the users of a website download the content with no compensation for the creators at all?I like to make fun of YT as much as anyone, but even this \"everything, all the time should be mine\" is a farcical concept to me. reply tourmalinetaco 11 hours agorootparentNice strawman. He didn’t even say any of that, simply that all websites should have options to download videos. No mentions of price, nothing that would harm copyright (which is an absolute joke).Maybe, if you weren’t an RIAA shill, we could have a productive conversation. reply dylan604 11 hours agorootparentThanks for the name calling, but thinking i&#x27;m a RIAA shill is laughable and shows the level of (lack thereof) intellect people have on this issue.Has the copyright system been corrupted by major corporate players? Of course it has. However, throwing it out to have no concept of copyright is an insult to those that do create content without being those corporate players. It takes time and effort and a not insignificant amount of money to bring content to the world. Removing any protections from those creators to be able to monetize their work product is just infantile tantrum throwing. reply stalfosknight 11 hours agorootparentprevHow dare a profit-seeking corporation want to make money! reply musicale 12 hours agoparentprevIt&#x27;s astonishing how much effort Google and other companies spend fighting their users. reply haltist 12 hours agorootparentPeerTube is decentralized video sharing software that works with a federated protocol but not enough people choose to host their content on PeerTube. The problem isn&#x27;t Google or the law on copyrighted content and who can make copies of it. The problem is people choose centralized content hosts like YouTube and all that it entails because it is more convenient than running and federating PeerTube nodes. reply Sebguer 12 hours agorootparentDoes Peertube address all of the moderation &#x2F; illegal content problems enumerated here, as they relate especially to video? https:&#x2F;&#x2F;telegra.ph&#x2F;why-not-matrix-08-07 reply Animats 11 hours agorootparentprevPeerTube is a useful form of decentralization. Each video is stored on its home site, but playout is distributed by making the browsers of people watching it share the streaming load. So if your video on your tiny PeerTube-connected site goes viral, your tiny site will not overload. All the viewers become redistribution nodes. At least in theory, this scales. The highest view count I can find on PeerTube is around 5K recent, not concurrent, views.I put technical videos on Hardlimit on PeerTube, because Google&#x27;s ads are annoying and I don&#x27;t need \"discovery\" or \"followers\". The videos are linked from discussions and papers. This works fine, but is not the usual use case, where people are seeking fame, fortune, or at least attention. reply toomuchtodo 11 hours agorootparentDo you have any recommendations for scaling out PeerTube? reply Animats 11 hours agorootparentIt&#x27;s a non-problem at the current user count. reply shalomv 11 hours agorootparentprevI remember an interesting project in 2009 from Opera called Opera Unite. Its goal was to turn the browser into a server so that you can share back out into the web. They had a few demos \"apps\" built in but sadly it never went anywhere. It&#x27;s interesting to imagine how the structure of the web would have evolved if that idea took off. Here&#x27;s their original post about it: https:&#x2F;&#x2F;dev.opera.com&#x2F;blog&#x2F;taking-the-web-into-our-own-hands... reply haltist 11 hours agorootparentI remember this. It was a very good idea. reply d0gbread 12 hours agorootparentprevYou have your facts correct and your conclusion backwards. reply haltist 11 hours agorootparentGreat feedback. reply izacus 11 hours agorootparentprevGoogle is offering download feature for paying users with a click.Asking you to pay them for the service and the creators that created the video isn&#x27;t really fighting you is it?It&#x27;s only \"fighting\" freeloaders. reply hollerith 11 hours agorootparentBy \"download feature\", do you mean download into private storage of the Youtube app of a smart phone (so that the video can be viewed when the phone is not connected) or do you mean download a video file that can be played in the player of the user&#x27;s choice?(I&#x27;m asking because I&#x27;ve never been a paying user of Youtube.) reply xp84 11 hours agorootparentThis is fair, and yes it&#x27;s 100% \"download into an encrypted area on a closed platform device and self-destruct for no reason after 30 days,\" not \"download it so that you have the video and can reliably play it offline or re-encode into a different format.\"YouTube itself is the lamest entity to be wasting time fighting youtube-dl because I doubt most creators want that protection. I can see why say, NBC.com or whoever doesn&#x27;t want to be sued by the content owners for letting people download a show. But YouTube? The site that shows videos to anyone without a subscription? Interesting choice of where to focus your attention, Google. reply svieira 11 hours agorootparentprevThe former reply Obscurity4340 11 hours agorootparentprevThe bigger problem is the way they use that as an avenue to sell you more shit and \"learn\" more deeply about you. Hard pass. Let people watch what they want and stop trying to build a profile, maybe then they&#x27;ll consider paying you. As it stands, there&#x27;s just no prayer of doing that if you&#x27;re linking your credit card to all that. reply musicale 11 hours agorootparentprevMore like a \"download into Google video locker that can only be played with the Youtube app, can&#x27;t easily be format-shifted&#x2F;clipped&#x2F;transcoded&#x2F;etc. and tracks you whenever you play it,\" right?So much effort that downgrades the experience for paying users.I imagine Tivo-style ad-skipping isn&#x27;t a feature either. reply yjk 11 hours agorootparentprevThough I never have used Youtube premium, Louis Rossmann talks a lot about this. If I remember correctly it was something about not actually getting a file when downloading, instead having something you&#x27;re forced to watch in the app and something not working right without internet access&#x2F;location restrictions. reply brunoqc 11 hours agorootparentprevThey also charge for picture-in-picture mode on your $1k phone that you bought from them. reply kam 11 hours agorootparentprevAnd archivists. And people who prefer a different video player app or unsupported device. reply giantrobot 11 hours agorootparentprevThey already sent me the fucking content when I watch it. Having a download button that just saves it to my disk means they save money delivering it to me if I watch a second time. reply godzillabrennus 11 hours agorootparentprevLet us not forget that the viewers are the product. The “users” are somewhat comprised of the people buying premium and mostly comprised of the advertisers buying ads for eyeballs to see.Google doesn’t make money from ads if you download a video outside of their player.I pay for YouTube premium and can download a video to my phone in the app. It’s not perfect but it works. reply Obscurity4340 11 hours agorootparentI am glad for all the paying people who care less about their privacy to the extent they can justify that. You matter, seriously. I&#x27;m being 100% genuine. I don&#x27;t think the world (economically) would continue to turn if everyone was like me unfortunately. It would be a tradgedy of the uncommons reply rjzzleep 11 hours agoparentprevAs someone else has stated is supports a lot of different sites, not just streaming, but also just video upload and sharing sites.I once spent some weeks maintaining a handful of extractors just for myself and this is definitely much better. reply tasty_freeze 11 hours agoparentprevIf you pay for a youtube subscription, there is a download button right next to the share button. reply user_7832 11 hours agorootparentCorrect me if I&#x27;m wrong, but isn&#x27;t that forcing you to use their system when offline and not truly giving you a copy of the mp4 file? reply shric 11 hours agorootparentCorrect, and I believe you can&#x27;t even access the video if you the app can&#x27;t phone home after a certain time.Also if you&#x27;re in (or even visiting) some (most?) countries this feature doesn&#x27;t work. You don&#x27;t get any refund either. reply mvdtnz 12 hours agoparentprevWhy do you think something \"should\" be a download button on every site? Who are you to tell someone who has created something that they must give it away? How much work do you do for free? reply musicale 12 hours agorootparentWhen exactly did we decide that digital video shouldn&#x27;t be easily recordable like analog video?In any case, a download button is basically like a DVR. It is also an obvious feature that- is easy to add- is logically part of any video hosting site- is wanted by most usersDVRs may be legal according to the law, but youtube and other sites spend an extraordinary amount of effort to make it hard for users to record the videos they are watching. It&#x27;s basically a technologically enforced ban on video recording for the 99% of users who can&#x27;t easily use youtube-dl or other tools. reply dylan604 11 hours agorootparentUsing a DVR&#x2F;VCR recorded the broadcast as is. You&#x27;re download idea bypasses all of the ads. Unless, without stating so, you&#x27;d accept a download file with the ads embedded.While YT might originally have started with the Yous of the world creating content, it has greatly evolved from that where very professional types are releasing to it. Of course YT loves that as it means much more interest from users to their site. However, you know that concessions had to be made to convince music labels to release their content on the platform. We all know what those mean. reply musicale 11 hours agorootparent> Using a DVR&#x2F;VCR recorded the broadcast as is. You&#x27;re download idea bypasses all of the ads. Unless, without stating so, you&#x27;d accept a download file with the ads embedded.That&#x27;s what automatic SkipMode is for!https:&#x2F;&#x2F;explore.tivo.com&#x2F;how-to&#x2F;SkipModeUnfortunately:\"Note: The SkipMode feature is available only on certain recorded shows; we hope to make it available for the most popular shows on the most popular channels watched by TiVo subscribers\"A limitation that 0.000% of viewers wanted. reply dylan604 11 hours agorootparentcurious if they were working with broadcasters to embed cuetones that the unit would scan to locate which is why it took a bit of time \"after recording\" for the skip icon to work. if that&#x27;s the case, then it&#x27;s obvious why it didn&#x27;t catch on. (i say didn&#x27;t because i have no idea if Tivo is still a thing or how old the page linked is.) reply harshitaneja 11 hours agorootparentprevI just tried recording youtube using the os provided screen recorder on ios and mac and was able to do so. reply musicale 10 hours agorootparentHow did you record the audio?Previously I&#x27;d tried to record video and never succeeded, but it (currently) works full-screen on youtube!Edit: Apparently the audio is just a limitation of QuickTime Player. So... Mac DVRs should work with youtube and possibly some other sites? reply mvdtnz 12 hours agorootparentprevWhere are DVRs banned?Edit - the parent wildly edited their comment so mine no longer makes sense. reply jcotton42 12 hours agorootparentGP&#x27;s point, aiui, is that using a DVR&#x2F;VCR isn&#x27;t really that different in concept from downloading a video off YouTube. reply JadeNB 11 hours agorootparentprev> When exactly did we decide that digital video shouldn&#x27;t be easily recordable like analog video?> In any case, a download button is basically like a DVR.> DVRs may be legal according to the law …The recordability of analog video (in the sense of whether it&#x27;s OK to do so, not whether it is physically possible—although there was that useless tab on videocassettes), and the acceptability of using a DVR, have not always been settled subjects. To the extent that such things can be quantified, I&#x27;d suspect that the amount of conflict over them was roughly comparable if you account for (1) the increased number of people in a position to have an informed opinion and (2) the increased visibility of conflict. reply musicale 11 hours agorootparent> The recordability of analog video (in the sense of whether it&#x27;s OK to do so, not whether it is physically possible—although there was that useless tab on videocassettes), and the acceptability of using a DVR, have not always been settled subjectsAnalog seems pretty well settled in the US for the past ~40 years.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Sony_Corp._of_America_v._Unive....But my point is actually a bit different. Weren&#x27;t VCRs a good thing? Isn&#x27;t it a bad thing that it is so much harder now to record internet TV than it was to record broadcast and cable TV in the 1980s-2000s? reply JadeNB 8 hours agorootparent> Analog seems pretty well settled in the US for the past ~40 years.Yes, but not always. There was a time when it was a new thing, and, when so, it was much argued.> But my point is actually a bit different. Weren&#x27;t VCRs a good thing? Isn&#x27;t it a bad thing that it is so much harder now to record internet TV than it was to record broadcast and cable TV in the 1980s-2000s?Yes, they were! Yes, it is! But my point wasn&#x27;t to disagree with you on either of these points, just to observe that it&#x27;s not that the content owners who went along with previous innovations are suddenly balking at this. Rather, my invocation of even long settled questions like analog recording was meant to point to the fact that content owners have always argued against use of their material that they didn&#x27;t like, which was any use of their material that they didn&#x27;t completely control and directly profit from. reply zeta0134 12 hours agorootparentprevThey&#x27;ve already given it away for free by uploading it to YouTube. That I choose to consume the content outside of the free web player is not their business at that point.Most frequently I do this because I am analyzing the audio, and it&#x27;s hard to reliably seek in the web player; my offline tools are much better at this task. reply mvdtnz 12 hours agorootparentMany people who upload videos to Youtube are getting paid based on the number of people who view the video. They also may choose platforms like Youtube in order to maintain some control over the distribution of their videos. reply specialist 8 hours agorootparentDoes youtube distinguish between downloading while watching and downloading for watching later? reply rngname22 11 hours agorootparentprevVideos uploaded to YouTube that have ads enabled are explicitly not given away for free. reply lhamil64 11 hours agorootparentprevHow is downloading a video \"giving it away\"? You&#x27;re already consuming the content.I guess the one angle I can see is that by watching the local copy, you aren&#x27;t seeing any ads that might be on the page&#x2F;video. But the website could embed ads into the downloaded video.Really, how is this any different than recording TV on a VCR (or DVR)? reply mvdtnz 11 hours agorootparent> Really, how is this any different than recording TV on a VCR (or DVR)?Each time a viewer watches a video a monetised channel makes a little more money. This money either comes from ads or Youtube Premium fees (Premium viewers are worth significantly more than free viewers).Programs like yl-dlp bypass this - non-premium users can download ad-free videos contributing a single view to a video and consume that content any number of times. Youtube no longer makes advertising revenue per view, and content creators no long get their cut.None of this is the case in TV, where ad revenue must be based on metrics other than straight-up view count, which cannot be counted meaningfully.> But the website could embed ads into the downloaded video.Many video creators do embed their own ads, but revenue from these ads are often based on view counts maintained by Youtube as well. reply giantrobot 11 hours agorootparent> Programs like yl-dlp bypass this - non-premium users can download ad-free videos contributing a single view to a video and consume that content any number of times. Youtube no longer makes advertising revenue per view, and content creators no long get their cut.Why should they get a cut every time I view a video? If I watch a video saved to disk I use 0% of YouTube&#x27;s infrastructure and cost the creator 0% in extra expenses.Do I owe them a cut if I remember part of a video? Do I owe them a double amount of ad watching if I watch the video with someone else? Do they owe me a cut if they repeated a detail from a Wikipedia article I edited or web page I wrote? What about their college history professor that taught them a historical fact, do they need to go back and pay them when they reference it in their video?For any bit of created media there are hundreds of uncredited and uncompensated second order contributions. The idea that someone making a YouTube video should get compensated every time I watch it is absolutely absurd. They&#x27;re certainly not tracking down every second order contribution to the video and compensating them in turn. reply mvdtnz 10 hours agorootparentWell, why shouldn&#x27;t they get a cut? If I pirate a video game or music CD it also costs the artists $0 when I use it. But if I wasn&#x27;t getting value out of it I wouldn&#x27;t have bothered to pirate it. Why should you get that value for nothing? reply giantrobot 4 hours agorootparentYou&#x27;re approaching the concept from the position that there&#x27;s some moral imperative that a media creator needs to be paid in perpetuity for every experiential instance of their work.If you buy a CD you pay for it one time. The artist doesn&#x27;t get a nickel every time you play a track. You could put it on repeat for 50 years and they&#x27;ll never get more than your up front payment. The only entity being paid is your power company for running that CD player for 50 years. If you powered the CD player with a solar panel and battery would you feel the utility company needs to be paid for your use of electricity despite not using any of their infrastructure?You don&#x27;t send a plumber a check every time you flush your toilet. If I watch a YouTube video once it&#x27;s simply ludicrous to suggest I need to pay for a second viewing if I&#x27;m not using anyone&#x27;s infrastructure but my own. reply musicale 11 hours agorootparentprev> Really, how is this any different than recording TV on a VCR (or DVR)?It really isn&#x27;t. Except that we don&#x27;t have easy-to-use DVRs for internet TV the way we used to have easy-to-use VCRs&#x2F;DVRs for broadcast and cable TV. reply sufficer 12 hours agorootparentprevI&#x27;d like to be able to download YouTube videos easily. Maybe it&#x27;s a feature uploaders can toggle on and off per video reply mvdtnz 12 hours agorootparentIf you pay for Youtube Premium you can download any video to your device for offline viewing. I&#x27;m not sure if this is configurable by the video uploader. The video can still only be viewed from within the Youtube app so it&#x27;s not like a general-purpose mp4. I suspect this is in part so that Youtube can continue to monitor how many times you watched a video so they can correctly compensate the uploader (and, obviously, to maintain control over their library). reply judge2020 12 hours agorootparentprevHow does YouTube operate the service with this feature? If enough people use it to download all the videos they want and then play them back without ads, then they&#x27;re just hosting and delivering video for free. It&#x27;s no secret that YouTube is already subsidized by ad-supported views and premium subscribers.And YouTube Premium already offers a Download button. It downloads it in the exact same format as they send it to your device in - m3u8 parts. reply zzo38computer 9 hours agorootparentprevThey don&#x27;t have to give it away, but if they publish it so that someone can view it, then others who can view it should also make their own copy to do what they want with, e.g. adjust volume, make a recorded copy to work without internet connection, convert file formats, downgrade resolution (if you want to save disk space), time shifting, deleting ads, etc. It isn&#x27;t the problem that the site doesn&#x27;t have a download; it is that the computer should have a record button but doesn&#x27;t. reply kcb 11 hours agorootparentprevIf you don&#x27;t want to give away your video, news article, blog post etc. Then don&#x27;t post it publicly on the Internet. reply jmondi 11 hours agoprevyt-dlp has been awesome, but one thing I [admittedly havent tried to solve and] don&#x27;t like about it is that it seems to default to unusual container types when downloading.When using yt-dlp, I get a .webm file, and when asking for audio only using `-x`, I get an .opus file. Is there any reason for this? reply ericol 11 hours agoparentThat is because by default yt-dlp tries to download the best &#x2F; better format available and (I take it the context of your downloads are YT) these are the best ones available.You can customize which format to download by doing first:yt-dlp -F Check what numbers are there, and then download the formats you want.You can customize both the video format & rate, and same for sound, by usingyt-dlp #+# Where the first hash is the id of the video stream, and the 2nd hash is the id of the audio id.Take into account that you&#x27;d probably need also ffmpeg available on the command line for this; that if you \"mix\" containers (Say, a webm video and an m4u audio stream) you-ll end up with an .mkv container; and finally, that all of the downloaded streams are themselves containers (.m4u, mp4 & webm). reply thaumasiotes 11 hours agorootparent> Take into account that [...] if you \"mix\" containers [...] you&#x27;ll end up with an .mkv containerHe&#x27;s complaining about getting an .mkv in the first place, so this seems unlikely to solve his problem. reply ericol 11 hours agorootparentHe can solve it if he tells yt-dlp to download a mix of .mp4 and .m4u reply mdaniel 11 hours agoparentprevto the best of my knowledge, that&#x27;s because your system does not have ffmpeg for subsequent transcoding of the site&#x27;s format into what you would consider \"your\" format: https:&#x2F;&#x2F;github.com&#x2F;yt-dlp&#x2F;yt-dlp&#x2F;blob&#x2F;2023.07.06&#x2F;README.md#s... (they also allow you to specify the path, if you don&#x27;t have it in your $PATH, via --ffmpeg-location ) reply thaumasiotes 11 hours agoparentprevA .webm file is an .mkv file. You can rename to .mkv without any ramifications.My guess would be that yt-dlp is giving you whatever file format it finds, with no editorializing. The default is just to go with \"best quality\" available. So \"Is there a reason for this?\" is likely a better question for whoever maintains the site(s) you&#x27;re downloading from. reply dylan604 11 hours agoparentprevi can imagine it&#x27;s a bit of grandstanding for open formats vs the encumbered formats that are more popular. reply hnarn 11 hours agorootparentNo. It’s simply going for the highest quality available. reply dylan604 11 hours agorootparenti&#x27;ll accept that. so the grandstanding is with Googs&#x2F;YT in only providing the higher quality in those formats. there&#x27;s no compelling reason other than pushing the other formats and trying to throw shade on the others. they are already using h.264, so just up the quality and not force a totally different codec. reply mikae1 12 hours agoprevThis project deserves attention, but I&#x27;m not sure it needs attention. No upvote this time. reply musicale 11 hours agoparentI understand the reasoning here. Right now youtube-dl is in the noise since 99% of people don&#x27;t use it (and probably can&#x27;t use it easily.) reply _ache_ 11 hours agoprevI found it much easier to contribute too yt-dlp than to youtube-dl. youtube-dl repository is badly managed, the fork could have been easily avoided by sharing responsibilities and decisions. reply WirelessGigabit 11 hours agoprevObligatory reference to https:&#x2F;&#x2F;github.com&#x2F;alexta69&#x2F;metube which allows you to front yt-dlp with a webpage.Already posted here how I have it as part of my stack: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37113339 reply throw74848 12 hours agoprev [9 more] [flagged] musicale 11 hours agoparent> Anyone who uses this tool is violating contract with GoogleA click-through EULA seems a bit different from a contract. reply skybrian 11 hours agorootparentDoes it matter? They could still suspend you. Good luck fighting that. reply tourmalinetaco 11 hours agorootparentGood luck getting suspended in the first place, that’d be quite the feat. reply jonathankoren 11 hours agorootparentprevThey&#x27;re not different at all.https:&#x2F;&#x2F;www.eff.org&#x2F;wp&#x2F;dangerous-terms-users-guide-eulas#:~:.... reply vanjajaja1 11 hours agoparentprevoof. suspended google account sounds very painfuldoes the same ruling apply when using something like Kapwing, which downloads the youtube video (probably using this tool)? That could be very painfuledit: this just makes me realise I should transition my stuff to somewhere safer reply sedatk 11 hours agoparentprevHow do they ever associate your Youtube account with this tool? reply tourmalinetaco 11 hours agorootparentCookies, maybe? Which would be indistinguishable from a normal usage considering its making the same API calls. Better safe than sorry for important accounts, but if they could catch you en masse for YT-DLP use they would have already. reply stalfosknight 11 hours agoparentprev [–] Good thing I don&#x27;t have a Google account in the first place. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "yt-dlp, a fork of youtube-dl, introduces new capabilities while maintaining alignment with the original project, supporting age-gated content, livestream downloads, and subtitle extraction.",
      "It offers multiple paths, portable configuration, and self-updating capabilities with detailed information about installation, dependencies, file management, and post-processing tasks.",
      "The guide includes examples for diverse use cases with options for customisation, network settings, authentication and format selection, and mentions extraction and post-processing plugins with a note on potential risks."
    ],
    "commentSummary": [
      "The article explores the debate surrounding a fork of YouTube-dl, called yt-dlp, that allows users to download videos from various internet platforms amid the DMCA (Digital Millennium Copyright Act) controversy.",
      "The conversation also puts a spotlight on the limitations of centralized video hosting platforms like YouTube and the advantages of decentralized platforms like PeerTube.",
      "A significant part of the discussion is about the impact these downloading tools have on content creators’ revenue, with divergent opinions on viewers' rights versus potential losses due to piracy and ad-blocking software."
    ],
    "points": 169,
    "commentCount": 103,
    "retryCount": 0,
    "time": 1694468248
  },
  {
    "id": 37467585,
    "title": "Nvidia’s AI supremacy is only temporary",
    "originLink": "https://petewarden.com/2023/09/10/why-nvidias-ai-supremacy-is-only-temporary/",
    "originBody": "Search Pete Warden's blog Ever tried. Ever failed. No matter. Try Again. Fail again. Fail better. Skip to content HOME ABOUT Why Nvidia’s AI Supremacy is Only Temporary September 10, 2023 By Pete Warden in Uncategorized 11 Comments Nvidia is an amazing company that has executed a contrarian vision for decades, and has rightly become one of the most valuable corporations on the planet thanks to its central role in the AI revolution. I want to explain why I believe it’s top spot in machine learning is far from secure over the next few years. To do that, I’m going to talk about some of the drivers behind Nvidia’s current dominance, and then how they will change in the future. Currently Here’s why I think Nvidia is winning so hard right now. #1 – Almost Nobody is Running Large ML Apps Outside of a few large tech companies, very few corporations have advanced to actually running large scale AI models in production. They’re still figuring out how to get started with these new capabilities, so the main costs are around dataset collection, hardware for training, and salaries for model authors. This means that machine learning is focused on training, not inference. #2 – All Nvidia Alternatives Suck If you’re a developer creating or using ML models, using an Nvidia GPU is a lot easier and less time consuming than an AMD OpenCL card, Google TPU, a Cerebras system, or any other hardware. The software stack is much more mature, there are many more examples, documentation, and other resources, finding engineers experienced with Nvidia is much easier, and integration with all of the major frameworks is better. There is no realistic way for a competitor to beat the platform effect Nvidia has built. It makes sense for the current market to be winner-takes-all, and they’re the winner, full stop. #3 – Researchers have the Purchasing Power It’s incredibly hard to hire ML researchers, anyone with experience has their pick of job offers right now. That means they need to be kept happy, and one of the things they demand is use of the Nvidia platform. It’s what they know, they’re productive with it, picking up an alternative would take time and not result in skills the job market values, whereas working on models with the tools they’re comfortable with does. Because researchers are so expensive to hire and retain, their preferences are given a very high priority when purchasing hardware. #4 – Training Latency Rules As a rule of thumb models need to be trainable from scratch in about a week. I’ve seen this hold true since the early days of AlexNet, because if the iteration cycle gets any longer it’s very hard to do the empirical testing and prototyping that’s still essential to reach your accuracy goals. As hardware gets faster, people build bigger models up until the point that the training once again takes roughly the same amount of time, and reap the benefits through higher-quality models rather than reduced total training time. This makes buying the latest Nvidia GPUs very attractive, since your existing code will mostly just work, but faster. In theory there’s an opportunity here for competitors to win with lower latency, but the inevitably poor state of their software stack (CUDA has had decades of investment) means it’s mostly an illusion. What’s going to change? So, hopefully I’ve made a convincing case that there are strong structural reasons behind Nvidia’s success. Here’s how I see those conditions changing over the next few years. #1 – Inference will Dominate, not Training Somebody years ago told me “Training costs scale with the number of researchers, inference costs scale with the number of users”. What I took away from this is that there’s some point in the future where the amount of compute any company is using for running models on user requests will exceed the cycles they’re spending on training. Even if the cost of a single training run is massive and running inference is cheap, there are so many potential users in the world with so many different applications that the accumulated total of those inferences will exceed the training total. There are only ever going to be so many researchers. What this means for hardware is that priorities will shift towards reducing inference costs. A lot of ML researchers see inference as a subset of training, but this is wrong in some fundamental ways. It’s often very hard to assemble a sizable batch of inputs during inference, because that process trades off latency against throughput, and latency is almost always key in user-facing applications. Small or single-input batches change the workload dramatically, and call for very different optimization approaches. There are also a lot of things (like the weights) that remain constant during inference, and so can benefit from pre-processing techniques like weight compression or constant folding. #2 – CPUs are Competitive for Inference I didn’t even list CPUs in the Nvidia alternatives above because they’re still laughably slow for training. The main desktop CPUs (x86, Arm, and maybe RISC-V soon) have the benefit of many decades of toolchain investment. They have an even more mature set of development tools and community than Nvidia. They can also be much cheaper per arithmetic op than any GPU. Old-timers will remember the early days of the internet when most of the cost of setting up a dot-com was millions of dollars for a bunch of high-end web server hardware from someone like Sun. This was because they were the only realistic platform that could serve web pages reliably and with low-latency. They had the fastest hardware money could buy, and that was important when entire sites needed to fit on a single machine. Sun’s market share was rapidly eaten by the introduction of software that could distribute the work across a large number of individually much less capable machines, commodity x86 boxes that were far cheaper. Training is currently very hard to distribute in a similar way. The workloads make it possible to split work across a few GPUs that are tightly interconnected, but the pattern of continuous updates makes reducing latency by sharding across low-end CPUs unrealistic. This is not true for inference though. The model weights are fixed and can easily be duplicated across a lot of machines at initialization time, so no communication is needed. This makes an army of commodity PCs very appealing for applications relying on ML inference. #3 – Deployment Engineers gain Power As inference costs begin to dominate training, there will be a lot of pressure to reduce those costs. Researchers will no longer be the highest priority, so their preferences will carry less weight. They will be asked to do things that are less personally exciting in order to streamline production. There are also going to be a lot more people capable of training models coming into the workforce over the next few years, as the skills involved become more widely understood. This all means researchers’ corporate power will shrink and the needs of the deployment team will be given higher priority. #4 – Application Costs Rule When inference dominates the overall AI budget, the hardware and workload requirements are very different. Researchers value the ability to quickly experiment, so they need flexibility to prototype new ideas. Applications usually change their models comparatively infrequently, and may use the same fundamental architecture for years, once the researchers have come up with something that meets their needs. We may almost be heading towards a world where model authors use a specialized tool, like Matlab is for mathematical algorithms, and then hand over the results to deployment engineers who will manually convert the results into something more efficient for an application. This will make sense because any cost savings will be multiplied over a long period of time if the model architecture remains constant (even if the weights change). What does this Mean for the Future? If you believe my four predictions above, then it’s hard to escape the conclusion that Nvidia’s share of the overall AI market is going to drop. That market is going to grow massively so I wouldn’t be surprised if they continue to grow in absolute unit numbers, but I can’t see how their current margins will be sustainable. I expect the winners of this shift will be traditional CPU platforms like x86 and Arm. Inference will need to be tightly integrated into traditional business logic to run end user applications, so it’s difficult to see how even hardware specialized for inference can live across a bus, with the latency involved. Instead I expect CPUs to gain much more tightly integrated machine learning support, first as co-processors and eventually as specialized instructions, like the evolution of floating point support. On a personal level, these beliefs drive my own research and startup focus. The impact of improving inference is going to be so high over the next few years, and it still feels neglected compared to training. There are signs that this is changing though. Communities like r/LocalLlama are mostly focused on improving inference, the success of GGML shows how much of an appetite there is for inference-focused frameworks, and the spread of a few general-purpose models increases the payoff of inference optimizations. One reason I’m so obsessed with the edge is that it’s the closest environment to the army of commodity PCs that I think will run most cloud AI in the future. Even back in 2013 I originally wrote the Jetpac SDK to accelerate computer vision on a cluster of 100 m1.small AWS servers, since that was cheaper and faster than a GPU instance for running inference across millions of images. It was only afterwards that I realized what a good fit it was for mobile devices. I’d love to hear your thoughts on whether inference is going to be as important as I’m predicting! Let me know in the comments if you think I’m onto something, or if I should be stocking up on Nvidia stock. Share this: TwitterFacebook Loading... Related How to run the Caffe deep learning vision library on Nvidia’s Jetson mobile GPU board October 25, 2014 Liked by 3 people My in-house GPU-processing server February 15, 2014 With 2 comments Five short links February 6, 2014 Post navigation « Accelerating AI with the Raspberry Pi Pico’s dual cores 11 responses Pingback: Por que a supremacia da AI da Nvidia é apenas temporária – linux-BR.org Iyanu says: September 10, 2023 at 11:07 am Your prediction is logical and it makes sense. Businesses focus on growing revenue and reducing costs. More users means more need for inference. Inference is cheaper on CPU than GPU. There will be more research on reducing the cost of inference. REPLY Ted says: September 10, 2023 at 1:23 pm Nvidia’s share dropped from its peak in the heyday of graphics. Nvidia’s share dropped from the peak in the frenzy of crypto. Nvidia’s share will drop from the pinnacle of market cap in implementing NNs. The real question, given this astounding string of successes is what will be the next act? REPLY Radu M. says: September 10, 2023 at 3:48 pm Good points Peter (and I hope you’re right…). However, I’d add the low power aspect to your vision, in addition to latency and throughput you already mentioned, particularly for anything edgeAI. REPLY Zhiqiang Xie says: September 10, 2023 at 7:48 pm Hi Pete, I believe that only the larger language models can provide the performance most people are looking for. Consequently, I think the majority will be offered through cloud services, integrated much like micro-services. While I can see Nvidia’s share possibly decreasing, I’m not convinced about CPUs taking a leading role in this space. I look forward to discussing this further when the new quarter begins at Stanford! REPLY Danil Zherebtsov says: September 11, 2023 at 2:29 pm Interesting thoughts. What do you think about the TinyML domain perspective, specifically in the scope of really small models working with sensor data on the edge? These models by default are meant to operate on tiny MCUs outside of the cloud environment. Could more sophisticated and (currently) heavy models for image/audio/video processing shift to the edge in some foreseeable future? REPLY Jaffa Krishna says: September 11, 2023 at 3:26 pm CPUs are not competitive for large model inference which seems to be the primary driver for revenue and profits for Nvidia. The problem with large model inference is that it’s memory bound it requires a hardware architecture that optimizes for memory transfer and compute the results in parallel much like the GPU. The way CPUs are designed today are optimized for workloads that are compute bound rather than memory bound. While CPUs have mature tool chains for single threaded applications & multi threaded applications, but their tool chains are no way close to the maturity of CUDA for massively parallel memory applications like large model inference. That said CPUs are somewhat competitive for the smaller computer vision models but their contribution to the revenue for Nvidia is quite small. REPLY Karl Freund says: September 11, 2023 at 4:09 pm Based on today’s MLPerf inference results, I think CPUs have a very long way to go to be able to provide the needed latencies. While inference MUST exceed training as AI evolves, even the HBM-equipped Xeon showed very poorly. Im sure Intel engineers will work hard to improve the software, but the interconnect to access adequate HBM memory for large models must be replaced. https://www.forbes.com/sites/karlfreund/2023/09/11/intel-gaudi2-looked-to-be-a-credible-alternative-to-nvidia-until/ REPLY Pingback: Nvidia’s AI supremacy is only temporary by sebg - HackTech Alex Tolley says: September 11, 2023 at 7:54 pm “I expect the winners of this shift will be traditional CPU platforms like x86 and Arm. Inference will need to be tightly integrated into traditional business logic to run end user applications, so it’s difficult to see how even hardware specialized for inference can live across a bus, with the latency involved. Instead I expect CPUs to gain much more tightly integrated machine learning support, first as co-processors and eventually as specialized instructions, like the evolution of floating point support.” Wouldn’t there likely be neuromorphic chips at the edge too to handle the inference, rather than just traditional CPU architectures, or is that unnecessary based on your work? REPLY matanyal says: September 11, 2023 at 8:37 pm I like your analysis of the current situation, but I suggest you take a look at the kind of work that Groq is doing. I think there is absolutely a future for dedicated hardware, especially in a latency sensitive world. REPLY Leave a Reply FOLLOW @PETEWARDEN ON TWITTER RSS - Posts RECENT POSTS Why Nvidia’s AI Supremacy is Only Temporary Accelerating AI with the Raspberry Pi Pico’s dual cores Explore the dark side of Silicon Valley with Red Team Blues How can AI help everyday life? What happens when the real Young Lady’s Illustrated Primer lands in China? RECENT COMMENTSmatanyal on Why Nvidia’s AI Supremac…Alex Tolley on Why Nvidia’s AI Supremac…Nvidia’s AI supremac… on Why Nvidia’s AI Supremac…Karl Freund on Why Nvidia’s AI Supremac…Jaffa Krishna on Why Nvidia’s AI Supremac… ARCHIVES September 2023 July 2023 May 2023 March 2023 January 2023 December 2022 November 2022 October 2022 September 2022 June 2022 May 2022 April 2022 February 2022 January 2022 December 2021 August 2021 April 2021 February 2021 November 2020 August 2020 May 2020 February 2020 January 2020 August 2019 July 2019 April 2019 March 2019 October 2018 July 2018 June 2018 May 2018 April 2018 March 2018 February 2018 January 2018 December 2017 November 2017 October 2017 August 2017 July 2017 June 2017 May 2017 April 2017 January 2017 December 2016 September 2016 May 2016 April 2016 March 2016 February 2016 November 2015 October 2015 September 2015 August 2015 May 2015 April 2015 March 2015 January 2015 December 2014 November 2014 October 2014 September 2014 August 2014 July 2014 June 2014 May 2014 April 2014 March 2014 February 2014 January 2014 December 2013 November 2013 October 2013 September 2013 August 2013 July 2013 June 2013 May 2013 April 2013 March 2013 February 2013 January 2013 November 2012 October 2012 August 2012 July 2012 June 2012 May 2012 April 2012 March 2012 February 2012 January 2012 December 2011 November 2011 October 2011 September 2011 August 2011 July 2011 June 2011 May 2011 April 2011 March 2011 February 2011 January 2011 December 2010 November 2010 October 2010 September 2010 August 2010 July 2010 June 2010 May 2010 April 2010 March 2010 February 2010 January 2010 December 2009 November 2009 October 2009 September 2009 August 2009 July 2009 June 2009 May 2009 April 2009 March 2009 February 2009 January 2009 December 2008 November 2008 October 2008 September 2008 August 2008 July 2008 June 2008 May 2008 April 2008 March 2008 February 2008 January 2008 December 2007 November 2007 October 2007 September 2007 August 2007 July 2007 June 2007 May 2007 April 2007 March 2007 December 2006 November 2006 October 2006 September 2006 August 2006 PETE WARDEN'S BLOG Footer menu HOMEABOUT Blog at WordPress.com. ↑ Follow",
    "commentLink": "https://news.ycombinator.com/item?id=37467585",
    "commentBody": "Nvidia’s AI supremacy is only temporaryHacker NewspastloginNvidia’s AI supremacy is only temporary (petewarden.com) 165 points by sebg 20 hours ago| hidepastfavorite161 comments runako 19 hours agoIf anything, this post suggests Nvidia has a long supremacy ahead. In particular, the author lays out what is likely to be a durable network in favor of Nvidia:- best in breed software- industry standard used and preferred by most practitioners- better (faster) hardwareNotably, this is a similar combination to that which led Wintel to be a durable duopoly for decades, with the only likely end the mass migration to other modes of compute.Regarding the \"what will change\" category, 2 of the bullet points essentially argue that the personnel he cites as being part of the lock-in will decide to no longer bias for Nvidia, primarily for cost reasons. A third point similarly leans on cost reasons.Nowhere in the analysis does the author account for the historical fact that typically the market leader is best positioned to also be the low-cost leader if strategically desired. It is unlikely that a public company like Intel or AMD or (soon) Arm would enter the market explicitly to race to zero margins. (See also: the smartphone market.)Nvidia also could follow the old Intel strategy and sell its high-end tech for training and its older (previously) high-end tech for inference, allowing customers to use a unified stack across training & inference at different price points. Training customers pay for R&D & profit margin; lower-price inference customers provide a strategic moat. reply visarga 18 hours agoparentRooting for Groq. They got an AI chip that can achieve 240 tokens per second for Llama-2 70B. They built a compiler that supports pytorch and have an architecture that scales using synchronous operations. They use software defined memory access - no hardware caching L1, L2,.. and same for networking, it runs directly from the Groq chip in synchronous mode having its activity planned by the compiler. Really a fresh take.https:&#x2F;&#x2F;youtu.be&#x2F;A3qbcwasEUY?t=571 reply pradn 17 hours agorootparentTensor libraries are high-level, so anything below them can be hyper-optimized. This includes the application model (do we still need processes for ML-serving&#x2F;training tasks?), operating system (how can Linux be improved or bypassed?), and hardware (general purpose computing comes with a ton of cruft - instruction de-coding, caches&#x2F;cache coherency, compute&#x2F;memory separation, compute&#x2F;GPU separation, virtual memory - how many of these thins can be elided, with extra transistors put to better use?). There&#x27;s so much money in generative AI that we&#x27;re going to see a bunch of well-funded startups doing this work. It&#x27;s very exciting to be back at the \"Cambrian explosion\" of the early mainframe&#x2F;PC era. reply EvgeniyZh 6 hours agorootparentprev240 tokens for 70b requires 16.8 * (bytes per parameter) TB memory bandwidth. So unless it&#x27;s like 4 bit quantized, it doesn&#x27;t sound plausible?In the same spirit, llms are memory-bound, so what possible hardware advantage can chip firm have? Buying faster memory? reply mathisfun123 6 hours agorootparentprevGroq is out of runway and will probably shutter soon. reply screye 16 hours agoparentprevThe current P&#x2F;E ratio puts Nvidia at 10x that of AMD and Intel. Nvidia is currently charging extortionate prices to all of the big FANG companies.At that point, I think it is more likely that the FANGs pour money into a competitor than continuing to pay arm and a leg for eternity.The thing about enterprise-hardware is that no one has brand loyalty. Nvidia also has a single point of failure. Nvidia is what Google would be if it was \"just a search company\".Nvidia will continue existing as one of the behemoths of the tech industry. But, if Nvidia continues to &#x27;only&#x27; sell GPUS, then will its stock continue growing with growth expectations sitting at about 3x of every other FANG company ? Unlikely. reply lumost 16 hours agorootparentEven with unlimited budget and talent, overcoming 25 years of success is ... difficult. Nvidia employs it&#x27;s own top-tier folks and now has massive margins to invest.If your goal is to sell an AI product to end-customers, choosing to pick up the R&D cost of building great AI chips as well as training gigantic models and the product R&D to make a product customers love ... is a tall order. reply andrewstuart 15 hours agorootparent“Years of success” is not a moat.“Years of success” means zero in the technology world.Something better with zero years success can win instantly. reply lumost 13 hours agorootparentI&#x27;d beg to differ, migrations are extraordinarily expensive in Tech. If you have a sky scraper, you don&#x27;t tear it down and rebuild it when materials become 10% stronger. Big tech firms generally maintain market position for decades. Cisco still remains the networking winner, and IBM still dominates mainframes, Oracle is going strong.AI compute isn&#x27;t something that snuck up on NVidia, they&#x27;ve built the market. reply jrockway 16 hours agorootparentprevHow effective has this been in the past, though? Everyone kind of did their hedging about switching to ARM because Intel wanted too much money, but Intel still seems to be the default on every cloud provider. AMD kind of came back out of nowhere and kept x86_64 viable, which seems to be more helpful to Intel than hurtful.Basically, the only proven strategy is to wait for AMD to blow up the competition on their own accord. Even then, \"hey no need to rewrite your code, you could always buy a compatible chip from AMD\" doesn&#x27;t seem that bad for Intel. But, maybe Nvidia has better IP protections here, and AMD can&#x27;t introduce a drop-in replacement, so app developers have to \"either or\" Nvidia&#x2F;AMD. reply Miraste 15 hours agorootparentAt the risk of eating my words later: AMD will never be competitive with Nvidia. They don&#x27;t have the money, the talent, or the strategy. They haven&#x27;t had a competitive architecture at the top end (i.e. enterprise level) since the ATI days. The only way they could take over AI at this point is if Jensen leaves and the new CEO does an Intel and fails for fifteen years straight. reply htrp 13 hours agorootparent> The only way they could take over AI at this point is if Jensen leaves and the new CEO does an Intel and fails for fifteen years straight.If Jensen becomes the CEO of AMD.... maybe they&#x27;ll be competitive in 10 years. reply vGPU 11 hours agorootparentprevThat’s exactly what people said about AMD before. Then bulldozer and threadripper showed up. reply Miraste 10 hours agorootparentRight, and Zen (I&#x27;m assuming you mean Zen) was great--but it succeeded only because Intel did nothing for years and put themselves in a position to fail. If Intel had tried to improve their products instead of firing their senior engineers and spending the R&D money on stock buybacks, it wouldn&#x27;t have worked.We can see this in action: RDNA has delivered Zen-level improvements (actually, more) to AMD&#x27;s GPUs for several years and generations now. It&#x27;s been a great turnaround technically, but it hasn&#x27;t helped, because Nvidia isn&#x27;t resting on their laurels and posted bigger improvements, every generation. That&#x27;s what makes the situation difficult. There&#x27;s nothing AMD can do to catch up unless Nvidia starts making mistakes. reply vGPU 9 hours agorootparentThey already are. The artificial limits on vram have significantly crippled pretty much the entire generation (on the consumer side).On the AI side, rocm is rapidly catching up, though it’s nowhere near parity and I suspect Apple may take the consumer performance lead for a while in this area.Intel is… trying. They tried to enter as the value supplier but also wanted too much for what they were selling. The software stack has improved exponentially however, and battlemage might make them a true value offering. With any luck, they’ll set amd and nvidia’s buns to the fire and the consumer will win.Because the entire 4xxx generation has been an incredible disappointment, and amd pricing is still whack. Though the 7800xt is the first reasonably priced card to come out since the 1080, and has enough vram to have decent staying power and handle the average model. reply MikusR 3 hours agorootparentprevBulldozer was the thing that almost killed amd. reply runako 16 hours agorootparentprevThis is conflating what happens in the stock market with what happens in the market for its products. Those two are related, but not as much as one might think.A solid parallel is Intel, which continues to dominate CPU sales even as its stock has not performed well. You may not want to own INTC, but you will directly or indirectly use an Intel product every day. Intel&#x27;s supremacy continues, even after the transition to hyperscaler clouds. reply jjoonathan 16 hours agorootparentprevNvidia the company will do great, the current batch of NVDA buyers probably won&#x27;t. reply ravenstine 18 hours agoparentprevPeople have been predicting companies like Intel and AMD overtaking Nvidia for a very long time now, and it&#x27;s never panned out. This isn&#x27;t to say that there can&#x27;t be competition that can match or exceed Nvidia, but I don&#x27;t think it&#x27;s going to be any of the other old guard companies at this point. Especially not Intel. Every year I see articles trotted out claiming that Intel is making a comeback in general, and it never happens. Intel might buy some company in thinking they can harvest the talent to compete with the likes of Nvidia or Arm, but their corporatism will ruin any talent they buy. reply ksec 18 hours agorootparent>People have been predicting companies like Intel and AMD overtaking Nvidia for a very long time now, and it&#x27;s never panned out.And I have been saying \"drivers\" for 10+ years. Anyone who has been through 3Dfx Voodoo, S3, Matrox, ATI, PowerVR era should have known this but somehow dont. And yet it keeps coming up. I still remember an Intel Engineer once said to me they will be competitive by no later than 2020 &#x2F; 2021. We are now in 2023, and Intel&#x27;s discrete GPU market share is still a single digit rounding error. To give some additional context Raja Koduri joined Intel in early 2018. And Intel has been working on Discrete Graphics GPU budding on top of their IGP asset since 2015 &#x2F; 2016. reply pseudosavant 18 hours agorootparentprevIntel&#x27;s grip on the CPU market was similarly one-sided not long ago. They had a 3 year process lead on anyone. Giants can falter. reply jonny_eh 17 hours agorootparentHas there been any indication that nVidia will, or even can, falter in the foreseeable future? reply tommek4077 18 hours agorootparentprevWell the Llama.cpp running on CPUs with decent speed and fast development improvements, hints towards CPUs. And there the size of the model is less important as the RAM is the limit. At least for interference this is now a viable alternative. reply redox99 17 hours agorootparentOutside of Macs, llama.cpp running fully on the cpu is more than 10x slower than a GPU. reply tommek4077 15 hours agorootparentBut having 32 real cores in a cpu is so much cheaper than having mumtiple gpus. RAM is also much cheaper as VRAM. reply kirill5pol 17 hours agorootparentprevFor local yes, but at data center level the parallelization is still often worth it. reply sottol 18 hours agoparentprevResearch doesn&#x27;t really have the sunk-cost that industry does. New students are willing to try new things and supervisors don&#x27;t necessarily need to reign them in.I wonder what is holding AMD back in research? Their cards seem much less costly. I would have figured a nifty research student would figure out quickly how to port torch and run twice as many gpus with his small budget to eek out a bit more performance. reply dauertewigkeit 18 hours agorootparent99% of people publishing at top conferences are not particularly technically skilled and do not want to waste time adopting a new platform, because the competition is to publish papers and nobody cares if you do that on an AMD machine instead of an NVIDIA machine.The best funded labs have research developers whose only job is to optimize implementations. However these same labs will have the latest NVIDIA hardware. reply zehaeva 18 hours agorootparentprevIf AMD cards were half the price of Nvidia ones then sure, this would happen. The 4090 can be had for ~$1600USD and the RX 7900 for about ~$1000USD. A significant discount, however the RX 7900 is about 3&#x2F;4ths as powerful as the 4090, which puts it more in the class as a 4080, which costs about as much.As a small budget research&#x2F;grad student, if the price difference isn&#x27;t that big, why waste the time porting torch to it? reply dauertewigkeit 18 hours agorootparentNah, price isn&#x27;t going to be a motivating factor. If AMD came up with a card that had 3x the VRAM of the latest NVIDIA offering there would be research groups who would be interested because loads of models are hardware bottlenecked. reply latchkey 18 hours agorootparentMI250&#x27;s (which are really 2 gpus on one board) are 128gb and can be chained together with other cards. reply comte7092 14 hours agorootparentprevOf course cost is a motivating factor.The very nature of GPUs implies that they are optimized for parallelizable workloads.If I can split my training across 3x the chips at 1&#x2F;10th the cost for each chip, why wouldn’t I do that? reply latchkey 18 hours agorootparentprevYou&#x27;re thinking consumer.MI250 cards are less than half the price of H100, and more importantly, you can buy them today. reply zehaeva 15 hours agorootparentNow I&#x27;m imaging a small budget grad student&#x2F;researcher with a budget of several hundred grand.Maybe I&#x27;m not as familiar with the word small as I thought I as. :) reply latchkey 15 hours agorootparentCan buy 4 MI250’s (8 gpus) in a high end chassis for less than $100k. Today.Try that with H100’s. reply WinLychee 18 hours agorootparentprevThe software support just isn&#x27;t there. The drivers need work, the whole ecosystem is built on CUDA not OpenCL, etc. Not to say someone that tries super hard can&#x27;t do it, e.g. https:&#x2F;&#x2F;github.com&#x2F;DTolm&#x2F;VkFFT . reply dathinab 18 hours agorootparentprevAFIK in research nothingAMD had competitive GPGPUs AFIK just only relevant to a small number of very very large customersproblems where mostly outside of researchmainly there wasn&#x27;t much insensitive (potential profit) for AMD to bring there GPGPU tooling to the consumer&#x2F;small company marked and polish it for LLMs (to be clear I do not mean OpenCL, which was long term available but general subpar and badly supported)Nvideas mindshare was just too dominant and a few years ago it wasn&#x27;t that uncommon for researchers to idk. create new building blocks or manual optimizations involving direct work with CUDA and similarBut that&#x27;s exactly what changed, by now, especially with LLMs, research does nearly always only involve usage of \"high level abstractions\" which are quite independent of the underlying gpu compute code (high-level might not be the best description as many of this GPU independent abstractions are still quite low level) .AMD has already shown that they can support that quite well and it seems to be mainly be question of polishing before it becomes more widely available.Another problem is that in the past AMD had decent GPU (compute&#x2F;server) parts and GPU (gaming) parts but there GPU (gaming) parts where not that usable for compute. On the other hand Nvidea sold high end GPUs which can do both and can be \"good enough\" even for a lot of smaller companies. So a ton of researchers had easy access to that GPUs where access to specialized server compute cards is always complicated and often far more expensive (e.g. due to only being sold in bulk). This still somewhat holds up for the newest generation of AMD GPUs but much much less so. At the same time LLMs become so large that even using the highest-end Nvidea GPU became ... to slow. And selling a more high end customer GPU isn&#x27;t really viable either IMHO. Additionally local inference seems to become much much more relevant and new AMD laptop CPU&#x2F;GPU bundles and dedicated GPUs seem to be quite well equipped for that.Also the marked it growing a lot, so even if you just manage to get smaller % cut of the marked share it might now be profitable. I.e. they don&#x27;t need to beat Nvidea in that marked anymore to make profit, grabbing a bit of marked share can now already be worthwhile.---> port torchIdk. if it&#x27;s already publically available&#x2F;published but AMD has demoed proper well working torch support based on ROCm (instead of OpenCL). reply latchkey 17 hours agorootparenthttps:&#x2F;&#x2F;pytorch.org&#x2F;blog&#x2F;experience-power-pytorch-2.0&#x2F;https:&#x2F;&#x2F;www.mosaicml.com&#x2F;blog&#x2F;amd-mi250 reply visarga 18 hours agorootparentprevYou can run LLMs on AMD. Maybe not every neural network, but LLMs do work. reply ksec 18 hours agoparentprevAgree, But may be in the author&#x27;s defence his conclusion is actually somewhat different to the title.>If you believe my four predictions above, then it’s hard to escape the conclusion that Nvidia’s share of the overall AI market is going to drop. That market is going to grow massively so I wouldn’t be surprised if they continue to grow in absolute unit numbers, but I can’t see how their current margins will be sustainable.So after all that what he really meant was that Nvidia cant keep their current margin.I cant stress how their current margin is only because of sudden supply and demand surge, and they are pricing it as such. Of course their margin will fall. That is like saying certain product margin will fall after COVID. Yes. because people wont be crazy about it. But it has no relevance whether they will stop buying the particular brand of products after COVID. reply runako 16 hours agorootparent> author&#x27;s defence his conclusion is actually somewhat different to the title.In my defense, his title is clickbait and at the bottom he makes claims that are not supported by his arguments. For example:> it’s hard to escape the conclusion that Nvidia’s share of the overall AI market is going to dropHard for it to increase from here, so this is not insightful.> I can’t see how their current margins will be sustainable.There&#x27;s no hint of an argument in his post for this. We have all watched as Apple and Microsoft increased volume and maintained margins by delivering value through an interlocking network of products&#x2F;users&#x2F;services. I don&#x27;t think it&#x27;s a stretch to think Nvidia can do the same. The onus is on the poster to say why this can&#x27;t happen, and he didn&#x27;t do that. reply xbmcuser 17 hours agorootparentprevLooking at how much the cost of foundries with newer technology is increasing with each generation I really don&#x27;t see the supply outpacing demand. AI&#x2F;NLP has just started to rise out of trough of disillusionment and I feel the demand is going to pick up a lot. reply riemannzeta 18 hours agoparentprevI agree, if by \"long\" you mean 5 years. The author seems to have a longer time horizon in mind than do most Wall Street analysts though.Sun Microsystems did great through the 1990s. But by the time the LAMP stack was fully mature, web servers had been commoditized. reply runako 16 hours agorootparentSun is not a great compare because it didn&#x27;t have the type of network the author lays out. There was a relatively small market in Sun-only software, for example, and a smaller set of people who exclusively programmed for Sun hardware.If I were forced to use Sun as a comparator, I would say their supremacy in the general-purpose high-end Unix workstation niche was never toppled, but that niche declined to irrelevance in popularity. The takeaway from that analogy here would be Nvidia is in trouble if people stop using GPUs in AI applications. reply riemannzeta 15 hours agorootparentThat&#x27;s fair. It seems we all agree that the timeline here is much longer than some might understand from the author&#x27;s remarks. But ultimately I agree with the author regarding Nvidia&#x27;s competition — it&#x27;s like a dog walking on its hind legs: it&#x27;s not done well; the surprise is that it&#x27;s done at all. reply dsizzle 18 hours agoparentprevOne of his points is that NVIDIA is unlikely to maintain its current high margins, and becoming a low-cost leader would lead to lower margins, so that part is consistent. reply emporas 15 hours agoparentprev>If anything, this post suggests Nvidia has a long supremacy ahead.I don&#x27;t know what you mean by long supremacy, later you mention decades, but Nvidia&#x27;s huge market share will last for 5 years, 7 years max.As soon as the computation has to not be absolutely accurate, but it has to approximate a very good solution of a large volume of data in a second, then biology is already great at that. Silicon chips are orders of magnitude worse, in energy consumption as well as the speed of the approximation, let alone the fact they overheat.In my view, silicon is on it&#x27;s way out, for use cases like that.https:&#x2F;&#x2F;www.forbes.com&#x2F;sites&#x2F;zinnialee&#x2F;2023&#x2F;06&#x2F;21&#x2F;cortical-l... reply dekhn 15 hours agorootparentIt is unlikely any biology-based computers are going to supplant any real computers any time soon (decades). Keeping a bunch of cells alive to run computations is simply a terrible approach and there&#x27;s no way they would get close enough to the incumbents to produce something competitive without spending billions on R&D that the chip industry already spent decades ago.Most computations we do are already approximate, not exact. Most of modern ML is approximate. reply emporas 15 hours agorootparentIf biology based computers are so impractical, then parent and you are correct. Nvidia will hold a big market share for a decade at least, probably more.I have a different opinion. Cells connected to silicon, even if they are short-lived compared to pure metal to some weeks maybe, the cost may easily outweigh the downsides.Think about headsets for V.R. for a minute. Headsets which overheat, have fans on them, and are heavy are a big problem for carrying them around for hours. What&#x27;s the alternative? A cord connected to a PC. That&#x27;s very cumbersome as well. reply dekhn 14 hours agorootparentHave you worked with cells before? I&#x27;ve worked with cells before and I struggle to see how you could implement a production cell-based computer that was cost-competitive. reply emporas 14 hours agorootparentNo i haven&#x27;t worked with cells, but the person who implemented the cells-silicon computer of Cortica claims to be a doctor and have figured it out somehow. I don&#x27;t know what the limits of such product would be, but cell&#x27;s death would be one of the limits for sure. There may be some more insurmountable problems with such technology, that i have no idea about.What i do know, if a technology like that exists, it has certain markets which is a better fit, than pure silicon. Anything wearable for example. V.R. headset is just one wearable device which comes to mind. reply dekhn 14 hours agorootparentGrowing eukaryotic cells is still something that needs well-outfitted research labs; it&#x27;s not something you can do in a production computing environment.You&#x27;re being misled by news filtered through the VC reality distortion field.Even if there are markets that fit, these players still ahve replace incumbents with billions of dollars of R&D investment and decades of production deployments. You&#x27;d have to pour many billions into establishing a foothold... in a low-profit business. replyTaikonerd 16 hours agoparentprevI wonder if Mojo could change this? I&#x27;m not that familiar with ML, but they&#x27;re claiming[1] to have a unified \"AI Engine\" that abstracts away the particular hardware. That would stop the \"engineers are more familiar with NVidia => NVidia ecosystem gets more investment...\" flywheel.[1]: https:&#x2F;&#x2F;www.modular.com&#x2F;blog&#x2F;weve-raised-100m-to-fix-ai-infr... reply runako 16 hours agorootparentI took a brief look at Mojo, and it reminds me of how Java was going to break the Wintel duopoly and let Sun thrive.(This analogy is not necessarily bad for Mojo any more than it was for Java as an ecosystem.) reply HDThoreaun 16 hours agoparentprevHis key point is that AI workloads will switch to CPU as training becomes a smaller portion of the pie. If this is true then Nvidia is not the market leader, because their CPU offerings are non existent. reply rhdunn 16 hours agorootparentFor ML&#x2F;neural networks, the vector&#x2F;matrix&#x2F;tensor acceleration is still valuable. Thus, running them on GPUs or specialist hardware will make them faster to complete -- such as generating images from stable diffusion. GPUs are also currently best suited to this due to being able to parallelize the calculations across the CUDA and specialist tensor cores.The other issue is the memory needed to run the models. NVidia&#x27;s NVLink is useful for this to share memory in a combined space across the GPUs. reply jasfi 18 hours agoparentprevNvidia have great hardware. If anyone can beat them, fine, but this seems unlikely. Groq looks cool though (thanks to the one that linked to their video). I&#x27;m wondering if the entry-level chips can really ever compete though, since LLMs need a certain amount of VRAM. Will the price of VRAM really ever fall substantially enough so that anyone could run their own LLM locally? reply pella 17 hours agorootparent> so that anyone could run their own LLM locally?180B ? https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37419518 reply jasfi 4 hours agorootparentThat&#x27;s encouraging. Hopefully the cost continues to come down. reply tgma 18 hours agoparentprevThis. Plus, in the high end AI world you are going to need to build a big machine not just a single chip on a PCIe card. They basically have a monopoly on high end RDMA fabric via Mellanox. reply RC_ITR 18 hours agoparentprevIt always seems so easy to &#x27;fast follow&#x27; in semiconductors, but then you&#x27;re the GM of the GPU group at Intel and you look for SerDes designers, then find out there are maybe 3 dozen good ones and they already work at Broadcom&#x2F;Nvidia&#x2F;Cisco. reply peoplearepeople 17 hours agoparentprev> - better (faster) hardwareIf TSMC starts having trouble with new process nodes, then I think Intel could quickly capitalize reply runako 16 hours agorootparentProcess node transitions are a risk for every manufacturer. Is there any reason to think TSMC would have unrecoverable trouble with a new process node, while Intel sails through?Separately, is there any reason Intel would not (under its fab model) accept Nvidia&#x27;s business in such a scenario? Coopetition like this is not unknown (ex: Samsung making chips for Apple). reply dathinab 18 hours agoparentprev> - industry standard used and preferred by most practitionersby now the industry standard for LLMs is shifting to a small number of higher level frameworks which abstract implementation details like CUDA 100% away.Even before in the last many years a AI researcher using CUDA explicitly per hand was super rare. TensorFlow, PyTorch etc. was what they where using.This means since 5+ years CUDA, DDN and similar where _hidden implementation details_.Which means outside of mindshare Nvidea is surprising simple to replace as long as anyone produces competitive hardware. At least for LLM-style AI usage. But LLMs are dominating the market.And if you look beyond consumer GPUs both AMD and Intel aren&#x27;t really that far behind as it might look if you only look at consumer GPUs suitability for AI training.And when it comes to inference thinks look even less favorable for Nvidea, because competitive products in that area already exist since quite a while (just not widely consumer available).> the low-cost leaderAt least for inference Nvidea isn&#x27;t in that position at all IMHO. A lot of inference hardware comes bundled with other hardware and local inference does matter.So inference hardware bundled with phone, laptop but also IoT chips (e.g. your TV) will matter a lot. But there Nvidea has mainly marked share in the highest end price segment and the network effect of \"comes bundles with\" matters a lot.Same applies to some degree to server hardware. If all you servers run intel CPUs and now you can add intel AI inferrence cards or CPUs with inference components integrated (even lower latency) and you can buy them in bundles, why should you not do so? Same for AMD, same for ARM, not at all the same for Nvidea.And during a time where training and research dominates it&#x27;s quite likely to push inference cards to be from the same vendor then training cards. But the moment inference dominates the effect can go the other way and like mentioned for a lot of companies weather it used Nvidea or AMD internal can easily become irrelevant in the near future.I.e. I&#x27;m expecting the marked to likely become quite competitive, with _risk_ for Nvidea, but also huge chances for them.One especially big risk is the tensions LLMs put on the current marked model of Nvidea which is something like \"sell high end GPUs which are grate for games and training allowing both marked to subvention each other and create an easy (consumer&#x2F;small company) availability for training so that when people (and companies) start out with AI they likely will use Nvidea and then stick to it as they can somewhat fluently upscale\". But LLMs are currently becoming so large that they brake that as GPUs for training for them need to be too big to still make sense as high end consumer GPUs. If this trend continuous we might end up in a situation where Nvidea GPUs are only usable for \"playing around\", \"small experiments\" when it comes to LLM training with a friction step when it comes to proper training. But with recent changes with AMD they can very well fill in the \"playing around\", \"small experiments\" in a way which doesn&#x27;t add additional friction as users anyway use more high level abstractions. reply breadwinner 19 hours agoprevThere are a lot of Nvidia chips being bought because of the hype. Saudi Arabia and UAE have decided to become AI powerhouses and the way to do that, of course, is to buy lots of Nvidia chips [1]. So has the UK government, and they are buying $130 million worth of chips [2]. There will be lots of disappointment, and the hype will die down.[1] https:&#x2F;&#x2F;www.ft.com&#x2F;content&#x2F;c93d2a76-16f3-4585-af61-86667c509...[2] https:&#x2F;&#x2F;www.theguardian.com&#x2F;business&#x2F;2023&#x2F;aug&#x2F;20&#x2F;uk-global-r... reply rmbyrro 18 hours agoparentWhy do you think it&#x27;s a hype and why it&#x27;ll die down?I&#x27;m now a heavy user of AI personally & professionally (as a dev). The two work projects I&#x27;m involved with are increasing by a lot the usage of GPU to apply LLM tech.I don&#x27;t see this coming back. The market growth rate will slow down, but it&#x27;ll continue to grow (and not come back) for quite a few years, I think.When it starts to slow (growth rate, not market), I guess there&#x27;ll be other breakthroughs in AI like GPT that&#x27;ll renew the trend. reply paulddraper 18 hours agorootparentHype. In 80% of cases people overestimate the usefulness of AI.Kinda like the dotcom bubble.Over the long long term it will be enormous, but they&#x27;re many growing pains until then reply josephg 18 hours agorootparent> In 80% of cases people overestimate the usefulness of AI.Looking at my chatgpt history, my partner and I seem to average about 3 conversations a day. We would use it a lot more than that if we had a way to invoke it with our voices, like Siri. Our usage is increasing over time as we figure out the sort of questions it’s good at answering.I’m not saying all the hype is justified, but if anything I think people underestimate how useful AI can already be in their lives. It just takes some learning to figure out how and when to use it.This is markedly different from both web3 and VR. It’s 2023 and I still make purchases with my Visa card and play most video games with mouse and keyboard (while my quest - cool as it is - gathers dust). reply dghlsakjg 17 hours agorootparentYou are an extreme outlier. Most of us on HN are.As of the end of august only 18% of US adults had tried ChatGPT at all (https:&#x2F;&#x2F;www.pewresearch.org&#x2F;short-reads&#x2F;2023&#x2F;08&#x2F;28&#x2F;most-amer...).For me, the biggest obstacle to get over is trust. I have seen ChatGPT make up facts far too often for it to be useful for a lot of what I ask of google. I also would be VERY leery of integrating it into customer support, etc. At some point I expect some company to have its chat bot enter into a contract with a customer and end up having to deliver. reply josephg 16 hours agorootparentThat makes sense. I suppose my answer is that for most questions I ask chatgpt, I&#x27;m ok with the answer being a bit wrong. For example, I asked it how long & hot to heat my oven when I baked cauliflower. It would have been a pity if we burned the cauliflower, but the answer was spot on. Likewise it gave a great answer when I asked for a simple crepe recipe. (The crepes were delicious!).Another time I asked this:> C minor and G major sound good together. What key are they in?And it answered that incorrectly, saying there wasn&#x27;t a key which contained both chords. But thats not quite right - they&#x27;re both contained in C harmonic minor.When you ask it to write code, the code often contains small bugs. But that can still be very helpful a lot of the time, to a lot of people.And its also utterly fantastic as a tool for creative writing, where you don&#x27;t care about facts at all. For example, the output of prompts like this are utterly fantastic:> I&#x27;m writing the character of a grumpy innkeeper in a D&D campaign and I want the character to have some quirks to make them interesting for the players. List 20 different weird quirks the innkeeper could have.I just put it in and got things like this:4. Height Requirement: Refuses to serve anyone taller or shorter than him, with a height chart at the door for reference.9. Historical Enthusiast: Dresses and talks like he&#x27;s from a different era, insists patrons do the same to get service. reply dekhn 15 hours agorootparentUh.... C minor and G major are keys&#x2F;scales, not chords https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;C_minor https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Minor_chord (I am not a musician, but I know the circle of fifths, keys, and chords). reply josephg 14 hours agorootparentMaybe I would have gotten a better answer if I specified the C minor and G major triads. I assumed chatgpt would figure that out from context. (And it sort of did, but it said they didn’t have any shared key). reply dekhn 13 hours agorootparentCan you try and report back (I don&#x27;t want to try to reproduce your exact experiment). reply josephg 12 hours agorootparenthttps:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;c904d3a0-9564-4d6f-8b62-406d3f...I’d like it to say “C harmonic minor” but honestly my knowledge of music theory might not be good enough to properly evaluate its response. What do you think? reply dekhn 10 hours agorootparentboth chords are in the notes of the key&#x2F;scale, but I don&#x27;t know that they would sound good if played together or sequentially. replyjacquesm 16 hours agorootparentprevThink about that for a second though: 18% of US adults used a product that didn&#x27;t exist five years ago. That&#x27;s an immense success and proves that the OP isn&#x27;t an extreme outlier but in fact is just one of very many.If anything what should amaze us is that ChatGPT managed to command that kind of market share in such a very short time. That&#x27;s approximately 46 million individuals. reply dghlsakjg 16 hours agorootparentI wish there was more data on how much it is getting used. To say that 18% of people used something is one thing. The question for me is, what percentage of people used the free version once or twice for novelty purposes and then never touched it again.A different poll from the same org found that the number of people who had used it was 14% back in May.If I&#x27;m remembering the timeline right, it really hit the zeitgeist hard in February, so it seems as if the growth is leveling off.In any case, getting 18% of people in the US to use your product in less than a year is still nothing to sneeze at. reply emporas 16 hours agorootparentprevI would argue that trying to estimate the value of statistical engines by taking into account only GPT, text is a narrow domain. How about visuals like SD, text like GPT, and music like Audiocraft? Music is still not very advanced but it&#x27;s coming. Human voice audio as well should get into the mix, for audiobooks n stuff. How about word transcripts from videos etc? I use that all the time.If 18% of adults have used GPT at least once, that sounds accurate, but how about every other tool? reply jacquesm 16 hours agorootparentProbably many more, but this one statistic was the one mentioned. And if that&#x27;s the size of it then it is already very impressive. Phonograph, Radio, TV, Computers and Mobile telephony for instance took much, much longer to reach similar numbers. reply checkyoursudo 13 hours agorootparentBut most of those 18% have tried it on the web interface for free. The rest of those things you mention are&#x2F;were very expensive, especially at first. My dad was lugging home expensive workstations from his office for years before anyone in my circles could really afford a home computer.Free+Hype makes me not that impressed with the number of people who have tried ChatGPT. Smartphone ubiquity today is way more amazing to me than a lot of people giving the weird new chatbot a try.If you can come back and tell me a year from now that even 10% of adults use something like ChatGPT once a month as anything other than a search engine replacement, I will be impressed. Really, I will. When the chatbot market gets bigger than a rounding error of the smartphone&#x2F;tablet market, then I will be impressed.I think they are fun. I can and do run the big models locally on my research hardware. People in my lab are doing some pretty neat things with LLMs and other tools in the current hype cycle. I personally like them. But there is massive, so-far-unwarranted hype. replyjocaal 17 hours agorootparentprev> ...about 3 conversations a day...Do you mind sharing examples of what you guys use it for? I basically never use LLM&#x27;s and I am curious what uses others have found for it. From what I have seen, it is mostly used by students as a better search engine reply josephg 16 hours agorootparentHere&#x27;s a random selection from the past couple weeks:> I&#x27;m visiting Oxford University for a few days. What are some things I should know before I travel? How do I fit in with people on my trip? Take the persona of a stuffy old Brittish aristocrat while answering.> Help me edit this text to write it in a way which is less likely to cause offense: (...)> I’m writing a story with different city states, where each city state has a different mix of cultural values. For example, one city might be very individualistic while another is more communal. The values exist to support storytelling. Each should be justifiable but also have interesting strengths and weaknesses that can be explored through stories told in those cultures. What are some other values by which real or fictional cultures could diverge in interesting ways?> Is rapeseed oil ok &#x2F; good for baking? We’re oven baking broccoli and potatoes. (followup): How hot should you make an oven to roast potatoes and cauliflower? How long should it be in the oven for?> How do you make crepes?> We’re in an Airbnb and the bathroom smells like arse. Any idea why? reply rmbyrro 17 hours agorootparentprevOk, one thing is the market & the tech. Another thing is share prices.Nvidia shares is probably overpriced right now, but we&#x27;re talking about the demand for its technology and its market dominance.> Kinda like the dotcom bubble.Would 1999 investors have lost money if they held Amazon.com shares - prior to dotcom bubble burst - to this day?Are you arguing the \"dotcom\" market was a hype that went away? Do you live in the same planet Earth as I do? reply ath92 16 hours agorootparentThe 1999 equivalent for Nvidia stocks would have been something like Sun (as mentioned in the article) or Cisco (because they sold routers which everyone thought were essential). reply rwalle 17 hours agorootparentpreveh, aren&#x27;t you just repeating \"Over the long long term it will be enormous, but they&#x27;re many growing pains until then\" reply RC_ITR 18 hours agorootparentprev>Kinda like the dotcom bubble.It&#x27;s interesting to me that people bring up &#x27;The Dot Com Bubble&#x27; as an example of empty hype, when in fact, investing in the Internet even at the peak (deploying capital proportional to 1999 market caps) has one of the best IRR&#x27;s in the history of time (Amazon, eBay&#x2F;PayPal, eTrade, etc.).I don&#x27;t think hype will die down so much as winners will be chosen and the long tail will stop buying GPUs (in the same way Pets.com and Webvan stopped building warehouses). reply staticman2 16 hours agorootparent\">It&#x27;s interesting to me that people bring up &#x27;The Dot Com Bubble&#x27; as an example of empty hype, when in fact, investing in the Internet even at the peak (deploying capital proportional to 1999 market caps) has one of the best IRR&#x27;s in the history of time (Amazon, eBay&#x2F;PayPal, eTrade, etc.).\"Do you have a source for this claim? Like, you or someone else has a market cap dataset of 1999 web companies and their market cap, including such 1999 darlings as stanlee.net, pets.com, etc. And you or someone else calculated the perormance of a .com portfolio circa 1999 if held for some time period past 1999?That sounds like a dubious claim, especially because there isn&#x27;t a clear line between a .com company and a non .com company. I recall related tech companies were also part of the .com hype cycle. reply RC_ITR 16 hours agorootparentI do!Let&#x27;s put it this way - at the end of 1999, the top 10 companies were Yahoo! ($110bn)| Amazon ($27bn)Yahoo! Japan ($25bn)eBay ($17bn)Infosapce&#x2F;Blucora ($10bn)Lycos ($8bn)Priceline ($7bn)eTrade ($7bn)Monster.com ($6bn)CNET ($4bn)Pets.com made a lot of noise in the media, but peaked at a $400mn valuation.Yahoo! exited in 2015 for $5bn plus about $40bn of Alibaba stock (bad but not awful)Amazon is the real driver as it went from $27bn to $1,500bn today, a 56x return and a 20% IRR (it&#x27;s nice when your #2 position does that).Yahoo! Japan went from $25bn to $32bn.eBay was $17bn, combined eBay and PYPL are $100bn.Priceline was $7bn and is now $113bn.eTrade was bought by Morgan Stanley for $13bn in 2020.Lycos was acquired by a Spanish telecom in 2000 for $13bn.The rest of the Top 10 were basically zeroes, but going down the list you also get Expedia ($1bn to $15bn).And keep in mind this is buying at basically the peak.The key is you actually had to listen to the wisdom of the market and not try to play in the penny stocks, which still largely holds true today. reply staticman2 15 hours agorootparentOkay, but if Nvidia is an \"AI\" company, then Cisco (352 bn) , Lucent (252 bn), Intel (271 bn), and Microsoft (583bn) and maybe even Nokia (197bn) were arguably 1999 \"web\" companies. An investment in hardware companies making telecommunications equipment was also considered an investment in the internet, as I remember it. But maybe your dataset includes that as well. reply RC_ITR 14 hours agorootparentNo, Coca-Cola also reached a peak in 1998 that it didn&#x27;t surpass until 2014, and calling that the \"Internet Bubble\" is definitely wrong.I&#x27;m just saying that the &#x27;Dotcom Bubble&#x27; is wildly misremembered. It was a broad market bubble with media coverage of the Internet.EDIT: To add to the point. The companies you cite are &#x27;picks and shovels&#x27; companies (don&#x27;t even get me started there - what&#x27;s the biggest pick and shovel company? the phrase should be &#x27;jeans, coffee and banks&#x27;). There was certainly a &#x27;picks and shovels&#x27; bubble that Nvidia may very well repeat, but the Internet was&#x2F;has always been a good investment. reply staticman2 6 hours agorootparentActual living, non hypothetical investors were not buying the 382 publicly traded \"web\" companies at market cap rates in 1999 then patiently waiting 20+ years. (I doubt retail investors could have even executed this strategy.) If your investment strategy can&#x27;t even be executed by retail investors I wouldn&#x27;t call it a \"good\" investment. replylarnik 10 hours agorootparentprevRemember NFTs? It was all the rage not that long ago and anyone who questioned otherwise was said to &#x27;not get the big picture&#x27;. NFTs were going to improve EVERYTHING.It&#x27;s not exactly the same, but the hype is similar. reply brucethemoose2 19 hours agoparentprevThe Saudis also bought a Cerebras datacenter. reply choppaface 18 hours agoparentprevHype and _competition_ . If your adversaries have tech for e.g. Defense applications, you need to have some of the tech yourself. reply YetAnotherNick 19 hours agoprevHow did author just assumed that CPU are competetive for inference. Maybe yes if you just want to run 7 billion parameters model with batch size of 1, but with batching(including continuos batching of vllm), GPU have 2 order higher throughput. And even assuming moore&#x27;s law is well alive, it will take decade to reach current GPU throughput. There is no way companies will shift to CPU for inference. reply moconnor 19 hours agoparentFor local inference there often isn’t a batch. If I chat with my own llama instance the batch size is one. The model processes a single token at a time doing a lot of vector-matrix multiplication, which is bandwidth bound. CPUs like the M1&#x2F;2 are very competitive here.Also, for local inference you only need to be fast enough for many applications. No need to do real time object detection at 1000 FPS or chat at 300 tokens&#x2F;s (code gen changes this). reply fomine3 9 hours agorootparentI understand that many people on HN prefer open-ish LLM on local hardware, but I think it doesn&#x27;t make sense sadly for efficient hardware usage perspective. Transferring input&#x2F;output text is almost free cost and local hardware can&#x27;t be fully utilized by a few people. SaaS make sense here, though I understand that privacy and censorship are matter. reply gsuuon 19 hours agorootparentprevFor straightforward chat batching wouldn&#x27;t be very useful, but it can still be very useful for building apps on top of local LLM&#x27;s which I&#x27;m hoping we&#x27;ll see more and more of. reply liuliu 17 hours agorootparentprevSpeculative decoding have higher batch size. reply brucethemoose2 19 hours agoparentprev> How did author just assumed that CPU are competetive for inference.CPUs have IGPs. And they are pretty good these days.LLMs in particular are an odd duck because the compute requirements are relatively modest compared to the massive model size, making them relatively RAM bandwidth bound. Hence DDR5 IGPs&#x2F;CPUs are actualy a decent fit for local inference.Its still inefficient, yeah. Dedicated AI blocks are the way to go, and many laptop&#x2F;phone CPUs already have these, they just aren&#x27;t widely exploited yet. reply imhoguy 19 hours agoparentprevWell, if CPUs are equipped with extra instructions like Intel AMX then why not? https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Advanced_Matrix_Extensions reply brucethemoose2 19 hours agorootparentOnly newer Intel server CPUs have this, and even then its a really odd instruction to \"activate\" and use.Even without AMX, llama.cpp is already fairly bandwidth bound for short responses, and the cost&#x2F;response on Sapphire Rapids is not great. I bet performance is much better on Xeon Max (Sapphire Rapids with HBM), but those SKUs are very expensive and rare. reply HDThoreaun 16 hours agorootparentTh author is suggesting we will start to see specially built servers that are optimized for AI inference. There&#x27;s no reason these can&#x27;t use special CPUs that utilize odd instructions. If inference does turn out to be optimized differently from training I think it&#x27;s unlikely that we won&#x27;t see a whole ecosystem surrounding it with specially built \"inference\" cpus and the like. reply brucethemoose2 13 hours agorootparent> Th author is suggesting we will start to see specially built servers that are optimized for AI inference.So far, cool genAI projects are rarely ported to anything outside of Nvidia or ROCM. Hence I am skeptical of this accelerator ecosystem.There is a good chance AWS, Microsoft, Google and such invest heavily in their own inference chips for internal use, but these will all be limited to those respective ecosystems. reply ip26 19 hours agoparentprevThe author is assuming inference will eventually get broken across many cheaper machines.To their credit, if an nvidia box is $50,000 and a cpu box is $5,000 then a cluster of ten cpu boxes is only one order of magnitude behind. reply YetAnotherNick 19 hours agorootparentI think that(no source but heard from few folks) if they run at full capacity, electricity cost will get larger than the base cost in few years. And energy per flop is an order of magnitude lower in GPU. reply melling 19 hours agoparentprevTraining can take hours, days, weeks, or months.Doesn’t the inference part only require seconds? Since it requires a fraction of the computation , can’t CPU’s be optimized for that? A few matrix multiplications reply josephg 17 hours agorootparentTraining an LLM can be batched - you can train using entire sentences &#x2F; blocks at a time. But when doing inference, you need to do one word at a time so you can put the output word back into the input.The optimization problem is that it’s often not the CPU that’s bottlenecked. It’s RAM. As I understand it, if you run llama locally you need to matrix multiply a few gigabytes of input data for every output token before your computer can start figuring out the next token. Since the weights don’t fit in your CPU’s cache, DDR bandwidth is the limiting factor, just pulling all the weights over and over into your cpu. GPUs are faster in part because they have much faster memory busses.To really optimize this stuff on the cpu, we need more than a few new CPU instructions. We need to dramatically increase ram bandwidth. The best way to do that is probably bringing ram closer to the cpu, like in Apple’s M1&#x2F;2 chips and nvidia’s new H100 chips. This will require a rethink of how PCs are currently built. reply dahart 19 hours agorootparentprevInference is only seconds on a GPU, but have a look at flops of modern GPUs to CPUs - matrix multiplications differ by two orders of magnitude. Seconds on the GPU is minutes on the CPU. And don’t forget inference needs to scale in the data center, it needs to run repeatedly for many users. reply tinco 19 hours agorootparentprevIt could, and they are. But that&#x27;s only relevant if you&#x27;re running the model locally. If the model is being ran at scale, then throughput matters and GPU&#x27;s would be king still. reply rerx 19 hours agorootparentprevGPUs will be better optimized for large matrix multiplications than CPUs, by design.And you need to the inference again and again, not just a single time (like your training). reply dist-epoch 18 hours agorootparentDesktop CPUs have integrated GPUs, so it&#x27;s more complicated. If I infer on the GPU inside my CPU, how do you count that? reply rerx 17 hours agorootparentTrue. Memory bandwidth may be the most limiting factor. reply chj 19 hours agoparentprevWith co-processors, he&#x27;s saying. reply choppaface 18 hours agoparentprevThere are a variety of tricks for making CPU inference competitive and start-ups who have made a business out of said software e.g. NeuralMagic.But yes the author does not give a substantive position despite his expertise in the area (he’s worked on e.g. the usb TPU product Google used to sell). reply hospitalJail 18 hours agoparentprev>How did author just assumed that CPU are competetive for inference.Apple marketing has been fierce. You see it in text on the internet, but in reality, its just Nvidia everywhere (unfortunately).If AI wasnt so transformative, I&#x27;d say we have a sad few years ahead, but the tools have been so useful, I&#x27;ll just bend the knee to Nvidia. reply pixl97 19 hours agoprevMuch like Nvidia&#x27;s actual GPU supremacy is only temporary... it&#x27;s just lasted a very long time and doesn&#x27;t show any signs of stopping.I personally think we&#x27;re on a very long path AI improvement. At least to me the idea we&#x27;re going to train an AI and stay on it&#x27;s core for any significant amount of time doesn&#x27;t seem likely to me. Continuous learning and feedback improvements are just one avenue we will take. Others will be expanding into multimodal models that self learn based on comparing what they generate with multiple forms of senses. reply mgreg 17 hours agoprevThanks to the folks at MLCommons we have some benchmarks and data to evaluate and track inference performance published today. Includes results from GPUs, TPUs, and CPUs as well as some power measurements across several ML use cases including LLMs.\"This benchmark suite measures how fast systems can process inputs and produce results using a trained model. Below is a short summary of the current benchmarks and metrics. Please see the MLPerf Inference benchmark paper for a detailed description of the motivation and guiding principles behind the benchmark suite.\"https:&#x2F;&#x2F;mlcommons.org&#x2F;en&#x2F;inference-datacenter-31&#x2F;For example the latest TPU (v5) from Google scores 7.13 queries per second with an LLM. Looking at GCP that server runs $1.2 &#x2F; hour on demand.On Azure an H100 scores 84.22 queries per second with an LLM. Couldn&#x27;t find the price for that but an A100 costs $27.197 per hour so no doubt the H100 will be more expensive than that.7.13 &#x2F; $1.2 = 5.94 queries&#x2F;second&#x2F;$ 84.22 &#x2F; $27.197 (A100 Pricing) = 3.09 queries&#x2F;second&#x2F;$[edited to include GCP TPU v5 and Nvidia H100 relative performance info for LLM Inference] reply dathinab 18 hours agoprevSome additional interesting points:- The recent LLM are so huge that even inference cost is quite expensive. Companies which want to enrich e.g. search with AI but don&#x27;t need full \"chat\" capabilities are already looking for alternatives which are cheaper to run even if a bit worse in capabilities (ignoring training cost).- For the same reason specialized hardware for inference has been a thing for quite a while and is currently becoming more mainstream. E.g. google cloud edge TPUs are for mainly inference, so are many phones AI&#x2F;Neural cores. I also wouldn&#x27;t be surprised if the main focus for e.g. the recent AI cores in AMD graphic cards would be inference through you can use them for more then that.- Both AMD and Intel might be less behind then it seems when it comes to training and especially inference. E.g. AMD has been selling somewhat successful GPU compute, just not to the general public. With OpenCL being semi abandoned this lead to them having close to no public mind share. Through with ROCm slowly moving to public availability and AI training being more consolidated on the internal architectures it uses this might change very well. Sure for research, especially of unusual AI architectures, Nvidea will probably still win for a long time. But for \"daily\" LLM training they probably soon will have serious competition, even more so for inference. Similar Intels new dedicated GPU architectures was made with AI training and inference in mind, so at least for inference I&#x27;m pretty sure they soon will be competitive, too.- AI training has also become increasingly more professional, with increasingly more often a small number of quite high level frameworks being used. That means that instead of having to make every project work well with your GPU you now can focus on a few high level frameworks. Similar AI architectures widely used differ less extrema then in the past and have less often big changes. Putting both together it means it&#x27;s today much easier to create hardware+driver which works for well most cases. Which can be good enough to compete.Even with all that said Nvidea has massive mind share which will give them a huge boost and when it comes to bleeding edge&#x2F;exotic AI research (not just the next generation of LLMs) they probably still will win out hugely. But LLMs is where the current money is, and as far as it seems generational improvements do not come with any massive conceptually architectural changes, but just better composition of the same (by now kinda old) building blocks. reply bryanlarsen 19 hours agoprevWhile it&#x27;s highly likely that in the future Nvidia&#x27;s market share will be lower than it is now since there&#x27;s basically only one direction share can go when it is currently ~99% (WAG). However it seems to me that the market will be larger in the future than it is now.IOW a smaller share of a larger pie. Not necessarily bad for Nvidia. reply rerx 19 hours agoprevI don&#x27;t think the article fully applies to large language models (LLMs).> Inference will Dominate, not TrainingThis rings true. While LLMs will be fine-tuned by many, fewer companies will train their own independent foundation models from scratch (which doesn&#x27;t require a \"few GPUs\", but hundreds with tight interconnect). The inference cost of running these in applications will dominate in these companies.> CPUs are Competitive for InferenceI disagree for LLMs. Running the inference still takes a lot of the type of compute that GPUs are optimized for. If you want to respond to your customers&#x27; requests with acceptable latency (and achieve some throughput), you will want to use GPUs. For \"medium-sized\" LLMs you won&#x27;t need NVLink-level interconnect speeds between your GPUs, though. reply brown 18 hours agoprev“Training costs scale with the number of researchers, inference costs scale with the number of users”.This is interesting, but I think I disagree? I&#x27;m most excited about a future where personalized models are continuously training on my own private data. reply Sohcahtoa82 18 hours agoparentHow can you disagree with that statement? Training takes significantly more processing power than inference, and typically only the researchers will be doing the training, so it makes sense that training costs scale with the number of researchers, as each researcher needs access to their own system powerful enough to perform training.Inference costs scaling with the number of users is a no-brainer.I&#x27;m pretty dumbfounded how you can just dismiss both statements without giving any reasoning as to why.EDIT:> I&#x27;m most excited about a future where personalized models are continuously training on my own private data.This won&#x27;t be as common as you think. reply visarga 17 hours agorootparent> typically only the researchers will be doing the trainingCitizen LLM developers are becoming a thing. Everyone trains (mostly fine-tunes) models today. reply Sohcahtoa82 17 hours agorootparentNon-technical people will not be fine-tuning models. A service targeted at the masses is unlikely to fine-tune a per-user model. It wouldn&#x27;t scale without being astronomically expensive. reply mandevil 17 hours agoparentprevWe will need at least one- if not several- research and data capture breakthroughs to get to that point. One person just doesn&#x27;t create enough data to effectively train models with our current techniques, no matter what kind of silicon you have. It might be possible, but research and data breakthroughs are much harder to predict than chip and software developer ergonomics improvements. Sometimes the research breakthroughs just never happen. reply waffletower 19 hours agoprevI don&#x27;t see CPUs being competitive for low-latency inference in the web accessible SaaS (&#x27;software as a service&#x27;) space. They certainly can be attractive for specialized backend applications where batch (in the macro-scheduling sense) processing can be utilzed. The author also neglects the attention that other GPU makers are investing in improving their software stacks, particularly AMD, to compete directly with Nvidia. reply lukeschlather 18 hours agoprev\"Inference costs will dominate\" seems very short-sighted. I&#x27;ve kind of laughed at any startup saying \"oh we will use AI to do \" for years but seeing what LLMs can do suddenly hardware seems like the limiting factor. I can think of endless applications if I had a few GPUs with a petabyte of onboard ram each that also run about 10000x the FLOPs of current GPUs and a few petabytes of storage for training data. I would be training models left and right to tackle whatever problem I thought of.Of course, it&#x27;s hard to say if such hardware will be available in my lifetime at a price point that I can get for personal use. In the meantime providing hardware for training will still underpin massive businesses.And especially as hardware costs come down I suspect \"fine-tuning\" will become more and more common and there will even be use cases where running inference on a large number of tokens looks a lot more like fine-tuning, which is to say you&#x27;re going to want the best GPU you can find and CPUs are just not going to work very well if at all. reply 015a 18 hours agoparentOne thing I think about: over time, more and more training will probably move closer to users devices.- Client-side training carries a lot of financial advantages; you can push the cost of the silicon, storage, and electricity onto the user.- There&#x27;s privacy benefits, which while not a major driver in adoption is something people think about.- Apple does this already. They&#x27;re going to keep doing this. When Apple makes a decision, it instantly impacts a massive plurality of the human population in a way that no other company can; and, it tangentially influences other companies.I think you&#x27;re right that \"inference costs will dominate\" is a short-sighted take. But: I think the better point is to think about where training will happen. Nvidia is weirdly poorly positioned to have a strong hand in client-side training. They don&#x27;t have a cost-efficient and electricity-efficient strategy in any of their products; except for Tegra, which has seen zero consumer uptake outside of the Nintendo Switch. There&#x27;s no hundred-billion-dollar client side AI training strategy anywhere approximate to the RTX 3070 in my gaming Windows PC, that ain&#x27;t happening. I&#x27;m doubtful they can make that pivot; there&#x27;s a lot of entrenched interest, and legitimately great products, from the existing computer & smartphone manufacturers. Apple has their chips. Google has their chips, and a really strong relationship with Samsung. Microsoft will be an ally, but they have very little power toward convincing their Windows users that a $1400 laptop is better than a $800 one because it has local AI training capability.But, I mean: server-side training is still going to be huge, and Nvidia will still be an extremely successful company. Its just when you consider their percent ownership of the net total of all AI training that will happen in 2030; its going to drop, and the biggest factor behind that drop isn&#x27;t going to be AMD; its going to be client-side training on chips made by Apple, Google, and others. reply Dritzzka 18 hours agoprevI have a feeling some security researcher is going to come out of the woodwork with a A.I security flaw in Nvidia Drivers or Hardware. reply SuchAnonMuchWow 19 hours agoprevWhat the OP is missing in its \"today\" analysis is that that cloud platform are choosing nvidia right now since its the most mature compute platform, and so the software for using GPU on the cloud will be written more and more in cuda &#x2F; using nvidia libs: it will become a defacto standard, and nvidia will entrench themselves that way. reply crop_rotation 19 hours agoparentThere is not much general purpose low level GPU software that is in demand. Most GPU software is using few specific high level ML libraries reply MPSimmons 19 hours agoprevWe _must_ build techniques to continue training existing models, and we have to figure out how to do it in a relatively ubiquitous way.The underlying data that a model is trained on becomes obsolete relatively quickly - I am constantly running into problems with GPT-4 while trying to solve technical problems, because it&#x27;s cutoff was 2021 and a ton of code has changed since then, rendering much of the knowledgebase useless. The \"paste in the current docs as context\" trick only scales so far.This is doubly so for large corporations who will be using \"inference\" on internal datasets. Training can&#x27;t be a one-time thing. New documents and state must constantly be added to the weights in order for this technology to be useful in the long run. We need to figure out a way to do this that doesn&#x27;t constantly make models forget about old training or dramatically overweight recent knowledge. reply propercoil 19 hours agoprevlol have fun building a CUDA competitive. Let us know when you have the drivers. reply ksec 18 hours agoparentExactly. It is also hard to grasp why this is needed to be stated upfront in 2023. Do people still believe next year will be the year of Linux Desktop? reply cameldrv 15 hours agoprevWe will see. I thought this in 2015 when AI for computer vision was starting to heat up and NVIDIA was the clear leader. I was certain AMD would put in the $20 million or so it would take to catch up with CUDA and CuDNN at that time. Based on that analysis, I decided that NVIDIA was overpriced as a stock. Whoops. reply Havoc 16 hours agoprevI’d say this substantially underestimates first move advantage.Early tech dominating the market often has significant staying power. See x86 reply airocker 19 hours agoprevInference will not work on cpu, I see 100 percent cpu frequently when doing cpu inference and we had to change to use GPUs for a large client. reply yalogin 18 hours agoprevFor Nvidia to lose their supremacy creating a model shouldn’t require large dedicated hardware and instead commodity CPUs should suffice. This is similar to how Facebook and google created the networking stack on commodity hardware. This I can see happening by massively parallelizing trainingUnfortunately the article doesn’t talk about any innovation in ML at all. reply rwalle 17 hours agoprev> anyone with experience has their pick of job offers right nowI have to say that this is absolutely not true, especially for those with less experience -- new graduates or people with few years of working experience (and without a PhD or many papers) reply kkielhofner 17 hours agoprevArticle is hit and miss.Mostly correct about inference.Snapchat has been running small ML on mobile devices for years for stuff like face filters, etc. Same for those features on iOS that do facial recognition to match pictures of friends with your contacts.Start to pay attention and you’ll realize your phone is doing things like object detection, classification, face tracking, voice assistant wake word detection, some on device speech and command recognition, and a wild array of other ML tasks.LLMs are sucking all of the oxygen out of the room but the overwhelming majority of end-user use of AI isn’t generative and won’t be for a long time if ever. The article is correct in saying inference, inference, inference.The future of inference is smaller application and use-case specific models deployed to edge. Many of these applications just don’t work with the latency of networks to cloud. Imagine face tracking for a Snapchat filter if it involved streaming video to a cloud for inference. Yeah, not happening.The hosting costs are also astronomical, big inference hardware is only getting harder to get and Nvidia only has so much manufacturing capacity.Leave the H100s up to Meta, OpenAI, etc that are training massive multi-billion parameter LLMs from scratch. Or people renting them in small batches to do finetuning of “smaller” models, etc.This is also getting chipped at - with the unified memory of Apple Silicon you can get the RAM of 2 A&#x2F;H100s today for less than the cost of used 80GB A100s. With an entire computer (Mac Pro), new and under warranty.Nvidia still wins on TFLOPS but expect M3&#x2F;M4&#x2F;whatever to close the gap on this by leaps and bounds. Again, not going up against Meta’s 15k H100s but all anyone else will ever need.Back to the mobile&#x2F;edge strategy, Xcode includes what is basically ML training and tuning functionality built in. You can literally train an object recognition model by dragging and dropping pictures, encrypt it, and bundle with your app all within Xcode. App developers are doing ML and barely even noticing. This is in latest Xcode, you can bet your bottom dollar Apple will be putting their significant resources to embracing all of this.Train your model on your Mac, bundle it with your app, scale to infinitely for $0 in hosting costs because the model is running on the user’s device. No Nvidia in sight.In terms of architecture you can still offload the big stuff to datacenter but at increasingly receding rates.I personally think the capability and demand for ML&#x2F;AI will quickly reach a point where Nvidia and clouds just cannot meet demand for the user base and breadth and scope of the functionality they will increasingly expect.ChatGPT has an estimated 100 MAU. Very impressive but Snapchat alone is 1 billion. Capacity, hardware advancements, and the economics of “host everything on big Nvidia” just doesn’t work out.Google has been putting TPU (lite) silicon in Pixel devices since roughly 2021. Apple with neural engine since the iPhone X in 2017…If you’ve been paying attention to these moves from Google and Apple over the last several years you would have seen this coming. They have not been caught flat-footed on this as so many people, press, etc think.Granted there will always be demand for the big datacenter stuff and Nvidia won’t be hurting anytime soon but expect to see demand for Nvidia hardware and cloud GPU usage to drop more and more as this approach eats more and more. reply gcapu 17 hours agoprevThe article has good arguments for Nvidia losing market share, not losing supremacy. The title is mostly clickbait. reply JackFr 17 hours agoprevSo where are the biggest GPU crypto-miners, and have they turned their GPU&#x27;s away from crypto to training models?Because when that happens, I can only assume that time-travel is about to be invented. It just makes sense that someone from the future went back in time and created a crypto craze to rival tulip mania, but to ensure that their operation could finance enough GPU&#x27;s to eventually invent time travel. reply politelemon 19 hours agoprevThanks for sharing. I don&#x27;t know if these predictions will pan out or not but it would make me very happy if inference becomes more accessible and does not stay in the (current) divide of haves and have-nots in terms of hardware and paywalls. The possibility of inference on crappy hardware would open up a lot more possibilities, many of which we haven&#x27;t dreamed of yet. reply imhoguy 19 hours agoparentInference on crappy hardware will bring crappy results. However upcoming SoC solutions with ML capabilities will definitely make a difference. E.g. RPi + Sony Aitrios on single board may bring interesting embedded applications: https:&#x2F;&#x2F;www.prnewswire.com&#x2F;news-releases&#x2F;raspberry-pi-receiv... reply seydor 17 hours agoprev\"Temporary\" is a relative term reply yieldcrv 17 hours agoprevJust like Portugal’s supremacy was only temporary for 400 years reply selimthegrim 16 hours agoparentWho’s the Pope of AI? reply labrador 15 hours agoprevTraining a model and deploying it to consumers to infer from it are two different things. NVidia will remain in demand for training, while deployment will use cheaper hardware on the final model to serve up to users. What am I missing? reply choppaface 18 hours agoprevFor background, Pete was a founder of jetpac which scraped millions of images from Instagram to use as content in their company which Google bought. [1] This essay’s bold claims about nvidia are like jetpac: something shortsighted, flashy, and designed to make Pete money.Several flags in the essay:“Machine learning is focused on training, not inference” Nope! There are many start-ups that do large-scale inference in the cloud, and have been long before Transformers existed. Some of said companies are customers of e.g. Roboflow and Determined.ai etc. Sure it’s not Google-scale, as Pete has been in Tensorflow land for the past few years.“Researchers have the Purchasing Power.” False! Some can afford a 2-GPU machine, but Pete’s employer and many other large companies have shifted the attention of researchers to problems that require large clusters. It’s almost impossible to publish now (e.g. reproduce results and do something new) without Google’s network (hardware money and people) having a hand in it.The rest of the essay outlines a thesis that an inference-focused product (where Pete invests himself) will disrupt nvidia. Investors take note! Googler is almost done with his handcuffs!There are many risks to nvidia’s moat (they failed to get Arm after all) but this piece is about Pete trying to find investors, not about Nvidia.[1] e.g. https:&#x2F;&#x2F;petewarden.com&#x2F;2018&#x2F;05&#x2F;28&#x2F;why-you-need-to-improve-yo... Among others reply KaoruAoiShiho 19 hours agoprevErr everything sounds right except for #2, wtf did he just say about CPUs LOL? reply orliesaurus 19 hours agoprevI have no idea what inference means but I hope it happens - and perhaps it will happen. That being said - things like Sun (i.e. solaris workstations) or Intel (for desktop or recently in the last 10ish years, servers) had the world under their thumb for 10+ years. Thus Nvidia might have quite a good reign ahead of themselves - even if it will eventually fade, like everyone else. reply tinco 19 hours agoparentWith inference they mean the dominance in purchasing will change from the producers to the consumers of machine learning models. Right now everyone is buying hardware to produce machine learning models (aka training) and at some point the author predicts the market will shift to buying hardware to consume (run inference) machine learning models.I don&#x27;t think I agree this is a significant shift that is guaranteed to happen. It might happen that we will go over some sort of hump where there&#x27;s less training happening than there was at the top of the hump, but who knows when that hump will be? It&#x27;s such a new field and there&#x27;s so many low hanging fruit improvements to be made. We could train new models for years and have steady significant improvements every time, even if there&#x27;s no fundamental breakthrough developments on the horizon.And even if there was a cooldown on new training, training is so many orders of magnitude more expensive than inference that the inference demand would have to be extreme in the face of a very unrealistically rate of training for inference to be dominant. reply pixl97 18 hours agorootparentYea, if the author is only thinking about text data, then maybe they&#x27;d have a point. But the world in which &#x27;intelligence&#x27; exists only a tiny bit textual. Visual then audio data represent most of what humans interpret. And who knows what continuous learning will look like.If you believe we are moving towards the more &#x27;star trek&#x27; like future of AI where AI observes and interprets the world as humans see it and experience it, a massive amount of compute is still needed for the foreseeable future.If you believe we are capping out on AI capability soon for some time, then you&#x27;ll see AI as more of part of the \"IBM toolkit\" offered as an additional compute service and it will more likely &#x27;fit&#x27; in our existing computer architectures. reply krallistic 19 hours agoparentprev\"Inference\" - getting the predictions out of the model. While training you need to run: Input -> Model -> Output (Prediction) - Compare with True Output (Label) -> Backpropagation of Loss through the Model. Which can highly batched & pipelined. (And you have to batch to train in any reasonable amount of times, and GPUs shine in batch regime)When a single user request comes in, you just want the prediction of that single input, so no backprogation and no batching. Which is more CPU friendly. reply syockit 18 hours agorootparentWow, now I learned something new. So even though statistics and machine learning overlap each other a lot, a word as simple as inference have totally different meanings. In statistics, it usually refers to determining the influence of an input, for a multi-input model. Getting predictions is simply called prediction. reply crop_rotation 19 hours agoprev [–] The problem is Nvidia has no real moat. Being better technically and having better software is not enough long term for ridiculous profits, unless you have an extreme lock in. And in Nvidia&#x27;s case, it is not even as if there is a wide variety of external software that has to run on any alternative. Most companies just need to run <5 ML frameworks and moving that inference to something cheaper doesn&#x27;t sound too hard, and in any case puts a ceiling on what Nvidia can charge. Training will be harder, but at some level of expenditure threshold crossing, there will be enough money pumped into it by atleast the big clouds to put a ceiling on Nvidia margins there too.The comparisons with Nvidia&#x27;s long term GPU dominance are misguided. GPUs were not making anywhere near the amount of money to put an extreme pressure from all sides. When you are on track to make MSFT level money without MSFT level moat, expect pressure from all sides trying to take any available slice. reply pixl97 18 hours agoparent [–] Nvidia has just as much of moat as Intel does on processors. Yes, Intels dominance has subsided some recently, but even then the &#x27;stickiness&#x27; of businesses and datacenters to stay with Intel is pretty extreme.Nvidia does a lot of work in performance, stability, and libraries that other vendors will have to complete with. reply crop_rotation 18 hours agorootparent [–] Intel ran general purpose software, that&#x27;s why it was dominating. Any seamless alternative had to take the vast array of x86 applications and give better perf&#x2F;price. An Nvidia alternative doesn&#x27;t have to run all CUDA applications out there to make a dent. It just has to run LLM infernece to make a serious dent in Nvidia earnings. reply pixl97 17 hours agorootparent [–] \"Intel ran general purpose software,\"Intel did not actually want to do this, and only between a series of lawsuits and licensing deals did it happen.AMD was a competitor to Intel for decades and only has really recently made a dent. At the end of the day delivering products and having a ecosystem developers can use are important. Nvidia&#x27;s competitors have not delivered on that yet. reply topspin 17 hours agorootparent [–] Is the ARM dent bigger than the AMD dent at this point, or visa versa? The TSMC dent is certainly no laughing matter.Intel is accruing dents...On the plus side they have a real GPU offering just when having a GPU offering is a great idea, assuming it can be made competitive at inference. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Nvidia's supremacy in machine learning (ML) may wane as the industry focus shifts from training to inference, implying a likely return to traditional CPU platforms like x86 and Arm.",
      "Inference, i.e., the application phase of ML models, is underemphasised currently compared to training, but its importance is expected to grow.",
      "The article sources its arguments from “Pete Warden's Blog” for context and provides a timeline for these predicted changes."
    ],
    "commentSummary": [
      "The article explores Nvidia's significant hold over the AI hardware market and the potential competition from companies such as AMD, Groq, and Mojo.",
      "The discussion delves into factors such as software support, industry standards, and pricing, that might impact Nvidia's market dominance and profitability.",
      "While Nvidia has a strong foothold now, the article concludes that there's an opportunity for other companies to challenge their position, especially with potential growth areas like AI chatbots and CPU usage in AI inference."
    ],
    "points": 165,
    "commentCount": 161,
    "retryCount": 0,
    "time": 1694441601
  },
  {
    "id": 37466207,
    "title": "Beyond OpenAPI",
    "originLink": "https://antonz.org/interactive-api-tutorials/",
    "originBody": "Anton Zhiyanov projects blog about Beyond OpenAPI Not all documentation is created equal. According to the popular classification, there are four document types: tutorials, how-to guides, technical references, and explanations. OpenAPI, the de facto standard for documenting APIs, is a decent reference-style documentation (and client code generator, of course). But it can't serve as a good how-to or tutorial. In this article, I will introduce a concise and readable way to write interactive tutorials and how-tos for any HTTP API (REST, RPC, or other style). And for that (surprise, surprise), we will rely on the HTTP protocol itself. A crash course in HTTP messages HTTP/1.x is a plain-text protocol that describes the communication between the client and the server. The client sends messages like this: POST /anything/chat HTTP/1.1 host: httpbingo.org content-type: application/json user-agent: curl/7.87.0 { \"message\": \"Hello!\" } And receives messages like this in response: HTTP/1.1 200 OK date: Mon, 28 Aug 2023 07:51:49 GMT content-type: application/json { \"message\": \"Hi!\" } HTTP/2, the successor to HTTP/1.1, is a binary protocol. However, all tools (such as the browser devtools or curl) display HTTP/2 messages in plain text (just like HTTP/1.1), so we can safely ignore this fact for our purposes. It's easy to read HTTP requests and responses once you get used to it. HTTP request consists of three main sections: Request line: POST /anything/chat HTTP/1.1 The method (POST) defines the operation the client wants to perform. The path (/anything/chat) is the URL of the requested resource (without the protocol, domain and port). The version (HTTP/1.1) indicates the version of the HTTP protocol. Request headers: host: httpbingo.org content-type: application/json user-agent: curl/7.87.0 Each header is a key-value pair that tells the server some useful information about the request. In our case it's the hostname of the server (httpbingo.org), the type of the content (application/json) and the client's self-identification (user-agent). Request body: { \"message\": \"Hello!\" } The actual data that the client sends to the server. The HTTP protocol is stateless, so any state must be contained within the request itself, either in the headers or in the body. HTTP response also consists of three main sections: Status line: HTTP/1.1 200 OK The version (HTTP/1.1) indicates the version of the HTTP protocol. The status code (200) tells whether the request was successful or not, and why (there are many status codes for different situations). The status message is a human-readable description of the status code. HTTP/2 does not have it. Response headers: date: Mon, 28 Aug 2023 07:51:49 GMT content-type: application/json Similar to request headers, these provide useful information about the response to the client. Response body: { \"message\": \"Hi!\" } The actual data that the server sends to the client. There is much more to the HTTP protocol, but this basic knowledge is enough to cover most of API use cases. So let's move on. Using HTTP to document API usage We are going to take an HTTP request: POST /anything/chat HTTP/1.1 host: httpbingo.org content-type: application/json user-agent: curl/7.87.0 { \"message\": \"Hello!\" } And modify it just a little bit: include the full URL in the request line instead of the path; remove the protocol version. POST http://httpbingo.org/anything/chat content-type: application/json { \"message\": \"Hello!\" } This format is perfect for API usage examples. It's concise and readable, yet formal enough to be executed programmatically (directly from the documentation, as we'll see shortly). Writing an interactive API guide Instead of telling you how to write an interactive API tutorial, I'm going to show you one. We'll use Gists API as an example. It's a compact and useful GitHub service for storing code snippets (called \"gists\"). Gists are quite handy when a full-blown Git repository is too much. Even if you are not a GitHub user, you still have access to the Gists API. Reading gists Let's take a look at the public gists of my pal Redowan (user rednafi). The response can be quite chatty, so we'll only select the 3 most recent (per_page = 3): GET https://api.github.com/users/rednafi/gists?per_page=3 accept: application/json Run Edit A family of non-standard x-ratelimit headers tell us how GitHub limits our requests: There is a total number of x-ratelimit-limit requests available per hour. We've already used x-ratelimit-used requests. So there are x-ratelimit-remaining requests left. We need to keep an eye on these to make sure we don't exceed the quota. We can use a combination of page and per_page query parameters to select a slice of gists. For example, here are gists 10-15: GET https://api.github.com/users/rednafi/gists?page=3&per_page=5 accept: application/json Run Edit Note that GitHub provides navigation links in the link header: link: ; rel=\"prev\", ; rel=\"next\", ; rel=\"last\", ; rel=\"first\" That's thoughtful of them! Okay, now let's take a look at the specific gist with id 88242fd822603290255877e396664ba5 (this one is mine; let's not bother Redowan anymore): GET https://api.github.com/gists/88242fd822603290255877e396664ba5 accept: application/json Run Edit We can see that there is a greet.py file written in the Python language with a certain content: class Greeter: def __init__(self, greeting): self.greeting = greeting def greet(self, who): print(f\"{self.greeting}, {who}!\") gr = Greeter(\"Hello\") gr.greet(\"world\") Run Edit (yep, you can also create interactive Python examples!) Interestingly, the gist has a history. It appears that every time you edit a gist, GitHub creates a new version, while also keeping previous versions. Let's get the earliest revision, which has a version = 4c10d27cfb163d654745f1d72f2c7ce14225b83b (a bit long, I know): GET https://api.github.com/gists/88242fd822603290255877e396664ba5/4c10d27cfb163d654745f1d72f2c7ce14225b83b accept: application/json Run Edit The code in the gist was much simpler back then: msg = \"Hello, world!\" print(msg) Run Edit Modifying gists Okay, so we know how to list gists for a user, how to get a specific gist, and even how to get a specific revision. Now let's create a new gist! POST https://api.github.com/gists content-type: application/json accept: application/json { \"description\": \"Greetings in Markdown\", \"public\": true, \"files\":{ \"README.md\":{ \"content\":\"Hello, world!\" } } } Run Edit What's that? We have a 401 Unauthorized error. The response body explains: \"requires authentication\" and even provides a link to the documentation (oh, I just love GitHub APIs). Understandably, GitHub does not allow anonymous users to create new gists. We have to authenticate with an API token. If you want the following examples to work, enter your API token in the field below. You can create one with a 'gist' scope in the GitHub settings. After you enter the token below, it will be stored locally in the browser and will not be sent anywhere (except to the GitHub API when you click the Run button). Save Let's try again, this time with an authorization header. Note the public parameter. The service supports \"secret\" gists (public = false), but it's the \"security by obscurity\" type of secrecy. Secret gists do not show up in the \"GET gists\" API method, but they are still accessible by id, even by anonymous users. POST https://api.github.com/gists content-type: application/json accept: application/json authorization: bearer {token} { \"description\": \"Greetings in Markdown\", \"public\": true, \"files\":{ \"README.md\":{ \"content\":\"Hello, world!\" } } } Run Edit I don't have a token, just show me the results HTTP status 201 Created means that a new gist has been created as a result of our request. Okay, now we can update a gist using its id (don't forget to replace the {gist_id} in the request line with the actual id value): PATCH https://api.github.com/gists/{gist_id} content-type: application/json accept: application/json authorization: bearer {token} { \"description\": \"Greetings in Markdown\", \"public\": true, \"files\":{ \"README.md\":{ \"content\":\"¡Hola, mundo!\" } } } Run Edit I don't have a token, just show me the results It now greets us in Spanish 🇪🇸 Very good. Finally, let's delete a gist: DELETE https://api.github.com/gists/{gist_id} accept: application/json authorization: bearer {token} Run Edit I don't have a token, just show me the results HTTP status 204 No Content means we deleted the gist, so GitHub has nothing more to tell us about it. It's a little sad to see it go, but we can always make another one, right? The Gists API has other useful features, but they are beyond the scope of this tutorial. Here are the functions we've covered: List user gists. Get a specific gist, or a specific revision of a gist. Create a new gist. Update an existing gist. Delete a gist. Now try managing your gists! You can always use this article as a playground. Implementation To run the API examples as we did in the previous section, you'll need a bit of JavaScript that does the following: Parses the HTTP request example. Calls the API. Displays the result. It's always nice when a playground doesn't need a server. Since we've limited ourselves to a small subset of HTTP request capabilities, parsing is fairly easy: // parse parses the request specification. function parse(text) { const lines = text.split(\"\\n\"); let lineIdx = 0; // parse method and URL const methodUrl = lines[0].split(\" \").filter((s) => s); const [method, url] = methodUrl.length >= 2 ? methodUrl : [\"GET\", methodUrl[0]]; lineIdx += 1; // parse headers const headers = {}; for (let i = lineIdx; i < lines.length; i++) { const line = lines[i].trim(); if (line === \"\") { break; } const [headerName, headerValue] = line.split(\":\"); headers[headerName.trim()] = headerValue.trim(); lineIdx += 1; } // parse body const body = lines.slice(lineIdx + 1).join(\"\\n\"); return { method, url, headers, body }; } const spec = parse(`GET https://httpbingo.org/uuid`); console.log(JSON.stringify(spec, null, 2)); Run Edit Calling the API and displaying the results is trivial — just use the Fetch API and display the result as plain text: // execCode sends an HTTP request according to the spec // and returns the response as text with status, headers and body. async function execCode(spec) { const resp = await sendRequest(spec); const text = await responseText(resp); return text; } // sendRequest sends an HTTP request according to the spec. async function sendRequest(spec) { const options = { method: spec.method, headers: spec.headers, body: spec.body || undefined, }; return await fetch(spec.url, options); } // responseText returns the response as text // with status, headers and body. async function responseText(resp) { const version = \"HTTP/1.1\"; const text = await resp.text(); const messages = [`${version} ${resp.status} ${resp.statusText}`]; for (const hdr of resp.headers.entries()) { messages.push(`${hdr[0]}: ${hdr[1]}`); } if (text) { messages.push(\"\", text); } return messages.join(\"\\n\"); } const spec = { method: \"GET\", url: \"https://httpbingo.org/uuid\", }; const text = await execCode(spec); console.log(text); Run Edit Fetch API works in the browser, so there is no intermediate server involved. The only nuance is that the documentation must either be on the same domain as the API itself, or the API must allow cross-domain requests. But even if that's not the case, you can always proxy the requests — it's not too much work. If you want an out-of-the-box solution, I've written a simple library that supports both JavaScript and Fetch API playgrounds: codapi-js Ideally, I'd like most documentation to be interactive. Not just API guides, but everything from algorithms (like hashing) to programming languages (like Go or Odin) to databases (like SQLite), frameworks and tools, and even individual packages. And (shameless plug here!) I'm building a platform that allows just that — easily embeddable code playgrounds for documentation, online education, and fun. Check it out if you are interested: codapi And please try to write an interactive guide the next time you develop an API! Subscribe to keep up with new posts. 30 Aug, 2023software ← Writing a package manager Mastering curl: interactive text guide → See also Writing a package manager Trying Odin (with a playground) Speed of algorithms (with cats) Subscribe: Email: m@antonz.org",
    "commentLink": "https://news.ycombinator.com/item?id=37466207",
    "commentBody": "Beyond OpenAPIHacker NewspastloginBeyond OpenAPI (antonz.org) 160 points by nalgeon 22 hours ago| hidepastfavorite42 comments yellow_lead 20 hours agoI would prefer reading the OpenAPI spec for an API - which is in a standardized format and has easily searchable&#x2F;skip-able sections, like schemas, endpoints, etc. An interactive tutorial that you mostly read from beginning to end is not convenient for devs - we want to find things within a few seconds of hitting the docs page. reply williamdclt 19 hours agoparentThe point of the article is not to _replace_ the spec. The point of the \"four-document types\" model is that different document types fit different use-cases. reply gdsdfe 19 hours agorootparentYeah that looks great for a blog post .. . Good luck writing and maintaining that for a real project in the real world reply boxed 19 hours agorootparentIt&#x27;s all about the tooling. I wrote my own for iommi where the html output of some code gets saved in a defined place, and then the finished documentation page embeds that html in an iframe. It&#x27;s not only WAY WAY easier to maintain than a bunch of screenshots, but I found a ton of issues with the documentation after I made it so it runs all the examples and I can look at the output.example: https:&#x2F;&#x2F;docs.iommi.rocks&#x2F;en&#x2F;latest&#x2F;cookbook_forms.htmlcorresponding documentation&#x2F;tests: https:&#x2F;&#x2F;github.com&#x2F;iommirocks&#x2F;iommi&#x2F;blob&#x2F;master&#x2F;docs&#x2F;test_do...my evil hack to get this working: https:&#x2F;&#x2F;github.com&#x2F;iommirocks&#x2F;iommi&#x2F;blob&#x2F;master&#x2F;make_doc_rst... and https:&#x2F;&#x2F;github.com&#x2F;iommirocks&#x2F;iommi&#x2F;blob&#x2F;master&#x2F;iommi&#x2F;docs.p... reply btown 17 hours agorootparentThat&#x27;s brilliant! https:&#x2F;&#x2F;github.com&#x2F;scientific-python&#x2F;pytest-doctestplus seems to be similar working in the opposite direction, using the documentation source as the single location for test code. I like your approach better and wish there was more support for that pattern more generally! reply boxed 4 hours agorootparentI started with that approach actually. It turned untenable after a while. It&#x27;s just much nicer to have the documentation just a part of your normal test suite without any preprocessing. That also means you get coverage in the normal way too. reply tepitoperrito 10 hours agorootparentprevsee https:&#x2F;&#x2F;documentation.divio.com&#x2F;adoption.html reply williamdclt 18 hours agorootparentprevMany projects maintain different document types in their docs. Of the top of my head: NestJS. reply sigwinch28 16 hours agoprev> According to the popular classification, there are four document types: tutorials, how-to guides, technical references, and explanations.This is Diátaxis: https:&#x2F;&#x2F;diataxis.fr&#x2F; reply jicea 15 hours agoprevThe \"HTTP\" format proposed in the article is the same we use with Hurl [1], an Open Source HTTP CLI based on plain text. POST http:&#x2F;&#x2F;httpbingo.org&#x2F;anything&#x2F;chat content-type: application&#x2F;json { \"message\": \"Hello!\" }We extend it a bit to add checks on response, and add request chaining, but it&#x27;s basically HTTP 1.x as this article shows it. A lot of others tools have the same idea, with minor differences:- Hurl (I&#x27;m one of the maintainer) https:&#x2F;&#x2F;hurl.dev- HTTP Client https:&#x2F;&#x2F;www.jetbrains.com&#x2F;help&#x2F;idea&#x2F;http-client-in-product-c...- httpYac https:&#x2F;&#x2F;httpyac.github.io- restclient.el https:&#x2F;&#x2F;github.com&#x2F;pashky&#x2F;restclient.el- REST Client https:&#x2F;&#x2F;github.com&#x2F;Huachao&#x2F;vscode-restclient- verb https:&#x2F;&#x2F;github.com&#x2F;federicotdn&#x2F;verbAnd many more...Worth noting, other tools have taken the YAML route (like Step CI https:&#x2F;&#x2F;stepci.com), JavaScript (k6 https:&#x2F;&#x2F;k6.io&#x2F;docs&#x2F;using-k6&#x2F;http-requests&#x2F;)... I&#x27;m biased of course, I&#x27;ve a tiny preference for the simple plain text format.And of course, there are also GUI application (Postman, Insomnia, RecipeUI amon others)[1]: https:&#x2F;&#x2F;hurl.dev reply pattycakes 14 hours agoprevOpenAPI is more than just documentation generation, it’s also used for runtime time validation and codegen for both client and server stubs. I’d argue that what’s discussed in this article can complement OpenAPI but doesn’t replace it. reply lux 19 hours agoprevOne thing that trips me up when I see this 4 quadrant structure for documentation is when to go with a tutorial and when to go with a how-to. Curious how others delineate between those. reply kaycebasques 18 hours agoparentTutorial takes you from an exact point A to an exact point B. Guide is much \"looser\" and just describes the general steps to get something done, without making any type of guarantee of being able to take you exactly from A to B. Mostly out of acknowledgment that the real-world is messy and everyone is going to have a slightly different system. Tutorial is for people starting from scratch or who want a gentle hands-on intro to your thing, guide is for people who are doing messy integration work with existing systems. It&#x27;s not a perfect delineator but it&#x27;ll get you most of the way there... reply juancampa 12 hours agorootparentThe way I think about it is: - Tutorial: learn how the system works - How-to: recipes for common use-cases reply ketozhang 4 hours agoparentprevIn diataxis, a tutorial serves your education and a how-to guide serves your work.Following this standard, a tutorial may contain a simpler or more contrived example; it may contain things you&#x27;d never do in production. reply layer8 9 hours agoparentprevTutorial is a Getting Started, with no specific goal other than to serve as a general hands-on introduction. It does not assume any prior experience with the tool&#x2F;product.How-to(s) is a cookbook, targeting specific use cases, and may not particularly cater to novices. reply tevon 19 hours agoprevI was hopeful starting this article. Because I do think we need something better than OpenAPI for self-documenting APIs...The idea of an interactive tutorial is great, but as others have mentioned, likely very difficult to maintain over time. reply hitchstory 16 hours agoparentI built this because I had the same idea: https:&#x2F;&#x2F;github.com&#x2F;hitchdev&#x2F;hitchstoryIf your specification is self rewriting, can be tested and can be used to generate docs then maintenance costs plummet. reply eyelidlessness 19 hours agoprevOpenAPI has great affordances for providing examples along with pertinent documentation sections. Many OpenAPI UIs provide ways to execute those examples or other interactive ways to populate and try requests. These could surely be better honed for the how-to guide style of documentation! But I think that’s probably a better place to start for people who are starting at, and looking to go beyond, what OpenAPI currently provides. reply azophy_2 10 hours agoprevthis thread reminds me of another thread [1] several days ago about web component using WASI runtime (runno.dev), which may have overlapping usecases with this project. worth looking[1] https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37287339 reply marcopicentini 20 hours agoprevWould be very interesting to see the same documentation principles applied to other thing (not API or developer docs). reply ebiester 19 hours agoparentI mean, there is nothing stopping people from using the [Diataxis Framework](https:&#x2F;&#x2F;diataxis.fr&#x2F;) for any sort of documentation - it just doesn&#x27;t have as great a foothold outside our sphere.I was a bit surprised it or Divio (where it was created) announced when they talked about the four types of documentation. I would love to see it make its way into information systems curriculum, as it&#x27;s a quite useful mental model. reply spondylosaurus 16 hours agorootparentI go back and forth on the usefulness of Diataxis and related information frameworks—Mark Baker (of EPPO fame) has an interesting series[1] about the DITA equivalent of task, concept, and reference:> If there is a problem with DITA, then, it is not that it lacks a theory of information design. The problem is that many people actually believe that it does have a theory of information design, and that that theory can be summed up in three words: concept, task, and reference. But a theory for breaking content up into pieces is not a theory of information design unless it also includes a theory of how the pieces should go back together.> There is, of course, nothing preventing DITA users from having or developing a sound theory about how the pieces should go back together. The problem is not that DITA does not provide one. The problem is that writers often do not see that they need one. They believe, or act as if they believed, that the devolution into concept, task, and reference is a complete information design. The result, generally, is Frankenbooks.Which I think is a salient point, and less an indictment on the \"three&#x2F;four types\" model than a reminder that you shouldn&#x27;t just throw together a bunch of type-delineated docs for their on sake; the individual pieces have to make a functional whole.So I&#x27;m certainly in favor of supplementing traditional OpenAPI-esque reference docs with more conceptual or task-based docs... provided that they&#x27;re actually designed to complement each other.[1] https:&#x2F;&#x2F;everypageispageone.com&#x2F;2012&#x2F;07&#x2F;28&#x2F;the-tyranny-of-the... reply simonw 19 hours agoprevWhat kind of sandbox are you using here for running Python&#x2F;etc code on your server? reply mdaniel 18 hours agoparentI&#x27;m not associated with the site, but using their bash one as an example it appears to just be docker I&#x27;ve always heard \"containerization is not a security boundary\" but I am not red-team enough to provide specific counter-examples reply rkeene2 14 hours agorootparentIf you do want a stronger security boundary, you can do that without using cgroups and other kinds of namespaces (aside from chroot) pretty easily using something like `firejail` -- that&#x27;s what I do for this demo [0] (all the software is in &#x2F;opt&#x2F;appfs, if you want to try stuff out -- you can browse it here [1])[0] https:&#x2F;&#x2F;rkeene.dev&#x2F;js-repl&#x2F;?arg=bash[1] https:&#x2F;&#x2F;browser.appfs.net&#x2F; reply mirekrusin 14 hours agoprevOr use jsonrpc and your documentation is ie typescript definition file, a list of function signatures. reply mdaniel 11 hours agoparentI don&#x27;t think that&#x27;s even remotely true, based on https:&#x2F;&#x2F;www.jsonrpc.org&#x2F;specification#examples reply mirekrusin 6 hours agorootparentJust like author simplifies HTTP communication, you can simplify: --> {\"jsonrpc\": \"2.0\", \"method\": \"subtract\", \"params\": [42, 23], \"id\": 1}19 reply verdverm 11 hours agoparentprevmost things are not written in typescriptOpenAPI, being JSON or Yaml, is portable reply mirekrusin 3 hours agorootparentJsonRPC is also portable.Whole spec fits single page. reply verdverm 5 minutes agorootparentthe JsonRPC comes from the typescript in GP, so the process of schema generation from types is not portable to other languages... reply troupo 20 hours agoprevWhat this misses is the curl response format.Long time ago at Klarna we used this tool: https:&#x2F;&#x2F;github.com&#x2F;for-GET&#x2F;katt Here&#x27;s an example: https:&#x2F;&#x2F;github.com&#x2F;for-GET&#x2F;katt&#x2F;blob&#x2F;master&#x2F;doc&#x2F;example-http... reply pphysch 13 hours agoprevcodapi is slick and this tutorial provides good insight into how HTTP APIs work.OpenAPI is wack though. It doesn&#x27;t provide any guarantees that the API does what it is supposed to do. I think in most cases it is a distraction and developer time would be better spent understanding HTTP and implementing and testing the endpoints.I&#x27;m curious if others have had good experiences consuming OpenAPI as intended, i.e. you get handed a new API and you generate the code interfaces and plug them directly into your business logic without writing any extra wrappers. Or do you end up writing lots of wrapping code anyways? reply simonw 19 hours agoprevI think people may be missing the core point of this article. As often happens on Hacker News (and the internet in general), people are responding more to the post title than the actual content.Anton has built a new thing, https:&#x2F;&#x2F;codapi.org&#x2F; - which provides a web component that makes it easy to embed interactive code snippets for HTTP APIs, Python code and more directly in pages of documentation.This article demonstrates this new technology in the context of the https:&#x2F;&#x2F;diataxis.fr&#x2F; documentation framework, which recommends going beyond just straight API reference documentation and ensuring you cover tutorials, how-to guides and explanations as well.I think this is really cool. reply kaycebasques 18 hours agoparentI read the full post. It meanders quite a bit. Would have been more effective to just announce the new tool without the provocative title or the detour into HTTP basics. Sending this comment in the spirit of friendly, respectful, constructive criticism. reply freeqaz 19 hours agoprevI hate that my brain has now reprogrammed this to mean \"ChatGPT\" (OpenAI) to me. I legit opened the link and expected to read about \"Beyond LLMs\" or somebody leaving work at OpenAI.But HTTP APIs with types are pretty cool too. Carry on, please! reply willio58 18 hours agoparentAt my job we recently implemented OpenAPI and it&#x27;s been painful hearing people call it OpenAI on zoom calls but it makes sense, they&#x27;re so darn close. reply stared 19 hours agoprev [–] While I like it, it also has shortcomings. For example, while gpt-4-32k is listed in https:&#x2F;&#x2F;platform.openai.com&#x2F;docs&#x2F;models&#x2F;gpt-4, it is not available for accounts that have access to its 8k-token variant, gpt-4-32k. reply simonw 18 hours agoparent [–] This is about OpenAPI, not OpenAI. reply stared 18 hours agorootparentMy bad! reply joshxyz 5 hours agorootparentprev [–] this made my day replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The article delves into the application of HTTP protocol in crafting interactive tutorials for APIs (Application Programming Interfaces).",
      "It showcases the GitHub Gists API via presented code snippets, illustrating its functionality.",
      "The piece also introduces the 'codapi-js' library utilized for interactive documentation and creating code playgrounds."
    ],
    "commentSummary": [
      "The article emphasizes the importance of API documentation and introduces the \"four-document types\" model to improve the OpenAPI specification.",
      "It mentions an array of tools and frameworks for better documentation, and applies the same documentation principles to other domains.",
      "It discusses the limitations of the DITA framework and suggests supplementing reference documentation with conceptual or task-based documents, touching on topics like containerization, sandboxing, and OpenAPI."
    ],
    "points": 160,
    "commentCount": 41,
    "retryCount": 0,
    "time": 1694435174
  }
]
