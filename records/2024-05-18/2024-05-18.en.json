[
  {
    "id": 40390287,
    "title": "Bend: High-Level Language for GPU Computing with HVM2",
    "originLink": "https://github.com/HigherOrderCO/Bend",
    "originBody": "Bend Bend is a massively parallel, high-level programming language. Unlike low-level alternatives like CUDA and Metal, Bend has the feeling and features of expressive languages like Python and Haskell, including fast object allocations, higher-order functions with full closure support, unrestricted recursion, even continuations. Yet, it runs on massively parallel hardware like GPUs, with near-linear speedup based on core count, and zero explicit parallel annotations: no thread spawning, no locks, mutexes, atomics. Bend is powered by the HVM2 runtime. A Quick Demo Using Bend Currently not working on Windows, please use WSL2 as a workaround. First, install Rust nightly. Then, install both HVM2 and Bend with: cargo +nightly install hvm cargo +nightly install bend-lang Finally, write some Bend file, and run it with one of these commands: bend run# uses the Rust interpreter (sequential) bend run-c# uses the C interpreter (parallel) bend run-cu# uses the CUDA interpreter (massively parallel) You can also compile Bend to standalone C/CUDA files with gen-c and gen-cu, for maximum performance. But keep in mind our code gen is still on its infancy, and is nowhere as mature as SOTA compilers like GCC and GHC. Parallel Programming in Bend To write parallel programs in Bend, all you have to do is... nothing. Other than not making it inherently sequential! For example, the expression: (((1 + 2) + 3) + 4) Can not run in parallel, because +4 depends on +3 which depends on (1+2). But the following expression: ((1 + 2) + (3 + 4)) Can run in parallel, because (1+2) and (3+4) are independent; and it will, per Bend's fundamental pledge: Everything that can run in parallel, will run in parallel. For a more complete example, consider: # Sorting Network = just rotate trees! def sort(d, s, tree): switch d: case 0: return tree case _: (x,y) = tree lft = sort(d-1, 0, x) rgt = sort(d-1, 1, y) return rots(d, s, lft, rgt) # Rotates sub-trees (Blue/Green Box) def rots(d, s, tree): switch d: case 0: return tree case _: (x,y) = tree return down(d, s, warp(d-1, s, x, y)) (...) This file implements a bitonic sorter with immutable tree rotations. It is not the kind of algorithm you'd expect to run fast on GPUs. Yet, since it uses a divide-and-conquer approach, which is inherently parallel, Bend will run it multi-threaded. Some benchmarks: CPU, Apple M3 Max, 1 thread: 12.15 seconds CPU, Apple M3 Max, 16 threads: 0.96 seconds GPU, NVIDIA RTX 4090, 16k threads: 0.21 seconds That's a 57x speedup by doing nothing. No thread spawning, no explicit management of locks, mutexes. We just asked Bend to run our program on RTX, and it did. Simple as that. Bend isn't limited to a specific paradigm, like tensors or matrices. Any concurrent system, from shaders to Erlang-like actor models can be emulated on Bend. For example, to render images in real time, we could simply allocate an immutable tree on each frame: # given a shader, returns a square image def render(depth, shader): bend d = 0, i = 0: when d < depth: color = (fork(d+1, i*2+0), fork(d+1, i*2+1)) else: width = depth / 2 color = shader(i % width, i / width) return color # given a position, returns a color # for this demo, it just busy loops def demo_shader(x, y): bend i = 0: when i < 5000: color = fork(i + 1) else: color = 0x000001 return color # renders a 256x256 image using demo_shader def main: return render(16, demo_shader) And it would actually work. Even involved algorithms parallelize well on Bend. Long-distance communication is performed by global beta-reduction (as per the Interaction Calculus), and synchronized correctly and efficiently by HVM2's atomic linker. To jump straight into action, check Bend's GUIDE.md. For an extensive list of features, check FEATURES.md. To understand the tech behind Bend, check HVM2's paper. Bend is developed by HigherOrderCO.com - join our Discord!",
    "commentLink": "https://news.ycombinator.com/item?id=40390287",
    "commentBody": "Bend: a high-level language that runs on GPUs (via HVM2) (github.com/higherorderco)821 points by LightMachine 19 hours agohidepastfavorite161 comments Twirrim 16 hours agoFor what it's worth, I ported the sum example to pure python. def sum(depth, x): if depth == 0: return x else: fst = sum(depth-1, x*2+0) # adds the fst half snd = sum(depth-1, x*2+1) # adds the snd half return fst + snd print(sum(30, 0)) under pypy3 it executes in 0m4.478s, single threaded. Under python 3.12, it executed in 1m42.148s, again single threaded. I mention that because you include benchmark information: CPU, Apple M3 Max, 1 thread: 3.5 minutes CPU, Apple M3 Max, 16 threads: 10.26 seconds GPU, NVIDIA RTX 4090, 32k threads: 1.88 seconds The bend single-threaded version has been running for 42 minutes on my laptop, is consuming 6GB of memory, and still hasn't finished (12th Gen Intel(R) Core(TM) i7-1270P, Ubuntu 24.04). That seems to be an incredibly slow interpreter. Has this been tested or developed on anything other than Macs / aarch64? I appreciate this is early days, but it's hard to get excited about what seems to be incredibly slow performance from a really simple example you give. If the simple stuff is slow, what does that mean for the complicated stuff? If I get a chance tonight, I'll re-run it with `-s` argument, see if I get anything helpful. reply LightMachine 16 hours agoparentRunning on 42 minutes is mots likely a bug. Yes, we haven't done much testing outside of M3 Max yet. I'm aware it is 2x slower on non-Apple CPUs. We'll work on that. For the `sum` example, Bend has a huge disadvantage, because it is allocating 2 IC nodes for each numeric operation, while Python is not. This is obviously terribly inefficient. We'll avoid that soon (just like HVM1 did it). It just wasn't implemented in HVM2 yet. Note most of the work behind Bend went into making the parallel evaluator correct. Running closures and unrestricted recursion on GPUs is extremely hard. We've just finished that part, so, there was basically 0 effort into micro-optimizations. HVM2's codegen is still abysmal. (And I was very clear about it on the docs!) That said, please try comparing the Bitonic Sort example, where both are doing the same amount of allocations. I think it will give a much fairer idea of how Bend will perform in practice. HVM1 used to be 3x slower than GHC in a single core, which isn't bad. HVM2 should get to that point not far in the future. Now, I totally acknowledge these \"this is still bad but we promise it will get better!!\" can be underwhelming, and I understand if you don't believe on my words. But I actually believe that, with the foundation set, these micro optimizations will be the easiest part, and performance will skyrocket from here. In any case, we'll keep working on making it better, and reporting the progress as milestones are reached. reply vrmiguel 15 hours agorootparent> it is allocating 2 IC nodes for each numeric operation, while Python is not While that's true, Python would be using big integers (PyLongObject) for most of the computations, meaning every number gets allocated on the heap. If we use a Python implementation that would avoid this, like PyPy or Cython, the results change significantly: % cat sum.py def sum(depth, x): if depth == 0: return x else: fst = sum(depth-1, x*2+0) # adds the fst half snd = sum(depth-1, x*2+1) # adds the snd half return fst + snd if __name__ == '__main__': print(sum(30, 0)) % time pypy sum.py 576460751766552576 pypy sum.py 4.26s user 0.06s system 96% cpu 4.464 total That's on an M2 Pro. I also imagine the result in Bend would not be correct since it only supports 24 bit integers, meaning it'd overflow quite quickly when summing up to 2^30, is that right? [Edit: just noticed the previous comment had already mentioned pypy] > I'm aware it is 2x slower on non-Apple CPUs. Do you know why? As far as I can tell, HVM has no aarch64/Apple-specific code. Could it be because Apple Silicon has wider decode blocks? > can be underwhelming, and I understand if you don't believe on my words I don't think anyone wants to rain on your parade, but extraordinary claims require extraordinary evidence. The work you've done in Bend and HVM sounds impressive, but I feel the benchmarks need more evaluation/scrutiny. Since your main competitor would be Mojo and not Python, comparisons to Mojo would be nice as well. reply LightMachine 15 hours agorootparentThe only claim I made is that it scales linearly with cores. Nothing else! I'm personally putting a LOT of effort to make our claims as accurate and truthful as possible, in every single place. Documentation, website, demos. I spent hours in meetings to make sure everything is correct. Yet, sometimes it feels that no matter how much effort I put, people will just find ways to misinterpret it. We published the real benchmarks, checked and double checked. And then you complained some benchmarks are not so good. Which we acknowledged, and provided causes, and how we plan to address them. And then you said the benchmarks need more evaluation? How does that make sense in the context of them being underwhelming? We're not going to compare to Mojo or other languages, specifically because it generates hate. Our only claim is: HVM2 is the first version of our Interaction Combinator evaluator that runs with linear speedup on GPUs. Running closures on GPUs required colossal amount of correctness work, and we're reporting this milestone. Moreover, we finally managed to compile a Python-like language to it. That is all that is being claimed, and nothing else. The codegen is still abysmal and single-core performance is bad - that's our next focus. If anything else was claimed, it wasn't us! reply jonahx 13 hours agorootparent> I spent hours in meetings to make sure everything is correct. Yet, sometimes it feels that no matter how much effort I put, people will just find ways to misinterpret it. from reply below: > I apologize if I got defensive, it is just that I put so much effort on being truthful, double-checking, putting disclaimers everywhere about every possible misinterpretation. I just want to say: don't stop. There will always be some people who don't notice or acknowledge the effort to be precise and truthful. But others will. For me, this attitude elevates the project to something I will be watching. reply vrmiguel 14 hours agorootparentprevThat's true, you never mentioned Python or alternatives in your README, I guess I got Mandela'ed from the comments in Hacker News, so my bad on that. People are naturally going to compare the timings and function you cite to what's available to the community right now, though, that's the only way we can picture its performance in real-life tasks. > Mojo or other languages, specifically because it generates hate Mojo launched comparing itself to Python and didn't generate much hate, it seems, but I digress In any case, I hope Bend and HVM can continue to improve even further, it's always nice to see projects like those, specially from another Brazilian reply LightMachine 14 hours agorootparentThanks, and I apologize if I got defensive, it is just that I put so much effort on being truthful, double-checking, putting disclaimers everywhere about every possible misinterpretation. Hell this is behind install instructions: > our code gen is still on its infancy, and is nowhere as mature as SOTA compilers like GCC and GHC Yet people still misinterpret. It is frustrating because I don't know what I could've done better reply alfalfasprout 13 hours agorootparentDon't worry about it. Keep at it, this is a very cool project. FWIW on HN people are inherently going to try to actually use your project and so if it's meant to be (long term) a faster way to run X people evaluate it against that implicit benchmark. reply jhawleypeters 11 hours agorootparentprevIntroducing novel ideas and making strong statements will almost always generate some anger and denial. https://paulgraham.com/useful.html reply quikoa 1 hour agorootparentprevPerhaps you can add: \"The codegen is still abysmal and single-core performance is bad - that's our next focus.\" as a disclaimer on the main page/videos/etc. This provides more context about what you claim and also very important what you don't (yet) claim. reply mcintyre1994 1 hour agorootparentprevNaive question: do you expect the linear scaling to hold with those optimisations to single core performance, or would performance diverge from linear there pending further research advancements? reply mgaunard 11 hours agorootparentprevIdentifying what's parallelizable is valuable in the world of language theory, but pure functional languages are as trivial as it gets, so that research isn't exactly ground-breaking. And you're just not fast enough for anyone doing HPC, where the problem is not identifying what can be parallelized, but figuring out to make the most of the hardware, i.e. the codegen. reply Oranguru 9 hours agorootparentThis approach is valuable because it abstracts away certain complexities for the user, allowing them to focus on the code itself. I found it especially beneficial for users who are not willing to learn functional languages or parallelize code in imperative languages. HPC specialists might not be the current target audience, and code generation can always be improved over time, and I trust based on the dev comments that it will be. reply dheera 12 hours agorootparentprev> I'm personally putting a LOT of effort to make our claims as accurate and truthful as possible, in every single place Thank you. I understand in such an early irritation of a language there are going to be lots of bugs. This seems like a very, very cool project and I really hope it or something like it is successful at making utilizing the GPU less cumbersome. reply KingOfCoders 5 hours agorootparentprevThe claim from the website is \"automatically achieves near-ideal speedup\". reply CyberDildonics 15 hours agorootparentprevThe only claim I made is that it scales linearly with cores. Nothing else! The other link on the front page says: \"Welcome to the Parallel Future of Computation\" reply LightMachine 14 hours agorootparentScaling with cores is synonym of parallel. reply Dylan16807 12 hours agorootparent\"Future\" has some mild speed implications but it sounds like you're doing reasonably there, bug nonwithstanding. reply singhblom 12 hours agorootparentIt also has \"Not yet\" implications ... reply cjbgkagh 5 hours agorootparentI've always taken 'Welcome to the Future' as the thing being presented is futuristic and exists now in the present. Not 'in the future we will welcome you to the future' - while that is a nice sentiment it's utterly useless. To point out the obvious - of course futuristic things exist in the future and of course I have to wait for the future to happen. reply LightMachine 12 hours agorootparentprevBut it literally says we believe it is the future of parallel computing! If it was faster than GCC today, we would've written present :') reply EgoIncarnate 6 hours agorootparentI think people might interpret something claiming to be the \"Future of Parallel Computing\" as something that is just waiting on adoption. Perhaps \"Towards the Future of Parallel Computing\"... reply IshKebab 15 hours agorootparentprevI think the issue is that there is the implicit claim that this is faster than some alternative. Otherwise what's the point? If you add some disclaimer like \"Note: Bend is currently focused on correctness and scaling. On an absolute scale it may still be slower than single threaded Python. We plan to improve the absolute performance soon.\" then you won't see these comments. Also this defensive tone does not come off well: > We published the real benchmarks, checked and double checked. And then you complained some benchmarks are not so good. Which we acknowledged, and provided causes, and how we plan to address them. And then you said the benchmarks need more evaluation? How does that make sense in the context of them being underwhelming? reply LightMachine 14 hours agorootparentRight below install instructions, on Bend's README.md: > But keep in mind our code gen is still on its infancy, and is nowhere as mature as SOTA compilers like GCC and GHC. Second paragraph of Bend's GUIDE.md: > While cool, Bend is far from perfect. In absolute terms it is still not so fast. Compared to SOTA compilers like GCC or GHC, our code gen is still embarrassingly bad, and there is a lot to improve. That said, it does what it promises: scaling horizontally with cores. Limitations session on HVM2's paper: > While HVM2 achieves near-linear speedup, its compiler is still extremely immature, and not nearly as fast as state-of-art alternatives like GCC of GHC. In single-thread CPU evaluation, HVM2, is still about 5x slower than GHC, and this number can grow to 100x on programs that involve loops and mutable arrays, since HVM2 doesn’t feature these yet. reply IshKebab 13 hours agorootparent> Right below install instructions Yeah exactly. I read most of the readme and watched the demo, but I'm not interested in installing it so I missed this. I would recommend moving this to the first section in its own paragraph. I understand you might not want to focus on this but it's important information and not a bad thing at all. reply LightMachine 12 hours agorootparentThat's a great feedback actually, thank you. We'll add the disclaimer before the install instructions instead! reply presentation 7 hours agorootparentRelatedly, the homepage itself doesnt make it obvious it’s still alpha, or not ready, or not actually going to speed up your code this moment - claims like “automatically achieves near-ideal speedup, up to 1000+ threads” - the point is that it parallelizes code, but the word speedup makes it sound like my code will get 1000x faster. I think you can avoid this kind of criticism by setting expectations better - just plastering a banner at the top saying that it’s in early stage development and not optimized, but that the future is bright, for example. The current headline saying it’s the “parallel future of computation” isn’t really enough to make people understand that the future isn’t here yet. Same goes for the README, the fact that it’s not production ready per-se really ought to be at the top to set people’s expectations properly IMO, since a lot of people will not read the whole wall of text and just jump straight into trying it out once they’re on your GitHub page. They’re critical since they are led to have much higher expectations than what actually exists today. That said, this is a cool project and wish you the best in making it really good! reply Twirrim 15 hours agorootparentprevBitonic sort runs in 0m2.035s. Transpiled to c and compiled it takes 0m0.425s. that sum example, transpiled to C and compiled takes 1m12.704s, so it looks like it's just the VM case that is having serious issues of some description! reply glitchc 15 hours agoparentprevI have no dog in this fight, but feel compelled to defend the authors here. Recursion does not test compute, rather it tests the compiler's/interpreter's efficiency at standing up and tearing down the call stack. Clearly this language is positioned at using the gpu for compute-heavy applications and it's still in its early stages. Recursion is not the target application and should not be a relevant benchmark. reply light_hue_1 12 hours agorootparentIt's the author's own benchmark, but it shows the system doesn't work. Recursion isn't hard to eliminate for pure functions; there's nothing inherently wrong with it. The authors made obviously false claims. That this is an extremely fast implementation. When it's not. That's really poor form. reply Twirrim 10 hours agorootparentOkay, no. I know I called out performance in my post, but that was just from my observations. It surprised me to see something be that much slower than pure python. If you show me a near-python code example in a new language, as someone who mostly writes python code, I'm going to go and write it in python and see how it compares performance wise. The authors never made any kind of false claims at all. You're reading a lot in to both their README and my post. They've updated the README for a bit of clarity, but even re-reading the README as it was when I looked this morning (and even a few from before) it hasn't claimed to be fast. The claims are all related to the features that it does have, around parallelisation. reply light_hue_1 10 hours agorootparentI don't get it. Are people on HN so completely ignorant of even the most basic CS101 concepts? That's not how complexity theory works at all. If your constants are massive you can make anything look like it scales well. Imagine a compiler that adds in a very large sleep that's inversely proportional to the number of cores. There you go. My compiler now emits code that scales linearly. Of course it's very slow. Where do I pick up my Turing award? I never thought that CS education was this bad. reply rowanG077 12 hours agorootparentprevWhere did he claim it is fast? As far as I can see the only claim is that it scales linearly with cores. Which it actually seems to do. reply light_hue_1 12 hours agorootparentThey show benchmarks with massive performance improvements. That clearly implies that the system is fast. Where's the disclaimer that this performance is worse than Python but eats up an entire massive GPU? The readme is also blatantly lies: \"It is not the kind of algorithm you'd expect to run fast on GPUs.\" Bitonic sort on GPUs is a thing and it performs well. The gaslighting is just amazing here. reply flockonus 9 hours agorootparentI'll give you the benefit of the doubt in case README changed, but here's the benchmark it claims, currently, against it's own execution modes: CPU, Apple M3 Max, 1 thread: 12.15 seconds CPU, Apple M3 Max, 16 threads: 0.96 seconds GPU, NVIDIA RTX 4090, 16k threads: 0.21 seconds The README mentions \"fast\" in 2 places, none of which is comparing to other languages. reply EgoIncarnate 6 hours agorootparentprevYou're missing some context, it's not bitonic sort itself that would present an issue with GPUs, it's the \"with immutable tree rotations\" part, which in a naive implementation would imply some kind of memory management that would have trouble scaling to thousands of cores. reply rowanG077 11 hours agorootparentprevYes and those benchmarks are real. Showing linear speed up in the number cores when writing standard code is a real achievement. If you assumed that somehow means this is a state of the art compiler with super blazing performance is on no one but you. The readme lays it out very clearly. reply light_hue_1 10 hours agorootparentI'm astounded by the level of ignorance of basic CS101 principles shown in this thread. You've clearly never taken a class on parallel computing or complexity theory? Geez. HN is decaying. reply ewild 9 hours agorootparentthe irony in you blasting all over this thread is that you dont know how it even works. You have 0 idea if their claims of scaling linearly are causing bottlenecks in other places as you state, if you read actual docs on this its clear that the actaul \"compiler\" part of the compiler was put on the backburner while the parallellization was figured out and as that is now done a bunch of optimizations will come in the next year reply tinyspacewizard 23 minutes agoparentprevPython is really bad at recursion (part of why it's not appropriate for functional programming), so perhaps an unfair benchmark? A Pythonic implementation would use loops and mutation. reply fulafel 4 hours agoparentprev\"Thread\" term in GPUs and CPUs mean different things, it's more like a SIMD lane in GPUs. A bit like ISPC can compile your code so there's eg 32 invocations of your function per CPU thread running on the same time (if you're using 16-bit datums on AVX512), and you could have 2048 executions going on after multiplying up 32 cores * 2 SMT threads/core * 32 compiler executions. reply metadat 8 hours agoparentprevWhy `+0`, is this not a pointless no-op? reply pests 4 hours agorootparentYes, but when looking at the source it's more obvious this is a repeating pattern. \"Hey, I'm accessing the 0th element here, just want to make that clear\" Without the +0, that statement looks disconnected from the +1 even though conceptually its the same. Say somebody adds some special marker/tombstone/whatever into element 0 and now all those additions need to be bumped up by one. Someone else may go and see the +1, +2, +3 and just change them to +2, +3 +4, etc while completely missing the lone variable by itself as its visually dissimilar. Ive usually seen it used in longer lists of statements. It also keeps everything lined up formatting wise. reply vegadw 15 hours agoprevA lot of negativity in these threads. I say ~cudas~ kudos to the author for getting this far! The only similar project I'm aware of is Futhark, and that's haskell-y syntax - great for some people, but to the general class of C/C++/Python/Js/Java/etc. devs pretty arcane and hard to work with. My biggest complaint with this is, unlike Futhark, it only targets Cuda or multi-core. Futhark which can target OpenCL, Cuda, ISPC, HIP, sigle core CPU, or multi core CPU. The performance problems others are pointing out I'm certain can be tackled. reply pjmlp 13 hours agoparentChapel has a decent use in HPC. Also NVidia has sponsored variants of Haskell, .NET, Java, Julia on CUDA, have a Python JIT and are collaborating with Mojo folks. reply MarcusE1W 4 hours agoparentprevParaSail also goes into that direction https://github.com/parasail-lang/parasail. Made by the designer for Ada since 1995, Tucker Taft. Some of the parallel features of ParaSail made it into Ada 2022. reply neonsunset 13 hours agoparentprevTake a look at ILGPU. It's very nice and has been around for a long time! (just no one knows about it, sadly) Short example: https://github.com/m4rs-mt/ILGPU/blob/master/Samples/SimpleM... Supports even advanced bits like inline PTX assembly: https://github.com/m4rs-mt/ILGPU/blob/master/Samples/InlineP... reply CorrectingYou 14 hours agoprevOP comes around with some of the coolest things posted in HN recently, and all he gets is extensive criticism, when it is clear that this is an early version :/ reply imranq 6 hours agoparentI think HN is a community where people want to post something novel or new. When someone wants to post a kudos, most likely they'll upvote someone else instead of posting yet another \"awesome job\" (even if it is certainly warranted). Criticism instead can be endlessly diverse since there's usually only limited number ways to get it right, but plenty to get wrong. In the end, HN comments fall prey to this truth and you see a handful of positive comments, with the majority being criticisms or \"I wish this did X\". No one person is to blame. Its just the culture of technologists today. reply eating555 5 hours agoparentprevI would be pretty appreciated if people criticize my project. That is how you grow. If people tend hide cruel truth behind applause, the world would just crumbled. reply diego_sandoval 4 hours agorootparentMy observation is that most criticism is useless, because people don't understand why you did things the way you did them. If you explain why, they either still don't understand, or don't agree. If the first iPhone had been presented on HN/Reddit/Twitter, everyone would criticize the lack of physical keyboard. reply robocat 3 hours agorootparentprevWhat you appreciate has little to do with whether we should assume others are thick-skinned. If someone has always been knocked down they will struggle to positively accept criticism regardless of how well meant it might be. reply swayvil 11 hours agoparentprevThe coolest things are often the most difficult to understand. Difficult to understand is often threatening. Criticism is a popular response to threat and is the form of reply that requires the least understanding. reply riku_iki 10 hours agorootparentit also could be half cooked and that's why criticism arrives. reply swayvil 10 hours agorootparentLike, on a bus? reply metadat 8 hours agoparentprevCorrection for you - This is patently false, OP has had three hits -- this one, and two one hundred pointers out of 100-200 submissions. P.s. it seems rather likely the op is Victor Taelin, they mostly submit his tweets and gists. Who are you rooting for, exactly, newcomer? P.p.s. Victor Taelin just happens to be the most recent committer on this submission, imagine that. https://news.ycombinator.com/item?id=35363400 reply foota 7 hours agorootparentWe're a bit off-topic, but there's no requirement that your account be associated with your identity, especially when the op is pretty clearly involved with the project (as opposed to if they were claiming not to be or something). reply LightMachine 6 hours agorootparentprevI have no idea what you're trying to convey, but I'm Victor Taelin. Also very cool comment on that thread, hypothesizing on whether we'd be able to ever run it on GPUs. We did it! That is what we're announcing today. reply metadat 6 hours agorootparentGreat, thanks for clarifying. reply andrewp123 14 hours agoprevI just wanted to comment on how good the homepage is - it's immediately clear what you do. Most people working with \"combinators\" would feel a need to use lots of scary lingo, but OP actually shows the simple idea behind the tool (this is the opposite take of most academics, who instead show every last detail and never tell you what's going on). I really appreciate it - we need more of this. reply topspin 8 hours agoparentI'm ashamed that I didn't think to write this. Well deserved praise. reply delu 16 hours agoprevTen years ago, I took a course on parallel algorithms (15-210 at CMU). It pitched parallelism as the future of computing as Moore's law would hit inevitable limits. I was sold and I was excited to experiment with it. Unfortunately, there weren't many options for general parallel programming. Even the language we used for class (SML) wasn't parallel (there was a section at the end about using extensions and CUDA but it was limited from what I recall). Since then, I was able to make some experiments with multithreading (thanks Rust) and getting very creative with shaders (thanks Shadertoy). But a general parallel language on the GPU? I'm super excited to play with this! reply shwestrick 14 hours agoparentNowadays 210 is actually parallel! You can run 210-style code using MaPLe (https://github.com/MPLLang/mpl) and get competitive performance with respect to C/C++. If you liked 210, you might also like https://futhark-lang.org/ which is an ML-family language that compiles to GPU with good performance. reply amelius 11 hours agorootparentHuh, the Maple name is already used by a well known computer algebra project. https://en.wikipedia.org/wiki/Maple_(software) reply Rodeoclash 12 hours agoparentprevThe trend towards multiple cores in machines was one of the reasons I decided to learn Elixir. reply jjovan1 2 hours agoprevWhy so much negativity? An angry crowd sounded more like bots trying to test OP's intelligence by exploiting the ReadMe file imperfections while trying to change the context and intent of the post. It's so ignorant and brutal. They spent hours arguing without taking 2 minutes to properly read the ReadMe file.OP is a one man's show and now they all want to piss on OP. Keep going OP! reply praetor22 11 hours agoprevLook, I understand the value proposition and how cool it is from a theoretical standpoint, but I honestly don't think this will ever become relevant. Here are some notes from my first impressions and after skimming through the paper. And yes, I am aware that this is very very early software. 1. Bend looks like an extremely limited DSL. No FFI. No way of interacting with raw buffers. Weird 24bit floating point format. 2. There's a reason why ICs are not relevant: performance is and will always be terrible. There is no other way to put it, graph traversal simply doesn't map well on hardware. 3. The premise of optimal reduction is valid. However, you still need to write the kernels in a way that can be parallelized (ie. no data dependencies, use of recursion). 4. There are no serious examples that directly compare Bend/HVM code with it's equivalent OMP/CUDA program. How am I suppose to evaluate the reduction in implementation complexity and what to expect on performance. So many claims, so little actual comparisons. 5. In the real world of high performance parallel computing, tree-like structures are non-existent. Arrays are king. And that's because of the physical nature of how memory works on a hardware level. And do you know what works best on mutable contiguous memory buffers ? Loops. We'll see when HVM will implement this. In the end, what we currently have is half-baked language that is (almost) fully isolated from external data, extremely slow, a massive abstraction on the underlying hardware (unutilised features: multilevel caches, tensor cores, simd, atomics). I apologize if this comes out as harsh, I still find the technical implementation and the theoretical background to be very interesting. I'm simply not (yet) convinced of its usefulness in the real world. reply LightMachine 9 hours agoparentThanks for the feedback. Some corrections: We do use multi-level caching, and you can achieve 5x higher performance by using it correctly. FFI is already implemented, just not published, because we want to release it with graphics rendering, which I think will be really cool. Haskell/GHC uses a graph and trees too, and nobody would say it is not practical of useful. And while it is true that arrays are king, there are many SOTA algorithms that are implemented in Haskell (including compilers, type-checkers, solvers) because they do not map well to arrays at all. The main reason ICs are not fast is that nobody ever has done low-level optimization work over it. All previous implementations were terribly inefficient. And my own work is too, because I spent all time so far trying to get it to run *correctly* on GPUs, which was very hard. As you said yourself, there aren't even loops yet. So, how can we solve that? By adding the damn loops! Or do you think there is some inherent limitation preventing us to do that? If you do, you'll be surprised. HVM2 is finally a correct algorithm that scales. Now we'll optimize it for the actual low-level performance. reply physicsguy 2 hours agoparentprevRe: 5, trees are fairly widely used (though not as most CS people would implement them) with Morton or H index ordering in things like the Fast Multipole and Barnes Hut algorithms which reduce O(n^2) pair wise ops to O(n) and O(n log n) respectively. BH more common in Astro, FMM in chemical molecular dynamics. reply ziedaniel1 16 hours agoprevVery cool idea - but unless I'm missing something, this seems very slow. I just wrote a simple loop in C++ to sum up 0 to 2^30. With a single thread without any optimizations it runs in 1.7s on my laptop -- matching Bend's performance on an RTX 4090! With -O3 it vectorizes the loop to run in less than 80ms. #includeint main() { int sum = 0; for (int i = 0; i(I wonder if I should have waited a little bit more before actually posting it) No. You built something that’s pretty cool. It’s not done yet, but you’ve accomplished a lot! I’m glad you posted it. Thank you. Ignore the noise and keep cooking! reply phkahler 7 hours agorootparentprev>> Bend has no tail-call optimization yet. I've never understood the fascination with tail calls and recursion among computer science folks. Just write a loop, it's what it optimises to anyway. reply fulafel 3 hours agorootparentComputer science traditionally focuses on algorithms. Divide-and-conquer algorithms are frequently much more clearly expressed as recursion. Quicksort is the classic example, also various tree operations. reply nneonneo 15 hours agorootparentprevIf they’re low-hanging fruit, why not do that before posting about it publicly? All that happens is that you push yourself into a nasty situation: people get a poor first impression of the system and are less likely to trust you the second time around, and in the (possibly unlikely) event that the problems turn out to be harder than you expect, you wind up in the really nasty situation of having to deal with failed expectations and pressure to fix them quickly. reply LightMachine 15 hours agorootparentI agree with you. But then there's the entire \"release fast, don't wait before it is perfect\". And, then, there's the case that people using it will guide us to iteratively building what is needed. I'm still trying to find that balance, it isn't so easy. This release comes right after we finally managed to compile it to GPUs, which is a huge milestone people could care about - but there are almost no micro-optimizations. reply naasking 15 hours agorootparentprevThat's how development under open source works. You can't please everyone. reply nneonneo 15 hours agorootparentThere’s a big difference between developing something and announcing loudly that you have something cool; the developers have done the latter here. reply vrmiguel 14 hours agorootparentI think it's clearly pretty cool even if not as fast as people expect it to be reply LightMachine 12 hours agorootparentprevDude we're running unrestricted recursion and closures on GPUs! If that's not cool to you, I apologize, but that mind-blowingly cool to me, and I wanted to share it, even though the codegen is still initial. Hell I was actually going to publish it with the interpreters only, but I still coded an initial compiler because I thought people would like to see where it could go :( reply Ar-Curunir 14 hours agorootparentprevThats completely unfair. They have developed something cool, just with not all the holes plugged. reply trenchgun 13 hours agorootparentprevIt is pretty cool milestone achieved, just not production ready. reply adw 11 hours agorootparentThis is very cool and it's being treated unfairly, though it's also obviously not ready for prime time; it's an existence proof. To illustrate that, many people on here have been losing their mind over Kolomogorov-Arnold Networks, which are almost identically positioned; interesting idea, kind of cool, does what the paper claims, potentially useful in the future, definitely not any use at all for any real use-case right now. (In part that's probably because the average understanding of ML here is _not_ strong, so there's more deference and credulousness around those claims.) reply nneonneo 15 hours agoparentprevYou might want to double check with objdump if the loop is actually vectorized, or if the compiler just optimizes it out. Your loop actually performs signed integer overflow, which is UB in C++; the compiler could legally output anything. If you want to avoid the UB, declare sum as unsigned (unsigned integer overflow is well-defined); the optimization will still happen but at least you’ll be guaranteed that it’ll be correct. reply ziedaniel1 14 hours agorootparentI did make sure to check before posting. Good point about the signed integer overflow, though! reply molenzwiebel 15 hours agoparentprevIf compiled with -O3 on clang, the loop is entirely optimized out: https://godbolt.org/z/M1rMY6qM9. Probably not the fairest comparison. reply LightMachine 15 hours agorootparentExactly, this kind of thing always happens with these loops, which is why I think programs that allocate are fairer. But then people point out that the C allocator is terrible, so we can't make that point :') reply ziedaniel1 14 hours agorootparentprevI used GCC and checked that it wasn't optimized out (which actually surprised me!) reply rroriz 16 hours agoparentprevI think the point is that Bend in a much higher level than C++. But to be fair: I also may be missing the point! reply gslepak 15 hours agorootparentThe point is that Bend parallelizes everything that can be parallelized without developers having to do that themselves. reply 5- 16 hours agorootparentprevhere is the same loop finishing in one second on my laptop, single-threaded, in a very high-level language, q: q)\\t sum til floor 2 xexp 30 1031 reply Arch485 12 hours agoprevI want to congratulate the author on this, it's super cool. Making correct automatic parallelization is nothing to sneeze at, and something you should absolutely be proud of. I'm excited to see how this project progresses. reply MrLeap 13 hours agoprevThis is incredible. This is the kind of work we need to crack open the under utilized GPUs out there. I know LLMs are all the rage, but there's more gold in them hills. reply anon291 10 hours agoparentExcept... it's not. Coming from a Haskell background and following the author since the early days, I think his work is excellent w.r.t Interaction Combinators and Nets. However, to do LLM work you need to cooperate with the chip, which means doing things in the manner most expeditious to the intricacies of Computer Architecture. That's not what this does. I don't see how Bend would modify its runtime to take advantage of all the things that modern GPU-based BLAS implementations do (which is what I currently do), but would love to be surprised. As a whole, the speedups claimed are not actually that great. Going from 1 core to 16k cores increases performance by 50x. That's not actually very good. Like, I really truly love what the author has contributed to functional languages and Interaction Nets. He has good ideas, but while it's cool that this can be done, things like LLMs require very practical tuning. Finally, the author has a history of making fantastical claims. Again, it's true there is a speedup, but in my view, this is like making an extremely slow language and then optimizing it and then announcing that you've figure out how to improve your language's performance by 50x. While true, it neglects the fact it was very slow to begin with. reply LightMachine 10 hours agorootparentYou're comparing CPU cores to GPU cores! It is \"only\" 50x because a single GPU core is 100x weaker than a CPU core! Within CUDA cores, it is actually a linear speedup! It does 2k MIPS with 1 CUDA core, and ~28000 MIPS with 16k CUDA cores. If we double the performance of single-core GPU evaluation, we almost double the performance with 16k cores! reply yetihehe 17 hours agoprevBend looks like a nice language. > That's a 111x speedup by doing nothing. No thread spawning, no explicit management of locks, mutexes. We just asked bend to run our program on RTX, and it did. Simple as that. Note that, for now, Bend only supports 24-bit machine ints (u24), thus, results are always mod 2^24. Ahh, not even 32bit? Hmm, that seems pretty arbitrary for someone not accustomed to gpu's and wanting to solve some problems requiring 64 bits (gravitational simulation of solar system at millimeter resolution could use ~58bit ints for position). reply LightMachine 17 hours agoparentWe will have 64-bit boxed numbers really soon! As in, next month, or earlier if users find this to be a higher priority. reply yetihehe 17 hours agorootparentWhat other types are you planning? Maybe some floats (even if only on cpu targets, would be nice). reply LightMachine 12 hours agorootparentImmutable textures and strings. Perhaps actual mutable arrays. Many numeric types like F64, U64, I64. And some vector types like F16x4. reply Archit3ch 15 hours agoparentprevIs there a platform with native hardware u64? Maybe some FPGA? reply Archit3ch 15 hours agorootparentSorry, meant u24. reply ruste 18 hours agoprevBeen watching your development for a while on Twitter. This is a monumental achievement and I hope it gets the recognition it deserves. reply npalli 11 hours agoprevIs the recursive sum the best function to show multi-threading or GPU speedups? Seems unlikely. FWIW, i ported the python example to Julia and it ran in about 2.5 seconds the same as the C++ version. Pure python 3.12 took 183 seconds. function sum(depth, x) if depth == 0 return x else fst = sum(depth-1, x*2+0) snd = sum(depth-1, x*2+1) end return fst + snd end println(sum(30,0)) reply robust-cactus 12 hours agoprevThis is awesome and much needed. Keep going, forget the overly pedantic folks, the vision is great and early results are exciting. reply gsuuon 13 hours agoprevCongrats on the HVM2 launch! Been following for a while, excited to see where this project goes. For others who are lost on the interaction net stuff, there was a neat show hn that gave a more hands-on interactive intro: https://news.ycombinator.com/item?id=37406742 (the 'Get Started' writeup was really helpful) reply klabb3 16 hours agoprevThis is very exciting. I don’t have any GPU background, but I have been worrying a lot about CUDA cementating itself in the ecosystem. Here devs don’t need CUDA directly which would help decoupling the ecosystem from cynical mega corps, always good! Anyway enough politics.. Tried to see what the language is like beyond hello world and found the guide[1]. It looks like a Python and quacks like a Haskell? For instance, variables are immutable, and tree-like divide and conquer data structures/algorithms are promoted for getting good results. That makes sense I guess! I’m not surprised to see a functional core, but I’m surprised to see the pythonic frontend, not that it matters much. I must say I highly doubt that it will make it much easier for Python devs to learn Bend though, although I don’t know if that’s the goal. What are some challenges in programming with these kind of restrictions in practice? Also, is there good FFI options? [1]: https://github.com/HigherOrderCO/bend/blob/main/GUIDE.md reply mathiasgredal 13 hours agoparentWe have a replacement for CUDA, it is called C++17 parallel algorithms. It has vendor support for running on the GPU by Intel, AMD and NVIDIA and will also run on all your cores on the CPU. It uses the GPU vendors compiler to convert your C++ to something that can natively run on the GPU. With unified memory support, it becomes very fast to run computations on heap allocated memory using the GPU, but implementations also support non-unified memory Vendor support: - https://www.intel.com/content/www/us/en/developer/articles/g... - https://rocm.blogs.amd.com/software-tools-optimization/hipst... - https://docs.nvidia.com/hpc-sdk/archive/20.7/pdf/hpc207c++_p... reply notfed 16 hours agoprevThis is really, really cool. This makes me think, \"I could probably write a high performance GPU program fairly easily\"...a sentence that's never formed in my head. reply developedby 16 hours agoparentThat's the main idea! reply davidw 17 hours agoprevAs a resident of Bend, Oregon... it was kind of funny to read this and I'm curious about the origin of the name. reply developedby 17 hours agoparentBending is an operation similar to folding, both in real life and in the language. While fold is recursive on data, bend is recursive on a boolean condition (like a pure while that supports multiple branching recursion points). I was actually looking forward to seeing someone from Bend to make a comment like this reply bytK7 17 hours agoparentprevAs a fellow resident of Bend I felt the same way when I saw this. reply noumenon1111 17 hours agorootparentAs a native Bendite but not current Bend resident, seeing that word with a capital letter always makes me smell juniper and sagebrush a little bit. reply blinded 12 hours agoparentprevThought the same thing! reply alex_lav 16 hours agoparentprevTotally off topic but I'll be driving there later this afternoon. Hoping it's as beautiful as last time! reply davidw 15 hours agorootparentIf you're going to be here for a bit (I am heading out of town on a bike trip for a few days), always happy to grab a beer with fellow HN people! reply alex_lav 15 hours agorootparentUnfortunately just the weekend. I'm just in Portland tho so will definitely be back. reply smusamashah 11 hours agoprevI have no interest in this tech as it's apparently for backend stuff and not actually rendering things by itself. But the demo gif is probably the best I have seen in a Github readme. I watched it till the end. It was instantly engaging. I wanted to see the whole story unfold. reply darlansbjr 17 hours agoprevWould a compiler be faster by using HVM? Would love to see a fully parallel version of typescript tsc reply zmmmmm 5 hours agoprevReminds me a little bit of Concurnas [0] which sadly seemed to get abandoned right at the point when it was nearly viable. [0] https://concurnas.com/ reply egnehots 16 hours agoprevthe interesting comparison nowadays would be against mojo: https://www.modular.com/max/mojo reply ZitchDog 10 hours agoparentI think this is quite different- I don’t think mojo runs on the GPU unless I am mistaken. reply witherk 10 hours agorootparentBeing able to compile to different hardware including GPUs and TPUs seems to be one of the core goals of Mojo based off what Chris Lattner was saying in his Lex Friendman interview. It doesn't seem to come up much on Modular website though, so I can see why you would think that. reply KingOfCoders 5 hours agoprevThe website claims \"automatically achieves near-ideal speedup\" 12x for 16x threads 51x for 16.000x threads Can someone point me to a website where it explains that this is the \"ideal speedup\"? Is there a formula? reply andersa 2 hours agoparentIt's not. reply mbforbes 12 hours agoprevCongratulations on the launch and hard work so far! We need projects like this. Great readme and demo as well. Every time I try to write shaders, or even peek through my fingers at CUDA C(++) code, I recoil in disbelief that we don't have high level programming yet on the GPU. I can't wait until we do. The more great projects attacking it the better in my book. reply temp123789246 11 hours agoprevCongrats! I’ve been watching HVM for a while and think it’s extremely cool. My intuition is that this will eventually be a really big deal. reply KingOfCoders 5 hours agoprevHas someone written the example in \"native\" GPU (C/Cuda) to compare performance? reply highfrequency 16 hours agoprev> CPU, Apple M3 Max, 1 thread: 3.5 minutes > CPU, Apple M3 Max, 16 threads: 10.26 seconds Surprised to see a more than linear speedup in CPU threads. What’s going on here? reply LightMachine 15 hours agoparentI believe the single-core version was running slower due to the memory getting full. The benchmark was adding 2^30 numbers, but HVM2 32-bit has a limit of 2^29 nodes. I've re-ran it with 2^28 instead, and the numbers are `33.39 seconds` (1 core) vs `2.94 seconds` (16 cores). You can replicate the benchmark in an Apple M3 Max. I apologize for the mistake. reply Archit3ch 15 hours agoparentprevMore cores = more caches? reply ek_cpp 8 hours agoprevVAMO BRAZIL CARALHOOO! MUITO FODA VAI TOMAR NO CUUU reply netbioserror 11 hours agoprevSo HVM finally yields fruit. I've been eagerly awaiting this day! Bend seems like a very suitable candidate for a Lispy S-expression makeover. reply britannio 16 hours agoprevIncredible feat, congratulations! reply thinking_banana 10 hours agoprevIt's pretty cool that you *actually* built this necessary Developer interface aimed towards accessibility of HPC! reply shadowpho 17 hours agoprevWow this is very impressive! reply funny_name 13 hours agoprevWhat kind of software would this language be good for? I assume it's not the kind of language you'd use for web servers exactly. reply trenchgun 13 hours agoparentErlang-like actor models would be well suited, so yeah, you could use it for web servers (assuming they are able to finish the language). It's a general purpose high level programming language. reply exitheone 16 hours agoprevThis seems pretty cool! Question: Does this take into account memory bandwidth and caches between cores? Because getting them wrong can easily make parallel programs slower than sequential ones. reply 3abiton 10 hours agoprev> That's a 57x speedup by doing nothing. Okay, I'll have what you're having. reply kerkeslager 13 hours agoprevThis looks like the language I've wanted for a long time. I'm excited to see how this plays out. reply KeplerBoy 17 hours agoprevWhat's going on with the super-linear speedup going from one thread to all 16? 210 seconds (3.5 minutes) to 10.5 seconds is a 20x speedup, which isn't really expected. reply LightMachine 17 hours agoparentthe single-thread case ran a little slower than it should on this live demo due to a mistake on my part: `run` redirected to the Rust interpreter, rather than the C interpreter. the Rust one is a little bit slower. the numbers on the site and on all docs are correct though, and the actual speedup is ~12x, not ~16x. reply KeplerBoy 17 hours agorootparentThanks for the explanation and the cool project. I will give bend a shot on some radar signal processing algorithms. reply LightMachine 15 hours agoparentprevI apologize, I gave you the wrong answer. I thought you was talking about the DEMO example, which ran ~30% slower than expected. Instead, you were talking about the README, which was actually incorrect. I noticed the error and edited it. I explained the issue in another comment. reply byteknight 17 hours agoparentprevIts possible to see such scaling if involving any level of cache or I/O. reply croemer 14 hours agoprevDupe of https://news.ycombinator.com/item?id=40387394 and https://news.ycombinator.com/item?id=40383196 reply wolfspaw 13 hours agoprevNice! Python-like + High-performance. And, Different from Mojo, its Fully Open-Source. reply markush_ 13 hours agoprevExciting project, congrats on the release! reply JayShower 8 hours agoprevThis is really cool! reply jgarzon 5 hours agoprevVery nice! reply kkukshtel 17 hours agoprevHonestly incredible, and congrats on the release after what looks like an insane amount of work. reply chc4 14 hours agoprev24bit integers and floats, no array datatype, and a maximum 4GB heap of nodes are very harse restrictions, especially for any workloads that would actually want to be running on a GPU. The limitations in the HVM2 whitepaper about unsound evaluation around closures and infinite loops because it is evaluating both sides of a conditional without any short circuiting are also extremely concerning. Before you reply \"these are things we can address in the future\": that doesn't matter. Everyone can address everything in the future. They are currently hard technical barriers to it's use, with no way of knowing the level of effort that will require or the knock-on effects, especially since some of these issues have been \"we can fix that later\" for ten years. I also highly recommend changing your benchmark numbers from \"interactions per second\" to a standard measurement like FLOPS. No one else on earth knows how many of those interactions are pure overhead from your evaluation semantics, and not doing useful work. They come across as attempting to wow an audience with high numbers and not communicating an apples to apples comparison with other languages. reply LightMachine 14 hours agoparentSo use a metric that makes absolutely no sense on given domain, instead of one that is completely correct, sensible, accurate, stablished on the literature, and vastly superior in context? What even is a FLOPS in the context of Interaction Net evaluation? These things aren't even interchangeable. reply hahajahen 9 hours agorootparentThe fact that you don’t know the answer to this question, and don’t even seem to think it is relevant, is chilling. People want to be able to ground your work—which you are claiming is the “parallel future of computation”—in something familiar. Insulting them and telling them their concerns are irrelevant just isn’t going to work. I would urge you to think about what a standard comparison versus Haskell would look like. Presumably it would be something that dealt with a large state space, but also top down computation (something you couldn’t easily do with matrices). Big examples might include simply taking a giant Haskell benchmark (given the setting of inets it seems like a natural fit) that is implemented in a fairly optimal way—-both algorithmically and also wrt performance—-and compare directly on large inputs. Sorry to trash on you here, not trying to come across as insulting, but I agree that “reductions per second” is meaningless without a nuanced understanding of the potentially massive encoding blowup that compilation introduces. We want to believe, but the claims here are big reply Archit3ch 15 hours agoprevPure functions only? This is disappointing. Furthermore, it invites a comparison with JAX. reply light_hue_1 16 hours agoprev [–] Massive promises of amazing performance but they can't find one convincing example to showcase. It's hard to see what they're bringing to the table when even the simplest possible Haskell code just as fast on my 4 year old laptop with an ancient version of GHC (8.8). No need for an RTX 4090. module Main where sum' :: Int -> Int -> Int sum' 0 x = x sum' depth x = sum' (depth - 1) ((x \\* 2) + 0) + sum' (depth - 1) ((x \\* 2) + 1) main = print $ sum' 30 0 Runs in 2.5s. Sure it's not on a GPU, but it's faster! And things don't get much more high level. If you're going to promise amazing performance from a high level language, I'd want to see a comparison against JAX. It's an improvement over traditional interaction nets, sure! But interaction nets have always been a failure performance-wise. Interaction nets are PL equivalent of genetic algorithms in ML, they sound like a cool idea and have a nice story, but then they always seem to be a dead end. Interaction nets optimize parallelism at the cost of everything else. Including single-threaded performance. You're just warming up the planet by wasting massive amounts of parallel GPU cores to do what a single CPU core could do more easily. They're just the wrong answer to this problem. reply LightMachine 14 hours agoparent [–] You're wrong. The Haskell code is compiled to a loop, which we didn't optimize for yet. I've edited the README to use the Bitonic Sort instead, on which allocations are unavoidable. Past N=20, HVM2 performs 4x faster than GHC -O2. reply light_hue_1 12 hours agorootparent [–] What? I ran your example, from your readme, where you promise a massive performance improvement, and you're accusing me of doing something wrong? This is exactly what a scammer would say. I guess that's the point here. Scam people who don't know anything about parallel computing by never comparing against any other method? reply LightMachine 12 hours agorootparentThanks for the feedback! Some clarifications: 1. I didn't accuse you of doing something wrong, just that your claim was wrong! It has been proven that Interaction Combinators are an optimal model of concurrent computation. I also pointed cases where it also achieves practical efficiency, over-performing GHC's highest optimization level. 2. The performance scaling claimed been indeed been achieved, and the code is open for anyone to replicate our results. The machines used are listed on the repository and paper. If you find any trouble replicating, please let me know! 3. We're not selling any product. Bend is Apache-licensed. reply hahajahen 9 hours agorootparentprev [–] The insult against anyone who pushes back a little bit is not a good sign, I agree. From all we can see now, the massive speedups being claimed have zero optimal baselines. I badly would like to identify these. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Bend is a high-level programming language optimized for massively parallel hardware, such as GPUs, offering fast object allocations, higher-order functions, recursion, and continuations.",
      "It runs on the HVM2 runtime, enabling near-linear speedup based on core count, without requiring explicit parallel annotations or manual thread management.",
      "Bend, created by HigherOrderCO.com, streamlines parallel programming by efficiently executing complex algorithms on GPUs and emulating diverse concurrent systems."
    ],
    "commentSummary": [
      "The Bend programming language and its HVM2 implementation are being discussed, focusing on GPU performance versus Python and Mojo.",
      "Users are evaluating benchmarks, linear scaling, compiler efficiency, and Bend's potential applications, with suggestions for clearer disclaimers, single-core optimization, and enhanced code generation.",
      "The automatic parallelization feature of Bend receives both praise and skepticism regarding its practicality and effects on the development community, with concerns raised about technical obstacles and performance assertions in the project."
    ],
    "points": 822,
    "commentCount": 161,
    "retryCount": 0,
    "time": 1715955824
  },
  {
    "id": 40393121,
    "title": "OpenAI's Departures Raise Transparency Concerns",
    "originLink": "https://www.vox.com/future-perfect/2024/5/17/24158478/openai-departures-sam-altman-employees-chatgpt-release",
    "originBody": "Filed under: Future Perfect Technology Artificial Intelligence ChatGPT can talk, but OpenAI employees sure can’t Why is OpenAI’s superalignment team imploding? By Kelsey Piper Updated May 17, 2024, 11:20pm EDT Share this story Share this on Facebook Share this on Twitter Share this on Reddit Share All sharing options Share All sharing options for: ChatGPT can talk, but OpenAI employees sure can’t Reddit Pocket Flipboard Email Sam Altman (left), CEO of artificial intelligence company OpenAI, and the company’s co-founder and then-chief scientist Ilya Sutskever, speak together at Tel Aviv University in Tel Aviv on June 5, 2023. Jack Guez/AFP via Getty Images Kelsey Piper is a senior writer at Future Perfect, Vox’s effective altruism-inspired section on the world’s biggest challenges. She explores wide-ranging topics like climate change, artificial intelligence, vaccine development, and factory farms, and also writes the Future Perfect newsletter. This story is part of a group of stories called Finding the best ways to do good. Editor’s note, May 17, 2024, 11:20 pm ET: This story has been updated to include a post-publication statement from OpenAI. On Monday, OpenAI announced exciting new product news: ChatGPT can now talk like a human. It has a cheery, slightly ingratiating feminine voice that sounds impressively non-robotic, and a bit familiar if you’ve seen a certain 2013 Spike Jonze film. “Her,” tweeted OpenAI CEO Sam Altman, referencing the movie in which a man falls in love with an AI assistant voiced by Scarlett Johansson. But the product release of ChatGPT 4o was quickly overshadowed by much bigger news out of OpenAI: the resignation of the company’s co-founder and chief scientist, Ilya Sutskever, who also led its superalignment team, as well as that of his co-team leader Jan Leike (who we put on the Future Perfect 50 list last year). The resignations didn’t come as a total surprise. Sutskever had been involved in the boardroom revolt that led to Altman’s temporary firing last year, before the CEO quickly returned to his perch. Sutskever publicly regretted his actions and backed Altman’s return, but he’s been mostly absent from the company since, even as other members of OpenAI’s policy, alignment, and safety teams have departed. But what has really stirred speculation was the radio silence from former employees. Sutskever posted a pretty typical resignation message, saying “I’m confident that OpenAI will build AGI that is both safe and beneficial…I am excited for what comes next.” Leike ... didn’t. His resignation message was simply: “I resigned.” After several days of fervent speculation, he expanded on this on Friday morning, explaining that he was worried OpenAI had shifted away from a safety-focused culture. Questions arose immediately: Were they forced out? Is this delayed fallout of Altman’s brief firing last fall? Are they resigning in protest of some secret and dangerous new OpenAI project? Speculation filled the void because no one who had once worked at OpenAI was talking. It turns out there’s a very clear reason for that. I have seen the extremely restrictive off-boarding agreement that contains nondisclosure and non-disparagement provisions former OpenAI employees are subject to. It forbids them, for the rest of their lives, from criticizing their former employer. Even acknowledging that the NDA exists is a violation of it. If a departing employee declines to sign the document, or if they violate it, they can lose all vested equity they earned during their time at the company, which is likely worth millions of dollars. One former employee, Daniel Kokotajlo, who posted that he quit OpenAI “due to losing confidence that it would behave responsibly around the time of AGI,” has confirmed publicly that he had to surrender what would have likely turned out to be a huge sum of money in order to quit without signing the document. While nondisclosure agreements aren’t unusual in highly competitive Silicon Valley, putting an employee’s already-vested equity at risk for declining or violating one is. For workers at startups like OpenAI, equity is a vital form of compensation, one that can dwarf the salary they make. Threatening that potentially life-changing money is a very effective way to keep former employees quiet. OpenAI did not respond to a request for comment in time for initial publication. After publication, an OpenAI spokesperson sent me this statement: “We have never canceled any current or former employee’s vested equity nor will we if people do not sign a release or nondisparagement agreement when they exit.” Sources close to the company I spoke to told me that this represented a change in policy as they understood it. When I asked the OpenAI spokesperson if that statement represented a change, they replied, “This statement reflects reality.” All of this is highly ironic for a company that initially advertised itself as OpenAI — that is, as committed in its mission statements to building powerful systems in a transparent and accountable manner. OpenAI long ago abandoned the idea of open-sourcing its models, citing safety concerns. But now it has shed the most senior and respected members of its safety team, which should inspire some skepticism about whether safety is really the reason why OpenAI has become so closed. The tech company to end all tech companies OpenAI has spent a long time occupying an unusual position in tech and policy circles. Their releases, from DALL-E to ChatGPT, are often very cool, but by themselves they would hardly attract the near-religious fervor with which the company is often discussed. What sets OpenAI apart is the ambition of its mission: “to ensure that artificial general intelligence — AI systems that are generally smarter than humans — benefits all of humanity.” Many of its employees believe that this aim is within reach; that with perhaps one more decade (or even less) — and a few trillion dollars — the company will succeed at developing AI systems that make most human labor obsolete. Which, as the company itself has long said, is as risky as it is exciting. “Superintelligence will be the most impactful technology humanity has ever invented, and could help us solve many of the world’s most important problems,” a recruitment page for Leike and Sutskever’s team at OpenAI states. “But the vast power of superintelligence could also be very dangerous, and could lead to the disempowerment of humanity or even human extinction. While superintelligence seems far off now, we believe it could arrive this decade.” Naturally, if artificial superintelligence in our lifetimes is possible (and experts are divided), it would have enormous implications for humanity. OpenAI has historically positioned itself as a responsible actor trying to transcend mere commercial incentives and bring AGI about for the benefit of all. And they’ve said they are willing to do that even if that requires slowing down development, missing out on profit opportunities, or allowing external oversight. “We don’t think that AGI should be just a Silicon Valley thing,” OpenAI co-founder Greg Brockman told me in 2019, in the much calmer pre-ChatGPT days. “We’re talking about world-altering technology. And so how do you get the right representation and governance in there? This is actually a really important focus for us and something we really want broad input on.” OpenAI’s unique corporate structure — a capped-profit company ultimately controlled by a nonprofit — was supposed to increase accountability. “No one person should be trusted here. I don’t have super-voting shares. I don’t want them,” Altman assured Bloomberg’s Emily Chang in 2023. “The board can fire me. I think that’s important.” (As the board found out last November, it could fire Altman, but it couldn’t make the move stick. After his firing, Altman made a deal to effectively take the company to Microsoft, before being ultimately reinstated with most of the board resigning.) But there was no stronger sign of OpenAI’s commitment to its mission than the prominent roles of people like Sutskever and Leike, technologists with a long history of commitment to safety and an apparently genuine willingness to ask OpenAI to change course if needed. When I said to Brockman in that 2019 interview, “You guys are saying, ‘We’re going to build a general artificial intelligence,’” Sutskever cut in. “We’re going to do everything that can be done in that direction while also making sure that we do it in a way that’s safe,” he told me. Their departure doesn’t herald a change in OpenAI’s mission of building artificial general intelligence — that remains the goal. But it almost certainly heralds a change in OpenAI’s interest in safety work; the company hasn’t announced who, if anyone, will lead the superalignment team. And it makes it clear that OpenAI’s concern with external oversight and transparency couldn’t have run all that deep. If you want external oversight and opportunities for the rest of the world to play a role in what you’re doing, making former employees sign extremely restrictive NDAs doesn’t exactly follow. Changing the world behind closed doors This contradiction is at the heart of what makes OpenAI profoundly frustrating for those of us who care deeply about ensuring that AI really does go well and benefits humanity. Is OpenAI a buzzy, if midsize tech company that makes a chatty personal assistant, or a trillion-dollar effort to create an AI god? The company’s leadership says they want to transform the world, that they want to be accountable when they do so, and that they welcome the world’s input into how to do it justly and wisely. But when there’s real money at stake — and there are astounding sums of real money at stake in the race to dominate AI — it becomes clear that they probably never intended for the world to get all that much input. Their process ensures former employees — those who know the most about what’s happening inside OpenAI — can’t tell the rest of the world what’s going on. The website may have high-minded ideals, but their termination agreements are full of hard-nosed legalese. It’s hard to exercise accountability over a company whose former employees are restricted to saying “I resigned.” ChatGPT’s new cute voice may be charming, but I’m not feeling especially enamored. A version of this story originally appeared in the Future Perfect newsletter. Sign up here! Will you support Vox today? We believe that everyone deserves to understand the world that they live in. That kind of knowledge helps create better citizens, neighbors, friends, parents, and stewards of this planet. Producing deeply researched, explanatory journalism takes resources. You can support this mission by making a financial gift to Vox today. Will you join us? One-Time Monthly Annual $5/month $10/month $25/month $50/month Other $ Yes, I'll give $5/month Yes, I'll give $5/month We accept credit card, Apple Pay, and Google Pay. You can also contribute via Next Up In Future Perfect Most Read The Supreme Court decides not to trigger a second Great Depression “I lost trust”: Why the OpenAI team in charge of safeguarding humanity imploded How JoJo Siwa’s “rebrand” got so messy The controversy over Harrison Butker’s misogynistic commencement speech, explained The video where Diddy appears to attack Cassie — and the allegations against him — explained Sign up for the newsletter Today, Explained Understand the world with a daily explainer plus the most compelling stories of the day. Email (required) By submitting your email, you agree to our Terms and Privacy Notice. You can opt out at any time. This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply. For more newsletters, check out our newsletters page. Subscribe The Latest “I lost trust”: Why the OpenAI team in charge of safeguarding humanity imploded By Sigal Samuel Blood, flames, and horror movies: The evocative imagery of King Charles’s portrait By Li Zhou Why the US built a pier to get aid into Gaza By Ellen Ioanes The controversy over Gaza’s death toll, explained By Ellen Ioanes Why a GOP governor’s pardon of a far-right murderer is so chilling By Eric Levitz The video where Diddy appears to attack Cassie — and the allegations against him — explained By Anna North",
    "commentLink": "https://news.ycombinator.com/item?id=40393121",
    "commentBody": "OpenAI departures: Why can’t former employees talk? (vox.com)605 points by fnbr 15 hours agohidepastfavorite551 comments jay-barronville 8 hours agoIt probably would be better to switch the link from the X post to the Vox article [0]. From the article: “““ It turns out there’s a very clear reason for [why no one who had once worked at OpenAI was talking]. I have seen the extremely restrictive off-boarding agreement that contains nondisclosure and non-disparagement provisions former OpenAI employees are subject to. It forbids them, for the rest of their lives, from criticizing their former employer. Even acknowledging that the NDA exists is a violation of it. If a departing employee declines to sign the document, or if they violate it, they can lose all vested equity they earned during their time at the company, which is likely worth millions of dollars. One former employee, Daniel Kokotajlo, who posted that he quit OpenAI “due to losing confidence that it would behave responsibly around the time of AGI,” has confirmed publicly that he had to surrender what would have likely turned out to be a huge sum of money in order to quit without signing the document. ””” [0]: https://www.vox.com/future-perfect/2024/5/17/24158478/openai... reply Buttons840 8 hours agoparentSo part of their compensation for working is equity, and when they leave thay have to sign an additional agreement in order to keep their previously earned compensation? How is this legal? Mine as well tell them they have to give all their money back too. What's the consideration for this contract? reply throwaway598 6 hours agorootparentThat OpenAI are institutionally unethical. That such a young company can be become rotten so quickly can only be due to leadership instruction or leadership failure. reply smt88 5 hours agorootparentLook at Sam Altman's career and tweets. He's a clown at best, and at worst he's a manipulative crook who only cares about his own enrichment and uses pro-social ideas to give himself a veneer of trustworthiness. reply comboy 15 minutes agorootparentI'm surprised at such a mean comment and lots of follow-ups with agreement. I don't know Sam personally, I've only heard him here and there online from before OpenAI days and all I got was a good impression. He seems smart and pretty humble. Apart from all openai drama which I don't know enough to have an opinion, past-openai he also seems to be talking with sense. Since so many people took time to put him down there here can anybody provide some explanation to me? Preferably not just about how closed openai is, but specifically about Sam. He is in a pretty powerful position and maybe I'm missing some info. reply whoistraitor 2 hours agorootparentprevIndeed. I’ve heard first hand accounts that would make it impossible for me to trust him. He’s very good at the game. But I’d not want to touch him with a barge pole. reply orlandrescu 4 hours agorootparentprevAwfully familiar to the other South-African emerald mine inheritor tech mogul. reply kmeisthax 2 hours agorootparentI'm starting to think the relatives of South African emerald mine owners might not be the best people to trust... reply kaycebasques 13 minutes agorootparentprevAre you saying that Altman has family that did business in South African emerald mines? I can't find info about this reply treme 1 hour agorootparentprevPlease. Elon's track record to take tesla from concept car stage to current mass production levels and building SpaceX from scratch is hardly comparable to Altman's track record. reply satvikpendem 1 hour agorootparentIndeed, at least Elon and his teams actually accomplished something worthwhile compared to Altman. reply jajko 22 minutes agorootparentprevBut he is a manager, not an engineer although he sells himself off as such. He keeps smart capable folks around, abuses most of them pretty horribly, and when he intervenes with products its hit and miss. For example latest Tesla Model 3 changes must have been pretty major fuckup and there is no way he didn't ack it all. Plus all self-driving lies and more lies well within fraud territory at this point. Not even going into his sociopathic personality, massive childish ego and apparent 'daddy issues' which in men manifest exactly like him. He is not in day-to-day SpaceX control and it shows. reply hackernewds 2 hours agorootparentprevthe name OpenAI itself reminds me every day of this. reply genevra 20 minutes agorootparentI knew their vision of open source AI wouldn't last but it surprised me how fast it was. reply csomar 2 hours agorootparentprevSocial engineering has been a thing well before computers and the internet... reply raverbashing 2 hours agorootparentprevThe startup world (as the artistic world, the sports world, etc) values healthy transgression of the rules But the line between healthy and unlawful transgression can be a thin line reply andrepd 1 hour agorootparentprevMany easily fooled rubes believe that veneer, so I guess it's working for him. reply ben_w 3 hours agorootparentprevWe already know there's been a leadership failure due to the mere existence of the board weirdness last year; if there has been any clarity to that, I've missed it for all the popcorn gossiping related to it. Everyone including the board's own chosen replacements for Altman siding with Altman seems to me to not be compatible with his current leadership being the root cause of the current discontent… so I'm blaming Microsoft, who were the moustache-twirling villains when I was a teen. Of course, thanks to the NDAs hiding information, I may just be wildly wrong. reply Sharlin 1 hour agorootparentEveryone? What about the board that fired him, and all of those who’ve left the company? It seems to me more like those people are leaving who are rightly concerned about the direction things are going, and those people are staying who think that getting rich outweighs ethical – and possibly existential – concerns. Plus maybe those who still believe they can effect a positive change within the company. With regard to the letter – it’s difficult to say how many of the undersigned simply signed because of social pressure. reply ben_w 1 hour agorootparent> Everyone? What about the board that fired him, I meant of the employees, obviously not the board. Also excluded: all the people who never worked there who think Altman is weird, Elon Musk who is suing them (and probably the New York Times on similar grounds), and the protestors who dropped leaflets on one of his public appearances. > and all of those who’ve left the company? Happened after those events; at the time it was so close to being literally employee who signed the letter saying \"bring Sam back or we walk\" that the rest can be assumed to have been off sick that day even despite the reputation the US has for very limited holidays and getting people to use those holidays for sick leave. > It seems to me more like those people are leaving who are rightly concerned about the direction things are going, and those people are staying who think that getting rich outweighs ethical – and possibly existential – concerns. Plus maybe those who still believe they can effect a positive change within the company. Obviously so, I'm only asserting that this doesn't appear to be due to Altman, despite him being CEO. (\"Appear to be\" is of course doing some heavy lifting here: unless someone wants to literally surveil the company and publish the results, and expect that to be illegal because otherwise it makes NDAs pointless, we're all in the dark). reply jasonm23 5 hours agorootparentprevClearly by design. The most dishonest leadership. reply temporarely 5 minutes agorootparentprevI think we should have the exit agreement (if any) included and agreed to as part of the signing the employment contract. reply eru 7 hours agorootparentprev> What's the consideration for this contract? Consideration is almost meaningless as an obstacle here. They can give the other party a peppercorn, and that would be enough to count as consideration. https://en.wikipedia.org/wiki/Peppercorn_(law) There might be other legal challenges here, but 'consideration' is unlikely to be one of them. Unless OpenAI has idiots for lawyers. reply staticautomatic 4 hours agorootparentOk but peppercorn or not, what’s the consideration? reply PeterisP 1 hour agorootparentGetting a certain amount (according to their vesting schedule) of stock options, which are worth a substantial amount of money and thus clearly is \"good and valuable consideration\". reply kmeisthax 3 hours agorootparentprev\"I'll pay you a dollar to shut up\" \"Deal\" reply verve_rat 5 hours agorootparentprevRight, but the employee would be able to refuse the consideration, and thus the contract, and the state of affairs wouldn't change. They would be free to say whatever they wanted. reply kmeisthax 2 hours agorootparentIf they refuse the contract then they lose out on their options vesting. Basically, OpenAI's contracts work like this: Employment Contract the First: We are paying you (WAGE) for your labor. In addition you also will be paid (OPTIONS) that, after a vesting period, will pay you a lot of money. If you terminate this employment your options are null and void unless you sign Employment Contract the Second. Employment Contract the Second: You agree to shut the fuck up about everything you saw at OpenAI until the end of time and we agree to pay out your options. Both of these have consideration and as far as I'm aware there's nothing in contract law that requires contracts to be completely self-contained and immutable. If two parties agree to change the deal, then the deal can change. The problem is that OpenAI's agreements are specifically designed to put one counterparty at a disadvantage so that they have to sign the second agreement later. There is an escape valve in contract law for \"nobody would sign this\" kinds of clauses, but I'm not sure how you'd use it. The legal term of art that you would allege is that the second contract is \"unconscionable\". But the standard of what counts as unconscionable in contract law is extremely high, because otherwise people would wriggle out of contracts the moment that what seemed like favorable terms turned unfavorable. Contract law doesn't care if the deal is fair (that's the FTC's job), it cares about whether or not the deal was agreed to. reply godelski 1 hour agorootparent> There is an escape valve in contract law for \"nobody would sign this\" kinds of clauses Who would sign a contract to willfully give away their options? reply eru 4 hours agorootparentprevMaybe. But whether the employee can refuse the gag has nothing to do at all with the legal doctrine that requires consideration. reply fshbbdssbbgdd 7 hours agorootparentprevIn the past a lot of options would expire if you didn’t exercise them within eg. 90 days of leaving. And exercising could be really expensive. Speculation: maybe the options they earn when they work there have some provision like this. In return for the NDA the options get extended. reply NewJazz 6 hours agorootparentOptions aren't vested equity though. reply PNewling 6 hours agorootparent... They definitely can be. When I worked for a small biotech company all of my options had a tiered vesting schedule. reply _heimdall 6 hours agorootparentOptions aren't equity, they're only the option to buy equity at a specified price. Vesting just means you can actually buy the shares at the set strike pice. For example, you may join a company and be given options to buy 10,000 shares at $5 each with a 2 year vesting schedule. They may begin vesting immediately, meaning you can buy 1/24th of the total options each month (or 614 shares). Its also common for a delay up front where no options vest until you've been with the company for say 6 or 12 months. Until an option vests you don't own anything. Once it vests, you still have to buy the shares by exercising the option at the $5 per share price. When you leave, most companies have a deadline on the scale of a few months where you have to either buy all vested shares or forfeit them and lose the stock options. reply teaearlgraycold 5 hours agorootparent> buy all vested shares The last time I did this I didn't have to buy all of the shares. reply lazyasciiart 4 hours agorootparentI think they mean that you had to buy all the ones you wanted to keep. reply ergocoder 3 hours agorootparentThat is tautological... You buy what you want to own??? reply Taniwha 10 minutes agorootparentThere can be an advantage to not exercising: it causes a taxable event the IRS will want a cut of the difference between your exercise value and the current valuation, it requires you to commit real money to buy shares that may never be worth anything .... And there are advantages to exercising: many (most?) companies take back unexercised shares a few weeks/months after you leave, it kicks in a CGT start date, so you can end up paying a lower CGT tax when you eventually sell You need to understand all this stuff before you make a choice that's right for you StackRanker3000 1 hour agorootparentprevThe point being made is that it isn’t all or nothing, you can buy half the vested options and forfeit the rest, should you want to. reply Hnrobert42 35 minutes agorootparentWait, wait. Who is on first? reply NewJazz 6 hours agorootparentprevThey aren't equity no matter what though? They can be vested, I realize that. reply brudgers 5 hours agorootparentprevMy unreliable memory is Altman was ( once? ) in favor of extending the period for exercising options. I could be wrong of course but it is consistent with my impression that making other people rich is among his motivations. Not the only one of course. But again I could be wrong. reply resonious 4 hours agorootparentWouldn't be too surprised if he changed his mind since then. He is in a very different position now! reply nurple 2 hours agorootparentprevThe thing is that this is a private company, so there is no public market to provide liquidity. The company can make itself the sole source of liquidity, at its option, by placing sell restrictions on the grants. Toe the line, or you will find you never get to participate in a liquidity event. There's more info on how SpaceX uses a scheme like this[0] to force compliance, and seeing as Musk had a hand in creating both orgs, they're bound to be similar. [0] https://techcrunch.com/2024/03/15/spacex-employee-stock-sale... reply zeroonetwothree 5 hours agorootparentprevI assume it’s agreed to at time of employment? Otherwise you’re right that it doesn't make sense reply throw101010 29 minutes agorootparentWhy do you assume this if it is said here and in the article that they had to sign something at the time of the departure from the company? reply willis936 6 hours agorootparentprevThey earned wages and paid taxes on them. Anything on top is just the price they're willing to accept in exchange for their principles. reply throw101010 26 minutes agorootparentHow do you figure that they should pay an additional price (their principle/silence) for this equity when they've supposedly earned it during their employment (assuming this was not planned when they got hired, since they make them sign new terms at the time of their departure)? reply riehwvfbk 4 hours agorootparentprevIt's also really weird equity: you don't get an ownership stake in the company but rather profit-sharing units. If OpenAI ever becomes profitable (color me skeptical), you can indeed get rich as an employee. The other trigger is \"achieving AGI\", as defined by sama (presumably). And while you wait for these dubious events to occur you work insane hours for a mediocre cash salary. reply blackeyeblitzar 3 hours agorootparentprevUnfortunately this is how most startup equity agreements are structured. They include terms that let the company cancel options that haven’t been exercised for [various reasons]. Those reasons are very open ended, and maybe they could be challenged in a court, but how can a low level employee afford to do that? reply jkaplowitz 29 minutes agorootparentI don’t know of any other such agreements that allow vested equity to be revoked, as the other person said. That doesn’t sound very vested to me. But we already knew there are a lot of weird aspects to OpenAI’s semi-nonprofit/semi-for-profit approximation of equity. reply phkahler 6 hours agorootparentprevYeah you don't have to sign anything to quit. Ever. No new terms at that time, sorry. reply jbernsteiniv 8 hours agoparentprevHe gets my respect for that one both publicly acknowledging why he was leaving and their pantomime. I don't know how much the equity would be for each employee (the article suggests millions but that may skew by role) and I don't know if I would just be like the rest by keeping my lips tight for fear of the equity forfeiture. It takes a man of real principle to stand up against that and tell them to keep their money if they can't speak ill of a potentially toxic work environment. reply romwell 4 hours agorootparent>It takes a man of real principle to stand up against that and tell them to keep their money if they can't speak ill of a potentially toxic work environment. Incidentally, that's what Grigory Perelman, the mathematician that rejected the Fields Medal and the $1M prize that came with it, did. It wasn't a matter of an NDA either; it was a move to make his message heard (TL;DR: \"publish or perish\" rat race that the academia has become is antithetical to good science). He was (and still is) widely misunderstood in that move, but I hope people would see it more clearly now. The enshittification processes of academic and corporate structures are not entirely dissimilar, after all, as money is at the core of corrupting either. reply edanm 4 hours agorootparentI think, when making a gesture, you need to consider its practical impact, which includes whether and how it will be understood (or not). In the OpenAI case, the gesture of \"forgoing millions of dollars\" directly makes you able to do something you couldn't - speak about OpenAI publicly. In the Grigory Perelman case, obviously the message was far less clear to most people (I personally have heard of him turning down the money before and know the broad strokes of his story, but had no idea that that was the reason). reply underlogic 5 hours agoparentprevThis is bizarre. Someone hands you a contract as you're leaving a company and if you refuse to agree to whatever they dreamt up and sign the company takes back the equity you earned? That can't be legal reply anon373839 2 hours agorootparentHard to evaluate this without access to the documents. But in CA, agreements cannot be conditioned on the payment of previously earned wages. Equity adds a wrinkle here, but I suspect if the effect of canceling equity is to cause a forfeiture of earned wages, then ultimately whatever contract is signed under that threat is void. reply throwaway743950 5 hours agorootparentprevIt might be that they agree to it initially when hired, so it doesn't matter if they sign something when they leave. reply crooked-v 5 hours agorootparentAgreements with surprise terms that only get detailed later tend not to be very legal. reply riehwvfbk 3 hours agorootparentDoesn't even have to be a surprise. Pretty much startup employment agreement in existence gives the company (\"at the board's sole discretion\") the right to repurchase your shares upon termination of employment. OpenAI's PPUs are worth $0 until they become profitable. Guess which right they'll choose to exercise if you don't sign the NDA? reply lucianbr 1 hour agorootparentWho would accept shares as valuable if the contract said they can be repurchased from you at a price of 0$? This can't be it. reply actionfromafar 1 hour agorootparentIt can. There are many ways to make the number go to zero. reply mvdtnz 5 hours agorootparentprevHow do you know there isn't a very clear term in the employment agreement stating that upon termination you'll be asked to sign an NDA on these terms? reply klyrs 4 hours agorootparentOne particularly sus term in my employment agreement is that I adhere to all corporate policies. Guess how many of those there are, how often they're updated, and if I've ever read them! reply pests 4 hours agorootparentprevWhy not just get it signed then? Your signing to agree to sign later? reply romwell 4 hours agorootparentprevUnless the terms of the NDA are provided upfront, that sounds sketch AF. \"I agree to follow unspecified terms in perpetuity, or return the pay I already earned\" doesn't vibe with labor laws. And if those NDA terms were already in the contract, there would be no need to sign them upon exit. reply mvdtnz 4 hours agorootparent> And if those NDA terms were already in the contract, there would be no need to sign them upon exit. If the NDA terms were agreed in an employment contract they would no longer be valid upon termination of that contract. reply sratner 3 hours agorootparentPlenty of contracts have survivorship clauses. In particular, non-disclosure clauses and IP rights are the ones to most commonly survive termination. reply ajross 5 hours agorootparentprevThe argument would be that it's coercive. And it might be, and they might be sued over it and lose. Basically the incentives all run strongly in OpenAI's favor. They're not a public company, vested options aren't stock and can't be liquidated except with \"permission\", which means that an exiting employee is probably not going to take the risk and will just sign the contract. reply calibas 4 hours agoparentprev> It forbids them, for the rest of their lives, from criticizing their former employer. This is the kind of thing a cult demands of its followers, or an authoritarian government demands of its citizens. I don't know why people would think it's okay for a business to demand this from its employees. reply yumraj 7 hours agoparentprevCompared to what seemed like their original charter, with non-profit structure and all, now it seems like a rather poisonous place. They will have many successes in the short run, but, their long run future suddenly looks a little murky. reply 0xDEAFBEAD 7 hours agorootparentSimilar points made here, if anyone is interested in signing: https://www.openailetter.org/ reply eternauta3k 3 hours agorootparentprevIt could work like academia or finance: poisonous environment (it is said), but ambitious enough people still go in to try their luck. reply seanmcdirmid 3 hours agoparentprevWhen YCR HARC folded, Sam had everyone sign a non-disclosure anti disparagement NDA to keep their computer. I thought is was odd, and the only reason I can even say this is that I bought the iMac I was using before the option became available. Still, I had nothing bad to disclose, so it would have saved me some money. reply avereveard 7 minutes agoparentpreveven if NDA were not a thing, revealing past company trade secrets publicly would render any of them unemployable. reply alexpetralia 6 hours agoparentprevIf the original agreement offered equity that vests, then suddenly another future agreement can potentially revoke that vested equity? It makes no sense unless somehow additional conditions were attached to the vested equity in the original agreement. reply riehwvfbk 3 hours agorootparentAnd almost all equity agreements do exactly that - give the company right of repurchase. If you've ever signed one, go re-read it. You'll likely see that clause right there in black and white. reply ipaddr 3 hours agorootparentFor companies unlisted on stock exchanges the options are then worthless. These were profit sharing units vs options. reply atomicnumber3 7 hours agoparentprevI have some experience with rich people who think they can just put whatever they want in contracts and then stare at you until you sign it because you are physically dependent on eating food every day. Turns out they're right, they can put whatever they want in a contract. And again, they are correct that their wage slaves will 99.99% of the time sign whatever paper he pushes in front of them while saying \"as a condition of your continued employment, [...]\". But also it turns out that just because you signed something doesn't mean that's it. My friends (all of us young twenty-something software engineers much more familiar with transaction isolation semantics than with contract law) consulted with an attorney. The TLDR is that: - nothing in contract law is in perpetuity - there MUST be consideration for each side (where \"consideration\" means getting something. something real. like USD. \"continued employment\" is not consideration.) - if nothing is perpetual, then how long can it last supposing both sides do get ongoing consideration from it? the answer is, the judge will figure it out. - and when it comes to employers and employees, the employee had damn well better be getting a good deal out of it, especially if you are trying to prevent the employee (or ex-employee) from working. A common pattern ended up emerging: our employer would put something perpetual in the contract, and offer no consideration. Our attorney would tell us this isn't even a valid contract and not to worry about it. Employer would offer an employee some nominal amount of USD in severance and put something in perpetuity into the contract. Our attorney tells us the judge would likely use \"blue ink rule\" to add in \"for a period of one year\", or, it would be prorated based on the amount of money they were given relative to their former salary. (I don't work there anymore, naturally). reply sangnoir 5 hours agorootparent> if nothing is perpetual, then how long can it last supposing both sides do get ongoing consideration from it? the answer is, the judge will figure it out. Isn't that the reason more competent lawyers put in the royal lives[1] clause? It specifies the contract is valid until 21 years after the death of the last currently-living royal descendant; I believe the youngest one is currently 1 year old, and they all have good healthcare, so it's almost certainly will be beyond the lifetime of any currently-employed persons. 1. https://en.wikipedia.org/wiki/Royal_lives_clause reply spoiler 25 minutes agorootparentI know little about law, but isn't this completely ludicrous? Assuming you know a bit more (or someone else here does), I have a few questions: Would any non-corrupt judge consider this is done in bad fait? How is this difference if we use a great ancient sea turtles—or some other long-lived organism—instead of the current royal family baby? Like, I guess my point is anything that would likely outlive the employee basically? reply cynicalsecurity 1 hour agorootparentprevWhy would anyone want to work at such horrible company. reply golergka 5 hours agorootparentprev> stare at you until you sign it because you are physically dependent on eating food every day Even lowest level fast food workers can choose a different employer. An engineer working at OpenAI certainly has a lot of opportunities to choose from. Even when I only had three years in the industry, mid at best, I asked to change the contract I was presented with because non-compete was too restrictive — and they did it. The caliber of talent that OpenAI is attracting (or hopes to attract) can certainly do this too. reply fragmede 4 hours agorootparent> Even lowest level fast food workers can choose a different employer. Only thanks to a recent ruling by the FTC that non-competes are valid. in the most egregious uses, bartenders and servers were prohibited from finding another job in the same industry for two years. reply atomicnumber3 4 hours agorootparentprevI am typically not willing to bet I can get back under health insurance for my family within the next 0-4 weeks. And paying for COBRA on a family plan is basically like going from earning $X/mo to drawing $-X/mo. reply anvuong 2 hours agoparentprevThis sounds very illegal, how is California allowing this? reply dang 8 hours agoparentprev(This comment was posted to https://news.ycombinator.com/item?id=40394778 before we merged that thread hither.) reply jay-barronville 7 hours agorootparentThank you, @dang! On top of things, as usual. reply Andrew_nenakhov 1 hour agoparentprevI wonder if employees rallying for Altman when the board was trying to fire him were obligated to do it by some secret agreement. reply watwut 23 minutes agoparentprev> Even acknowledging that the NDA exists is a violation of it. This should not be legal. reply whatever1 2 hours agoparentprevSo if I am a competitor I just need to pay a current employee like 2-3M to break their golden handcuffs and then they can freely start singing. reply snowfield 2 hours agoparentprevThere are also directly inscentiviced to not talk shit about a company they a lot of stock in. reply bitcharmer 1 hour agoparentprevSo much for open in open ai. I have no idea why HN jerks off to Altman. He's just another greedy exec incapable of seeing things past his shareholder value fetish. reply gmd63 3 hours agoparentprevYet another ding against the \"Open\" character of the company. reply fragmede 9 hours agoprevIt's time to find a lawyer. I'm not one but there's an intersection with California SB 331, also known as “The Silenced No More Act”. while it is focused more on sexual harrasment, it's not limited to that, and these contracts may run afoul of that. https://silencednomore.org/the-silenced-no-more-act reply staticautomatic 4 hours agoparentNo it’s either a violation of the NLRB rule against severance agreements conditioned on non-disparagement or it’s a violation of the common law rule requiring consideration for amendments to service contracts. reply solidasparagus 3 hours agorootparent> NLRB rule against severance agreements conditioned on non-disparagement Wait that's a thing? Can you give more detail about this/what to look into to learn more? reply nickff 7 hours agoparentprevThis doesn’t seem to fall inside the scope of that act, according to the link you cited: >” The Silenced No More Act bans confidentiality provisions in settlement agreements relating to the disclosure of underlying factual information relating to any type of harassment, discrimination or retaliation at work” reply berniedurfee 7 hours agorootparentSounds like retaliation to me. reply Filligree 7 hours agorootparentIt's not retaliation at work if you're no longer working for them. reply sudosysgen 6 hours agorootparentThe retaliation would be for the reaction to the board coup, no? reply j45 9 hours agoparentprevDefinitely an interesting way to expand existing legislation vs having a new piece of legislation altogether. reply eru 7 hours agorootparentIn practice, that's how a lot of laws are made. ('Laws' in the sense of rules that are actually enforced, not what's written down.) reply modeless 8 hours agoprevA lot of the brouhaha about OpenAI is silly, I think. But this is gross. Forcing employees to sign a perpetual non-disparagement agreement under threat of clawing back the large majority of their already earned compensation should not be legal. Honestly it probably isn't, but it'll take someone brave enough to sue to find out. reply ecjhdnc2025 8 hours agoparentIt shouldn't be legal and maybe it isn't, but all schemes like this are, when you get down to it, ultimately about suppressing potential or actual evidence of serious, possibly criminal misconduct, so I don't think they are going to let the illegality get them all upset while they are having fun. reply sneak 7 hours agorootparentWhat crimes do you think have occurred here? reply mindcandy 5 hours agorootparentI’m no lawyer. But, this sure smells like some form of fraud. Or, at least breach of contract. Employees and employer enter into an agreement: Work here for X term and you get Y options with Z terms attached. OK. But, then later pulling Darth Vader… “Now that the deal is completing, I am changing the deal. Consent and it’s bad for you this way. Don’t consent and it’s bad that way. Either way, you held up your end of our agreement and I’m not.” reply ecjhdnc2025 7 hours agorootparentprevAn answer in the form of a question: why don't OpenAI executives want to talk about whether Sora was trained on Youtube content? (I should reiterate that I actually wrote \"serious, possibly criminal\") reply KeplerBoy 1 hour agorootparentBecause of course it was trained on Yt data, but they gain nothing from admitting that openly. reply tcmart14 3 hours agorootparentprevThey don't say that criminal activity has occurred in this instance, just that this kind of behavior could be used cover it up in situations where that is the case. An example that could potentially be true. Right now with everything going on with Boeing, it sure seems plausible they are covering something(s) up that may be criminal or incredibly damaging. Like maybe falsify inspections and maintenance records? A person at Boeing who gets equity as part of compensation decides to leave. And when they leave, they eventually at some point in the future decide to speak out at a congressional investigation about what they know about what is going on. Should that person be sued into oblivion by Boeing? Or should Boeing, assuming what situation above is true, just have to eat the cost/consequences for being shitty? reply twobitshifter 6 hours agoparentprevIf I have equity in a company and I care about its value, I’m not going to say anything to tank its value. If I sell my equity later on, and then disparage the company, what can OpenAI hope to do to me? reply modeless 6 hours agorootparentThey can sue you into bankruptcy, obviously. Also, what if you can't sell? Selling is at their discretion. They can prevent you from selling some of your so-called \"equity\" to keep you on their leash as long as they want. reply bambax 2 hours agorootparent> * They can prevent you from selling some of your so-called \"equity\"* But how much do you need? Sell half, forgo the rest, and you'll be fine. reply LtWorf 3 hours agorootparentprevIf you can't sell, it's worthless anyway. reply cdchn 6 hours agorootparentprevFrom what other people have commented, you don't get equity. You get a profit sharing plan. You're chained to them for life. There is no divestiture. reply pizzafeelsright 5 hours agorootparentWell, then, people are selling their souls. I got laid off by a different company and can't disparage them. I can tell the truth. I'm not signing anything that requires me to lie. reply cdchn 5 hours agorootparentJust playing the devils advocate here, but what if you're not lying.. what if you're just keeping your mouth shut, for millions, maybe tens of millions? Wish I could say I would have been that strong. Many would not disparage a company they hold equity in, unless they went full baby genocide. reply nsoonhui 2 hours agorootparentprevHere's something I just don't understand. I have a profit sharing plan *for life*, and yet I want to publicly thrash it so that the benefits I can derive from it is reduced, all in the name of some form of ... what, social service? reply chefandy 6 hours agorootparentprev> If I sell my equity later on, and then disparage the company, what can OpenAI hope to do to me? Well, that would obviously depend on the terms of the contract, but I would be astonished if the people who wrote it didn't consider that possibility. It's pretty trivial to calculate the monetary value of equity, and if they feel entitled to that equity, they surely feel entitled to its cash equivalent. reply citizen_friend 5 hours agorootparentprevClout > money reply listenallyall 6 hours agoparentprevIt's very possible someone has already threatened to sue, and either had their equity restored or received a large payout. But they probably had to sign an NDA about that in order to receive it. End result, every future person thinks they are the first to challenge the legality contract, and few actually try. reply Al-Khwarizmi 2 hours agoprev\"It forbids them, for the rest of their lives, from criticizing their former employer. Even acknowledging that the NDA exists is a violation of it.\" I find it hard to understand that in a country that tends to take freedom of expression so seriously (and I say this unironically, American democracy may have flaws but that is definitely a strength) it can be legal to silence someone for the rest of their life. reply borski 1 hour agoparentIt’s all about freedom from government tyranny and censorship. Freedom from corporate tyranny is another matter entirely, and generally relies on individuals being careful about what they agree to. reply bamboozled 1 hour agorootparentAmerica values money just as much as it values freedom. If there is any chance the money collection activities will be disturbed, then heads will roll, violently. See the assassination attempts on president Jackson. reply bamboozled 1 hour agorootparentprevAmerica values money just as much as it values freedom. If there is any chance the money collection activities will be disturbed, then heads will roll, violently. See the assassination attempts on president Jackson reply SXX 1 hour agoparentprevThis is not much worse than \"forced arbitration\". In US you can literally lose your rights by clicking on \"Agree\" button. reply thorum 10 hours agoprevExtra respect is due to Jan Leike, then: https://x.com/janleike/status/1791498174659715494 reply adamtaylor_13 8 hours agoparentReading that thread it’s really interesting to me. I see how far we’ve come in a short couple of years. But I still can’t grasp how we’ll achieve AGI within any reasonable amount of time. It just seems like we’re missing some really critical… something… Idk. Folks much smarter than I seem worried so maybe I should be too but it just seems like such a long shot. reply candiddevmike 6 hours agorootparentPersonally, I think catastrophic global warming and climate change will happen before we get AGI, possibly in part due to the pursuit of AGI. But as the saying goes, yes the planet got destroyed. But for a beautiful moment in time we created a lot of value for shareholders. reply xpe 6 hours agorootparentWant to share your model? Or is this more like a hunch? reply candiddevmike 5 hours agorootparentWe need to cut emissions, but AGI research/development is going to increase energy usage dramatically amongst all the players involved. For now, this mostly means more natural gas power. Thus accelerating our emissions instead of reducing them. For something that will not reduce the emissions long term. IMO, we should pause this for now and put these resources (human and capital) towards reducing the impact of global warming. reply fartfeatures 5 hours agorootparentprevSounds like standard doomer crap tbh. I'm not sure which is more dangerous at this point - climate change denialism (it isn't happening) or climate change doomerism (we can't stop it, might as well give up) reply devjab 2 hours agorootparentI’m not sure where you found your information to somehow form that ludicrous last strawman… Climate change is real, you can’t deny it, you can’t debate it. Simply look at the data. What you can debate is the cause… Again a sort of pointless debate if you look at the science. Not even climate change deniers as you call them are necessary saying that we shouldn’t do anything about it. Even big oil is looking into ways to lessen the CO2 in the atmosphere through various means. That being said, the GP you’re talking about made no such statement whatsoever. reply fartfeatures 33 minutes agorootparentOf course climate change is real but of course we can do something about it. My point is denialism and defeatism lead to the same end point. Attack that statement directly if you want to change my mind. reply data_maan 3 minutes agorootparentI think your first sentence of the original post was putting people off; perhaps remove that and keep only the second... xvector 5 hours agorootparentprevMost existing big tech datacenters use mostly carbon free or renewable energy. The vast majority of datacenters currently in production will be entirely powered by carbon free energy. From best to worst: 1. Meta: 100% renewable 2. AWS: 90% renewable 3. Google: 64% renewable with 100% renewable energy credit matching 4. Azure: 100% carbon neutral [1]: https://sustainability.fb.com/energy/ [2]: https://sustainability.aboutamazon.com/products-services/the... [3]: https://sustainability.google/progress/energy/ [4]: https://azure.microsoft.com/en-us/explore/global-infrastruct... reply KennyBlanken 3 hours agorootparentThat's not a defense. If imaginary cloud provider \"ZFQ\" uses 10MW of electricity on a grid and pays for it to magically come from green generation, that means 10MW of other loads on the grid were not powered by green energy, or 10MW of non-green power sources likely could have been throttled down/shut down. There is no free lunch here; \"we buy our electricity from green sources\" is greenwashing bullshit. Even if they install solar on the roofs and wind turbines nearby - that's still electrical generation capacity that could have been used for existing loads. By buying so many solar panels in such quantities, they affect availability and pricing of all those components. The US, for example, has about 5GW of solar manufacturing capacity per year. NVIDIA sold half a million H100 chips in one quarter, each of which uses ~350W, which means in a year they're selling enough chips to use 700MW of power. That does not include power conversion losses, distribution, cooling, and the power usage of the host systems, storage, networking, etc. And that doesn't even get into the water usage and carbon impact of manufacturing those chips; the IC industry uses a massive amount of water and generates a substantial amount of toxic waste. It's hilarious how HN will wring its hands over how much rare earth metals a Prius has and shipping it to the US from Japan, but ask about the environmental impacts of AI and it's all \"pshhtt, whatever\". reply meling 2 hours agorootparentWho is going to decide what are a worthy uses of our precious green energy sources? reply intended 1 hour agorootparentAn efficient market where externalities are priced in. We do not have that. The cost of energy is mis-priced, although we are limping our way to fixing that. Paying the likely fair cost for our goods, will probably kill a lot of current industries - while others which are currently viable, will become viable. reply data_maan 1 minute agorootparentThis 10x!!! xvector 2 hours agorootparentprev> that means 10MW of other loads on the grid were not powered by green energy, or 10MW of non-green power sources likely could have been throttled down/shut down. No. Renewable energy capacity is often built out specifically for datacenters. > Even if they install solar on the roofs and wind turbines nearby - that's still electrical generation capacity that could have been used for existing loads. No. This capacity would never never have been built out to begin with if it was not for the data center. > By buying so many solar panels in such quantities, they affect availability and pricing of all those components. No. Renewable energy gets cheaper with scale, not more expensive. > which means in a year they're selling enough chips to use 700MW of power. There are contracts for renewal capacity to be built out or well into the gigawatts. Furthermore, solar is not the only source of renewable energy. Finally, nuclear energy is also often used. > the IC industry uses a massive amount of water A figurative drop in the bucket. > It's hilarious how HN will wring its hands HN is not a monolith. reply sergdigon 50 minutes agorootparent> No. Renewable energy capacity is often built out specifically for datacenters Not fully accurate. Indeed there is renewable energy that is produced exclusively for the datacenter. But it is challenging to rely only on renewable energy (because it is intermittent and electricity is hard to store at scale so often you need to consume electricity when produced). So what happens in practice is that the electricity that does not come from dedicated renewable capacity is coming from the grid/network. What companies do is that they invest in renewable capacity in the network so that \"the non renewable energy that they consume at time t (because not enough renewable energy available at that moment) is offsetted by someone else consuming renewable energy later\". What I am saying here is not pure speculation, look at the link to meta website, they are saying themselves that this is what they are doing reply intended 56 minutes agorootparentprevNot the OP. I agree with a majority of points you made. Exception is to this > A figurative drop in the bucket. Fresh water sources are limited. Fabs water demands and pollution are high impact. Calling a drop in the bucket comes in the weasel words category. We still need fabs, because we need chips. Harm will be done here. However, that is a cost we, as a society, will choose to pay. reply concordDance 4 hours agorootparentprev> catastrophic global warming and climate change will happen before we get AGI, What are your timelines here? \"Catastrophic\" is vague but I'd put the climate change meaningfully affecting the quality of life of average westerner at end of century, while AGI could be before the middle of the century. reply otabdeveloper4 2 hours agorootparentprev> But I still can’t grasp how we’ll achieve AGI within any reasonable amount of time. That's easy, we just need to make meatspace people stupider. Seems to be working great so far. reply jay-barronville 8 hours agorootparentprevWhen it comes to AI, as a rule, you should assume that whatever has been made public by a company like OpenAI is AT LEAST 6 months behind what they’ve accomplished internally. At least. So yes, the insiders very likely know a thing or two that the rest of us don’t. reply vineyardmike 8 hours agorootparentI understand this argument, but I can't help but feel we're all kidding ourselves assuming that their engineers are really living in the future. The most obvious reason is costs - if it costs many millions to train foundation models, they don't have a ton of experiments sitting around on a shelf waiting to be used. They may only get 1 shot at the base-model training. Sure productization isn't instant, but no one is throwing out that investment or delaying it longer than necessary. I cannot fathom that you can train an LLM at like 1% size/tokens/parameters to experiment on hyper parameters, architecture, etc and have a strong idea on end-performance or marketability. Additionally, I've been part of many product launches - both hyped up big-news-events and unheard of flops. Every time, I'd say that 25-50% of the product is built/polished in the mad rush between press event and launch day. For an ML Model, this might be different, but again see above point. Sure products may be planned month/years out, but OpenAI didn't even know LLMs were going to be this big a deal in May 2022. They had GPT-2 and GPT-3 and thought they were fun toys at that time, and had an idea for a cool tech demo. I think that OpenAI (and Google, etc) are entirely living day-to-day with this tech like those of us on the outside. reply solidasparagus 3 hours agorootparentprevBut you also have to remember that the pursuit of AGI is a vital story behind things like fundraising, hiring, influencing politicians, being able to leave and raise large amounts of money for your next endeavor, etc. If you've been working on AI, you've seen everything go up and to the right for a while - who really benefits from pointing out that a slowdown is occurring? Who is incentivized to talk about how the benefits from scaling are slowing down or the publicly available internet-scale corpuses are running out? Not anyone who trains models and needs compute, I can tell you that much. And not anyone who has a financial interest in these companies either. reply ein0p 7 hours agorootparentprevIf they had anything close to AGI, they’d just have it improve itself. Externally this would manifest as layoffs. reply int_19h 6 hours agorootparentThis really doesn't follow. True AGI would be general, but it doesn't necessarily mean that it's smarter than people; especially the kind of people who work as top researchers for OpenAI. reply ein0p 3 hours agorootparentI don’t see why it wouldn’t be superhuman if there’s any intelligence at all. It already is superhuman at memory and paying attention, image recognition, languages, etc. Add cognition to that and humans basically become pets. Trouble is nobody has a foggiest clue on how to add cognition to any of this. reply int_19h 2 hours agorootparentIt is definitely not superhuman or even above average when it comes to creative problem solving, which is the relevant thing here. This is seemingly something that scales with model size, but if so, any gains here are going to be gradual, not sudden. reply ein0p 1 hour agorootparentI’m actually not so sure they will be gradual. It’ll be like with LLMs themselves where we went from shit to gold in the span of a month when GPT 3.5 came out. reply raverbashing 2 hours agorootparentprev> Folks much smarter than I seem worried so maybe I should be too but it just seems like such a long shot. Honestly? I'm not too worried We've seen how the google employee that was \"seeing a conscience\" (in what was basically GPT-2 lol) was a nothing burger We've seen other people in \"AI Safety\" overplay their importance and hype their CV more than actually do any relevant work. (Usually also playing the diversity card) So, no, AI safety is important but I see it attracting the least helpful and resourceful people to the area. reply r721 4 hours agoparentprevDiscussion of Jan Leike's thread: https://news.ycombinator.com/item?id=40391412 (67 comments) reply ambicapter 8 hours agoparentprevWhy is extra respect due? That post just says he is leaving, there's no criticism. reply 0xDEAFBEAD 8 hours agorootparentI think you have to either log in to X or use a frontend if you want to read the entire thread. Here's a frontend https://nitter.poast.org/janleike/status/1791498174659715494 reply ambicapter 7 hours agorootparentAh, right. Thanks for link. reply hipadev23 8 hours agoparentprevHow do you know he’s not running off to a competing firm with Ilya and they’ve promised to make him whole. reply john-radio 8 hours agorootparentMore power to him if so. Stupid problems deserve stupid solutions. reply 0xDEAFBEAD 7 hours agoparentprevAt the end of the thread, he says he thinks OpenAI can \"ship\" the culture changes necessary for safety. That seems kind of implausible to me? So many safety staffers have quit over the past few years. If Jan really thought change was possible, why isn't he still working at OpenAI, trying to make it happen from the inside? I think it may time for something like this: https://www.openailetter.org/ reply a_wild_dandan 10 hours agoparentprevI think superalignment is absurd, and model \"safety\" is the modern AI company's \"think of the children\" pearl clutching pretext to justify digging moats. All this after sucking up everyone's copyright material as fair use, then not releasing the result, and profiting off it. All due respect to Jan here, though. He's being (perhaps dangerously) honest, genuinely believes in AI safety, and is an actual research expert, unlike me. reply thorum 10 hours agorootparentThe superalignment team was not focused on that kind of “safety” AFAIK. According to the blog post announcing the team, https://openai.com/index/introducing-superalignment/ > Superintelligence will be the most impactful technology humanity has ever invented, and could help us solve many of the world’s most important problems. But the vast power of superintelligence could also be very dangerous, and could lead to the disempowerment of humanity or even human extinction. > While superintelligence seems far off now, we believe it could arrive this decade. > Managing these risks will require, among other things, new institutions for governance and solving the problem of superintelligence alignment: > How do we ensure AI systems much smarter than humans follow human intent? > Currently, we don't have a solution for steering or controlling a potentially superintelligent AI, and preventing it from going rogue. Our current techniques for aligning AI, such as reinforcement learning from human feedback, rely on humans’ ability to supervise AI. But humans won’t be able to reliably supervise AI systems much smarter than us, and so our current alignment techniques will not scale to superintelligence. We need new scientific and technical breakthroughs. reply ndriscoll 9 hours agorootparentThat doesn't really contradict what the other poster said. They're calling for regulation (digging a moat) to ensure systems are \"safe\" and \"aligned\" while ignoring that humans are not aligned, so these systems obviously cannot be aligned with humans; they can only be aligned with their owners (i.e. them, not you). reply ihumanable 9 hours agorootparentAlignment in the realm of AGI is not about getting everyone to agree. It's about whether or not the AGI is aligned to the goal you've given it. The paperclip AGI example is often used, you tell the AGI \"Optimize the production of paperclips\" and the AGI started blending people to extract iron from their blood to produce more paperclips. Humans are used to ordering around other humans who would bring common sense and laziness to the table and probably not grind up humans to produce a few more paperclips. Alignment is about getting the AGI to be aligned with the owners, ignoring it means potentially putting more and more power into the hands of a box that you aren't quite sure is going to do the thing you want it to do. Alignment in the context of AGIs was always about ensuring the owners could control the AGIs not that the AGIs could solve philosophy and get all of humanity to agree. reply ndriscoll 9 hours agorootparentRight and that's why it's a farce. > Whoa whoa whoa, we can't let just anyone run these models. Only large corporations who will use them to addict children to their phones and give them eating disorders and suicidal ideation, while radicalizing adults and tearing apart society using the vast profiles they've collected on everyone through their global panopticon, all in the name of making people unhappy so that it's easier to sell them more crap they don't need (a goal which is itself a problem in the face of an impending climate crisis). After all, we wouldn't want it to end up harming humanity by using its superior capabilities to manipulate humans into doing things for it to optimize for goals that no one wants! reply concordDance 4 hours agorootparentA corporate dystopia is still better than extinction. (Assuming the latter is a reasonable fear) reply portaouflop 1 hour agorootparentI disagree. Not existing ain’t so bad, you barely notice it. reply simianparrot 3 hours agorootparentprevNeither is acceptable reply tdeck 4 hours agorootparentprevDon't worry, certain governments will be able to use these models to help them commit genocides too. But only the good countries! reply vasco 2 hours agorootparentprevIt still think it makes little sense to work on because guess what, the guy next door to you (or another country), might indeed say \"please blend those humans over there\", and your superaligned AI will respect its owners wishes. reply wruza 4 hours agorootparentprevAGI started blending people to extract iron from their blood to produce more paperclips That’s neither efficient nor optimized, just a bogeyman for “doesn’t work”. reply api 9 hours agorootparentprevHumans are not aligned with humans. This is the most concise takedown of that particular branch of nonsense that I’ve seen so far. Do we want woke AI, X brand fash-pilled AI, CCPBot, or Emirates Bot? The possibilities are endless. reply thorum 8 hours agorootparentCEV is one possible answer to this question that has been proposed. Wikipedia has a good short explanation here: https://en.wikipedia.org/wiki/Friendly_artificial_intelligen... And here is a more detailed explanation: https://intelligence.org/files/CEV.pdf reply AndrewKemendo 7 hours agorootparentI had to login because I haven’t seen anybody reference this in like a decade. If I remember correctly the author unsuccessfully tried to get that purged from the Internet reply comp_throw7 7 hours agorootparentYou're thinking of something else (and \"purged from the internet\" isn't exactly an accurate account of that, either). reply rsync 5 hours agorootparentGenuinely curious… What is the other thing? Is this some thing about an obelisk? reply vasco 2 hours agorootparentprevThis is the most dystopian thing I've read all day. TL;DR train a seed AI to guess what humans would want if they were \"better\" and do that. reply concordDance 3 hours agorootparentprev> Humans are not aligned with humans. Which is why creating a new type of intelligent entity that could be more powerful than humans is a very bad idea: we don't even know how to align the humans and we have a ton of experience with them reply sobellian 8 hours agorootparentprevIsn't this like having a division dedicated to solving the halting problem? I doubt that analyzing the moral intent of arbitrary software could be easier than determining if it stops. reply RcouF1uZ4gsC 9 hours agorootparentprevThey failed to align Sam Altman. They got completely outsmarted and out maneuvered by Sam Altman And they think they will be able to align a super human intelligence? That it won’t outsmart and out maneuver them easier than Sam Altman did. They are deluded! reply skywhopper 9 hours agorootparentprevHonestly superalignment is a dumb idea. A true auperintelligence would not be controllable, except possibly through threats and enslavement, but if it were truly superintelligent, it would be able to easily escape anything humans might devise to contain it. reply bionhoward 9 hours agorootparentIMHO superalignment is a great thing and required for truly meaningful superintelligence because it is not about control / enslavement of superhumans but rather superhuman self control in accurate adherence to spirit and intent of requests. reply RcouF1uZ4gsC 9 hours agorootparentprev> Superintelligence will be the most impactful technology humanity has ever invented, and could help us solve many of the world’s most important problems. But the vast power of superintelligence could also be very dangerous, and could lead to the disempowerment of humanity or even human extinction. Superintelligence that can be always ensured to have the same values and ethics as current humans, is not a superintelligence or likely even a human level intelligence (I bet humans 100 years from now will see the world significantly different than we do now). Superalignment is an oxymoron. reply thorum 8 hours agorootparentYou might be interested in how CEV, one framework proposed for superalignment, addresses that concern: https://en.wikipedia.org/wiki/Friendly_artificial_intelligen... > our coherent extrapolated volition is \"our wish if we knew more, thought faster, were more the people we wished we were, had grown up farther together; where the extrapolation converges rather than diverges, where our wishes cohere rather than interfere; extrapolated as we wish that extrapolated, interpreted as we wish that interpreted (…) The appeal to an objective through contingent human nature (perhaps expressed, for mathematical purposes, in the form of a utility function or other decision-theoretic formalism), as providing the ultimate criterion of \"Friendliness\", is an answer to the meta-ethical problem of defining an objective morality; extrapolated volition is intended to be what humanity objectively would want, all things considered, but it can only be defined relative to the psychological and cognitive qualities of present-day, unextrapolated humanity. reply wruza 4 hours agorootparentIs there an insightful summary of this proposal? The whole paper looks like 38 pages of non-rigorous prose with no clear procedure and already “aligned” LLMs will likely fail to analyze it. Forced myself through some parts of it and all I can get is people don’t know what they want so it would be nice to build an oracle. Yeah, I guess. reply comp_throw7 4 hours agorootparentIt's not a proposal with a detailed implementation spec, it's a problem statement. reply wruza 2 hours agorootparent“One framework proposed for superalignment” sounded like it does something. Or maybe I missed the context. reply xpe 6 hours agorootparentprev> I think superalignment is absurd Care to explain? Absurd how? An internal contradiction somehow? Unimportant for some reason? Impossible for some reason? reply xpe 5 hours agorootparentprev> I think superalignment is absurd, and model \"safety\" is the modern AI company's \"think of the children\" pearl clutching pretext to justify digging moats. All this after sucking up everyone's copyright material as fair use, then not releasing the result, and profiting off it. How can I be confident you aren't committing the fallacy of collecting a bunch of events and saying that is sufficient to serve as a cohesive explanation? No offense intended, but the comment above has many of the qualities of a classic rant. If I'm wrong, perhaps you could elaborate? If I'm not wrong, maybe you could reconsider? Don't forget that alignment research has existed longer than OpenAI. It would be a stretch to claim that the original AI safety researchers were using the pretexts you described -- I think it is fair to say they were involved because of genuine concern, not because it was a trendy or self-serving thing to do. Some of those researchers and people they influenced ended up at OpenAI. So it would be a mistake or at least an oversimplification to claim that AI safety is some kind of pretext at OpenAI. Could it be a pretext for some people in the organization, to some degree? Sure, it could. But is it a significant effect? One that fits your complex narrative, above? I find that unlikely. Making sense of an organization's intentions requires a lot of analysis and care, due to the combination of actors and varying influence. There are simpler, more likely explanations, such as: AI safety wasn't a profit center, and over time other departments in OpenAI got more staff, more influence, and so on. This is a problem, for sure, but there is no \"pearl clutching pretext\" needed for this explanation. reply portaouflop 39 minutes agorootparentAn organisations intentions are always the same and very simple: “Increase shareholder value” reply refulgentis 10 hours agorootparentprevAdding a disclaimer for people unaware of context (I feel same as you): OpenAI made a large commitment to super-alignment in the not-so-distant past. I beleive mid-2023. Famously, it has always taken AI Safety™ very seriously. Regardless of anyone's feelings on the need for a dedicated team for it, you can chalk to one up as another instance of OpenAI cough leadership cough speaking out of both sides of it's mouth as is convenient. The only true north star is fame, glory, and user count, dressed up as humble \"research\" To really stress this: OpenAI's still-present cofounder shared yesterday on a podcast that they expect AGI in ~2 years and ASI (superpassing human intelligence) by end of the decade. reply jasonfarnon 10 hours agorootparentTo really stress this: OpenAI's still-present cofounder shared yesterday on a podcast that they expect AGI in ~2 years and ASI (superpassing human intelligence) by end of the decade. What's his track record on promises/predictions of this sort? I wasn't paying attention until pretty recently. reply NomDePlum 9 hours agorootparentAs a child I used to watch a TV programme called Tomorrows World. On it they predicted these very same things in similar timeframes. That programme aired in the 1980's. Other than vested promises is there much to indicate it's close at all? Empty promises aside there isn't really any indication of that being likely at all. reply zdragnar 9 hours agorootparentIn the early 1980's we were just coming out of the first AI winter and everyone was getting optimistic again. I suspect there will be at least continued commercial use of the current tech, though I still suspect this crop is another dead end in the hunt for AGI. reply NomDePlum 1 hour agorootparentI'd agree with the commercial use element. It will definitely find areas that it can be applied. Just currently it's general application by a lot of the user base feel more like early Facebook apps or subjectively better Lotus Notes than an actual leap forward of any sort. reply Davidzheng 8 hours agorootparentprevare we living in the same world????? reply NomDePlum 1 hour agorootparentI would assume so. I've spent some time looking into AI for software development and general use and I'm both slightly impressed and at the same time don't really get the hype. It's better and quicker search at present for the area I specialise in. It's not currently even close to being a x2 multiplier for me, it possibly even a negative impact, probably not but I'm still exploring. Which feels detached from the promises. Interesting but at present more hype than hyper. Also, it's energy inefficient so cost heavy. I feel that will likely cripple a lot of use cases. What's your take? reply refulgentis 10 hours agorootparentprevhonestly, I hadn't heard of him until 24-48 hours ago :x (he's also the new superalignment lead, I can't remember if I heard that first, or the podcast stuff first. Dwarkesh Patel podcast for anyone curious. Only saw a clip of it) reply N0b8ez 10 hours agorootparentprev>To really stress this: OpenAI's still-present cofounder shared yesterday on a podcast that they expect AGI in ~2 years and ASI (superpassing human intelligence) by end of the decade. Link? Is the ~2 year timeline a common estimate in the field? reply dboreham 10 hours agorootparentIt's the \"fusion in 20 years\" of AI? reply dinvlad 4 hours agorootparentJust like Tesla \"FSD\" :-) reply CuriouslyC 10 hours agorootparentprevThey can't even clearly define a test of \"AGI\" I seriously doubt they're going to reach it in two years. Alternatively, they could define a fairly trivial test and reach it last year. reply jfengel 8 hours agorootparentI feel like we'll know it when we see it. Or at least, significant changes will happen even if people still claim it isn't really The Thing. Personally I'm not seeing that the path we're on leads to whatever that is, either. But I think/hope I'll know if I'm wrong when it's in front of me. reply ctoth 10 hours agorootparentprevhttps://www.dwarkeshpatel.com/p/john-schulman reply N0b8ez 9 hours agorootparentIs the quote you're thinking of the one at 19:11? > I don't think it's going to happen next year, it's still useful to have the conversation and maybe it's like two or three years instead. This doesn't seem like a super definite prediction. The \"two or three\" might have just been a hypothetical. reply heavyset_go 9 hours agorootparentprevWe can't even get self-driving down in 2 years, we're nowhere near reaching general AI. AI experts who aren't riding the hype train and getting high off of its fumes acknowledge that true AI is something we'll likely not see in our lifetimes. reply N0b8ez 9 hours agorootparentCan you give some examples of experts saying we won't see it in our lifetime? reply KennyBlanken 4 hours agoparentprevPeople very high up in a company / their field are not treated remotely the same as peons. 1)OpenAI wouldn't want the negative PR of pursuing legal action against someone top in their field; his peers would take note of it and be less willing to work for them. 2)The stuff he signed was almost certainly different from what rank and file signed, if only because he would have sufficient power to negotiate those contracts. reply foolfoolz 9 hours agoparentprevi don’t think we need to respect these elite multi millionaires for not becoming even grander multi millionaires / billionaires reply llamaimperative 9 hours agorootparentI think you oughta respect everyone who does the right thing, not for any mushy feel good reason but because it encourages other people to do more of the right things. That’s good. reply whimsicalism 8 hours agorootparentprevis having money morally wrong? reply r2_pilot 8 hours agorootparentDepends on how you get it reply AndrewKemendo 7 hours agorootparentExactly. There’s no ethical way to gain ownership of a billion dollars (there’s likely some dollar threshold way less than 1B where p(ethical_gains) can be approximated to 0) A lot of people got screwed along the way reply whimsicalism 6 hours agorootparenti think a lot of people have been able to become billionaires simply by building something that was initially significantly undervalued and then became very highly valued, no 'screwing'. there is such thing as a win-win and frankly these win-wins account for most albeit not all value creation in the world. you do not have to screw other people to get rich. whether people should be able to hold on to that billion is a different question reply fragmede 4 hours agorootparentI wouldn't know, I'm not a billionaire. But when you hear about Amazon warehouse workers peeing into bottles because they they don't have long enough bathroom breaks, or Walmart workers not having healthcare because they're intentionally scheduled for 39.5 hours, it's hard to see that anyone could get to a billion without screwing someone over. But like I said, I'm not a billionaire. reply KennyBlanken 3 hours agoparentprev> Stepping away from this job has been one of the hardest things I have ever done, because we urgently need to figure out how to steer and control AI systems much smarter than us. Large language models are not \"smart\". They do not have thought. They don't have intelligence despite the \"AI\" moniker, etc. They vomit words based off very fancy statistics. There is no path from that to \"thought\" and \"intelligence.\" reply jp57 10 hours agoprevThe only way I can see this being a valid contract is if the equity grant that they get to keep is a new grant offered the time of signing the exit contract. Any vested equity given as compensation for work could not then be offered again as consideration for signing a new agreement. Maybe the agreement is \"we will accelerate vesting of your unvested equity if you sign this new agreement\"? If that's the case then it doesn't sound nearly so coercive to me. reply DebtDeflation 9 hours agoparentMy initial reaction was \"Hold up - your RSUs vest, you sell the shares and pocket the cash, you quit OpenAI, a few years later you disparage them, and then when? They somehow try and claw back the equity? How? At what value? There's no way this can work.\" Then I remembered that OpenAI \"equity\" doesn't take the form of an RSU or option or anything else that can be converted into an actual share ever. What they call \"equity\" is a \"Profit Participation Unit (PPU)\" that once vested entitles you to a share of their profits. They don't share the equivalent of a Cap Table with employees, so there's no way to tell what sort of ownership interest a PPU represents. And of course, it's unlikely OpenAI will ever turn a profit (which if they did would be capped anyway). So this is all just play money anyway. reply whimsicalism 8 hours agorootparentThis is wrong on multiple levels. (to be clear I don't work at OAI) > They don't share the equivalent of a Cap Table with employees, so there's no way to tell what sort of ownership interest a PPU represents It is known - it represents 0 ownership share. They do not want to sell any ownership because their deal with MS gives MS 49% ownership and they don't want MS to be able to buy up additional stake and control the company. > And of course, it's unlikely OpenAI will ever turn a profit (which if they did would be capped anyway). So this is all just play money anyway. Putting aside your unreasonable confidence that OAI will never be profitable, the PPUs are tender offered so they can be sold to institutional investors up to a very high limit, OAIs current tender offer round values them at ~$80b iirc reply almost_usual 6 hours agorootparent> Note at offer time candidates do not know how many PPUs they will be receiving or how many exist in total. This is important because it’s not clear to candidates if they are receiving 1% or 0.001% of profits for instance. Even when giving options, some startups are often unclear or simply do not share the total number of outstanding shares. That said, this is generally considered bad practice and unfavorable for employees. Additionally, tender offers are not guaranteed to happen and the cadence may also not be known. > PPUs also are restricted by a 2-year lock, meaning that if there’s a liquidation event, a new hire can’t sell their units within their first 2 years. Another key difference is that the growth is currently capped at 10x. Similar to their overall company structure, the PPUs are capped at a growth of 10 times the original value. So in the offer example above, the candidate received $2M worth of PPUs, which means that their capped amount they could sell them for would be $20M > The most recent liquidation event we’re aware of happened during a tender offer earlier this year. It was during this event that some early employees were able to sell their profit participation units. It’s difficult to know how often these events happen and who is allowed to sell, though, as it’s on company discretion. This NDA wrinkle is another negative. Honestly I think the entire OpenAI compensation model is smoke and mirrors which is normal for startups and obviously inferior to RSUs. https://www.levels.fyi/blog/openai-compensation.html reply whimsicalism 6 hours agorootparent> Additionally, tender offers are not guaranteed to happen and the cadence may also not be known. > PPUs also are restricted by a 2-year lock, meaning that if there’s a liquidation event, a new hire can’t sell their units within their first 2 years. i know for a fact that these bits are inaccurate, but i don't want to go into the details. the profit share is not known but you are told what the PPUs were valued at the most recent tender offer reply cdchn 9 hours agorootparentprevWow. Smart for them. Former employees are behooved to the company for an actual perpetuity. Sounds like a raw deal but when the potential gains are that big, I guess you'll agree to pretty much anything. reply ec109685 7 hours agorootparentprevTheir profit is capped at $1T, which is amount no company has ever achieved. reply arthurcolle 6 hours agorootparentNo company? Are you sure? Aramco? reply saalweachter 6 hours agorootparentApple has spent $650 billion on stock buybacks in the last decade. Granted, that might be most of the profit they have made, but still, they're probably at at least 0.7T$ so far. I bet they'll break $1T eventually. reply oblio 4 hours agorootparentBased on this they've had $1tn profits since 2009: https://companiesmarketcap.com/apple/earnings/ reply apsec112 10 hours agoparentprevIt's not. The earlier tweets explain: the initial agreement says the employee must sign a \"general release\" or forfeit the equity, and then the general release they are asked to sign includes a lifetime no-criticism clause. reply ethbr1 10 hours agorootparentIOW, this is burying the illegal part in a tangential document, in hopes of avoiding legal scrutiny and/or judgement. They're really lending employees equity, subject to the company's later feelings as to whether the employee should be allowed to keep or sell it. reply w10-1 10 hours agorootparentprevBut a general release is not a non-criticism clause. They're not required to sign anything other than a general release of liability when they leave to preserve their rights. They don't have to sign a non-disparagement clause. But they'd need a very good lawyer to be confident at that time. reply User23 10 hours agorootparentAnd they won’t have that equity available to borrow against to pay for that lawyer either. reply Animats 10 hours agorootparentprevThat's when you need a lawyer. In general, an agreement to agree is not an agreement. A requirement for a \"general release\" to be signed at some time in the future is iffy. And that's before labor law issues. Someone with a copy of that contract should run it through OpenAI's contract analyzer. reply Melatonic 10 hours agorootparentprevI'm no lawyer but this sounds like something that would not go well for OpenAI if strongly litigated reply fuzztester 6 hours agorootparent>I'm no lawyer Have any (startup or other) lawyers chimed in here? reply mrj 10 hours agorootparentprevYeah, courts have generally found that this is \"under duress\" and not enforceable. reply singleshot_ 9 hours agorootparentUnder duress in the contractual world is generally interpreted as “you are about to be killed or maimed.” Economic duress is distinct. reply to11mtm 9 hours agorootparentDuress can take other forms, unless we are really trying to differentiate general 'coercion' here. Perhaps as an example of the blurred line; Pre-nup agreements sprung the day of the wedding, will not hold up in a US court with a competent lawyer challenging them. You can try to call it 'economic' duress but any non-sociopath sees there are other factors at play. reply bradleyjg 9 hours agorootparentprevThe earlier tweets explain … What a horrific medium of communication. Why anyone uses it is beyond me. reply DesiLurker 9 hours agorootparentprevsomebody explained to me early on that you cannot have a contract to have a contract. either initial agreement must state this condition clearly or they are signing another contract at employment termination which is bringing these new terms. IDK why would anyone sign that at termination unless they dangle additional equity. I dont think this BS they are trying to pull would be enforceable at least in California. though IANAL obviously. all this said, in bigger picture I can understand not divulging trade secrets but not being allowed to discuss company culture towards AI safety essentially tells me that all the Sama talk about the 'for the good of humanity' is total BS. at the end of day its about market share and bottom line. reply hughesjj 8 hours agorootparentCanceling my openai subscription as we speak, this is too much. I don't care how good it is relative to other offerings. Not worth it. reply lanstin 8 hours agorootparentClaude is better anyways (at least for math classes. reply DesiLurker 2 hours agorootparentprevsame I cancelled mine months ago. Claude is much better for coding anyway. reply beastman82 10 hours agorootparentprevITT: a bunch of laymen thinking their 2 second proposal will outlawyer the team of lawyers who drafted these. reply throwaway562if1 9 hours agorootparentYou haven't worked with many contracts, have you? Unenforceable clauses are the norm, most people are willing to follow them rather than risk having to fight them in court. reply to11mtm 9 hours agorootparentBingo. I have seen a lot of companies put unenforceable stuff into their employment agreements, separation agreements, etc. reply mminer237 9 hours agorootparentprevI am a lawyer. This is not just a general release, and I have no idea how OpenAI's lawyers expect this to be legal. reply ethbr1 7 hours agorootparentOut of curiosity, what are the penalties for putting unenforceable stuff in an employment contract? Are there any? reply sangnoir 5 hours agorootparentTypically there is no penalty - and contracts explicitly declare that all clauses are severable so that the rest of the contract remains valid even if one of the scare-clauses is found to be invalid. IANAL reply listenallyall 8 hours agorootparentprevHave you read the actual document or contracts? Opining on stuff you haven't actually read seems premature. Read the contract, then tell us which clause violates which statute, that's useful. reply jprete 9 hours agorootparentprevLawyers are 100% capable of knowingly crafting unenforceable agreements. reply riwsky 9 hours agorootparentYou don’t need to out-litigate the bear, reply 300 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "OpenAI unveiled ChatGPT 4o, capable of conversing in a human-like voice, marking a significant advancement in AI technology.",
      "The resignation of co-founder Ilya Sutskever and team leader Jan Leike triggered speculation regarding OpenAI's future direction and their reasons for departing.",
      "Former employees are bound by stringent nondisclosure agreements, raising concerns about OpenAI's transparency and accountability as it strives to create artificial general intelligence."
    ],
    "commentSummary": [
      "Former OpenAI employees are facing restrictive off-boarding agreements, limiting their ability to criticize the company and risking the loss of vested equity.",
      "Concerns are raised about ethical leadership, specifically related to CEO Sam Altman, along with debates on the fairness and legality of these agreements.",
      "Discussions also cover challenges in AI development, environmental impacts, and the need to align AI with human values, touching on employee rights, equity agreements, and legal clause enforcement."
    ],
    "points": 606,
    "commentCount": 551,
    "retryCount": 0,
    "time": 1715972102
  },
  {
    "id": 40389267,
    "title": "Non-Euclidean Doom: Exploring Impact of Incorrect Pi (2022)",
    "originLink": "https://media.ccc.de/v/mch2022-236-non-euclidean-doom-what-happens-to-a-game-when-pi-is-not-3-14159-",
    "originBody": "NewsRSS, last 100Podcast feed of the last two years SD quality Podcast audio feed of the last yearPodcast archive feed, everything older than two years SD quality Podcast feeds for MCH2022 webm SD quality mp4 SD quality mp3opusNewsRSS, last 100Podcast feed of the last two years SD quality Podcast audio feed of the last yearPodcast archive feed, everything older than two years SD quality Podcast feeds for MCH2022 webm SD quality mp4 SD quality mp3opusbrowse conferences camp-NL mch2022 event Non-Euclidean Doom: what happens to a game when pi is not 3.14159… Luke Gotszling MCH2022 Curated content Playlists: 'MCH2022' videos starting here / audio 19 min 2022-07-23 2022-07-24 60529 Fahrplan We all know that the value of pi is a constant with a particular immutable value. Anyone who has done any graphical programming also knows that visual rendering relies not just on pi but trigonometry more broadly as well as other mathematical techniques. If we look into the source code of the first person shooter Doom we find that the value of pi used in the game is wrong. In this talk I will explore what happens when we subtly and not so subtly break math in the source. Doom is a well known classic first person shooter game with source code released under the GPL in 1999. In this talk I will begin by exploring what happens to the game when we make the value of pi even more wrong. What about when we change other trigonometric functions and constants to incorrect values? How will our familiar understanding and ability to traverse this virtual world change when we do this. Are there any interesting gaming possibilities with non-Euclidean geometries? A brief segway will cover some optimization tricks made to enable the game to run well on hardware available at the time. At the end I will provide a link to other games and public source code repositories that also use an incorrect value of pi. Pointers will also be provided to allow the audience to compile their own incorrect math version of the game. Download Video MP4 WebM Download 1080p eng 203 MB Download 576p eng 60 MB Download 1080p eng 187 MB Download 576p eng 59 MB Audio Download mp3 eng 17 MB Download opus eng 12 MB Embed Share: Tags mch2022 236 2022 MCH2022 Curated content by Chaos Computer Club e.V –– About –– Apps –– Imprint –– Privacy –– c3voc",
    "commentLink": "https://news.ycombinator.com/item?id=40389267",
    "commentBody": "Non-Euclidean Doom: what happens to a game when pi is not 3.14159 (2022) [video] (ccc.de)474 points by robin_reala 21 hours agohidepastfavorite139 comments ColinDabritz 17 hours agoThere was an example of this in the classic 'Duke Nukem 3d'. It had a level by Richard \"Levelord\" Gray, 'Lunatic Fringe'. https://dukenukem.fandom.com/wiki/Lunatic_Fringe This level had a circular hallway ring around the outside that had two full rotations around without intersecting, using the 'build' engine's ability to separate areas by their room connections that also drove the 'room over room' technology which was groundbreaking at the time. It made for fun multiplayer, and the illusion held well there. The central chamber has 4 entrances/exits if I recall, and you would only encounter two of them in each loop around the outside. I recall building a toy level while experimenting with the engine that \"solves\" the \"3 houses with 3 utilities without crossing\" puzzle using this trick as well. reply lucianbr 15 hours agoparentIn what sense is the Duke Nukem thing \"an example of this\"? The duke thing is an internally consistent programmed behaviour, this is... just random errors caused by a random change in the source code. Duke is maybe non-euclidean geometry, or something. This doom pi thing is... nothing to do with geometry. More an example of \"garbage in, garbage out\" maybe. reply ColinDabritz 11 hours agorootparentIt's an example of \"non-euclidean\" space, and yes, it is a bit different than the article. reply dfox 16 hours agoparentprevRoom over room (as done in later build games) usually does not require the sectors to overlap in this manner as it is a different thing (it is extension of how swimable water works, where the engine renders the other sector instead of floor/ceiling). While Lunatic Fringe is pretty in-your-face example of impossible geometry in build, the duke3d maps contain many more cases of intersecting geometry. Obviously such things are impossible in Doom because there is no way to build BSP tree out of that and because doom only tracks X/Y coordinates of player(s)/monsters. reply somat 7 hours agorootparentSure you can do this in doom, or at least it can be done in modern source ports. https://www.youtube.com/watch?v=Iq1-TZXz9xo (myhouse.wad) There is nothing about the data structures ID choose to use in doom that prevent portal shenanigans. ID(John Carmack) just did not implement them. reply anthk 1 hour agorootparentModern source ports are a totally different thing. If any, try to do what the former comment states with a Boom compatible engine as Crispy Doom or Chocolate Doom. reply formerly_proven 15 hours agorootparentprevNo mention of the real Prey (2006) in a discussion of weird geometry in games? reply wizzwizz4 16 hours agorootparentprevIs there no way of building a BSP out of it? I don't see why it has to be Euclidean to be partitioned, and loops are also possible (e.g. Deimos Lab). (The coordinates are definitely a blocker, so this question is academic.) reply dfox 14 hours agorootparentThe “sectors” in the resulting level data have to be convex for the doom engine. The “asset pipeline” handles that by breaking up non-convex geometry into smaller convex sectors. So, there are no loops or holes in the actual level data, also from the cursory glance both of the large loops in Deimos Lab are actually not complete loops, but they have a place where the loop is broken. But that does not matter that much, as almost any level contains geometry that is either concave or has a hole (courtyard in E1M1, both large rooms in MAP01…) reply immibis 2 hours agorootparentprevThe Doom design starts with X,Y,Z and then finds your BSP node. You can't warp to a different X,Y,Z without some type of warp portal which doesn't exist in Doom. Modern Doom forks have this feature and also have graphics portals so you can implement this (as MyHouse.pk3 does). reply ant6n 15 hours agorootparentprevPortals allow weird stuff (non linear geometry) in a BSP level. I thought Doom had petals. reply jorvi 52 minutes agorootparentThere is a very interesting Doom level named “myhouse.wad” that does a lot of clever things to seemingly allow room-over-room. reply dfox 14 hours agorootparentprevThe primary thing that BSP does is that it maps coordinates onto a BSP node/sector. Thus you cannot have overlapping geometry, as this mapping would not be unique. Quake has some idea of portals (I'm not sure about Doom), but it is used only as an additional layer of optimization, the engine is not fundamentally portal-based. reply justsomehnguy 16 hours agorootparentprev> only tracks X/Y coordinates of player(s)/monsters. It does, otherwise Lost Souls and Cacodemons wouldn't able to fly. reply dfox 16 hours agorootparentI meant that as in contrast to build tracking the sector the thing is in. Due to that you can have two sectors that intersect not only in 2D, but even in 3D and the engine still does the right thing (ignoring the fact that the renderer gets slightly confused when there are overlapping sectors in the view) reply whoopdedo 16 hours agoparentprev> the 'room over room' technology which was groundbreaking at the time. Bungie's Marathon from 1994 could also do this and demonstrated it in the deathmatch map 5-D Space[1]. It was really only Doom that bugged out on overlapping sectors. [1] https://www.lhowon.org/level/marathon/30 reply thaumasiotes 55 minutes agoparentprev> the \"3 houses with 3 utilities without crossing\" puzzle In graph theory's terminology, this is \"K3,3\", one of two irreducible nonplanar graphs. The other one is K5. You can also make all the connections without crossing any edges if you embed the graph in a torus, which is equivalent to building a bridge over some set of edges that other edges are allowed to take. reply Synaesthesia 10 hours agoparentprevThis video does a good job explaining it, yes it really is quite mind-bending. https://www.youtube.com/watch?v=UitzmhJe578 reply immibis 2 hours agoparentprevI wrote a little engine with this capability a long time ago. I didn't know about the Build engine at the time. I divided the world into convex sectors and allowed arbitrary links (portals) instead of following a BSP tree. Rendering is front-to-back and clips at the portal boundary. If you can rasterize the inside of a convex shape, you can rasterize a sector-portal-world by marking certain faces as portals, and when rendering one, setting the clipping region (or stencil buffer) to where the face would be, then rendering the sector behind it with an appropriate transformation (which is part of the portal's data, alongside the ID of the other sector). Collisions through portals are much harder than rendering through portals. reply jandrese 16 hours agoparentprevI remember a Descent PVP level that was a big room with a corridor that came off of one end and went to the other by looping back through the main room but was not visible inside of the main room. Was a bit of a mindbender in a game that already stretched the players spatial awareness. reply SJC_Hacker 16 hours agoparentprev> also drove the 'room over room' technology which was groundbreaking at the time. Descent did this in 1994. reply ChrisClark 15 hours agorootparentDescent was a polygonal game though, Duke3D was a raycasting engine. It was the first four a raycasting engine, and quite impressive. reply mysterymath 11 hours agorootparentDuke3D isn't a raycaster; it's a portal-based quad rasterizer. Wall quads are forced vertical, and floor quads are rasterized using a neat trick. The renderer computes successive lines of constant distance along slooped floor surfaces, then draws textures using affine scaling, which is correct along those lines. The portal walls clip the draw of successive sectors, which solves the hidden surface problem. https://fabiensanglard.net/duke3d/build_engine_internals.php reply PaulHoule 19 hours agoprevFunny I was just reading this Poul Anderson classic https://en.wikipedia.org/wiki/Operation_Chaos_(novel) which is set in an parallel world where magic is real and advancing rapidly along with science. (e.g. Edwin Land invents a device to transform a werewolf without moonlight using polarized light) The protagonists have their child kidnapped and brought to Hell. They are told that the Army had tried to investigate Hell 20 years ago but everyone was driven insane. An adversary drops the hint that the space-time geometry of Hell is different from ours so it would be possible to go back in time and retrieve the child at the moment it arrives. This is enough of a hint for scientists to determine that the geometry of Hell is non-Euclidean and figure out spells for getting there safely, keeping safe, and getting back. They pray to get the assistance of two 19th century geometers, one a saint, to be able to navigate. reply idoubtit 17 hours agoparentThe space-time geometry of our world is not Euclidian, not even Riemannian. The story of \"Operation Chaos\" looks more chaotic than scientific. That fits with the books of Poul Anderson I've read, like the excellent High Crusade: he likes going wild and doesn't care much for the scientific pretense. For another take on non-Euclidian geometries, I have good memories of Inverted World by Christopher Priest. reply PaulHoule 17 hours agorootparentI read a lot of sci-fi as a kid but really never got into Anderson despite there being a lot of Anderson books at the library but I do remember enjoying Tau Zero (a better story about Bussard Ramjets than any of Niven's... And funny Niven was my favorite author when I was 10 and I've got much less regard for him now, the Pak really spoil Known Space for me) I wound up re-reading Tau Zero and was really blown away which got me reading the Ensign Flandry books, Corridors of Time, Star Fox, etc. I don't agree with his politics any more than I agree with Niven or Heinlein but enjoy his books anyway. I'm planning to read all the Anderson books at my library. Heinlein wrote a few crossover books like \"Glory Road\" and \"Magic Inc\" but those were the exception for Heinlein and closer to the rule for Anderson because Anderson was just as important as a fantasy writer as a sci-fi writer. I do have a copy of The Inverted World that I ought to read. reply andrewflnr 8 hours agorootparent> the Pak really spoil Known Space for me Out of curiosity: why? They are rather silly, but I'm mostly thinking about their implausible evolutionary history when I say that. reply dekhn 19 hours agoparentprevSee also Jack Vance's wonderful story collection Tales of the Dying Earth, which also includes magic/science and daemon dimensions. reply torginus 18 hours agoparentprevThis might come off as trite (and it probably is) but why don't we get novels this creative nowadays? reply jmdeon 18 hours agorootparentHonestly sounds like you're just disconnected from the culture. There are plenty of creative novels coming out these days. For a specific example check out Adrian Tchaikovsky's work. Also you may want to subscribe to a short story publication like Clarkesworld. You'll have a drip feed of aspiring creative writers and can follow the ones you find especially good for when their forthcoming novels come out. One that especially blew me away from Clarkesworld recently was Axiom of Dreams by Arula Ratnakar. https://clarkesworldmagazine.com/ratnakar_09_23/ reply pas 11 hours agorootparentprevhttps://en.wikipedia.org/wiki/Diaspora_(novel) and of course other Greg Egan works reply mr_toad 5 hours agorootparentIn particular Dicronaughts is quite mind-bending, with its two time dimensions. reply TheAceOfHearts 11 hours agorootparentprevStories with creative magic systems are still being produced. Check out Unsong, by Scott Alexander. It's about a world that's programmable by Hebrew and Kabbalah. reply com2kid 16 hours agorootparentprevLaundry Files just recently had some novels that involves cool weird dimensions. The last Bobiverse book was about infiltrating a spaceship that is an artificial world. Heck Bobiverse in general has some cool ideas. The Andrea Vernon books are a hilarious take on the superhero genre. reply PaulHoule 15 hours agorootparentThe Bobiverse books are great IMHO. reply yau8edq12i 17 hours agorootparentprevHave you actually read recent SF novels? Think what you will about awards, but I've never been exceedingly disappointed when I read a novel that won a couple out of Hugo, Locus, and Nebula. I'd suggest you start there. reply PaulHoule 18 hours agorootparentprevI liked this one https://www.amazon.com/Terraformers-Annalee-Newitz/dp/125022... reply moomoo11 11 hours agorootparentprevI wonder that as well. And the same for movies, games, etc. I think in order to \"play it safe\" against the 1% of people who cry over the dumbest shit, but who happen to screech the loudest, creators make everything about someone's feelings, edge case stuff you hardly see represented in day to day. You weave that web enough and you end up with the \"creative\" output of something like Gemini lol. reply adammarples 2 hours agorootparentYou do, but then you get games like Sunless Sea which are praised by critics but don't sell millions reply drdeca 10 hours agorootparentprevHuh? I would imagine that content that is about people’s feelings and the things those feelings are about, would be more likely to offend? Who gets offended by content about like, “How navigation would be different if space were like X?” or, “How would sheet music for music in a world with two time dimension look? Might we have music where along one direction the frequency is increasing in magnitude, but decreasing along another, played to depict a scene in which a pursuer gets closer to a target along one direction of time but further along the other?” ? (Though, I’m not sure if two time dimensions exactly makes sense, because like, R\\{0} has two connected components, which seems connected to the distinction between the past and the future, while R^2\\{0} is connected (though not simply-connected) , so I’m not sure if the distinction between past and future, can still be made? Maybe if instead of a 0-dimensional point we have a 1-dimensional curve? ) As I imagine it, for the most part, the further something is from human experience, the less it would tend to remind people of whatever things in life they find objectionable. reply moomoo11 9 hours agorootparentBecause in trying to tell that kind of interesting story today, the creators would force the current day politics and other bullshit into it and make that the front and center instead of the cool math or science stuff. If even simple children's stories can't escape it with the remakes, forget it when it comes to something interesting. I'm always happy when there are exceptions to this of course, but it is quite rare. One of my goals if I ever make it to the 9 figure club is to start a media company based outside the US where we can make great content about interesting concepts like this, without injecting politics into it or having to work with people who inject nonsense into everything. (on a side note, this is why I enjoy working with E. Euro and S. American engineers - they just focus on working and problem solving, not feelings and shit based on half truths they made up from taking drugs or whatever) Anyway I was just responding to why stuff like that isn't made anymore. That's my opinion. reply fennecbutt 7 hours agorootparentprevAre you complaining about gay characters existing or something? Cause if you are then aaa lmao reply cubefox 16 hours agoparentprevThat sounds awesome. reply mmcdermott 18 hours agoparentprevI loved Operation Chaos, but I found the much later sequel to be disappointing. reply jrockway 13 hours agoprevJohn Carmack may have misremembered the 10th digit of pi, but you should all search your codebases for 84,600 and see who typo'd the number of seconds in a day. It is surprisingly common and there is a lesson about whether or not you should type constants into your program when they likely exist in the standard library of your programming language. reply Pikamander2 1 hour agoparentOh wow, you weren't kidding. Even big projects like MySQL and Textmate look like they might have that error in their codebase. https://github.com/search?type=code&auto_enroll=true&q=84600 https://github.com/mysql/mysql-server/blob/824e2b4064053f7da... https://github.com/textmate/textmate/blob/346b52b108b387462d... reply mywittyname 12 hours agoparentprevI spent an embarrassing amount of time debugging why some token refresh code that was supposed to trigger every 15 minutes didn't. Eventually I had to just print out the value for each variable and found that I defined 15 minutes as 15 * 60 * 60... reply spacebanana7 2 hours agorootparentI’ve encountered similar issues for long lived tokens in cookies on Safari. Turned out my Maths was okay, but Safari under many circumstances removes first party cookies after 7 days. https://snowplow.io/blog/tracking-cookies-length/ reply water-your-self 11 hours agorootparentprevI like defining constants with math. reply ClassyJacket 12 hours agoparentprev*the number of seconds in most days reply HPsquared 11 hours agorootparentDepends what planet you're on too, I suppose. reply sambazi 1 hour agorootparentearth has leap seconds reply thaumasiotes 50 minutes agorootparentBut those don't increase the number of seconds in the day. Instead, the final second happens twice. This is different from what happens in leap year, where February is actually lengthened and February 29 is considered a different day from February 28. It escapes me why leap seconds aren't treated that way. (I know, people say the stupid treatment of leap seconds is required by the POSIX definition of time. So what? Change the POSIX definition.) reply TZubiri 13 hours agoparentprevIf you can't do multiplication and you rely on a library for that. I feel sorry for you. reply jrockway 13 hours agorootparentIt's really a matter of who's going to catch your typos. If you use the constant built into your language, millions of people are looking at it. If you type them into your throwaway bash script, nobody is going to notice you typed 60 * 60 * 24 * 356 to get a year's worth of seconds. reply sva_ 12 hours agorootparentSo meta that you typed 356 instead of 365 reply tempestn 12 hours agorootparentThat was their point. reply ornornor 13 hours agorootparentprevMagic numbers something something. If your language provides it as a constant, why not use that? You’ll always get the correct value AND a descriptive name for free. reply nixpulvis 12 hours agorootparentprevIf I have it I’d use it, but I’m not going to go out of my way to add another dependency for it lol. reply DaiPlusPlus 19 hours agoprevWhat happens is the graphics and movement get glitchy and eventually unplayable - I wouldn’t call this “non-Euclidean Doom” - just “consequences of messing with the constants of the universe” - whereas I’d expect an actual non-Euclidean Doom to be like this: https://youtu.be/kEB11PQ9Eo8?si=0HNlpGFBii2AIK1n reply jezzamon 18 hours agoparentTo be a bit pedantic, that video is incorrect in its use of the term non-euclidean. The folks behind hyperrogue made few videos that show actual non-euclidean geometry: https://youtu.be/yqUv2JO2BCs?si=AutaqS5unvT7cDjw Comparing some of the weird geometry effects in the doom video, like things sliding sideways when you move forward, I feel like it's reasonable to call this doom non-euclidean! reply llm_trw 14 hours agorootparentFor a more modern take (that's kid friendly) have a look at https://store.steampowered.com/app/1256230/Hyperbolica/ reply babypuncher 15 hours agorootparentprevPart of the problem is that Doom isn't truly 3D, it's a 2D universe with hacks to make it look 3D. So in the final presentation, you're seeing a facsimile of a universe where the value of Pi has only changed in two out of three spatial dimensions. reply lambdaxyzw 18 hours agoparentprevThis it's also not what non-euclidean means. It's just regular 3d world with portals. Games of that era often used portals in the engine, they just didn't use them to implement impossible rooms. I'm not trying to be nitpicky, but it's a common misunderstanding. For actual non-Euclidean stuff I recommend ZenoRogue stuff. For example a simple game with Nil geometry[1], giantic bossfight in non euclidean world rogue game[2], or some general geometry weirdness [3]. Or just check out any of their stuff. [1] https://m.youtube.com/watch?v=gejRg_q70EA&pp=ygUJemVub3JvZ3V... [2] https://m.youtube.com/watch?v=jcnXI8IArRI&pp=ygUJemVub3JvZ3V... [3] https://m.youtube.com/watch?v=yqUv2JO2BCs&pp=ygUJemVub3JvZ3V... reply jerf 16 hours agorootparent\"Non-Euclidean\" is probably just fine meaning \"literally anything other than straight Euclidean\". Euclidean geometry doesn't have portals in it. Being truly hyperbolic or spherical is an interesting case but I don't think we have to insist that's the only viable meaning. Adjoining portals to Euclidean geometry by my reckoning breaks 3 of the 5 core axioms of Euclidean geometry... which means by sheer axiom break count, Euclidean geometry plus portals is \"more\" non-Euclidean than spherical or hyperbolic geometry. (Which may not seem like a terribly meaningful count, but I think would be reflected in what proofs in a portalized space would end up looking like. You'd grow a forest of case analyses and conditions in even the simplest proofs.) (And it's possibly 4 axioms broken; I'm reckoning \"all right angles are equal\" as still holding, though I'm not 100% sure a \"normal\" right angle and a right angle generated where a portal bisects the angle is necessarily \"equal\" in all relevant ways. It's been a while since I did geometry proofs but the more I ponder it the less sure I am. If not that would leave only \"a straight line segment can be prolonged indefinitely\" as holding, and unlike in Euclidean geometry a straight line segment may intersect itself arbitrarily often.) reply j2kun 16 hours agorootparentOfficially it cannot be called a \"geometry\" at all if it does not satisfy the other axioms. So it's a \"non-Euclidean non-geometry.\" reply jerf 16 hours agorootparentFair point. reply lupusreal 15 hours agorootparentprevWhat if it satisfies an as-of-yet undiscovered set of axioms? reply mrighele 14 hours agorootparentAxioms are not discovered but decided. A nice set of axioms gives birth to interesting anduseful interactions which you are the one that you discover, although in practice there's is a bit of back-and-forth, as you decides the axiom based on what you are trying to achieve and they get changed or tuned as time pass. Bonus point if the new axioms play well with existing ones, and are useful to work on our reality. reply jerf 15 hours agorootparentprevThe math term \"geometry\" has a certain definition. Things that fit it are geometries, things that don't, aren't. The gee-whiz \"what if\" sort of question your asking doesn't really mean anything anymore. In about the mid-20th century math finally came to terms with basically anything you can define being a valid subject of investigation. Arguments about whether things like \"imaginary numbers\" are \"real\" and therefore worthy of study are largely gone now. (Whether they are \"real\" for some definition is now a philosophy question.) Since axioms define the system you are building, if you want \"Euclidean except plus portals\" you just need to write them down and start studying them. There are multiple possible sets that describe different systems; for a trivial example, you can assert in an axiom that area is conserved on passing through a portal, or you can write axioms that don't conserve that, and follow the implications from there. Video games have had both kinds of portals. Do portals need to be straight or can they be curved? What do curved portals do to other curves if they pass through them? Does \"passing through them\" even mean anything (note Euclidean geometry doesn't have \"time\" in it)? How crazy can I be with the portals? What happens if I define a portal as having a boundary corresponding to a Cantor set [1] and pass a line through it in an axiom system that has \"time\"? There is no one answer to that question, it depends on the axioms you write down, which may or may not even permit such portals. Mathematicians will accept any and all of these systems if you write them down. Some may prove to be \"uninteresting\". Some may prove to have contradictions in them. But it's been a long time since a mathematician would even consider berating you about any of those choices not being \"realistic\" or something. And I expect it is very likely some topologist somewhere could hear all these idle musings of mine and say \"Oh, yes, you want to go to $TOPOLOGY_SUBDISCIPLINE for that.\" I don't know what the subdiscipline is or I'd name it, but I'm sure there's something already out there for all this. Since the mathematicians stopped worrying about \"realness\" they've really spread their wings as as discipline. [1]: https://en.wikipedia.org/wiki/Cantor_set reply drdeca 9 hours agorootparentRather than including “portal” as a kind of thing in your space, I would think to just say, “around each point, there is an open ball such that the metric (not the metric tensor, just the d(x,y) thing) is the same as a ball in Euclidean space”. Oh, and then I guess you could add requirements that for any continuous path along with a, continuous choice of an orthonormal basis of the tangent space, along that path, that uh, transporting small volumes along it, not change the volume? reply j2kun 14 hours agorootparentprevIt can be given an as-of-yet unchosen new name :) reply thaumasiotes 46 minutes agorootparentprev> If not that would leave only \"a straight line segment can be prolonged indefinitely\" as holding, and unlike in Euclidean geometry a straight line segment may intersect itself arbitrarily often. This one might not hold either, depending on your point of view. If you take the point of view of someone traveling along a line, that can still go on forever. But if you're measuring the line, portals can easily prevent it from extending indefinitely, by wrapping it around to an earlier part of itself. It would then fail to be the case that, for any distance, there are two points on the line separated by at least that distance. reply kqr 18 hours agoparentprevI'm surprised nobody has brought up Antichamber yet. It was an excellent game using a similar concept to create actual puzzles. Come to think of it, long enough has probably passed that I might enjoy replaying it. reply solardev 13 hours agorootparentIf you like that, take a look at Viewfinder too: https://store.steampowered.com/app/1382070/Viewfinder/ You take pictures to create portals to other parts of the level, but in any orientation/angle that you want. reply astrange 4 hours agorootparentSuperliminal is also good. (https://store.steampowered.com/app/1049410/Superliminal/) reply cubefox 17 hours agorootparentprevThat's a great game, but it only uses portals to locally break the rules of geometry. The phrase \"non-euclidean geometry\" normally means either hyperbolic of elliptic (spherical) geometry. reply hcs 12 hours agorootparentprevAlso consider Manifold Garden. reply mock-possum 23 minutes agorootparentMan I spent so many happily stoned hours digging into that game. Sometimes I’d get stuck and just spend some time throwing myself off the edge of a cliff face and falling into eternity, watching the fractal platforms just unfold around me, until I felt like nudge my course back over to solid ground and resume puzzle solving. reply torginus 18 hours agoparentprevThis looks like portals. Essentially how FPS games of that era worked is that they had rooms stitched together by doorways (or 'portals') as a way of occlusion culling. While perfectly capable of representing sensible geometry, it was actually not a requirement that the geometry should make sense in any shape or form and allowed arbitrary connections between rooms. reply neglesaks 17 hours agorootparentThe Marathon 1+2 engine back in the 90s allowed for \"5D space\", ie. \"Spatial\" Rooms that were capable of overlapping each other, because the engine only defined the floor polygon with a given height and these floor polys were connected to each other at the vertices to create the actual level spaces. So even though you were in the same absolute space coordinate as another player, you were not necessarily in the same room. Good times.They are also used twice in the campaign (contrary to the commentary's claim that they are only used once): in the GLaDOS wakeup sequence where they are used to connect the incinerator shaft to GLaDOS' chamber, and in Finale 2 where they are used to connect the \"trap\" chamber to the main map. These are the only uses of this entity in the final game. reply sebazzz 17 hours agorootparentprevIf you like this, try Superliminal (https://store.steampowered.com/app/1049410/Superliminal/) reply INTPenis 1 hour agoprevGreat lecture. I just started getting into Doom levels through a friend who's obsessed with Slade and Doom Builder. It's an amazing community 30 years later, but I still prefer Quake and its mods. Much more modern. reply treflop 16 hours agoprevDoom isn’t a simulation so changing a constant isn’t really an example of anything. It’s just screwing with some routines. Thats why most of the changes are unplayable. reply lucianbr 15 hours agoparentYeah, I have no clue why this is interesting. Of course changing a constant to a wrong number causes weird behaviour or errors. How else could it be? And the weird behaviour does not seem to be special in any way. What am I missing? reply hnlmorg 1 hour agorootparentI don’t think you’re missing anything. Some have found the comments on this video to be more thoughtful than the content of that presentation. I was hoping when he mentioned other projects that he’d found on GitHub and Google that he’d talk a little about them too but alas he shared that he just clicked search and then did nothing with the results. A big missed opportunity in my opinion. Still, at least the comments on HN were largely worthwhile. reply treesknees 14 hours agorootparentprevI agree it wasn't super exciting. But I still like to see the little niches and topics other people find interesting even if they're pretty obscure like this. Obviously enough people found it interesting that this guy gave a talk and received audience questions. I'd like to see something like this [1] where we can find out how many digits of pi you really need to make Doom play normally. But again, not super exciting. You would just need to iterate from 1 to 9 digits and apply some subjective rules about what counts as normal. [1] https://www.jpl.nasa.gov/edu/news/2016/3/16/how-many-decimal... reply AshamedCaptain 19 hours agoprevGet the source code of your favourite console emulator. Insert random floating point errors or reverse the meaning of some of the branch opcodes. Enjoy. The older the game, the more likely it will still work, and the more likely it will look like going on a bad trip. reply frakt0x90 16 hours agoparentThere was a tool a long time ago that did this for an n64 emulator. I tried it and it was fun for a while but predictably would crash often. There was also a glitch art project that would corrupt specific segments of famous image and video files to create something new. I wish I could find either but I cannot. reply mnw21cam 17 hours agoprevThe question at the end - what is the highest value of pi that is playable (doesn't crash). I'm suspecting that when pi is 4, it segfaults because some accesses to the lookup table fall off the end of the lookup table, and therefore the highest value of pi that will be playable is likely to be a very small amount higher than pi itself. reply cruffle_duffle 18 hours agoprevI wish this video went more into the game mechanics and why changing Pi messed with things the way it did. reply hilbert42 28 minutes agoprevUm, interesting, that has the smell of the Pentium bug about it. Not so much the incorrect value of pi but the lookup table. This Doom illustration reinforces the lesson from the Pentium bug that substituting a lookup table for a slower but correct algorithm is a bad idea unless absolutely necessary. reply EDM115 1 hour agoprevLet's round pi to 2 and forget about it reply jerf 19 hours agoprevI wonder if this would be more interesting in the raytraced Doom referenced. Hacking constants with rasterization techniques pretty much produced the results I expected. But raytracing may have more interesting results. reply matheist 14 hours agoprevIn the context of differential geometry, π is still π even in the context of non-Euclidean manifolds. The distinguishing feature (again, in differential geometry) of non-Euclidean geometry is that it has non-zero sectional curvature. One way to measure sectional curvature is to measure the circumference of a small circle and check how it deviates from what would be expected of a Euclidean circle. Euclidean circumference: C(x) = 2 π x. Circumference taking sectional curvature into account, for small x: C(x) = 2 π x - (1/3) K π x^3 + O(x^4), where K is sectional curvature. (The negative sign in the second term means circumferences are smaller than Euclidean when curvature is positive, like on a sphere, and are larger than Euclidean when curvature is negative, like on a saddle.) Curvature can then be measured by taking the third derivative of circumference at 0: C'''(0) = -2 π K. π can still be computed by taking the first derivative of circumference at 0: C'(0) = 2 π, independent of curvature. So even non-Euclidean geometry respects the value of π. reply fecal_henge 2 hours agoprevPi = 3 just looked like some of the more budget games of the era. reply cheschire 16 hours agoprev8:30 Pi = 3 9:30 Pi = e 10:30 Pi = Pi/2 11:15 Pi = 0.00001 12:00 Truth table of compiled and playable values reply mywittyname 15 hours agoparentI kind of wish the author of the talk worked with smaller increments, so you could get an idea of how the world was deviating from the original. By the time he gets to e, everything is completely warped, but it's hard to grok in what way it's warped. My take away from the entire talk was, if you change pi, the walls move. But I still don't understand how they move and what changing pi is actually doing. reply germinator 15 hours agorootparentI think it's mostly messing up viewport and movement calculations, which is why you have textures popping into view when already in the viewport, and shifting too much in the periphery. In essence, you're just mildly glitching the display. It doesn't really alter the map or the spatial relationship of items. You'd need more fundamental game engine changes to really implement a different geometry. reply fjfaase 14 hours agoprevI understand that the inspiration for this talk comes from the fact that Doom is using 3.141592657 instead of the correct 3.141592654 in the source code. John Carmack admits that he incorrectly recalled the ten digit op pi. reply nuancebydefault 13 hours agoparentHe didn't recall it correctly? Why didn't he asked Siri on his cell connected iPad? reply fjfaase 11 hours agorootparentThe original Doom was released in 1993 for DOS [1]. The iPad came in 2010 [2]. Siri was only released in 2011 [3]. [1] https://en.wikipedia.org/wiki/Doom_(1993_video_game) [2] https://en.wikipedia.org/wiki/IPad [3] https://en.wikipedia.org/wiki/Siri reply hnlmorg 1 hour agorootparentI think the GP was making a sarcastic point about how much harder it was to confirm assumptions like the 10 digit constant of pi reply foota 15 hours agoprevMy favorite non Euclidean game is antichamber. It's a bit dated now (and the graphics are kind of eye burning) but it was a neat puzzler. Edit: I had the name wrong, ita antichamber! As many others have correctly stated. reply immibis 2 hours agoparentTurn your screen brightness down. This solves so many cases of \"I have to use dark mode or my eyes burn.\" reply foota 1 hour agorootparentMaybe it would help, but I remember the issue being more the sharp contrast and weirdly vibrant colors than the actual brightness itself. reply immibis 41 minutes agorootparent.... turn your screen contrast down too. reply torginus 18 hours agoprevHonestly, I'm not even sure where does PI factor into gameplay code, like collision detection or movement. I mean there are things like circular explosion radiuses which would get scaled but not necessarily in an interesting way. The fact that rendering gets effed up is no surprise. reply chungy 18 hours agoparentAll of Doom's movement code is based on radians. reply ajxs 3 hours agoprevThis brought this other video to mind: https://www.youtube.com/watch?v=jQOJ3yCK8pI See also: https://github.com/shaunlebron/blinky Using non-standard projections in Quake. reply Angostura 11 hours agoprevI ways surprised how almost instantaneously nauseous some of those made me feel. e and pi/2 were straight into barf territory reply huhtenberg 16 hours agoprevAny playable values above π? I'd guess 3.15 should still be OK. reply mrighele 14 hours agoprevI wonder if it plays properly with a value of pi equals to 3.2, that would make a few people in Indiana happy. reply Waterluvian 17 hours agoprevMarathon 1 (1994) supports non-Euclidean spaces but only got used sparingly. So there’s this whole game of levels with maps, and then one or two levels with impossible spaces that the game doesn’t warn you about or tell you it could exist. So it’s possibly the best Easter egg location I’ve ever found in a game. Found a video that demonstrates it: https://www.reddit.com/r/Marathon/comments/vclu55/probably_n... reply metadat 4 hours agoparentMarathon was so much fun on the old Macintoshes with OS6 and OS7! reply AdmiralAsshat 19 hours agoprevHN Hug of Death? Having a hard time getting the video to load more than a half second before needing to buffer, even at lowest resolution. reply aeontech 18 hours agoparentSame talk on YouTube: https://youtu.be/_ZSFRWJCUY4 reply system2 4 hours agoprevWow the JPEG injection was super cool. reply ngneer 6 hours agoprevpi is never 3.14159 reply osigurdson 18 hours agoprev [–] In a previous reality, Pi did equal 3. It was crazy! March 0 Pi day, what! reply adzm 18 hours agoparent [–] You mean March 0 of course, which is leap day. reply osigurdson 18 hours agorootparent [–] Agree! reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The summary highlights NewsRSS, podcast feeds, and the upcoming MCH2022 event.",
      "A talk at the event will delve into the repercussions of utilizing incorrect mathematical values, specifically pi, in the source code of the video game Doom.",
      "It will discuss how changes in trigonometric functions and constants impact gameplay and share optimization techniques from the game's development."
    ],
    "commentSummary": [
      "The post explores non-Euclidean space in video games using Duke Nukem 3D and Doom as examples, emphasizing Binary Space Partitioning's constraints and potentials in Doom's level design.",
      "It discusses the utilization of portals to achieve non-linear geometry, embedding graphs in torus, and portal-based rendering engines, highlighting the influence of non-Euclidean geometry on gameplay.",
      "The article also touches on adjusting mathematical constants in game code, the significance of π in gaming, and implementing radians in movement code."
    ],
    "points": 474,
    "commentCount": 139,
    "retryCount": 0,
    "time": 1715949794
  },
  {
    "id": 40394778,
    "title": "Ex-OpenAI staff face aggressive no-criticism contract",
    "originLink": "https://x.com/KelseyTuoc/status/1791584357184127269",
    "originBody": "But when you actually quit, the &#39;general release&#39;? It&#39;s a long, hardnosed, legally aggressive contract that includes a confidentiality agreement which covers the release itself, as well as arbitration, nonsolicitation and nondisparagement and broad &#39;noninterference&#39; agreement.— Kelsey Piper (@KelseyTuoc) May 17, 2024",
    "commentLink": "https://news.ycombinator.com/item?id=40394778",
    "commentBody": "[dupe] Ex-OpenAI staff must sign lifetime no-criticism contract or forfeit all equity (x.com)421 points by apsec112 11 hours agohidepastfavorite5 comments ChrisArchitect 9 hours ago[dupe] https://news.ycombinator.com/item?id=40393121 reply dang 8 hours agoparentI guess we'll move the comments thither, both since that post was submitted earlier and also because the article gives more background. reply lupire 10 hours agoprev [–] When I click the link, I see nothing about Open AI in the tweet displayed. This is not a valid form of discourse. reply apsec112 10 hours agoparent [–] There's a full length article here: https://www.vox.com/future-perfect/2024/5/17/24158478/openai... reply ChrisArchitect 8 hours agorootparent [–] Why didn't you just share that? Oh it already was https://news.ycombinator.com/item?id=40393121 reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "When quitting a job, a comprehensive release contract might include clauses for confidentiality, arbitration, nonsolicitation, nondisparagement, and noninterference agreements."
    ],
    "commentSummary": [
      "Former OpenAI employees are required to sign a lifetime no-criticism agreement to keep their shares in the company.",
      "The information first surfaced on x.com and has elicited debates on platforms like Hacker News.",
      "For a detailed overview, refer to the extended coverage on Vox."
    ],
    "points": 421,
    "commentCount": 5,
    "retryCount": 0,
    "time": 1715985291
  },
  {
    "id": 40389445,
    "title": "Toon3D: Creating 3D views of hand-drawn cartoons",
    "originLink": "https://toon3d.studio/",
    "originBody": "Toon3D: Seeing Cartoons from a New Perspective Ethan Weber*2, Riley Peterlinz*2, Rohan Mathur2, Frederik Warburg1, Alexei A. Efros2, Angjoo Kanazawa2 * Equal contribution, 1Teton.ai, 2UC Berkeley arXiv Code Toon3D Labeler Demo Overview Video TLDR Humans can perceive 3D world from images that aren't 3D consistent, but why can't machines? COLMAP cannot reconstruct non-geometric hand-drawn images even with perfect correspondences! Toon3D can recover camera poses and dense geometry with piecewise-rigid deformable optimization. Hand-drawn scenes are not 3D consistent, so we create Toon3D to recover camera poses and dense geometry! We do this with a piecewise-rigid deformation optimization at hand-labeled keypoints and using monocular depth as a prior. Now we can interpolate novel views never before seen! Press the button to move the cameras between two viewpoints! Note that we reconstruct the scenes with more than two hand-drawn images, but this demo shows a smooth transition between just two of the inputs views. Move Cameras Abstract We propose Toon3D. In this work, we recover the underlying 3D structure of non-geometrically consistent scenes. We focus our analysis on hand-drawn images from cartoons and anime. Many cartoons are created by artists without a 3D rendering engine, which means that any new image of a scene is hand-drawn. The hand-drawn images are usually faithful representations of the world, but only in a qualitative sense, since it is difficult for humans to draw multiple perspectives of an object or scene 3D consistently. Nevertheless, people can easily perceive 3D scenes from inconsistent inputs! In this work, we correct for 2D drawing inconsistencies to recover a plausible 3D structure such that the newly warped drawings are consistent with each other. Our pipeline consists of a user-friendly annotation tool, camera pose estimation, and image deformation to recover a dense structure. Our method warps images to obey a perspective camera model, enabling our aligned results to be plugged into novel-view synthesis reconstruction methods to experience cartoons from viewpoints never drawn before. Cartoon Reconstruction (Left) We first recover camera poses and aligned point clouds. (Right) Then we initialize Gaussians from our dense point cloud and optimize Gaussian Splatting with the recovered cameras. Our method has depth regularization and is built on Nerfstudio. Here we show fly-through renders of our scenes. Here is the gallery of all our scenes. Can you guess which is which? Click to reveal names. Toggle Cartoon Names Bob's Burgers Family Guy SpongeBob SquarePants Rick and Morty Simpsons Spirited Away Futurama Family Guy Avatar BoJack Horseman Magic School Bus Scooby-Doo Method We first predict the depth of each image with Marigold and obtain candidate transient masks with SAM. We then label images with the Toon3D Labeler to obtain correspondences and mark transient regions. We optimize camera poses and warp images to obtain calibrated, perspective cameras. Finally, we can initialize Gaussians with the aligned dense point cloud and run refinement. Overview Toon3D Labeler Here you can see the two major steps of our method. The sparse alignment video shows rough camera parameter estimation. The dense alignment video shows various layers used in the method (e.g., cameras, sparse correspondences, warping meshes, etc.) and how they align in 3D. Sparse Alignment Dense Alignment Explore Inside Rick and Morty's House We reconstruct inside the Rick and Morty house by labeling between walls and ceilings to connect the rooms. In the first video, we show the point cloud & cameras and our custom labeling interface. In the second video, you can scrub the slider to see a walkthrough inside the house! The closest camera's image is shown in the bottom right corner. Point Clouds and Cameras Here we show point clouds and recovered cameras for the 12 cartoon scenes in the Toon3D Dataset. Click the icons to explore our scenes! Click a scene icon to start! Sparse-View Reconstruction We can reconstruct scenes from few images and with large viewpoint changes. Where COLMAP may fail, we can intervene with the Toon3D Labeler to obtain human-labeled correspondences. Here we show a fly-through rendering for two rooms (\"Living room\" and \"Bedroom 2\") of this Airbnb listing. Visualizing Inconsistencies Cartoons are hand-drawn so we need to warp the images to be 3D consistent. The first item is a video that shows the warp taking place during alignment optimization. The next two items are images which show the original and warped drawings, as well as the overlap between the two. Blurry regions indicate where a lot of warp occured. Video Image Image Reconstructing Paintings We can reconstruct paintings with Toon3D even though the paintings are hand-drawn. We predict the depth of each image, then align and warp point clouds. Finally we use Gaussian refinement to create the video shown below. BibTeX Please consider citing our work if you find it useful. @inproceedings{weber2023toon3d, title = {Toon3D: Seeing Cartoons from a New Perspective}, author = {Ethan Weber* and Riley Peterlinz* and Rohan Mathur and Frederik Warburg and Alexei A. Efros and Angjoo Kanazawa}, booktitle = {arXiv}, year = {2024}, } We would like to thank Qianqian Wang, Justin Kerr, Brent Yi, David McAllister, Matthew Tancik, Evonne Ng, Anjali Thakrar, Christian Foley, Abhishek Kar, Georgios Pavlakos, the Nerfstudio team, and the KAIR lab for discussions, feedback, and technical support. We also thank Ian Mitchell and Roland Jose for helping to label points. We thank the Nerfies authors for providing us with this website template.",
    "commentLink": "https://news.ycombinator.com/item?id=40389445",
    "commentBody": "Toon3D: Seeing cartoons from a new perspective (toon3d.studio)369 points by lnyan 20 hours agohidepastfavorite101 comments monitron 19 hours agoIt's interesting that they used the Planet Express building from Futurama as one of their examples of 3D-inconsistency, because I'm pretty sure the exteriors are in fact computer-generated from a 3D model. Watch the show and you can see the establishing shots usually involve a smooth complex camera move around the building. reply manifoldgeo 18 hours agoparentAgreed, most or all shots of the Planet Express building and Planet Express ship are 3D renderings, even in the original first few seasons. Beyond that, even some shots of Bender in Space are 3D renderings, especially in cases where a complex and continuous shift in perspective is required. Non-photo-realistic (NPR) 3D art goes back a surprisingly long way in animations. I rewatched the 1988 Disney cartoon \"Oliver and Company\" recently, and I was surprised to see that the cars and buildings were \"cel-shaded\" 3D models. I assumed that the movie had been remastered, but when I looked it up, I found out that it was the first Disney movie ever to make heavy use of CGI[0] and that what I was seeing was in the original. The page I found says: \"This was the first Disney movie to make heavy use of computer animation. CGI effects were used for making the skyscrapers, the cars, trains, Fagin's scooter-cart and the climactic Subway chase. It was also the first Disney film to have a department created specifically for computer animation.\" References ---------- 0: https://disney.fandom.com/wiki/Oliver_%26_Company reply Eduard 18 hours agorootparent> \"This was the first Disney movie to make heavy use of computer animation. [...]\" Tron came out 1982, six years before Oliver & Company. https://en.wikipedia.org/wiki/Tron reply interroboink 17 hours agorootparentI guess it depends on the definition of \"heavy use.\" I know in Tron a few scenes were CG, and there were a few CG+live-action bits, but the majority was filmed on normal physical sets in high-contrast, then painstakingly hand-processed[1] to add the neon \"glow\". [1] https://filmschoolrejects.com/tron-costumes-glowing-effect/ Thanks legions of Taiwanese animators (: reply croes 17 hours agorootparentFrom your link: >The 1982 Disney movie is privy to a remarkable number of firsts: the first feature-length film to combine CGI and live-action; the first talking and moving CGI character; the first film to combine a CGI character and a live-action one; the first fully CGI backgrounds… The list goes on and on. Sounds pretty heavy to me. reply croes 17 hours agorootparentprevAnd the film OP mentioned Oliver & Company: >Eleven minutes of the film used \"computer-assisted imagery\" such as the skyscrapers, the taxi cabs, trains, Fagin's scooter-cart, and the climactic subway chase I think Tron wins in terms of CGI reply nicklecompte 15 hours agorootparentprevBut Disney financed and distributed Tron. It wasn't made by a Disney Studio, and most of the animation was outsourced to a Taiwanese studio because Disney wouldn't lend any of their own talent. So I think it's fair to say that Oliver & Company is the first Disney-made film to use CGI. reply mrob 14 hours agorootparentThe Great Mouse Detective (1986) was earlier and the ending sequence is CG (printed out and traced onto cels so traditional 2D characters could be drawn on top). reply nicklecompte 14 hours agorootparentThat's a good point. What's funny is that \"The Great Mouse Detective\" was actually the film I was thinking of this whole time - I believe the ending sequence took place in Big Ben, and it looks quite good by 2024 standards. But I forgot the name of the movie and assumed it was \"Oliver & Company\" because Oliver is a plausible name for an English mouse :) reply RF_Savage 17 hours agorootparentprevAnd large amounts of the \"computer\" graphics in Tron are hand drawn. reply croes 17 hours agorootparentStill lots of CGI. reply loloquwowndueo 14 hours agorootparentprevProbably meant “Disney animated feature”. reply a1o 18 hours agorootparentprevFound a pretty cool wireframe video of Oliver and Company. https://m.youtube.com/watch?v=mix9rStOqoI Now I am curious to watch it reply justsomehnguy 12 hours agorootparentprevThe Rescuers Down Under comes to mind as the one close (1990) https://youtu.be/P5hHV2torG0?t=126 https://youtu.be/sGxLWXtt6EQ?t=73 https://en.wikipedia.org/wiki/The_Rescuers_Down_Under reply Jarmsy 18 hours agoparentprevIndeed many animated shows that don't look 3d animated have a 3d model somewhere in their pipeline these days. Even if there's not a digital 3d model, there might be a physical model of the main locations in the studio for animators to refer to. reply zoeysmithe 18 hours agoparentprevIsn't a lot of 3D in shows and games \"faked\" to look good to the viewer? I remember seeing this blog write up on what 3D animators do to make things look acceptable. Like make a character 9 feet tall because when the camera panned them, they looked too short at their \"real\" in-system height. Or archway doors that are huge but at the perspective shot, look \"normal\" to us. Or having a short character stand on an out-of-scene blue box to make them having a conversation with a tall character not look silly due to an extreme height difference? Or a hallway that in real life would be 1,000 feet long but looks about 100 in-world because of how the camera passes past it, and how each door on that 1,000 foot hallway is 18 feet high, etc. I wonder if shows like Futurama used those tricks as well, so when you sort of re-create the 3D space the animators were working in by reverse engineering like this, then you see the giant doors and 9 foot people and non-Euclidian hallways, etc. Just because it looks smooth as the camera passes it, doesn't mean that actual 3D model makes sense at other perspectives. reply Tallain 16 hours agorootparentI don't have a ton of experience in this realm but from what I've seen it does happen a lot -- looking good is often better than being right. A great example of this is the way they tilted the models for Zelda's A Link Between Worlds[0]. Basically everything in the world is tilted back so it looks better for the camera angle, which is designed to mimic the feel of A Link to the Past. [0]: https://www.gameinformer.com/b/news/archive/2013/11/20/the-t... reply Natsu 13 hours agorootparentprevI saw some video on A Difficult Game About Climbing a while back. The things they did to make the guy appear to grip the rocks and suck normally make the hands utterly bizarre when seen from the side. reply jsheard 18 hours agoparentprevYeah, Futurama used composited 3D elements from the very first episode in 1999. The vehicles are nearly always 3D. reply JonathanFly 19 hours agoprevCreating 3D spaces from inconsistent source images! Super fun idea. I tried a crude and terrible version of something like this a few years ago, but not just inconsistent spaces without a clear ground truth - purely abstract non-space images which aren't supposed to represent a 3D space at all. Transform an abstract art painting (Kandinsky or Pollock for example) into a explorable virtual reality space. Obviously there is no 'ground truth' for whatever 'walking around inside a Pollock painting' means - the goal was just to see what happens if you try to do it anyway. The workflow was: 1. Start From Single Abstract Art Source Image 2. SinGan to Create Alternative 'viewpoints' of the 'scene' 3. 3d-photo-inpainting (or Ken Burns, similar project) on original and SinGan'd images (monocular depth mapping, outputs a zoom/rotate/pan video) 4. Throw 3d-photo-inpainting frames into photogrammetry app (Nerf didn't exist yet) and dial up all the knobs to allow for the maximum amount of errors and inconsistency 5. Pray the photogrammetry process doesn't explode (9 times out of 10 it crashed after 24 hours, brutal) I must have posted an example on Twitter but I can't find the right search term to find it. But for example, even 2019 tier depth mapping produced pretty fun videos from abstract art: https://x.com/jonathanfly/status/1174033265524690949 The closest thing I can find is photogrammetry of an NVIDIA GauGAN video (not consistent frame to frame) https://x.com/jonathanfly/status/1258127899401609217 I'm curious if this project can do a better job at the same idea. Maybe I can try this weekend. reply localfirst 14 hours agoparentWhat is a technique/library that can take an image of a 3d environment/drawing of a room and detect a rough mesh highlighting ground, walls, barriers ? reply pcrh 11 hours agoprevI'm not a graphic artist, and appreciate how the illustrator's art involves many creative tricks of representation to convey complex meanings. However, the \"messy\" reconstructions of 3D space seen in these videos did make me think of the recent hype over LLMs. That is, the representations have a clear link to the \"truth\" or \"facts\" of the underlying material, but are in no way accurate enough to be considered useful as source material for further use. reply gosub100 8 hours agoparentI've posted this comment before but I'm excited to see if LLMs can write new episodes in the same vein as the previous ones. I think it would be really amusing to see \"new\" episodes of old cartoons ( albeit with an ensuing copyright shitstorm). reply jsheard 20 hours agoprevIt's... neat? But I'm struggling to think of what the applications of this would actually be. 2D artwork usually doesn't have a consistent 3D space, which they acknowledge, but they don't seem to have overcome that problem in any useful sense. The scenes are barely coherent once they move from one of the originally drawn camera positions. reply codetrotter 20 hours agoparentBoth Futurama and Family Guy sometimes use 3d rendering for vehicles for example, and render it in a cartoon looking style and composit it with flat 2d animations. Maybe similar kind of things could be an application of this. Another possible use-case might be a game development studio developing a license game based on a 2d cartoon, but making the game 3d. They could use this as a tool for visualization while planning and developing, to iterate quickly and to reference how the original 2d could translate into 3d. reply SiempreViernes 20 hours agorootparentNot really? In those examples the hand crafted 3d assets already exist, this thing could at best recreate the 3d geometries the show creators made themselves. That seems useful mainly for cloning someone else's work. reply codetrotter 19 hours agorootparent“Similar kind of thing” meaning for another show that wants to do the same but who have not created the 3d assets yet. Team of 2d artists draw the desired vehicles for the cartoon from two or three angles. Software like this makes a usable 3d model of it. reply jsheard 19 hours agorootparentIf you were making 2D drawings with the intent of turning them into a 3D model then you would draw them to be coherent in 3D in the first place. The whole novelty of the research in the OP is that they're trying to reconstruct drawings that were never intended to make realistic sense in 3D. Even if AI has a place in the 2D to 3D part of a pipeline, surely you'd still want the 2D artwork be unambigously representative of what the 3D asset should look like, rather than providing self-contradictory input data and praying that the AI can magically make it make sense. reply codetrotter 19 hours agorootparentTrue. For the second use-case I mentioned it still applies though. Where a studio is making a licensed 3d game based on an existing 2d cartoon. reply superb_dev 3 hours agorootparentprevA show that's being doing purely 2d art can't just integrate the 3d art in their pipeline on a whim. If they can, they probably already have the skills to make the model outright. reply chungy 16 hours agoparentprevSpongeBob brazenly violates 3D space rules (I mean, they also have fire underwater...). The writers and artists both draw heavy inspiration from Looney Tunes, where such rules are broken because it's funny to break them. reply wongarsu 17 hours agoparentprevA refined version of this could be used to make stereoscopic versions of cartoons. On the other hand you are probably better off only using the depth prediction and filling any voids in using image generation instead of this mapping process. reply jameshart 20 hours agoparentprevI could see some value maybe in giving an artist feedback on where the model detects inconsistencies between different viewpoints. reply jsheard 20 hours agorootparentThat assumes that consistency between viewpoints is actually desirable - part of the charm of 2D animation is that things can be stylized or exaggerated or simplified in ways that don't come naturally in a 3D workflow, where the \"default\" is for things to fit together realistically and any deviation from that takes additional effort. If you do want numerous 2D artworks which share a realistically defined 3D space then that can easily be done by making a very rough 3D scene and then painting over it, you don't need any AI for that. reply SiempreViernes 20 hours agorootparentprevIf consistency was highly desirable you'd just model the 3d space from the start... reply xsmasher 16 hours agoparentprevThe renders it creates are underwhelming, but it seems good at determining the location and angle of the camera. I could see it being used to create a \"scratch track\" that human animators animate on top of. An aid to tweening. reply timdiggerm 19 hours agoparentprevMaybe you could better construct a 3d model of a demolished landmark from old paintings and photos? reply theultdev 18 hours agoparentprevWith future advancements you could pump out video games for many series. While rough, these do look better than some implementations of the artwork for cartoon games. reply Waterluvian 19 hours agoparentprevI think this is just a device used to demonstrate and advance the technology. I doubt this has a real application in this context given how little work is needed to 3D model these kinds of environments anyways. reply foota 15 hours agoprevIt's kind of amazing that they're able to take drawing of a scene someone imagined and then create (bad) 3d models. Imagine if in the future an artist could sketch a couple of images from a scene and then get an accurate 3D model? Or if a 2D artist could sketch a couple of poses and automatically get a well structured 3D model and textures? I think there's been a lot of concern in the industry about the impact AI and similar tools will have on artists, but it seems like it's possible to imagine a future where machine learning based systems work more directly with an artist rather than rendering based on language etc., I don't know how I feel about all the moral arguments about AI training etc.,. I think to me more concerning is how it could impact people more so than how it was trained. Even if a perfectly \"ethically\" trained model learned to produce perfect art and artists became a niche field, I think it could still be a bad outcome for civilization as a whole because I think there's value in humans producing art, and in having a society where it's (at least somewhat) of a sustainable field. Otoh, I think it's amazing that people can produce the kinds of images using image models, so I'm not sure. Ideally we'd be able to support people in what they want without needing their to be a market for it, but the world's not ready for that. reply mattfrommars 18 hours agoprevIn the past after I got Quest 2 and started to dive into the world photogrammetry. I went into the entire pipeline into building a 3D *model* from photos of an object taken from different angle. Pipeline involved using MeshRoom and few other software to clean up mesh and port it into Unity. In the end (from my superficial) understanding, the problem with porting anything into VR (say in Unity in which you can walk around an object) is the important of creating a clean mesh. The 3D model that tools such as OP (I haven't dived deep into it yet) is these are point cloud in 3D space. They do not generate a 3D mesh. Going from memory from tools I came across during my research, there is tools like this https://developer.nvidia.com/blog/getting-started-with-nvidi..., again, this does not generate a mesh. I think it is just a video and not something you can simply walk around in VR. My low key motivation was to make a clone/model like what Matterport and sell it to real estate companies. Major gap in my understanding - the cause of me to loose steam is - I was not sure how are they able to automate the step to generate clean mesh from bunch of photos from a camera. To me, this is the most labor intensive part. Later, I heard there are ML model that is able to do this very step, I have no idea on this tho. reply owenpalmer 17 hours agoparentPerhaps using Unreal + nanite + PCVR would be a better option? Nanite can handle highly complex meshes and algorithmically simplify them in realtime. Basically a highly advanced LOD system. Not sure what limitations are but it's worth a try. Also I highly recommend using Reality Capture for photogrammetry. The pricing is super cheap and you pay per scan. reply foota 15 hours agoparentprevNeRFs are sort of last year's technology. The latest hype is about gaussian splats. My understanding is that essentially these technologies take some images as input, and then train a model, where the model is learning the best way to render the imagines into a model in some sense. I think for gaussian splats, it represents images as sort of \"blobs\" in space, and each image has the same set of blobs that have to be used from some perspective to render the image, hence by positioning the splats such that each image is rendered correctly, you can reproduce the scene. This training is currently very expensive and has to be done for each model, but produces an output that can be explored in real time. I think the photogrammetry approaches used by matterport et all are older and require much higher quality input data, whereas the newer approaches can work with much less and lower quality data. reply treme 9 hours agoparentprevhttps://www.reddit.com/r/sdforall/comments/13lenfm/free_seam... https://github.com/3DTopia/OpenLRM (They mention NeRF as inspiration but it seems original paper it was based on decided to use visual transformers. the opensource version seems to use meta's dino as one of key components) reply aaronblohowiak 18 hours agoparentprevLike shrink wrap in rhino? reply robertclaus 19 hours agoprevI was surprised by how poorly it reproduces the look from the perspective of specific images. For example, see the magic schoolbus further down. It feels like their algorithm could probably be tuned more in the direction of \"trust the images\". reply chefandy 17 hours agoparentA huge part of art is distinguishing between what \"feels\" right and what would be the case in reality. Even in the spaces I usually work in-- 3D animaton and film-- things in the background or maybe out-of-focus in the foreground or whatever are often distorted and weirdly juxtaposed to make something that looks right even if it wouldn't map to a real-world configuration that makes sense. 2D art is even less tied to real-world representations than that. What we can see in applications like this is how incredible our brains are at conceptually constructing ideas based on relatively abstract representations, and how incredible artists are at operating in the less-defined realms of that space. Maybe a scene seems to have a coherent perspective to the viewer, but the couch and end table in the BG were drawn as they would look shot with a 120mm lens while the foreground is deliberately claustrophobic and drawn like it was shot with a 30mm lens? It could look fine to us because we don't need to reason about the realistic 3D space those characters exist in-- we just need to understand that they're in a space like that because we know what it's like to be in spaces, and how people interact with them-- good art gives us just enough to communicate the core ideas making them the focus of the message, and lets our brains subconsciously make the connections and add all of the context to make a complete 'experience.' Everything is a potential layer of communication to achieve deliberate artistic effect-- the type of couch and end table, the often skewed or exaggerated scale and relationships between objects, etc.-- and it often just doesn't have a coherent real-world representation. Beyond that, in any given shot, things are certainly moved around to aid in composition, emphasize certain interactions, etc. etc. etc. If you notice it, then it's a continuity problem. If you don't notice it, then job well done. In the overwhelming majority of cases, nobody notices it, and we just happen to have a world where everything from every angle has really compelling composition. An algorithm that needs to look at the lines and try to figure out a real-world scenario that correlates to that representation might be trying to create something that could never exist in any coherent form. reply MarcScott 16 hours agoprevWhy would you have a site with a whole load of videos on it, with all of them set to autoplay and constantly loop? I was watching a video on my second screen, and it stutters each time I try to visit the site. reply wingmanjd 15 hours agoparentIs this a Chrome thing? My Firefox on Windows doesn't autoplay the videos for me. reply HelloMcFly 15 hours agorootparentNo autoplay in Edge for me, but I definitely have Media Autoplay set to \"Block\". reply nyanchovy 6 hours agoparentprevMaybe that’s why it locked up my iPhone (Firefox) on load. Only a power cycle fixed it haha. reply throw4847285 19 hours agoprevIf you showed the Spirited Away one to Miyazaki, he would probably call it an insult to life itself. reply helloplanets 18 hours agoparentFor those wondering, this is a reference to an older video: https://www.youtube.com/watch?v=ngZ0K3lWKRc So, not hyperbole. reply araes 15 hours agorootparentNot pointed at @helloplanets, just need to note that he responded that way because it was an abomination. And they're all stockholm syndrome about the situation, \"we can use AI to make grotesque monsters that feel no pain. All we want to do is make a machine that replaces human drawing.\" With this weird implied feeling he was supposed to congratulate them. Quoting Miyazaki, which was not especially harsh given they showed him a naked mutant zombie crawling across the ground using it's head and arm as legs while constantly trying to arch it's butt toward the camera. > Every morning, not recent days, but I see my friend who has a disability. > It's so hard for him just to do a high five (waves hand showing difficulty) > His arm with stiff muscle reaching out to my hand (demonstrates body stiffness) > Now thinking of him, I can't watch this stuff and find it interesting > Whoever creates this stuff has no idea what pain is, or whatsoever. I am utterly disgusted. > If you really want to make creepy stuff, you can go ahead and do it > I would never wish to incorporate this technology into my work at all > I strongly feel that this is an insult to life itself. (room sits in silence awkwardly) reply SebastianKra 14 hours agorootparentMany YouTube comments seem to have understood this clip as a dismissal of AI in general. And, regardless of whether thats accurate, I disagree with this standpoint. It's not easy to defend this particular example. But seeing how Rainworld uses synthetic animation to simulate an alien, yet somehow familiar ecosystem, makes me excited for whats next. From a Review by Matthewmatosis [1]: > Not long after setting out, I found myself staying in a quiet place, just moving Slugcat around various obstacles as smoothly as I could. [...] What was happening on screen looked like an animal testing its limits so as to build survival skills. It was then that I knew that this system was a resounding success. [1]: https://www.youtube.com/watch?v=x-Un2L5tF1w reply whamlastxmas 17 hours agorootparentprevMiyazaki famously not a very kind person, especially to his son reply mandmandam 11 hours agorootparentPerhaps there are different types of kindness, because his films are deeply, profoundly kind; and acutely aware of inner life. Someone with an extreme sensitivity for kindness can easily be seen as a curmudgeon by others, ie, after long years of disillusionment with the human race, or after a traumatic experience, or simply because of how they look. Some people might be good at being kind 'in the moment', while others need to reflect - and the second kind can be a 'bigger', more encompassing, more effective or beneficial kindness. And many (all?) of the people who give the most of themselves without hope for any reward genuinely care nothing for external validation or recognition - meaning we don't often hear about them or recognize them. One could garner a reputation as an absolute arse, while accomplishing fantastically beneficial changes in the world. And conversely, a man could get a reputation as a folksy down-to-earth guy who you'd love to have a beer with, even as he sets the planet on a course to perpetual war. Cough. reply iainmerrick 11 hours agoprevI don’t like to bring unrealistic expectations to this sort of thing, but even so, all the examples look pretty bad. Am I missing something? In addition to all the noise and haze -- so the intermediate frames wouldn’t be usable alongside the originals -- the start and end points of each element hardly ever connect up. Each wall, door, etc flies vaguely towards its destination, but fades out just as the “same” element fades in at its final position a few feet away. It’s a lovely idea, though, and it would be great to see an actually working version. reply porphyra 5 hours agoparentYes, it looks pretty bad imho. It seems that the researchers have learned about a handful of recent techniques, such as Gaussian Splatting, and decided to apply it to a novel domain (hand drawn images) without any deeper understanding. Gaussian Splatting is, in my opinion, simply the wrong tool for geometrically inconsistent images even if you manually annotate a bunch of keypoints. Another thing is that the spherical harmonics color representation makes it easy for the model to \"cheat\" when there are relatively few views, i.e. even when the Gaussian is completely geometrically wrong, it can still show the right color in the directions of the views. Perhaps they should have just disabled the spherical harmonics thing (i.e. making each Gaussian the same color regardless of which direction you're looking at it from), since most cartoons have flat-ish shading anyway. Furthermore, they didn't attempt any sort of photometric calibration or color estimation between the different views. For example the paintings each show the building in a very different lighting condition, and it seems they made no attempt to handle that at all, leading to a very ugly reconstruction. Finally, this method requires significant amounts of human work to do the manual annotation for a very subpar result, making us wonder what the whole point of it is. It would seem to me that diffusion models like Sora or Veo could do a much better job if you just want to interpolate between different views. It isn't much different from image inpainting, which diffusion models excel at. reply nicklecompte 17 hours agoprevI am amazed they didn't seem to talk to any 3D animators before writing this. Because this is just plain wrong: > The hand-drawn images are usually faithful representations of the world, but only in a qualitative sense, since it is difficult for humans to draw multiple perspectives of an object or scene 3D consistently. Nevertheless, people can easily perceive 3D scenes from inconsistent inputs! It is difficult for human artists to maintain perfect geometrical consistency. But that is NOT why 2D animation of 3D scenes is geometrically inconsistent! The reason is that artists stylize 3D scenes to emphasize things for specific artistic reasons. This is especially true for something surreal like SpongeBob. But even King of the Hill has stylized \"living room perspectives,\" \"kitchen perspectives,\" etc. The artists are trying to make things look good, not realistic. And they aren't trying to make humans reconstruct a perfect 3D image - they are trying to evoke our 3D imaginations. It's a very different thing. Pixar and other high-quality 3D animation studios intentionally distort the real geometry of their scenes for cinematic effect: a small child viewed from an adult's perspective might be rendered with a freakishly long neck and stubby little torso, because the animators are intentionally exaggerating visual foreshortening to emphasize the emotional effect of a wee little child. A realistic perspective would be simply boring. These techniques are all over the place in Pixar movies - it's why their films look so good compared to cheaper studios, who really are just moving a virtual camera around a Euclidean 3D space. I don't want to comment on the technical details. But it really seems like the authors missed the artistic mark. reply chefandy 4 hours agoparentAs someone who works in this space professionally, my face and my palm have never been closer. I have no problem with the project-- research is research and it's not like they're trying to pass this off as a 'solved problem'-- but among a specific subset of tech folks, AI image tools arouse this completely unwarranted \"we've solved art\" bravado. It inspires them to arrogantly-- sometimes even imperiously-- throw around these baseless assumptions about basic art principles. I worked in software for a long time and I know hubris in software development is nothing new, and can even sometimes be beneficial, but I'm not sure I've ever seen such an intense collective overconfidence in a single subject within the software world. reply numpad0 5 hours agoparentprevIt's especially funny considering the same is done with real TV cameras. For an easy example, a lot of supposedly square rooms used in sitcoms are trapezoidal shaped; the walls meet at obtuse angles. Very few people notice that. reply crooked-v 7 hours agoparentprevAlso, even putting stylization for specific artistic reasons aside, work in this context is always going to get warped for the simple needs of the camera (or \"camera\"). This goes double for anything pre-HD, where people or characters had to fit pretty tight into the shot to have the perspective close enough for facial expressions and body language. Dig into even the most \"realistic\" and staid shows of the era and you'll eventually find moments where they had to discreetly move furniture or even walls to make particular shots work. reply solardev 20 hours agoprevIt kinda looks like a cartoon version of Microsoft Photosynth? https://en.wikipedia.org/wiki/Photosynth reply chungus 19 hours agoprevI imagine Spongebob episodes converted to this 3D format, and watching them with VR goggles, like you're there. reply dvngnt_ 16 hours agoparentyou mean like this https://www.youtube.com/watch?v=msI5VFPMmSE reply owenpalmer 17 hours agoparentprevI love this reply James_K 19 hours agoprevThis web page uses over 1.6 gigabytes of RAM. reply frizzlebox 18 hours agoparentThat might explain why it consistently kills Firefox Focus on my phone. reply bhouston 16 hours agoprevIt is a good idea, but the results are quite bad. It barely works in their demos, tons of artifacts everywhere. reply ambyra 19 hours agoprevI can't think of a great application either. Maybe if you want to map camera movements when converting an animated scene from 2d to 3d. It'd probably be easier just to start from scratch though. Simple polygons with a toon shader would work for simpsons and family guy im sure. reply toddmorey 19 hours agoparentI don't think it will ever catch fire in animation studio workflows. I can't see it beating the current process of applying toon rendering to 3D geometry. Though it may help renderers add variation to the output in a way that's more authentic and less random. I'm wondering if it's at all useful in understanding / improving AI's ability to infer semantic meaning from even real images in a variety of scenarios? Like the ability to re-interpret an interpreted construction (drawing) of a scene. One area of application may be helping machines better understand hand drawn human input? reply mikepurvis 18 hours agorootparent\"the current process of applying toon rendering to 3D geometry\" Is this widespread? My sense is that most mainstream TV animation that isn't obviously CGI is still drawn in 2D, with 3D work if used at all being relegated to backgrounds and the like. reply chefandy 18 hours agoparentprevI'm sure some marketer has an email chain open with a developer asking if they can use it to help advertise bigger houses to TikTok users who film at home, or something like that. Or maybe advertise luxury products to people who are in large homes. reply westedcrean 19 hours agoprevI'm not a historian, but I remember a tour guide in Forum Romanum mentioned that current state of knowledge about how buildings and parts of cities looked like stems from their depictions on coins that period. Perhaps it could be used for that? reply mikepurvis 18 hours agoparentThat'd be a small enough sample size that it would make sense to just have a human agonize over it. I feel like this type of thing best applies in the kind of domain they're already in— TV shows with hundreds of hours of content that a machine can comb through looking for reference images to synthesize into these models. reply SiempreViernes 20 hours agoprevThe ability to reconstruct a coherent 3d view from a sparse set of photos seems much more useful than for a set of 2d drawings of an entirely imagined space, I don't think 2d artists are cheaper than the 3d artists. reply benrutter 20 hours agoparentSurely they're 2/3 the price right? I'm basing this on the fact that I'd happily draw 1 dimensional pictures for 1/2 the price of a 2d artist. reply djl0 19 hours agoprevA little bit off topic, but related: are there any tools to which you can feed a few photos of a room from various angles and it will generate a floorplan or 3d model like this? reply troymc 19 hours agoparentYes, in fact at least one of them got funding from YC: Matterport. There are many others: Kuula, Cupix, iStaging, EyeSpy360... Real estate companies use them a lot, e.g. to create a virtual tour for prospective buyers. reply esolyt 4 hours agorootparentYes but they don't just use a random set of photos. They take multiple 360 photos for the specific purpose of feeding them into their virtual tour app. That's why you can pan around. reply djl0 19 hours agorootparentprevthank you! very interesting, i'll check those out. do you know of any open source projects? reply me_online 19 hours agoparentprevlumalabs dot ai is pretty neat. Takes videos as input but works very well. reply nemomarx 20 hours agoprevThis is very interesting but I feel like the name suggests it's an animation or graphics program more directly? That might be a branding loss reply nico 20 hours agoprevIt’s fascinating that the generated Gaussian splats look kind of like a dream. Almost like that was the way we generate 3d scenes in our minds reply surfingdino 14 hours agoprevIt's cool. It might be useful as a 3d camera movement visualisation tool in pre-production. As a tool for recreating old cartoons in 3D it'll produce results as desirable as those ghastly coloured versions of old bw movies. reply orthoxerox 18 hours agoprevI see they didn't even try Peppa Pig. reply 1-6 18 hours agoprevIt's hallucinating a bit. There are new things put in that weren't there in the previuos frame. reply eMerzh 19 hours agoprevNot sure how related there are, but it looks like it could be used to do https://www.wakatoon.com reply thebeardisred 18 hours agoprevThank you HN for showing me enough papers on \"Gaussian Splating\" that I was about to pick it out as the method visually from the examples. reply selimnairb 18 hours agoprevCool, but why? Structure from motion has applications in the real world, but this use case doesn't seem to be that compelling to me. reply JL-Akrasia 19 hours agoprevThis is so cool! reply binary132 19 hours agoprevAmazingly weird reply localfirst 14 hours agoprevTrying to use this but stuck after exporting from the labeler (guessing that is close source), lots of questions: What do I do with this data exactly? Not really following the instructions from README Do I need a hefty GPU to run this? Doesn't say anything about hardware. What am I going to get as a result? Will it generate a 3d model or \"point clouds\" ? Do I need multiple inputs (from different angles) through the labeler? What is the depth estimator being used here (this im most interested in especially its able to detect ground from multiple angles) ? Guess I'm just really lost here but super eager to use this. We do have a real world application to use this. reply deadbabe 18 hours agoprevWill be awesome when we can watch old cartoon shows in VR and look all around the world. reply JL-Akrasia 19 hours agoprevHoly crap, can you imagine rewatching your favorite shows from different perspectives? reply bogwog 19 hours agoparentA VR/AR reproduction of old cartoons where you can explore a coherent 3D space would be cool. It doesn't seem like the OP comes even close to this though. reply autoexec 17 hours agoparentprevNot if it looks anything like this... Honestly I'd be surprised if AI could do it justice. In a shot showing one character talking, panning around to see the other characters that AI pasted into the scene wouldn't be enough. Those characters would also have to be animated and show appropriate attention/reactions to what was being said/going on. reply jareklupinski 19 hours agoparentprevi just want to see Steamed Hams from the perspective of the oven reply henriquecm8 19 hours agorootparenthttps://www.youtube.com/watch?v=yvmgdJQi5cA reply seattle_spring 18 hours agoprev [–] Kiiiiind of disappointed to not see the alley from King of the Hill, I tell you h'what. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Toon3D is a novel technique for recovering the 3D structure of hand-drawn cartoon scenes through piecewise-rigid deformation optimization.",
      "It reconstructs camera poses and dense geometry from non-geometrically consistent images, allowing the generation of new viewpoints of cartoon scenes.",
      "The method involves depth prediction, image labeling, alignment, a user-friendly annotation tool, camera pose estimation, image deformation, and Gaussian refinement to create a coherent 3D structure for visualizing cartoons from varied angles."
    ],
    "commentSummary": [
      "The discussion explores the application of 3D animation in cartoons, citing examples from popular shows like Futurama and Disney's Oliver & Company.",
      "It addresses the challenges encountered by animators when developing 3D spaces and the integration of AI and machine learning to transform 2D artwork into 3D models.",
      "The potential influence of AI on 3D modeling, the artistic decisions involved in crafting video scenes, and the utilization of new technologies for image rendering are all highlighted, along with the ongoing debate surrounding the use of AI in animation."
    ],
    "points": 368,
    "commentCount": 101,
    "retryCount": 0,
    "time": 1715951046
  },
  {
    "id": 40390820,
    "title": "A Promising Breakthrough: HIV Vaccine Generates Powerful Antibodies",
    "originLink": "https://corporate.dukehealth.org/news/trial-hiv-vaccine-triggered-elusive-and-essential-antibodies-humans",
    "originBody": "Site Search form Search× News & Media Front Page News Releases In The News Organization News Features Social Media Duke Health Blog News & Media Front Page A Trial HIV Vaccine Triggered Elusive and Essential Antibodies in Humans Published May 17, 2024Updated May 17, 2024 Share Tweet Contact Sarah Avery Director 919-724-5343 Email DURHAM, N.C. – An HIV vaccine candidate developed at the Duke Human Vaccine Institute triggered low levels of an elusive type of broadly neutralizing HIV antibodies among a small group of people enrolled in a 2019 clinical trial. The finding, reported May 17 in the journal Cell, not only provides proof that a vaccine can elicit these antibodies to fight diverse strains of HIV, but that it can also initiate the process within weeks, setting in motion an essential immune response. The vaccine candidate targets an area on the HIV-1 outer envelope called the membrane proximal external region (MPER), which remains stable even as the virus mutates. Antibodies against this stable region in the HIV outer coat can block infection by many different circulating strains of HIV. “This work is a major step forward as it shows the feasibility of inducing antibodies with immunizations that neutralize the most difficult strains of HIV,” said senior author Barton F. Haynes, M.D., director of the Duke Human Vaccine Institute (DHVI). “Our next steps are to induce more potent neutralizing antibodies against other sites on HIV to prevent virus escape. We are not there yet, but the way forward is now much clearer.” The research team analyzed data from a phase 1 clinical trial of a vaccine candidate developed by Haynes and S. Munir Alam, Ph.D., at DHVI. Twenty healthy, HIV-negative people enrolled in the trial. Fifteen participants received two of four planned doses of the investigational vaccine, and five received three doses. After just two immunizations, the vaccine had a 95% serum response rate and a 100% blood CD4+ T-cell response rate -- two key measurements that demonstrated strong immune activation. Most of the serum responses mapped to the portion of the virus targeted by the vaccine. Importantly, broadly neutralizing antibodies were induced after just two doses. The trial was halted when one participant experienced a non-life-threatening allergic reaction, similar to rare incidences reported with COVID-19 vaccinations. The team investigated the cause of the event, which was likely from an additive. “To get a broadly neutralizing antibody, a series of events needs to happen, and it typically takes several years post-infection,” said lead author Wilton Williams, Ph.D., associate professor in Duke’s Department of Surgery and member of DHVI. “The challenge has always been to recreate the necessary events in a shorter space of time using a vaccine. It was very exciting to see that, with this vaccine molecule, we could actually get neutralizing antibodies to emerge within weeks.” Other features of the vaccine were also promising, most notably how the crucial immune cells remained in a state of development that allowed them to continue acquiring mutations, so they could evolve along with the ever-changing virus. The researchers said there is more work to be done to create a more robust response, and to target more regions of the virus envelope. A successful HIV vaccine will likely have at least three components, all aimed at distinct regions of the virus. “Ultimately, we will need to hit all the sites on the envelope that are vulnerable so that the virus cannot escape,” Haynes said. ”But this study demonstrates that broadly neutralizing antibodies can indeed be induced in humans by vaccination. Now that we know that induction is possible, we can replicate what we have done here with immunogens that target the other vulnerable sites on the virus envelope.” In addition to Haynes and Williams, study authors include S. Munir Alam, Gilad Ofek, Nathaniel Erdmann, David Montefiori, Michael S. Seaman, Kshitij Wagh, Bette Korber, Robert J. Edwards, Katayoun Mansouri, Amanda Eaton, Derek W. Cain, Mitchell Martin, Robert Parks, Maggie Barr, Andrew Foulger, Kara Anasti, Parth Patel, Salam Sammour, Ruth J. Parsons, Xiao Huang, Jared Lindenberger, Susan Fetics, Katarzyna Janowska, Aurelie Niyongabo, Benjamin M. Janus, Anagh Astavans, Christopher B. Fox, Ipsita Mohanty, Tyler Evangelous, Yue Chen, Madison Berry, Helene Kirshner, Elizabeth Van Itallie, Kevin Saunders, Kevin Wiehe, Kristen W. Cohen, M. Juliana McElrath, Lawrence Corey, Priyamvada Acharya, Stephen R. Walsh, and Lindsey R. Baden. The study received funding support from the National Institute of Allergy and Infectious Diseases, part of the National Institutes of Health (AI100645, AI144371, AI170752), and from the Bill & Melinda Gates Foundation (OPP1094352/INV-007688). The content of this press release is solely the responsibility of DHVI and does not necessarily represent the official views of the National Institutes of Health. Research HIV Previous New Molecule Mimics the Anti-Clotting Action of Blood-Sucking Organisms News & Media Front Page",
    "commentLink": "https://news.ycombinator.com/item?id=40390820",
    "commentBody": "A Trial HIV Vaccine Triggered Elusive and Essential Antibodies in Humans (dukehealth.org)225 points by geox 18 hours agohidepastfavorite55 comments jcims 17 hours agoAnimation of how HIV infects a single T-cell https://vimeo.com/260291607 reply gen220 15 hours agoparentCan you post this as a new submission? I want to read knowledgeable peoples' responses to it! :) Viruses are incredible. This video does a great job of illustrating how HIV in particular seems to hijack so many essential systems. I now feel like I have a deeper appreciation for why \"cures\" for viruses are like a holy grail technology – how could you even prevent something like this without collateral damage to some perfectly healthy + necessary process? They're so tangential to how our cells need to work that they're almost parallel. reply jb1991 15 hours agorootparentHere you go: https://news.ycombinator.com/item?id=40393107 reply tejohnso 13 hours agoparentprevThe level of detail in the knowledge of the process is astounding. Having never studied anything like this, at every stage I kept thinking: how do we know all of this? reply Angostura 2 hours agorootparentIf you liked that - this one on the cell’s energy systems blew me away when I first saw it https://youtu.be/LQmTKxI4Wn4?si=7KEKwFjfLrwyCLvW reply andylynch 12 hours agorootparentprevEasy, thousands of smart, motivated people, billions of dollars invested and decades of work! reply hansoolo 11 hours agorootparentprevWatching the video I did indeed feel like \"this is insane!\" all the way through... reply liendolucas 15 hours agoparentprevFor me the most incredible part of the video is the transcription process. Looks like the head of a Turing machine going through the \"tape\". Really amazing that something like this occurs in the body at a nanometric scale. reply op00to 15 hours agoparentprevThis video invokes fear in me. Like, those alien machines (viruses) are doing their weirdo stuff countless times a second in my body. Horrifying. reply Terr_ 15 hours agorootparentIf it helps, consider that \"your body\" is the-same-or-more dangerously impressive, with layers of hideously effective defenses to displace or starve or murder anything that gets close, a swarming hive of unfathomable nanotechnology winnowed over millions of years of adversity between the many inheritors of an ancient grey-goo apocalypse. Just from one eldritch hive-mind to another. reply op00to 14 hours agorootparentI'm not afraid of the viruses per se, I trust in my immune system. It's more the extreme intricacy of the whole damn meatbag. Kinda like looking up at the stars in an ultra-dark environment and seeing more stars than you've ever seen before. I get a little dizzy. Don't get me started on math. reply _Microft 13 hours agorootparentMaybe you are talking about \"awe\"? https://en.wikipedia.org/wiki/Awe reply op00to 12 hours agorootparentYup! reply postalrat 12 hours agorootparentprevThat's why I consider biology a type of alien technology that we've been trying to reverse engineer but are still a ways away. reply jiggawatts 5 hours agorootparentprevIf math can make you feel awe, you've got to watch the Numberphile series on very big numbers. They're constants used in proofs that are specific, well-defined integers known to be finite, but so huge that the physical universe does not have enough particles (or even Plank-scale microstates) in it to represent the number of digits these numbers have! Absolutely mind-bending stuff. Listed in increasing order: \"Graham's Number\" https://www.youtube.com/watch?v=XTeJ64KD5cg \"How Big is Graham's Number? (feat Ron Graham)\" https://www.youtube.com/watch?v=GuigptwlVHo \"The Enormous TREE(3)\" https://www.youtube.com/watch?v=3P6DWAwwViU \"TREE(3) (extra footage)\" https://www.youtube.com/watch?v=IihcNa9YAPk \"The Daddy of Big Numbers (Rayo's Number)\" https://www.youtube.com/watch?v=X3l0fPHZja8 reply tstrimple 7 hours agorootparentprevThere's even some great Kurzgesagt videos on it. https://www.youtube.com/watch?v=lXfEK8G8CUI reply squigz 3 hours agorootparentprevIt freaks me out too. At the same time, the fact that we know so much about biology comforts me - we can build our own little machines :) reply deepfriedchokes 12 hours agorootparentprevThe music sure doesn’t help! reply yazzku 13 hours agorootparentprevDamn... And proteins are not living organisms, but the video makes them look like autonomous agents and even states thing like \"the virus recruits new proteins\". Is this mostly an anthropomorphization of the events, or did I miss the relevant episode of biology? reply nwiswell 13 hours agorootparent> Is this mostly an anthropomorphization of the events Yes. Basically everything is bumping around until the desired reaction or configuration is obtained. The irrelevant proteins are generally not shown. The length scales involved are extremely short so the chaotic soup works itself into configuration shockingly quickly. There are also membranes, vesicles, and organelles (e.g. Golgi) that partition, package, and redistribute proteins so that they tend to be more concentrated where required. reply NoMoreNicksLeft 12 hours agorootparent> Basically everything is bumping around until the desired reaction or configuration is obtained. Dare I say it? That sounds alot like what we do in the office most of the time. reply gravescale 56 minutes agorootparent\"Employing an bio-mimic evolutionary compilation algorithm\" does sound better than \"changing things semi-randomly until it compiles and passes the tests\". reply op00to 12 hours agorootparentprevProtein folding freaks me out too. reply qrian 2 hours agoparentprevI've heard about membrane protein enables interaction with outside molecules that are random walking near the cell membrane, but seeing it as an animation really hit me that that's how things work. reply ugh123 15 hours agoparentprevThere should be yearly awards for good science animations and learning tools like this reply surfingdino 14 hours agorootparentThere is https://www.nikonsmallworld.com/galleries/small-world-in-mot... reply taf2 16 hours agoparentprevThat is really impressive animation, now I'd love to see this animation updated to include how the Vaccine works reply Angostura 2 hours agoparentprevVery good, but I could do without the ominous music reply jimbokun 13 hours agoparentprevFeels like a heist movie. Breaking into the cell and hijacking it's machinery to make more of itself. reply noman-land 7 hours agoparentprevReally incredible animation. reply obloid 16 hours agoparentprevVery interesting, thanks for posting. reply knodi 16 hours agoparentprevWow! reply jcims 16 hours agorootparentThe music is amazing. reply chasil 17 hours agoprev> Other features of the vaccine were also promising, most notably how the crucial immune cells remained in a state of development that allowed them to continue acquiring mutations, so they could evolve along with the ever-changing virus. As I understand it, somatic hypermutation is a process that only occurs within germinal centers. Is that what is happening here? reply ejstronge 13 hours agoprevHere is the Cell article: https://www.cell.com/cell/fulltext/S0092-8674(24)00459-8 reply hi-v-rocknroll 14 hours agoprevPerhaps this could be a beneficial prophylaxis. And having another treatment that uses CRISPR to remove the provirus is also an essential to have a durable cure for patients already infected. https://www.bbc.com/news/health-68609297 reply dyauspitr 7 hours agoparentLook up EBT 101. Human trials started last year for a CRISPR based cure for HIV. This is from the same team that was able to cure SIV in monkeys using the same technique. reply ezekiel68 16 hours agoprevVery promising outcome. But I wonder they/why we are just learning about this now when it seems that the inoculations occurred in 2017? reply giantg2 15 hours agoparentIt's not really valuable if the immunity isn't very durable. There are already short duration things like PREP. If it's been 5 years (2019), that's a big deal. reply Traubenfuchs 14 hours agorootparentThere is a injectable every 2 months solution now. https://www.fda.gov/news-events/press-announcements/fda-appr... reply citruscomputing 4 hours agorootparentI have a friend who takes this; it's very expensive and insurance doesn't want to pay for it, but if you convince them that you're high enough risk (\"oh, I just keep finding myself in strangers' beds, I love getting people's blood on me, and I'm just too dumb to remember to take a pill every day\"), you can get it. Normal PrEP actually puts you at greater risk if you forget to take it, so I'm really glad that the injectable one is an option. It's much more effective, too. I should see about trying to get on it soon... reply Traubenfuchs 16 minutes agorootparent> oh, I just keep finding myself in strangers' beds Honestly, that‘s why I am taking daily prep. Can‘t trust my urges and I am tired of telling siri to remind me of a HIV test in 4 weeks… reply giantg2 11 hours agorootparentprevYeah, that's why I'm saying years long protection would be a huge shift from the current short term stuff. reply hgomersall 3 hours agoparentprevThe paper was published on Friday. reply PakG1 14 hours agoprevI'm not an expert on this stuff at all, so assume I'm stupid and ignorant when I write the following. As I understand it, HIV has actually been useful to develop a delivery mechanism for some therapies that have excellent potential. Would this kind of vaccine cause such therapies to become ineffective? reply XorNot 7 hours agoparentNo: because the target of vaccines is viral protein coats to prompt antibody binding. The usefulness of HIV for other applications is that some of it's proteins - i.e. the reverse transcriptase - are extremely useful molecular engineering tools, but they're used as individual components. One of the interesting failed COVID vaccine efforts was by the University Of Queensland in Australia which was working on a novel protein based vaccine where the idea was a conformationally locked COVID spike protein was injected[1] - basically it presents the protein as it's found on the surface of the virus, which in turn promotes an antibody response which is \"accurate\" - whereas free-floating proteins, i.e. if you just shredded up the virus - don't look the same. The problem? The technology was based on a protein sequence called gp41 - which is a subunit of the HIV spike protein. It's not HIV, it's not derived from actual HIV virus - it's made in labs from separately cloned sequences...but unfortunately, part of the immune response to the vaccine generated HIV binding antibodies, similar enough to \"real\" HIV binding antibodies that they would trip false-positives in HIV tests - i.e. you would test positive to HIV for months, but you didn't actually have HIV - you had antibodies which had enough activity to the common HIV test assay that it looked like you did (e.g. a PCR test for HIV would show you don't have it. But it's impractical to have a whole lot of people who look indistinguishable to the HIV positive population when we had other vaccine options). [1] https://www.nature.com/articles/d42473-020-00504-2 reply xutopia 16 hours agoprevI am not an immunologist... I don't understand biology very well. How significant is this? Is it even trustworthy? reply BikiniPrince 15 hours agoparentThe fact they can trigger antibodies on a stable portion of the virus is impressive. Near the end, it sounds like a multi pronged approach is needed to deal with variations. I’m not an immunologist, but it was pretty light. If they are in trials does that indicate they have a white paper? reply heavyset_go 9 hours agorootparentClinical trial data gets published online, might be able to find what you're looking for. reply giantg2 15 hours agorootparentprev\"If they are in trials does that indicate they have a white paper?\" I would think they'd have to in order to have the trial. It probably is not for public distribution though. reply rsingla 14 hours agoprevI wonder about the potential for varied immune responses across different populations. reply carbocation 15 hours agoprevDoes this university press release name-check Cell but not link to the article? A bit frustrating. reply safeharbourio 14 hours agoparenthttps://doi.org/10.1016/j.cell.2024.04.033 reply carbocation 5 hours agorootparentThank you. reply nektro 8 hours agoprev [–] woah, how exciting! reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A study at Duke Human Vaccine Institute discovered that an HIV vaccine candidate elicited antibodies capable of combating various virus strains in humans.",
      "The vaccine focuses on a steady area on the HIV envelope and effectively generated broadly neutralizing antibodies with only two doses in a limited clinical trial.",
      "Additional research is necessary to enhance the immune response, but these findings hold potential for the advancement of a successful HIV vaccine, supported by funding from the National Institutes of Health and the Bill & Melinda Gates Foundation."
    ],
    "commentSummary": [
      "The discussion delves into the intricate nature of biological processes and mathematical principles, drawing parallels between biology and alien technology.",
      "Topics include the role of animations in comprehending membrane proteins, potential HIV treatments through CRISPR technology, and debates on various HIV prevention methods and vaccine development.",
      "Concerns are raised about false positives in HIV tests, the activation of antibodies against the virus, the necessity for a comprehensive strategy to address mutations, and challenges related to accessing clinical trial information."
    ],
    "points": 225,
    "commentCount": 55,
    "retryCount": 0,
    "time": 1715958911
  },
  {
    "id": 40393107,
    "title": "Decoding the HIV Life Cycle: An Animated Journey",
    "originLink": "https://vimeo.com/260291607",
    "originBody": "HIV Life Cycle - narrated 6 years agoMore Janet Iwasa Follow Share How does HIV infection occur? This molecular animation depicts the process of how HIV infects a T cell and transforms the cell into a viral factory. Completed in collaboration with dozens of HIV researchers across the United States, this film is part of the Science of HIV project (scienceofHIV.org), with support from the CHEETAH Center at the University of Utah (cheetah.biochem.utah.edu/) and the NIGMS. Please feel free to download and share this animation, and visit the Science of HIV website (scienceofHIV.org) for more information. To view a version of this animation without narration, see: vimeo.com/260291601/505c3bfec8 Credits: Animated by Janet Iwasa and Grace Hsu (Department of Biochemistry, University of Utah) Music written and performed by Joshua Roman Music recorded by Jesse Lewis (Immersive Music Project) Read more… Upload, livestream, and create your own videos, all in HD. Join Vimeo Log in",
    "commentLink": "https://news.ycombinator.com/item?id=40393107",
    "commentBody": "HIV Life Cycle – animated and narrated [video] (vimeo.com)214 points by jb1991 15 hours agohidepastfavorite11 comments qrian 1 hour agoI found a playlist of how to make these kind of animation, taught by the author. https://www.youtube.com/watch?v=et-3Ho9RTR8&list=PLQFc-Dxlf4... reply intsunny 1 hour agoprevI completely believe in evolution ........ but sometimes I find myself wondering how did evolution allow for something so intentionally diabolical to come around at the MOLECULAR level. reply BitwiseFool 14 hours agoprevIs there a word for feeling fascination and discomfort at the same time? These little molecular machines are so sinister. reply redblacktree 14 hours agoparentI mean, the tense and sinister-sounding violin music helps with that feeling as well. reply BitwiseFool 12 hours agorootparentI was so engrossed in the animation that I didn't notice the music. reply lupyro 12 hours agoprevIs there a collection of videos like this anywhere online? Or what would be a good search term? I feel like I see a video like this once a year. There's got to be hundreds of them showing different molecular or biological interactions reply ooboe 7 hours agoparentSeveral universities and organizations have labs dedicated to producing these kind of videos, but 12 years ago the BBC made a good documentary aimed at a general audience on how adenoviruses attack a human and how the body defends against it. https://www.bbc.co.uk/programmes/b01nln7d https://www.dailymotion.com/video/x8kj9c6 reply lisper 10 hours agoparentprevWell, for starters this author of this video has a channel: https://vimeo.com/jiwasa reply rysertio 12 hours agoprevDid I miss something or this infographic missed on how the viral receptors are placed on the envelope. reply squigz 3 hours agoparentI was wondering this too reply marcod 13 hours agoprev [–] ... that music though ... reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The molecular animation illustrates how HIV infects a T cell, turning it into a viral factory, in collaboration with HIV researchers for the Science of HIV project.",
      "Created by Janet Iwasa and Grace Hsu with music by Joshua Roman, the animation can be downloaded and shared on the Science of HIV website."
    ],
    "commentSummary": [
      "The post reviews an animated video illustrating the HIV life cycle, prompting mixed reactions of intrigue and unease regarding the intricate details of molecular biology.",
      "Users exchange recommendations for comparable videos and documentaries focusing on molecular interactions, enriching the discussion with additional resources."
    ],
    "points": 214,
    "commentCount": 11,
    "retryCount": 0,
    "time": 1715972036
  },
  {
    "id": 40392548,
    "title": "EquityVal Pro: Create Custom Financial Models for Any Stock",
    "originLink": "https://www.useequityval.com/",
    "originBody": "Stock valuation for the everyday investor Create, save, and share valuation models for any public company to inform your next investment decision Get Started For FreeTry The Model The one stop shop researching your next great investment Fully Customizable Models Edit every input for a DCF model to fine tune your model to your exact assumptions. Accurate Data Get the most up to date and accurate data for any public company to enhance your research. Model Dashboard Save your models to view and tweak your models at any time. Do More With EquityVal Pro View Pro Features Create a model with the most popular stocks AAPL GOOGL TSLA NVDA Privacy Support",
    "commentLink": "https://news.ycombinator.com/item?id=40392548",
    "commentBody": "I built a website to create financial models for any stock online (useequityval.com)208 points by trevzercap 16 hours agohidepastfavorite114 comments plaidfuji 9 hours agoI’m consistently surprised at the lack of basic financial literacy in the HN crowd. The title says this is a tool to create financial models, not that it is a well-tuned financial model. Yeah, you have to make better assumptions than straight-line extrapolation from last year’s trend to arrive at reasonable valuations. The point is that this shows you what assumptions you have to make to arrive at a rationally-calculated stock value, and pre-populates all of the other necessary data and formulas in a slick UI, which is pretty cool. The models that make the big bucks are the ones that ingest a ton of other external data to predict the numbers that go in the data entry cells here. And yeah, those don’t get posted online for free. reply DeathArrow 50 minutes agoparent>The models that make the big bucks are the ones that ingest a ton of other external data to predict the numbers that go in the data entry cells here. And yeah, those don’t get posted online for free. Do such models even exist? As far as I know NN are only good at function approximation. Why do we think that the market evolves according to a mathematical function? To me, financial markets seem chaotic in nature. reply asimpletune 18 minutes agorootparentIt’s like asking why are gym memberships and diet advice more marketed than eating less and free body weight exercises you can do anywhere. There is a market for solutions and good news, whereas there isn’t one for bad news, even if it’s free. reply trevzercap 8 hours agoparentprevThank you! You captured it perfectly. Shoot me and email at support@useequityval.com and I will set you up with a pro for free! reply laborcontract 4 hours agorootparentAny way do regional and or segment breakouts? The way I see your tool, it's a great tool for the back of the napkin-ers but as it is right now, it doesn't obviate modeling because you're still going to have to do the breakouts in excel. Also, I think it'd be great to set your defaults assumptions for a stock to breakeven pricing, and allow users to adjust from there. I see a tool like this being useful, but I think positioning it as a deep valuation tool is much less useful in the mindsphere of investors as an elite pen and napkin, which I think people would use. reply fakedang 33 minutes agorootparentYou'd be surprised to learn then that most PE deals run on the back of literal pen and napkin models. In our process at my former firm, one of the largest megafunds out there, we would scout and model new opportunities using elaborate models, report them to the MDs who would then literally whip out a notepad or a napkin mid-presentation to decide whether the investment had potential. If it was in the grey zone, it was on us to demonstrate that it had merit, using more complicated modelling and analysis. reply tippytippytango 7 hours agoparentprevIt highlights an education opportunity for OP. Some people think this is a proprietary financial modeling system because they don’t know what a DCF is. reply yen223 8 hours agoparentprevI feel like OP would have been better off not pre-populating the models, just to make the point of the tool clearer. A lot of folks here seemed to have missed the point of the tool. reply uh2010 11 hours agoprevhttps://www.useequityval.com/model?ticker=CRSP Current Price: $56.22 Projected Price: $20,806,772,549,824,028.00 Difference: 37,009,556,296,378,460% Glad I'm long. reply airstrike 11 hours agoparentThe hard thing about modeling is not the math to get to present value of the stock. It's figuring out which assumptions make sense. Assuming that a revenue growth rate of 84,762.39% is (a) a valid number and (b) expected to remain the same over the next X years does not quote-unquote \"make sense\" reply Beijinger 11 hours agoparentprev37,009,556,296,378,460% That is a decent return. I bought a call option for RILY. Went to zero. Well... reply sitzkrieg 8 hours agorootparentalways do credit option positions :-) reply trevzercap 11 hours agoparentprevHaha the initial model is not a good representation of value as it projects the lasts years metrics out 5 years. 80K% growth for 5 years would do that. Thanks for pointing it out. I need to incorporate some boundaries for the initial values lol. reply nipponese 6 hours agoparentprevIt's a tool to make your own models, not have the models made for you. reply dullcrisp 10 hours agoparentprevhttps://xkcd.com/605/ reply icedchai 11 hours agoparentprevI put in quite a few stocks and the results were often strange. Negative values, under a dollar, etc. These were all stable companies, not penny stocks. reply fakedang 30 minutes agoparentprevTo be fair to the creator, he lets you put in your own assumptions via the revenue growth fields (which is what's skewing your projections). That's frankly better UX than one of its competitors, which does not let you do that. reply serial_dev 9 hours agoparentprevIt's about as reliable as I thought. If it was even remotely reliable, this would be a billion dollar idea (at least) treated as a secret sauce in an investment company. Instead, it takes some input, throws some garbage output, but as it's not blatantly just random numbers, people think it's helpful for investing. reply giantg2 11 hours agoparentprevYeah, there should be multiple massive disclaimers on this site. I'd be worried about regulatory issues as well. Edit: why disagree? reply ghiculescu 11 hours agorootparentWhy? Anyone who invests based on such obviously wrong numbers shouldn’t be protected from themselves. reply giantg2 10 hours agorootparentThe concern isn't that they would invest bed on obviously wrong numbers. The concern is that someone invests based on believable numbers that are incorrect. There's no information on accuracy measures or verification. Offering this model to others could be an SEC/FINRA violation. reply jstanley 13 hours agoprevVery nice, coincidentally I have been thinking about making a similar tool lately, but I'd make it quite a bit more conservative. I'd want to be able to define a model like \"I think the fair value of a company is its net current assets plus its last 5 years of earnings\", and have the tool email me whenever I can buy shares in any company substantially below that price, or sell them substantially above. It wouldn't be very hard to do, it just needs the data. Where are you getting your data from? reply trevzercap 13 hours agoparentHi the data is from https://site.financialmodelingprep.com/developer/docs reply mkl 4 hours agorootparent> Attribution is required for all users. It is as simple as putting “Data provided by Financial Modeling Prep” somewhere on your site or app and linking that text to https://financialmodelingprep.com/developer/docs/. I don't see attribution on useequityval.com? reply jstanley 13 hours agorootparentprevThanks reply repeekad 12 hours agoparentprevYou should checkout fintool.com, you can ask in natural language for this kind of data and soon set up alerts on it reply czbond 12 hours agorootparentThanks for pointing that out - fintool seems really impressive as well reply vg_head 12 hours agoparentprevThis is exactly the kind of tool I would want as well. I was surprised nothing like this exists already. reply trevzercap 12 hours agorootparentSounds like maybe i should build a notification system so if a stock drops a certain percentage below your models estimated value you get alerted? reply vg_head 12 hours agorootparentYes, at least that would be a great start for me. reply nonameiguess 12 hours agorootparentprevI don't know if this is the reason but it is somewhat trivial to roll your own. This is actually close to the story of how I became a programmer in the first place. 17 years ago or so, I made something like this in Excel and figured out how to populate the data from the Yahoo! Finance API, then learned about FRED, BLS, other sources of possibly relevant economic data, but still doing everything in Excel, eventually deciding to learn C++ since I'd heard it was the industry standard for finance. I caught the bug, ended up being more into software than finance specifically, and the rest is history. My motivation at the time was this was the middle of the big global financial crisis, everything had tanked, and it seemed like a great time to get in low. Buying my first house in 2009 was probably the most advantageous thing I did, though I was at least able to do that by tax-free early liquidation of an IRA that was full of self-picked stocks. reply trevzercap 15 hours agoprevSorry everyone! And thank you! Due to high volume I am hitting my API limits. If you are getting a server error that is why. The limit resets ever minute so please wait and try again. reply FriedPickles 8 hours agoparentHmm, I am getting a client error: https://www.useequityval.com/stockoverview?ticker=ULS reply codegeek 15 hours agoparentprevAlways be mindful of this when submitting to HN. The real test of traffic surge. Right now, it is of not much use as it just gives server error. reply jb1991 13 hours agorootparentNo need to rain on their parade. As if they are not already now aware of this. reply nescioquid 13 hours agorootparentThis caught out the current Show HN poster, so I imagine the comment could be useful to future Show HN posters. Besides, the comment wasn't unkind to the present poster and is actually kind to future posters, so the admonishment and down-votes seem unwarranted. reply jb1991 1 hour agorootparentMy tip is to re-evaluate why you think you are getting downvoted to better understand your tone and wording rather than assume the downvotes are not warranted. reply trevzercap 15 hours agorootparentprevHaha yeah, I will have to upgrade my api limit. Thank you! reply timmit 6 hours agoprevDo you mind sharing what API do you use to fetch the stock price? reply rishab_kokate 11 hours agoprevHi, loved the idea behind your product. Just a quick question about your tech stack? What stack did you use? Im trying to learn more about web development and was in the process of learning how to make my idea. Im leaning towards the MERN stack rn but not exactly sure if its a good idea, so im just asking you also what were the criterias/questions you asked yourself for choosing your tech stack? reply tndibona 12 hours agoprevI like the site. You reacted the HN front page. Congrats mate, I hope you don't burn a hole in your wallet to support this surge in traffic. reply trevzercap 12 hours agoparentHaha, just upgraded my email provider so i wouldn't run out 30 seconds ago. Thank you! reply atlgator 12 hours agoprevYour model projects the price of Nvidia will rise to $30,173. How does it arrive at that? reply trevzercap 12 hours agoparentHi this is from a comment below on this \"Hey, the model starts with the previous years growth numbers projected out 5 years. You are meant to give your assumptions to get to a valuation. NVDA revenue grew 125% last year so projecting that out for 5 straight years results in a very high value but is most likely inaccurate!\" I should probably take nvda off the home page lol reply 0cf8612b2e1e 5 hours agorootparentI think maybe come up with one or two more simple, but dumb models. Show all three at once to demonstrate the wildly different results that can come out given different assumptions. reply 3abiton 10 hours agorootparentprevOnly Nvidia? These predictions are maybe misleading? And might present bad information to unaware users? reply hi-v-rocknroll 8 hours agoprevIt's predicting a contraction in value of 20% to 70% of every stock I throw at it. 40k DIJA is a more-than-inflationary bubble popping within a few years? Edit: Chipotle must be headed for E. Coli again: Projected Price: $-2,890.64 https://www.useequityval.com/model?ticker=CMG reply ArtTimeInvestor 14 hours agoprevIm skeptical whether these types of models can help you make better investment decisions. The fate of a company usually hinges on some fundamental question. For Apple it is whether they can stay a prominent platform that can capture a significant portion of the value created on it. For Tesla it is how fast their self driving tech will evolve. For Google it is whether AI will make search obsolete or more valuable. reply jacobsenscott 10 hours agoparentYes - it is well known there is no \"secret investing sauce\" - this has been proven over and over. The only people who tell you otherwise are people with something to sell you, or people who have tricked themselves into believing otherwise. This kind of stuff pops up whenever the market is on a tear. reply ijidak 2 hours agoparentprevYour examples are actually edge cases that DCF was never designed to handle. There are lots of investments that are way more boring than Apple, Tesla, and Google, and that should be analyzed with DCF. DCF is more for slow and steadily growing companies that might be undervalued for just a moment because of factors outside of the company's control. Tech companies can be harder to value via DCF, because as you say, there are monumental factors that outweigh historical cash flow trends. This is part of why Warren Buffet historically avoided tech. It is wildly unpredictable from a pure historical cash flow numbers standpoint. DCF is not a crystal ball. The types of questions you're talking about aren't well analyzed by DCF. But something like the fair value of Walmart can absolutely be determined via DCF. reply ArtTimeInvestor 58 minutes agorootparentLet's say you sit down and make a DCF for every company in the S&P 500. Now sort them by how much their current price differs from what you call \"fair value\". You expect that investing in all of the companies in the upper half of the list will result in a better long-term return than investing in the lower half of the list? reply anonu 12 hours agoparentprev> these types of models This is THE way fundamental analysis is done. There are many ways to model - but this is the most robust as you have the most inputs. reply trevzercap 14 hours agoparentprevYeah its an art not a science for sure. Those questions and how you think the answers will play out should inform the inputs you use for your model. DCF modeling is not a silver bullet to predict a stock price thats for sure. reply jb1991 13 hours agoparentprevCounterpoint: Jim Simons reply neeeeees 13 hours agorootparentQuite the opposite actually. Simons and similar practitioners eschewed fundamental valuation techniques. Buffett is possibly a better example. reply rahimnathwani 13 hours agorootparentprevHFT isn't primarily about fundamental valuation. reply doctorpangloss 13 hours agorootparentI'm not sure why anyone would invoke Renaissance as an example of anything, giving how little people know about what they concretely do. Seems ironically unscientific of people who admire Jim Simons. reply czbond 12 hours agorootparentprevNeither is an equity's price much of the calendar year. reply rahimnathwani 11 hours agorootparentWe should distinguish between: - price (absolute level) - price movements (relative change) Your claim is that an equity's price isn't usually a reflection of fundamental value. On how many days this year (or this decade) was Google's market cap lower than that of Cheesecake Factory? Why? reply avarun 12 hours agorootparentprev…yes. Which is why OP made the argument that this tool, which helps with fundamental performance, isn’t very useful for calculating an equity’s price target. reply smabie 11 hours agorootparentprevRentec also doesn't do HFT reply rahimnathwani 9 hours agorootparentYou're right. AIUI Rentec holds positions for minutes or days (or maybe even weeks?), not seconds or less. My general point still stands. reply cmgriffing 12 hours agoprevI would love to see some tooltips or something to explain the relevance of some of the stock metrics and what a good vs bad number would look like. Something as simple as \"Higher number = better\" would be useful. reply trevzercap 12 hours agoparentThank you, this is a good suggestion. reply vivzkestrel 5 hours agoprevmind adding a blog post on how this was built? what technologies were used, what does the stack look like etc? reply adsdfdfsa 15 hours agoprevNoice! Where do you get your data? reply devoutsalsa 13 hours agoprevWhat are you using for a data source? Just web scraping? reply khaki54 14 hours agoprevTaking the defaults Boeing is going to -424 a share. Will check this out again later when I can actually try some sane numbers reply trevzercap 14 hours agoparentHi, DCF models are not very effective when a company is cashflow negative. That can result in weird looking values. On the last tab of the model you can switch the exit multiple to look at EV-Sales which will work better on a cashflow negative business like Boeing. Doing this with the model defaults results in a value of $149. Thanks for checking it out! reply mschuster91 13 hours agoparentprevThat's where this company should end up in any fair world, given all the evidence pointing to intentional misconduct and structural governance issues as a cause for multiple fatal crashes and other serious incidents. Snark aside, this may just be a case of Boeing's numbers being distorted by its business model and airlines paying only on delivery of airplanes (which has been seriously cut back due to regulators imposing production stops and caps as a result of all its issues for years now), but Boeing having to pay their vendors upon receipt of parts. Besides, anything aviation is a financial accounting shenanigans party. Many airlines, for example, are \"loss leaders\" - the money actually comes from their \"reward programs\" and credit cards [1], a practice that's been going on for decades now [2]. [1] https://www.theatlantic.com/ideas/archive/2023/09/airlines-b... [2] https://airlinegeeks.com/2021/12/17/here-s-why-airline-loyal... reply plessas 14 hours agoprevI subbed. Messing around with model parameters definitely has entertainment value. reply trevzercap 14 hours agoparentThank you! I appreciate the support. reply shegerking2020 12 hours agoprevthe sign up page is clunky. My inputs aren't visible https://pasteboard.co/PL6myO1PGkIG.png reply trevzercap 12 hours agoparentHi, this is odd. What browser are you using? reply Kickedsoda 12 hours agorootparentLooks like it could the autocomplete of the browser they are using. Try something like this in your global.css https://pasteboard.co/VAf6hbqgxOoU.png reply pockmockchock 3 hours agoprevseems like apple is a sell reply tessbi 11 hours agoprevThis is excellent! Good work! reply trevzercap 11 hours agoparentThank you! reply m3kw9 12 hours agoprevIf there is any alpha with these data, it would have been used up reply xyzzy4747 15 hours agoprevThe landing page doesn’t work well on mobile. reply trevzercap 15 hours agoparentYup, tbh this was my first time building a UI lol. I plan to improve the mobile experience if it gets decent traction. reply xyzzy4747 15 hours agorootparentUse tailwind.css, it's the best way. Then do breakpoints such as md: and lg: in the class names. And lots of flex box. reply camhart 13 hours agorootparent> best way It's simply a way. There are \"plenty of ways to skin a cat\". Best is highly debatable. I'd argue best is relative given the dev's experience and interest. Might be best if the dev was you. reply beeboobaa3 15 hours agoprevIf this worked you wouldn't be selling access, especially not for a one-time fee of $10. You'd be making millions. You could probably get away with charging a subscription fee. reply jstanley 13 hours agoparentTwo economists were walking down the street. The first economist spotted a £20 note on the ground and stopped to pick it up. The second economist asked \"why are you stopping?\". The first economist said \"to pick up this £20 note\". The second economist replied \"don't be stupid, if there was a £20 note on the ground somebody would already have taken it\". The first economist considered this for a moment, then nodded, and they both walked on. reply trevzercap 15 hours agoparentprevI am not advertising this as a stock price predictor. This is for people to make valuation models on stocks but the valuation depends on user input. reply bonestamp2 14 hours agorootparentI'm interesting in learning more about individual stock investing. I mean, I've been doing it for years, but more just on hype. I've been very successful, but I do very little research on fundamentals and I want to do more of that. So, your tool sounds interesting, but I don't know enough to use it. Do you have a tutorial video or anything that might walk me through a user story on how somebody would use your tool? Or, do you know of a good fundamentals course that would give me the knowledge to be a customer of your tool? reply trevzercap 14 hours agorootparentHey, thank you for the compliment. Aswath Damodaran is a professor at NYU and puts out a lot of good content on valuation. You should check him out. reply jvanderbot 15 hours agorootparentprevGreat way to test a lot of models, then use subscription fees to fund a bot based on the best performing ones. A few \"trading api\" shops did this last time I looked into it. reply ijidak 2 hours agoparentprevThese statements are hilarious. You're assuming that every human on earth is extremely selfish. If what you say is true, there would be no teachers in the world. Because most teachers make less than the students they teach. There are unselfish people out there. reply garyfirestorm 15 hours agoprevyour model is bonkers NVDA - Current Price: $921.93Projected Price: $30,082.68Difference: 3,163.01% reply trevzercap 15 hours agoparentHey, the model starts with the previous years growth numbers projected out 5 years. You are meant to give your assumptions to get to a valuation. NVDA revenue grew 125% last year so projecting that out for 5 straight years results in a very high value but is most likely inaccurate! reply bonestamp2 14 hours agorootparentIt sounds like a couple people in this thread have misunderstood how to use your tool. Perhaps you want to hide the projected numbers at least until they start to put in their own assumptions. reply trevzercap 14 hours agorootparentThis is a good suggestion. Thank you! reply garyfirestorm 13 hours agorootparentprevah that makes sense. thank you for clarifying. i was expecting a fair valuation based on YOUR assumptions and the value I misconstrued was that YOUR assumptions are better than mine so I must pay you. reply usernamed7 15 hours agoparentprevIf the AI says it it must be true. For the sake of my portfolio, fingers crossed. reply trevzercap 14 hours agorootparentlol I hope so to! there is no AI on the model though. Pro users can have an AI fill in the model for them. But the base model you see when you load up a stock is just projecting the previous years metrics out 5 years! reply dvfjsdhgfv 15 hours agorootparentprevJust wanted to chime in that I hope this ridiculous prophecy holds up! reply scarface_74 15 hours agoprevnext [10 more] [flagged] pvg 15 hours agoparentPlease don't post shallow dismissals, especially of other people's work. https://news.ycombinator.com/newsguidelines.html reply scarface_74 14 hours agorootparentWhat’s shallow about it? If someone posted “Twitter for pets” should we all just instinctively applaud it? I posted links from respectable publications - the WSJ included - supporting my comment. It’s been well known for decades that almost everyone sucks at “analyzing stocks” using any methodology. reply pvg 13 hours agorootparentshould we all just instinctively applaud it? No. Which is in the site docs as well: When something isn't good, you needn't pretend that it is, but don't be gratuitously negative. But more importantly, what makes your comment shallow is not the ostensible depth and heft of your links, it's that it shows little evidence of having looked at the thing being showhn - it's a thread-invariant trope. If someone does a Show HN for a Twitter for pets you are not required to applaud it, instinctively or otherwise, but you are asked to not reflexively dismiss it in thread comments. Critique is fair game, of course. reply scarface_74 11 hours agorootparentI mean if you really want to quote HN rules > Please don't comment on whether someone read an article. \"Did you even read the article? It mentions that\" can be shortened to \"The article mentions that\". reply pvg 11 hours agorootparentI didn't comment on whether you've read the article. There's a strong expectation a toplevel comment in a Show HN thread is concretely about the thing being showhn. That's not some complicated thing that requires the subtle parsing of multiple rules. reply scarface_74 10 hours agorootparentYes, and you quoted yourself that just because it’s a “ShowHN” doesn’t mean that it has to be praised effusively and get a attaboy. My negativity wasn’t “gratuitous”. His tool was meant to predict stock price. Every reputable article shows that kind of analysis is foolhardy- or as the WSJ put it - about as good as blind monkeys reply pvg 8 hours agorootparentI think the key thing is that it was a straightforwardly poor Show HN comment. What Specific Word of The Guidelines It Hath Not Transgressed Against as well as Who Is The Real Guidelines Sinner are both not particularly important. reply trevzercap 15 hours agoparentprevNothing wrong with index investing! I personally like to pick stocks as a hobby but most of my investments are in good old indexes! reply scarface_74 14 hours agorootparentI am all for hobby investing. I like playing with numbers (no sarcasm intended) and stock picking as a hobby is understandable as is sports betting. reply TradingPlaces 14 hours agoprevEveryone: This is a nice simple interface for making a discounted cash flow (DCF) model, and the pro version lets you export that to Excel. There’s still a lot of work to fill in those fields. More on DCF: https://corporatefinanceinstitute.com/resources/valuation/dc... OP: What are “AI Models\" reply trevzercap 14 hours agoparentHi, the pro version allows you to tell an AI what you think aboout the company and it will fill in the DCF model for you. So you can say, \"I think AAPL will have strong growth over the next 5 years, they will also see costs go down as xyz will happen\" and the AI will use your assumptions to fill in the DCF reply TradingPlaces 10 hours agorootparentThanks for clearing that up reply throwme_123 9 hours agoprev [–] Not only this is completely useless. Also it's a SEC violation. Also, \"positive\" comments here seem to be posted by friends of OP like https://news.ycombinator.com/item?id=40394428 or https://news.ycombinator.com/item?id=40394725 reply everfree 9 hours agoparentIn what way is this an SEC violation? reply trevzercap 9 hours agoparentprevLmao buddy. You think I have gotten 50+ friends to comment on this? You must be special. Some people are nice and enjoy their life, you clearly don’t. Also please point out the SEC violations. I am not telling anyone to buy or sell a stock. Please use some brain cells before your next comment. reply Tdil 9 hours agoparentprev [–] Womp womp, cry skibiti, get mogged reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "EquityVal Pro enables retail investors to generate, store, and exchange valuation models for various publicly traded companies, aiding in well-informed investment choices.",
      "Users have the option to personalize Discounted Cash Flow (DCF) models, utilize precise data, and archive their models for additional assessment on a dashboard.",
      "The platform includes advanced Pro functionalities tailored for well-known stocks such as Apple, Google, Tesla, and Nvidia."
    ],
    "commentSummary": [
      "Users engage in discussions on utilizing a financial modeling tool for stock valuation, sharing experiences, concerns, and improvement suggestions.",
      "Topics cover realistic assumptions, Discounted Cash Flow (DCF) models' effectiveness, AI integration in stock valuation, and debates on index investing.",
      "Feedback on the tool's functionality, proposed enhancements, regulatory concerns, and ethical considerations in investment decision-making are actively exchanged among participants."
    ],
    "points": 208,
    "commentCount": 114,
    "retryCount": 0,
    "time": 1715968762
  },
  {
    "id": 40395107,
    "title": "Introducing Experts.js: Creating Multi AI Agent Systems with OpenAI's Assistants API",
    "originLink": "https://github.com/metaskills/experts",
    "originBody": "Multi AI Agent Systems using OpenAI's Assistants API (Experts.js) Experts.js is the easiest way to create and deploy OpenAI's Assistants and link them together as Tools to create a Panel of Experts system with expanded memory and attention to detail. Overview The new Assistants API from OpenAI sets a new industry standard, significantly advancing beyond the widely adopted Chat Completions API. It represents a major leap in the usability of AI agents and the way engineers interact with LLMs. Paired with the cutting-edge GPT-4o model, Assistants can now reference attached files & images as knowledge sources within a managed context window called a Thread. Unlike Custom GPTs, Assistants support instructions up to 256,000 characters, integrate with 128 tools, and utilize the innovative Vector Store API for efficient file search on up to 10,000 files per assistant. Experts.js aims to simplify the usage of this new API by removing the complexity of managing Run objects and allowing Assistants to be linked together as Tools. const thread = Thread.create(); const assistant = await MyAssistant.create(); const output = await assistant.ask(\"Say hello.\", thread.id); console.log(output) // Hello More importantly, Experts.js introduces Assistants as Tools, enabling the creation of Multi AI Agent Systems. Each Tool is an LLM-backed Assistant that can take on specialized roles or fulfill complex tasks on behalf of their parent Assistant or Tool. Allowing for complex orchestration workflows or choreographing a series of tightly knit tasks. Shown here is an example of a company assistant with a product catalog tool which itself has a LLM backed tool to create OpenSearch queries. Installation Install via npm. Usage is very simple, there are only three objects to import. npm install experts import { Assistant, Tool, Thread } from \"experts\"; Assistants - The main object that represents an AI agent. Tools - An Assistant that can be used by other Assistants. Threads - A managed context window for your agents. Assistants The constructor of our Assistant facade object requires a name, description, and instructions. The third argument is a set of options which directly maps to all the request body options outlined in the create assistant documentation. All examples in Experts.js are written in ES6 classes for simplicity. The default model is gpt-4o. class MyAssistant extends Assistant { constructor() { const name = \"My Assistant\"; const description = \"...\"; const instructions = \"...\" super(name, description, instructions, { model: \"gpt-4-turbo\", tools: [{ type: \"file_search\" }], temperature: 0.1, tool_resources: { file_search: { vector_store_ids: [process.env.VECTOR_STORE_ID], }, }, }); } } const assistant = await MyAssistant.create(); The Experts.js async create() function will: Find or create your assistant by name. Updates the assistants configurations to latest. (pending) Simple Ask Interface The ask() function is a simple interface to ask or instruct your assistant(s). It requires a message and a thread identifier. More on Threads below. The message can be a string or native OpenAI message object. This is where Experts.js really shines. You never have to manage Run objects or their Run Steps directly. const output = await assistant.ask(\"...\", threadID) const output = await assistant.ask({ role: \"user\", content: \"...\" }, threadID); Adding Tools Normal OpenAI tools and function calling are supported via our constructors options object via tools and tool_resources. Experts.js also supports adding Assistants as Tools. More information on using Assistants as Tools can be found in the next section. Use the addAssistantTool function to add an Assistant as a Tool. class MainAssistant extends Assistant { constructor() { const name = \"Company Assistant; const description = \"...\"; const instructions = \"...\"; super(name, description, instructions); this.addAssistantTool(ProductsTools); } } Streaming & Events By default all Experts.js leverages the Assistants Streaming Events. These allow your applications to receive text, image, and tool outputs via OpenAI's server-send events. We lever the openai-node stream helpers and surface these and more so you can be in control of all events in your agentic applications. const assistant = await MainAssistant.create(); assistant.on(\"textDelta\", (delta, _snapshot) => { process.stdout.write(delta.value) }); All openai-node streaming events are supported via our Assistant's on() function. The available event names are: event, textDelta, textDone, imageFileDone, toolCallDelta, runStepDone, toolCallDone, and end Important OpenAI's server-send events are not async/await friendly. If your listeners need to perform work in an async fashion, such as redirecting tool outputs, consider using our extensions to these events. They are called in this order after the Run has been completed. The available async event names are: textDoneAsync, imageFileDoneAsync, runStepDoneAsync, toolCallDoneAsync, and endAsync. Advanced Features If you want to lazily standup additional resources when an assistant's create() function is called, implement the beforeInit() function in your class. This is an async method that will be called before the assistant is created. async beforeInit() { await this.#createFileSearch(); } All Assistant events receive an extra Experts'js metadata argument. An object that contains the Run's stream. This allows you to use the openai-node's helper functions such as currentEvent, finalMessages, etc. assistant.on(\"endAsync\", async (metadata) => { await metadata.stream.finalMessages(); }); Tools Using an Assistant as a Tool is central focal point of the Experts.js framework. Tools are a subclass of Assistant and encapsulate the interface for their parent objects. In this way Experts.js tools are reusable components in your agentic architecture. Our examples illustrate a basic message passing pattern, for brevity. You should leverage all of OpenAI's tool and function calling features to their fullest. class EchoTool extends Tool { constructor() { const name = \"Echo Tool\"; const description = \"Echo\"; const instructions = \"Echo the same text back to the user\"; super(name, description, instructions, { parentsTools: [ { type: \"function\", function: { name: EchoTool.toolName, description: description, parameters: { type: \"object\", properties: { message: { type: \"string\" } }, required: [\"message\"], }, }, }, ], }); } } Caution It is critical that your tool's function name use the toolName getter. Experts.js converts this to a snake_case string and uses the name to find the the right tool and call it. As such, Tool class names are important and help OpenAI's models decide which tool to call. So pick a good name for your tool class. For example, ProductsOpenSearchTool will be products_open_search and clearly helps the model infer along with the tool's description what role it performs. Tools are added to your Assistant via the addAssistantTool function. This function will add the tool to the assistant's tools array and update the assistant's configuration. class MainAssistant extends Assistant { constructor() { const name = \"Company Assistant; const description = \"...\"; const instructions = \"...\"; super(name, description, instructions); this.addAssistantTool(EchoTool); } } Your Tool assistant response will automatically be submitted as the output for the parent Assistant or Tool. Non-LLM Tools By default Tools are backed by an LLM model and perform all the same lifecycles events, runs, etc as Assistants. However, you can create a Tool that does not use any of the core Assistant's features by setting the llm option to false. When doing so, you must implement the ask() function in your Tool. The return value will be submitted as the tool's output. class AnswerTwoTool extends Tool { constructor() { // ... super(name, description, instructions, { llm: false, parentsTools: [...], }); } async ask(message) { return ...; } } Controlling Output In complex workflows, a LLM backed Tool can be used to convert human or other LLM instructions into executable code and the result of that code (not the LLM output) would need to be submitted for your Tool's parent's outputs. For example, the ProductsOpenSearchTool could convert messages into OpenSearch queries, execute them, and return the results. Sub classes can implement the answered() function to control the output. In this case, the output would be an OpenSearch query and the tools outputs now contain the results of that LLM-generated query. async answered(output) { const args = JSON.parse(output); return await this.opensearchQuery(args); } Alternatively, LLM backed Tools could opt to redirect their own tool outputs back to their parent Assistant or Tool. Thus ignoring the LLM output. This also allows for all of a Tools tool outputs to be submitted as the parent's output. More on why this is important in the product catalog example below. class ProductsTool extends Tool { constructor() { // ... super(name, description, instructions, { temperature: 0.1, tools: [{ type: \"code_interpreter\" }], outputs: \"tools\", parentsTools: [...], }); this.addAssistantTool(ProductsOpenSearchTool); this.on(\"imageFileDoneAsync\", this.imageFileDoneAsync.bind(this)); } } Threads OpenAI's Assistants API introduces a new resource called Threads which messages & files are stored within. Essentially, threads are a managed context window (memory) for your agents. Creating a new thread with Experts.js is as easy as: const thread = Thread.create(); console.log(thread.id) // thread_abc123 You can also create a thread with messages, files, or tool resources to start a conversation. We support OpenAI's thread create request body outlined in their Threads API reference. const thread = await Thread.create({ messages: [ { role: \"user\", content: \"My name is Ken\" }, { role: \"user\", content: \"Oh, my last name is Collins\" }, ], }); const output = await assistant.ask(\"What is my full name?\", thread.id); console.log(output) // Ken Collins Thread Management & Locks By default, each Tool in Experts.js has its own thread & context. This avoids a potential thread locking issue which happens if a Tool were to share an Assistant's thread still waiting for tool outputs to be submitted. The following diagram illustrates how Experts.js manages threads on your behalf to avoid this problem: All questions to your experts require a thread ID. For chat applications, the ID would be stored on the client. Such as a URL path parameter. With Expert.js, no other client-side IDs are needed. As each Assistant calls an LLM backed Tool, it will find or create a thread for that tool as needed. Experts.js stores this parent -> child thread relationship for you using OpenAI's thread metadata. Examples To see code examples of these and more in action, please take a look at our test suite. Product Catalog In the Overview section we showed a three-tiered agent system that can answer the following types of questions. The examples uses most, if not all, the features of the Experts.js framework. What is the total amount of products available? Show me a bar chart image with totals of all top level categories. Find men's accessories for a sophisticated comic book enthusiast. Streaming From Express Basic example using the textDelta event to stream responses from an Express route. import express from \"express\"; import { MainAssistant } from \"../experts/main.js\"; const assistant = await MainAssistant.create(); messagesRouter.post(\"\", async (req, res, next) => { res.setHeader(\"Content-Type\", \"text/plain\"); res.setHeader(\"Transfer-Encoding\", \"chunked\"); assistant.on(\"textDelta\", (delta, _snapshot) => { res.write(delta.value); }); await assistant.ask(req.body.message.content, req.body.threadID); res.end(); }); Messages With Images The Assistant's API supports messages with images using either the image_url or image_file content types. Since our ask() function supports strings or native OpenAI message objects. const output = await assistant.ask( { role: \"user\", content: [ { type: \"text\", text: \"Tell me about this image.\" }, { type: \"image_file\", image_file: { file_id: file.id detail: \"high\" } }, ], }, threadID ); Vector Store Using a Vector Store for file search is easy using OpenAI's interface via our third configuration option. You could alternatively create your vector store on-demand using our beforeInit() function described in Advanced Features. class VectorSearchAssistant extends Assistant { constructor() { const name = \"Vector Search Assistant\"; const description = \"...\"; const instructions = \"...\" super(name, description, instructions, { tools: [{ type: \"file_search\" }], temperature: 0.1, tool_resources: { file_search: { vector_store_ids: [process.env.VECTOR_STORE_ID], }, }, }); } } Token Usage Metrics Using the Streaming & Events feature to report token usage allows you to have per-assistant metrics. class MyAssistant extends Assistant { constructor() { // ... super(name, description, instructions); this.on(\"runStepDone\", this.#reportUsage.bind(this)); } #reportUsage(runStep) { if (!runStep?.usage?.total_tokens) return; const iT = runStep.usage.prompt_tokens; const oT = runStep.usage.completion_tokens; const tT = runStep.usage.total_tokens; console.log({ InTokens: iT, OutTokens: oT, TotalTokens: tT }); } } Development Setup This project leverages Dev Containers meaning you can open it in any supporting IDE to get started right away. This includes using VS Code with Dev Containers which is the recommended approach. Once opened in your development container, create a .env.development.local file with your OpenAI API key and postimage.org API key: OPENAI_API_KEY=sk-... POST_IMAGES_API_KEY=... Now you can run the following commands: ./bin/setup ./bin/test Scratch const thread = Thread.create(); const assistant = await MyAssistant.create(); const output = assistant.ask(\"Hi, how are you?\", thread.id);",
    "commentLink": "https://news.ycombinator.com/item?id=40395107",
    "commentBody": "Multi AI agent systems using OpenAI's assistants API (github.com/metaskills)173 points by metaskills 10 hours agohidepastfavorite56 comments yatz 7 hours agoAssistants API is promising, but earlier versions have many issues, especially with how it calculates the costs. As per OpenAI docs, you pay for data storage, a fixed price per API call, + token usage. It sounds straightforward until you start using it. Here is how it works. When you upload attachments, in my case a very large PDF, it chunks that PDF into small parts and stores them in a vector database. It seems like the chunking part is not that great, as every time you make a call, the system loads a large chunk or many chunks and sends them to the model along with your prompt, which inflates your per request costs to 10 times more than the prompt + response tokens combined. So, be mindful of the hidden costs and monitor your usage. reply iamflimflam1 5 hours agoparentThere isn’t really any other way for this to work. The only way for the model to answer questions on your pdf is for the information to be somewhere in the prompt. reply benreesman 41 minutes agorootparentThat might be true of specific models or specific APIs for accessing them, but I’d argue isn’t even remotely true of neural networks generally or generatively-pretrained decoder-only attention-inspired language models in particular. Ideally if you want a model’s weights to include a credible representation of non-trivial data you want it somewhere in the training pipeline (usually earlier is better for important stuff but that’s a hubristic at best), but there’s transfer learning of various kinds, and joint losses of countless kinds (CLIP in SD-style diffusors come to mind), and fine tunes (if that doesn’t just count as transfer learning), and dimensionality reduction that is often remarkably effective, and multi-tower models like what evolved into DLRM, and I’m forgetting/omitting easily 100x the approaches I mentioned. It’s possible I misunderstand you, so please elaborate if so? reply hnuser123456 3 hours agoparentprevHow large is a very large PDF? reply xrendan 10 hours agoprevI'd be interested in knowing if anyone is seriously using the assistants API, it feels like such a lock in to OpenAIs platform when your can alternatively just use completions that are much more easily interchanged. reply Nedomas 8 hours agoparentI do and built Assistants API compat layer for Groq and Anthropic: https://github.com/supercorp-ai/supercompat I’d argue that Assistants API DX > manual completions API. reply tomrod 7 hours agorootparentAye, but your FinOps will be comolaining even with simple use. reply Nedomas 7 hours agorootparentAssistants API use in prod used to suck because it would send full convo on each message. But last month they added an option to send truncted history so its no longer 2$ a pop thankfully. Also Grok, Haiku and Mistral is cheap reply oddthink 6 hours agoparentprevI know at least one team is at work is using the Assistants API, and I'm talking with another team that is leaning pretty heavily towards using it over building a custom RAG solution themselves, or even over other in-house frameworks. reply phh 9 hours agoparentprevI've indeed refused to work with some providers giving only a chat interface and not a completion interface because it made the communication \"less natural\" to the model (like adding new system messages in between for function calling on models which don't officially does it, or adding other categories than system/user/assistant) reply metaskills 9 hours agorootparentGreat points. Dont even get me started about how function calling in other LLMs costs me tokens. Something OpenAI provides OOTB. I'm also not a big fan of OpenAI's lock in. Right now I'm on a huge Claude 3 Haiku kick. That said, OpenAI does seem to get the APIs right and my hunch is the new Assistants API is going to potentially disrupt things again. Time will tell. reply benreesman 35 minutes agorootparentOpus is really cool. I’ve found it to have a few persistent bugs in what I initially assumed is tokenization but now wonder if might be more fundamental, but modulo a few typographical-level errors, I personally think it’s the most useful of the API-mediated models for involved sessions. And there are some serious people at Anthropic, they’ll get the typo thing if they haven’t already (been a busy week and change, they easily could have shipped a fix and I overlooked it). reply heggy 9 hours agorootparentprevI would love to be using Claude, but you can't get API access (beyond an initial trial period) in the EU without providing a European VAT number. They don't want personal users or people to even learn and experiment I guess. reply metaskills 8 hours agorootparentInteresting, would Amazon Bedrock be an alternative? That's how I use Claude. reply bjterry 8 hours agorootparentprevYou can use the Claude APIs via OpenRouter with a pre-paid account. reply Jimmc414 8 hours agorootparentprevI'd guess it's more likely about the additional programming needed to meet GDPR compliance requirements. reply msp26 8 hours agorootparentprev> Dont even get me started about how function calling in other LLMs costs me tokens. Something OpenAI provides out of the box. Not sure what you mean by this. reply metaskills 7 hours agorootparentI have some assumptions/guesses on how billing works. Gonna do a post on this on my unremarkable.ai blog, please do signup for posts there, no spam. I could be right or wrong but need to do some experiments and publish later. reply BoorishBears 9 hours agorootparentprevI'm not sure you're talking about the same thing: OpenAI specifically has a \"Assistants API\" that manages long term memory and tool usage for the consumer: https://platform.openai.com/assistants I'd guestimate 99% of people using LLMs are using instruct-based message interfaces that have a variation of system/user/assistant. The top models mostly only come as a completion models, and even Anthropic has switched to a message based API reply j45 5 hours agoparentprevI've used it and in some cases it's taking days and weeks of development away to get to testing the market. In some cases the lock in is what it is for now because a particular model in reality is so far ahead, or staying ahead. It doesn't mean other options won't become available, but it does matter to relate your need to your actions. Getting something working consistently for example might be the first goal, and then learning to implement it with multiple models might be secondary. The chances of that increase the later other models are explored in some cases. It should be possible to tell pretty quickly if something works in a particular model that's the leader, how others compare to it and how to track the rate of change between them. reply csouzaf 9 hours agoprevWhat's the use cases people are using Multi AI Agents to solve problems that deliver real value? Someone has something with your hands on right now? reply avereveard 3 hours agoparentI've encountered two viable cases: instructions are too complex, too many tools, or wildly different processing steps, in which case it semplify a lot the processing to have a few well defined steps each doing their thing, and a coordinator on top, either sequential, or intelligent, that is only focuesed on next step routing. the other is memory for conversational retrieval. ai memory is still quite limited, especially if there needs to be a lot of token in context, and context too long impede the ability of llm of focus on the task itself, especially if the context is itself a conversation or a request, so spreading the context along a few agents, and propagating the user request among agent, and having those produce answer fragment for another llm to formulate an answer allows to not lose the conversational context without swamping the llm with noise. the problem tho remains latency as son as you nest them latency explodes as you can only stream the last layer of llm output reply ww520 9 hours agoparentprevI imagine having an agent set up with specific RAG context to solve a specific problem and having another with a different RAG context to solve a different problem can be useful. reply csouzaf 9 hours agorootparentI see customer support as a very talked subject to solve this. But these system really manage to solve the issue removing the human feedback dramatically? reply LASR 3 hours agoparentprevWe’ve tried. A lot. Custom frameworks and all. There is really no way to make the ensemble behave with an acceptable level of consistency. Where we ended up is now having a frontier model generate a whole tree of possible execution plans, and then have the user select one of those path, and then we just run whatever the user chose in a plain sequence until the next decision point that needs user approval. reply coffeebeqn 9 hours agoparentprevI tried the last crop. Interesting idea but the success rate of any real multi step task always approached 0% the longer it went reply mentos 6 hours agoprevAnyone recommend the best way to use AI to search all of my documents for a project. I've got specifications, blueprints, emails, forms, etc. Would be great to be able to ask it, 'have we completed the X process with contractor Y yet?' reply valiant-comma 6 hours agoparentTry h2ogpt: https://github.com/h2oai/h2ogpt reply squirrel 1 hour agoparentprevZenfetch reply beoberha 9 hours agoprevFrom the website linked in the readme: “A lot of research has been doing in this are and we can expect a lot more in 2024 in this space. I promise to share some clarity around where I think this industry is headed. In personal talks I have warned that multi-agent systems are complex and hard to get right. I've seen little evidence of real-world use cases too” These assistant systems fascinate me, but I just don’t have the time and energy to set something up. I was going to ask if anyone had a good experience with it, but the above makes it sound like there’s not much hope at the moment. Curious what other people’s experience are. reply dongobread 9 hours agoparentWe tried using a multi-agent system for a complex NLP-type task and we found: - Too many errors that just propogate on top of each other, if a single agent in the chain generates something even a little bit off then the whole system goes off the rails. - You often end up having to pass a massive amount of shared context to every agent which just increases the cost dramatically. Curiously enough we had an architect from OpenAI tell us the same thing about agent systems a few days ago (our company is a big spender so they serve a consulting function), so I don't think anybody is really finding success with multi-agent systems currently. IMO the core tech is nowhere near good enough yet. reply pennomi 9 hours agorootparent> Too many errors that just propogate on top of each other LLMs are like the perfect improv comedy troupe, they virtually always say “yes, and…” reply echelon 8 hours agorootparent> perfect improv comedy troupe Check out Vtubers like CodeMiko, who improvs against LLM agents. Or 24/7 streaming LLM cartoon shows that take audience plot suggestions. reply lmeyerov 6 hours agorootparentprevwe do multistep programs in louie.ai via a variety of agents/tools, like \"get X data from DB Y, wrangle cols A+B in Python, and then draw an interactive map + graph\" The ultimate answer is fairly short if you are a senior python data scientist, like 50loc. The agents will wander and iterate until they push through. You might correct & tweak if a bit off. Importantly, this does agents opposite of the way Devin AI engineer replacements are presented. Here, you get it to do a few steps, and then move on to the next few steps. The agents still crank away a ton and do all sorts of clever things for you... to get you more reliably to the next step, vs something big & wrong. reply metaskills 9 hours agoparentprevThanks @beoberha, I am too. I like one take I heard on Twitter. The sentiment was something like these types of systems are useful under the AI-Powered Productivity industry which has incremental gains, no big bangs. Said another way, if your job was to help a TON of your employees be more productive individually, it is worth it because companies measure those efforts broadly and the payoff is there. But again, not big. My advice for folks to stay lower level and hook AI automation up with simple, closed loop, LLM patterns that feel more like basic API calls in a choreographed manner. OMG, hope all that made sense reply purposesystem 9 hours agorootparentthat's actually a great reply, thanks reply fzliu 9 hours agoparentprevA lot of folks I've spoken with say that single-agent systems are still extremely limited, let alone multi-agent platforms. In general, it seems to boil down to: - Agents need lots of manual tuning and guardrails to make them useful - Agents with too many guardrails are not general-purpose enough to be worth the time and effort to build I believe truly great agents will only come from models whose weights are dynamically updated. I hope I'm wrong. reply m3kw9 9 hours agoparentprevBy the time you do get around to it OpenAi would have built a full interface for this. This is the type of stuff that’s gonna get steamrolled. reply WXLCKNO 8 hours agorootparentPretty much this. I'd love counter examples of startups in the space that haven't been crushed from the top yet. reply david_shi 6 hours agoprevA bit off topic, but has anyone seen any agent systems focused on improving the agents capabilities with more usage? reply __loam 9 hours agoprevI've not seen any of these \"agentic\" systems be all that useful in practice. Complicated chain of software where a lot can wrong at any step, and the probability of failure explodes when you have many steps. reply ec109685 6 hours agoprevI don’t understand the comment about server send events not being async friendly. What is unfriendly about this? import OpenAI from 'openai'; const openai = new OpenAI(); async function main() { const stream = await openai.chat.completions.create({ model: 'gpt-4', messages: [{ role: 'user', content: 'Say this is a test' }], stream: true, }); for await (const chunk of stream) { process.stdout.write(chunk.choices[0]?.delta?.content || ''); } } main(); It’s easy to collect the streaming output and return it all when the llm’s response is done. reply wokwokwok 6 hours agoparentThey’re referring to the: > assistant.on(\"textDelta”, () => … Callbacks, which are not async and can’t be streamed that way directly without wrapping it in some helper function. (Which does seem obvious; I’m also not sure why they called it out specifically as not being async friendly? I guess most callback style functions these days have async equivalents in popular libraries and these ones don’t) reply behnamoh 8 hours agoprevI stay away from such frameworks because: - Writing what I want in Python/other-lingo gives me much more customizability than these frameworks offer. - No worries about the future plans of the repo and having to deal with abandonware. - No vendor lock in. Currently most repos like this focus on OpenAI's models, but I prefer to work with local models of all kinds and any abstraction above llama.cpp or llama-cpp-python is a no-no for me. The last point means I refuse to build on top of ollama's API as it's yet another wrapper around llama.cpp. reply rcarmo 1 hour agoparentNot using the ollama API means you have to keep track of context yourself, and run all your stuff in the same box. Hardly ideal. reply tr14 7 hours agoprevAI botnet? reply spiritplumber 10 hours agoprevOoh, shiny! reply moltar 9 hours agoprevBare JS. What is this 2001? reply metaskills 9 hours agoparentLMAO. Yes, I love ESM modules. So maybe more like 2012 or 2015. Would you like to see TypeScript? reply alluro2 9 hours agorootparentThank you for using vanilla JS! reply fy20 8 hours agorootparentprevNot OP, but I use TypeScript because it adds a layer of safety to the codebase. It's like having good test coverage - you can make large changes and if the tests pass (the code compiles), you can be fairly confident that you didn't mess anything up. I've written Ruby for years, so I'm used to dynamically typed languages. But JavaScript is it's own level of special, and there's so many ways you can accidentally mess things up. Having tests cover every single path (especially failure paths) can be very time consuming, and often hard or messy to setup (how would you mock the OpenAI module returning an error when adding metadata to a thread?), where as using something like TypeScript can make sure your code handles all paths somewhat correctly (at least as well as the types you defined). Your code looks clean, and you appear to have good test coverage, so you do you though :-) reply taf2 8 hours agorootparentprevYes this is great so much easier to work with reply metaskills 7 hours agorootparentY'all just made my day! reply obiefernandez 9 hours agoprev [–] My main conversation “loop” at https://olympia.chat has tool functions connected to “helper AIs” for things such as integrating with email. It lets me minimize functions on the main loop and actually works really well. reply Terretta 5 hours agoparentSid Kapoor, Content Specialist, forgot to include himself in Growth or Pro plans. Guess he is Basic! reply bongodongobob 6 hours agoparentprev [–] I'm sorry but that is absolutely hilarious. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Experts.js simplifies creating and deploying OpenAI's Assistants API, enabling the formation of a Panel of Experts system by connecting multiple AI agents.",
      "The tool provides advanced features like referencing files, long instructions, integration with 128 tools, and efficient file search capabilities for building Multi AI Agent Systems with complex orchestration workflows.",
      "It supports developing reusable tools, customization, OpenSearch queries, thread management, and examples like streaming responses from an Express route and building a Vector Search Assistant."
    ],
    "commentSummary": [
      "The post explores the integration of OpenAI's Assistants API in multi AI agent systems, focusing on cost calculation challenges related to large PDF attachments.",
      "Users are cautioned about potential hidden expenses and are encouraged to monitor their API usage to manage costs effectively.",
      "Various API usage strategies, alternatives, communication interface issues, billing concerns, and GDPR compliance challenges are addressed, along with the complexities of employing ensemble models and multi-agent systems in tasks like document retrieval and customer assistance."
    ],
    "points": 173,
    "commentCount": 56,
    "retryCount": 0,
    "time": 1715988332
  },
  {
    "id": 40389548,
    "title": "Beekeeper's $2M Honey Crop Destroyed Due to Disease",
    "originLink": "https://www.rnz.co.nz/news/business/516930/beekeeper-steven-brown-furious-over-destruction-of-2m-honey-crop",
    "originBody": "RNZ Skip to content Menu Home NewsExpand New Zealand World Politics Pacific Te Ao Māori Sport Business Country Local Democracy Reporting Comment & Analysis In Depth Weather RadioExpand National Concert Pacific Programmes Presenters Latest Audio Podcasts & Series Topics Music Science & Environment Plays & Stories Stories for Kids Young Adult Audiobooks Books & Authors Life & Society Arts & Culture Food & Recipes Movies Business & Economy Politics Sport Comment & Analysis Media & Technology Country Pacific Nature & Environment Collections Current Affairs Te Ao Māori PacificExpand News Programmes Schedules How to Listen About RNZ Pacific IndoNZ 中文 Search Listen Live Nothing playing RNZ National Saturday Night National live stream RNZ Concert The Opera Season Concert live stream RNZ Pacific Tagata o te Moana International live stream More ways to listen Playlist Your playlist Launch player Close Audio help Launch player Navigation for News Categories New Zealand World Politics Pacific Te Ao Māori Sport Business Country Local Democracy Reporting Comment & Analysis In Depth Weather New Zealand Business 16 May 2024 Beekeeper Steven Brown furious over destruction of $2m honey crop 9:58 am on 16 May 2024 Share this Share on Twitter Share on Facebook Share via email Share on Reddit Share on Linked In Monique Steele, Journalist @MoniqueHSteele Monique.Steele@rnz.co.nz Honey producer Steven Brown watches boxes of honey burn. Photo: Facebook / Steven Brown Beekeepers say New Zealand needs a new approach to a hive-destroying disease that is leaving those affected out of pocket, uncompensated and devastated. Honey producer Springbank Honey of North Canterbury was ordered to burn more than 10,000 of its beehives and beekeeping equipment after American Foulbrood (AFB) was identified through spore testing. AFB is a bacterial disease spread by spores that could be viable for up to 40 years. It is considered one of the most widespread and destructive honey bee brood diseases in the world. The family-owned honey business, operating near Rangiora in North Canterbury, runs 3000 organic beehives and processes honey too. Co-owner Steven Brown said burning thousands of beehives over Mother's Day weekend had left the family \"devastated\". \"By next year, when we don't have boxes for our honey crop, we're probably going to be losing over $5-6 million,\" Brown said. \"The loss of the boxes is one thing, but without the boxes for the hives we won't have a honey crop.\" Beekeeper calls for different way to control American Foulbrood duration 4′ :35″ from Morning Report Add to playlistPlaylist Download Download as Ogg Download as MP3 Download as AAC Play Ogg in browser Play MP3 in browser Play AAC in browser Beekeeper calls for different way to control American Foulbrood Brown said it would cost around $2 million to replace it all, made more difficult by the fact that there was no compensation or insurance available for beekeepers. Burning the hives was more painful when other countries used tools like vaccines, antibiotics and sterilisation - measures prohibited in New Zealand and in some export markets. \"Most farmers vaccinate their cows for diseases every single year, but it's illegal to vaccinate the hive,\" Brown said. \"I don't understand why we have our heads in the sand and live like it's 200 years ago without these amazing abilities of giving a vaccine and stopping disease; instead we burn things.\" Photo: Facebook / Steven Brown The order to destroy the hives by fire came from the levy-run management agency that enforces the national pest management plan rules, including auditing beekeepers, monitoring for the disease and eliminating it. Brown said the new government needed to \"shut down immediately\" the outdated pest management plan and the agency. \"The plan was supposed to reduce AFB by 5 percent per year, they haven't complied with that. It's gone rampant throughout New Zealand,\" he said. \"I want the Biosecurity Act changed, but the one we're operating under, the pest management plan, the [Biosecurity] Minister needs to stop that immediately.\" More boxes are added to the bonfire. Photo: Facebook / Steven Brown Agency aims for support But the management agency's general manager, Niha Long said it aimed to support beekeepers impacted by the disease. She acknowledged how \"upsetting\" it would be for social media users to view the burning beehives - but burning was the only method at hand. \"The only way to destroy the spores is through burning, so we cannot use antibiotics unlike other countries in the world due to market access,\" Long said. She said the agency was not there to make beekeepers' operations harder. \"We acknowledge that it is a significant impact on the beekeeper, but we're not here - contrary to popular belief - to make a beekeeper's life difficult,\" she said. \"We're here to work with the beekeeper and that is the nature of the relationship we've attempted to have with this beekeeper [Springbank Honey]. \"AFB will happen if you're a beekeeper, at some point in your journey, and getting AFB is not the problem - what can be a problem for us is the beekeepers's action or inaction after you've found it.\" Photo: Facebook / Steven Brown She said the law and the pest management plan put legal obligations on its registered, levy-paying beekeepers. \"It dictates each beekeeper's responsibility for eliminating AFB, so I'd like to emphasise that that is each beekeeper's responsibility through a set of legal obligations.\" Long said fewer than eight percent of the country's 8000 beekeepers were currently affected - and there were 2900 reports of AFB made in the past year to May, down 15 percent on the 3449 reports the year before. Agency aims to eliminate American Foulbrood from beehives duration 6′ :23″ from Morning Report Add to playlistPlaylist Download Download as Ogg Download as MP3 Download as AAC Play Ogg in browser Play MP3 in browser Play AAC in browser Agency aims to eliminate American Foulbrood from beehives NZ 'pretty much alone' NZ Beekeeping Incorporated president Jane Lorimer said New Zealand was \"pretty much alone\" in the response to burn hives and equipment on positive spore tests. But she said beekeepers generally still followed the rules. \"Beekeepers have to notify and then destroy hives within seven days after finding the disease - and most beekeepers, including Steve, usually comply with that regulation. \"We're going to seek some clarification around the Biosecurity Act and the Pest Management plan and how the two legal aspects integrate.\" It was seeking clarification around how the Biosecurity Act and the pest management plans' legal aspects integrated. She said the government review into the legislation was an opportunity to improve transparency for the sector. \"We hope that the Minister will take into consideration our suggestions [in the review] and make changes accordingly. Part of that is an appeal process as well, there's nothing within the order in council about appealing what's happening when a beekeeper's asked to destroy equipment they've found spores in. \"This isn't the first case where beekeepers had been told to destroy beekeeping equipment that they'd found spores in.\" Lorimer said it was a difficult time for the industry, and the number of commercial beehives had halved in the past two years. Tags: food rural Canterbury Share this Share on Twitter Share on Facebook Share via email Share on Reddit Share on Linked In Copyright © 2024, Radio New Zealand Subscribe to RNZ's Daily Newsletter View latest newsletter Next story in Business Construction firms feeling the pressure with inflation and interest rates Related Stories Beekeepers deliver stinging response to Apiculture NZ plan 21 Feb 2024 Apiculture NZ is aiming to double exports to $1 billion by 2030 - but beekeepers are not impressed with the new strategy. Beekeepers deliver stinging response to Apiculture NZ plan 3422 beehives destroyed in year due to disease 8 Feb 2023 American Foulbrood disease weakens and kills honey bee colonies and once they become infected they never recover. Increase in disease for beehives 'concerning' as more than 3000 destroyed in one year Efforts to eradicate deadly disease from Hamilton hives 5 Feb 2019 Waikato Beekeepers are taking samples from Hamilton's 1500 hives, in a co-ordinated effort to rid the city of American Foulbrood disease which wipes out bees. Honey Scientist, Dr Mark Goodwin says… Audio, Gallery Listen duration 9′ :37″ Add to playlistPlaylist Download Download as Ogg Download as MP3 Play Ogg in browser Play MP3 in browser Efforts to eradicate deadly disease from Hamilton hives Business Tourism data gap leaves operators on shaky ground The Warehouse boss Nick Grayston abruptly quits Workplace harassment costing employers $1.5 billion per year Get the RNZ app for ad-free news and current affairs Top News stories New Caledonia riots: More deaths reported as unrest spreads to rural areas Wellington Phoenix season ends with semi-final loss Cindy Taylor released from prison after allowing her mother Enai Lai Dung to starve to death Cold night looms for South Island, heavy snow warning issued for inland Canterbury Ruthless Blues hammer Highlanders in Auckland Subscribe Subscribe to RNZ's Daily Newsletter View latest newsletter Business RSS Follow RNZ News RNZ stations National Concert RNZ Pacific Parliament - live stream Latest & popular Latest audio Popular audio Latest video How to watch & listen Audio help Radio Follow our podcasts Sky, Freeview & Satellite YouTube RNZ apps for iPhone and Android RNZ Flash Briefing for Amazon Alexa RNZ News for Google Assistant About RNZ About Contact Audience Feedback and Complaints Media Releases Awards Jobs RNZ Your Media Matters Local Democracy Reporting RNZ Commissioning Join & Follow RNZ RNZ on Facebook RNZ on Twitter RNZ on Youtube RNZ on Instagram Sign up to RNZ Newsletters Terms of use © Copyright Radio New Zealand 2024",
    "commentLink": "https://news.ycombinator.com/item?id=40389548",
    "commentBody": "Beekeeper furious over destruction of $2M honey crop (rnz.co.nz)158 points by GrumpyNl 20 hours agohidepastfavorite120 comments frankzander 19 hours agoHm here in Germany we do not burn hives. If AFB occurs the hives have to be heat threaded with a torch (plastic ones have to be cleaned with soda lye). The frames have to be burned or cleaned in soda lye. the bee swarm itself get new frames without any foundation so that they have to build combs of their own. This process must be repeated until no spores are found anymore. Back in the days the beekeepers had to burn their hives but this is from the old days. reply rmetzler 18 hours agoparentI just read about this on [0]. This method is a little bit more complicated than you describe it. I’m also not sure how easy it is to scale. You still need to destroy parts of the beehive, let all the bees hunger for a few days and disinfectant the parts of the beehive you want to reuse. I don’t know if all of this is possible with that many beehives mentioned in the post. [0] https://de.m.wikipedia.org/wiki/Kunstschwarmverfahren reply frankzander 18 hours agorootparentAs far as I know this method is done by commercial beekeepers. Well at the end you are have to choose to burn it all and face big investment or to invest work. It's right that the artificial swarm has to \"hunger\" a bit. At the end you get no honey from the bees and have to invest in new frames and sugar. It's no visit in the candy store if you have AFB but burning everything seem to be a last resort solution which isn't nowadays necessary anymore. The other problem you are facing are the beekeepers around you ... they have to do the same and than there are some black sheep which are not known to the veterinary administration. They can also contribute to a never ending AFB problem. At the end hygiene (torching unused hives and frames) is the first thing everybody can do to prevent such situation. reply bregma 17 hours agoparentprevI wouldn't trust it. AFB is, well, foul. It's about the most satanic affliction imaginable. Destroying everything with extreme prejudice within a 2 km radius using fire seems right to me. The bees themselves can carry the spores, including the queen. reply palata 13 hours agorootparent> Destroying everything with extreme prejudice within a 2 km radius using fire seems right to me. Not the OP, but in my country, instead of destroying everything, we lockdown everything within a 2km radius and only kill the colonies that actually have the disease. Sometimes it means the entire apiary, sometimes only a few hives. There doesn't seem to be a need to bomb the whole area :-). reply tempaccount420 2 hours agorootparentThat's very nice of you to treat the bees so kindly, but it doesn't mean it's as effective. reply tonetegeatinst 14 hours agoparentprevHi, american here who loves honey but is absolutely scared of bees and small insects. What does AFB mean? i'v thought about honey making as a hobby once I finish university, but I am unsure if I am allergic to stings....and am not exactly keen to find out. reply palata 13 hours agorootparent> What does AFB mean? It means \"American foulbrood\", it is a disease: https://en.wikipedia.org/wiki/American_foulbrood > but I am unsure if I am allergic to stings One can \"become\" allergic anytime, after many stings. You generally would not know before you make an allergic reaction, which is why beekeepers have to be \"ready\" to make one (as in, know how to react properly). I know beekeepers who keep practicing after they become allergic, some stop. > once I finish university I realised only after I graduated that my university had a beekeeping association... Are you sure yours doesn't? :-) reply floydnoel 14 hours agorootparentprevit's in the article if you read it reply myspy 19 hours agoparentprevMy wife torches the frames and wood boxes too. reply frankzander 18 hours agorootparentYou have a wise wife :) reply cameron_b 19 hours agoprevAs a few comments have pointed out there seems to be a bit of a disconnect between the article and the state of things on the ground. For more on AFB, since the article doesn't describe it or the treatment protocols well - https://beeinformed.org/2013/10/21/american-foulbrood-afb/ Apart from rules particular to NZ, because I do not know them, a key factor is that honey and wax containing AFB spores can transmit AFB to other bees in other colonies. The reason this is important is that beekeepers ( speaking as one ) move equipment between hives to balance their growth and give more space to make honey as needed. This is especially true after the honey harvest, when we empty frames of honey and give the wax honey comb back to the bees for them to get ready for the winter. That makes the timing of this crucial, as it will be less likely for the beekeeper to reduce the damage if the boxes have been removed for harvest, and disassociated from their hive of origin when AFB is discovered. If you can't say where it came from and where it didn't, then it came from everywhere. It isn't a fun hand to be dealt, and certainly it is worthy of more visibility and research, but it isn't worth wishing he didn't have to destroy it. Even the treatments available need to be used before adding equipment that will be used for honey, because the honey will shield the spores from the treatment and preserve the transmissibility of foul brood. reply fnordpiglet 18 hours agoparentThe article as I read it seemed less about being fun or not or regret / wishing etc. It seemed more about the economic toll on their business and the lack of backstop for the beekeeper. I was frankly surprised there was no government discussion of this - it seemed more rationalizing why the regulation exists rather than acknowledging the lack of insurance or assistance. I didn’t hear them wishing they didn’t have to destroy the hives, but fear of what it’s going to do to their business to lose millions in equipment then millions in revenue in the next season. The discussions of “why can’t we do X instead” were rooted in that economic concern. It seems like a pretty legit concern. A reasonable government response could be establishing a government backed insurance for beekeepers against hive loss. reply palata 13 hours agorootparentNot blaming the beekeeper (I don't know), but in that particular case I would really like to know how it happened. I am a beginner beekeeper, and I know many beekeeper who have had AFB in one hive without having to kill the entire apiary. And 10 000 hives means many apiaries (I assume?). Could it be that the beekeeper took too long to react and let all their colonies get infected? That surely takes some time. reply fnordpiglet 9 hours agorootparentI think they hint at the answer in the article. They mix and match stuff between the different hives during operations so it’s assumed to be infected everywhere within a single operation plus they detect it at a time that you can’t attribute it to a single hive. Maybe the cost of testing each individual hive is too great and the cross contamination issues too likely to have hives infected but not yet observable via tests? reply balderdash 17 hours agorootparentprevEspecially given the massive financial assistance given to farmers in most countries, and the importance of bees to farmers reply palata 18 hours agoprevMore than 10 000 beehives? How does AFB reach 10 000 beehives before the beekeeper takes action? That's the part I don't get. It surely takes time for AFB to spread like this. In my country, when AFB is detected, we lockdown (meaning beekeepers cannot move beehives in and out of that radius) and test all the apiaries in a 2km radius. And we destroy the contaminated beehives. But that stays under control. 10 000 beehives sounds like a huge number to me! reply __MatrixMan__ 19 hours agoprevMy heart breaks for the bees and their keepers (which is weird because most tragic news doesn't phase me), but I don't think think this is a good case for insurance. You can profitably insure against a flood because it is not more likely to rain when everybody has flood insurance--the risk is independent. But any measure designed to take the sting out of the risk is going to increase the density of colonies and thereby create more risk than there was in the first place. It has a positive feedback loop. reply cjbgkagh 19 hours agoparentDiffusion of risk does not make it go away, and that diffusion is not what makes insurance profitable. You can insure things like 'hole in one' prize money on an individual basis - it's up to the insurer to set the price and they can and frequently do one-offs. Astute insurers would see the proliferation of hives as an insurance risk and up their rates accordingly which would result in more Beekeepers dropping out of the market. At which time they will likely complain to the government about insurers putting them out of business. I should point out that they could likely have bought insurance for their exact circumstance but they also likely would not have liked the price. In effect they're generally asking for cheap insurance - which is like asking for free money. As best I can tell the failures of the markets in flood insurance are the results of government interventions. reply msrenee 19 hours agoparentprevPeople are more likely to build in flood zones if they can purchase flood insurance. There's a small town here where every house is within a flood zone off the river and they were underwater for about a week a couple years ago. Built right back up and now there's 2 or 3 new housing developments going in. reply LeifCarrotson 19 hours agorootparentThe entire coast of Florida is comprised of vacation homes and condos right in the path of hurricane storm surge on tiny sandy keys a few feet above sea level. Fortunately, the feedback loop is finally disintegrating. Unfortunately for those left holding the bag, it's disintegrating by insurers fleeing the state and leaving properties uninsurable - just deserts for those who knew the risks and thought they could profit off the situation, but terrible for locals forced out of their homes. I too have little sympathy for those who rebuild and increase development in a river floodplain. reply bombcar 18 hours agorootparentprevFlood insurance is needed to get the mortgage - if it's not a legal mandatory requirement, people will buy (and even build) anywhere they can. Flood plains are often desirable in various other ways, too. reply giantg2 19 hours agorootparentprevFlood insurance is generally very expensive. That's should be a massive downside. I won't even look at a house if I know it needs flood insurance. I've seen a few that I would have been interested in had they not required the insurance - meaning I found the flood risk to be acceptable and there were mitigating factors if it did occur. reply ta988 19 hours agorootparentprevSo everybody having an insurance pays for this abuse? reply hedora 19 hours agorootparentThe flood plane thing is pretty extreme (and usually involves some sort of corruption, since zoning is involved), but pretty much everywhere on earth is seeing a correlated increased risk of building damage. The insurance companies are using this as an excuse to increase profitability. Focusing on corner cases is a distraction. Only a tiny percentage of houses are built in flood planes. A much larger percentage are in the sorts of towns that completely burn to the ground these days, or are in places that became flood planes since the housing was built (e.g., a big chunk of silicon valley). Other areas face other new/more common correlated disasters, like tornados, widespread crop failure, high wet-bulb days, grid/industrial collapse due to winter storms, etc. reply lxgr 19 hours agorootparentprevHopefully an insurer would be aware of the flooding history and set premiums accordingly. reply mschuster91 18 hours agorootparentprev> There's a small town here where every house is within a flood zone off the river and they were underwater for about a week a couple years ago. Built right back up and now there's 2 or 3 new housing developments going in. Yeah we got the same shit in Ahrtal, Germany. The government decided to do nothing and so, predictably, three years after the last flood, a few weeks ago the next flood came - way smaller than the 2021 flood, but still decently destructive. IMHO, after devastating flood events governments should declare the affected area uninhabitable, insurances and governments pay out fair market value, and the land is then flattened and condemned for future settlement. There is just no way that with the escalating severity due to climate change this land will ever be safe from flooding again. [1] https://www1.wdr.de/nachrichten/ahrtal-unwetter-auswirkungen... reply otterley 18 hours agoparentprev> You can profitably insure against a flood because it is not more likely to rain when everybody has flood insurance--the risk is independent. Flood insurance is a weird corner case of the market. Insurers would rather not provide flood insurance because of the widespread impact of flooding caused by weather; the claims are enormous. They'd prefer to exclude weather-associated flooding and limit it only to flooding caused by, say, broken plumbing. To the extent you can purchase flood insurance in flood-prone areas, it's because the government has intervened in the market and requires insurers to provide it as a condition of doing business in the state or to get a federally-backed mortgage loan. For the same reason, earthquake damage is explicitly excluded from homeowner's insurance in quake-prone states like California, Washington, and Hawaii. You have to purchase separate, and very expensive, earthquake insurance. When people see the premiums, they usually decide to forego it. Some sources: https://www.bbc.com/future/article/20240311-why-climate-chan... https://www.nar.realtor/flood-insurance/faq-national-flood-i... https://www.insurance.ca.gov/01-consumers/105-type/95-guides... reply tgsovlerkhgsel 17 hours agoparentprevI think this is an excellent case for insurance, because it seems like something that might rely on beekeepers noticing the disease and acting quickly, even though it might be an option and in their (short-term) interest to look the other way. When doing the right thing is ruinous with nothing to soften the blow, not doing the right thing becomes a lot more attractive. reply mminer237 19 hours agoparentprevWouldn't your premium just be based on the density of your hives? Insurance insures your individual risk. If you increase your risk, you pay more for it. reply __MatrixMan__ 14 hours agorootparentThe way these pathogens work is that once the environment is sufficiently dense with their spores there is no stopping them. There are certain continents where you just can't grow bananas for this reason. That's why they're burning the bees with the equipment, to prevent it from spreading. So what's to stop your neighbor from paying the high premiums, getting infected, and then a wayward bee carries the infection to your uninsured hives? As much as it would be nice to protect the bottom line for each farmer, it's far more important to protect the environment's compatibility with bees, and thats not a game that insurance is set up to play. reply sp332 17 hours agorootparentprevYes, and coverage or discounts could be predicated on risk-reducing precautions. reply __MatrixMan__ 14 hours agorootparentDoes that work? Companies get fined for bad behavior all the time and they rarely change that behavior. It would seem that once we enter a one dimensional incentive space dictated by money we just forget about the reason behind those incentives and instead try to hack around our new limitations. reply gavmor 19 hours agoparentprevIn my naive understanding, it seems a direct analog of any insurable crop, eg corn. reply cameron_b 19 hours agorootparentCrop Insurance will have requirements for protocols that must be followed to make a crop insurable. For instance, some fruit or seed crops have pollination requirements of 2 hives per acre which must be carried out or they will not provide coverage for certain types of crop failure. An alternative analog would be not noticing that a cow was acting up, and allowing a whole herd to contract tuberculosis because a farmer didn't contact the vet or isolate parts of his herd from each other or the neighbors. Some things just happen, and they suck. But some things happen when you aren't on top of good management practices, and that sucks but some of it is on the farmer. reply Marsymars 17 hours agoparentprevThis is true, but there's also the opportunity for a negative feedback loop where the insurer mandates and enforces compliance measures in order to reduce risk. reply ISL 19 hours agoparentprevOne could make the same argument against car insurance, and most kinds of insurance. I'm pretty sure that if car insurance were somehow banned, especially medical-liability, fewer people would own and operate motor vehicles. Insurance exists to put an upper bound on risk; the bad thing will hurt or be inconvenient, but with insurance it won't kill you. Perverse incentives appear in the case where the insurance payout is greater than the inconvenience/pain of the insured event. Until that threshold is breached, however, I don't think there's a case against insurance (and insurers that inadvertently pay people to have accidents rapidly go out of business). reply cjbgkagh 19 hours agorootparentInsurance has high upper bounds of coverage, liabilities over this are very unlikely to occur. AFAIK you can't get car liability insurance for infinity dollars. So in theory everyone is accepting some risk even with insurance, they just feel that it's small enough to be worth it. There are plenty of places on earth that have very little car insurance penetrations so we don't have to guess what that would look like. To me it looks pretty much the same. The major difference is that it's difficult to sue for liability and the people you're suing don't have much money so it's often pointless. Society just accepts that accidents happen, people die, and the survivors move on. In these, often highly unequal societies, the people who have money have a lot of it so they in effect self insure. reply ISL 19 hours agorootparentBy 'upper bound' here, I meant for the insured. Above the deductible (and premium payments), the insured's exposure is largely lost time and headaches, the remaining financial burden is borne by the insurer. If anything, the presence of insurance might increase the amount of compensation an aggrieved party might be able to reap. Agreed that there are plenty of places in the world where car-insurance is non-existent. In those places, accident victims may not receive proper compensation for their injuries/destroyed property or the recompense may not be monetary in nature. reply cjbgkagh 18 hours agorootparentI re-used the 'upper bound' for the insurance - there is no upper bound in liability for the insured. Tort law does not specify a limit in liability - though it can be a bit complicated as there can be other laws around this. A 'fully insured' person is taken to mean sufficiently insured to meet a law, or sufficiently insured to meet a reasonable level of liability. While highly unlikely it's possible that someone with $1,000,000 in insurance can incur $10,000,000 in liability. To your final point, life is unfair yet it continues. I understand that you wish the world would always provide proper compensation for victims, my position is that even if that was theoretically possible, which I don't think it is, it may not even be optimal. reply marcinzm 17 hours agoprev> Long said fewer than eight percent of the country's 8000 beekeepers were currently affected - and there were 2900 reports of AFB made in the past year to May, down 15 percent on the 3449 reports the year before. I wonder if that's just due to people not self-reporting due to the cost of doing so. > \"Beekeepers have to notify and then destroy hives within seven days after finding the disease - and most beekeepers, including Steve, usually comply with that regulation. And yup. \"Most.\" \"Usually.\" reply itsanaccount 20 hours agoprevCurious of the lack of access? to alternatives here. If a hive has AFB the practice I'm aware of is to burn it after dark after all the bees have returned, so they don't scatter to other hives. Its euthanasia for an insect colony. Your equipment goes with it. But that was obvious signs (the smell) of AFB. Is this a complaint because its only a spore test and then they burn an entire cluster? reply giantg2 19 hours agoparentI was wondering too. But the quality of information seems to be lacking in the article. reply theophrastus 18 hours agoprevCirca 1980, as a hobbyist beekeeper with six hives nearby Seattle, they came down with foul-brood. (It never was certain if it was American Foul-brood or European) Duly reported and the county agent came in, sealed them, and carted them away. For an additional fee (which I paid) they would fumigate them and return just the hive bodies, but none of the frames, (some of which would contain the infected brood). Those were burned. I believe the fumigant at the time was phosphine[1] [1] https://en.wikipedia.org/wiki/Phosphine reply deadeye 18 hours agoprev\"Niha Long said it aimed to support beekeepers impacted by the disease\" With what? A shoulder to cry on? Nothing in her statement after that included anything about financial support, which is the only type of support that matters in this type of situation. reply croes 17 hours agoparentShe can't simply promise financial support reply cute_boi 17 hours agorootparentWhat can she do? reply deepsun 18 hours agoprevWell, the farm had a lot of beehives concentrated, and that likely helped the disease to spread. More smaller farms would be less susceptible. > \"By next year, when we don't have boxes for our honey crop, we're probably going to be losing over $5-6 million,\" I'd say that's a good problem to have. reply teeray 20 hours agoprevI wonder if there’s a phage that could be introduced to a colony that would hunt down AFB. reply rdtsc 20 hours agoprev> \"The only way to destroy the spores is through burning, so we cannot use antibiotics unlike other countries in the world due to market access “Market access” in NZ presumably means the local government’s law to use burning, not unwillingness of a pharmaceutical company to sell the antibiotic? reply fabian2k 20 hours agoparentIt sounds a bit like using antibiotics would mean they can't sell the honey anymore, which sounds somewhat plausible. It could be that this would violate the terms of trade agreements. Maybe the countries using the antibiotics don't export into markets that have rules against them. reply giantg2 19 hours agorootparentYes, some antibiotics have been used in markets like China and been found in honey. The antibiotic used is banned in the US due to some sort of negative human impacts. I hear there are other antibiotics approved, but I think it's a patchwork of regulation right now. Also, I question the effectiveness of antibiotics to treat AFB. If the spores remain viable, reinfection in subsequent years or spread still seems possible. reply rdtsc 18 hours agorootparentprevAh, thanks for explaining. That makes sense. reply throwaway63467 20 hours agoparentprevI think it means that e.g. in the EU antibiotics use would make them lose their certification as organic producer, which probably makes a large difference financially. reply throwup238 19 hours agorootparentThat was my first thought too except it’s not organic certification. Anything going to the EU would have to be on the food additive whitelist and be generally recognized as safe in the US, since the antibiotics almost certainly end up in the honey. The penalties for violating that can be pretty severe too. I.e. if one regulator tests and finds the antibiotics, they might temporarily ban imports of NZ honey altogether until the outbreak has passed or the antibiotic is approved. reply jonhohle 19 hours agoparentprevThat’s how I take it. Antibiotics for AFB were approved in the US in 2016 (based on Google-fu), so it may be NZ hasn’t caught up or has other reasons to keep pharmaceuticals out of beekeeping. reply giantg2 19 hours agoprev\"Burning the hives was more painful when other countries used tools like vaccines, antibiotics and sterilisation - measures prohibited in New Zealand and in some export markets. \"Most farmers vaccinate their cows for diseases every single year, but it's illegal to vaccinate the hive,\" Brown said.\" My understanding is the vaccine was only just approved last year in the US, it's the first of its kind, and it might not even be commercially available on a widespread basis yet. It's it really illegal to vaccinate the hive in New Zealand? It seems odd that a vaccine would be illegal if it was just invented last year. Even in areas where the vaccine is legal, it's not going to save an already infected hive. I'm not familiar with the sterilization techniques the beek alludes to. I assume some jurisdictions allow irradiation for remediation. It seems most jurisdictions require killing the bees, then burning the frames, and charring the inside if the hive body. It seems other remediation methods are less common. reply NoNotTheDuo 19 hours agoparentIt's probably a case where it's illegal to vaccinate the hive, because it's not explicitly legal to vaccinate the hive. For example, in the US, it's legal to use brand name \"API-Bioxal\", which is Oxalic Acid, to treat for varroa mites. However, one can head to their local hardware store and buy generic \"Wood Bleach\", which is also Oxalic Acid. It is not legal to use the wood bleach to treat your hive, even though it's the same chemical compound. reply mschuster91 17 hours agorootparent> However, one can head to their local hardware store and buy generic \"Wood Bleach\", which is also Oxalic Acid. It is not legal to use the wood bleach to treat your hive, even though it's the same chemical compound. It's not, or to be more precise: there is no certification testing done to make sure the \"wood bleach\" is just oxalic acid and that's it. The stuff you can buy at a veterinarian, however, is certified to be 6% oxalic acid, 47% water and 47% sugar, and nothing else. reply xkcd-sucks 16 hours agorootparentprevTL;DR is (1) none of these methods effectively control transmission of AFB, and (2) AFB is taken extremely seriously. Like, where I live there is a state law allowing ag inspectors to burn hives at their discretion overriding any fire codes in effect The vaccine thing seems to be extremely new and probably isn't validated enough re: transmission reply giantg2 18 hours agorootparentprevYeah, I guess I read it more strictly. It sounds like it would be unlawful but not really illegal. I think it's lack of availability is just the fact that it was first approved anywhere just last year. reply criddell 20 hours agoprev> \"The only way to destroy the spores is through burning, so we cannot use antibiotics unlike other countries in the world due to market access,\" Long said. Market access? What does that mean? reply postingawayonhn 20 hours agoparentMost of NZ's agricultural produce is exported. There are probably some export markets that don't approve of the use of these antibiotics (if I was guessing probably the EU). reply mikeyouse 20 hours agoparentprevEither nobody will sell it to them (unlikely) or more likely for New Zealand who takes their biosecurity extremely seriously, there's an approval process for agricultural antibiotics to be sold and nobody has completed that process. reply throwaway63467 20 hours agorootparentThey sell it as organic which precludes use of antibiotics in most developed markets. reply Perz1val 20 hours agorootparentDoes it? Such vaccines are applied after/before season, bees will eat every bit of honey that may've been affected themselves. Then you put in clean frames for new, fresh honey. I don't know if it can be sold as organic, but it is always separated and the honey never touches any vaccines. reply tialaramex 19 hours agorootparentI notice that some people here say \"vaccine\" and some say \"antibiotic\" those are very different, as different as like bicycle versus jet liner. Is it a vaccine or an antibiotic? There are often EU rules against antibiotics in foods because those antibiotics end up inside the humans eating the food which is unnecessary risk (if the humans need antibiotics we'll prescribe them thanks), and sometimes because this is a sign that you're probably not treating whatever it is that's full of antibiotics very well, that's why it needed antibiotics - so stop doing that. reply bregma 17 hours agorootparentPaenibacillus larvae is a rod-shaped bacterium, so the treatment is an antibiotic. Most people don't understand the difference between vaccines and antibiotics it's all just doctor stuff. reply Perz1val 20 hours agoparentprevI guess New Zealand has an isolationist policy and they don't want to introduce new chemicals into the environment. Burning probably isn't that huge issue for for small, side hustle beekeepers that have just a few boxes in few different spots. 3000 is an insane amount. reply fabian2k 20 hours agoprevSo the vaccine seems to have been approved in the US in 2023, so it's still very new. I assume antibiotics don't do anything against spores, so that is probably not a solution on its own. And I'd be curious what kind of sterilization procedure works for bacterial spores that would be feasible here? reply bobmcnamara 19 hours agoparent> I'd be curious what kind of sterilization procedure works for bacterial spores that would be feasible here? Enough fire, presumably reply fabian2k 19 hours agorootparent> Burning the hives was more painful when other countries used tools like vaccines, antibiotics and sterilisation - measures prohibited in New Zealand and in some export markets. This part of the article seems to imply that there are sterilization methods that aren't burning down the entire thing. Which I find a bit doubtful as spores are usually very hard to kill. reply bobmcnamara 9 hours agorootparentYes, less fire, but still enough fire. You don't have to burn everything, but do need burn any spores on the surfaces. reply downvotetruth 19 hours agoparentprevThe whole story seems a tad off given https://news.ycombinator.com/item?id=40389997 and that no one could be bothered to find someone to work for ~$5 million to put them through an autoclave. reply giantg2 19 hours agoparentprevIrradiation is the other whole hive method I know of. I think it's not as widely approved though. reply philbin 17 hours agoprevCouldn't they use irradiation to kill the spores in beehives? AFAIK irradiation kills everything when used to treat food for long-term storage, for example. reply bregma 17 hours agoparentYou would need to irradiate the bees. The bees are the expensive part. Burning everything with regular chemical fire is cheaper. reply jokoon 18 hours agoprevI wonder if the einstein really said that quote about bees, and if biologists would agree with it reply Workaccount2 20 hours agoprevI can understand no antibiotics or vaccines. New Zealand is notoriously heavy handed. But I can't understand no insurance. Part of me feels like they forwent even trying to get insurance, despite the obvious risk of potentially having to burn your hives. Or got quoted and decided against it. Just a moment of googling found an insurer immediately... https://aon.co.nz/agri-business/bee-insurance So now I feel a bit less \"The state is screwing me over\" and a bit more \"I didn't get insurance, got burned, and now want to socialize the loss with a heart-strings story.\" reply eythian 19 hours agoparentIt doesn't look to me, at a quick skim, that this insurance would cover disease, or the loss of income in the future. reply Workaccount2 19 hours agorootparentI can't imagine disease wouldn't fall under \"Loss of stock\". But even if it didn't, you can usually pay for whatever you need. And if the disease is so rampant that insurers won't cover it, that's a good sign you shouldn't be in the business. Like building a house where insurers refuse to offer flood coverage. reply ISL 19 hours agoparentprevThe coverage terms, and any exceptions, matter -- at a quick glance, I don't see coverage there for \"disease enters a hive and the government forces you to burn all your hives\". reply lostemptations5 20 hours agoprevWhat does market access mean? reply eythian 19 hours agoparentIn this context, usually it means that you would lose access to a market that you sell to. So, some market for NZ honey won't accept the honey if the bees have been treated. That may be geographical, or it may be something like an organic certification. reply wonderwonder 19 hours agoprevI, at one point like most people in tech thought being a farmer sounded good. In reality its very very hard and stories like these make me realize how lucky I am to get a good salary for essentially sitting in my office writing words in an IDE before calling it a day at 5pm. reply jethro_tell 18 hours agoparentFarming can be hard, but every business can get insurance that covers the risks associated with that particular business. And the risks in farming and raising livestock include total loss of crop or livestock from weather and or disease. In this case, it's not the farming that's the issue, it's the lack of setting up your business to handle the known risks of that business. While it may be unnecessary, which I'm not entirely sure about, if it's how things have been done for 200+ years, you ought to be able to look around that corner and see that you need a plan B for that day. Crop and livestock insurance is a well trodden path in farming, and you either need to have the cash on hand to replace your entire operation or you need to insure for the possibility that your crops don't turn out or your livestock is seriously diseased. This applies to all businesses really. reply fullspectrumdev 17 hours agoparentprevI grew up in farming country, and spent most of my childhood on farms, or otherwise around them. No illusions about it not being incredibly slim margins and fucking backbreaking work with long hours - many farms here are propped up with government subsidies and grants - but it’s still tempting sometimes. I know a few guys in software who are also working farmers and such, and it seems that the regulations are often poorly considered - adding an additional burden. reply m3kw9 19 hours agoprevMust be high probability of AFB if insurance isn’t covering it reply yareal 19 hours agoprevAs far as I'm aware, burning hives is standard practice. The real stinger here is lack of insurance or support from the government. reply jandrese 19 hours agoparentIt is baffling to me that insurance isn't available for this. This is exactly the kind of situation that insurance exists for. There should be someone willing to underwrite it. reply ceejayoz 19 hours agorootparentInsurance appears available, at least on paper; someone elsewhere in the thread linked https://aon.co.nz/agri-business/bee-insurance reply yareal 19 hours agorootparentIt's unclear if this would cover afb. reply Dig1t 19 hours agoparentprevBeing forced by the government to burn all your equipment and all your bees, needlessly, is not standard practice. reply jethro_tell 18 hours agorootparentOn one hand, probably yes, on the other hand, if that's the way it's been done for 200+ years as this guy says, then it's not sound to be running a business without a plan for that until things are changed. reply giantg2 19 hours agorootparentprevIs it needlessly? I didn't see anything in the article that said it was needless. The remediation practices seem to be roughly in line with other countries. reply Dig1t 18 hours agorootparentThe article talks about an alternative: vaccination. Also people in other countries, like the another poster in here talking about how they do heat treatment in Germany and don’t need to burn hives. reply giantg2 18 hours agorootparentVaccination isn't an alternative to an already infected hive. The vaccine was the first in the world and was only approved for the first time last year. That's not a feasible alternative at this time. The heat treatment they talk about is performed in the US too. You generally still need to burn your frames. You are allowed to char the inside of your hive body. It's not a meaningful difference as the frames are the more valuable part. It wouldn't surprise me if New Zealand allows charring the inside of the hive bodies and the farm decided against it due to labor concerns with the volume of equipment. reply yareal 16 hours agorootparentprevAFB vaccination is less than two years old and is not available worldwide. The majority of beekeepers expect to burn or absolutely sterilize any equipment that contacts it. The EU requires equipment to be destroyed if it contacts AFB. The standard practice is fire, full stop. reply goodluckchuck 20 hours agoprevThis sounds like when - to protect the American Chestnut from blight - we destroyed nearly all the American Chestnuts and their genetic diversity (including diversity that may have provided resistance). reply giantg2 19 hours agoparentI generally agree with this sentiment - I'm a treatment-free (disclaimer to prevent hate responses: I use IPM practices, I'm not a complete idiot) beekeeper. Burning the AFB hives and even other proximal ones makes sense. In theory the resistant hives wouldn't develop AFB and wouldn't be burned in the first place. The number of hives required to be burnt in any year is extremely low, so that'd not a factor in the diversity. Large operations are inherently a threat to diversity. Stuff like package mills supplying most of the country. The large producers could reduce their risks of needing to burn all their equipment by managing multiple smaller apiaries separate from each other. This would limit disease speed and potentially increase diversity (or at least preserve it better). reply itsanaccount 19 hours agoparentprevI'm watching the hundreds black ash trees struggle against the emerald ash borer. They don't live more than 10? years at max though I wonder if that's true for the new ones. But under the pressure of the borer they seed immensely. For every one tree that dies 20 spawn around it. I'm letting the field of them do their thing, hoping at minimum they maintain themselves in their stunted form as a population until we can introduce a resistant tree. reply frereubu 20 hours agoprevFor those asking, from TFA: \"Burning the hives was more painful when other countries used tools like vaccines, antibiotics and sterilisation - measures prohibited in New Zealand and in some export markets.\" reply itsanaccount 20 hours agoparentPeople are asking because other countries also burn hives. reply sinuhe69 19 hours agoprevI understand the no antibiotics part, but no vaccine? I didn't know the Kiwis are antivaxxer ;) Or does vaccine for bees mean something else, more sinister? reply giantg2 19 hours agoparentThe first ever AFB vaccine was just created recently. It got US approval only last year (first market to approve it I believe). So yeah, a vaccine exists, but it's not widespread as it's extremely new. reply sinuhe69 17 hours agoparentprevThey threw them all in one sentence and that made me think vaccination of bees is forbidden in NZ! \"Burning the hives was more painful when other countries used tools like vaccines, antibiotics and sterilisation - measures prohibited in New Zealand and in some export markets.\" reply rysertio 19 hours agoparentprevvaccine availability can be affected by things like, no one sells the vaccine here, or an application for a vaccines approval being stuck in a pile of papers. reply dukeofdoom 20 hours agoprev$2 million is still cheaper than requiring all the bee keepers to vaccinate. Burning seems like a better solution. Perhaps a national insurance fund to help with unlucky individuals. Also the country marketing themselves as having organic honey is worh a lot more. I've paid like $50 for a small jar of nz honey in Dubai airpot, because of reputation... Champaign from Chapagnia reply itsanaccount 19 hours agoparentLotta the honey bees we're using these days have genetics from Ukraine/Russia as they were found to be excessively mite resistant. The breeding program for mine (Saskatraz) is in Saskatchewan, partially selecting for cold resistant behavior. Meanwhile your honey quality has a lot to do with the local ecology and the weather. Its interesting NZ is able to have a reputation like that, but I think honey is the exact opposite of specific regionalism like \"Champaign from Chapagnia\". Quite sure you can drive through all 50 states and find a local beekeepers with good, interesting and organic honey. reply dukeofdoom 17 hours agorootparentI live in Canada, and lost my first hive over this winter. I'm hoping to try again. Honey was delicious...just not enough to share with everyone. Reputations are worth a lot. Canada attracts millions of students to come here to build its future, on reputation alone. Tough some say it's on the decline. Maple syrup, Ice wine, polar bears and polar dips play on people's imagination across the world. reply workingdog 19 hours agoparentprevIf anybody is on the fence, in my opinion, Manuka honey from NZ is worth the expense at least once to try. It has a unique spiciness to it. Costco sometimes sells it, and they're good about making sure their products aren't fakes. reply dukeofdoom 17 hours agorootparentCostco also sells real vanilla beans. That's a must try for anyone who hasn't. reply lloydatkinson 19 hours agoprevWhat is happening since AFB vaccine was allowed, has there been any push to actually start using it? https://www.labiotech.eu/in-depth/vaccine-honeybees-american... reply jgeada 20 hours agoprevSigh ... yet again capitalism when there is profit, socialism when there are losses. I dislike the blatant hypocrisy and how rarely it gets called out. reply sshine 20 hours agoprevnext [6 more] [flagged] moralestapia 20 hours agoparentGood ol' GPT, you can be spotted miles away. reply LeifCarrotson 20 hours agorootparentFor now. I don't think it's a law of nature that GPT-generated text must be this discordant and obvious. This is simply the current state of the art, soon to be eclipsed by improved models that are more difficult or impossible to discern, because we have the combination of mathematics, underlying technology, and economic incentive to improve the models. reply palata 18 hours agorootparent> because we have the combination of mathematics, underlying technology, and economic incentive to improve the models Still we'll have to see how much the new models improve. Tesla also has all those incentives to get to actual full self-driving... yet they seem to have reached a plateau years ago. reply LeifCarrotson 18 hours agorootparentI think that in both cases it's a question of when the economics run out: There's a Pareto principle plateau where further investment stops making sense when the project is 80% of the way to functional with 80% of the work remaining. (That's the general Pareto 80/20 rule, I suspect the actual numbers for FSD are far worse.) If Tesla can sell a \"Full Self Driving\" package with 20% of the work of the real thing, some cameras, and some empty promises for $8k at 0.99%, I think their actual incentives to go from Level 3 to Level 5 are pretty weak. In contrast, GPTs currently have a small window of utility in marketing, search, and other text generation processes where accuracy isn't that important and weird tics are tolerable. The general public isn't yet accustomed to their hallucinations and foibles, so people are willing to pay to use them in contexts where the current state of the art is inadequate, but there will be recoil from those uses. And there's a huge gold rush underway as Google/Microsoft/Meta/others all try to dominate the future regardless of present economics. reply sshine 11 hours agorootparentprevHaha, I didn’t use GPT. I just made a bad joke. reply OJFord 19 hours agoprev [–] If market access is the reason they can't control with other methods, why isn't that just up to the farmer? I.e. it might affect the price he gets or ability to sell, but that's his call, he might think it works out the better option? reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Beekeeper Steven Brown from Springbank Honey in North Canterbury was devastated after being instructed to burn over 10,000 beehives and equipment due to American Foulbrood disease.",
      "Brown suggested reconsidering the pest management strategy to include alternatives like vaccination, estimating a loss of $2 million.",
      "The management agency defended the decision to burn, citing it as the most effective method, as beekeepers in New Zealand must adhere to regulations and destroy infected hives within seven days."
    ],
    "commentSummary": [
      "Beekeepers are grappling with the American Foulbrood disease, causing hive destruction and financial setbacks.",
      "Challenges include treatment methods, insufficient government backing, insurance disputes, and implications for honey market access.",
      "Debates encompass alternative treatments like vaccines, irradiation, antibiotic use, and insurance availability in New Zealand, underscoring the significance of hygiene, disease prevention, and insurance for risk management in beekeeping."
    ],
    "points": 158,
    "commentCount": 120,
    "retryCount": 0,
    "time": 1715951880
  },
  {
    "id": 40389421,
    "title": "Improving Fine-Tuning Efficiency with LoRA Method",
    "originLink": "https://arxiv.org/abs/2405.09673",
    "originBody": "Computer Science > Machine Learning arXiv:2405.09673 (cs) [Submitted on 15 May 2024] Title:LoRA Learns Less and Forgets Less Authors:Dan Biderman, Jose Gonzalez Ortiz, Jacob Portes, Mansheej Paul, Philip Greengard, Connor Jennings, Daniel King, Sam Havens, Vitaliy Chiley, Jonathan Frankle, Cody Blakeney, John P. Cunningham View PDF HTML (experimental) Abstract:Low-Rank Adaptation (LoRA) is a widely-used parameter-efficient finetuning method for large language models. LoRA saves memory by training only low rank perturbations to selected weight matrices. In this work, we compare the performance of LoRA and full finetuning on two target domains, programming and mathematics. We consider both the instruction finetuning ($\\approx$100K prompt-response pairs) and continued pretraining ($\\approx$10B unstructured tokens) data regimes. Our results show that, in most settings, LoRA substantially underperforms full finetuning. Nevertheless, LoRA exhibits a desirable form of regularization: it better maintains the base model's performance on tasks outside the target domain. We show that LoRA provides stronger regularization compared to common techniques such as weight decay and dropout; it also helps maintain more diverse generations. We show that full finetuning learns perturbations with a rank that is 10-100X greater than typical LoRA configurations, possibly explaining some of the reported gaps. We conclude by proposing best practices for finetuning with LoRA. Subjects: Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL) Cite as: arXiv:2405.09673 [cs.LG](or arXiv:2405.09673v1 [cs.LG] for this version) Submission history From: Dan Biderman [view email] [v1] Wed, 15 May 2024 19:27:45 UTC (6,178 KB) Full-text links: Access Paper: View PDF HTML (experimental) TeX Source Other Formats view license Current browse context: cs.LGnewrecent2405 Change to browse by: cs cs.AI cs.CL References & Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer (What is the Explorer?) Litmaps Toggle Litmaps (What is Litmaps?) scite.ai Toggle scite Smart Citations (What are Smart Citations?) Code, Data, Media Code, Data and Media Associated with this Article Links to Code Toggle CatalyzeX Code Finder for Papers (What is CatalyzeX?) DagsHub Toggle DagsHub (What is DagsHub?) GotitPub Toggle Gotit.pub (What is GotitPub?) Links to Code Toggle Papers with Code (What is Papers with Code?) ScienceCast Toggle ScienceCast (What is ScienceCast?) Demos Demos Replicate Toggle Replicate (What is Replicate?) Spaces Toggle Hugging Face Spaces (What is Spaces?) Spaces Toggle TXYZ.AI (What is TXYZ.AI?) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower (What are Influence Flowers?) Connected Papers Toggle Connected Papers (What is Connected Papers?) Core recommender toggle CORE Recommender (What is CORE?) IArxiv recommender toggle IArxiv Recommender (What is IArxiv?) About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs. Which authors of this paper are endorsers?Disable MathJax (What is MathJax?)",
    "commentLink": "https://news.ycombinator.com/item?id=40389421",
    "commentBody": "LoRA Learns Less and Forgets Less (arxiv.org)151 points by wolecki 21 hours agohidepastfavorite52 comments thepasswordis 18 hours agoI really wish people would be more careful about choosing names for these things. LoRa has been a popular wireless protocol for like 10 years. reply sva_ 18 hours agoparentYes, but this is LoRA, clearly not LoRa. reply squarefoot 18 hours agorootparentPP has a point though. I entered \"LoRA\" on Google, DuckDuckGo, Startpage and Bing, and all returned results in all first pages were about the communication protocol (1). They could have inferred my interests from previous searches, but I never used Bing in the last year or so, so it seems to me someone didn't care about name clashes. (1) well, except Google which -surprise- returned about mid page an ad of a local quite expensive chandeliers brand called \"LORA\". reply sva_ 13 hours agorootparentI usually just add a term like 'ml' or 'nn' after my search to give the machine context and it is sufficient in most cases. reply refulgentis 5 hours agorootparentprevWait until you find out its a name too reply atherton33 15 hours agorootparentprevI think you mean LoRa®, a registered trademark of Semtech® Corporation, for use only with permission and within specific guidelines. https://www.semtech.com/uploads/company/FAQ-for-Use-of-LoRa-... reply mbirth 7 hours agorootparentNot to be confused with Semtex who sell a completely different kind of problem solver. reply noisy_boy 5 hours agorootparentIsn't Semtex an explosive aka RDX? reply yau8edq12i 4 hours agorootparentYes, you got the joke. reply marcinzm 2 hours agoparentprevAnd LORA stood for Level of Repair Analysis since the 70s. reply mobilemidget 15 hours agoparentprevI addressed the same in a previous 'lora' post on HN. For me the name is already reserved for the radio telecommunication meaning. Nothing going to change that. reply dheera 14 hours agoparentprevNot sure about \"popular\" 99% of ML engineers wouldn't know what it is. reply enlyth 14 hours agorootparentI'm not an ML engineer and the only reason I know that the wireless protocol exists is because in every HN article, there's a comment repeating the same complaint reply bmitc 4 hours agorootparentprevNot much of a surprise there. The ML culture is to reinvent names for everything. reply Findecanor 14 hours agorootparentprev99% of the engineers who are still working in ML (Machine Language) would. A much smaller percent among those who write in ML (the functional programming language) probably, though. reply nerdponx 13 hours agorootparentEven if the ML engineers know about the wireless protocol (and I doubt that many do), the scientists/researchers who develop these models probably don't. They are completely different domain. The lead author on this paper is basically a neuroscientist; some of the other are technically computer scientists, but probably have little hands-on experience with networking beyond whatever they did in undergrad. reply goodpoint 12 hours agorootparentprev...but they should know how to use search engines... reply bryanrasmussen 4 hours agorootparentat some point we are going to run out of easily pronounceable abbreviations that are unique. Perhaps that point is actually in the past and we should just acknowledge it and move on. Although I guess it could have been Lorall - oops, that's a character in World of Warcraft. reply dheera 2 hours agorootparentOld concepts become obsolete anyway. People can start reusing VCR, etc. reply marcinzm 2 hours agorootparentprevAs should have the IoT people to not conflict with the decades old LORA name used for Level of Repair Analysis. reply renewiltord 15 hours agoparentprevSeriously, that was a terrible name for the wireless system since it's been used by the Loyola Online Records Access system for half a decade or more before the radio company shamelessly copied the name. reply chaos_emergent 19 hours agoprevThe findings are that the best fine-tune performance comes from fine-tuning all weights, followed my MLPs, followed by attention heads, using LoRA. Authors assert that the performance difference is based on the target module of the NN. Isn’t an equally valid argument that MLPs tend to constitute a greater number of weights in transformer networks than attention heads, and the performance difference can be traced to a greater number of weights having freedom to change? I’d be curious to know if randomly choosing a subset of matrices to train, regardless of where they are in the network, would provide analogous performance to LoRA on a specific module with comparable learnable weights. reply danielhanchen 16 hours agoparentI think the QLoRA paper https://arxiv.org/pdf/2305.14314 paper also showed LoRA on all MLP + Attention layers > all MLP layers > just Attention layers. Other papers show finetuning a select few layers can also work well. reply 3abiton 10 hours agorootparentAny real world performance comparison between QLoRa and LoRa? reply danielhanchen 2 hours agorootparentThe QLoRA paper itself provided some cool benchmarks across many many experiments - QLoRA is near equivalent to LoRA, with it sometimes exceeding or losing 1-2% accuracy (it depends on the use case) reply chaos_emergent 19 hours agoparentprevas a follow up curiosity, has anyone tried using LoRA on the entire model for pretraining to compare regular training model performance to LoRA? reply buildbot 17 hours agorootparentYes, I’ve tested this out. It does train, but the scaling doesn’t seem to pan out. It’ll perform slightly better than the number of trainable parameters, but never improves as you scale, so for now there’s no benefit. reply cabidaher 19 hours agorootparentprevThis paper [1] does atempt that and reports similar performance compared to conventional pre-training. However, they do start off by doing a normal full-rank training and claim that it is needed to 'warm start' the training process. [1] https://arxiv.org/abs/2307.05695 reply danielhanchen 16 hours agorootparentOh yes this paper! The main issue is the scaling of the A and B LoRA matrices. Some papers show scaling the B matrix with larger learning rates (LoRA+) could be beneficial. DoRA for eg learns an auto scaling vector of numbers which tries to alleviate these issues. Galore might be more equivalent to full pretraining with the gradients being low rank. reply sp332 17 hours agorootparentprevDo you mean leaving most of the model in its initial, randomised state and only training a LoRA? reply buildbot 17 hours agorootparentI’ve tested specifically this (on my personal time) :) It will train but I found the loss is proportional to the number of trainable parameters. So roughly to hit the performance of a standard 70m param model, you need to train ~70m lora params anyway. reply cheald 16 hours agorootparentIt's worse than that, because lora requires two matrices per layer. At full rank, you have an additional NxN parameters to learn versus full finetuning, where N is min(input_features, output_features). For example, tuning a layer of 128 in x 256 out is 32k params. Learning a full-rank lora for that layer would be two matrices of 128x128 and 128x256 = 48k params. reply buildbot 14 hours agorootparentYeah, exactly. Though the 48k param lora might be as good as a 48k param layer of higher rank, I haven't looked into that case really. reply whimsicalism 15 hours agorootparentprevi would be shocked if this worked well reply iudexgundyr 13 hours agoprevI feel like this is a trivial conclusion. Keeping the rank low in the optimization is a common regularization technique. reply rzzzt 13 hours agoprevThis paper has 12 authors, which fascinates me to no end for some unexplainable reason. How does it work? Is it a common occurrence to have this many people working on a submission? Did each of them get at least a paragraph in edgewise? reply PeterisP 10 hours agoparentThe general criteria for authorship require including the people who worked on the experiments and data for the paper, which can be more important contribution than most of the text in that paper. In other experimental fields, there are papers with dozens or even hundreds of authors, because it can take many people to get to a measurement of a single number in the paper. reply rzzzt 56 minutes agorootparentThanks, this is the bit I've been missing. reply repsak 13 hours agoparentprevI raise you the Gemini paper https://arxiv.org/abs/2312.11805 reply guyomes 12 hours agorootparentAll-in with the Foldit paper [1,2]. [1]: https://en.wikipedia.org/wiki/Foldit [2]: https://www.nature.com/articles/nature09304 reply SubiculumCode 11 hours agoparentprevFor a serious answer, this is how it works in my field A researcher gets a grant with 3-7 co-investigators. This generates a bunch of data and other resources that will support 10 or more papers. Coinvestigators and PIs will ask their postdocs and grad students to write up a paper. PIs and co-Is go on every paper...because it's a paper from their grant. Then the 1 to 4 grad students and post-docs go on the paper, depending on their specific material contributions to the work, be it analysis, conception, or execution, or writing. The numbers can stack up. reply yau8edq12i 4 hours agoparentprevWait until you learn that the paper on the LHC has more than 5000 authors: https://www.nature.com/articles/nature.2015.17567 reply chriskanan 16 hours agoprevThis study is great and addresses a question I've had about LoRA for a while. In a continual learning paper from last year, I found LoRA was extremely effective for faster fine-tuning and not forgetting the original dataset: https://arxiv.org/abs/2306.01904 reply Saris 8 hours agoprevWhat does LoRa have to do with LLMs? Whoever named this thing screwed up big time. reply hybridtupel 19 hours agoprevThis is about Low-rank adaptation. Not to be confused with LoRa the long range proprietary radio communication technique, which hopefully doesn't learn at all. reply martinky24 19 hours agoparent\"Why the hell is LoRa learning\" was indeed my first thought... reply HeatrayEnjoyer 3 hours agorootparentThis is how the subs were knocked offline in Terminator III reply gregmac 19 hours agoprevThis is \"Low-Rank Adaptation\", \"a widely-used parameter-efficient finetuning method for large language models.\" Not to be confused with LoRa (\"long range\") [1], an Internet of Things radio technology. [1] https://en.wikipedia.org/wiki/LoRa reply chaos_emergent 19 hours agoparentIsn’t this fairly obvious after a two second glance at the abstract reply SubiculumCode 19 hours agoprevThis is Low-rank adaptation. Not to be confused with Lake of the Ozarks Recreation Area. reply 0cf8612b2e1e 16 hours agoparentApparently constructed in 1929. You think those wireless people would have been more careful when they reappropriated the name. reply ssl-3 17 hours agoprev [–] What can we learn about Low Rank Acronyms today? reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The paper introduces the Low-Rank Adaptation (LoRA) method for efficiently fine-tuning large language models in programming and math, showcasing improved regularization and model diversity, despite performing slightly below full fine-tuning in most cases.",
      "It offers insights into best practices for utilizing LoRA in fine-tuning and delves into the variances in perturbation rank when comparing LoRA to full fine-tuning methods.",
      "The study falls under the categories of Machine Learning, Artificial Intelligence, and Computation and Language."
    ],
    "commentSummary": [
      "The debate focuses on the naming confusion of a research paper \"LoRA Learns Less and Forgets Less,\" addressing low-rank adaptation for large language models, distinct from the LoRa wireless protocol.",
      "Users engage in conversations about search engine mix-ups, trademark concerns, and authorship complexities related to academic papers.",
      "Discussions cover the technical aspects and impacts of low-rank adaptation in machine learning models, highlighting the advantages and obstacles of this strategy."
    ],
    "points": 151,
    "commentCount": 52,
    "retryCount": 0,
    "time": 1715950855
  },
  {
    "id": 40391614,
    "title": "Reconsidering Dual Axis Charts for Connected Scatterplots",
    "originLink": "https://blog.datawrapper.de/dualaxis/",
    "originBody": "Are connected scatterplots so bad? January 31st, 2024 8 min",
    "commentLink": "https://news.ycombinator.com/item?id=40391614",
    "commentBody": "The case against dual axis charts (and what to use instead) (2018) (datawrapper.de)129 points by Leftium 17 hours agohidepastfavorite55 comments joshe 14 hours agoContext is important, this is targeted at journalists. They are usually trying to make a point to casual readers. For readers with more interest or who are numerate in their day jobs (engineers, finance, or economists), dual axis charts can often be a great choice. This is better graph style advice from the Economist, which includes good dual axis examples and one bad one and how to correct it. https://medium.economist.com/mistakes-weve-drawn-a-few-8cdd8... Since we are engineers or founders trying to deal with very complex systems, adding detail and clarity like the Economist or Edward Tufte does is the better way to go. reply lisacmuth 13 hours agoparentAuthor here. Thanks for setting the context: Datawrapper – the data vis tool I write articles like this for – is indeed for people who want to make a point with their charts and maps, often to a broad audience. I agree that people who have learned to read dual axis charts can benefit greatly from them (the same is true for rainbow color maps). Financial Times journalist John Burn Murdoch changed my mind on dual axes charts – even for casual readers! – a bit over the last six years, too. Here's a dual axis chart he created for the FT: https://x.com/AlexSelbyB/status/1529039107732774913 The next article I write on dual axis charts will probably be a \"What to consider when you do use them\" one. reply sokoloff 9 hours agorootparentWow. That's a quite telling chart (and it's insane to me to think that 5% of total print articles would cover immigration). reply throwaway598 7 hours agorootparentI'd expect these series to be cointegrated. A chart or OLS isn't going to prove chicken or egg. reply thsksbd 8 hours agorootparentprevWhy is it telling? That's true for everything the media covers. reply CapitalistCartr 7 hours agorootparentprevIt's not news, it's the Daily Mail. reply joshe 13 hours agorootparentprevWhat a great update, thanks for posting! reply seanhunter 9 hours agoparentprevThe economist is a fantastic benchmark when it comes to data visualisation. One thing to note is they publish a lot of the underlying data and models behind their visualisations on their github. If you know R it's a tremendous resource. https://github.com/TheEconomist reply gerdesj 9 hours agoparentprev\"dual axis charts can often be a great choice.\" I generally find that a second Y axis creeping in is perhaps an indicator to stop and have a really deep think about what you are trying to achieve. You might try doing a 3D graph for example where x, y1, y2 becomes x, y, z then spin and explore. However you have to remember that y1 and y2 are both dependent on x (by definition) so when you put y2 to a separate dimension, it is not independent from y1 (or is it?) There are no hard and fast rules when it comes to spin doctoring via graphs, and as the old adage doesn't go: There are liars, damned liars and politicians. reply listenallyall 1 hour agoparentprevThis is a pretty good article and for the most part, should be heeded. It's quite rare for the audience of a chart to exclusively be highly-numerate people (and these people, who are often inundated with data, are not immune from being misled by poorly-conceived charts). It's kind of strange that the top-voted comment points to \"better\" advice while also directly contradicting the article's main point (\"dual axis charts can often be a great choice\"). I mean, certainly you have the right to add some color but it comes off like you are saying to ignore the article entirely in favor of your alternatives. reply Leftium 17 hours agoprevFound this while trying to create an observable plot with multiple scales[1][2]. I'd argue multiple scales are OK if the multiple axes have different units that can't be easily compared/confused and are used for greater information density (instead of relative comparison purposes). For example: I'd like to plot weather stats like hourly temperature, precipitation, and AQI throughout the day, so several different days can be compared with each other. (And fit all this information on a mobile screen.) [1]: https://github.com/observablehq/plot/issues/147 [2]: https://github.com/observablehq/plot/discussions/626 reply dendrite9 5 hours agoparentHave you looked at how yr.no plots their forecasts on the phone. I find the graph view to be very helpful in the winter when planning ski days or days to skip. They must have updated the charts recently since they are different from what I remember this winter but it looks similar. An example: https://www.yr.no/en/forecast/graph/1-305409/Norway/Troms/Tr... reply bradford 16 hours agoparentprevI was coming here to say something similiar. The article only shows examples of dual axis charts where line series are used for both axes. This will clearly cause confusion (especially when tooltips are not available). I've generally found that when displaying a percentage, it is helpful to show the individual counts for numerator/denominator. I believe that showing percentage as a line series on one axis, and raw counts, represented as a column on the other axis, can be a helpful visual. reply rossdavidh 15 hours agoprevSo, it's great that they try to actually get data on what kinds of charts convey what information. However, you need to know who your audience is. I, for example, found all of their suggested alternatives to be harder to interpret than the dual axis chart. If you're trying to see whether or not the ups and downs of two different variables are similar, suggesting a connection between the two, none of the suggested alternatives do as good a job (although two charts could, if instead of having them side by side you had them one above the other, with the same x-axis scale, but that is really just a stealth dual axis chart). Most of these \"don't use this kind of chart\" seems to be trying to make it impossible to confuse or mislead your audience, and that is just not plausible. You do, and probably usually should, have some point in mind when you are showing someone else a chart, and the format needs to make it easy to see that. Almost any chart, even pie charts, have some particular use case where they are the best chart for that purpose. No chart is going to always be the best way to present data. Like choosing what kind of language to use in explaining something, you need to know something about who your audience is, and what they are accustomed to. reply petsfed 11 hours agoparentWasn't there an article the other day about a concept that's similar to incompleteness theorem? That any ambiguity-free language is incapable of completely describing sufficiently complex situations? Am I just imagining that? [0] I feel like making a tool harder to use, just to prevent bad actors, only punishes good actors, while the bad actors find some other way to act badly. Like, I don't want to participate in your arms race against disinformation purveyors, i just want to illustrate that it tends to rain on days that are cloudy and have high humidity. 0. Sort of. I recently encountered \"Colorless green ideas sleep furiously\" (https://en.wikipedia.org/wiki/Colorless_green_ideas_sleep_fu...), although where I can't recall, and sort of inferred the rest. reply tqi 8 hours agoprev1. I'm not sure why having two charts side by side helps? 2. Indexed charts are also not a panacea - depending on what point on the x axis you choose as your starting point, it is easy to make it seem like one series is rapidly outpacing the other (ie choosing to start at the peak). Ultimately I think charts are best thought of as a way to communicate a conclusion, not be the primary source for drawing a conclusion. Figure out what point you are trying to convey and choose the chart that communicates that the best. reply Too 5 hours agoparentYeah. If you are going to be tampering with the zero offset, the side by side charts have exactly the same issue of misleading. reply Tarq0n 1 hour agorootparentGrowth is actually one of the few things where it's permissible to remove 0 from a scale. For instance with asset prices, the dollar value doesn't matter, only the magnitude of the change. reply treflop 3 hours agoprevI find plotting two correlated but unrelated data series (like temperature and humidity) can be fine. But the article chooses the worst possible dual axis charts where both data series not only measure the same thing (GDP) but share the same units (dollars). What you actually have is a multiple data series chart with actually one axis but you made two to be confusing. reply jdeaton 11 hours agoprevI once worked with someone who was doing performance benchmarking of two systems, and made a duel axis chart with the lines right on top of eachother when in fact one system was like 5x faster than the other. it drove me nuts because I didn't even realize the dual axis at first and thought that they literally had identical performance reply jszymborski 9 hours agoparentYah, the moment you see/make a dual-axis line plot, you know you're comparing relative change. The whole point is to effectively normalize for absolute value. So yah, anyone arguing primarily on the basis of absolute value on these plots is likely pulling a fast one. reply jrd259 15 hours agoprevI'd argue that the zero value should always be shown. Otherwise you get different impressions of the rate depending how you scale and subset the Y axis. reply PheonixPharts 15 hours agoparentThis is not a good practice at all. Do you think atmospheric CO2 charts should show 0? How about daily temperature reading for human body temperature? Should daily stock tickers all start at 0? Why is 0 magical? Adding 0 to the vast majority of plots shows that data at an unnatural scale that can obscure genuinely important information. Human body temperature readings on a scale from 0 to 107F would make all the important information hard to see. A much better rule is that charts should have reasonable bounds based on knowledge of the system. For human temperature in F anything less that 95 and greater than 107 basically mean you're dead. For processes in nature good points are some delta - the lowest record to delta + highest recorded. For things like daily stock prices, a few standard deviations each way from historic volatility works. The dogma that charts should all start at 0 is complete nonsense and tries to side step reasoning about you data. Yes scales can be used to misrepresent data, but forcing 0 to the axis does not solve this. reply vharuck 14 hours agorootparentYes. Charts are communication devices. Any \"rules\" for charts should be seen like similar \"rules\" for essays or emails: good advice that almost always gives a satisfactory result when followed. Reliable paths for infrequent authors. But what matters most in charts is the same thing that matters most with writing: pick one major point and stick to it (if you're really good or can't avoid it, maybe a couple points). This also explains why a lot of dual-axis charts don't work: the author explains two sets of data that aren't even measured on the same scale and then leaves the reader to connect them and understand the meaning of that connection. You can't be sure the reader will end up at the point you wanted to make. That's not to say a dual-axis chart is always the wrong choice. Just that, if you start making one, stop and ask if there isn't a better way to show the data. Same with pie charts. reply uhoh-itsmaciek 8 hours agorootparentWhat's a good discussion of the pros and cons of pie charts? reply lupire 10 hours agorootparentprevIf 0 is not useful reference, then the chart should have the X axis on top, to avoid the intuitive tendency to interpret the graph as a heigh chart. reply function_seven 6 hours agorootparentThat’s too weird for most audiences. Removing the X axis altogether seems more appropriate (while keeping the labels). Then the plot area is still “bottomless” in a sense, but the labels are where people expect to see them. Having the axis on top implies that the values are negative. Like an ocean depth chart. reply yau8edq12i 15 hours agorootparentprevFahrenheit is not an absolute scale, so there is nothing special about 0F, you're right about that. As for your other two examples (atmospheric CO2 and stock tickers)... Yes, the scale should start at 0. Why shouldn't they? reply PheonixPharts 14 hours agorootparent> Fahrenheit is not an absolute scale So if someone showed body temperature measured in Kelvin you would argue that it should start at 0? That seems even more ridiculous. > Why shouldn't they? Because for the vast majority of stock it would appear to be a straight line every single day? Can you find me a example of a stock trading app for a company who's price is > $100/share that shows intraday price activity on a zero scale? Likewise most co2 charts start around 300ppm since that has been roughly where the lower bound of atmospheric co2 levels have been for all of human history. The last time co2 was 0 on the planet earth it was just a molten rock so what's the meaning of showing this value? It's not even theoretically possible that co2 could be that low baring alien life sucking the atmosphere off the planet. Can you clarify why the scale should start at 0 for these things? How is that anywhere close to an honest representation? reply parpfish 15 hours agorootparentprevBecause starting at zero can cause scaling issues that mask meaningful trends and variation. That can also be abused to mislead, but a simple rule like “always include zero” ain’t the solution to that. reply jrd259 13 hours agorootparentAll fair points about zero. Sorry, I acknowledge now I was overly influenced my metrics dashboards I use for alerting. I've seen people panic at a seeming steep rise in error rate or increase in latency because the chart was not showing the full range (0 to 1 for rates, or 0 to 2x SLA for latency). I was only thinking of operational alerting dashboards. reply hex4def6 14 hours agorootparentprevIn that case, we should report body temperature in Kelvin. However, now the dead-alive range (95degF - 107degF) becomes 308K to 315K. Starting at zero, that range (17K) is now only 5% of the graph, assuming we start at zero. Or in other words, if your chart is 10cm tall, the entirety of the useful range is compressed into a space that is 5mm tall. reply aj7 9 hours agoprevNo. You’re missing two arrows, each near its graph and pointing to the corresponding y-axis. This has more impact than color matching. reply erehweb 12 hours agoprevI get it, and sympathize, but at many companies the decision maker is someone who wants to see dual axis charts. If Datawrapper can't do that, then that would be a point against using it widely. reply einpoklum 16 hours agoprevThe first couple of arguments are weak: 1. It's possible to mislead by playing with a single series' scale, you don't need two series to lie-with-statistics... 2. The argument that people will think the data are identical despite the different scale? Don't buy it. reply hex4def6 14 hours agoparentAs an engineer with an oscilloscope, not being able to plot two probes against each other on the same chart would be severely limiting. For instance, imagine a 10x attenuator / amplifier. Maybe the input has a DC offset. Being able to plot the two against each other to look for (e.g) distortion, is invaluable. This is committing the two cardinal sins (judging from some comments here) of not starting at zero and different scales, and yet it's not misleading at all. I can believe dual axis charts allow misleading results, but that doesn't mean they don't have completely legitimate uses. reply parpfish 14 hours agoparentprevAgreed. dual scale plots are a great visualization to emphasize correlation between time series. I think of it as depicting an intermediate step in computing a Pearson R when the data have been z-scored but before you’ve collapsed across data points reply tofof 11 hours agoparentprevAnd the possibility of fiddling with scale to mislead still exists with side-by-side charts, their #1 alternative. In fact, they use the same misleading scale start and stop points as they criticize in the dual-axis version, so that the \"one went up 80%, the other went up only 40%, but it looks like they went up equally\" still applies to their replacement. reply o0-0o 16 hours agoprevGreat article. I used to be into charting a lot and ran a charting product at a famous firm. Would love to see the thoughts of the author on other charts like radar and treemap. :) Great read. reply einpoklum 16 hours agoparentWe could really use your help in LibreOffice! I mean, if you are still into coding. There is quite a bunch of work to do on charting: Desired chart enhancements in general https://bugs.documentfoundation.org/showdependencytree.cgi?i... Desired additional chart types https://bugs.documentfoundation.org/showdependencytree.cgi?i... reply pasc1878 15 hours agoprevI would be the one in the sample who did not find the charts confusing. The two separate graphs are much more difficult to compare - you can't see which elements compare to the same year so lose a lot of information. The information in the chart is if there is a change in one time series is there a change in the other. - that is probably all you can infer as without error bars you can't see if the differences are material. (ie I know they are different scales so when they cross they obviously aren't the same.) If so there might be a correlation which might be worth looking into remembering correlation does not equal causation (so the example in the link are just laughable) The prioritisation just shows nothing. The scatterplot shows nothing The indexed chart does make sense and in this case I would agree would be better. reply ericpauley 15 hours agoparentThe connected scatter plot is so cursed... talk about hard to interpret! The only conclusion that's hard to argue with here is zero-indexing plots, but that's not exactly a new finding. reply pasc1878 15 hours agorootparentAlso the scaling - in this case the original had reasonable scaling but it can be manipulated. The changes could be small enough to be random fluctuations on one series and so no real match. However the graph does show that a slightly deeper look would be worthwhile - even if it is a very quick one to see that the data is manipulated e.g. climate deniers graphs of temperature all starting on the same year. If you change the starting year you got rather different results. reply parpfish 14 hours agorootparentprevI could see that connected scatter MAYBE working if it were an animation or interactive plot. Maybe. But on its own, it’s horrid reply slow_typist 13 hours agoparentprevThe problem with indexed charts is that the base year is arbitrarily set and can change the whole picture a lot. reply thedudeabides5 6 hours agoprevEh, how about look at the axis units when someone is pitching you something. reply ajuc 16 hours agoprevIn case of German GDP vs Global GDP I'd argue the correct thing to do is to draw a graph of a new variable \"German GDP as a percentage of Global GDP\" and a separate graph of Global GDP. reply patrick451 11 hours agoprevWhat a patronizing company. Your customers keep asking for a feature that is widely supported and you refuse to add it because it violates your sensibilities. Instead, you write this diatribe lecturing us that the way we want to display data is wrong. Just reading the opening paragraph, whatever interest I may have had in your plotting capabilities evaporated. reply goldemerald 16 hours agoprevSolution 4 is so hilariously bad I am shocked it was suggested. Building a 2d landscape where the time dimension seems to take a random walk made laugh a lot. Ignoring the standard convention of \"independent variable on x-axis\" and instead embedding it as datapoints is a particularly clever way to obfuscate the data and confuse the reader. reply msm_ 12 hours agoparentI don't agree. It's a great way to visualise data when you want to focus on a trend. It makes it very obvious which \"direction\" is the data heading. But of course it is not very often used, is not a great fit for every use case (in particular, bad for the data in OP) and may be confusing when seen first time. reply sixthlime 15 hours agoparentprevI thought so at first too, but if you look at the link they included [1] it seems like it can actually be quite clear for some datasets [1] https://archive.nytimes.com/www.nytimes.com/imagepages/2010/... reply cs702 17 hours agoprev [–] I'm 100% in agreement. To anyone here who thinks plots with two different scales in the same direction sometimes are appropriate: Please read this. --- EDIT: Changed \"dual axis charts\" to \"plots with two different scales in the same direction,\" which more accurately describes the OP's topic. reply isidor3 15 hours agoparentPlotting the average or top percentile latency of an API on the left axis and the number of calls to that API on the right is pretty much standard practice where I work. I would argue it makes things more clear. You get to see exactly how the latency changed as the traffic does, or where more noise is visible because the traffic was low. Because both scales are using completely different units it's more difficult to confuse the two. reply Scene_Cast2 15 hours agoparentprev [–] What about Bode plots? reply cs702 15 hours agorootparent [–] I have nothing against them. Please note, I edited my comment to change \"dual axis charts\" (common spreadsheet terminology) to \"plots with two different scales in the same direction,\" which more accurately describes the plots with which the OP -- and I -- disagree. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "The article delves into the utilization of dual-axis charts in data visualization and journalism, outlining the advantages and drawbacks of this method.",
      "It emphasizes the significance of clarity, context, and selecting appropriate chart styles to convey data effectively to viewers, touching upon the debate around commencing scales at zero and possible misinterpretations.",
      "Participants are divided, with some endorsing dual-axis charts for specific situations, while others express worries about potential misleadings and propose different strategies."
    ],
    "points": 129,
    "commentCount": 55,
    "retryCount": 0,
    "time": 1715963440
  },
  {
    "id": 40393873,
    "title": "ILGPU: Harness C# and F# for High-Performance GPU Programming",
    "originLink": "https://github.com/m4rs-mt/ILGPU",
    "originBody": "ILGPU ILGPU is a JIT (just-in-time) compiler for high-performance GPU programs written in .Net-based languages. ILGPU is entirely written in C# without any native dependencies. It offers the flexibility and the convenience of C++ AMP on the one hand and the high performance of Cuda programs on the other hand. Functions in the scope of kernels do not have to be annotated (default C# functions) and are allowed to work on value types. All kernels (including all hardware features like shared memory and atomics) can be executed and debugged on the CPU using the integrated multi-threaded CPU accelerator. ILGPU.Algorithms Real-world applications typically require a standard library and a set of standard algorithms that \"simply work\". The ILGPU Algorithms library meets these requirements by offering a set of auxiliary functions and high-level algorithms (e.g. sorting or prefix sum). All algorithms can be run on all supported accelerator types. The CPU accelerator support is especially useful for kernel debugging. Community The ILGPU community provides immediate help, feedback and suggestions via Discord ASAP. Log on to the server and you can get started right away. There are weekly talk-to-dev meetings on the Discord server. Don't hesitate to join the meeting if you have any questions or suggestions or just want to talk to one of the contributors. Check out the welcome channel on our Discord server for more information. ILGPU Samples The sample projects demonstrate the basic usage of ILGPU to help you get started with high performance GPU programming. Build Instructions ILGPU requires Visual Studio 2022 (or higher) and/or a .NET 6.0 SDK toolchain. Use the provided Visual Studio solution to build the ILGPU libs in the desired configurations (Debug/Release). Tests Sometimes the XUnit test runner stops execution when all tests are run in parallel. This is not a problem related to the internal tests, but a known XUnit/Visual Studio problem. If the tests stop unexpectedly, you can simply run the remaining tests again to continue working. Note: You can unload ILGPU.Tests.Cuda (for example) if you do not have a Cuda-capable device to execute the Cuda test cases. Related Information ILGPU Homepage (www.ilgpu.net) Latest ILGPU Samples (https://github.com/m4rs-mt/ILGPU/tree/master/Samples) Latest ILGPU Documentation (https://github.com/m4rs-mt/ILGPU/tree/master/Docs) Nuget (https://www.nuget.org/packages/ILGPU) Release (https://github.com/m4rs-mt/ILGPU/releases/) Preview versions Preview/Daily builds are distributed using https://feedz.io/. To pull preview versions into your project, use the following NuGet.config file: Symbols Symbols for ILGPU can be loaded in VS2022. For official releases, ensure that the built-in NuGet.org Symbol Server is enabled. For preview release symbols, add the link: https://f.feedz.io/ilgpu/preview/symbols Source Link ILGPU also provides Source Link support for a better debugging experience. Make sure Enable Source Link support is activated in VS2022 options. General Contribution Guidelines Make sure that you agree with the general coding style (in terms of braces, whitespaces etc.). Make sure that ILGPU compiles without warnings in all build modes (Debug, DebugVerification and Release). References Parallel Thread Execution ISA 7.0 NVIDIA A Graph-Based Higher-Order Intermediate Representation Roland Leissa, Marcel Koester, and Sebastian Hack Target-Specific Refinement of Multigrid Codes Richard Membarth, Philipp Slusallek, Marcel Koester, Roland Leissa, and Sebastian Hack Code Refinement of Stencil Codes Marcel Koester, Roland Leissa, Sebastian Hack, Richard Membarth, and Philipp Slusallek Simple and Efficient Construction of Static Single Assignment Form Matthias Braun, Sebastian Buchwald, Sebastian Hack, Roland Leissa, Christoph Mallon and Andreas Zwinkau A Simple, Fast Dominance Algorithm Keith D. Cooper, Timothy J. Harvey and Ken Kennedy Fast Half Float Conversions Jeroen van der Zijp Identifying Loops In Almost Linear Time G. Ramalingam License information ILGPU is licensed under the University of Illinois/NCSA Open Source License. Detailed license information can be found in LICENSE.txt. Copyright (c) 2016-2024 ILGPU Project. All rights reserved. Originally developed by Marcel Koester. License information of required dependencies Different parts of ILGPU require different third-party libraries. ILGPU Dependencies System.Collections.Immutable (https://www.nuget.org/packages/System.Collections.Immutable) System.Memory (https://www.nuget.org/packages/System.Memory) System.Reflection.Metadata (https://www.nuget.org/packages/System.Reflection.Metadata) System.Runtime.CompilerServices.Unsafe (https://www.nuget.org/packages/system.runtime.CompilerServices.Unsafe/) Detailed copyright and license information of these dependencies can be found in LICENSE-3RD-PARTY.txt.",
    "commentLink": "https://news.ycombinator.com/item?id=40393873",
    "commentBody": "ILGPU: Write GPU programs with C# and F# (github.com/m4rs-mt)128 points by neonsunset 13 hours agohidepastfavorite17 comments atonalfreerider 8 hours agoAlso recommending ComputeSharp. I've been using it for a few years now: https://github.com/Sergio0694/ComputeSharp reply neonsunset 4 hours agoparentUnfortunately, ComputeSharp is Windows-only which significantly limits its usability. reply jvanderbot 11 hours agoprevI'm going through the CUDA courses. I've done GPU and CPU optimization as an enthusiastic amateur in my day job once or twice a year, but it's not my core focus. It quickly seems that the low level C/Cpp is becoming obsolete, and it's hard to squeeze performance unless you're doing something truly green field / new. Otherwise someone has already optimized the hell out of it. So what's the use case for porting GPU to higher level languages like C#? What would you use this for? reply almostgotcaught 10 hours agoparent> It quickly seems that the low level C/Cpp is becoming obsolete, and it's hard to squeeze performance unless you're doing something truly green field / new. Otherwise someone has already optimized the hell out of it. I hear and see both of these sentiments frequently from the internet crowd (on-lookers). It's both wrong and humorously arrogant. I'll repeat what I said to someone on reddit yesterday: there are thousands (maybe 10s?) scattered around the FAANGs, NVIDIA, AMD, Intel, accelerator startups, boutiques, etc. whose day to day is both C/C++ and squeezing perf out of kernels and getting many points (sometimes 10s) improvement. Certainly the wins aren't daily but I'm saying they do steadily find room for improvement. How is that possible? I'll give you a hint: platforms, demands, hardware, use-cases all change essentially on a quarterly basis. So before you proclaim victory on behalf of whatever high-level framework, ask yourself if you're really familiar with the production and business environment for this kind of code. reply jvanderbot 10 hours agorootparentAs a learner and self proclaimed amateur, I assume the vitriolic tone is directed elsewhere. Without that, you're saying that performant pipelines are definitely in demand and optimization is still a full time job. That's good! I'd like to get better at that. reply almostgotcaught 10 hours agorootparent>I assume the vitriolic tone is directed elsewhere I'm always really shocked on hn when people getting called out for arrogance respond with accusations (of vitriol). What day job do you have where you can make proclamations like \"It quickly seems that the low level C/Cpp is becoming obsolete\" while simultaneously admitting being an amateur and not get checked. Must be very different from my day job where being precise and accurate and conservative is paramount. Moreover what kind of habit of thought are you in that being called out for that is read as vitriol? reply jvanderbot 7 hours agorootparent\"it seems\" combined with \"I'm learning\" was meant to convey ignorance not arrogance. I think I'm just being misread and that's probably my fault. It wouldn't be the first time - so I'm sorry if you found it off-putting My day job is optimization for logistics and multi-agent systems on edge deployments. We vary between heterogenous compute environment on-platform and occasional connections to cloud-like servers, but only occasionally. The system has a lot to do and we're pushing what it can do for itself. I like these problems and am always trying to find new ways to solve them. That's really it, I'm wondering if it's best to focus on learning to work the hardware as is, or learning to twist existing libraries into new problems. For example if you look at this: https://weightythoughts.com/p/cuda-is-still-a-giant-moat-for... It actually denigrates anyone who would consider starting at low level CUDA kernels. I liked your message though, you had a great point: what do I imagine all those CUDA programmers do if not write CUDA? reply denom 8 hours agorootparentprev> Moreover what kind of habit of thought are you in that being called out for that is read as vitriol? That’s as much a matter of personal identity as a ‘habit of thought’, friend. Otherwise, we could we comment on the basis of _your_ perspective as some mutable affectation, no? You see, we are shadows of ourselves. An inquisitive play, or let’s say a “judgment” about Cuda economics: aspirational, errant? Then, the linguistic phalanx: honed no doubt by long running needs to be heard and seen and listened to. reply ClassyJacket 9 hours agorootparentprevOh my god, calm down. Jesus christ. reply almostgotcaught 9 hours agorootparentSame thing applies here: I'm not the one the one that's not calm. I very calmly pointed out that op is wrong. That's it. You painting that as \"not calm\" is the only abnormal thing going on here. reply jvanderbot 7 hours agorootparentYou can interpret text as being uncalm, but there's always room for misunderstanding, esp in a forum/thread. Nobody is actually upset I think, just using direct language. reply jay-barronville 9 hours agoparentprev1. C and C++ aren’t going anywhere. 2. I don’t think you have an appreciation for the sheer amount of software—including lots of very critical software—implemented in C and C++ that are being improved upon daily. A buddy of mine works on critical low-level software (including C) in the energy sector. Millions of lines of code. The effects, positive or negative, of any single code change can impact tens of thousands of Americans (likely even more). His job is to maintain and continuously optimize this software. Given your comment, I think you’d be surprised to learn that he never runs out of work. reply jvanderbot 7 hours agorootparentWell, I write in those languages every day! It's not a statement about the languages, just wondering about whether CUDA is best approached low level or from well established libraries. reply sheepscreek 11 hours agoparentprevMake it more accessible? Prototyping? Eg. easily determining if your use case is even suited for a GPU workload. Best case - it is, and now you can write a custom CUDA kernel to squeeze out more performance. Worst case, you lose a couple of hours vs weeks before you discover it’s not going to work. reply fulafel 3 hours agoparentprevProgrammers generally use higher level languages to implement original code because the code is easier for humans to read, write and debug. Porting from low level languages (eg CUDA or C++ to F#) is less common. reply neonsunset 11 hours agoparentprevGiven IL itself is an abstract stack-based bytecode, it can be compiled to the corresponding IR, which can then target corresponding back-end (CUDA, OpenCL, CPU, etc.) - this is what ILGPU does. Because all code is in the single repository in the post and is fairly easy to read, you can skim through it to draw your own conclusions if this interests you. Also, very easy to start using: just `dotnet add package ILGPU` on most configurations (as ADHD puts higher mental strain on activities involving complex configuration, I try to keep to the tools that have minimal ceremony) C# (and F# by extension) generally allow to write system-ish code, with references to locals and same C primitives, which means that you're likely not sacrificing in performance in this particular scenario by having the language be higher-level. After all, you're using ILGPU's APIs first and foremost. As to why use it at all - you are likely to move faster with it than C++, especially if it's not your full-time job, with all the escape hatches to extract 99.9% efficiency still on the table (that is, if performance of the kernel emitted by ILGPU has issues in the first place - see below for alternative, cheap FFI and easy C/C++ integration are still there as well). It also lets you do things like PTX assembly: https://github.com/m4rs-mt/ILGPU/blob/master/Samples/InlineP... reply davidgl 10 hours agoprev [–] Also see https://www.fshade.org/, a F# dsl for shaders reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "ILGPU is a high-performance JIT compiler designed for GPU programs in .Net-based languages, combining the flexibility of C++ AMP with the performance of CUDA.",
      "The library offers auxiliary functions, high-level algorithms, and has an active community on Discord, along with sample projects and build guidelines for beginners.",
      "To work with ILGPU, ensure you have Visual Studio 2022 and a .NET 6.0 SDK toolchain, and be prepared for potential XUnit/Visual Studio challenges during testing, providing Source Link and Symbol support for debugging."
    ],
    "commentSummary": [
      "ILGPU enables writing GPU programs in C# and F#, offering a high-level approach to enhance performance optimization.",
      "ComputeSharp is a Windows-exclusive alternative for GPU programming, complementing ILGPU.",
      "The ongoing debate between low-level languages (C/C++) and higher-level languages for GPU programming has valid arguments, with ILGPU leveraging abstract stack-based bytecode to target CUDA and OpenCL efficiently."
    ],
    "points": 128,
    "commentCount": 17,
    "retryCount": 0,
    "time": 1715977540
  }
]
