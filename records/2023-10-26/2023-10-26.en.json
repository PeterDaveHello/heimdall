[
  {
    "id": 38012032,
    "title": "OpenAPI DevTools – Chrome extension that generates an API spec",
    "originLink": "https://github.com/AndrewWalsh/openapi-devtools",
    "originBody": "Effortlessly discover API behaviour with a Chrome extension that automatically generates OpenAPI specifications in real time for any app or website.",
    "commentLink": "https://news.ycombinator.com/item?id=38012032",
    "commentBody": "OpenAPI DevTools – Chrome extension that generates an API specHacker NewspastloginOpenAPI DevTools – Chrome extension that generates an API spec (github.com/andrewwalsh) 733 points by mrmagoo2 21 hours ago| hidepastfavorite96 comments Effortlessly discover API behaviour with a Chrome extension that automatically generates OpenAPI specifications in real time for any app or website. ttul 10 hours agoThis is super cool. Writing code to drop into the JavaScript console lets you do insane things. I’ve found great success using ChatGPT to help me write the code, which I then just cut and paste into the console. Asking it to “make it all run in parallel using async&#x2F;await” will massively speed up execution of serial tasks.For instance, I had GPT help me write browser JS that groks literally thousands of IP addresses in an open security tool that shall not be named. I can vacuum much of their entire database in seconds by making hundreds of async calls. While they do have bot protection on the website, they appear to have no protection at all on their browser APIs once the user has been given a cookie… I suspect this is common. reply the_absurdist 20 hours agoprevI wish this would document the auth headers.What would be particularly useful is if it saved token values and then (through search) joined them on the response of the auth call to get the initial token.That way you could easily determine what auth call was needed to get you a token to use the endpoint. reply mrmagoo2 12 hours agoparentGreat suggestion, I will look into this. reply hoerzu 7 hours agorootparentI have used llama to figure out the duplications &#x2F; pathparamters :) reply a_c 20 hours agoprevLove it!I used https:&#x2F;&#x2F;vite-plugin-web-extension.aklinker1.io&#x2F;guide&#x2F; before to have cross browser extension support. If you don&#x27;t mind I could take a look to add firefox support (no guarantee) reply mrmagoo2 12 hours agoparentAs a follow up, the algorithm that powers this makes use of the chrome.devtools.network API. Specifically it passes the Request object that is in the HAR 1.2 archive format.So if you can pass the equivalent of that in Firefox&#x2F;other browsers to the insert method and switch things up a bit, it should be relatively straightforward. I will think about pulling out the core logic into its own lib.https:&#x2F;&#x2F;developer.chrome.com&#x2F;docs&#x2F;extensions&#x2F;reference&#x2F;devto...https:&#x2F;&#x2F;developer.chrome.com&#x2F;docs&#x2F;extensions&#x2F;reference&#x2F;devto...https:&#x2F;&#x2F;github.com&#x2F;AndrewWalsh&#x2F;openapi-devtools&#x2F;blob&#x2F;main&#x2F;sr... reply a_c 3 hours agorootparentIndeed I have issue here. Firefox maintain a library for unified extension API https:&#x2F;&#x2F;github.com&#x2F;mozilla&#x2F;webextension-polyfillTheir type definition for HAR request isn&#x27;t exported https:&#x2F;&#x2F;github.com&#x2F;DefinitelyTyped&#x2F;DefinitelyTyped&#x2F;blob&#x2F;mast...So I can&#x27;t drop in replace the type on https:&#x2F;&#x2F;github.com&#x2F;AndrewWalsh&#x2F;openapi-devtools&#x2F;blob&#x2F;main&#x2F;sr... reply lucasyvas 20 hours agoparentprevThis would be excellent reply mrmagoo2 19 hours agoparentprevHey absolutely please do, thank you! reply parhamn 17 hours agoparentprevAre devtools extensions&#x2F;panels standardized? reply a_c 17 hours agorootparentDo you mean the devtool protocol[1]? I didn&#x27;t follow the space so have no knowledge on it. On the other hand there seem to be a polyfilled API on chrome.devtools.network.Request which OP&#x27;s extension uses extensively https:&#x2F;&#x2F;github.com&#x2F;DefinitelyTyped&#x2F;DefinitelyTyped&#x2F;blob&#x2F;mast...[1] https:&#x2F;&#x2F;chromedevtools.github.io&#x2F;devtools-protocol&#x2F; reply distortedsignal 16 hours agoparentprevI&#x27;d love to see FF support on this. reply civilitty 10 hours agoparentprevThere&#x27;s also Plasmo which provides some abstractions over the browsers: https:&#x2F;&#x2F;github.com&#x2F;PlasmoHQ&#x2F;plasmo reply archiewood 17 hours agoprevMy most common use case here is to then want to hit the API from python, and adjust the params &#x2F; url etc.Would love a \"copy to python requests\" button thatgrabs the headersgenerates a boilerplate python snippet including the headers and the URL: import requests import json url = &#x27;&#x27; headers = { &#x27;User-Agent&#x27;: &#x27;Mozilla&#x2F;5.0 ...&#x27;, ... } data = { \"page\": 5, \"size\": 28 ... } response = requests.post(url, headers=headers, data=json.dumps(data)) if response.status_code == 200: print(response.json()) else: print(f\"Error {response.status_code}: {response.text}\") reply ea016 17 hours agoparentSteps to do so:- open the network console- right click on the request- click \"copy as curl\"- visit https:&#x2F;&#x2F;curlconverter.com&#x2F; to convert to Python&#x2F;Node&#x2F;any language reply tech234a 15 hours agorootparentAlso available as a VSCode extension that automatically matches the pasted content to the programming language used in the current file: https:&#x2F;&#x2F;marketplace.visualstudio.com&#x2F;items?itemName=curlconv... reply verhovsky 13 hours agorootparentI made a fork of the Chrome DevTools that adds \"Copy as Python\" to the right click menu of each request in the Network tab. You can tell Chrome to use a different version of the DevTools if you start it from the command linehttps:&#x2F;&#x2F;github.com&#x2F;curlconverter&#x2F;curlconverter&#x2F;issues&#x2F;64#iss... reply tilne 16 hours agorootparentprevThank you for this. I didn’t know curlconverter existed. reply archiewood 13 hours agorootparentprevThis is my current workflow, though with ChatGPT.I was just trying to save a few clicks reply novia 11 hours agorootparentYou made your request sound important to implement when you already have a workaround that doesn&#x27;t take very much time...This is why feature bloat is a thing reply MurageKabui 16 hours agorootparentprevI was to say this lol reply knowsuchagency 16 hours agoparentprevYou could take the OpenAPI json generated from this project and feed it to https:&#x2F;&#x2F;docs.scalar.com&#x2F;swagger-editor which generates boilerplate in several formats, including Python reply gabrielsroka 13 hours agoparentprev1. You should almost always use requests.Session() instead of requests. It&#x27;s faster, and can make the code shorter.2. requests can dump to JSON for you by using json=, so you don&#x27;t need a separate module. It&#x27;ll even set the content-type header to application&#x2F;json for you. import requests url = &#x27;&#x27; headers = { &#x27;User-Agent&#x27;: &#x27;Mozilla&#x2F;5.0 ...&#x27;, ... } session = requests.Session() session.headers.update(headers) data = { \"page\": 5, \"size\": 28 ... } response = session.post(url, json=data) if response.status_code == 200: print(response.json()) else: print(f\"Error {response.status_code}: {response.text}\") reply prometheon1 11 hours agoparentprevYou could potentially go one step further and make Python classes that wrap the whole API automatically from the OpenAPI file: https:&#x2F;&#x2F;github.com&#x2F;mom1&#x2F;apiclient-pydantic-generator reply kej 16 hours agoparentprevIt seems like you could combine this extension with some of the OpenAPI -> Python projects to get your desired result. (e.g. https:&#x2F;&#x2F;github.com&#x2F;wy-z&#x2F;requests-openapi ) reply yread 16 hours agoparentprevwow what a perfect service to steal session cookies reply lucasyvas 20 hours agoprevThis reminds me a lot of:https:&#x2F;&#x2F;github.com&#x2F;alufers&#x2F;mitmproxy2swaggerHowever, having the capability delivered in a browser extension is extremely handy! reply aeontech 17 hours agoparentthis comment section is a goldmine :)Thanks for sharing this, I suspect this is going to be super useful for my work reply pihentagy 1 hour agoprevIs there a way to filter out headers?The result contains headers like content-length and similar.Also it would be nice if it could factor out common schemas. reply jimmySixDOF 21 hours agoprevNice this made me go back and check up on the Gorilla LLM project [1] to see whats they are doing with API and if they have applied their fine tuning to any of the newer foundation models but looks like things have slowed down since they launched (?) or maybe development is happening elsewhere on some invisible discord channel but I hope the intersection of API calling and LLM as a logic processing function keep getting focus it&#x27;s an important direction for interop across the web.[1] https:&#x2F;&#x2F;github.com&#x2F;ShishirPatil&#x2F;gorilla reply quan 20 hours agoparentI open sourced this tool that takes OpenAPI spec and let you control API using natural language https:&#x2F;&#x2F;github.com&#x2F;mquan&#x2F;api2aiLet me know if you have any questions or feature request reply ushakov 19 hours agorootparentHow is this different from what LangChain already offers with their OpenAPI chain?https:&#x2F;&#x2F;python.langchain.com&#x2F;docs&#x2F;use_cases&#x2F;apis reply quan 6 hours agorootparentafaik, the langchain solution loads entire openAPI spec which consumes a lot of token and won&#x27;t work for many large API. For efficient token usage, api2ai divides the task into two steps: api planning and params parsing. First step takes a summarization of all the endpoints. Once the endpoint is known, we parse params using the schema of the selected endpoint. reply adrianbr 21 hours agoprevThis is amazing! to figure out the website apis has always been a huge pita. With our dlt library project we can turn the openapi spec into pipelines and have the data pushed somewhere https:&#x2F;&#x2F;www.loom.com&#x2F;share&#x2F;2806b873ba1c4e0ea382eb3b4fbaf808?... reply user3939382 18 hours agoprevThere&#x27;s a similar, more powerful tool if you&#x27;re into thishttps:&#x2F;&#x2F;www.akitasoftware.com&#x2F; reply digitalsanctum 17 hours agoparentFYI, Akita was just bought by Postman: https:&#x2F;&#x2F;www.akitasoftware.com&#x2F;blog-posts&#x2F;announcing-akita-ha... reply misnome 17 hours agoparentprevCrikey, if you hadn&#x27;t directly connected this as similar, I would have no idea what their product would even vaguely do from that landing page. reply user3939382 15 hours agorootparentAgree.> Akita makes monitoring and observing system behavior accessible for every developer. Quickly discover all your endpoints, see which are slowest, and learn which have errorsTranslation: Install a Docker extension that intercepts and inspects your network requests to infer the shape of your API.I feel like when you&#x27;re targeting developers, you should quickly explain what it is you actually do. reply karaterobot 14 hours agorootparentCompanies in general should do this, not just ones targeting developers! Instead they have a bunch of vague marketing copy that means nothing. It&#x27;s a pet peeve.My favorite is when they think they&#x27;re keeping it short and to the point, with no bull. So, they&#x27;ll have a hero section with copy like \"Sharpen capacity. Scale across segments. Nuff said.\" No, not enough said, say more! reply Aeolun 11 hours agorootparent> Companies in general should do this, not just ones targeting developers! Instead they have a bunch of vague marketing copy that means nothing. It&#x27;s a pet peeve.This seems to appeal to purchasing teams. When you write what the app actually does suddenly it’s technical and the team doesn’t understand what is written any more. reply rattray 12 hours agoparentprevhttps:&#x2F;&#x2F;www.useoptic.com&#x2F; is another one, which is a little more tailored to building & updating OpenAPI specs. Works well on live traffic and&#x2F;or tests. reply aeontech 17 hours agoparentprevThe important distinction that this is entirely client-side, while Akita requires an agent running server-side. reply ushakov 18 hours agoparentprevThere&#x27;s actually a whole lot of them! Keploy comes to mind and Pixie (eBPF-based) reply pbnjay 6 hours agoprevDamn I literally built a really similar tool myself using HAR files just a couple weeks ago! Yours is way more polished though, nice work.I have a lot of ideas in this space (some PoCs), and I&#x27;ve been starting to scope out a company around them. Would love to chat to see if there&#x27;s any shared opportunity for both of us! reply autonomousErwin 16 hours agoprevThis is a first step into turning the entire web into an API albeit before we hit the login&#x2F;signup roadblocks (but then that&#x27;s where agents come in) reply toyg 11 hours agoparentThat&#x27;s used to be called \"the semantic web\".Dreams never die and what is old will be new again. reply ricberw 18 hours agoprevThis is awesome!I&#x27;ll second&#x2F;third the feature request for auto-including auth headers&#x2F;calls (as many of the sites I&#x27;m trying to understand&#x2F;use APIs from use persistent keys, and scraping these separately is just unnecessary extra time).On that same note, I&#x27;d greatly appreciate keeping the initial request as a \"sample request\" within the spec.I&#x27;d also greatly appreciate an option to attempt to automatically scrape for required fields (e.g. try removing each query variable one at a time, look for errors, document them).Thanks for this :) reply digitalsanctum 16 hours agoprevGreat project! These features come to mind that would be great additions:1. Ability to filter response properties.2. Ability to work with non-JSON (web scraping) by defining a mapping of CSS selectors to response properties.3. Cross-reference host names of captured requests with publicly documented APIs.4. If auth headers are found, prompt user for credentials that can then be stored locally.5. \"Repeater\" similarly found in Burp Suite.6. Generate clients on the fly based on the generated OpenAPI spec. reply worldsayshi 13 hours agoparent- Allow using it as a library instead of just a browser extension which would in turn allow:- Integration with some kind of web crawler to allow automatically walking a web site and extract a database of specificationsEdit: Hmm, it seems that genson-js[1] was used to merge schemas.1 - https:&#x2F;&#x2F;www.npmjs.com&#x2F;package&#x2F;genson-js reply mrmagoo2 12 hours agorootparentGenson-js is used to merge JSON Schema objects. Essentially there are 5 schemas that we care about in each request - request bodies, request headers, response bodies, response headers, and query parameters. Each endpoint (which may or may not be parameterised) has only one schema for each of these values.The idea for a crawler is a good one. The core logic that handles spec generation is decoupled from everything else, so it can be extracted into its own library.But there are approaches that exist for this already, such as har-to-openapi.https:&#x2F;&#x2F;github.com&#x2F;jonluca&#x2F;har-to-openapi reply worldsayshi 12 hours agorootparentInteresting! Thanks! Awesome project :) reply digitalsanctum 16 hours agoparentprev7. Train a machine learning model to recognize and extract tabular and repeated data based on training data.8. Optionally publish generated OpenAPI specs to a central site or open PR to a GH repo, \"awesome-openapi-devtools\"? reply mrmagoo2 12 hours agoparentprevSome great ideas here, thank you. I do want to keep it small and focused so I&#x27;ll forego complex functionality like the Repeater, but you&#x27;ve raised some common pain points I&#x27;ll tackle. reply ch_sm 18 hours agoprevVery nice! Auto generating type information from looking at permutations of values is hard though. Q: Does this handle optional values? Also, being able to mark string field as \"enums\" and then collecting the possible values instead of just typing it as \"string\" would be mega handy. reply mrmagoo2 11 hours agoparentIt doesn&#x27;t have any way of determining which values are optional, so it doesn&#x27;t make that distinction. Hear you on the enums, I&#x27;ll take another look at what&#x27;s possible without adding overhead. reply RileyJames 21 hours agoprevAmazing. I’ve often wished this would exist. Thank you.It was always my step 1 towards Xxx. Keen to know what directions you were thinking?I’d love to see more remixing on top of API’s websites typically only expose for their own use. reply mrmagoo2 20 hours agoparentFor sure, there are a few tools out there like Requestly to change API behaviour, but it&#x27;s a frustrating experience. In terms of the direction, planning to keep this simple so I&#x27;ve no plans for additional features. reply jtbayly 16 hours agoprevThis looks very useful, but what do I do with the discovered data?Suppose I have a site that runs a search that I want to be able to automate. However, instead of sending the search term in the URL, it updates live (presumably via some API call).Now suppose I need a one-click solution to be able to open that page and run a specific search.Is there another Chrome plugin that would allow me to use this API data to make that happen? reply saran945 20 hours agoprevThanks for sharing Chrome extension @mrmagoo2.It&#x27;s amazing to see a tool that simplifies the process of generating OpenAPI spec. this is the best showHN this year. reply ushakov 18 hours agoparentAgreed! What would be more awesome though is if it could generate OpenAPI spec from existing HAR files reply mrmagoo2 11 hours agorootparentIt could do as it works with the HAR 1.2 format. There is another library that can do this. It isn&#x27;t suitable for the FE as it uses QuickType & pulls in a ton of dependencies, but it is far more configurable.https:&#x2F;&#x2F;github.com&#x2F;jonluca&#x2F;har-to-openapi reply jpmonette 21 hours agoprevHad in mind to build something like this for quite some time to quickly explore undocumented APIs - looking forward to see your progress! reply mrmagoo2 20 hours agoparentThank you! reply HanClinto 20 hours agoprevOkay, this is wonderful. Love it already!!Sometimes I click on a path parameter and it doesn&#x27;t \"create\" it, even though there are several other examples in the list. Not sure if it&#x27;s a bug, or something I&#x27;m doing wrong.Overall, this is an absolutely wonderful tool and I&#x27;ve wanted something like this for a long time. Incredibly useful, thank you!! reply mrmagoo2 20 hours agoparentThat sound like a bug, I need to test that feature more thoroughly. Thanks for reporting. reply hubraumhugo 16 hours agoprevReally cool, we&#x27;re using a similar technique at Kadoa to auto-generate scrapers for any website. Analyzing network calls to find the desired data in API responses is one of the frist things we do before starting to process the DOM. reply albertgoeswoof 18 hours agoprevCool! Can you add autocomplete of paths to URLs based on the spec now?so I can be typing in the URL bar for any website I have landed on in the past and tab through all the available routes?e.g.- news.ycombinator.com_- news.ycombinator.com&#x2F;new- news.ycombinator.com&#x2F;submit- news.ycombinator.com&#x2F;showetc. reply wackget 19 hours agoprevThe description doesn&#x27;t explain exactly what this extension does.I assume it monitors all XHR requests as you browse a website, and if the request&#x2F;response matches [some criteria (e.g. is JSON?)] it will assume it&#x27;s an API request and log it?Is that correct?If so, it will only work on websites where the frontend is implemented like a PWA, with lots of AJAX calls to fetch data, etc. For sites whose pages are all generated server-side, the extension won&#x27;t generate any API schema, right?Edit: Also how does it differentiate \"API requests\" with regular AJAX content fetching? If a website fetches some arbitrary content via an AJAX request (e.g. some lazy-loaded HTML), that&#x27;s not an API request. That&#x27;s just part of a website&#x27;s layout. reply iforgotpassword 19 hours agoparentHow would it, there isn&#x27;t any API in the first place with classic websites. Your could maybe consider the urlencoded post requests an API, but then the reply is another html website so how do you formally specify the reply format? \"The queried data is somewhere right below the thirdexcept when there&#x27;s a new message for the logged in user, then it&#x27;s the fourth one\" reply jameshart 19 hours agoparentprevObviously - a browser extension can only monitor API calls from the browser. reply wackget 19 hours agorootparentNot obviously; all it says is it generates a schema \"while using\" a website.\"Using\" could mean navigating between pages, submitting data via forms, etc. reply yencabulator 16 hours agoparentprevWorse, for something like SvelteKit load functions, this will think there&#x27;s a \"real API\" where what&#x27;s actually there is an internal detail and will change often.https:&#x2F;&#x2F;kit.svelte.dev&#x2F;docs&#x2F;load reply a_c 19 hours agoparentprevIt does generate schema.> Instantly generate an OpenAPI 3.1 specification for any website or application just by using it reply wackget 19 hours agorootparentYeah but my question remains: by what criteria is a request classed as an \"API request\"? Websites make tons of XHR requests and not all of them are API requests.I want to know what this extension does that&#x27;s different than me looking at the browser&#x27;s Dev Tools > Network tab. reply mrmagoo2 19 hours agorootparentThe criteria can be found below. There are no hard and fast rules, but the goal is to only include requests that you might otherwise find in a spec.https:&#x2F;&#x2F;github.com&#x2F;AndrewWalsh&#x2F;openapi-devtools&#x2F;blob&#x2F;main&#x2F;sr... reply voidmain0001 20 hours agoprevThe documentation states &#x27;automatically populate based on JSON requests that fire as you browse the web&#x27; so does this mean that gRPC protobuf are not captured? reply jcrites 18 hours agoparentDoes gRPC &#x2F;ProtoBuf have support for web browsers? I don&#x27;t know of a situation where I&#x27;d encounter those in a web application. reply voidmain0001 17 hours agorootparenthttps:&#x2F;&#x2F;blog.envoyproxy.io&#x2F;envoy-and-grpc-web-a-fresh-new-al... reply mrmagoo2 18 hours agoparentprevAnything that isn&#x27;t a JSON request is specifically ignored. reply mdaniel 18 hours agorootparentI saw your sibling comment about \"keeping it simple,\" however that is a bit counter to \"generates OpenAPI specifications\" since those for sure are not limited to just application&#x2F;json request&#x2F;response bodiesI wanted to draw your attention to \"normal\" POST application&#x2F;x-www-form-urlencodedand its multipart&#x2F;form-data friend The latter is likely problematic, but the former is in wide use still, including, strangely enough, the AWS API, although some of their newer services do have an application&#x2F;json protocolI know that&#x27;s a lot of words, but the tl;dr would be that if you want your extension to be application&#x2F;json only, then changing the description to say \"OpenAPI specifications for application&#x2F;json handshakes\" would help the consumer be on the same page with your goals reply mrmagoo2 9 hours agorootparentYou raise a good point and it would be great to account for this. I will take a look at this. Excellent suggestion. reply Aarekaz 21 hours agoprevThis looks super interesting. Works for anything? Damn. reply lukeplato 16 hours agoprevWould be cool if this shared the user found specs to create a database of API specs for the web reply corry 20 hours agoprevAwesome! Any chance of a Safari extension too? reply sdmike1 15 hours agoprevA Firefox version of this would be super handy! Does that already exist? reply pmkelly4444 19 hours agoprevthis is very cool! I just tried using it, unfortunately, my NextJS app dir project makes most requests from the server side, so it was only capturing \"posts\" made from the client. Is there a way to run it from the server? reply ec109685 17 hours agoprevWould love this for apps. reply siva7 20 hours agoprevI&#x27;m sure many developers wished at some point such magic would exist reply chris_nielsen 21 hours agoprevThis looks super useful, can’t wait to try it at work tomorrow! reply namtab00 17 hours agoparentCare to share what would it be useful for?I mean, and I&#x27;m asking as a backend dev, if you have to integrate with some API, you use the provided docs&#x2F;swagger ui.Why&#x2F;when would you care to rely on an API integration when it&#x27;s interface is not publicly shared? reply imhoguy 15 hours agorootparentBecause this is for these edge cases where docs are crap and Swagger spec is non-existent. reply zoover2020 15 hours agorootparentprevReverse engineering? You just described it reply fullofdev 9 hours agoprevlooks really cool! congrats! reply jasfi 21 hours agoprevThis could be useful for learning from any site you admire. reply ushakov 18 hours agoprevThe problem with this type of tools is that they only produce specs based on infos they can get.The spec produced will be incomplete (missing paths, methods, response variants, statuses). For that you should use a framework like Fastify, NestJS, tsoa, FastAPI, which have built-in OpenAPI support.Can be very valuable for reverse-engineering though :) reply ushakov 19 hours agoprev [–] We at Step CI have a similar tool, that acts as a proxy and can generate OpenAPI spec for the request&#x2F;response pairs.(You can also use it to generate automated tests)If you&#x27;re interested: mish@stepci.com replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A Chrome extension has been developed that can generate OpenAPI specifications for any app or website in real time.",
      "This tool simplifies the process of understanding the behavior of APIs (Application Programming Interfaces).",
      "OpenAPI specifications provide a format to describe, produce, consume, and visualize RESTful web services."
    ],
    "commentSummary": [
      "The OpenAPI DevTools Chrome extension allows users to automatically generate OpenAPI specifications for websites and applications in real time.",
      "Users are seen to engage in discussions about associated tools and projects in API management and web interoperability, with suggestions for improvements and added feature requests.",
      "The conversation also highlights the significance of API integration in cases where interface information is unavailable to the public and points out reverse engineering as a possible method."
    ],
    "points": 733,
    "commentCount": 96,
    "retryCount": 0,
    "time": 1698236659
  },
  {
    "id": 38015277,
    "title": "iLeakage: Browser-Based Timerless Speculative Execution Attacks on Apple Devices",
    "originLink": "https://ileakage.com/",
    "originBody": "iLeakage: Browser-based Timerless Speculative Execution Attacks on Apple Devices Overview of the iLeakage Attack. We present iLeakage, a transient execution side channel targeting the Safari web browser present on Macs, iPads and iPhones. iLeakage shows that the Spectre attack is still relevant and exploitable, even after nearly 6 years of effort to mitigate it since its discovery. We show how an attacker can induce Safari to render an arbitrary webpage, subsequently recovering sensitive information present within it using speculative execution. In particular, we demonstrate how Safari allows a malicious webpage to recover secrets from popular high-value targets, such as Gmail inbox content. Finally, we demonstrate the recovery of passwords, in case these are autofilled by credential managers. View Our Paper Cite (BibTeX) Demo Videos. Recovering Instagram Credentials We show a scenario where the target uses an autofilling credential manager (LastPass in this demo) to sign into Instagram with Safari on macOS. Recovering Gmail Inbox Content Assuming the target is signed into Google on Safari for iOS, we recover the subject lines of the Gmail account's most recent messages on an iPad. Recovering YouTube Watch History We recover YouTube watch history from the Chrome browser for iOS, which is a shell on top of Safari's browsing engine due to Apple's App Store policy. The People Behind iLeakage. Jason Kim Georgia Institute of Technology Stephan van Schaik University of Michigan Daniel Genkin Georgia Institute of Technology Yuval Yarom Ruhr University Bochum architecture.fail Check out our lab website! Contact us at info@ileakage.com Frequently Asked Questions. The Basics Is my Apple device affected? Why is iLeakage significant? How can I defend against iLeakage? Is this attack detectable? Have malicious actors used iLeakage in practice? Am I at risk if I use credential managers? When did you notify Apple? For Tech-Savvy Readers What are JavaScript and WebAssembly? What is a Side Channel? What are Speculative Execution Attacks? How is iLeakage different from Spectre? How does iLeakage work? Is there more technical information? Miscellaneous What about other web browsers? Is the logo free to use? Acknowledgments This research was supported by the Air Force Office of Scientific Research (AFOSR) under award number FA9550-20-1-0425; an ARC Discovery Project number DP210102670; the Defense Advanced Research Projects Agency (DARPA) under contract HR00112390029 and W912CG-23-C-0022; the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) under Germany's Excellence Strategy - EXC 2092 CASA - 390781972; the National Science Foundation under grant CNS-1954712; and gifts by Cisco and Qualcomm. The views and conclusions contained in this website are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of the U.S. Government. Parts of this work were undertaken while Yuval Yarom was affiliated with the University of Adelaide. Copyright © 2023 Georgia Institute of Technology. All rights reserved.",
    "commentLink": "https://news.ycombinator.com/item?id=38015277",
    "commentBody": "iLeakage: Browser-Based Timerless Speculative Execution Attacks on Apple DevicesHacker NewspastloginiLeakage: Browser-Based Timerless Speculative Execution Attacks on Apple Devices (ileakage.com) 513 points by aw1621107 16 hours ago| hidepastfavorite189 comments jeroenhd 15 hours agoThings I&#x27;m missing from this FAQ:- Is this a Webkit vulnerability or a Safari vulnerability?- Does enabling Lockdown mode mitigate this vulnerability, seeing as mobile Safari doesn&#x27;t expose these dev settings?- What&#x27;s the timeline on the disclosure to Apple?Edit: they updated the page to answer the last question: When did you notify Apple? We disclosed our results to Apple on September 12, 2022 (408 days before public release). reply rfoo 15 hours agoparent> Is this a Webkit vulnerability or a Safari vulnerability?This is technically a Hacker News Favorite Processor a.k.a. M1&#x2F;M2 vulnerability. However all relevant CPUs on the market now has the same vulnerabilities so it became a feature so software has to be designed to mitigate it.It is impractical to get rid of all possible Spectre gadgets from WebKit, so the browser should be designed to leverage OS&#x27;s Spectre mitigation to deal with these vulnerabilities (i.e. isolate different websites in different processes).And, in the FAQ:> Ultimately, we achieve a out-of-bounds read anywhere in the address space of Safari&#x27;s rendering process.So, in my opinion, this is a Safari vulnerability: they hold Site Isolation wrong. reply jeroenhd 14 hours agorootparent>> Ultimately, we achieve a out-of-bounds read anywhere in the address space of Safari&#x27;s rendering process.> So, in my opinion, this is a Safari vulnerability: they hold Site Isolation wrong.Previously, something I would normally consider a Safari specific bug (IndexedDB storage not being isolated to its owning web page) also made it into Gnome Web and various other WebKit browsers. Site Isolation is enabled on other browsers but as an outsider I have no idea if that is normally handled by WebKit or by the surrounding framework.It looks like Gnome Web&#x2F;Epiphany is safe at least: https:&#x2F;&#x2F;gitlab.gnome.org&#x2F;GNOME&#x2F;epiphany&#x2F;-&#x2F;merge_requests&#x2F;448 but there are plenty of WebKit implementations out there, such as cars and video game consoles. reply fh9302 14 hours agorootparentThe merge request you linked is for cross-site navigation, which is a different feature flag than the cross-site window open recommended by this paper. reply jeroenhd 14 hours agorootparentHmm, unfortunate. It was tagged as \"site isolation\" in https:&#x2F;&#x2F;gitlab.gnome.org&#x2F;GNOME&#x2F;epiphany&#x2F;-&#x2F;blob&#x2F;master&#x2F;NEWS?r... so I thought it was the same feature. reply mdeeks 15 hours agoparentprevThey have an answer to your last question in the FAQ When did you notify Apple? We disclosed our results to Apple on September 12, 2022 (408 days before public release). reply mgiampapa 14 hours agorootparent408 days and it still requires a user to enable via a debug menu? This is not a good security look from apple. reply fguerraz 12 hours agorootparentI don’t know why they make it an Apple problem. They claim their attack works on all browsers, and it doesn’t look like it’s fixed on any of them. reply SXX 12 hours agorootparentThe only reason why attack works on all browsers is because Apple force all browsers on their platform to use Webkit. This is why it&#x27;s Apple problem. reply hmottestad 2 hours agorootparentThat’s only true for the iOS related platforms. Nice old MacOS still lets you run any browser you want, including one you’ve developed yourself if you so wish. reply depereo 11 hours agorootparentprevIt works on webkit. Firefox isn&#x27;t affected on MacOS, but it is on iOS because apple forces the use of webkit there. reply hu3 12 hours agorootparentprevIt only affects Apple processors. From the FAQ:Yes (with a very high chance), if you have a device running macOS or iOS with Apple&#x27;s A-series or M-series CPUs. This includes all recent iPhones and iPads, as well as Apple&#x27;s laptops and desktops from 2020 and onwards. reply fh9302 15 hours agorootparentprevThey added this FAQ point a couple minutes ago, that&#x27;s why the existing comments didn&#x27;t see it. reply jeroenhd 15 hours agorootparentprevThat wasn&#x27;t on the page when I read it.Good that they&#x27;ve added it. Disappointing to see that Apple has gone so long without releasing a fix. reply drvdevd 15 hours agoparentprevThis appears to be an architectural vulnerability where a speculative execution side channel similar to Spectre can be utilized within Safari or any other browser. The specifics of which environment is exploitable comes down to the specifics of the JavaScript-based gadget they use to trigger&#x2F;measure this side channel. It may be in the linked paper which I haven’t read yet. reply Aloha 11 hours agoprev> Am I at risk if I use a credential manager?> Not for the most part. In fact, we encourage using credential managers as opposed to trying to remember all of your passwords. In general, this is a better approach than reusing passwords or storing them insecurely. While iLeakage can recover credentials that are autofilled into a webpage, we note that many platforms require user interaction for autofill to occur.Why would use of a credential manager change this? If its leaking something out of memory it should effect all memory within the Safari process space? I&#x27;m not familiar enough in this area to understand this caveat. reply borski 9 hours agoparentThey&#x27;re basically saying: a) you are safer with a password manager than without, in general, despite it not providing any additional security for this particular attack; it is also not any more vulnerable. having a password manager doesn&#x27;t make you more likely to be caught by this attack (because the last thing they want to do is accidentally convince people to stop using them, in favor of &#x27;newpassword2&#x27;)b) you are safer yet if you turn off automatic autofill and instead use a hotkey or some other form of user interaction reply NobodyNada 10 hours agoparentprevI think they’re saying that you’re not more vulnerable with a password manager than you would be without one. I.e. they can recover passwords that have been autofilled into a page, just as if you entered the password manually, but they can’t read all your stored passwords directly out of your password manager. reply Aloha 10 hours agorootparentThat doesn&#x27;t jive to me with my read of their text. reply gumby 7 hours agorootparentFWIW I read it the same as the others. reply HALtheWise 4 hours agoparentprevOne of their demos was showing how they could recover a username&#x2F;password combination for a third-party site (Instagram), which was specifically possible because a password manager was in use that auto-filled those fields, putting them in memory. One possible reading of that is that you&#x27;d be immune if you didn&#x27;t use a password manager, didn&#x27;t let your browser remember the password, and just typed it in each time. There&#x27;s a bunch of reasons that&#x27;s a dumb objection:- Having a password manager is good for lots of other reasons, and at least means that only one website is compromised if the password is stolen- Their technique could probably also steal session tokens, which isn&#x27;t quite as bad as stealing a password but is still bad.- Password managers can be configured to require a click to fill in the password, which also defeats this attack. reply Thorrez 8 hours agoparentprev>Why would use of a credential manager change this?Change what?>If its leaking something out of memory it should effect all memory within the Safari process space?AFAIU, Safari generally puts different origins and extensions in different address spaces, so it&#x27;s not vulnerable to speculative execution attacks. This attack found a way to make 2 different origins share the same address space. I&#x27;m assuming the attack doesn&#x27;t apply to extensions. From the paper:>We begin by abusing Safari’s site isolation policy, demonstrating a new technique that allows the attacker page to share the address space with arbitrary victim pages, simply by opening them using the JavaScript window.open API. reply masswerk 14 hours agoprevPlease correct me, if I&#x27;m misinterpreting this, but is the framing regarding Webkit-only actually correct? The cache exploit seems to be a general one:> Here, we show that our attacks have near perfect accuracy across Safari, Firefox, and Tor.Moreover, is the attack via `window.open()` really specific to Webkit, or is Webkit just the only engine that was studied in depth for this study? Notably, `window.open()` implies a shared context between the calling window, which receives a reference to the newly created window, and the new window, which has a back reference via `window.opener`. Do other browser engines achieve perfect isolation? reply mccr8 13 hours agoparentChromium and Firefox have implemented site isolation on their desktop browsers, so pages that are not same site should never be loaded in the same process. On mobile browsers, Chromium&#x27;s site isolation is limited, and Firefox has not finished implementing it.https:&#x2F;&#x2F;www.chromium.org&#x2F;Home&#x2F;chromium-security&#x2F;site-isolati... reply masswerk 13 hours agorootparentNotably, the paper suggests that Webkit is even more hardened:> Taking this approach a step further, Safari follows a simple one process per tab model, where two web- pages are never consolidated into the same rendering process, even under high memory pressure and even if they share an eTLD+1 in their URLs. Instead, Safari spawns a new rendering process for each tab until the system runs out of memory.It&#x27;s only in the context of `window.open()` that this isolation strategy is defeated. Given that both the calling window and the newly opened window share mutual references to each other, isn&#x27;t the next side channel attack lurking around the corner, even if these windows are rendered by separate processes? reply mccr8 11 hours agorootparentThe paper does imply that, but I would disagree that it is more hardened. I would guess that this strict process per tab model is Safari&#x27;s attempt to get some degree of isolation despite not having true site isolation.> Given that both the calling window and the newly opened window share mutual references to each other, isn&#x27;t the next side channel attack lurking around the corner, even if these windows are rendered by separate processes?Non-same-origin opener references only allow very restricted operations. It is possible that there are undiscovered issues, but it is a lot less powerful than running in the same process. It isn&#x27;t like having a raw pointer from one window to another. reply cedws 16 hours agoprevI&#x27;m confused. This seems like a high severity issue, but the fix is behind a debug menu? Why has this been made public before a fix has been properly rolled out everywhere?This also goes to show how the side channel mitigations are totally useless and we should stop pretending such attacks have been fixed. It is not safe to run untrusted code, no matter how you sandbox it. Not on a host using a modern CPU running multiple applications. reply autoexec 11 hours agoparent> Why has this been made public before a fix has been properly rolled out everywhere?It looks like apple has had over 400 days to fix this. That&#x27;s already more time than I&#x27;d have given them. It&#x27;s far better that apple users are told what their risks are than to just leave apple users ignorant of the danger for another year+ by not saying anything while praying that nobody else is already aware of the flaw and quietly exploiting this.I&#x27;m all for giving companies time to fix their bugs, but at a certain point it becomes more irresponsible to not inform the people impacted. reply paulirish 15 hours agoparentprevI&#x27;m as confused about the mitigation status as others. However, the paper is clearer than the website:> That is, while the speculative JavaScript sandbox escape is still possible, an attacker becomes limited to reading their own address space and therefore their own data. Finally, at the time of writing, Apple’s patch is publicly available [57] and is implemented in Safari Technology Preview versions 173 and newer [58].[57] is https:&#x2F;&#x2F;github.com&#x2F;WebKit&#x2F;WebKit&#x2F;pull&#x2F;10169. At the bottom of it, an engineer continues to link ongoing hardening patches for window.open() + process isolation. reply kickdaddy 15 hours agoparentprevFor standard Safari (not technology preview) 17.0 on Ventura \"Swap Processes on Cross-Site Window Open\" is already enabled (and labeled Stable) for me. I did not enable it so it&#x27;s possible Apple already enabled this and their description of how to enable etc. is out of date.Edit: The below comment is correct, I was looking at a similarly named item \"Swap Processes on Cross-Site Navigation\" - it appears this is not enabled by default right now. reply t-sauer 15 hours agorootparentI also checked on my iPhone which I just upgraded to 17.1 and the flag is present and already enabled there as well.Edit: Seems like I got confused by the other very similar feature flag as well. reply fh9302 15 hours agorootparentprevAlso enabled by default for me on macOS 14.1.Edit: It appears I confused it with a similarly named flag. It doesn&#x27;t appear to be enabled on macOS yet by default. reply cedws 15 hours agorootparentprevThey disclosed this vulnerability today but it appears the information on the vuln scare site is outdated. Bit sloppy. reply fh9302 15 hours agorootparentI think users here, including myself, got confused because there is a feature flag that has a similar name.\"Swap Processes on Cross-Site Navigation\" is enabled by default, but this paper recommends \"Swap Processes on Cross-Site Window Open\". reply fh9302 16 hours agoparentprevIt&#x27;s unclear if they even reported this issue to Apple. reply matthewdgreen 16 hours agorootparentThey reported it to Apple a long time ago, over a year I think. The problem appears to be that it&#x27;s very hard to mitigate.ETA: To be clear, this isn&#x27;t me speculating. I spoke with one of the authors and asked this specific question. Apple hadn&#x27;t shared the mitigation with them as of a few days ago. reply fh9302 15 hours agorootparentThank you. Do you know if lockdown mode &#x2F; disabling JIT would mitigate the issue? reply matthewdgreen 15 hours agorootparentFrom what I’m told disabling JIT might do the job. With consequences to things breaking down. reply MatthiasPortzel 15 hours agorootparentprevFrom the site (perhaps it was updated to include this?):> We disclosed our results to Apple on September 12, 2022 (408 days before public release). reply HatchedLake721 16 hours agorootparentprevInterestingly, the YouTube videos are 13 months old. reply thfuran 15 hours agorootparentThat&#x27;s when they reported it to apple. reply cedws 16 hours agorootparentprevIt&#x27;s been reported>At the time of public release, Apple has implemented a mitigation for iLeakage in SafariHowever the site gives no details on timelines or a report at all.(edit) They have added a \"When did you notify Apple?\" to the FAQ. reply DannyBee 15 hours agorootparentLook at the faq reply cedws 15 hours agorootparentSee edit. replyschmichael 14 hours agoprev> We disclosed our results to Apple on September 12, 2022 (408 days before public release).Really interested to find out why Apple has (mostly) slept on this for over a year! reply KirillPanov 14 hours agoparentBecause they can.They are one of the CVE gods, so they can veto issuance of CVEs against their products. That kind of power means you can move as slowly as you please. reply semiquaver 9 hours agorootparentBS. Being a CVE numbering authority (of which there are several hundred) does not grant a veto against CVE issuance. They are allowed to issue CVEs on their products but by no means are they the only authority that may issue them for Apple vulnerabilities. reply viraptor 6 hours agorootparentAlso, you don&#x27;t need to issue a CVE to publish a vulnerability. You just make it public regardless and say CVE was denied for it. reply zenlambda 13 hours agoprevI thought I had seen a mention of a fix on the ileakage website and then it dissapeared. I almost thought I imagined the whole thing, but actually they have been making changes to the website only in the past hour.> \"To mitigate our work, Apple has just released iOS 17.1, iPadOS 17.1, and macOS Sonoma 14.1. Update your devices now!\"Which they have now reverted.https:&#x2F;&#x2F;github.com&#x2F;ileakage-authors&#x2F;ileakage-authors.github.... reply cedws 13 hours agoparentI think one of the authors of the paper are reading this thread because when I pointed out that there was no timeline on the site, they added a brief section to the FAQ. There is also some confusion here about whether a fix has been rolled out so I think they&#x27;ve also become confused. reply kuhsaft 12 hours agoparentprevStrange. I’ve updated to iOS 17.1 and under Settings -> Safari -> Advanced -> Feature Flags, the `Swap Processes on Cross-Site Navigation` is there and is enabled by default. I wonder if it’s different from `Swap Processes on Cross-Site Window Open` on macOS. reply t-sauer 1 hour agorootparentIt is different. The cross-site navigation flag is a couple of years old. It was enabled by default for iOS in November 2018 for example https:&#x2F;&#x2F;github.com&#x2F;WebKit&#x2F;WebKit&#x2F;commit&#x2F;e191fc8c412850cb9fd0... reply st3fan 12 hours agorootparentprevalso on by default on 17.0.3. i definitely did not change this. reply ngneer 11 hours agoprev\"We note that iLeakage is a significantly difficult attack to orchestrate end-to-end, and requires advanced knowledge of browser-based side-channel attacks and Safari&#x27;s implementation\" - possibly the reason Apple is not losing sleep over this? reply BearOso 8 hours agoparentSo difficult to orchestrate that it&#x27;s unfeasible, so there&#x27;s effectively 0% risk involved.Yet another scary nickname and domain name for it says unprofessional and untrustworthy to me. reply viraptor 6 hours agorootparentIt&#x27;s been shown possible, so: 1. There&#x27;s a number of well funded agencies which would be happy to abuse it. They have both the skills and time to do it. 2. Showing that Spectre is possible on Intel created a steady stream of similar attacks. Other groups are likely already looking into it and may come up with much more feasible options. reply userbinator 6 hours agorootparentprevThe security industry runs on fear, so that&#x27;s not so surprising.IMHO if you&#x27;re being targeted by a nation-state actor, or otherwise someone who knows enough about your hardware and software environment to be able to do something like this, there are far more important things to worry about.All these side-channels require a lot of setup and can be easily perturbed by other unpredictable sources of noise in the environment. reply allan_s 1 hour agoprevI don&#x27;t know how to point out an improvement> defaults write com.apple.Safari IncludeInternalDebugMenu 1.if you get> Could not write domain &#x2F;Users&#x2F;YourUser&#x2F;Library&#x2F;Containers&#x2F;com.apple.Safari&#x2F;Data&#x2F;Library&#x2F;Preferences&#x2F;com.apple.Safari; exitinginstead you can check in the \"develop\" menu of safari , and section \"feature flags\" reply vinay427 24 minutes agoparentAt least for me, this was caused by a OS security permission: enabling Full Disk Access for the terminal emulator app in Security & Privacy (System Preferences) fixed it for me and the setting can obviously be reverted afterwards. reply jeron 13 hours agoprev> if you have a device running macOS or iOS with Apple&#x27;s A-series or M-series CPUs. This includes all recent iPhones and iPads, as well as Apple&#x27;s laptops and desktops from 2020 and onwards.as a rare Intel Mac owner, I guess I am not affected then reply lern_too_spel 9 hours agoparentIf you&#x27;re on MacOS, you can simply not use Safari. If you&#x27;re on iOS, you have to use lockdown mode, which is the only safe way to use an iPhone. Any benchmarks done without lockdown mode should be considered as useful as CPU benchmarks run with mitigations=off. reply kevincox 9 hours agorootparentThat&#x27;s absolutely not fair. Lockdown mode isn&#x27;t the default and should only provide defense in depth. Devices running the default configuration are absolutely expected to be secure. reply lern_too_spel 6 hours agorootparent> Devices running the default configuration are absolutely expected to be secure.That might be the customer&#x27;s expectation, but that isn&#x27;t what Apple is providing. We&#x27;ve time and again seen that the default configuration is not secure. Apple has known about this bug for more than a year now, and the only protection remains to use lockdown mode. reply timvisee 1 hour agoprevAnother good reason to allow other browser engines on iOS devices. reply avodonosov 6 hours agoprevIt must be time consuming to read other process&#x27; memory through such a side channel. Then limiting JS execution time for web pages should mitigate this vulnerability?By default only small amount of js execution is allowed for web pages (small event handlers and such). If a page tries to execute more js, browser should ask user&#x27;s permission to extend the limit. (Maybe several levels of the limit should be supported?). Some web pages could be added to a permanent list of trusted domains with permanently increased limit.Upd: 4-5 minutes, in the first video (https:&#x2F;&#x2F;youtu.be&#x2F;Z2RtpN77H8o?si=XB4oI9ner8pFTIqN) - see the time on the top right of their screen. When the attack starts it&#x27;s 5:22, ends at 5:27. reply piperswe 6 hours agoparentThis will likely just fatigue users, who will just keep tapping \"yes\" on the prompts to make the websites work. reply avodonosov 5 hours agorootparentMost web sites will not be affected. Also, a well designed notification dialog, with clear explantion and useful options - allow once, forbid, allow and add the website to trusted domains for N days, etc. - will help users. reply userbinator 6 hours agorootparentprevThe point is that most sites don&#x27;t need that much intense JS processing.Also, a \"no, and don&#x27;t ask again\" button would be very useful in this case. reply codezero 11 hours agoprevIf you&#x27;re getting an error when trying to run:defaults write com.apple.SafariTechnologyPreview IncludeInternalDebugMenu 1Make sure your terminal has Full Disk Access and try again. reply jesseendahl 14 hours agoprev>Finally, we demonstrate the recovery of passwords, in case these are autofilled by credential managers.Can&#x27;t wait for passkeys to replace passwords everywhere. reply drvdevd 15 hours agoprevFrom a cursory review of the FAQs on the page it appears one mitigation might be to only keep one browser tab open at a time? They appear to be using timers and a cache eviction gadget to infer the state of other browser tabs&#x2F;processes so it’s unclear what they can recover if you are not concurrently having a session to a particular site outside the gadget execution context. ??? reply lights0123 15 hours agoparentThey use window.open on a mouseover event listener to open another page. Even if you close it, they still are able to read from it as that memory isn&#x27;t immediately zeroed or returned to the OS. reply missblit 8 hours agoparentprevBesides windows.open I&#x27;d wonder if iframes could also be vulnerable if they launch in the same process.Chrome and Firefox both support Out-Of-Process Iframes as part of their security setup; though I&#x27;m not sure if Firefox has it enabled by default yet. Firefox even drew some lovely pictures about it here: https:&#x2F;&#x2F;hacks.mozilla.org&#x2F;2021&#x2F;05&#x2F;introducing-firefox-new-si... reply Kiboneu 13 hours agoprevThe website says that you can enable the “Swap Processes on Cross-Site Navigation” flag only on macos; actually on iOS you can access this flag via Settings -> Safari -> Advanced -> Feature Flags. I think this is the ios equivalent to the macos mitigation that the authors are suggesting. reply jacopoj 12 hours agoparentThat&#x27;s a different flag. The website says you should enable \"Swap Processes on Cross-Site Window Open\" reply thoughtsimple 13 hours agoparentprevIt also seems to be on by default on iOS 17.1. It doesn&#x27;t seem to on by default in MacOS Sonoma (14.1). reply Belopolye 16 hours agoprev> However, this mitigation is not enabled by default, and enabling it is possible only on macOS.Is this not covered by lockdown mode on iOS? Crazy. reply fh9302 16 hours agoparentThe paper mentions JIT multiple times, lockdown mode disables JIT. I hope someone else can confirm it but it appears it would be mitigated in this case. reply kevincox 9 hours agorootparentIt seems like JIT would make the attack easier as faster code will get more accurate timings but it doesn&#x27;t seem to really stop the attack. reply sinuhe69 6 hours agoprevAll auto-password filling on iOS requires 2FA so Apple doesn’t have to fear or how it’s to explain that Apple hasn’t mitigated this attack vector yet?For websites, leaving the site auto signed-in seems the more practical way to exploit the vulnerability, so don’t leave sensitive site auto signed-in and use a native app for them instead is the natural way of mitigation? reply Razengan 1 hour agoprevI just want to say how comically bizarre the whole OS&#x2F;Browser dichotomy&#x2F;duplication has become. reply archo 6 hours agoprevIs this mitigated with 25 oct updates https:&#x2F;&#x2F;support.apple.com&#x2F;en-au&#x2F;HT201222 reply sroussey 15 hours agoprevwindow.open() strikes again reply fh9302 15 hours agoparentDoes this mean you would have to visit a malicious website, that malicious website would open a different website with window.open(), and from this they can read data through this side channel attack? reply paulirish 14 hours agorootparentYes. But it&#x27;s incredibly hard to pull off.My understanding is that the theory of this attack was introduced with Spectre. iLeakage adds enough research to create a working proof-of-concept, plus acknowledgment that, as of last year, it wasn&#x27;t addressed in Safari.More on site isolation (the functionality that mitigates these attacks):https:&#x2F;&#x2F;w3c.github.io&#x2F;webappsec-post-spectre-webdev&#x2F; https:&#x2F;&#x2F;www.chromium.org&#x2F;Home&#x2F;chromium-security&#x2F;site-isolati... https:&#x2F;&#x2F;blog.chromium.org&#x2F;2021&#x2F;03&#x2F;mitigating-side-channel-at... reply jefozabuss 1 hour agorootparentI think it&#x27;s not that hard to pull this off as you can disguise this with a \"social login\" feature. E.g. imagine a website promoting raffles &#x2F; free prizes if you log in with fb&#x2F;insta&#x2F;etc, there are way too many gullible users who&#x27;d use these pages.I&#x27;d not be surprised if accounts used in troll farms &#x2F;bots&#x2F; are stolen this way. reply mccr8 11 hours agorootparentprevThere have long been working Spectre attacks. From skimming the paper a bit, I think the contribution of this work is that they have come up with an attack that works on Apple&#x27;s processors, as well as bypasses for a number of mitigations WebKit has (that fall short of site isolation). reply jeroenhd 15 hours agorootparentprevThat seems to be the implication of this attack. The mitigation referenced by the web page are being rolled out in newer versions of Safari and iOS, according to other comments in these threads.The mitigation seems to be to split the process space.From the paper: Attacking Gmail. With Google being one of the world’s largest email providers, it is highly likely for a target to be signed in with their personal account. By having the event listener inside the attacker’s page access execute window.open(gmail.com), we can consolidate the target’s inbox view into the attacker’s address space. We then leak the contents of the target’s inbox, see Figure 11. Recovering Android Text Messages. Android users can send and receive text messages from a browser window by pairing their phone with Google’s Messages platform. Thus, by opening Google Messages using window.open(), we can recover a target’s text messages without attacking their mobile phone itself. reply wutwutwat 14 hours agoprevWhat is the point of the dedicated vulnerability marketing websites? Like, for real, why do people buy a domain, configure dns, design a full webpage, setup some server somewhere?Is there some secret world I don&#x27;t know about that&#x27;s driven by how banger your vulnerability disclosure presentation is? Every one anymore has a full site. Is this what it takes to get attention these days? Everything, including computer bugs, needs a marketing campaign? Every time I see these sites I roll my fucking eyes at how ridiculous it is that people keep making them, but it seems to only be increasing in occurances.Can someone explain this to me because I feel like I&#x27;m missing something. Just feels like peak consumerism and attention economy bs that shouldn&#x27;t be needed imo, but I hope I&#x27;m missing some crucial thing that makes these valid reply saagarjha 14 hours agoparentIt&#x27;s because when a news website wants to talk about the vulnerability they get a webpage to link to that is canonical and has all the information someone would want to get an accurate description of the issue. reply wutwutwat 14 hours agorootparentIsn&#x27;t that exactly what https:&#x2F;&#x2F;www.cve.org&#x2F; would be for? reply saagarjha 14 hours agorootparentNo, that&#x27;s the place where you get an identifier for the issue. You still need a place with answers to frequently asked questions, more details as to how the attack works, artifacts and proof-of-concept code, etc. reply wutwutwat 14 hours agorootparentCVE&#x27;s usually link to the SCM issue&#x2F;pull request where the conversation, and reproduction takes place. We&#x27;ve been finding and patching vulnerabilities for decades without the need for dedicated websites to inform folks, so that reason for these sites needing to exist doesn&#x27;t make any sense. reply mrmuagi 13 hours agorootparentOn CVE I see a fact-oriented bug tracker style database of CVE issues with a schmorgus board link&#x2F;reference barf on each CVE page, but on the OP site I see a really well presented (with videos, faq, paper) description of the issue? It does feel self-marketing yes, but it&#x27;s entirely deserved if they found the issue?I&#x27;m sure keen folk can digest SCM pull requests, but that population is a super minority I think to well presented content disseminated on youtube, sites, blogs, etc.I don&#x27;t think CVE being mandated as the only place vulnerability&#x2F;conversations are had would be optimal, no? reply JadeNB 12 hours agorootparent> schmorgus boardI know HN frowns on grammar-policing comment, and rightly so; but I thought nonetheless you might like to know (and it looks so much more formal this way anyway!) that it&#x27;s \"smörgåsbord\" (or the diacritics are commonly omitted in English). reply dskrvk 8 hours agorootparentPronounced [ˈsmœ̂rɡɔsˌbuːɖ] reply fullspectrumdev 46 minutes agorootparentprevBahahaha no, the vast majority of CVE’s are at best a vague description, a severity score, and no context. reply saagarjha 14 hours agorootparentprevYeah, that&#x27;s not how Apple&#x27;s CVEs work. reply eep_social 14 hours agorootparentprevWould you send your CFO there though? CTO sure, of course but there’s a whole word of non-technical people who need to consume this kind of information nowadays. reply wutwutwat 14 hours agorootparentI wouldn&#x27;t send my CFO anywhere because it has jack shit to do with him and if it ever did, my CTO who would be fine looking at a CVE website and would have zero issue distilling the problem down when HE talks to the CFO, since talking to people like that is part of the CTOs job reply eep_social 13 hours agorootparentThat’s certainly your prerogative! reply HtmlProgrammer 14 hours agorootparentprevYes reply coryfklein 13 hours agoparentprevThe amount of time and effort they spent setting up the website – since this is 2023 and websites are super easy to set up – is probably dwarfed by the amount of time they spent on the vulnerability itself. reply wutwutwat 13 hours agorootparentThe time and effort isn&#x27;t the concern, the precedent that a vulnerability isn&#x27;t severe unless it has a marketing campaign these are setting is, and based on some comments here, it&#x27;s taking place reply calibas 12 hours agorootparentThey waited over a year before disclosing the vulnerability. Since Apple didn&#x27;t fix it in that time, they&#x27;re now relying on negative publicity to pressure Apple into fixing the issue.And the problem here is that Apple and other companies don&#x27;t address these vulnerabilities until someone forces their hand. That&#x27;s why a \"marketing campaign\" is required, unfortunately. reply k8svet 14 hours agoparentprevThis site regularly upvotes posts on X (nee Twitter) and Medium and other sites that actively nag me. It would take me less than 6 minutes to register a domain on njalla, pay in crypto, add the DNS to cloudflare, and upload some static files to a GitHub repo. And no nagware! Even if it is self promotion, I couldn&#x27;t be bothered to whine about this when I&#x27;m inundated with far more bullshit from far more prominent, frequent actors on a daily basis. reply wutwutwat 14 hours agorootparentI don&#x27;t get bothered by people doing it because they are able to, or care how long it takes them to spin it up, good for them. The thing that bothers me is that disclosing sec vulnerabilities isn&#x27;t a popularity contest, and as you can see from other comments here, people are gauging the severity of the vulnerability based on if it has a fucking marketing website or not. That&#x27;s not a good pattern to keep enforcing imo reply k8svet 14 hours agorootparentIf people are actually judging the importance of a vuln based on \"it has a domain\" then my issue would be with them.People have all sorts of miscalibrated heuristics with which they judge things. Regardless of the originators intentions. reply wutwutwat 13 hours agorootparentTreat the problem not the symptoms. People can&#x27;t use the marketing site to gauge severity if they don&#x27;t exist. reply ziddoap 13 hours agorootparentprevWhy is your question not directed at the people that bother you, if that is the case?Seems rather unproductive to question why the site exists when your problem is with people using the existence of the site to make decisions. reply wutwutwat 13 hours agorootparentMy problem is with the sites existing, which is what my original comment is asking about. The people using them to guage severity is a symptom of the problem of these sites being a thing, and is naturally going to happen in a world like this. If the website marketing doesn&#x27;t exist, the people using them to gauge severity won&#x27;t be able to do so. Treat the problem not the symptoms. reply ziddoap 13 hours agorootparentIf I had a website that posted a sci-fi story and people misinterpret the story as being real and factual, should I take my website down or should people refresh themselves on how to differentiate sci-fi from reality?I would argue that the people who think the existence of a website is a good gauge for vulnerability severity need to have a refresher on how to gauge vulnerability severity. The inability&#x2F;lack of education in how to assess severity is the root of the problem in my opinion. reply wutwutwat 12 hours agorootparentI have no idea how to go about responding to your hypothetical question, people reading fiction and thinking it&#x27;s real doesn&#x27;t compare to people being conditioned to not care about sec vulns unless it has a dedicated website with pretty logos.War of the Worlds was broadcast and people freaked out that aliens were invading. I don&#x27;t think they tracked each of those people down and told them to not be so stupid, they started adding disclaimers to the broadcasts so people coming in late or whenever they would know it was a story and fiction. They fixed the problem not the symptoms. reply ziddoap 12 hours agorootparentAgree to disagree, I guess. replycrimsontech 13 hours agorootparentprevEverything seems to be a popularity contest now. I’ve seen people with the job title “Cyber Influencer”.It could just be that the researcher is immensely proud of their work and wants to show it off with its own website, logo, clever name, etc. reply wutwutwat 13 hours agorootparentThey should be proud, and I&#x27;m not bothered by that one bit, the work they did is a great thing. This website existing or not should have no bearing over the good work they did or them being proud of the work they did. reply Domenic_S 14 hours agorootparentprev> domain on njalla, pay in crypto, add the DNS to cloudflareone of these things is not like the other reply judge2020 14 hours agoparentprevThis is hosted on GitHub Pages, so it takes very minimal resources to setup and keep running. The domain is also likely $10, assuming they didn&#x27;t need to pay a squatter for it.I think it&#x27;s just a trend for any any huge-scale vulnerability research team to put together a website for it, as that amount of effort will indicate a certain level of attention the exploit requests of the reader &#x2F; the security community at large.And it doesn&#x27;t always happen. Log4shell, for example, was not its own website: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=29504755 reply wutwutwat 14 hours agorootparent> as that amount of effort will indicate a certain level of attention the exploit requests of the reader &#x2F; the security community at large.Feels like a dangerous way to gauge the severity of issues. What if the discloser doesn&#x27;t have the funds or the skills to setup a dedicated website? Will it not get any attention since there&#x27;s no yodawgiheardyoulike0days.com website to float up to the top of HN? This is what CVE severity scoring is for and what should be used, not the presence of a dedicated website, no? reply saagarjha 13 hours agorootparentCVE scoring is about as worthless as whether a vulnerability has a website. reply wutwutwat 13 hours agorootparentMaybe, but it&#x27;s at least an agreed upon system and a centralized database and format, which can be improved since a org is behind it with the goal to make sec vul disclosure the best it can be. The wild west of marketing websites isn&#x27;t advancing towards any sort of shared understanding. reply saagarjha 13 hours agorootparentI am 100% on board with free and easy assignment of CVEs and a central database of them. I just don&#x27;t think they are a good place for keeping vulnerability details, because it is too rigid. Having a link to relevant details is good enough, and if the link happens to just include everything in it then I&#x27;m fine with that. reply schiffern 12 hours agorootparentprev\"All crisis is profit.\" :)Clearly we need Vulnerability Website as-a-Service (VWaaS). .(joking or not? even i don&#x27;t know! What I know is, there seems to be a fine line between cynicism and prophecy...) reply wutwutwat 12 hours agorootparentYou joke but I bet it&#x27;s already in the YC fall 23 batch reply smoldesu 13 hours agorootparentprev> What if the discloser doesn&#x27;t have the funds or the skills to setup a dedicated website?Evidently they just get ignored, if their account of direct disclosure to Apple is anything to go off of. reply auggierose 13 hours agoparentprevIt&#x27;s a paper. Plenty of papers come with their own website. The purpose of a paper is to make its findings publicly accessible, so putting in the extra work for a website to accompany it is understandable. reply gosub100 13 hours agoparentprevmaybe they want to maximize their career opportunities? It&#x27;s gotten better over the years, but for a long time security researchers and white-hats toiled away and never even got a \"thanks\", sometimes they got legal threats. If I had the patience to work in this industry I&#x27;d want to maximize my returns. reply huijzer 13 hours agoparentprev> Like, for real, why do people buy a domain, configure dns, design a full webpage, setup some server somewhere?Same can be said for personal blogs. The purpose is showing off. By the way, setting up a server nowadays is ridiculously easy and cheap. If you have done it a few times and you use a simple static site stack with CI then you can have a site live in 15-30 minuted including SSL and hosting for free (GitHub Pages, Cloudflare, or GitLab Pages for example). reply wutwutwat 13 hours agorootparentPersonal blogs, or any other website, have nothing to do with creating branding and dedicated websites to disclose security vulnerabilities. Computer bugs have logos. reply Reptur 13 hours agoparentprevIn think its plausible that hosting it yourself ensures that companies can&#x27;t exert pressure to have it removed. reply weaksauce 13 hours agoparentprevit&#x27;s a webpage promoting a vulnerability they found and a paper they wrote and is owned by georgia institute of tech. they ~~have servers~~ are just using github pages and a budget already i&#x27;m sure for marketing. this is marketing. reply staplers 13 hours agoparentprevHave developers really come full circle to \"why do we make websites?\" reply logn 7 hours agorootparentYes, we dream of an alternate timeline with CVE promos on TCP&#x2F;IP HyperCard https:&#x2F;&#x2F;www.wired.com&#x2F;2002&#x2F;08&#x2F;hypercard-what-could-have-been... reply wutwutwat 13 hours agorootparentprevYes, that&#x27;s what my comment was asking, why do we make websites, you nailed it, and I thank you for the concise way of asking what I took so many more words to ask above. reply HtmlProgrammer 14 hours agoparentprevNope you’ve got it in one reply Flockster 16 hours agoprev> However, iOS has a different situation. Due to Apple&#x27;s App Store and sandboxing policies, other browser apps are forced to use Safari&#x27;s JavaScript engine. That is, Chrome, Firefox and Edge on iOS are simply wrappers on top of Safari that provide auxiliary features such as synchronizing bookmarks and settings. Consequently, nearly every browser application listed on the App Store is vulnerable to iLeakage.This should be a reason to lift this policy and allow different engines on these devices! reply frizlab 15 hours agoparentBecause increasing the attack surface would somehow increase the security? reply robocat 15 hours agorootparentYou have a laptop with a browser. You buy a laptop with a more secure browser. You have increased attack surface yet security is improved.It is quite possible a native Chrome on iOS would be more secure. reply frizlab 13 hours agorootparentAbsolutely not. You now have a computer where you have chromium’s flaws for your daily internet browsing and Safari(or whatever native browser is on the OS)’s flaws for the native apps that use the native browser.Yes indeed, you’re still free not to use these apps. But would you? At some point why not get a computer where the internet is the “OS” (a chromebook for instance……… where guess what? you cannot use an alternate rendering engine. Interesting, no?) reply m-p-3 11 hours agorootparentTechnically you can run an alternative browser on ChromeOS under the form of an Android app, or by running a different one in the Linux sandbox. reply HideousKojima 15 hours agorootparentprevIn exchange for decreasing the amount of affected users and application? Absolutely. No one would be forced to use a non-Safari browser.A software monoculture means that a bug for one is a bug for all. reply frizlab 15 hours agorootparentBut you’d also get apps that decide to use chromium for whatever reason outside of the user’s control, thus making these users vulnerable to chromium flaws…In short, you increase the possibilities, you increase the attack vectors. There is no way around it AFAIK. reply HideousKojima 15 hours agorootparent>outside of the user’s controlUsing the app at all is in the user&#x27;s control. The current state of iOS is that they don&#x27;t have any control whatsoever. reply frizlab 13 hours agorootparentHere’s an example: I know I have the control of not using youtube because I really dislike gougle. Would any of my family member? Absolutely not. Would they use their browser if they could in the youtube app? Most definitely yes.So no, it is most definitely not in the user’s control. reply smoldesu 5 hours agorootparent> Would they use their browser if they could in the youtube app? Most definitely yes.> So no, it is most definitely not in the user’s control.You&#x27;re comparing impulse control to hard runtime limitations. It doesn&#x27;t really track; I understand your apprehension, but if none of your family members notice or care then maybe Google&#x27;s hypothetical solution here worked? If that&#x27;s an undesirable outcome for you, I think you should be lobbying for better alternatives instead of using it as a boogeyman to excuse iron-grip ecosystems. Two wrongs aren&#x27;t going to make a right here. reply zimpenfish 15 hours agorootparentprev> Using the app at all is in the user&#x27;s control.Not if it is mandated by work, home, family, government, etc. reply wyldberry 15 hours agorootparentIf it&#x27;s mandated then they never had the control there to begin with. reply jwells89 13 hours agorootparentprev> A software monoculture means that a bug for one is a bug for all.That&#x27;s true, but the situation is not improved by a Chromium&#x2F;Blink monoculture. It&#x27;s the same problem with a slightly different flavor.So yes, iOS should be opened to third party engines, but at the same time steps should be taken to stymy Chromium&#x27;s dominance. reply walterbell 16 hours agoparentprevBrave on iOS can disable Javascript on all web pages except those you trust by opt-in. reply jmull 12 hours agoparentprevThey should allow different engines, but this isn&#x27;t a reason. Different browsers have different vulnerabilities, but aren&#x27;t substantially more secure as far as I&#x27;m aware. reply fsflover 16 hours agoparentprevBut it&#x27;s for your security! Not joking: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=21587191 reply paulmd 15 hours agorootparentunironically, having three browser engines is three times the attack surface, what&#x27;s the problem with that claim?uarch \"multiculture\" hasn&#x27;t saved us from architectural attacks, actually it probably increases the total number of vulnerabilities, and browser multiculture won&#x27;t magically make them all perfectly secure and perfectly implemented either. if each browser is only 99% secure now you have 0.99^3 total security, you have ~tripled your odds of a vulnerability existing in at least one of your apps at a given time.there are other arguments in favor of sideloading, but, I don&#x27;t really see how multiple browsers is a security improvement, actually it seems unironically much worse on that front, since now you are depending on three teams of engineers (two of which are not even at your company) to execute perfectly and never have a vulnerability, in what is one of the highest-privilege applications (essentially the canonical \"full control\" app). People want their browser to have access to location info (thus bluetooth&#x2F;wifi settings), camera, camera roll (thus long-term location history), microphone, everything. The fewer applications that exist like that the better you are.I can&#x27;t fathom anyone saying that they should, for example, run three different high-privilege pieces of software in their production systems, when one would do fine - f.ex you wouldn&#x27;t run nginx, apache, and keycloak all mixed into your environments. That would obviously inflate the risk of being subject to at least one attack. Why is the browser different? reply Veserv 15 hours agorootparentBecause you are not running all of them at the same time, you are only running one of them. The one you choose to run can be better than the current one you are forced to use and thus your attack surface has decreased because you are not using the worse ones.Having options does not reduce your security except in-so-far as exposing the underlying mechanism allowing choice increases your attack surface, and even then that does not inherently reduce your security. A mechanism allowing multiple implementations requiring more available attack surface, but which is used by a high quality application to provide a highly secure implementation is still better than a reduced mechanism designed to only allow a single application when that application provides a low quality implementation.Also, the argument you just proposed could just as easily be used to argue that we should disallow any other operating system other than Windows 3.1 since having more operating systems just increases the attack surface. That is patently absurd for the reasons I just stated above and is why your argument is fatally flawed. reply planb 14 hours agorootparent> Because you are not running all of them at the same time, you are only running one of themThis is not true. The moment Apple allows different browser engines, my Gmail app would use blink. As a browser, I’d maybe use Firefox&#x2F;gecko and all Apple apps would still use the embedded WebKit.Yes, this is my choice and I would do it knowing I’m increasing my attack surface, but apple‘s reasoning is not false… reply AnthonyMouse 14 hours agorootparentA given application is still not using more than one browser engine. If there is a vulnerability in Webkit and all apps have to use Webkit, all apps are vulnerable. If only a third of apps use Webkit, only a third of apps are vulnerable. A different third of apps might be vulnerable if there is a vulnerability in Blink. When the security record of each browser engine is comparable, this isn&#x27;t a net increase in exposure, it just averages out to the same. When the others have a better record -- and Google and Mozilla have both introduced a number of novel security and privacy features -- then the net exposure goes down.Meanwhile having the choice is a security advantage because a) the user could choose the one with the best security record, whether or not it&#x27;s Apple&#x27;s and b) if there is an active vulnerability in Safari today then the user can use Chrome or Firefox today, and then do the reverse on the day there is an active vulnerability in Chrome.The main concern people seem to have with this is the one which is also caused by Apple -- apps might embed a browser engine and then if it&#x27;s vulnerable you have to update lots of apps. But this is only because of their lacking support for independent libraries. If the Firefox browser engine was provided as an iOS library by Mozilla then Mozilla would update the library and every app that uses it would get the update at once. That problem is only caused by this not being supported.And is a problem that extends to more than browser engines. Apps can&#x27;t use their own browser engines, but they might incorporate some common third party code that doesn&#x27;t require JIT compilation, and then if someone finds a vulnerability in that code you still have to update a zillion apps. Specifically because the code isn&#x27;t distributed as a dynamic library by its developers and instead gets copied into each app independently -- which not only impairs security but takes up more storage and memory to have multiple copies of the same code. reply planb 1 hour agorootparent> If the Firefox browser engine was provided as an iOS library by Mozilla then Mozilla would update the library and every app that uses it would get the update at once. That problem is only caused by this not being supported.We don&#x27;t want to go back to DLL hell, do we? History has shown that this approach does not scale, and definitely not on mobile. reply astrange 12 hours agorootparentprev> A given application is still not using more than one browser engine.That doesn&#x27;t seem true, I can easily imagine an app that&#x27;s based on Firefox but can still cause a WebKit page to open, you just need a system API that uses WebKit.> If the Firefox browser engine was provided as an iOS library by Mozilla then Mozilla would update the library and every app that uses it would get the update at once.That&#x27;s not how the app update lifecycle works, they&#x27;re all independent. (Otherwise they&#x27;d break a lot more easily.) reply hotnfresh 12 hours agorootparentI’ve worked on Android apps that embed a browser engine but also use native web views. I doubt it’s rare. They’d exist on iOS too, if it were possible. replybratwurst3000 15 hours agorootparentprevMaybe three times the browser engine, three times the chance to have a safe engine at the end? reply geekteq 14 hours agorootparentAs far as I understand, The attack surface will be reduced in the end. Here is why: The amount of processed content is the same, no matter if you use one browser engine on single device or many. So if we assume that browser is 99%, the chance to _not_ hit the vulnerable page is 99%. However, by segregation of browser data between engines, the exposure of confidential information is reduced in case of breach reply fsflover 12 hours agorootparentprev> unironically, having three browser engines is three times the attack surface, what&#x27;s the problem with that claim?If only one third of the users run a vulnerable browser, the other 2&#x2F;3 would be safe. Security through compartmentalization. reply HatchedLake721 16 hours agoparentprevWhat next? iOS security vulnerability? This should be a reason to lift this policy and allow different operating systems on these devices! &#x2F;s reply smoldesu 13 hours agorootparentIf Europe&#x27;s governments weren&#x27;t so reliant on Apple&#x27;s surveillance, maybe their regulators would demand that. reply HatchedLake721 12 hours agorootparentLol what? You can&#x27;t just drop a bomb `Europe relying on Apple&#x27;s surveillance` without any details reply smoldesu 12 hours agorootparenthttps:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Five_Eyes> In early 2014, the European Parliament&#x27;s Committee on Civil Liberties, Justice and Home Affairs released a draft report which confirmed that the intelligence agencies of New Zealand and Canada have cooperated with the NSA under the Five Eyes programme and may have been actively sharing the personal data of EU citizens. The EU report did not investigate if any international or domestic US laws were broken by the US and did not claim that any FVEY nation was illegally conducting intelligence collection on the EU.For reference, this is the same NSA that has boasted about having inroads at companies like Google, Microsoft and Apple. The same FIVE EYES that recently \"somehow\" found the damning evidence to accuse India of conspiring to kill a foreign dissident.Europe relies on America&#x27;s surveillance network, and America&#x27;s surveillance network relies on ___________. replylondons_explore 15 hours agoprevSo, Apple is letting secrets from one origin be in the same OS process as running code from another origin?Isn&#x27;t that shoddy security architecture 101? reply masswerk 14 hours agoparentI&#x27;m not entirely sure about this. The paper mentions that in Chrome and Firefox \"different rendering processes handle pages with different effective top-level domain plus one sub-domain (eTLD+1).\" (Meaning, windows in the same eTLD+1 group still share a process.) To proceed,> \"Taking this approach a step further, Safari follows a simple one process per tab model, where two web- pages are never consolidated into the same rendering process, even under high memory pressure and even if they share an eTLD+1 in their URLs. Instead, Safari spawns a new rendering process for each tab until the system runs out of memory.\"This suggests that Safari&#x2F;Webkit is even more hardened in general. It&#x27;s only in the context of `window.open()` that this isolation strategy is defeated. Notably, `window.open()` somewhat implies a shared context between the calling window and the newly opened one, since both windows receive a direct reference to the respective other one. I can&#x27;t see any description, how other browser engines would handle this differently and would achieve perfect isolation, or, in case these were explored in similar depth, might yield similar vulnerabilities. reply londons_explore 15 hours agoparentprevYes. Even without spectre, this would let anyone with any webkit exploit get secrets from any other website.Browsers with sandboxed multi-process architectures have been around since 2008, precisely because experts realised that rendering engines are so complex they cannot reasonably be secured, so need to be sandboxed for protection.Unfortunately, I suspect that security experts within Apple were well aware of this, but were overruled because iOS devices tend to not have much RAM, and the user experience would be severely degraded by doing proper process-per-origin isolation, due to RAM exhaustion. reply johncolanduoni 14 hours agorootparentChrome on Android also opted not to deploy their version of full per-origin isolation for the same reason. However Chrome does create a new process for cross-origin navigation, which is sufficient to protect pages which disable iframe embedding. That&#x27;s what Apple missed here. reply fh9302 14 hours agorootparentSafari has protection against cross-site navigation enabled by default. The issue here is cross-site window open. reply pvg 15 hours agorootparentprevThat is a rather odd self-socratic method of commenting. reply londons_explore 14 hours agorootparentI usually do it because I want to pose a question and then give one viewpoint of answer to that question, while leaving the floor open to other viewpoints&#x2F;opinions.If done well, it leads to a better comment-reading experience. Not sure I did it well in this example though. reply pvg 13 hours agorootparentIt ends up looking like sockpuppetry gone wrong and I think it kind of gives you an excuse to pose the opening question in a (however inadvertent) flameframy, scarecrowy way. reply npunt 14 hours agorootparentprevI like the style, your comment created a clear train of thought and context reply Veserv 14 hours agorootparentprevNo. On page 9, Section 5.1 they state that by default Safari will spawn one process per tab and they provide less consolidation by default than Firefox or Chrome. It is only window.open(), which is used to create popups, that was not updated from the old design that did not use isolation to the new model that does support isolation. The \"security experts\" at Apple were just too incompetent to audit their code base and fix all the known security holes.I mean, this is not exactly shocking coming from the same company with \"security experts\" that released a version of macOS that allowed anybody to login to root with any password [1]. Their security review process is grossly incompetent. At some point you should stop believing the \"security experts\" who do the security equivalent of putting antifreeze into the ice cream because they ran out of sugar and the antifreeze tastes sweet so it must work just as well.[1] https:&#x2F;&#x2F;arstechnica.com&#x2F;information-technology&#x2F;2017&#x2F;11&#x2F;macos... reply est 4 hours agoprevJavascript should stop executing after body.load.And only resumes executing when user clicks&#x2F;touch some specific UI elements.Browser should NOT be a generic application container. The browser was designed for \"browsing\" after all. reply exabrial 15 hours agoprevSo what we&#x27;ve learned once again is: running random code off of the internet is a bad idea... Wonder if we&#x27;ll stop doing this at some point? reply rfoo 15 hours agoparentBe ready to say \"playing random video off of the Internet is a bad idea\" if someone decided JavaScript has to be gone. reply Zuiii 6 hours agorootparentI would have assumed the range of things you could do in video would be limited by codec. Can you provide links that explain how video can achieve similar feats? reply rfoo 2 hours agorootparentFont: https:&#x2F;&#x2F;developer.apple.com&#x2F;fonts&#x2F;TrueType-Reference-Manual&#x2F;..., there&#x27;s a lot of exploits in various implementations about ten years ago: https:&#x2F;&#x2F;security.stackexchange.com&#x2F;questions&#x2F;91347&#x2F;how-can-a.... There&#x27;s still active ITW exploits in 2023: https:&#x2F;&#x2F;googleprojectzero.github.io&#x2F;0days-in-the-wild&#x2F;&#x2F;0day-...Image: The famous JBIG2.Video: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Stagefright_(bug) reply jwells89 15 hours agoparentprevTo me the danger seems to be not in the randomness of the code, but that it can run without the user&#x27;s prompting or consent. Perhaps it would be a good idea for browsers to disable JS JIT by default (as this is where a large percentage of holes crop up) and allow the user to enable it where they find the benefit low-risk and worthwhile (e.g. with vetted web apps).The downside is that the web is a bit slower by default, but that might not necessarily be such a bad thing and encourage more developer consciousness of how much JS they&#x27;re pulling in and how resource intensive it is. reply Syonyk 15 hours agorootparentJust disable JIT and WASM.I&#x27;ve been browsing that way for... oh, at least a year, probably more, and I don&#x27;t notice a difference. The world isn&#x27;t actually Javascript benchmarks (which suffer horribly, running the same hot loop over and over), and I seldom notice the performance difference.It&#x27;s just the default in my template for web browsing Qubes, along with disabling a few other things.If you&#x27;re on an Apple device, ignore Apple and enable Lockdown. You don&#x27;t lose much (some image formats, occasionally this is annoying), and you gain serious robustness against a huge wave of attacks. reply n8cpdx 12 hours agorootparentA little known fact is that you can disable lockdown mode per site and per app (e.g. you can disable lockdown mode for obsidian to make it work properly since it is web based).So actually it isn’t disabling JIT, it is making JIT opt-in.You also lose custom fonts on sites, but that is more feature than bug these days. reply euazOn 11 hours agorootparentThats a great tip, thanks! As a sidenote, how do you sync Obsidian on iOS? reply userbinator 9 hours agoparentprevA little extra attack surface won&#x27;t stop the vested interests from making sure that their code (tracking, ads, whatever other user hostilities) continues to run. reply HideousKojima 15 hours agoparentprevHit F12.Unless you&#x27;re using NoScript or something similar, you&#x27;re doing just that right now. reply pwdisswordfishc 13 hours agoprevWhy does a website about a security vulnerability in a JavaScript engine sabotage the security mitigation of disabling JavaScript, by requiring it for collapsible sections? As if they couldn&#x27;t just use . reply autoexec 11 hours agoparentNo joke! It&#x27;s amazing how much better protected you are by not allowing javascript and other active content by default but websites are dead set against letting people do that without massive inconvenience because for some reason displaying even basic text and images has become unthinkable without requiring a bunch of third party remotely hosted JS reply ceva 12 hours agoprev [–] Interesting replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The iLeakage attack is a browser-specific side channel attack directed at Safari web browser on Apple devices, exploiting speculative execution to access sensitive data.",
      "The attack is capable of retrieving Gmail inbox content and autofilled passwords, highlighting potential vulnerabilities in web-browsing security.",
      "The research was backed by numerous organizations and grants, focusing not only on the effectiveness of the attack but also on potential defenses against it."
    ],
    "commentSummary": [
      "iLeakage, a new browser-based attack affecting Safari on Apple devices, has been detected. It could potentially access autofilled credentials from websites.",
      "Despite being reported to Apple over a year ago, the vulnerability remains unresolved, impacting recent iPhones, iPads, and Apple desktops and laptops, though using a password manager does not increase vulnerability.",
      "The situation sparked discussions on site isolation effectiveness in other browsers, the time Apple took to address the vulnerability, and the complexities of mitigating such vulnerabilities."
    ],
    "points": 512,
    "commentCount": 189,
    "retryCount": 0,
    "time": 1698254149
  },
  {
    "id": 38012263,
    "title": "Loyal workers are selectively and ironically targeted for exploitation",
    "originLink": "https://www.sciencedirect.com/science/article/abs/pii/S0022103122001615",
    "originBody": "Skip to main content Skip to article Journals & Books Search Register Sign in Access through your institution Purchase PDF Article preview Abstract Introduction Section snippets References (93) Cited by (2) Journal of Experimental Social Psychology Volume 106, May 2023, 104442 Loyal workers are selectively and ironically targeted for exploitation☆ Author links open overlay panel Matthew L. Stanley a, Christopher B. Neck b, Christopher P. Neck c Show more Add to Mendeley Share Cite https://doi.org/10.1016/j.jesp.2022.104442 Get rights and content Abstract Loyalty is often touted as a moral principle, or virtue, worth exemplifying in social and business relations. But is it always beneficial to be loyal? We investigate possible negative consequences of being a loyal employee in the workplace. Instead of protecting or rewarding them, loyal employees are selectively and ironically targeted by managers for exploitative practices (Studies 1–2). The targeting of these loyal workers is mediated by the assumption that loyal individuals are readily willing to make personal sacrifices for the objects of their loyalty (Study 1). We then find evidence for the reverse causal pathway: workers who agree (versus refuse) to be exploited in the workplace acquire stronger reputations for loyalty (Studies 3 and 4). These bidirectional causal links between loyalty and exploitation have the potential to create a vicious circle of suffering. We discuss the implications of these results for obtaining a reputation for loyalty. Introduction Loyalty is a foundational moral principle, or virtue, that people usually value and aspire to embody in their social and business relations (Altman, 2008; Coughlan, 2005; Fiske, 1991, Fiske, 1992; Graham et al., 2011, Graham et al., 2013, Graham et al., 2018; Haidt & Graham, 2007; Haidt & Joseph, 2007; Reichheld, Markey Jr, & Hopton, 2000; Shweder, Much, Mahapatra, & Park, 1997; Souryal & McKay, 1996; Van Kenhove, De Wulf, & Steenhaut, 2003). Those who display loyalty to their countries, families, companies, religious organizations, sports teams, and other groups are publicly venerated (at least among their own group members), and the value placed on loyalty is emphasized in national oaths of allegiance, military and business mottos, anthems, literature, film, awards, and codes of conduct (Coleman, 2009; Connor, 2007; Hildreth, Gino, & Bazerman, 2016; Kruger, 2021; Reichheld & Teal, 2001; Souryal & McKay, 1996). Individuals with reputations for loyalty (relative to those without such reputations) are considered to be better friends (Shaw, DeScioli, Barakzai, & Kurzban, 2017), employees (Hirschman, 1970; McGinley & Shi, 2022), and leaders (Fehr, Yam, & Dang, 2015). Loyalty can also facilitate prosocial behavior by encouraging people to help others in their organizations and communities, and it can foster trust and cooperation among group members to achieve shared goals (Graham et al., 2011; Hirschman, 1970; Powers, 2000; Reichheld & Teal, 2001; Rosanas & Velilla, 2003). Disloyalty, in contrast, tends to elicit disgust, contempt, and moral outrage among observers, often damaging personal and professional reputations (Baumeister & Leary, 1995; Haidt, 2003; McManus, Kleiman-Weiner, & Young, 2020; Rousseau, 2001; Rozin, Lowery, Imada, & Haidt, 1999). Decades of research across the fields of organizational behavior, psychology, evolutionary biology, and business ethics have identified numerous positive outcomes of loyalty and negative outcomes of disloyalty (Berry, Lewis Jr, & Sowden, 2021; Haidt, 2003; Hirschman, 1970; Kruger, 2021; Powers, 2000; Reichheld & Teal, 2001; Rosanas & Velilla, 2003; Sinn & Hayes, 2017; Van Kenhove et al., 2003). But is loyalty always beneficial? Although people tend to value loyalty as a moral virtue, it is possible that loyal people are disproportionately (and ironically) targeted for potentially harmful and unfair managerial practices in the contemporary workplace. Employing complementary methods and designs, we investigate whether and why loyalty could lead to deleterious consequences for those who are loyal. More specifically, we first investigate whether workers who have reputations for loyalty are perceived to be more exploitable, because loyal individuals are expected to make personal sacrifices for the objects of their loyalty.1 We then investigate whether those employees who agree to poor treatment boost their reputations for being loyal. If workers are perceived to be more exploitable because of their reputations for loyalty and if agreeing to poor treatment boosts workers' reputations for loyalty, these bidirectional causal relations have the potential to create a vicious circle of suffering for certain workers. Researchers across different fields have examined several constructs related to loyalty that describe different components of interpersonal bonds and social relationships (e.g., feelings of attachment, commitment, identification, liking, love; Abrams & Hogg, 1988; Brewer, 1999; Schrag, 2001; Mowday, Steers, & Porter, 1979; O'Reilly & Chatman, 1986; Mael & Ashforth, 1992; Rubin, 1973; Seligman, Fazio, & Zanna, 1980; Tajfel & Turner, 1979; Scott, 1965; Sternberg, 1986). Much of what makes loyalty unique and distinct from related constructs is its inherent moral nature (Hildreth et al., 2016). That is, loyalty is a moral principle or virtue. The quintessential moral nature of loyalty is important because it creates a strong expectation, or perhaps even an obligation or imperative, to act in an individual's or group's interest, because it is the morally right thing to do (Hildreth et al., 2016). The inherent moral nature of loyalty is reflected in recent theorizing. For example, Shweder et al. (1997) argue that there are three distinct, cross-cultural “codes of morality” – community, autonomy, and divinity – that drive human action, with loyalty being central to the code of community. Drawing on insights from cultural anthropology, evolutionary psychology, and social psychology, Moral Foundations Theory (MFT) contends that loyalty is one of five innate foundations of morality that emerged to contend with scarce resources and social challenges (Graham, Haidt, & Nosek, 2009; Graham et al., 2013, Graham et al., 2018, Graham et al., 2011; Haidt & Joseph, 2007). Taking a social-relational approach to morality, Relationship Regulation Theory (Rai & Fiske, 2011) posits four fundamental and distinct moral motives or obligations—unity, hierarchy, equality, and proportionality—that drive moral action, with loyalty being central in the motive/obligation for unity (see also, Fiske, 1991, Fiske, 1992). According to each of these theories, people take concerns about loyalty to exist within the purview of morality, and loyalty operates to bind our groups together, making them more cohesive and coordinated in ways that usually facilitate group success. Loyalty may give rise to an expectation that people should act in ways that favor the objects of their loyalty. Indeed, this expectation for action is built into Hirschman's seminal treatise on Exit, Voice, and Loyalty (Hirschman, 1970; see also, Barry, 1974) and the Attitude-Based Framework of Loyalty (Oliver, 1999). One specific kind of action that might be expected of the loyal is that they make personal sacrifices for the objects of their loyalty. That is, they might be expected to act in accordance with an individual's or group's interests, even when doing so comes at a personal cost. Several operationalizations of loyalty in business ethics explicitly refer to this expectation for self-sacrifice. For example, Elegido (2013) refers to loyalty as a “deliberate commitment to further the best interests of one's employer, even when doing so may demand sacrificing some aspects of one's self-interest beyond what would be required by one's legal and other moral duties” (p. 496). Hart and Thompson (2007) account of loyalty “involve[s] self-sacrifice in the face of alternatives” (p. 300). Schrag (2001) remarks that the loyal are expected to “sacrifice convenience or immediate advantage for the sake of the person or group or organization” (p. 45) (see also, Zdaniuk & Levine, 2001). Due to the inherent moral nature of loyalty, self-sacrifice for the objects of one's loyalty should be considered as the morally right thing to do. This expectation for self-sacrifice may, therefore, take the form of an obligation or imperative. Although operationalizations of loyalty often come with an expectation for self-sacrifice, there is no empirical evidence linking loyalty to an expectation for self-sacrifice. We empirically investigate whether lay people expect the loyal to self-sacrifice for the objects of their loyalty. Over the past few decades, many different definitions of loyalty have proliferated both within and between fields. But a necessary precondition of any definition of loyalty is that at least two objects (e.g., individuals, groups, organizations) exist, with at least one being the object of loyalty. Most definitions of loyalty also involve partiality (i.e., favorable bias) toward an object (Brewer & Brown, 1998; Hildreth et al., 2016; Hirschman, 1970; Oliver, 1999). Accounting for the inherent moral nature of loyalty, we broadly define loyalty as the moral principle of partiality toward an object, which gives rise to expectations (or perhaps obligations or imperatives) for action on behalf of the object of loyalty (e.g., self-sacrifice). See Hildreth et al. (2016) for a similar definition of loyalty. What exactly constitutes a case of exploitation? Many (now) illegal practices are clearly exploitative (e.g., sex trafficking) to the point of being self-evident. But in other cases, what counts as exploitative might be less clear, and people often disagree over whether specific cases of worker treatment are exploitative or not (Kim, Campbell, Shepherd, & Kay, 2020; Mayer, 2007; Shelby, 2002). Much of the business ethics literature adopts a fairness-based account of exploitation, according to which exploitation occurs when an agent or entity takes unfair advantage of another agent or entity (Snyder, 2010; Wertheimer, 1996; Zwolinski, 2012). The (un)fairness of a transaction between agents/entities is typically measured by how the benefits resulting from the transaction are distributed (Wertheimer, 1996). Applied to an organizational context, it would be exploitative for management, representing the organization's goals and interests, to have some workers work excessively or engage in tasks unrelated to their job duties without extra pay or tangible reward (Kim et al., 2020). In such cases, workers are not rewarded for their behavior, and management receives all the benefits. In other words, management benefits at the expense of the workers.2 One might argue that it is not truly exploitative for managers to merely ask, but not require, certain workers to work excessively or to do tasks unrelated to their job duties without extra pay or tangible rewards. If workers are only asked, and not required, to work excessively or do tasks unrelated to their job duties without extra pay or tangible reward, then employees could still freely choose whether to acquiesce. In line with Kim et al. (2020), however, we argue that when there is a significant power difference between agents/entities in a transaction, agents/entities with less power may not feel free to decline the more powerful agent/entity's request. Applied to an organizational context, management controls outcomes necessary and vital to workers (e.g., promotion, job security, health insurance (at least in the U.S.), bonuses, etc.), so workers are put in a particularly vulnerable position when asked to do extra work or do tasks unrelated to their job duties without extra pay or tangible rewards. They may feel as though they can't decline such requests from management, or else they could be harmed. For our series of studies, we adapted materials from Kim et al. (2020) to ensure that we capture unfair transactions between management and their workers where management reaps the benefits at the expense of the workers. We make it clear that workers who work excessively or perform uncomfortable tasks unrelated to their job duties do not receive any extra pay or tangible reward. In our cases, management benefits at the expense of workers. The cases of exploitation used in our series of studies also count as exploitation under other theoretical accounts (e.g., vulnerability-instrumentalization views; Goodin, 1985, Wood, 1995).3 But, more importantly, we also pre-test the cases of exploitation used in our studies to ensure that people tend to agree, on average, that they are exploitative. What matters most for addressing our hypotheses is that lay people tend to believe these cases of poor worker treatment are exploitative – not whether some particular normative, philosophical account is right. We have now characterized the central constructs under investigation – loyalty and exploitation. But what exactly is the relationship between loyalty and exploitation? We hypothesize bidirectional causal links between loyalty and exploitation that could create a vicious circle of suffering for contemporary workers. In one direction, we hypothesize that workers with reputations for loyalty (relative to other workers without such reputations) will be perceived as more exploitable in the workplace, because of the lay assumption that loyal people are readily willing to make personal sacrifices for the objects of their loyalty. Consider a manager who wants some additional work done. The manager intends to ask a worker to stay late to do extra work and to work on some of their upcoming vacation days, but the manager isn't offering extra compensation or any other reward for that matter. The manager intends to take unfair advantage of a worker, benefitting at the expense of the worker. On our account, the manager should presume that loyal workers would be particularly likely to do this extra work and work on their vacation days, because loyalty comes with an expectation for self-sacrifice to management (or to the organization as a whole). Staying late to do extra work and working on vacation days without compensation or any other rewards are, definitionally and quintessentially, self-sacrificing behaviors. In contrast, the manager shouldn't expect disloyal workers to self-sacrifice for the manager or for the organization as a whole; it seems improbable that they would agree to engage in potentially harmful and unfair practices that predominantly benefit management and the larger organization. We expect to find evidence corroborating the hypothesis that workers with reputations for loyalty (relative to other workers without such reputations) will be perceived as more exploitable, because of the assumption that loyal individuals are readily willing to make personal sacrifices for the objects of their loyalty. However, there is a case to be made for the competing hypothesis: that managers would attempt to protect or reward employees for their loyalty by not targeting them for exploitative practices. Hiring and retaining loyal employees is highly desirable to organizations (Hirschman, 1970; McGinley & Shi, 2022), as loyal employees offer numerous benefits to management and the larger organization (Hirschman, 1970; Powers, 2000; Reichheld & Teal, 2001; Rosanas & Velilla, 2003). If managers are interested in retaining and motivating more desirable employees, they should presumably refrain from taking unfair advantage of them in ways that could cause them to suffer. They shouldn't treat loyal employees poorly by asking them to, for example, work on their scheduled days off or work late without reward. Our studies were designed to impartially adjudicate between these competing hypotheses. We not only expect to find evidence for a causal link from loyalty reputation to exploitation; we also expect that workers who agree to be exploited by management (relative to workers who refuse) will obtain stronger reputations for loyalty, due to the very act of agreeing to submit to exploitative practices. When a person acts in ways indicative of them possessing some trait, then that person should gain a reputation for possessing that trait (assuming others were exposed to the person's actions; Emler, 1990). So, when a person acts in ways that are indicative of loyalty toward some object and when other people see those actions, that person should acquire a reputation for being loyal. Consider a worker who has agreed to poor treatment in several ways over time: they have agreed to work late on several occasions and on many of their vacation days for no rewards. These are actions that are indicative of loyalty to management; they show partiality toward management at personal cost. The worker should, therefore, gain a reputation for loyalty. Despite the now considerable literature detailing positive outcomes of loyalty and negative outcomes of disloyalty (Haidt, 2003; Hirschman, 1970; Kruger, 2021; Powers, 2000; Reichheld & Teal, 2001; Rosanas & Velilla, 2003), evidence in favor of our hypotheses would suggest that those who seem loyal are more likely to suffer potentially harmful and unfair treatment in the workplace. Such evidence would call into question the value of loyalty, at least for certain individuals in certain contexts. Across four studies, we investigate whether loyal employees are selectively and ironically targeted by managers for exploitation in hypothetical scenarios, whether this targeting of loyal workers for exploitation is mediated by the expectation that loyal individuals are readily willing to make personal sacrifices for the objects of their loyalty, and whether those who agree (versus refuse) to be exploited in the workplace acquire stronger reputations for loyalty. To start, in Study 1, participants were presented with a worker who had acquired a reputation for loyalty, disloyalty, or neither loyalty nor disloyalty. We test whether managers express greater willingness to ask workers with a reputation for loyalty to be exploited than workers without such a reputation. Study 1 also probes mechanism, testing whether managers are more willing to ask loyal employees to be exploited because of the assumption that loyal people are readily willing to make personal sacrifices for the objects of their loyalty. Study 2 then tests for specificity of process. We do not expect a reputation for possessing just any moral virtue to encourage targeting for exploitation. Instead, we expect loyalty to be unique among moral virtues insofar as a reputation for loyalty (as opposed to other moral virtues) is what encourages managers to target workers for exploitation. To offer some evidence that loyalty is unique, we compare loyalty to two other common moral virtues that people usually value and aspire to exemplify – fairness and honesty. Loyalty, fairness, and honesty are all closely related moral virtues. Based on evidence coalesced across 20 countries, loyalty, fairness, and honesty all appear in Schwartz (1992) universal psychological structure of human values, with loyalty and honesty in the same value cluster of Benevolence and with fairness in the closely related neighboring cluster of Universalism. In addition, research and theory on moral identity and the self-concept consider virtues like loyalty, fairness, and honesty to be closely interconnected (Hildreth et al., 2016; Kihlstrom & Klein, 1994) and central in people's constructed self-concepts (Aquino & Reed II, 2002; Stanley & De Brigard, 2019). Studies 3 and 4 reverse the causal pathway from loyalty reputation to exploitation, testing whether workers who agree (versus refuse) to be exploited are seen as more loyal in the eyes of managers. Assessing bidirectional causal links between loyal reputation and exploitation is important because evidence in favor of bidirectional causal links could be indicative of a vicious circle of harm and suffering for workers. Study 4 also tests whether the certainty with which managers believe that a case of poor worker treatment is exploitative predicts their judgments about the loyalty of employees who agree to be treated poorly. We expect that the more certain managers are that a practice is exploitative, the more loyal they will judge employees who agree to this poor treatment. For all studies, we report all exclusion criteria, all materials and conditions included, and all independent and dependent measures. We ensured ample power across studies by seeking at least 100 participants per condition after expected exclusions. In each study, the sample size was determined before any data analysis. To best address our hypotheses, we recruited samples of managers with at least one year of experience. These managers were not permitted to access more than one study. Studies 1, 2, and 4 were all formally pre-registered, and we did not deviate from these pre-registrations. De-identified data for all studies are publicly available (https://osf.io/ze9a2/?view_only=256ed8597c2446fcb52a67172a33ddbc). Section snippets Study 1 In Study 1, managers were randomly assigned to see a profile of a worker with a reputation for loyalty, disloyalty, or neither loyalty nor disloyalty (between-subjects manipulation). Managers then reported their willingness to ask the worker to work late several evenings for no reward and do uncomfortable tasks unrelated to their job duties for no reward. These are two common forms of contemporary workplace exploitation (Kim et al., 2020). We test whether managers are more willing to ask the Study 2 The results of Study 1 indicate that loyal employees are more likely to be targets of exploitative managerial practices in hypothetical scenarios (relative to employees with reputations for disloyalty and baseline controls), and that this targeting of loyal workers for exploitation is mediated by the expectation that loyal people are readily willing to make personal sacrifices for the objects of their loyalty. Study 2 extends Study 1 by assessing specificity of process. We expect loyalty Study 3 The previous studies offer consistent evidence that loyal employees are selectively targeted for exploitative managerial practices in hypothetical scenarios. That is, the previous studies offer causal evidence from loyalty reputation to exploitation. In Study 3, we experimentally investigate the reverse-direction of this process, testing whether workers who agree (versus refuse) to be exploited in the workplace subsequently acquire stronger reputations for loyalty. Study 3 was pre-registered (//osf.io/dw65k/?view_only=8b2042b08ca644eeb39be03be9c5139a Study 4 Study 4 has two aims. First, we attempt to conceptually replicate the central finding from Study 3 that workers who agree (versus refuse) to be exploited in the workplace subsequently acquire stronger reputations for loyalty. Second, we test whether the certainty with which managers believe that a case of poor worker treatment is exploitative predicts their judgments about the loyalty of those who agree to be treated poorly. We expect that the more certain managers are that a practice is General discussion Across four studies, we found consistent support for our hypotheses. First, we found that loyal employees are selectively targeted by managers for exploitation in hypothetical scenarios (Studies 1–2), and that the targeting of these loyal workers is mediated by the expectation that loyal people are readily willing to make personal sacrifices for the objects of their loyalty (Study 1). These effects were specific to targets with reputations for loyalty (Study 2). We then found evidence for the Conclusions Society has made some positive strides in formally outlawing egregious kinds of exploitation (Crane, 2013; Quirk, 2006; Wertheimer, 1996), but more subtle types of exploitation remain all too common (Kim et al., 2020). Insofar as exploitative managerial practices persist, certain workers will be targeted for exploitation. Although loyalty is typically touted as a moral virtue worth exemplifying, our research indicates that loyal workers are perceived to be more exploitable than other employees, Authorship statement The submitted work is original and is the authors' own work. This manuscript is not under review at any other journal. Declaration of Competing Interest The authors declared that they had no conflicts of interest with respect to their authorship or the publication of this article. References (93) J. Dungan et al. The psychology of whistleblowing Current Opinion in Psychology (2015) J. Graham et al. Moral foundations theory: The pragmatic validity of moral pluralism J.A.D. Hildreth et al. Does loyalty trump honesty? Moral judgments of loyalty-driven deceit Journal of Experimental Social Psychology (2018) J.A.D. Hildreth et al. Blind loyalty? When group loyalty makes us see evil or engage in it Organizational Behavior and Human Decision Processes (2016) R.T. Mowday et al. The measurement of organizational commitment Journal of Vocational Behavior (1979) D.L. Paulhus et al. The dark triad of personality: Narcissism, Machiavellianism, and psychopathy Journal of Research in Personality (2002) S.H. Schwartz Universals in the content and structure of values: Theoretical advances and empirical tests in 20 countries A. Shaw et al. Whoever is not with me is against me: The costs of neutrality among friends Journal of Experimental Social Psychology (2017) M.L. Stanley et al. Belief in divine moral authority satisfies the psychological need for structure and increases in the face of perceived injustice Journal of Experimental Social Psychology (2022) A. Waytz et al. The whistleblower’s dilemma and the fairness– Loyalty tradeoff Journal of Experimental Social Psychology (2013) View more references Cited by (2) The dark side of generosity: Employees with a reputation for giving are selectively targeted for exploitation 2023, Journal of Experimental Social Psychology Show abstract Meaningful Work, Well-Being, and Health: Enacting a Eudaimonic Vision 2023, International Journal of Environmental Research and Public Health ☆ This paper has been recommended for acceptance by Dr. Paul Conway. View full text © 2022 Elsevier Inc. All rights reserved. Recommended articles Reversing the cumulative redundancy bias to demonstrate metacognitive flexibility in cue utilization Journal of Experimental Social Psychology, Volume 107, 2023, Article 104471 David J. Grüning, …, Klaus Fiedler The mind's “aye”? Investigating overlap in findings produced by reverse correlation versus self-report Journal of Experimental Social Psychology, Volume 107, 2023, Article 104473 Jordan Axt, …, Emery Wehrli Who's on first? People asymmetrically attend to higher-ranked (vs. lower-ranked) competitors Journal of Experimental Social Psychology, Volume 104, 2023, Article 104405 Evan Weingarten, …, Alixandra Barasch Show 3 more articles Article Metrics Citations Citation Indexes: 2 Captures Readers: 23 Mentions Blog Mentions: 1 News Mentions: 19 Social Media Shares, Likes & Comments: 170 View details About ScienceDirect Remote access Shopping cart Advertise Contact and support Terms and conditions Privacy policy We use cookies to help provide and enhance our service and tailor content and ads. By continuing you agree to the use of cookies. All content on this site: Copyright © 2023 Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the Creative Commons licensing terms apply.",
    "commentLink": "https://news.ycombinator.com/item?id=38012263",
    "commentBody": "Loyal workers are selectively and ironically targeted for exploitationHacker NewspastloginLoyal workers are selectively and ironically targeted for exploitation (sciencedirect.com) 406 points by ck45 21 hours ago| hidepastfavorite310 comments xyzelement 20 hours agoHow committed to be to one&#x27;s job is a dynamic topic. To me, the ideal dynamic is finding a place that will recognize and reward you for working hard and \"owning it\" - and to work hard and \"own it\" in that environment.In contrast, working hard in a place that doesn&#x27;t reward you is sad. Slacking in a place where you can succeed more if you try harder is also sad.I find that some people will perceive themselves to be exploited and orient their life around avoiding it, regardless of the situation (vs, reserving that feeling for avoiding actually exploitive situations.) For example, it&#x27;s common to see HN posts describing someone as \"subjecting themselves to unpaid overtime\" when they work hard - meanwhile the person saying it is making $60K while the person being talked about is making $600K. There are some cases where working hard&#x2F;loyalty&#x2F;etc can lead to outsized rewards - but you need to be smart and keep your eyes open for that kind of space.And then, assuming you are in the right kind of environment - allowing yourself to care and be engaged makes your work days much more fun. I think commonly in the example I described, the person that&#x27;s proud of inoculating themselves from exploitation not only make 10% of what they can, but the exactly 8 hours of work they put in is a miserable drag for them. The guy working harder for 10X the comp might also be having more fun. reply distract8901 19 hours agoparentMy last job was a corporate hellscape. I worked really hard to move up to assistant manager, then corporate put me in a failing store on the other side of the state and just left me to rot. I had zero employees, just me and the manager. We constantly got berated for not meeting sales targets, which meant corporate sent us less product to sell, so our numbers got worse...Then there was the mandatory unpaid overtime, the 12 hour days running the entire store solo. It nearly put me in the hospital, and I&#x27;m not exaggerating.Then I got an unbelievable offer for a tech job ten minutes from my house. It was \"only\" twice my corporate salary, and I&#x27;m definitely being way underpaid for essentially being the senior R&D engineer. But it pays enough that my husband doesn&#x27;t have to work and we don&#x27;t want for anything. My job is so much fun, and my dedication is definitely noticed and appreciated. They&#x27;ve already given me a raise unprompted, and once we have enough revenue, I expect I&#x27;ll get a much bigger one. Not that I really care about the money, I feel respected here, and I get to use all of my talents instead of cold-calling people to sell more crap.I&#x27;ll never go back to that corporate life. It was absolutely soul crushing for someone who has a lot of initiative and a lot of skills. This is where I was meant to be. reply neeleshs 19 hours agorootparentCurious question - how did you make the transition from being a store manager to an R&D Engineer? Was this a skill you already possessed but couldn&#x27;t utilize before? reply distract8901 14 hours agorootparentPretty much. I took the retail job because I couldn&#x27;t find a programming job. Before that I was a video game programmer. I actually got hired here as a mid level unity programmer, but it quickly became clear that my other skills were more valuable.I&#x27;ve done electronics as a hobby for most of my life, and I just have a natural talent for engineering and problem solving. R&D is something I&#x27;ve wanted to do since I first heard of it at 10 years old. The stars just never aligned until now. reply dopidopHN 18 hours agorootparentprevMy previous R&D lead was a store manager just before as well. He was a stellar lead.Maybe there is some untapped potential in all the store managers of the world? reply skeeter2020 17 hours agorootparentI bet they&#x27;re great at solving a million little problems, shielding devs and getting shit done. If that&#x27;s your priority&#x2F;emphasis they&#x27;d be a great source of solid employees. reply flatline 17 hours agorootparentprevSo-called “soft skills” are essential to effective management and hence team cohesion, employee happiness, and lots of other hard to measure metrics which still contribute directly to the bottom line and the team’s ability to deliver. Someone with minimal technical skills and great people skills can still effectively lead strong technical teams. If those skills are not present on a team at all, they will struggle 100% of the time. Nobody may even recognize the struggle if there is no one who can identify these things. reply xyzelement 17 hours agorootparentprevI actually bet your experience holding it down and getting shit done in that failing store was a good reflection of your ability and character and helped you get the next gig. reply gopher_space 11 hours agorootparentprev> Maybe there is some untapped potential in all the store managers of the world?McDonalds is a great leadership pipeline because there&#x27;s no reason for a competent assistant manager to stick around. reply biomcgary 15 hours agorootparentprevI&#x27;ve never worked in a large corporation, just academia and startups. The nature of exploitation in academia is reasonably well known and you pretty get much what you expect if you go in with eyes open (although there is variation depending on your academic advisor). I transitioned from academia to a startup that was far more exploitive than anything I experienced previously, but the exposure it gave led to another startup that has been the exact opposite (generous compensation and equity, great colleagues, etc).In each case (various academic labs and the two startups), my loyalty was to the biological problem we were trying to solve rather than to the institution. I selected advisors and startup based on the problem that we were trying to solve (e.g. improving drug development and human health). As long as I thought the institution was making progress, I was willing to overlook a lot. I suspect that the video game industry and a few others might (space!) have a lot of people with a similar view of loyalty (and levels of tolerated exploitation). reply H8crilA 18 hours agorootparentprevWhy did you not leave more or less immediately? I know that hindsight is 20&#x2F;20, but still, it is pretty obvious you were not taken seriously at all. reply distract8901 14 hours agorootparentI was at the company for three or four years. It was fine working as a floor level employee, and my last manager encouraged me and gave me a lot of freedom to do what I wanted because I really did boost sales. I only took the assistant manager position because everyone around me told me I&#x27;d do great.I lasted six months. The only reason I stayed that long was because we were promised some huge bonuses for meeting our sales targets, which never happened. I got like $50.My manager gave her two weeks notice a week before I did and our region manager didn&#x27;t find anyone to cover. He expected me to run the entire store by myself for a week. I said no and walked out. They had to leave the store closed for several days because absolutely nobody worked there. It was extremely cathartic. reply pierat 18 hours agorootparentprevThats a no-brainer, really.In the US (assumption of location), we have nearly no social net. We pay 30+% in taxes, but little to show for it if we lose jobs, or dealing with horrific jobs.And with the spates of homeless arrests, even sleeping under an overpass or rough camping is illegal.And of course, the worse the job, the less the pay, and the stickier the employees due to not being able to save.Ive been in similar situations, with terrible jobs, up to and including a manager who ordered me to lie to a state entity over his botched fix. reply jjoonathan 17 hours agorootparentThose who make income pay 30+% in taxes.Those who make capital gains do not.Of course, those who make capital gains don&#x27;t need a social safety net, but discussions about taxes need to include both tax tracks because they behave so very differently. reply lotsofpulp 17 hours agorootparentIf your effective income tax rate is 30%+ in the US, you either have a very high income, easily top decile, or you live&#x2F;work in Oregon (but that’s only a few million people). reply dmoy 17 hours agorootparent$90k in NYC is >30% effective after federal, state, city, and FICA.But yea it&#x27;s probably top 10%.If you include medical costs outside of FICA, which many other Western countries get for near free after taxes, then it looks... quite different. reply lotsofpulp 16 hours agorootparentI guess certain cities like NYC&#x2F;Philadelphia might also push effective income tax to over 30% for lower incomes, but for the purposes of comparing income tax rates and capital gains tax rates in the US, it does not make sense to include the social security component of FICA or medical costs.Edit: I am barely getting 30% in NYC, even including FICA (zip code 10118)https:&#x2F;&#x2F;smartasset.com&#x2F;taxes&#x2F;income-taxes$90k as single is $27,171, or 30.19%.$90k as married filer shows $20,758, which is 23.06% (incl FICA).But, again, I would not include all of the social security portion of FICA (6.2%), since presumably you will be getting some of that back. reply zdw 16 hours agorootparentprevSales tax + local&#x2F;state&#x2F;federal taxes + social security&#x2F;medicare can be above 30% even for folks not in the highest brackets. reply lotsofpulp 16 hours agorootparentSales taxes and social security taxes cannot be lumped in with income taxes, for the purposes of comparing income tax rates and capital gains tax rates. reply pierat 6 hours agorootparentI&#x27;m the great-great-great-grandparent, and I didn&#x27;t specify the *type* of taxes.The state took it from me, either directly before I saw it, at a point of sale, as some convenience fee (restaurants, bars, etc), liquor fees to punish my drinking, or countless other state-sanctioned money transfer.I like a return on my investment, and the same goes for the government I live in. And although this sounds like some libertarian style drivel, I&#x27;m not complaining about the taxes themselves, but what I get in return for what I pay for. And in this country (USA), it aint much. The most I&#x27;ve seen the govt do, after kilodollars paid in, was a whole $1200 singular check during covid. Everything else I \"get\", is fee&#x27;d, fine&#x27;d, and taxed to death.I would prefer a strong safety net for everyone. Universal healthcare. Free K-12 school lunches. Free university classes&#x2F;degrees.Yeah, I look at the WHOLE package of taxes, what I pay in, and what I get. Well, there&#x27;s a reason why I&#x27;m talking with my partner about leaving the country, and even possibly renouncing. But hell, even US citizenship is a -$3500 hole in my pocket. reply pierat 17 hours agorootparentprevTrue, but the post is about \"workers\" (who are being abused by management&#x2F;ownership), who are getting \"income\". This isn&#x27;t about the managerial or owner class.Sure, there&#x27;s edge cases where founders and early startup workers get paid income and capital (stocks, etc) both, but that&#x27;s not the scope of the article. reply jjoonathan 14 hours agorootparentRight, but I detected a whiff of a complaint that taxes were high, so I wanted to emphasize that a huge chunk of the wealth out there is taxed at much lower rates. These are edge cases if you count by number of people, but not if you count by number of dollars. Rich people live in a different world. replyxyzelement 18 hours agorootparentprevThis is amazing, thank you for sharing the story and the contrast between a good and bad workplace. It&#x27;s not that different than marriage - if both parties are committed to acting well, it&#x27;s amazing. If either party slacks&#x2F;abuses its a nightmare. reply lotsofpulp 17 hours agorootparentThat type of work environment is endemic to retail&#x2F;hospitality&#x2F;food service businesses. Combination of low quality of life at work and low pay. reply mikelevins 17 hours agoparentprevI think I agree with everything you&#x27;ve said here, but I want to offer a caution to those who pursue hard work that is fun.I&#x27;ve worked in all permutations of your descriptions. If I believe in a project and can get good results on it, and much moreso if I&#x27;m having fun, I will work very hard. If I don&#x27;t believe in it or have trouble getting good results or no one cares, then it&#x27;s very hard for me to motivate myself.Obviously, I prefer the situations where I&#x27;m highly motivated, and in fact I&#x27;ve worked very hard on some projects. Too hard, in fact.The fact that a project is something you believe in, that you&#x27;re highly motivated, that you can make a difference with it, or that you&#x27;re having a lot of fun, doesn&#x27;t make overwork healthy.I&#x27;ve overworked myself a couple of times in my life. I hesitate to describe the worst case; I don&#x27;t think readers will believe my description of what I did. Suffice to say that I worked on a new system project at Apple and was highly motivated to make it succeed (it didn&#x27;t). I owned a small non-tech business at the same time.I worked way too hard for a while. I didn&#x27;t mind it. On the contrary, I was deliriously happy to do it. Nobody had to ask me to work hard. But it still did me harm.I don&#x27;t know for sure that working like that caused or contributed to the chronic illnesses I now have, but I do know that the literature on one of them says that it&#x27;s correlated with excessive hours worked and excessive exercise. I did both. (My side business involved a lot of intense exercise.)Oh, and if the overwork did cause or contribute to my chronic illness, then it may also have cost me a fortune. I went bankrupt in the process of getting one of those illnesses properly diagnosed and treated. So even if hard work does happen to pay really well, that doesn&#x27;t necessarily make it worthwhile--not even necessarily financially worthwhile.Again, nobody made me work like that. I did it because I was motivated and having fun. It was nevertheless very bad for me. That became clear over the months after I did it, and I may still be paying for it.You might think that I would have learned my lesson from that episode, and that&#x27;s true to some extent. I&#x27;ve never worked that hard again. I have worked too hard since then, though. It&#x27;s a consequence of personality traits, I think. It&#x27;s a trap I can too easily fall into, even though I know better. So I have to keep watch and listen to my loved ones and my doctors when they warn me that I&#x27;m trending that way.In short: don&#x27;t think that fun and motivation make you immune to the ill effects of overwork. They don&#x27;t. reply gosub100 17 hours agorootparentreminds me of the stories of pro ball players who work and train their whole lives to finally get signed, but they&#x27;re one injury or bad season away from losing the stardom.I&#x27;m the opposite, I have the chops to get mid-grade developer jobs (the leetcode stuff kept me from the \"big leagues\" of FAANG which I&#x27;m fine abstaining from, they would sniff me out very quickly) and live comfortably, but I have next to no motivation to get anything beyond the minimum done. I think ADHD is part of it (but its on me for never getting it diagnosed or treated), and sometimes I feel guilty for \"stealing time\" from my employer (yet I&#x27;ve never been fired for bad performance, somehow my JIRA tickets always get done-enough to stay afloat). I am passionate about personal projects though, and I love coding. I still get satisfaction from solving bugs, but realistically I&#x27;ll never be more than a mid-level maintenance coder. reply ip26 16 hours agorootparentprevWhat do you think the threshold where you cross from “hard and fun” to “definitely overwork, you’ll hurt yourself” is? 50 hours a week? (10 hour days) Maybe 55? reply mikelevins 15 hours agorootparentI don&#x27;t think it&#x27;s that simple. There are too many variables. It&#x27;s probably different for each person and depends on a host of health-related things. It&#x27;s probably also different for the same person at different stages of life.Wouldn&#x27;t it be nice if there was a simple number or rule or formula? We&#x27;re not that lucky. You have to pay attention, preferably with the help of sensible people who know you and have an interest in your continued well being. And yeah, that can be the luck of the draw, too. reply johnnyanmac 1 hour agorootparent>Wouldn&#x27;t it be nice if there was a simple number or rule or formula? We&#x27;re not that lucky.no worries, big corpo will make one box fit all for you while extracting your time and labor. if you don&#x27;t have enough, well tough.>You have to pay attention, preferably with the help of sensible people who know you and have an interest in your continued well beingI&#x27;d love to have someone with that interest. reply TeMPOraL 14 hours agorootparentprevPerhaps it&#x27;s for the best, because if it was a specific number, companies would require you to work no less than this number. reply mistrial9 17 hours agorootparentprevthank you for this detailed post - I believe that you and others like you became enablers for a darkside of management at Apple. However with clarity and time you are re-balancing yourself.source: directly worked at Apple in Santa Clara and Cupertino reply Apocryphon 17 hours agorootparentThere is something severely unexamined about middle management culture in that company, papered over by a culture of silence. reply vsareto 19 hours agoparentprev>There are some cases where working hard&#x2F;loyalty&#x2F;etc can lead to outsized rewardsPeople are so disillusioned to \"hard work == comfortable life\" that they might not even recognize it when it&#x27;s real, or be incredibly suspicious.There is also a separate, much bigger lesson in that if you make friends and&#x2F;or play politics, you also don&#x27;t have to work as hard and still get rewarded (sometimes massively).When you layer all of these facts, it&#x27;s really hard to sign up to be a hard worker. It feels more like punishment once you learn how easy the rich people have it. reply red-iron-pine 18 hours agorootparent> It feels more like punishment once you learn how easy the rich people have it.For sure. A lot of HN went straight into STEM programs and then into STEM roles, and never had a chance to really do crappy jobs. I think of my brother&#x27;s friend, who went straight to top tier tech school, then FAANG, than another FAANG. Nice guy, but he lives in a different universe and is painfully out of touch for anythign that doesn&#x27;t involve hyperscalable infrastructure.I worked wayyyyyy harder in bartending, or retail, or the military than I ever did in any IT&#x2F;DevOps gig. And in most cases in IT I get paid 4-5x more. reply bradlys 17 hours agorootparentI’ll be the counterpoint and say that all the shit jobs I did were way easier than any tech jobs I’ve had.Working retail was boring but it was a joke in terms of stress or care. Working doing help desk IT work was similar. Same for other odd jobs I picked up.Then I joined startups, big tech, etc. all in SV and the stress is insanely high compared to anything else. The hours suck even when you’re an aggressive guy like I am about WLB - because I still have to spend hundreds of hours preparing for interviews every year. It’s mandatory to keep your compensation high and to avoid the new toxic boss you just got.I left a $1m+&#x2F;yr job because the stress was too much. Experiences with tech is a wide gamut but my experience is one of it being a shit show. I have friends who get paid well and have good hours and a great work environment but I’ve never been in that side of being happy at my jobs. I keep joining shitty employers&#x2F;teams - somewhat out of bad luck tbh. reply johnnyanmac 1 hour agorootparentI think it&#x27;ll vary not just on individual prowess and interest, but in what kind of ways you want to grow. Bartending never \"changes\" but the people do. Even if every interaction is unique you learn a fundamental dozen approaches and your career is spent optimizing to identify what approach to use on which person. There will be a point where you get very comfortable and into the groove if you enjoy that line of work.And honestly tech isn&#x27;t that different. Except you will never get a groove if you move every few years and the stack and tribal knowledge never builds. It&#x27;s like it a bartender changed towns every year, with each demographic widly different from the last. some skills transfer but you realize others are unique to this demographic and older skills may even be a negative. But if you&#x27;re someone who always wants to be working on a new problem, this is a better deal. You&#x27;ll never get \"bored\" so to speak.>It’s mandatory to keep your compensation high and to avoid the new toxic boss you just got.I feel these may go more hand in hand than we realize. reply hanslovsky 16 hours agorootparentprevI have never had issues with terrible WLB, but I have also never sought out FAANG in SV (and never have been anywhere $1m+). The closest I&#x27;ve been was Biotech. I am not sure that I would trade my WLB for a much more stressful job that pays 2-3x what I make now. It could mean that my spouse \"retire\" from work and take care of the home and kids, while still maintaining the ability of hiring external help. In that case, the increase in work stress may be compensated by reduced stress of household management reply bradlys 11 hours agorootparentI wish I could take lower income jobs. Sadly, I cannot. The majority of single women in SV expect a minimum of $500k&#x2F;yr income (if you intend to marry and have kids) regardless of what they earn. Similar woes now that I live in NYC.They all want the $3m house, private school, and the full-time nanny. If you get lucky - maybe you find one who will compromise for a $2m house but she&#x27;ll give up her job.I hate this dating market tbh. reply johnnyanmac 46 minutes agorootparent>The majority of single women in SV expect a minimum of $500k&#x2F;yr income (if you intend to marry and have kids) regardless of what they earn.Did you really fall for that horrible tiktok \"trend\"?rerfame it this way: say you have a 500k income and 6 months of savings (so, 250k dollars that is easily accessible. even in some stupidly expensive 4K&#x2F;month apartment with 4k expenses in everything else, we&#x27;re talking 2.5 years of living expenses). How much would it cost you to make it your full time job to work out, and figure out how to make yourself more physically appealing? I include changes in diet in that 4k \"other living expenses\" (even a wasteful $100&#x2F;day of meals is $3k in expenses. may as well invest in something like Factor or HelloFresh).You don&#x27;t even have to quit your job, but it sounds like it&#x27;s the kind of job that drains you dry. So let&#x27;s just use that savings on yourself while you still have \"you\" left. enroll in a bootcamp, make it your full time mission to go out everyday and move around, find a good tailor to get some good semi-formal and formal clothes for you, find some new non-tech interests that let you tell more casual stories, maybe even invest in a life coach and figure out what you are(n&#x27;t) doing that is(n&#x27;t) helping. Someone with that income has the money to do all of this very comfortably.There are way too many \"studs\" making ends meet on under 70k in high CoL areas to make me feel like someone making 500k can&#x27;t do anything else to attract a mate. If it&#x27;s that important, make use of that money you earned through sweat and tears and better yourself. I don&#x27;t even think you need to change this much (if you&#x27;re more into nerdy stuff, just find some good tabletop meetups or comic book clubs. You&#x27;re in NYC you probably have any kind of esoteric social gathering I can name), but clearly there are some deep seeded mindsets or perceptions to correct if this is what you really think.I&#x27;m not going to tell you to accept your body because I don&#x27;t know you. But if you don&#x27;t accept it, change it. reply ApolloRising 3 hours agorootparentprevThat&#x27;s not even remotely true. Not sure where you are dating but there are tons of quality women out there not like that. reply monknomo 17 hours agorootparentprevI&#x27;m curious - how do you choose a team or a job? I wonder if there is something you&#x27;re looking for that correlates with stress, or if you&#x27;re just unlucky reply bradlys 11 hours agorootparentThere&#x27;s very little choice involved. I interview with an assload of companies and go with whoever pays the most and&#x2F;or whatever opportunity seems best for career growth.Genuinely, I am rather unlucky. I&#x27;ve talked to many peers and even for people who have interviewed for the same job as I had - I constantly go through a much more rigorous process than others. I had to interview with directors, principle engineers, follow up interviews, etc. in order to get my last job when all my peers just did a typical onsite (2 coding, 1 behavior, 1 system design) for the same role whereas I did that in addition to all this other stuff. Same job and role - no downleveling or anything. reply bluefirebrand 19 hours agorootparentprev> When you layer all of these facts, it&#x27;s really hard to sign up to be a hard worker. It feels more like punishment once you learn how easy the rich people have it.It is very easy to become extremely bitter when you&#x27;re being lectured by someone who makes more in a month than you do in a year about \"hard work\"Especially when you know their job is basically answering emails, giving a presentation once in a while, and golf trips with customers. reply johnny99k 19 hours agorootparentDo you really think that&#x27;s ALL they do? My manager (who is the director of engineering of the company) does what you are describing and it may seem like a no-work job. However, he also:-manages multiple, large, multi-year projects across multiple time zones -is a filter for the shit that rains down from upper-management (the most important role of a manager) -if any of these projects fail, he gets blamed (and most likely fired) reply bluefirebrand 19 hours agorootparentOkay, but imagine another Director of Engineering who- Is responsible for managing large multi-year projects across multiple timezones and basically offloads all of his responsibilities to his direct reports and just asks for status reports now and then- Is not just not filtering the shit from above but is also a source of shit from above- diffuses blame downwards instead of taking any for himself, cuts people under him and is never disciplined when projects fail.He makes as much or more than the guy you report to.Who holds him accountable? His other buddies in upper management? Maybe eventually, but let&#x27;s be real here. If he ever does get fired he gets a golden parachute and worms his way in at another company in no time.Maybe this isn&#x27;t true at the middle manager-y layer, but it&#x27;s definitely a pattern we&#x27;ve seen plenty of examples of with executives and other upper management types. reply lazide 17 hours agorootparentThe accountability comes from the people under him leaving&#x2F;actual poor results, or doing poor work because of burnout, resulting in poor results.If it works well enough though, he’s fine.A lot of folks don’t realize their value when they’re burning themselves out making your case look good, which enables it, and not even getting paid for the effort.Those people often rant the exact same way you are, while not changing their behavior.They also tend to be the most angry when their part is make clear though. So I guess it’s a good thing it’s at least semi anonymous here? reply zmgsabst 17 hours agorootparentHow is other people suffering him experiencing accountability? reply lazide 15 hours agorootparentWhat does suffering have to do with accountability, if everything important keeps working, no laws are broken, and the org meets its metrics?If they leave and things blow up, then that impacts things no? Accountability is about ensuring someone gets held to account for the results of their actions.Accountability doesn’t mean ‘they pay because I’m unhappy’. It means ‘if they break the law, they get punished’. Or ‘if they break the org or don’t deliver results their bosses want they get fired.’.Being a dick of a boss isn’t illegal. Burning people out (when they do it voluntarily) isn’t illegal. Things they may be doing that cause that tend to be purely subjective and individual, and many people will disagree it’s even happening!Punishing them for those may be vengeance, or revenge, lashing out, or whatever.And since no one can make someone happy (or unhappy), and there isn’t even an objective measure of it, society generally doesn’t care about that legally. What would accountability mean in those cases then?Going to jail because people don’t like you as a boss?Making a hostile work environment is already against the law and actionable, if it can be proven. It’s a reasonably high bar though, and most environments people are pissed about around here likely don’t meet it.It’s up to everyone individually to make those decisions and tradeoffs. They’re accountable for the results of continuing to work somewhere, or not, for instance.It’s a two way street. In the sense of;“The law, in its majestic equality, forbids rich and poor alike to sleep under bridges, to beg in the streets, and to steal their bread.” ― Anatole FranceIt may not be great, but other alternatives are so prone to abuse and shittiness that I personally haven’t seen many better alternatives. reply johnny99k 17 hours agorootparentprevI have had co-workers that got paid the same amount as me and did much less (and knew less). This happens with any job and is not exclusive to management.This sounds like &#x2F;antiwork fan fiction. reply lazide 15 hours agorootparentIt’s often ‘I killed myself making everything perfect, and that asshole didn’t even say thanks!’.Some bosses encourage it, some bosses try to discourage it (and fail), some bosses don’t even notice.Been on both sides. In the end, the ‘hero’ is usually the one that is the actual problem, unfortunately, and can’t stop. reply Raidion 18 hours agorootparentprevI think that&#x27;s what&#x27;s weird about it. You&#x27;re not paid for your work, you&#x27;re paid for the value your work is expected create (although of course there are inefficiencies).Someone with experience in a higher level role can make it look easy, and it is objectively &#x27;easier&#x27; than a lot of jobs. &#x27;Easy&#x27; discounts the work someone has often had to do to get into those roles, but it also highlights how privileged some of these people are.Having a family that prioritizes education, the education actually being good, having the ability to focus on studies instead of needing money or to take care of family, the ability to go to college without worrying about finances... All these are huge levers that get people into these director+ roles, and those are things that aren&#x27;t available to the wide swath of humanity. People do amazing things despite these challenges, but it&#x27;s clearly harder to do. reply PH95VuimJjqBqy 18 hours agorootparentprevThis was basically my reaction when reading that post.There are definitely crappy managers who don&#x27;t bring much to the table, but a good manager does those same things but is a lever for their teams (and are invaluable as a result). reply strikelaserclaw 19 hours agorootparentprevpeople who&#x27;ve always been rich won&#x27;t have much issue making money without working hard but for people who need to move up the ladder, i&#x27;m afraid without working hard you just can&#x27;t make that leap. You have to work hard and work smart, optimizing for a long term success.Too many people forget about the second part of the equation which is optimizing for long term success. You optimize long term success by constantly learning, creating and using that to leverage into positions with more responsibility &#x2F; higher impact. reply stratigos 19 hours agorootparentprev\"basically answering emails\" is usually also done within a context of subject matter expertise and long term career experience. This is akin to saying \"programmers just bang on a keyboard and clock out at the end of the day, easy!\" reply bluefirebrand 19 hours agorootparentWhen you&#x27;re above a certain level you are not the subject matter expert anymore, you hire subject matter experts and have them give you options.Maybe this isn&#x27;t true in companies you&#x27;ve worked for, but it&#x27;s still pretty common for \"engineering manager\" to be a title held by an MBA with no engineering knowledge. reply pierat 17 hours agorootparentI had a job where the systems engineering team was lead by a person who had an MBA, and didn&#x27;t even know what an IP address was. And they were making customer decisions like \"This deployment MUST happen tonight no matter what\".I plainly said \"I will do my best to do the deployments, but if deployment scripts fail, I will NOT risk customer data to complete this task\".The CTO overheard this dictate by our manager. The CTO backed me 100%. And, she was the previous syseng for our dept, and worked up the ranks from helpdesk->syseng->cto. Fucking sharp lady. reply Our_Benefactors 17 hours agorootparentprevI personally have never had a manager who did not at one time or another demonstrate detailed and outside technical knowledge. Maybe I am an extremely lucky outlier but I’ve yet to encounter the mythical MBA Engineering manager. Maybe things have changed over time? reply confidantlake 13 hours agorootparentI didn&#x27;t either until I did. I think it is more common outside of \"tech\" companies. replyjohnny99k 19 hours agorootparentprev\"When you layer all of these facts, it&#x27;s really hard to sign up to be a hard worker. It feels more like punishment once you learn how easy the rich people have it.\"Play the game, get rewarded. I&#x27;ve been a hard worker my whole life, but I now limit my total output, so my employers don&#x27;t expect me to over-work myself 100% of the time. Life becomes much easier after this.It also helps that I&#x27;m an hourly consultant. When the shit hits the fan and a company tries to force me to work nights and weekends to make a deadline that was a result of their incompetence&#x2F;mis-management, they now have to think twice about it because it directly affect the budget. reply itsoktocry 18 hours agorootparentprev>There is also a separate, much bigger lesson in that if you make friends and&#x2F;or play politics, you also don&#x27;t have to work as hard and still get rewarded (sometimes massively).Because there is more to success and life than \"hard work\". Who can blame people (with money) who are willing to pay extra to be around people they want to spend time with (\"make friends\")?There&#x27;s a trope in the tech work that people should tolerate \"angry nerds\" because they are 10xers or whatever. Most of the real world doesn&#x27;t operate that way. reply mcpackieh 16 hours agorootparentprevSynthesis: Work hard at making friends and playing politics. reply regentbowerbird 19 hours agoparentprevYou make very good points and I personally agree with you fundamentally, however your example is a bit exaggerated: there are very few jobs where just \"working harder\" will lead to a 10× jump in compensation. Making 600K$pa would put someone in the top 1% of earners in the US, obviously not something generalizable to the entire population.I do agree one must stay on the lookout for opportunities where working harder is rewarded, and also that one should try finding some joy in work. But also that one must stay realistic in their expectations, and that much joy is to be found outside of work (relationships, hobbies, discovery, leisure, etc). reply brightball 19 hours agorootparentMy first job out of college was at a telco making $72k &#x2F; year.I worked my tail off. Worked late. Never missed deadlines. Signed on after hours. Learned a lot. Followed process. Took lots of pride in my work.And I got a lot better at what I do.When 2 members of my 3 person team departed and all of the work fell to me, I asked for a raise to $90k. Seemed reasonable to me taking on the work of 3 people given my track record.I was told that wasn’t possible. So I interviewed elsewhere with my updated resume and turned in my notice. Within a day of turning in my notice I got a counter offer.Apparently, one of the corporate policies at this telco was to only offer significant raises for retention purposes if the employee had another offer. Which was nuts but apparently the only way to find out if you were valued was to interview elsewhere.At that point, I was so annoyed that I decided to leave anyway…to another job where I worked long hours and was on call. But I learned a lot.The hard work paid off and I haven’t actually had to interview for a job in about 15 years.This is what I think about when I hear people talk about not putting in the extra time. If I’d done that, done only the job exactly according to minimum expectations I would have collected a paycheck…and probably been stuck in the same place. reply garciasn 17 hours agorootparentNever. Ever. Ever. Ever. Ever. Ever. Accept a counter. Never. Why?If they didn&#x27;t recognize your value before and they only recognize it when you threaten to depart, they aren&#x27;t respecting you any more w&#x2F;the counter; they&#x27;re just using that to stave off the impending issues that arise and will likely take any future opportunity to recoup that &#x27;loss&#x27;.I actively advocate, in advance, for my team. They have clear expectations on what the next step in their career w&#x2F;us is and have a general idea of what to expect salary wise when they reach it. If they&#x27;re looking, it means that I have failed them in my #1 core competency and priority as a leader to ensure they are getting what they need out of their day to day and I would prefer they openly communicate with me in advance of their feeling a need to look.If you are not getting this out of your current leadership, find a new job where your leader will be someone will be that advocate for you. Very often, people are a company&#x27;s most valuable asset and they should work hard to retain that asset without rigamarole. reply somsak2 12 hours agorootparentI think the first thing I struggle with in this worldview is that companies don&#x27;t think about roles as \"how much value\" they bring to the business. If they did, most ICs would be paid far more highly. But since employees negotiate as individuals, and companies negotiate as huge orgs (or cartels of orgs a la https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;High-Tech_Employee_Antitrust_L...), an employer is able to pay you just enough so that you won&#x27;t leave.Without a competing offer, how can they be sure that you&#x27;ll actually leave? Showing them that you can forces their hand. But you&#x27;re still extremely unlikely to be receiving anywhere close to your supposed \"value\" to the business, and unfortunately mere managers can&#x27;t really change such a fundamental misalignment. reply pdimitar 17 hours agorootparentprevI wish a had a manager like you, even just once in my life.sighs deeplyKeep up the good fight. I hope your people appreciate you. reply garciasn 17 hours agorootparentThey claim to like me and, being that several of them have worked with me at multiple companies over a 15 year span and at least one other has requested I take them with me in the future, I would probably say they appreciate my style.That said, to respond to another commenter, policy can certainly cause friction with this sort of methodology and I have definitely run into it in the past. But, leaders exist to navigate company politics so their direct reports have more time to deal with the work they do; any friction encountered that is insurmountable points to deeper organizational issues and can (and in my case does) necessitate my moving somewhere that allows me the autonomy to build strong teams and develop high performing teams. reply startupsfail 17 hours agorootparentprevIt doesn’t harm to negotiate. Yes, there was clearly a failure, but it could have been a middle management or HR level fail. Or a poor policy. reply itsoktocry 18 hours agorootparentprev>Apparently, one of the corporate policies at this telco was to only offer significant raises for retention purposes if the employee had another offer.Yes, and I&#x27;m not sure if I feel completely negative about it. On the one hand, just pay up if the value is there, don&#x27;t play games, right? On the other, the employer is \"calling your bluff\" about it being, more or less, about money alone. In the end, the policy works, I think. reply zmgsabst 16 hours agorootparentI consider it a red flag when employers take antagonistic positions, such as “calling my bluff”.That shows a clear level of disrespect and willingness to play games with my life — and is the sort of outcome one should expect if you allow departments like HR to engage in dark triad behaviors inside the company.HR treating employees like cattle to exploit is a Day 2 failure mode. reply somsak2 12 hours agorootparentHow else can an employer decide who to give a raise to or not? What prevents everyone from asking for a raise?I think the employer-employee relationship, especially when it comes to salary, is inherently antagonistic because our interests are basically 100% oppositely aligned. An employee always wants to be paid more; an employer always wants to pay less. reply zmgsabst 9 hours agorootparent> an employer wants to pay lessYour dark triad mentality is showing through:An employer doesn’t have an inherent reason to pay less — they have an inherent reason to increase value of the company.That people conflate the two goals of the company is purely a result of unchecked dark triad thinking in HR — and the preference of exploitation over growth.This is a Day 2 failure mode because the substitution of your real goal (“make more money”) for a dark triad goal (“maximally exploit my workers”) leads to self-defeating behavior on the primary goal: you make less money by exploiting your workers.However, as it satisfies the desire to abuse from unhealthy people, we tend towards that defective behavior when dark triad behavior isn’t regulated appropriately. reply rcbdev 3 hours agorootparentI have worked for two big American companies (global headcount ~300-400k) and two big companies from Europe (global headcount ~50-70k - hard to find any bigger that have their HQ here).These \"dark triad\" corporate failure modes you describe I&#x27;ve always suspected are a distinctly US-American phenomenon and I have always avoided companies headquartered in the US because of this. We do have exploitative companies founded here as well of course but their practices pale in comparison to what I&#x27;ve seen people go through at the American counterparts. reply somsak2 5 hours agorootparentprevI wouldn&#x27;t necessarily say that wanting to pay an employee less is \"exploitive,\" just as I wouldn&#x27;t label an employee&#x27;s desire to make more an attempt to exploit the company either. I&#x27;m just saying that those are opposing goals that are going to make it difficult to build a fully aligned relationship between the two parties.Not sure I really understand how this position relates to the Dark Triad concept. I thought that these days DT was really only bandied about by people in the pick-up community with something to sell to frustrated men. reply zmgsabst 3 hours agorootparentI would call attempting to earn more than a fair share of the value you create “exploiting the company”. You’re the one creating a false impression by insisting that those are the only goals one could have in this situation:You can interact in modalities besides trying to maximally exploit your partner — and game theoretically, those cooperative modalities are dominant.The mistake you’re making, due to viewing the world through a Machiavellian lens, is supposing that’s the only or even optimal strategy — when empirically and theoretically it’s not.That you closed out with a lame insult (“muh incels!”) shows perhaps my comment struck closer to home than you’re comfortable with. reply lazide 15 hours agorootparentprevSure. It’s also really common. reply zmgsabst 8 hours agorootparentSure — and literally flies your planes into the ground.Ask Boeing. reply lazide 7 hours agorootparentSure - and do you think that means it doesn’t exist after that, or will cease existing at any point in the future regardless of how much we want it to? reply zmgsabst 3 hours agorootparentSure — we see that behavior routinely destroy companies who engage in it, while the opposite causes corporate growth.This creates a constant flux of new companies engaging in healthy partnership with their employees and old companies cycling back to rekindle growth — and which removes the ones who engage in that problematic behavior, persistently.So that behavior always brings about its own cessation.See my point about “Day 2”.Engaging in Day 2 policy is a choice; working with Day 2 companies is a choice.There’s nothing at all which requires this phenomenon, other than people make lame excuses as if dark triad behavior is some unavoidable law of physics. replybrightball 18 hours agorootparentprevYep. The older I get, the more I understand it too. reply pierat 17 hours agorootparentprevAnd this is why pay transparency is a legal right, as part of discussing working conditions with colleagues.Then again, I think the next step to move towards is to recognize that we techies are going towards \"factory code-work\", and to respond with unionization appropriately. And unions arent just for getting more money, but also demand for payment of overtime, sane vacation policies, remote work, and more.And yes, I&#x27;m an 8-n-skate. Want me longer? Fuckyoupayme. I dont work for free. reply JusticeJuice 19 hours agorootparentprevYeah. You don&#x27;t get paid for hard work, you get paid for experience applied to lucrative problems. reply orochimaaru 18 hours agorootparentActually you get paid and promoted for making your vp and csuite earn brownie points. reply nostrademons 16 hours agorootparent...which is the \"applied to lucrative problems\" part. VPs and C-suites get brownie points by making money. reply orochimaaru 11 hours agorootparentNot always. It could be for starting new lines of business or just plan political wrangling. May even be something that loses the company money. reply __xor_eax_eax 18 hours agorootparentprevThats where the experience comes in reply sangnoir 18 hours agorootparentprevIMO, you don&#x27;t get paid for experience either. You get paid the minimum amount your employer thinks they can get away with without you leaving, capped at some fraction of the value you add,(less overheads, risks, etc). reply uberduper 18 hours agorootparentprevIt&#x27;s common for performance based RSU grants to stack up to this sort of total comp over a few years. reply tetha 18 hours agoparentprevAn example I have from work is: We all have the idea that we&#x27;re working 40 hours a week, on Monday to Friday, averaged across two weeks. This sets the normal pace, but I have no problem pulling one or two 12 hours days to put out some massive production fires. It just has to be clear: This means at least 1 day of me not working, usually - if you add in overtime rates - much rather 2. Weekend work is handled in a similar way. 3-4 hours on a weekend are 1 weekday off.If a company respects this and cooperates this way, I&#x27;m perfectly fine pulling long hours if necessary, or weekend work if the criticality explains it.But at the same time, if you start micro-managing my hours and start being picky if I organize my hours on a day around some long-running tasks I just need to wait for... I mean be happy I&#x27;m doing laundry off the clock or counting reduced time while the archive system is shoveling data towards servers, which requires minimal monitoring. And I have a phone notification setup if it does something weird. reply PH95VuimJjqBqy 18 hours agorootparentThis has always been how I work as well.If you call me at 10pm I&#x27;ll pick up the phone, if I roll in late or sneak out early or take a long lunch, I don&#x27;t want to hear anything about it. quid pro quo. reply PH95VuimJjqBqy 18 hours agoparentprev> In contrast, working hard in a place that doesn&#x27;t reward you is sad. Slacking in a place where you can succeed more if you try harder is also sad.I understand the place where this comes from, but I don&#x27;t agree. I think this is a very personal thing and there cannot be a single approach that works for everyone.But for me, if I&#x27;m not trying my very best I can&#x27;t continue doing the job. I&#x27;m internally motivated, I know that I&#x27;m doing a great job and can be proud of the work, I don&#x27;t need others to tell me.I can think of two jobs I left over these sorts of issues.One was abusive -- VP told my manager to write me up over an email I sent out asking a question about software they were using. That was on a Thursday, I was gone the following Monday. I was later told that VP was removed because she regularly made people cry (she was just mean).One because I realized the politics meant I couldn&#x27;t do a good job. I had stepped into a fight between a manager and a CISO and the CISO made sure we were setup for failure. 2-3 months after I left they moved the manager directly under the CISO and he quit.but in general I&#x27;ve not found myself getting exploited. That doesn&#x27;t mean I always agree with what management is doing but it&#x27;s generally been well-meaning by earnest people and I sometimes think if people feel they&#x27;re constantly running into management like this they might be mis-interpreting. Oddly enough, I&#x27;ve found the larger companies (multi-billion dollar companies) to be more pleasant than smaller companies where it seems tribalism is much more rampant. reply xyzelement 18 hours agorootparentI totally agree and thank you for sharing these anecdotes. I think your point is a good one - ideally you find yourself in a work environment that lets you be the kind of employee you want to be (and ideally that means a productive and engaged employee in a rewarding environment) reply ulnarkressty 19 hours agoparentprevI&#x27;m curious how the rewards in the \"best places\" to work look like. There was a famous study that found that developers are happy when they get enough money not to care, but in real life this doesn&#x27;t seem to be the case. Whenever I speak with my management buddies, they always lament about engineers who complain they&#x27;re not being appreciated enough. When asked what proper appreciation would look like, they always give various answers which always boil down to money (i.e. \"you could praise me in front of everyone for the great job I did, but actually want a raise &#x2F; more money than the guy I perceive to be a slacker\").If we&#x27;re being honest, one is employed by the company to make them money, so it will always more or less boil down to this. Would anyone be satisfied that they made their boss a million more, while getting a pat on the back and the same salary? reply xyzelement 18 hours agorootparent(I am the person you&#x27;re responding to). For me personally, comp is an indicator that I am working on something important and that I am being appreciated - so yes, when I talk about being \"rewarded\" I am talking about comp and other tangibles like flexibility, etc. in addition to respect. And look, if a company has been good to me but there&#x27;s a tough year and everyone gets small raises, I can roll with that as part of the longer term commitment, but that has to be offset by fat raises in fat years.This might be different for people who are happy to work for small comp in a non-profit or a lean startup, but I struggle to relate to that personally (doesn&#x27;t mean they are wrong but its not for me.) reply eschneider 18 hours agorootparentprevPraise is cheap. If a company really appreciates you, they will give you money. It&#x27;s how they keep score. (Or some cash equivalent like stock, or options.) reply red-iron-pine 17 hours agorootparentto paraphrase Mad Men:\"you don&#x27;t appreciate me!\"\"that&#x27;s what the money is for!\" reply hashtag-til 19 hours agoparentprevThe employee side of it is to become the \"de facto\" owner of something important, and making the calculated move to \"big salary raise or I&#x27;m leaving\". Obviously you need to be backed up with another offer and be prepared to leave.You can&#x27;t use that often, but doing it at the right time, it works. Worked for me at least :) reply xyzelement 17 hours agorootparent&#x2F;&#x2F; and making the calculated move to \"big salary raise or I&#x27;m leaving\"Even better is to be in a place that&#x27;s smart enough to pay people to begin with because it hires the \"best\" (ie people with options.) reply hashtag-til 17 hours agorootparentAgree, but over the years - and being in the meetings salary raises are discussed&#x2F;approved&#x2F;rejected - I see this pattern that companies only act if they perceive urgency.The quiet person doing an absolutely amazing job is never seen as an urgent case. It is sad and I don&#x27;t agree with this view at all, but my opinion is not enough to change the system, so I need to live with it. reply xyzelement 17 hours agorootparentEven in that case, I&#x27;d never do the \"big raise or I am leaving\" move and I wouldn&#x27;t respect someone who did. If you gotta play that card, I&#x27;d do something much softer like \"hey, I love working here but it&#x27;s getting a little hard to keep hanging up on these recruiters offering me 3X.. can we talk?\" reply hashtag-til 15 hours agorootparentI respect your PoV and I know lots of people who consider “big raise or leave” move unethical.Personally I think it is a negotiation and a financial transaction - I’m trading my time for my salary and I better make the most out of it.At the same time - from a negotiation perspective I find unlikely showing your hand in the way you describe is going to work in your favour. In practice, it also has the potential to backfire and you being branded as “disengaged” and a “flight risk”.PS: please note I’m saying this in good faith, don’t read my comment with a snarky&#x2F;sarcastic conotation :) reply gedy 15 hours agorootparentprevWhat&#x27;s the difference?I&#x27;ve done this, and company didn&#x27;t take me seriously. So then I did get an offer and said I&#x27;m leaving - then they actually did something. reply red-iron-pine 18 hours agorootparentprevtold a coworker to do the same thing recently, lol.like \"bro if you get hit by a car things are gonna get ugly -- so leverage that\"we&#x27;ll see if he will reply TimPC 19 hours agoparentprevI think the right strategy is to try and select for a place that rewards you properly for hard work in interviews. If you&#x27;re in a place that doesn&#x27;t slacking is generally bad for your career so my advice is mostly to move on rather than slack. It&#x27;s very hard to keep your career on an upward trajectory if you put in two years of slacking somewhere. At some point that&#x27;s going to hurt you in terms of the sharpness of your knowledge and what you can demo&#x2F;talk about on your successful projects when interviewing. reply vsareto 18 hours agorootparent>At some point that&#x27;s going to hurt you in terms of the sharpness of your knowledge and what you can demo&#x2F;talk about on your successful projects when interviewing.I don&#x27;t think this is a real problem IMO. If you learned it in the first place, you can learn it again after slacking off for a bit. You might need a few months for the focused effort, which is honestly not a cost but probably what we in the industry call a sabbatical.It may add some risk to getting a job if your life is suddenly turned upside down after slacking and you need a job right this instant. That slacking might fail you some interviews, but not all of them. Even in this situation, there are financial options and temp jobs to get by with.I don&#x27;t think anyone should ever be convinced that if you stop practicing something that your ability disappears completely. I&#x27;d put some faith into the idea that you can relearn it just as well or better when the need arises. reply TimPC 15 hours agorootparentI&#x27;m not saying your ability disappears completely. I also think it depends on the job market you&#x27;re in. At my current company we interview under 1 in 1000 applicants because we get over 500 applications a day for open roles. The job market right now is not the same as the job market three years ago where you easily got 10 interviews, could pass 3 of them and then have a competitive negotiation with multiple companies. If you need to be in the top 0.1% of applicants to even get an interview you&#x27;re going to get far fewer interviews. This is especially true if you are trying to push the limits on compensation and applying for positions that may be a slight stretch for your current experience. reply tshaddox 18 hours agoparentprevHow do you determine if a situation is \"actually\" exploitive? On one hand, you could say that no employment arrangement is exploitative if the employee agreed to the terms. On the other hand, you could argue that every employment arrangement is exploitative if the employer is making profit and thus could may employees more than they are. reply Detrytus 17 hours agorootparent> you could argue that every employment arrangement is exploitative if the employer is making profit and thus could may employees more than they are.Employer is also bringing in the value to the relationship: most software projects, for example require more than one person. If you was just a freelancer you wouldn&#x27;t even be considered by the client, when they choose the vendor. Your company also insulates you from legal and financial risks (such as contractual penalties for not delivering the project on time). That&#x27;s why they take some part of the profit. Now, what the fair split is, that&#x27;s an endless debate. reply aidenn0 18 hours agoparentprev> I find that some people will perceive themselves to be exploited and orient their life around avoiding it, regardless of the situation...Right it works both ways; some people will be blind to being exploited. It really makes me doubt that I have anything even remotely close to an objective view of things that are close to me. reply xyzelement 18 hours agorootparent&#x2F;&#x2F; makes me doubt that I have anything even remotely close to an objective view of things that are close to me.So first of all, that is the wisest perspective on life! Human perception is objectively limited and recognizing that we may not be seeing (or even capable of seeing) reality is empowering.But on the topic of exploitation vs fair compensation, I don&#x27;t think it&#x27;s impossible to figure out where you stand if you can move your feelings out of the way. Say you&#x27;re a developer making 600K in my previous example, where an average dev is making I dunno, 150K. Being at 4X the average is a pretty good sign that you have a pretty decent gig going. Can you and should you push it to 700k? Absolutely! But probably no room to feel victimized.On the flip side, if you&#x27;re making 60K and hear of someone making 600K - it&#x27;s less obvious how much of that is you and how much of that is someone underpaying you because they are greedy or because they can&#x27;t? To suss it out - question #1 is - can they even afford to pay more? Like if you work for a mom-and-pop whose whole profit might be 600K for the year, you&#x27;re in a pretty capped situation no matter who you and and what you&#x27;d do, so in terms of pure comp you should find something else. And then - how do you know if you&#x27;re \"as good\" as the guy making 600K? One thing to try would be to interview for those FAANG jobs and see how close or far you&#x27;re to landing them. If you are capable and persistent, you find yourself there. Maybe not making 600 but not making 60 either. On the flip side, if you can&#x27;t then maybe you can&#x27;t and maybe 60 or something like that is fair.Still no guarantee of objectivity but this is how one would gather the data. reply aidenn0 17 hours agorootparent> But on the topic of exploitation vs fair compensation, I don&#x27;t think it&#x27;s impossible to figure out where you stand if you can move your feelings out of the way...See, I&#x27;d like to think that&#x27;s something I could (and already) do, but from the outside watching other people try to do this and fail utterly -- anything from \"If you have a boss, they are exploiting you period\" to blind loyalty to a company that clearly is exploiting people -- I do have to spend some time second guessing myself. reply Detrytus 16 hours agorootparentprev> Can you and should you push it to 700k? Absolutely! But probably no room to feel victimized.People always compare themselves to their peers. If you are making 600k at FAANG then yes, you are better off than those making 150k working for a small software company in Pennsylvania, but that is completely irrelevant to you. What matters is that your FAANG colleague, two desks away, is making 700k - he&#x27;s not better developer than you, is he? reply esafak 16 hours agorootparentMaybe not, but it helps to remember that productivity is hard to measure and that what they value may not be what you value. reply mlinhares 16 hours agoparentprevTrouble is that it is really hard to find these places and the place might be like that when you join and stop being it as it grows, so there&#x27;s never a good solution other than continuing to go other places and see if they&#x27;re better. reply dasil003 19 hours agoparentprevYeah it’s funny, I’ve generally always worked hard and been rewarded. Occasionally I’ve had a bad job or a bad boss and I’ve moved on quickly. I do have an anti-authoritarian streak (got me in trouble in school), but I’ve never felt exploited in the workplace.A big part of this is the privilege of working in software where my skills are highly valued. But even here I see people with a victim complex all the time. The whole “the only reward for getting done early is more work” indicates a deep misunderstanding of both the problem-solving leverage we have as software engineers as well as how to have your value be recognized by your employer. It’s not about working more hours, it’s about understanding the business and making your own work effective. This is completely orthogonal from maintaining clear work&#x2F;life boundaries, which you should also do, and most reasonable places don’t have a problem with. reply gitanovic 19 hours agoparentprevI totally agree. This is very on point reply epups 19 hours agoparentprevI really like your formulation of the issue. I am currently in a tough spot where I&#x27;m not recognised and rewarded, and after some reflection I had two choices: either I slow down to the level of everyone else, or I find somewhere else to work. I chose the latter, based on the perspective you describe here. For me, life is too short to waste it at half-power most of the day, and I actually feel bad when not working hard. Working only enough to pay the bills is probably more sane, but I cannot do it. The challenge now, of course, is to find somewhere where this attitude is adaptive. reply xyzelement 17 hours agorootparent(I am the person you&#x27;re responding to.) I think your attitude is right and will pay you in the medium or long term if not immediately. You can&#x27;t control what you can&#x27;t control but you CAN control a lot - how you work, how you look for job, etc. You&#x27;ll be fine! reply brightlancer 17 hours agoparentprevI suspect almost everyone on HN isn&#x27;t legally bound to their employer, so I also reject the \"exploitation\" bit.But I do want to challenge the compensation argument:> For example, it&#x27;s common to see HN posts describing someone as \"subjecting themselves to unpaid overtime\" when they work hard - meanwhile the person saying it is making $60K while the person being talked about is making $600K.Higher paying jobs naturally have higher expectations. OTOH, I&#x27;ve also had managers&#x2F; employers who used \"we pay you well\" an excuse for all kinds of garbage treatment, specifically _avoidable_ garbage treatment: short notice evenings, weekends, _holidays_; denying vacation to compensate for staffing; pressuring folks to return from (legally protected) medical or family leave; required to do work completely out of the job&#x27;s scope; and so on.Now, some jobs are inherently like that. If the expectations are set up front and adhered to, then it&#x27;s a free choice on each side. IME, lots of jobs don&#x27;t have to be that way, the expectations aren&#x27;t set up front, and expectations change. It takes only one jerk with a title to ruin things. reply thepasswordis 18 hours agoprevOne of the most depressing, nihilistic realizations I have had in my 30s is:* People don&#x27;t care about the work you do, they care about how you make them feel.* People will steal the work that you do, or imply that they were a part of it, when they weren&#x27;t.* Those people will employ what I had though were high school tier manipulative tactics by sidechanneling communications, or in the way they talk in meetings to imply that they are more useful they than actually or, or to imply they had a involvement in things they didn&#x27;t.* \"Middle managers\" love this stuff, and will promote and hire people who also play this stupid game.I have seen people share into our slack channels, or start meetings out by playing the most absolutely useless, tik-tok-level, linkedn-level garbage fake bizbro videos as if they are important useful business information that we need to incorporate into our philosophy.I&#x27;ve seen companies then go to hire these absolutely useless borderline pyramid-scheme bizbros, incorporate their useless vocabulary cancer, and bring them into our meetings and make us defer to them on things.This stuff is incredibly demoralizing.Loyal, good workers get exploited by these parasitic people because they care about the company, they care about their good coworkers, and they take pride in making good products. Obviously this stuff is all easily exploitable by the people I&#x27;m describing. reply turtledragonfly 17 hours agoparentI see your \"People X..., People Y...\" language, and I just want to note that over-generalization can be a path towards depression[1].I don&#x27;t mean this directed at you specifically, but it&#x27;s fairly common for people to take their bad experiences in a handful of places and extrapolate that to all places everywhere, and end up feeling depressed&#x2F;nihilistic, as you mention. I find myself doing it too, from time to time.So, maybe this is more directed at other readers who might see your comment and take it as validation of their \"everyone sucks\" suspicions — grain of salt, and all that.But I agree that what you describe is genuinely demoralizing and a crap way to be treated (: I hope you get to experience a good work life, if you haven&#x27;t already.[1] There&#x27;s a good amount of research on this topic (search for \"depression, over-generalization\"), in addition to my personal experiences. reply anotherhue 17 hours agoparentprevBeen there, seen that. I feel like culturally we&#x27;re told that this behaviour is unusual so we are constantly surprised. Some scepticism and school-of-life in our earlier education might be for the best, no matter how disappointing it would be to hear. reply silenced_trope 16 hours agoparentprev> I have seen people share into our slack channelslol I had to do this at my last job. My manager would say I need more visibility, share it with X team since it touches on their work.Then I&#x27;d have to be like \"Hey we just launched this project&#x2F;feature, look at it!\" And nobody in that team&#x27;s channel would comment on it.I felt the exact way you&#x27;re describing - I&#x27;m sharing something into a channel just to seem important.I&#x27;m not sure how to reconcile the need for visibility, there&#x27;s probably more subtle ways. Or alternatively being in the channel for a while and being part of discussions there rather than popping in just to give myself visibility when there&#x27;s something worth showing. reply betenoire 16 hours agorootparentI share your feeling. Here are some answers I&#x27;ve come up with for myself.If you want engagement... Your manager got you to share it by directly asking you to. You will have better luck receiving feedback if you follow that lead. You asked them to look at it, and got discouraged by the lack of any reciprocity. Ask for engagement, if that&#x27;s what you feel like you want. One effective way for me to do this is to share my assumptions. :)If you don&#x27;t want to feel like you are playing that \"importance\" game... Play it on behalf of your team, instead of you. Give kudos to everyone around you. And be genuine about it. reply mbrochh 7 hours agoparentprevHoly shit, my wife is working for a mega corp and is currently experiencing EXACTLY this.This is the reason why I will never join a company that has more than 100 employees. Once they get big, they all turn into cancer. reply hintymad 13 hours agoparentprevI&#x27;m not sure if this is avoidable in a big enough company when the density of talent keeps diluting. It looks the only exception is when the CEO was so strong that he hires only sharp managers, like in the early days of those explosive startups. On the other hand, individuals can avoid the trap by joining small enough companies when each person&#x27;s scope and contribution is clearly visible and measurable. reply Culonavirus 16 hours agoparentprevAaaah yes, middle management. The successes are always of their own making, but the failures are always blamed on the devs. Shit rolls downhill. The worst is the situation when there&#x27;s no buffer between IT and Business (ideally a person well aware of the constraints and requirements of both) and the person you report to is a \"bizbro\".I once had such a manager, who managed our small dev team, but he was not a coder, he didn&#x27;t have any IT background, he was a dude with business background... and the depth of which he was able to understand the business logic of our systems was on the \"typical user\" level (i.e. he used the systems, but had no idea what amount of work would additions and changes in these systems require). This person reported directly to our CEO. So of course we would spend obscene amounts of time on trash features which were complex to incorporate into the existing structures and most of which provided questionable business value in the end (i.e. a feature took 6 \"man months\" to develop and integrate, but its added monetary value to the business was probably similar or lower than that). Because of these bs jobs coming from the top, we were swamped with questionable work and our core systems and features stagnated. At the same time, hiring more people - adding to the IT team - was out of the question because we were already \"so expensive\". And so this person came up with a genius idea of offloading one of our core systems to an external entity (so we have more time to spend on his questionable tasks). I mean, fair enough if you do that while being well aware of all the business logic and make a calculated decision, but this person (and I don&#x27;t want to be too specific here) basically went behind our backs, told the ceo something along the lines of \"hey, we&#x27;re gonna offload system X to entity Y for Z amount of money, so our IT has more time for other important stuff\" and then, once everything was a done deal, came to us that we&#x27;re going to integrate Y. Long story short, we spent about 2 years (on&#x2F;off) on replacing our X to work with Y, tightly integrating it with Y&#x27;s api (and that company in general), having around a dozen of 2-5 hour meetings, Y updating their system like 10 times so it even does what our system X did 5 years ago and spent a crap ton of money on all of this (easily more than new hires would cost). Why would it take two years, why wouldn&#x27;t we cut our losses? Because sunk cost fallacy and because the manager couldn&#x27;t admit fault to the ceo. We were going to do this because it was his idea. reply jcomis 16 hours agoparentprevI worked for a large consulting company and this sort of behavior wasn&#x27;t just present, it was actively sought out and rewarded. I was part of an acquisition that was slightly removed from it, but watching these absolutely toxic dynamics take place was really eye opening. reply mouzogu 15 hours agoparentprevtoxicity starts at the top.upper management hire bull-shitters who tell them what they want to hear or who will execute the unpopular things they don&#x27;t want to do....and so on down the chain. reply red-iron-pine 16 hours agoparentprev> People don&#x27;t care about the work you do, they care about how you make them feel.this is true, but also keep in mind having a project that delivers engenders a lot of good feelings.it sounds to me like the parent poster doesn&#x27;t get that politics and maneuvering is everywhere, from restaraunts to FAANGs. Some places are definitely worse than others, for sure, but it&#x27;s an inevitable facet of human nature, and you can&#x27;t ignore it.Not playing the game or picking a side still means you&#x27;re picking a side, and side that is one that will often has less say. reply lambdasquirrel 17 hours agoparentprevIt’s not just work. It’s social scenes and people in general. It’s an uncommon person who does right by other people. reply acuozzo 20 hours agoprevI worked many different blue collar jobs in New Jersey as a teenager¹ in the early 2000s and I learned that every blue collar workplace has one or more of these \"go-to\" persons.They&#x27;re always there early AND late. They never, ever turn down requests for MORE X even if they&#x27;re salaried and even if it makes their lives unnecessarily difficult.They&#x27;re often the ones most visibly damaged by the job, but they also irrationally defend their abusers. Perhaps they think that they&#x27;ll be promoted one day, but why would a manager promote their best underling, especially if they&#x27;ve shown that they&#x27;ll never be a flight risk?[1] Seriously, I started at fourteen and job-hopped ~2x&#x2F;year: a \"schoolyear job\" and a \"summer job\". reply walleeee 18 hours agoparentI don&#x27;t think some lingering hope of promotion is the likeliest motivator for people who pour themselves into relatively poorly compensated work. Many people take pride in something for its own sake, and&#x2F;or for the value it provides to others. I would argue these people are a massively underappreciated force in the world, and a big reason anything works at all. For every ladder climber slashing and burning their way through the social fabric, there are dozens of people quietly going about their days cleaning up debris, providing largely unseen services, perhaps even with little awareness of the significance of their contributions.This is of course a caricatured oversimplification, and I am in no way defending abusive arrangements, but I worry that the relative proportions of each type seem to be changing, and not in a promising direction. I also worry about the normalization of scorched earth, such that a young person might never learn, or learn only later, that the latter is not the only or the most rewarding approach to life. Finally I worry there is a similar lesson still to be learned at the species level: reciprocal partnerships with ecosystems and other living beings tend to produce better long term outcomes than opportunistic extraction reply ip26 7 hours agorootparentKim Scott’s superstars vs rockstars. reply omgmajk 20 hours agoparentprevI was this person at my old job. It was never about a promotion for me but some misplaced sense of a work ethic that was somewhat drilled into my brain. I&#x27;ve turned around since then and still do a lot but not too much. reply 3seashells 20 hours agorootparentProtestant work ethics ruins life&#x27;s. reply BoxOfRain 19 hours agorootparentI think the tendency of the Protestant work ethic to find value digging holes only to fill them in again over simply doing nothing at all in the first place is quite a negative thing; that&#x27;s not the same thing as saying hard work in general is a bad thing, just that it&#x27;s both the hard work and the ends it&#x27;s being put to that are important rather than work itself being intrinsically a good thing.I think there&#x27;s nuances here, I imagine we can all agree that the Victorian workhouse is not an institution anybody ought to revive for example while also appreciating that not all hard work has to be exploitative. reply hn_version_0023 18 hours agorootparentIME, there’s a difference between hard work and toil, which the Protestant work ethic is unable to discern.Often the toil is the point. I’m stuck in one of those jobs presently and am aggressively interviewing. reply lazide 14 hours agorootparentToil is a good way to distract from the bigger issues that are too overwhelming to contemplate.And the work ethic is rarely Protestant, but really a stress reaction for a certain percentage of the population. One that is very hard to get out of once it starts. reply halfmatthalfcat 19 hours agorootparentprevOr gives meaning - it&#x27;s possible to derive value from doing successful hard work outside of any external validation (promotions, accolades, raises, etc). reply anigbrowl 9 hours agorootparent&#x27;Meaning&#x27; doesn&#x27;t pay the rent or preserve your job if you appear in the wrong part of someone&#x27;s spreadsheet. It&#x27;s dangerous to internalize concepts like this because you will get shafted by people who don&#x27;t share them. reply giraffe_lady 19 hours agorootparentprevDo people who say this sort of thing not have families? Put your hard work in at home, in your own community. It&#x27;s still work if no one is paying you for it. reply thfuran 19 hours agorootparentDo people who say that sort of thing work for a company that they believe is totally worthless? Work can still be valuable (to one&#x27;s community even) if someone else is making money from it. reply everforward 19 hours agorootparent> Do people who say that sort if thing work for a company that they believe is totally worthless? Work can still be valuable (to one&#x27;s community even) if someone else is making money from it.Sure, the value is just distributed the opposite of the way most people would like it to be. The vast majority of the benefits accrue to a practically random individual, some goes to the worker, and a tiny bit trickles to the community.I would wager most people are far more interested in situations where the worker and community benefit greatly, and a tiny bit trickles to whoever owns the business.Besides that, if you wanted to benefit your community there are much better and easier than ways than grinding away at work and being proud of the income tax you pay, I guess? reply thfuran 19 hours agorootparentYes, I&#x27;m sure a community without doctors or nurses or social workers or public defenders would be glad about all that retained value. reply chownie 18 hours agorootparentFrom the guidelines:Please respond to the strongest plausible interpretation of what someone says, not a weaker one that&#x27;s easier to criticize.----------The vast majority are not doctors, nurses or public defenders. The vast majority work for private companies whose direct value to the local community is much less obvious, with the exception of paying people who (might?) live close by to the business. reply PH95VuimJjqBqy 14 hours agorootparentplease don&#x27;t do this, it&#x27;s the lowest form of rebuttal and is itself technically breaking the guidelines. reply PH95VuimJjqBqy 14 hours agorootparentprevIt&#x27;s not even the company, it&#x27;s your coworkers and a sense of responsibility towards them. Never at the expense at being abused by the company themselves, but I have to imagine those that don&#x27;t see the value in being trusted by your coworkers (and trusting them in return) are probably just really crappy coworkers.Shitty companies exist and you must always be prepared to protect yourself against abuse, but it&#x27;s ridiculous to look down on those who want what they do 8+ hours a day to have value. reply giraffe_lady 19 hours agorootparentprevThey specifically mentioned work as meaning-making. And no work provides meaning as raising children or spending time with my elders does, no. Once I&#x27;ve met my obligations to my employer my extra energy goes into my people. reply halfmatthalfcat 19 hours agorootparentI think you took what I was saying as giving exclusive meaning. Work is just a part of life. I&#x27;m not seeing anybody making the argument that work is the ultimate meaning of life. reply ilovetux 18 hours agorootparentYou might not be seeing it here in these comments, but there are definitely workplaces where you are scoffed at if make a request like taking the afternoon off to go see your child play soccer.These places thrive on people forgoing any personal life in order to line someone else&#x27;s pockets. reply lazide 14 hours agorootparentprevHaving been in a situation where helping out with kids caused massive insecurity issues and resulted in major problems, and helping with non-profits resulted in being stalked by some very problematic people?Be careful what you wish for. reply halfmatthalfcat 19 hours agorootparentprevI&#x27;m not sure why you can&#x27;t put hard work into home, community and your job? Is there a specific reason you think that is the case?You could make the argument that working hard at your job is setting an example for your family (kids) and community (through leadership&#x2F;running a successful business&#x2F;employing people of the community&#x2F;etc). reply giraffe_lady 19 hours agorootparentIf you have as much time as you want and never get tired then sure, do it all. Most people seem to experience tradeoffs between these things but I&#x27;m sure some don&#x27;t.For the second thing, you could make that argument. Are you? Because I&#x27;m old, and our fathers mostly considered \"good parenting\" to be work as hard as possible outside the home to aspire to wealth and model hard work. And I don&#x27;t know any of my generational peers that aim to emulate them in this, because it makes you a distant and uninvolved member of your family.So if you&#x27;re going to make this argument for yourself you certainly can. I&#x27;ve experienced first hand what \"setting a good example\" through labor does for your children. reply halfmatthalfcat 19 hours agorootparentI see what you&#x27;re saying and I very well may have a father who fits the archetype you&#x27;re describing but it&#x27;s hard to generalize or stereotype because there&#x27;s so many family dynamics at play when we grow up. Not denying your experience, I&#x27;m sure the \"alpha male, hard worker\" father figure (or parent figure) has had a net negative in some families but in my specific instance, it&#x27;s brought passion and ownership into other parts of my life (marriage, kids, etc).It&#x27;s also made me realize that yes, I want to be there for my kids more than my dad did, but I also have personal goals related to work that I want to accomplish in my life, more macro-level goals. It&#x27;s also made me more involved in my community because I want more ownership in what&#x27;s going on around me. It&#x27;s definitely a balance and you need the self-awareness and time management to finese it. reply c0pium 12 hours agorootparentprevI know a lot of people whose parents set a good example by working hard and moving up, and were also very present to them. It’s pretty normal in my peer group for this to have been the case.The fact that your tiny view of humanity doesn’t include those people doesn’t mean they don’t exist. reply lazide 14 hours agorootparentprevMany times doing that will cause far worse problems, especially at home. Work is at least ‘safe’. reply vkou 16 hours agorootparentprevIt would be nice if my landlord derived value from doing the socially useful service of providing housing outside of any external validations like the rent I pay him. reply octokatt 14 hours agorootparentprevIt&#x27;s the Protestant Work Ethic combined with Puritan&#x2F;Catholic Guilt that really gets you. reply tehnub 14 hours agorootparentprevAs if people working hard doesn&#x27;t occur all over the world and throughout history. reply esafak 15 hours agorootparentprevNot if you are your own boss. reply convolvatron 19 hours agorootparentprevshould we really aspire to being a useless lump? I firmly believe that there is great personal value to be found in the work of creation and digging an ever deeper groove.if someone is taking your passion and making money so that they can be a useless lump - that&#x27;s really fine. its sad if they ruin your work because they don&#x27;t care or know better. and of course its ultimately critical to cultivate relationship and build families - so its not _everything_.life without work is pretty empty reply bluefirebrand 19 hours agorootparentLife without work is only empty if you&#x27;ve been raised on a protestant \"work gives life meaning\" attitude and you can&#x27;t envision any other way.There are monks living in mountain monasteries who spend their whole lives in quiet reflection, doing basic chores and making basic meals, and they believe they live the richest lives possible.I&#x27;m not saying we should all be monks, but this idea that work is the only way to live a fulfilling life is very narrow, and very much cultural. reply dzikimarian 18 hours agorootparentHello. Probably no single protestant influenced directly how I was raised and I still think, that doing something that you don&#x27;t care about for 8h a day \"because I need money\" is tremendous waste of life, if you have any other option (as probably most of HN does). reply randomdata 18 hours agorootparentprevA so-called hermit monk may achieve complete solitude, but even most monks will spend some time trading something they have of value with other monks (and possibly beyond).That&#x27;s all work is. A state of: I can do something for you, and you can do something for me, and we see ourselves as both being better off for it. Sometimes practical constraints means something cannot be delivered immediately, so a party may promise to deliver it later. That is all money and accounting is – a record of the promises made.We&#x27;re social creatures. I expect most do truly do see life as being empty if they cannot grow with other people. Protestantism may have taken notice of that, but it didn&#x27;t invent it. reply robertlagrant 19 hours agorootparentprevThe point is that we need something to do, to feel useful. Sitting on a beach all day every day would get pretty dull, even if it is a common dream life.I don&#x27;t think this is particularly cultural. Most people who survived history did so through work so their children lived, or through raising children to be survivors. That&#x27;s worth considering, instead of just blaming culture. reply bluefirebrand 18 hours agorootparentI think \"we need to feel useful\" is absolutely a cultural thing, or at least how we define what \"useful\" is cultural.Again, the monks believe they live rich lives without being \"useful\" by North American standards, that&#x27;s certainly a cultural thing.In North America our culture strongly believes a person&#x27;s value is linked to their usefulness.That&#x27;s not up for debate really. I mean you can try to argue it&#x27;s not, but honestly look around. Look at what value we place on people who are homeless, addicts, crippled, blind, deaf, or hell, even someone who is just unemployed.We look down on them heavily. We judge them as having lower value because they are less useful.Even look at the original comment and the disdain for \"useless lumps\"This attitude doesn&#x27;t exist everywhere. Don&#x27;t try and say it&#x27;s not cultural. reply robertlagrant 18 hours agorootparent> Don&#x27;t try and say it&#x27;s not cultural.You seem to have only one counterexample: monks. Why would you assume that their highly unusual replacement of this by devotion to God is the less cultural option? reply Apocryphon 17 hours agorootparentAlright, how about Ancient Greek philosophers? reply robertlagrant 16 hours agorootparentSimilarly unusual, no? Compared to the number of people who aren&#x27;t that? Of course a society that works to survive (which is to say: all of them) can sustain a few people not working. But that&#x27;s not because they&#x27;re culturally advanced people in a world of backward thinkers. It&#x27;s because they were few. reply Apocryphon 16 hours agorootparentTwitch streamers and TikTok influencers reply robertlagrant 12 hours agorootparentWell, they&#x27;re actually part of modern culture, so I don&#x27;t think they can be a counterexample from history :-) reply Apocryphon 4 hours agorootparentOrnamental hermits.https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=27734627 replybluefirebrand 17 hours agorootparentprevMonks are just an example that very plainly demonstrates that a person&#x27;s \"worth\" is a cultural determination, not an objective fact of human existence.Do you need me to go and list all of the ways every culture on the planet has different views on the value of an individual?I don&#x27;t have that kind of time. reply nradov 17 hours agorootparentprevIn the real world we have limited resources. Some societies are wealthy enough to sustain a few freeloaders without causing much trouble, but there are limits. If no one does useful work then we all freeze and starve.It&#x27;s interesting to look at the social and political divisions that have been growing in Israel over the role of the Haredi (ultra-orthodox). The men are exempt from conscription and mostly don&#x27;t work for wages. Instead they focus on religious study and survive on welfare and donations. More secular Israelis tend to resent the Haredi as useless lumps who don&#x27;t do their fair share of work. reply brightlancer 15 hours agorootparentprev> Again, the monks believe they live rich lives without being \"useful\" by North American standards, that&#x27;s certainly a cultural thing.That&#x27;s begging the question.Historically, nearly all societies valued work because work was necessary; they valued being \"useful\".Historically, nearly all societies also specialized, moving some folks away from directly producing&#x2F; harvesting food and to other jobs like building tools; they also produced art, philosophy, religion, and other things which don&#x27;t appear to be \"useful\" but _empirically are_.> Look at what value we place on people who are homeless, addicts, crippled, blind, deaf, or hell, even someone who is just unemployed.> We look down on them heavily. We judge them as having lower value because they are less useful.No. WTF, no.Most people who are \"unemployed\" _were_ employed and _will soon be_ employed. Most people who are homeless had a home and will soon have a home. These are usually short term circumstances.The folks who are long-term unemployed or long-term homeless are a completely different category: lots of substance abuse, mental issues they refuse to treat, refusal to adhere to basic societal norms, etc.But if someone improves themselves, wow, do folks love a comeback story. I think that&#x27;s almost universal across societies, but I&#x27;m happy to see evidence otherwise.As for physically handicapped folks, plenty of them work for money. Some of them can&#x27;t _but they want to_. And they find other ways to be useful to their families, their community, their society. I don&#x27;t see disdain for that.But that one is definitely cultural. Historically, most societies would \"put them out of their misery\". Still true in Canada.> Even look at the original comment and the disdain for \"useless lumps\"> This attitude doesn&#x27;t exist everywhere.Generally, yes, it does. See everything above. reply Vrondi 18 hours agorootparentprevIt is absolutely cultural. For example, most Historians believe that while certain times of the year were packed with grueling hard work, the average medieval farm worker had absolute hordes of time off compared to the average modern worker. When the work was done, it was done. You weren&#x27;t useless if you were relaxing in the down times, even large blocks of down time, and since their culture was based around seasonality, it wasn&#x27;t looked down upon.Very different from modern corporate work culture, where you must appear to be working all the time, even if there&#x27;s no work of value to do at a given time, and even if you worked day and night last month on a crunch project.Very much cultural. reply robertlagrant 16 hours agorootparentAs in...serfs? They also starved to death and got conscripted into wars. They also probably had to work their lord&#x27;s land before they got to their own, if there was time. Their lives were often terrible.They also just did more. They didn&#x27;t work to earn money to employ someone to work on their house; they went home and worked on their house. That might look to a simple observer as them working less, but I doubt the serf would see it that way. reply PH95VuimJjqBqy 14 hours agorootparentand kings have been beheaded, therefore kings live terrible lives?The existence of something bad happening doesn&#x27;t refute the point being made. reply robertlagrant 12 hours agorootparentIt would be if pretty much every king would be constantly beheaded, every day. reply PH95VuimJjqBqy 6 hours agorootparentoh definitely, because every serf got killed every day... reply robertlagrant 33 minutes agorootparentNo, the bad thing you mentioned was beheading on monarchs, which wasn&#x27;t normal. The bad things I mentioned happened to serfs every day. That&#x27;s why your comparison was meaningless.vkou 16 hours agorootparentprevJust because the serfs weren&#x27;t working the fields in winter, doesn&#x27;t mean they weren&#x27;t working. They were putting in the other couple of thousand of hours of labour that were needed to keep a household running - most of which was spent on making clothes.Life prior to the industrial revolution sucked. It took a lot of backbreaking labour to produce basic necessities of life. reply Vrondi 18 hours agorootparentprevThis is a brilliant example of someone who is so indoctrinated that they don&#x27;t even realize it. reply nine_zeros 19 hours agorootparentprev> life without work is pretty emptyBut grinding away for a manager ain&#x27;t it either. reply bdw5204 19 hours agorootparentThe solution that Jefferson and Lincoln (among other American Founders) envisioned was that everybody would eventually be self-employed even if they started their career as an employee to gain experience and save up capital. Working for somebody else means they get the better end of the deal (i.e. you probably won&#x27;t have a job for long if they aren&#x27;t making a profit off of you) so of course universal self-employment is the only way to have an economy where people get compensated fairly for the value of their work.Unfortunately, the generation of politicians after Lincoln allowed the capitalists who took advantage of Lincoln&#x27;s \"free labor\" system to pull the ladder up behind them then the next generation (the \"Progressives\") decided big business was \"inevitable\" and just needed to be regulated so it didn&#x27;t become a monopoly that cheated consumers. The generation after that allowed the workers to form unions which could bargain for something resembling what they were worth which worked fairly well for a generation until it was dismantled as the \"solution\" to an inflation crisis caused by US foreign policy and US environmental policy (I&#x27;m referring to the 1970s inflation crisis, not the current one that has the same causes).Tech is one of the few places in the American economy where the true American Dream of financial independence and self employment is still accessible even if you weren&#x27;t born a millionaire and you don&#x27;t win a Powerball or Mega Millions jackpot. But there is a fair question of how much longer it will be until FAANG and&#x2F;or government regulation to \"rein in Big Tech\" pulls that ladder up like all of the previous ladders have been pulled up by big business and&#x2F;or its allies in big government who pretend to be its enemies. reply ilovetux 18 hours agorootparent> The generation after that allowed the workers to form unionsThat is a very interesting way of describing that process. Lives were lost in that battle. reply bdw5204 17 hours agorootparentThe main reason why the Wagner Act was passed into US federal law as part of FDR&#x27;s New Deal was because FDR believed the Great Depression had been caused by low wages. Specifically, lack of purchasing power on the part of working people due to low wages was and is widely considered a major cause of the Depression. Allowing unions rather than suppressing them by state force or allowing corporations to suppress them by private force was seen as a way to stabilize the economy and increase the profitability of corporations by driving up wages which would actually help business because consumers would actually be able to afford their products. reply gowld 18 hours agorootparentprevIf every transaction was one-sided than it doesn&#x27;t matter whether you are an employee or entrepreneur.Trade happens because it&#x27;s mutually beneficial. reply bdw5204 17 hours agorootparentI never implied that transactions are one-sided. Accepting employment is beneficial to the employee, in our current economy. If you attempt to start your own business without sufficient capital (in the form of savings, outside investment or loans), you will go bankrupt before you can turn a profit because it costs money to live and because there are startup costs for a new business that must be paid before you turn a profit. But if you accept employment at the market rate (which is always less than the amount of wealth your labor creates or you probably won&#x27;t be able to find an employer), you are typically paid within a few weeks with few or no upfront costs which matters if you aren&#x27;t already financially independent. replygadders 15 hours agoparentprevI&#x27;ve recently been looking into socio-economic diversity (i.e. coming from a poor&#x2F;blue collar background) and how it affects progression at professional companies.People from lower soc-ec backgrounds tend to focus on technical excellence, and wait to be noticed and promoted, rather than engaging in more overt self promotion. There is a great video on the topic by a guy called Luke Hart here: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=gwKcjg5lPk8 reply AndrewKemendo 19 hours agoparentprevI&#x27;ve been",
    "originSummary": [
      "A recent research study suggests employees commemorated for their loyalty are often chosen for exploitation by managers, potentially leading to adverse workplace outcomes.",
      "The assumption behind this exploitation is the perceived willingness of loyal staff to make personal sacrifices, and agreeing to exploitation further reinforces their reputation for loyalty.",
      "The study underscores the harm loyalty can cause in certain work contexts, stressing the need to tackle exploitative practices in the workplace."
    ],
    "commentSummary": [
      "The discussion covers a range of work-related topics, such as exploitation of loyal workers, tax rates, work-life balance, and perceptions of hard work versus success.",
      "Other areas include compensation and power dynamics, job satisfaction, importance of upskilling, workplace challenges, cultural perspectives on work, and the concept of universal self-employment with labor rights.",
      "Overall, the post emphasizes the complex and multifaceted nature of work, shedding light on its value, meaning, and potential benefits and drawbacks."
    ],
    "points": 406,
    "commentCount": 310,
    "retryCount": 0,
    "time": 1698238484
  },
  {
    "id": 38020109,
    "title": "Jina AI launches open-source 8k text embedding",
    "originLink": "https://jina.ai/news/jina-ai-launches-worlds-first-open-source-8k-text-embedding-rivaling-openai/",
    "originBody": "notifications NEWS FOR POWER USERS FOR DEVELOPERS FOR ENTERPRISES COMPANY language English arrow_circle_left BACK TO NEWSROOM star Featured Releases Jina AI Launches World's First Open-Source 8K Text Embedding, Rivaling OpenAI rss_feed Jina AI October 25, 2023 • 4 minutes read Berlin, Germany - October 25, 2023 – Jina AI, the Berlin-based artificial intelligence company, is thrilled to announce the launch of its second-generation text embedding model: jina-embeddings-v2. This cutting-edge model is now the only open-source offering that supports an impressive 8K (8192 tokens) context length, putting it on par with OpenAI's proprietary model, text-embedding-ada-002, in terms of both capabilities and performance on the Massive Text Embedding Benchmark (MTEB) leaderboard. Benchmarking Against the Best 8K Model from Open AI When directly compared with OpenAI's 8K model text-embedding-ada-002, jina-embeddings-v2 showcases its mettle. Below is a performance comparison table, highlighting areas where jina-embeddings-v2 particularly excels: Rank Model Model Size (GB) Embedding Dimensions Sequence Length Average (56 datasets) Classification Average (12 datasets) Reranking Average (4 datasets) Retrieval Average (15 datasets) Summarization Average (1 dataset) 15 text-embedding-ada-002 Unknown 1536 8191 60.99 70.93 84.89 56.32 30.8 17 jina-embeddings-v2-base-en 0.27 768 8192 60.38 73.45 85.38 56.98 31.6 Notably, jina-embedding-v2 outperforms its OpenAI counterpart in Classification Average, Reranking Average, Retrieval Average, and Summarization Average. Features and Benefits Jina AI’s dedication to innovation is evident in this latest offering: From Scratch to Superiority: The jina-embeddings-v2 was built from the ground up. Over the last three months, the team at Jina AI engaged in intensive R&D, data collection, and tuning. The outcome is a model that marks a significant leap from its predecessor. Unlocking Extended Context Potential with 8K: jina-embeddings-v2 isn’t just a technical feat; its 8K context length opens doors to new industry applications: Legal Document Analysis: Ensure every detail in extensive legal texts is captured and analyzed. Medical Research: Embed scientific papers holistically for advanced analytics and discovery. Literary Analysis: Dive deep into long-form content, capturing nuanced thematic elements. Financial Forecasting: Attain superior insights from detailed financial reports. Conversational AI: Improve chatbot responses to intricate user queries. Benchmarking shows that in several datasets, this extended context enabled jina-embeddings-v2 to outperform other leading base embedding models, emphasizing the practical advantages of longer context capabilities. Availability: Both models are freely available for download on Huggingface: Base Model (0.27G) - Designed for heavy-duty tasks requiring higher accuracy, like academic research or business analytics. Small Model (0.07G) - Crafted for lightweight applications such as mobile apps or devices with limited computing resources. Size Options for Different Needs: Understanding the diverse needs of the AI community, Jina AI offers two versions of the model: jinaai/jina-embeddings-v2-base-en · Hugging Face We’re on a journey to advance and democratize artificial intelligence through open source and open science. jinaai/jina-embeddings-v2-small-en · Hugging Face We’re on a journey to advance and democratize artificial intelligence through open source and open science. In reflecting on the journey and significance of this launch, Dr. Han Xiao, CEO of Jina AI, shared his thoughts: \"In the ever-evolving world of AI, staying ahead and ensuring open access to breakthroughs is paramount. With jina-embeddings-v2, we've achieved a significant milestone. Not only have we developed the world's first open-source 8K context length model, but we have also brought it to a performance level on par with industry giants like OpenAI. Our mission at Jina AI is clear: we aim to democratize AI and empower the community with tools that were once confined to proprietary ecosystems. Today, I am proud to say, we have taken a giant leap towards that vision.\" This pioneering spirit is evident in Jina AI's forward-looking plans. A Glimpse into the Future Jina AI is committed to leading the forefront of innovation in AI. Here’s what’s next on their roadmap: Academic Insights: An academic paper detailing the technical intricacies and benchmarks of jina-embeddings-v2 will soon be published, allowing the AI community to gain deeper insights. API Development: The team is in the advanced stages of developing an OpenAI-like embeddings API platform. This will provide users with the capability to effortlessly scale the embedding model according to their needs. Language Expansion: Venturing into multilingual embeddings, Jina AI is setting its sights on launching German-English models, further expanding its repertoire. About Jina AI GmbH: Located at Ohlauer Str. 43 (1st floor), zone A, 10999 Berlin, Germany, Jina AI is at the vanguard of reshaping the landscape of multimodal artificial intelligence. For inquiries, please reach out at contact@jina.ai. Categories: star Featured Releases Learn more Jina 3.22.3 Update Jina is a MLOps framework that empowers anyone to build cross-modal and multi-modal applications on the cloud. Engineering Group October 25, 2023 • 1 minutes read DocArray 0.39.1 Update DocArray is a library for representing, sending and storing multi-modal data, perfect for Machine Learning applications. Engineering Group October 23, 2023 • 1 minutes read Jina 3.22.2 Update Jina is a MLOps framework that empowers anyone to build cross-modal and multi-modal applications on the cloud. Engineering Group October 20, 2023 • 1 minutes read toc In this article Benchmarking Against the Best 8K Model from Open AI Features and Benefits A Glimpse into the Future Offices location_on Berlin, Germany (HQ) Ohlauer Str. 43 (1st floor), zone A, 10999 Berlin, Germany Geschäftsanschrift: Leipziger str. 96, 10117 Berlin, Germany location_on Beijing, China Level 5, Building 6, No.48 Haidian West St. Beijing Haidian, China location_on Shenzhen, China 402, Floor 4, Fu'an Technology Building, Shenzhen Nanshan, China Power Users PromptPerfect SceneXplain BestBanner JinaChat Rationale Developers DocArray Jina Finetuner CLIP-as-service JCloud LangChain-Serve VectorDB Executor Hub DALL-E Flow DiscoArt ThinkGPT DevGPT RunGPT Jerboa Enterprise Finetuner+ Inference Jina AI Cloud Searchscape Semantica Company Contact sales Newsroom About us Our Vision Our Mission Our Approach Our Value Join us open_in_new Open day Intern program © Jina AI GmbH 2020-2023. All rights reserved. email Privacy Policy Terms and Conditions Privacy Settings",
    "commentLink": "https://news.ycombinator.com/item?id=38020109",
    "commentBody": "Jina AI launches open-source 8k text embeddingHacker NewspastloginJina AI launches open-source 8k text embedding (jina.ai) 362 points by artex_xh 9 hours ago| hidepastfavorite131 comments burcs 9 hours agoThis is great news!It feels like open-source is closing the gap with \"Open\"AI which is really exciting, and the acceleration towards parity is faster than more advancements made on the closed source models. Maybe it&#x27;s wishful thinking though? reply udev4096 6 hours agoparentIs it tho? It&#x27;s not really open source if they don&#x27;t give us the information regarding training datasets reply jerpint 6 hours agorootparentIt definitely is open source even if they don’t disclose all details behind the training reply SOLAR_FIELDS 5 hours agorootparentThe very definition of what constitutes open source is being called into question in these kinds of discussions about AI. Without the training details and the weights being made fully open it’s hard to really call something truly open, even if it happens to meet some arbitrary definition of “open source”.A good definition of “truly open” is whether the exact same results can be reproduced by someone with no extra information from only what has been made available. If that is not possible, because the reproduction methodology is closed (a common reason, like in this case) then what has been made available is not truly open.We can sit here and technically argue whether or not the subject matter violated some arbitrary “open source” definition but it still doesn’t change the fact that it’s not truly open in spirit reply m3at 1 hour agorootparentTo take an other example, would you call a game that has its code and all assets (ex. character sprites) freely available open source? Or would the process that was used to create the assets in the first place also be required to be considered open?The parallel can be made with model weights being static assets delivered in their completed state.(I favor the full process being released especially for scientific reproducibility, but this is an other point) reply abriosi 2 hours agorootparentprevImagine someone giving you a executable binary without the source code and calling it \"open source\" reply jyrkesh 2 hours agorootparentI&#x27;m actually mostly in your camp here. But it&#x27;s complicated with AI.What if someone gave you a binary and the source code, but not a compiler? Maybe not even a language spec?Or what if they gave you a binary and the source code and a fully documented language spec, and both of &#x27;em all the way down to the compiler? BUT it only runs on special proprietary silicon? Or maybe even the silicon is fully documented, but producing that silicon is effectively out of reach to all but F100 companies?It&#x27;s turtles all the way down... reply DougBTX 2 hours agorootparentprevYou can pass in any command line arguments you like, so it must be open source reply okaram 4 hours agorootparentprevNotice you are creating your own arbitrary definition of &#x27;truly open&#x27;, which IMHO corresponds more with &#x27;reproducible&#x27;.We already have a definition of open source. I don&#x27;t see any reason to change it. reply TeMPOraL 4 hours agorootparentProblem is, the literal&#x2F;default definition of \"open source\" is meaningless&#x2F;worthless in this context. It&#x27;s the weights, training data and methodology that matter for those models - NOT the inference shell.It&#x27;s basically like giving people a binary program and calling it open source because the compiler and runtime used are open source. reply losteric 4 hours agorootparentprevThe inference runtime software is open, the weights are an opaque binary. Publishing the training data, hyperparameters, process, etc - that would make the whole thing \"open source\". reply magicalhippo 1 hour agorootparentThe quake engine is still open source even though it doesn&#x27;t come with the quake game assets, no?It seems unreasonable to require the training data just to be called open source, given it has similar copyright challenges as game assets.Of course, this wouldn&#x27;t make the model reproducible. But that&#x27;s different from open source. reply darkwater 10 minutes agorootparentGood example. And in fact you are calling the \"engine\" opensource, not the whole Quake game. The &#x27;assets\" in most \"opensource\" AI models are not available. pjc50 1 hour agorootparentprevThe old Stallman definition used the phrase \"preferred form for modification\" rather than the more specific \"source code\". What do you need to effectively modify an AI model? reply otikik 2 hours agorootparentprevWell the other day on this very website there were some very opinionated voices stating that Open Source is “exclusively what OSI defines”. I am not on that camp, more like in yours. To me there’s open source and OSI-approved open source. But you will encounter people very set on that other opinion, which I found interesting.Make no mistake, I am super grateful to OSI for their efforts and most of my code out there uses one of their licenses. I just think they are limited by the circumstances. Some things I consider open are not conforming to their licenses and, like here, some things that conform might not be really open. reply richardw 3 hours agorootparentprevSo if someone includes images in their project they need to tell you every brush stroke that led to the final image?All sorts of intangibles end up in open source projects. This isn’t a science experiment that needs replication. They’re not trying to prove how they came up with the image&#x2F;code&#x2F;model. reply xnorswap 2 hours agorootparentThose \"Brush Strokes\" are effectively the source code. To be considered open source, yes source code needs to be provided along side the binaries (the \"image\"). reply rolisz 4 hours agorootparentprevThen a lot of stuff is not open source. Have you tried reproducing random GitHub repos, especially in machine learning? reply selcuka 5 hours agorootparentprevHow do you define \"source\", then?By this logic any freely downloadable executable software (a.k.a. freeware) is also open source, even though they don&#x27;t disclose all details on how to build it. reply mogwire 5 hours agorootparentSource would be the way the data is produced so that you can replicate it yourself and make changes.If I hand you a beer for free that’s freeware. If I hand you the recipe and instructions to brew the beer that is open source.We muddy the waters too much lately and call “free” to use things “open source”. reply TeMPOraL 3 hours agorootparent> If I hand you a beer for free that’s freeware. If I hand you the recipe and instructions to brew the beer that is open source.Yeah, but what those \"open source\" models are is like you handing me a bottle of beer, plus the instructions to make the glass bottle. You&#x27;re open-sourcing something, just not the part that matters. It&#x27;s not \"open source beer\", it&#x27;s \"beer in an open-source bottle\". In the same fashion, those models aren&#x27;t open source - they&#x27;re closed models inside a tiny open-source inference script. reply imranhou 2 hours agorootparentPerhaps one more thing that is missing in context is that I&#x27;m also getting the right to alter that beer by adding anything I like to it and redistributing it, without knowing its true recipe. reply szundi 1 hour agorootparentprevInteresting as the literal source of the result is not open reply andy99 8 hours agoprevWhat is the use case for an 8k token embedding? My (somewhat limited) experience with long context models is they aren&#x27;t great for RAG. I get the impression they are optimized for something else, like writing 8k+ tokens rather than synthesizing responses.Isn&#x27;t the normal way of using embedding to find relevant text snippets for a RAG prompt? Where is it better to have coarser retrieval? reply dragonwriter 6 hours agoparent> What is the use case for an 8k token embedding?Calculating embeddings on larger documents than smaller-window embedding models.> My (somewhat limited) experience with long context models is they aren&#x27;t great for RAG.The only reason they wouldn&#x27;t be great for RAG is that they aren&#x27;t great at using information in their context window, which is possible (ISTR that some models have a strong recency bias within the window, for instance) but I don&#x27;t think is a general problem of long context models.> Isn&#x27;t the normal way of using embedding to find relevant text snippets for a RAG prompt?I would say the usual use is for search and semantic similarity comparisons generally. RAG is itself an application of search, but its not the only one. reply 3abiton 2 hours agorootparentI wonder how the perfomance fair when context size is increased. Intuitively this should be higher, but some quantized models I&#x27;ve tested showed noticeably worst performance. reply Kubuxu 34 minutes agorootparentYour KV cache size is linear with context size which might put you tight on memory. There is also increased cost of recalculating KV cache of context window when the window has to move but this is close to being solved with streaming LLMs. reply kristopolous 7 hours agoparentprevIs this what you mean by RAG? https:&#x2F;&#x2F;www.promptingguide.ai&#x2F;techniques&#x2F;rag? reply simonw 7 hours agorootparentI have an explanation of RAG in the context of embeddings here: https:&#x2F;&#x2F;simonwillison.net&#x2F;2023&#x2F;Oct&#x2F;23&#x2F;embeddings&#x2F;#answering-... reply Grimburger 6 hours agorootparentYou could just sum it up for us all rather than do a divert to your blog?It&#x27;s Retrieval Augmented Generation btw.To quote:> The key idea is this: a user asks a question. You search your private documents for content that appears relevant to the question, then paste excerpts of that content into the LLM (respecting its size limit, usually between 3,000 and 6,000 words) along with the original question.> The LLM can then answer the question based on the additional content you provided. reply simonw 6 hours agorootparent> You could just sum it up for us all rather than do a divert to your blog?Why? Have links gone out of fashion?I even linked directly to the relevant section rather than linking to the top of the page.The paper that coined the term used the hyphen, though I think I prefer it without: https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2005.11401 reply Grimburger 5 hours ago[flagged]| rootparentnext [8 more] > Have links gone out of fashion?Yes.You wrote far more words than needed to answer the comment, I did it for you instead. reply simonw 5 hours agorootparentOne of the reasons I write so much stuff is so I can provide links to things I&#x27;ve written to answer relevant questions. reply scubbo 4 hours agorootparentAnd those of us with the sense to value your insight, and the attention-span to read more than tweet-sized content, thank you for it. reply discordance 3 hours agorootparentprevThanks so much for your writings and for posting the link (and also for Datasette!). I&#x27;ve learned in the past few months from your blog. reply monkeydust 1 hour agorootparentprevAppreciate it. Your posts in general have been great - accessible to a large audience, quality links to follow up research and catchy analogies even when they don&#x27;t fully hold true (llm as a calculator for words - which I admit I use with citation!). Keep going. reply gar1t 26 minutes agorootparentprevI liked your link a lot. reply mhog_hn 4 hours agorootparentprevThank you, nice blog. reply gkbrk 4 hours agorootparentprev\"Links have gone out of fashion\" is an odd thing to write on a Link Aggregator website. replyteaearlgraycold 7 hours agorootparentprevYes reply teaearlgraycold 7 hours agoparentprevYou could get a facsimile to a summary for a full article or short story. Reducing an 8k token article to a summary using a completions model would cost far more. So if you need to search through collections of contracts, scientific papers, movie scripts, etc. for recommendations&#x2F;clustering then bigger input sizes can do that in one shot.Think of it like skipping the square root step in Euclidean distance. Perfectly valid as long as you don’t want a distance so much as a way to compare distances. And doing so skips the most computationally expensive operation. reply refulgentis 7 hours agorootparentI think I&#x27;m missing something: like, yeah, it&#x27;s vector search for bigger text chunks. But arguably vector search with bigger text chunks is _definitively_ worse -- this isn&#x27;t doing summarization, just turning about 25 pages of text to 1024 floats, which you then can use cosine similarity to measure the semantic similarity to other textI&#x27;d much rather know what paragraph to look in than what 25 pages to look in reply simonw 7 hours agorootparentI imagine it&#x27;s more useful for finding related articles and clustering things than for semantic search, which will work much better against smaller chunks - especially if you&#x27;re implementing Retrieval Augmented Generation. reply rolisz 6 hours agorootparentI think the point is: if you compress 25 pages of text into 1024 floats, you will lose a ton of information, regardless of what the use case is, so you&#x27;re probably still better of with chunking. reply TeMPOraL 3 hours agorootparent> if you compress 25 pages of text into 1024 floats, you will lose a ton of informationSure, but then if you do it one page at a time, or one paragraph at a time, you lose ton of meaning - after all, individual paragraphs aren&#x27;t independent of each other. And meaning is kind of the whole point of the exercise.Or put another way, squashing a ton of text loses you some high-frequency information, while chunking cuts off the low-frequency parts. Ideally you&#x27;d want to retain both. reply imranhou 1 hour agorootparentprevGood point, I wonder how different it is to use a large context here vs having some other model summarize an 8k article into a small paragraph and using embedding from the paragraph instead where such a large context wouldn&#x27;t be necessary. reply simonw 6 hours agorootparentprevI&#x27;ve been getting great results for related documents by embedding entire blog posts, e.g. here: https:&#x2F;&#x2F;til.simonwillison.net&#x2F;gis&#x2F;pmtiles#relatedI&#x27;m not sure how I would do that after chunking. reply thomasahle 4 hours agorootparentDid you compare with simple baselines like bag-of-words and word vectors? reply simonw 4 hours agorootparentMy previous implementation used TF-IDF - I basically took all the words in the post and turned them into a giant \"word OR word OR word OR word\" search query and piped that through SQLite full-text search. https:&#x2F;&#x2F;til.simonwillison.net&#x2F;sqlite&#x2F;related-contentI jumped straight from that to OpenAI embeddings. The results were good enough that I didn&#x27;t spend time investigating other approaches. reply thomasahle 2 hours agorootparent> Into a giant \"word OR word OR word OR word\"Does that mean you&#x27;d return other docs if they share just one word?The idea of tfidf is that it gives you a vector (maybe combined with pca or a random dimensionality reduction) that you can use just like an Ada embedding. But you still need vector search. reply rolisz 4 hours agorootparentprevThat&#x27;s not quite tfidf though. I agree you can get better results than that with Ada embeddings, but I would argue you can get even better results with embeddings from smaller chunks. reply simonw 4 hours agorootparentI guess technically it&#x27;s bm25, since it&#x27;s using the rank mechanism in SQLite FTS5: https:&#x2F;&#x2F;www.sqlite.org&#x2F;fts5.html#sorting_by_auxiliary_functi... replyteaearlgraycold 4 hours agorootparentprevEver read the back of a book? reply TeMPOraL 2 hours agorootparentYou mean the marketing blurb? Those tend to carry low information value, sometimes even negative - as in, if you didn&#x27;t know anything else about the book, reading the blurb will make you even more wrong about it than you were. This is a common feature of marketing copy. reply scotty79 35 minutes agorootparentprevIsn&#x27;t it up to 8k? So you can index your documents by paragraphs if you prefer? reply antman 3 hours agorootparentprevyou could do both reply jncraton 8 hours agoprevThis is great to see. It looks like the size of the embedding vector is half the size of text-embedding-ada-002 (768 vs 1536) while providing competitive performance. This will save space in databases and make lookups somewhat faster.For those unaware, if 512 tokens of context is sufficient for your use case, there are already many options that outperform text-embedding-ada-002 on common benchmarks:https:&#x2F;&#x2F;huggingface.co&#x2F;spaces&#x2F;mteb&#x2F;leaderboard reply minimaxir 7 hours agoparentThe 768D-sized embeddings compared to OpenAI&#x27;s 1536D embeddings are actually a feature outside of index size.In my experience, OpenAI&#x27;s embeddings are overspecified and do very poorly with cosine similarity out of the box as they match syntax more than semantic meaning (which is important as that&#x27;s the metric for RAG). Ideally you&#x27;d want cosine similarity in the range of [-1, 1] on a variety of data but in my experience the results are [0.6, 0.8]. reply TeMPOraL 2 hours agorootparentUnless I&#x27;m missing something, it should be possible to map out in advance which dimensions represent syntactic aspects, and then downweigh or remove them for similarity comparisons. And that map should be a function of the model alone, i.e. fully reusable. Are there any efforts to map out the latent space of ada models like that? reply karxxm 4 hours agorootparentprevYou wrote „out of the box“, did you find a way to improve this? reply teaearlgraycold 3 hours agorootparentYou can do PCA or some other dimensionality reduction technique. That’ll reduce computation and improve signal&#x2F;noise ratio when comparing vectors. reply simonw 8 hours agoprevI just shipped a new llm-embed-jina plugin for my LLM tool which provides access to these new Jina models: https:&#x2F;&#x2F;github.com&#x2F;simonw&#x2F;llm-embed-jinaHere&#x27;s how to try it out.First, install LLM. Use pip or pipx or brew: brew install llmNext install the new plugin: llm install llm-embed-jinaYou can confirm the new models are now available to LLM by running: llm embed-modelsYou should see a list that includes \"jina-embeddings-v2-small-en\" and \"jina-embeddings-v2-base-en\"To embed a string using the small model, run this: llm embed -m jina-embeddings-v2-small-en -c &#x27;Hello world&#x27;That will output a JSON array of 512 floating point numbers (see my explainer here for what those are: https:&#x2F;&#x2F;simonwillison.net&#x2F;2023&#x2F;Oct&#x2F;23&#x2F;embeddings&#x2F;#what-are-e...)Embeddings are only really interesting if you store them and use them for comparisons.Here&#x27;s how to use the \"llm embed-multi\" command to create embeddings for the 30 most recent issues in my LLM GitHub repository: curl &#x27;https:&#x2F;&#x2F;api.github.com&#x2F;repos&#x2F;simonw&#x2F;llm&#x2F;issues?state=all&filter=all&#x27; \\jq &#x27;[.[]{id: .id, title: .title}]&#x27; \\llm embed-multi -m jina-embeddings-v2-small-en jina-llm-issues - \\ --storeThis creates a collection called \"jina-llm-issues\" in a default SQLite database on your machine (the path to that can be found using \"llm collections path\").To search for issues in that collection with titles most similar to the term \"bug\": llm similar jina-llm-issues -c &#x27;bug&#x27;Or for issues most similar to another existing issue by ID: llm similar jina-llm-issues 1922688957Full documentation on what you can do with LLM and embeddings here: https:&#x2F;&#x2F;llm.datasette.io&#x2F;en&#x2F;stable&#x2F;embeddings&#x2F;index.htmlAlternative recipe - this creates embeddings for every single README.md in the current directory and its subdirectories. Run this somewhere with a node_modules folder and you should get a whole lot of interesting stuff: llm embed-multi jina-readmes \\ -m jina-embeddings-v2-small-en \\ --files . &#x27;**&#x2F;README.md&#x27; --storeThen search them like this: llm similar jina-readmes -c &#x27;backup tools&#x27; reply simonw 6 hours agoparentWrote this up on my blog: https:&#x2F;&#x2F;simonwillison.net&#x2F;2023&#x2F;Oct&#x2F;26&#x2F;llm-embed-jina&#x2F; reply bosky101 6 hours agoparentprevThe only feedback I had from your embedding post was wish we could create the array of floating points without openaiGreat timely turnaround time, good sir. Ht reply X6S1x6Okd1st 8 hours agoparentprevThank you so much for all the work you&#x27;ve put into llm! reply mike_ivanov 4 hours agoparentprevJFYI, this is what happens on my M1 Macbook:$ brew install llm $ llm ModuleNotFoundError: No module named &#x27;typing_extensions&#x27;Not sure where to report it. reply IanCal 22 minutes agorootparentProbably not this, but check with `which llm` what that&#x27;s running. I had weird issues not matching the documentation but just had some other random python cli tool called llm I&#x27;d put in my home bin for and forgotten about it. reply simonw 3 hours agorootparentprevWhoa, that is a weird one. Do you know what version of Python you have from Homebrew?It looks like that package is correctly listed in the formula: https:&#x2F;&#x2F;github.com&#x2F;Homebrew&#x2F;homebrew-core&#x2F;blob&#x2F;a0048881ba9a2... reply dazzaji 7 hours agoparentprevExcellent! And you were just saying how risky it is to rely long-term on OpenAI text embeddings in your post on the topic. The timing for this open source option worked out nicely. reply omneity 9 hours agoprevImpressive work.I wonder what would be the best way to use 8k embeddings. It’s a lot of information to keep in a vector, so things like “precision” of the embedding space and its ability to distinguish very similar large documents will be key.Maybe it can be useful for coarse similarity matching, for example to detect plagiarism? reply sroussey 9 hours agoparent8K is the context length. Their vector dimension size is actual much smaller, which is great for a number of use cases, though maybe not the ones you are thinking about. reply omneity 8 hours agorootparentYes that’s also how I understood it. Maybe it was ambiguously expressed, but I mean “8k tokens as input is a lot of information to encode” reply marinhero 6 hours agoprevHow well do LLMS like this work with a non-English language? Or are these open source models limited to English? reply simonw 5 hours agoparentQuite a few of the top ranked models on this leaderboard are multilingual: https:&#x2F;&#x2F;huggingface.co&#x2F;spaces&#x2F;mteb&#x2F;leaderboardhttps:&#x2F;&#x2F;huggingface.co&#x2F;BAAI&#x2F;bge-large-en-v1.5 FlagEmbedding for example describes itself as covering Chinese and English. reply anigbrowl 4 hours agoparentprevStability has a Japanese port which is getting lots of work https:&#x2F;&#x2F;twitter.com&#x2F;StabilityAI_JP&#x2F;status&#x2F;171699857824440759... reply m3at 1 hour agorootparentThis is not an embedding model though. Yes you can always extract some embeddings from somewhere, but for most LLMs those won&#x27;t perform well for retrieval (which makes sense as it&#x27;s not what the models are optimizing for) reply ttul 4 hours agoparentprevThat depends on whether the training data contained languages other than English. reply moralestapia 8 hours agoprevAda is one of the (if not the) worst model offered by OpenAI, though ... reply simonw 8 hours agoparentYou&#x27;re thinking of the old \"ada\" GPT-3 model - the one that was a companion to \"davinci\" and \"babbage\".I believe \"text-embedding-ada-002\" is entirely unrelated to those old GPT-3 models. It&#x27;s a recent embedding model (released in December 2022 - https:&#x2F;&#x2F;openai.com&#x2F;blog&#x2F;new-and-improved-embedding-model ) which OpenAI claim is their best current best available embedding model.I understand your confusion: OpenAI are notoriously bad at naming things! reply moralestapia 8 hours agorootparentOh, thanks for clarifying!Edit: looking at the press release, the improvement over old Ada is ... marginal? And Ada-01 is&#x2F;was a poor performing model, tbh. I guess I&#x27;ll have to run some tests, but at first sight it doesn&#x27;t seem that wow-ey. reply LASR 2 hours agorootparentSo just to be super clear, this is an embedding model. It generates no text. It’s not outputting words.Maybe I am assuming incorrectly, but I think the poor performance you are referring to is the old Ada completion model, where the output is text. That was poor indeed. reply itake 32 minutes agorootparentThis article is not kind to the old ada embeddings model:https:&#x2F;&#x2F;medium.com&#x2F;@nils_reimers&#x2F;openai-gpt-3-text-embedding...If the new ada model only has marginal improvements, it seems open source is way to go. replyKutsuya 1 hour agoprevthis is super cool! I wish there was an easy to understand and follow guide on how to make your own embedding, for llama2 for example. All I can find are various guides that already assume you know everything there is to training an embedding.I just want to make an embedding between a conversation of me and my friend and simulate talking to them. Is this a hard thing to train to begin with?If anyone knows or could help me with this, I would be very grateful! reply nicognaw 7 hours agoprevJina AI itself is also a great framework to expose APIs from deep neural net models and deploy them to Kubernetes clusters, which I think is very promising, but they didn&#x27;t get as much hype as I predicted that they deserved. reply dylanjcastillo 3 hours agoprevI wonder how much better is this, compared to taking the average ( or some other aggregation) of embeddings with a smaller context length. Has anyone done a similar comparison? reply pietro72ohboy 2 hours agoparentThe issue with averaging is that over large inputs, it drowns out small signal. For example, there is a chance that it completely loses a reference to something made only in a single sentence somewhere in a large document. reply extasia 2 hours agoprevIs this a text encoder model, BERT style? reply 3cats-in-a-coat 55 minutes agoprevGreat company name. reply smcl 25 minutes agoparentI&#x27;m gonna try to explain this because I thought the same thing, though you may enjoy it for another reason. Among Czech or other slavic software people - \"jiná AI\" could be like \"another AI\" and, to me at least, brings to mind the \"yet another {thing}\" naming convention (yacc = \"yet another compiler compiler\" for example). reply pknerd 6 hours agoprevPardon my ignorance in advance but could it be used to \"chat\" with PDFs and websites? I am looking for OpenAI alternatives as I am in learning phase reply lofties 5 hours agoparentNo. “Chatting with PDFs” is (mostly) taking a users chat message, retrieve relevant content via e.g embedding search, then feed that into an LLM with a prompt that’s something along the lines of “given this information, can you answer this question”.This tool helps with embedding part.I’ve built a bunch of ”chat with your PDFs” bots, do reach out if you have any questions me at brian.jp. reply pknerd 5 hours agorootparentActually I wanna use langchain. OpwnAI is not free. I wanted to test two use cases:- chat with documents(pdf, doc etc)- chat with website. Like, if I integrate with an ecommerce site, I can ask questions from the website. What options do I have in free for both cloud and locally? reply clarkmcc 6 hours agoparentprevCheck out my little side project for chatting with PDFs. You should be able to load most models including this one. https:&#x2F;&#x2F;github.com&#x2F;clarkmcc&#x2F;chitchat reply pknerd 5 hours agorootparentThis looks cool so can it be used to feed Website&#x2F;Products data in CSV&#x2F;JSON format and \"chat\" with it? reply seydor 1 hour agoparentprevusing the bing tab of microsoft edge browser, you can chat with PDFs and i think they use GTP4 or equivalent reply canadaduane 5 hours agoparentprevNo, this is an embedding model, not a text completion model. reply Nitrolo 9 hours agoprevIs there something like oobabooga to easily run this in a click-and-run way? Where I can load up a model, a text, and ask it questions? reply simonw 8 hours agoparentSee my comment here: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38020655 for a CLI tool that lets you do this.Note that embedding models are a different kind of thing from a Large Language Model, so it&#x27;s not the kind of model you can ask questions.It&#x27;s a model which can take text and turn it into an array of floating point numbers, which you can then use to implement things like semantic search and related documents.More on that here: https:&#x2F;&#x2F;simonwillison.net&#x2F;2023&#x2F;Oct&#x2F;23&#x2F;embeddings&#x2F; reply minimaxir 7 hours agoparentprevThe Hugging Face page for the model has a two line load-and-encode Python code demo: https:&#x2F;&#x2F;huggingface.co&#x2F;jinaai&#x2F;jina-embeddings-v2-base-en reply brucethemoose2 8 hours agoparentpreviirc ooba has its own integrated vectordb called superbooga.I bet you could hack this in. reply sroussey 9 hours agoprevDoes anyone know what they are using for this comparison and ranking? And where does instruct-xl stand in the mix? reply sroussey 9 hours agoparentOh duh, it’s right in the post and instructor-xl is number 9. And so many new participants now! reply sroussey 8 hours agorootparentThe ranking are here:https:&#x2F;&#x2F;huggingface.co&#x2F;spaces&#x2F;mteb&#x2F;leaderboardIt’s amazing how many new and better ones there are since I last looked a few months ago. Instructor-xl was number 1, now it is number 9, and its size is more than 10x the number 2 ranked!Things move fast! reply backendEngineer 5 hours agoprevoh thank god I first read Jira... reply neximo64 8 hours agoprevDoes it match OpenAI on number of params? reply minimaxir 7 hours agoparentNo one knows since OpenAI has not disclosed the number of paramerers their embeddings model uses. reply e1g 8 hours agoprevTheir OpenAI benchmark is GPT3 (text-embedding-ada-002), not GPT4. reply simonw 8 hours agoparent\"text-embedding-ada-002\" isn&#x27;t GPT3, it&#x27;s a different kind of model. Embedding models and Large Language Models aren&#x27;t the same thing. reply e1g 7 hours agorootparentLLMs and embedding models are certainly different, but it&#x27;s a useful benchmark to calibrate expectations. OpenAI released text-embedding-ada-002 a year ago, and they describe the ada model as[1] \"the original GPT-3 base model [...] capable of very simple tasks, usually the fastest model in the GPT-3 series\".It&#x27;s fair to expect GPT3-level results - not GPT 3.5 and certainly not open-source tiny GPT4 as some might think when they read \"rivaling OpenAI\".[1] https:&#x2F;&#x2F;platform.openai.com&#x2F;docs&#x2F;models&#x2F;whisper reply simonw 7 hours agorootparentNo, you&#x27;re confusing two things here.\"text-ada-001\" is LLM in the GPT3 family, described as \"Capable of very simple tasks, usually the fastest model in the GPT-3 series, and lowest cost\"\"text-embedding-ada-002\" is entirely different - that page describes it as \"Our second generation embedding model, text-embedding-ada-002 is a designed to replace the previous 16 first-generation embedding models at a fraction of the cost.\" reply e1g 6 hours agorootparentOpenAI doesn&#x27;t say directly what text-embedding-ada-002 is, but in the release blog post they show that performance is comparable to davinci&#x2F;curie, which places it firmly in the universe of GPT3. I understand it&#x27;s not a straight line comparison, but to me it&#x27;s still a useful mental heuristic about what to expect.[1] https:&#x2F;&#x2F;openai.com&#x2F;blog&#x2F;new-and-improved-embedding-model (see \"Model improvements\") reply simonw 6 hours agorootparentYou mean this table here? text-embedding-ada-002 53.3 text-search-davinci-*-001 52.8 text-search-curie-*-001 50.9 text-search-babbage-*-001 50.4 text-search-ada-*-001 49.0That&#x27;s not comparing it to the davinci&#x2F;curie&#x2F;babbage GPT3 models, it&#x27;s comparing to the \"search-text-*\" family.Those were introduced in https:&#x2F;&#x2F;openai.com&#x2F;blog&#x2F;introducing-text-and-code-embeddings as the first public release of embeddings models from OpenAI.> We’re releasing three families of embedding models, each tuned to perform well on different functionalities: text similarity, text search, and code search. The models take either text or code as input and return an embedding vector.It&#x27;s not at all clear to me if there&#x27;s any relationship between those and the GPT3 davinci&#x2F;curie&#x2F;babbage&#x2F;ada models.My guess is that OpenAI&#x27;s naming convention back then was \"davinci is the best one, then curie, then babbage, then ada\". reply e1g 5 hours agorootparentHow interesting. I assumed that a consistent codename such as Ada&#x2F;Davinci refers to the lineage&#x2F;DNA of the OpenAI model from which a distinct product was created. But I can see how these codenames could be \"just\" a revision label of A&#x2F;B&#x2F;C&#x2F;D (Ada&#x2F;Babbage&#x2F;Curie&#x2F;Davinci), similar to \"Pro&#x2F;Max&#x2F;Ultra\". If true, a product named \"M2 Ultra\" could have nothing to do with another product called \"Watch Ultra\". reply simonw 5 hours agorootparentWow I genuinely hadn&#x27;t noticed the A&#x2F;B&#x2F;C&#x2F;D thing! reply helloplanets 6 hours agorootparentprevReading through that article, the specific Davinci&#x2F;Curie models they seem to be referring to are called the following: &#x27;text-search-davinci-001&#x27;, &#x27;text-search-curie-001&#x27;, &#x27;text-similarity-davinci-001&#x27; and &#x27;text-similarity-curie-001&#x27;.Are you sure these have anything to do with &#x27;text-davinci-003&#x27; or &#x27;text-curie-001&#x27;?Will have to agree with everyone here that OpenAI is good at being extremely confusing. It seems like the logic might be something along the lines of the &#x27;text-search&#x27; portion being the actual type of the model, while the &#x27;curie-001&#x27; &#x2F; &#x27;-&#x27; format is just a personalized way of expressing the version of that type of model. And the whole &#x27;GPT&#x27; category used to be a sort family of models, but now they&#x27;ve just switched it to the actual name of the newer gargantuan LLMs. Then, because the &#x27;GPT&#x27; models are now that different thing altogether these days, the newest &#x27;text-embedding&#x27; model is just named &#x27;ada-&#x27; because it&#x27;s on that iteration of the &#x27;text-embedding&#x27; type of model, adhering to the older principle of naming their models? Not sure, ha. Definitely feels like doing some detective work. reply minimaxir 7 hours agorootparentprevtl;dr OpenAI is bad at product naming. reply minimaxir 7 hours agorootparentprevWhen people talked about GPT-3 they always referred to davinci which is the largest model, not ada. reply andrewstuart 9 hours agoprevAnyone got links to examples of text embedding? reply RossBencina 8 hours agoparentOpenAI have a brief explainer with a bunch of example use cases here:https:&#x2F;&#x2F;platform.openai.com&#x2F;docs&#x2F;guides&#x2F;embeddings&#x2F;what-are-... reply BoorishBears 8 hours agoparentprevEasiest example is taking three words: Universe, University, College.- University and Universe are similar alphabetically.- University and College are similar in meaning.Take embeddings for those three words and `University` will be near `College`, while `Universe` will be further away, because embeddings capture meaning:UniversityCollegeUniverse_With old school search you&#x27;d need to handle the special case of treating University and College as similar, but embeddings already handle it.With embeddings you can do math to find how similar two results are, based on how close their vectors are. The closer the embeddings, the closer the meaning. reply osigurdson 7 hours agorootparentAnother interesting point is that math can be performed on embedding vectors: emb(\"king\") - emb(\"man\") + emb(\"woman\") = emb(\"queen\"). reply minimaxir 6 hours agorootparentThat&#x27;s a property of Word2Vec specifically due to how it&#x27;s trained (a shallow network where most of the \"logic\" would be contained within the embeddings themselves). Using it for embeddings generated from LLMs or Embedding layers will not give as fun results; in practice the only thing you can do is average or cluster them. reply TeMPOraL 1 hour agorootparent> That&#x27;s a property of Word2Vec specifically due to how it&#x27;s trained (a shallow network where most of the \"logic\" would be contained within the embeddings themselves).Is it though? I thought the LLM-based embeddings are even more fun for this, as you have many more interesting directions to move in. I.e. not just:emb(\"king\") - emb(\"man\") + emb(\"woman\") = emb(\"queen\")But also e.g.:emb() + av(sad) + bv(short) - c*v(positive) = emb()Where a, b, c are some constants to tweak, and v(X) is a vector for quality X, which you can get by embedding a bunch of texts expressing the quality X and averaging them out (or doing some other dimensional reduction trickery).I&#x27;ve suggested this on HN some time ago, but only been told that I&#x27;m confused and the idea is not even wrong. But then, there was this talk on some AI conference recently[0], where the speaker demonstrated exactly this kind of latent space translations of text in a language model.--[0] - https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=veShHxQYPzo&t=13980s - \"The Hidden Life of Embeddings\", by Linus Lee from Notion. replytayo42 8 hours agoprevYou can&#x27;t fine tune without using their library tied to their cloud? Did I misunderstand? Do you need fine tune? reply Zuiii 8 hours agoprevColor me surprised! it looks like its actually open source (Apache 2.0) and not the usual false advertising by some two-faced company or institution. Links here:* https:&#x2F;&#x2F;huggingface.co&#x2F;jinaai&#x2F;jina-embeddings-v2-base-en * https:&#x2F;&#x2F;huggingface.co&#x2F;jinaai&#x2F;jina-embeddings-v2-small-en reply RossBencina 9 hours agoprev [–] Some relevant stats from the link:8192 token input sequence length768 embedding dimensions0.27GB model (with 0.07GB model also available)Tokeniser: BertTokenizer [1], 30528 token vocab [2]Is an 8K sequence length directly comparable to text-embedding-ada-002 if the vocabulary is much smaller? I seem to remember its tokeniser has a larger vocabulary.[1] https:&#x2F;&#x2F;huggingface.co&#x2F;jinaai&#x2F;jina-embeddings-v2-base-en&#x2F;blo...[2] https:&#x2F;&#x2F;huggingface.co&#x2F;jinaai&#x2F;jina-embeddings-v2-base-en&#x2F;blo... reply LoganDark 8 hours agoparent> Is an 8K sequence length directly comparable to text-embedding-ada-002 if the vocabulary is much smaller? I seem to remember its tokeniser has a larger vocabulary.Words that aren&#x27;t in the vocabulary can still be represented by multiple tokens. Some models can input and output valid UTF-8 at the byte level (rather than needing a unique token for each codepoint). For example RWKV-World. reply space_fountain 8 hours agorootparentA large vocabulary means less tokens are needed to represent the same information reply HPMOR 5 hours agorootparent*fewerLess is used for qualitative data like “I love him less”. Whereas fewer is used for countable things like “I need fewer tokens.” reply scubbo 4 hours agorootparentUsername checks out. reply DavidSJ 7 hours agoparentprev [–] A uniform distribution over 30528 tokens is just under 15 bits of information per token, whereas a vocabulary size of ~60000 would be just under 16 bits per token. In practice it&#x27;s not uniform, but this shows that they&#x27;re in the same ballpark. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Jina AI, a Berlin-based AI company, has unveiled its second-generation text embedding model, jina-embeddings-v2, which is open-source and supports an 8K context length, a characteristic challenging OpenAI's proprietary model.",
      "The new model has reportedly outmatched OpenAI in numerous benchmarks, offering extended context which is beneficial for applications like legal document examination, medical research, and conversational AI.",
      "Jina AI's future plans include publishing an academic paper, developing an embeddings API platform, and launching multilingual models to expand its reach and versatility."
    ],
    "commentSummary": [
      "Jina AI introduced an open-source 8k text embedding model, sparking debates on the concept of \"openness\" regarding disclosing training specifics and the model's utility for tasks such as text retrieval and generation.",
      "Competing against it, OpenAI launched a new text embedding model with a smaller vector size, which performs effectively and ensures speedy lookups, despite some controversy around the model's naming and its connection to previous models like GPT-3.",
      "The discourse also delves into the advantages and limitations of the new model, the relationship between different OpenAI models, and the generally perceived efficiency of text embeddings."
    ],
    "points": 360,
    "commentCount": 131,
    "retryCount": 0,
    "time": 1698279881
  },
  {
    "id": 38012008,
    "title": "First malaria vaccine reduces early childhood mortality",
    "originLink": "https://www.science.org/content/article/first-malaria-vaccine-slashes-early-childhood-deaths",
    "originBody": "ADVERTISEMENT NEWS CAREERS COMMENTARY JOURNALS LOG IN BECOME A MEMBER News Home All News ScienceInsider News Features GET OUR E-ALERTS HOME NEWS ALL NEWS FIRST MALARIA VACCINE SLASHES EARLY CHILDHOOD MORTALITY NEWSHEALTH First malaria vaccine slashes early childhood mortality Huge analysis of RTS,S in Africa shows it decreased toddler deaths by 13% 24 OCT 20231:50 PM ETBYMEREDITH WADMAN A child receives an RTS,S vaccine in Kenya in March. Final data from a 4-year program showed a 13% decline in deaths among children young enough to have received three doses as babies.YASUYOSHI CHIBA/AFP VIA GETTY IMAGES SHARE: Facebook Twitter Linked In Reddit Wechat Email In a major analysis in Africa, the first vaccine approved to fight malaria cut deaths among young children by 13% over nearly 4 years, the World Health Organization (WHO) reported last week. The huge evaluation of a pilot rollout of the vaccine, called RTS,S or Mosquirix and made by GlaxoSmithKline, also showed a 22% reduction in severe malaria in kids young enough to receive a three-shot series. Hundreds of thousands of children are born annually in the parts of Ghana, Kenya, and Malawi included in the analysis, for which WHO revealed the final data on 20 October at the annual meeting of the American Society of Tropical Medicine and Hygiene. “The RTS,S malaria vaccine is already saving lives,” said John Tanko Bawa, director of malaria vaccine implementation at PATH, a nonprofit that develops vaccines and therapies for global health problems. He added, “What we have seen is a considerable impact of a vaccine described as having modest efficacy.” (A late-stage clinical trial delivered lackluster results on the durability of the vaccine’s protection.) The 13% drop in deaths is so remarkable that “I was surprised I didn’t hear any gasps when it was stated,” joked medical epidemiologist Mary Hamel, who led the WHO pilot program. The mortality decline could translate to tens of thousands of lives saved if RTS,S, which WHO approved for widespread use in 2021, is more broadly deployed: In 2021, malaria killed an estimated 468,000 children under age 5 in sub-Saharan Africa. Seventeen countries in the region have already won approval to receive doses that will start to roll out next year. SIGN UP FOR THE SCIENCEADVISER NEWSLETTER The latest news, commentary, and research, free to your inbox daily SIGN UP “The data speak for themselves,” said Kwaku Poku Asante, a physician and epidemiologist who directs the Kintampo Health Research Centre and who oversaw the analysis in Ghana. “This was a very large, very robust evaluation done in a real-life setting, and you’re seeing this huge impact.” In clinical trial results published in 2015, RTS,S showed 36.3% efficacy against clinical malaria a median of 4 years after toddlers were vaccinated. In the $70 million pilot, mandated by WHO and launched in 2019, nearly 2 million very young children have been vaccinated in the three countries. As the vaccine rolled out, researchers were tasked with studying its real-world impacts on deaths and severe malaria and determining whether it could be fit into routine childhood vaccination schedules without hurting the administration of other vaccines. WHO also asked the researchers to examine safety signals hinted at in the earlier phase 3 clinical trial. That study associated vaccination with meningitis, an inflammation of membranes that envelop the brain, and a severe complication of infection known as cerebral malaria. They also found more deaths among girls who received RTS,S than girls who received a comparator vaccine, against rabies. ADVERTISEMENT But earlier data from the pilot rollout, released in 2021, showed that those potential safety issues disappeared when the vaccine was administered to hundreds of thousands more children than in the clinical trials, leading WHO to approve the vaccine that year. Unfortunately, the clinical trial data continue to provide fodder for vaccine opponents, Daniel Kyabayinze, director of public health in Uganda, commented to the presenters at last week’s meeting. To calculate mortality in the three countries, where death registry statistics are unreliable, the researchers employed tens of thousands of community reporters—more than 14,000 of them in Kenya alone—to conduct household surveys of childhood deaths in 79 areas where the RTS,S vaccine was administered and 79 comparator areas where it was not available. Researchers then compared the death rates of babies whose age made them eligible to receive three doses of the vaccine with those of young children who were not age-eligible for three doses, in both RTS,S areas and unvaccinated areas. The comparison, covering 46 months, revealed the 13% decline in mortality—excluding accidental deaths—attributed to RTS,S. The researchers used the same method to detect the 22% decline in severe malaria, counting admissions for severe cases of the disease at designated “sentinel” hospitals in RTS,S and comparator areas. The mortality benefit was documented even in the areas with the lowest RTS,S coverage, notes Matthew Laurens, a malaria vaccine researcher at the University of Maryland School of Medicine. Depending on the area, between 63% and 75% of eligible children got the initial three-dose series of the vaccine, given in the first year of life; 33% to 53% got the fourth dose about 1 year later. Laurens theorizes that beyond preventing malaria, the RTS,S vaccine may be “training” the immune system in a general way that extends a protective benefit against other infections. For instance, clinical malaria is known to exhaust T cells, he says, and vaccination, by preventing infection, might therefore leave T cells readier to combat other pathogens. Such a general survival benefit has been documented for measles and tuberculosis vaccination. Other leading causes of death in the young children in these areas include pneumonia and diarrhea caused by pathogens including Streptococcus pneumoniae and rotavirus. Data on the feasibility of the vaccine rollout were also promising: Giving RTS,S to 5-month-olds to 24-month-olds did not hurt the uptake of other childhood vaccines, which had been a concern. And it didn’t cause a decline in bed net use due to a false sense of security. But some public health leaders still worry that uptake of the vaccine will require trade-offs. “We now have an additional tool, and yet we are still struggling to implement the tools that we [already] have in many countries,” David Walton, U.S. global coordinator for the President’s Malaria Initiative, told the panel that presented the data last week. The cost of adding the roughly $10 per dose vaccine to existing prevention efforts “is formidable for many countries,” he noted. A second malaria vaccine called R-21 won WHO authorization earlier this month and is likely to be available more cheaply and in greater quantities than RTS,S. The lengthy, expensive RTS,S pilot program came at a cost, Hamel acknowledged. It “really did contribute to a delay in widespread use of the vaccine,” she told the audience. But without it, “I really believe that questions would have lingered” about the vaccine’s safety, effectiveness, and impact—and the feasibility of reaching kids. The pilot program and its critical data, she added, have “forged a pathway for future malaria vaccines.” doi: 10.1126/science.adl5503 RELEVANT TAGS: HEALTH ABOUT THE AUTHOR Meredith Wadman mail Twitter Author Meredith Wadman's beat includes biology research, policy, and sexual harassment . MORE FROM NEWS 25 OCT 2023 Spy photos of Syrian desert reveal ancient Roman forts BY ANDREW CURRY 25 OCT 2023 ‘Why can’t you make a coral out of an anemone?’ BY CHRISTIE WILCOX 25 OCT 2023 Little nuclear physics lab to tackle Department of Energy’s big data problem BY ADRIAN CHO VIEW MORE Got a tip for Science's news department? CONNECT Sign up for ScienceAdviser Subscribe to ScienceAdviser to get the latest news, commentary, and research, free to your inbox daily. SUBSCRIBE ADVERTISEMENT SCIENCEINSIDER 25 OCT 2023BY ADRIAN CHO Little nuclear physics lab to tackle Department of Energy’s big data problem 25 OCT 2023BY JEFFREY MERVIS Can Indigenous knowledge and Western science work together? New center bets yes 23 OCT 2023BY SCIENCE NEWS STAFF Prominent journal editor fired for endorsing satirical article about Israel-Hamas conflict 23 OCT 2023BY ROBERT F. SERVICE U.S. urges DNA synthesis firms to ramp up screening for biosecurity threats VIEW MORE ADVERTISEMENT SIFTER 20 SEP 2023BY CHRISTIE WILCOX RNA recovered from Tasmanian tiger—a first for extinct animal 8 SEP 2023BY RODRIGO PÉREZ ORTEGA Echoes of U.S. housing discrimination seen in bird survey data 16 AUG 2023BY CHRISTIE WILCOX Want to run a marathon in less than 2 hours? Unusual formation could help 9 AUG 2023BY CHRISTIE WILCOX An entire ecosystem lives beneath scorching hydrothermal vents VIEW MORE ADVERTISEMENT Support nonprofit science journalism Help News from Science publish trustworthy, high-impact stories about research and the people who shape it. Please make a tax-deductible gift today. DONATE Not Now Skip slideshow NEWS All News ScienceInsider News Features Subscribe to News from Science News from Science FAQ About News from Science CAREERS Careers Articles Find Jobs Employer Hubs COMMENTARY Opinion Analysis Blogs JOURNALS Science Science Advances Science Immunology Science Robotics Science Signaling Science Translational Medicine Science Partner Journals AUTHORS & REVIEWERS Information for Authors Information for Reviewers LIBRARIANS Manage Your Institutional Subscription Library Admin Portal Request a Quote Librarian FAQs ADVERTISERS Advertising Kits Custom Publishing Info Post a Job RELATED SITES AAAS.org AAAS Communities EurekAlert! Science in the Classroom ABOUT US Leadership Work at AAAS Prizes and Awards HELP FAQs Access and Subscriptions Order a Single Issue Reprints and Permissions TOC Alerts and RSS Feeds Contact Us FOLLOW US GET OUR NEWSLETTER © 2023 American Association for the Advancement of Science. All rights reserved. AAAS is a partner of HINARI, AGORA, OARE, CHORUS, CLOCKSS, CrossRef and COUNTER. Terms of Service Privacy Policy Accessibility",
    "commentLink": "https://news.ycombinator.com/item?id=38012008",
    "commentBody": "First malaria vaccine reduces early childhood mortalityHacker NewspastloginFirst malaria vaccine reduces early childhood mortality (science.org) 348 points by rbanffy 21 hours ago| hidepastfavorite111 comments lopis 20 hours agoWeirdly, there&#x27;s only a link to the old paper [0] that initially reported only on severe malaria cases and the complications. I can&#x27;t find the source of the reduction in deaths.But regardless, I found \"slashing\" to be a bit exaggerated when the fatality reduction was 13% in a small pilot program. Very promising, but sensationalistic. I guess when you&#x27;re up against anti-vax fear mongering, you need to fight fire with fire.[0] https:&#x2F;&#x2F;pubmed.ncbi.nlm.nih.gov&#x2F;25913272&#x2F; reply timr 18 hours agoparent> I guess when you&#x27;re up against anti-vax fear mongering, you need to fight fire with fire.That&#x27;s completely unfair, in this case. The vaccine in question was associated with an increase in deaths in some subgroups (vs control), and overall low effectiveness in the phase 3 clinical trials.A 13% decrease in mortality in this study is actually quite good given what was expected, but it is in no way \"fear mongering\" to question the safety&#x2F;efficacy balance, even now. For example, you&#x27;d likely never administer this vaccine outside of high-risk populations. The fact that the safety signals \"went away\" in this trial is likely more indicative of the baseline risk of the population than any change in the vaccine itself.Where is this line? Hard to say, but just for the sake of argument: anyone suggesting that we add this to mandatory vaccination schedules in the US would be a total lunatic. Should it be widely used outside of the worst parts of Africa, where malnutrition and preventable childhood illness are rampant? Again, hard to say.Vaccines are not automatically good, and it isn&#x27;t \"anti-vax fear mongering\" to question a particular vaccine. We have to test them, and see if the rewards are greater than the risks in the populations where we intend to use them. reply rhuru 12 hours agorootparentI think a lot of people simply ignore the basic fact that vaccines aren&#x27;t safe by nature, they have to be proven to be safe through very very rigorous processes. Anti-vaxxers might come across as a lunatic but their extreme behaviour does not make opposite is true by default. reply asynchronous 11 hours agorootparentprevAn astoundingly level-headed take for HN. We need more science in the science community. reply aredox 17 hours agorootparentprev\"The fact that the safety signals \"went away\" in this trial is likely more indicative of the baseline risk of the population than any change in the vaccine itself\" - or just the fact that sometimes, a study can give the wrong signal, the same way it can happen you land a coin three times heads in a row and yet the coin isn&#x27;t biased... reply mlyle 20 hours agoparentprevA 13% reduction in all-cause mortality is huge. There are other methodological&#x2F;reliability concerns, but malaria isn&#x27;t near 100% of death, even among children. reply BurningFrog 19 hours agorootparentOne way to describe Africa&#x27;s development in this era is that they&#x27;re economically 100 years behind the rich world, but catching up 3 years per year.In that environment, you&#x27;d expect child mortality to go down year by year, regardless of this vaccine.Maybe the study corrects for that, but the complete absence of details in this report isn&#x27;t promising. reply regularfry 19 hours agorootparentIt&#x27;s not regardless of the vaccine, though. You&#x27;d expect child mortality to go down year by year because of things like that. There used to be malaria in the UK, I&#x27;m sure child mortality dropped when it died off here too. reply BurningFrog 18 hours agorootparentMy point is that you need to compare how much the death rates went down in comparable regions, before attributing this 13% decrease to the vaccine. reply ipqk 17 hours agorootparentIt is compared to non-vaccinated regions, if you had bothered to read the article.> To calculate mortality in the three countries, where death registry statistics are unreliable, the researchers employed tens of thousands of community reporters—more than 14,000 of them in Kenya alone—to conduct household surveys of childhood deaths in 79 areas where the RTS,S vaccine was administered and 79 comparator areas where it was not available. reply benchaney 17 hours agorootparentprevThat’s not how these kinds of trials work. The 13% figure comes from comparing the control and intervention groups, which were observed over the same period of time. The change in baseline mortality over time of the entire population isn’t relevant. reply mattmaroon 16 hours agorootparentprevYou really don’t if it’s controlled. The control group would have any other factors baked in.If the group that got the vaccine has a 13% lower all cause mortality than the group that didn’t, and it was your standard randomized controlled double blind study, that’s a huge win. reply mlyle 18 hours agorootparentprev> but the complete absence of details in this report isn&#x27;t promising.We don&#x27;t have the actual report yet: just reporting on it being presented at a conference. I have not found it in indexes yet, but hopefully soon.> Maybe the study corrects for thatYes: the article we&#x27;re reading makes it clear that it&#x27;s comparing like-communities where there was and was not vaccine rollout, not looking at time series data. reply Fomite 14 hours agorootparentI&#x27;m actually surprised we don&#x27;t have the actual report yet - for large medical conferences and big results like this, there&#x27;s often a joint Press Release - Conference Presentation - Journal Publication release. reply eru 4 hours agorootparentprevOf course, the catching up of &#x27;3 years per year&#x27; is partially thanks to roll-outs of vaccination. reply TimPC 13 hours agorootparentprevThey look at differences across comparable regions that got the vaccine and regions that didn&#x27;t with time period controlled for so I&#x27;d say they account for that. reply BurningFrog 14 hours agorootparentprevOK, I&#x27;ve been convinced that I&#x27;m wrong, because the number is of course compared to the control group.I apologize for any inconvenience! reply p_j_w 16 hours agorootparentprevDo you not understand how control groups work? reply BurningFrog 14 hours agorootparentI do, just wasn&#x27;t thinking of it when posting :( reply p_j_w 12 hours agorootparentFair enough! Good on you for realizing your error. reply thinkcontext 15 hours agorootparentprevYes, it is clear that they do not. reply grecy 18 hours agorootparentprevIt is a fact that poor&#x2F;undeveloped countries are currently developing faster than any country ever has at any point in history.If you have not read it, Factfullness by Hans Rosling is incredible. reply vmilner 19 hours agorootparentprevI hadn’t grasped the all-cause aspect from a skim read. reply lettergram 19 hours agorootparentprevThat’s not all that huge when there’s such a small number of deaths in the given group over that time. This is part of the reason a lot of drugs later prove to be useless…I also don’t see a citation for the 13% reduction in all cause mortality. To be honest, that’s an insanely weird metric to review for a malaria vaccine. Why not malaria related deaths?Total in 2015 study [1]:> 8922 children and 6537 young infants were included in the modified intention-to-treat analyses.Total deaths: …? Are we talking 8 deaths in the control group and 7 in those injected?This isn’t clear at all to me[1] https:&#x2F;&#x2F;pubmed.ncbi.nlm.nih.gov&#x2F;25913272&#x2F;On page 20 of the 2021 report we see 1443 deaths in comparison group and 1421 in implementing group [2]. With a pretty wide margin of error I might add. Is that what they’re reporting…?[2] https:&#x2F;&#x2F;www.nitag-resource.org&#x2F;sites&#x2F;default&#x2F;files&#x2F;2022-05&#x2F;M... reply roywiggins 18 hours agorootparentAll-cause mortality is easier to measure, it also takes into account any deaths caused by the vaccine, and any deaths caused by non-malaria proximate causes that would nevertheless have been averted by the vaccine. Malaria is really bad for you even if you survive it, and probably makes you more vulnerable to dying of other things:\"For instance, clinical malaria is known to exhaust T cells, he says, and vaccination, by preventing infection, might therefore leave T cells readier to combat other pathogens. Such a general survival benefit has been documented for measles and tuberculosis vaccination. Other leading causes of death in the young children in these areas include pneumonia and diarrhea caused by pathogens including Streptococcus pneumoniae and rotavirus.\"So, surviving malaria could very easily make it harder to survive your next encounter with rotavirus; vaccinating against malaria would then reduce deaths from rotavirus. reply timr 18 hours agorootparentYeah, but...it&#x27;s also subject to sample bias. Especially in a place like east Africa, having enough resources (not just money -- time, transport, etc.) to get a crazy expensive new vaccine could easily have co-variates that affect all-cause mortality.It&#x27;s great to report it, but you definitely want to see the cause-specific numbers, too. reply roywiggins 17 hours agorootparentThey used two sets of controls: 1, an entire set of communities where the vaccination wasn&#x27;t offered at all, and 2, children who were not eligible due to age. They weren&#x27;t just comparing children who got the vaccine with children who didn&#x27;t, they were comparing children who were eligible for the vaccine and those who weren&#x27;t, and that couldn&#x27;t have been so easily confounded:\"79 areas where the RTS,S vaccine was administered and 79 comparator areas where it was not available\"\"Researchers then compared the death rates of babies whose age made them eligible to receive three doses of the vaccine with those of young children who were not age-eligible for three doses, in both RTS,S areas and unvaccinated areas.\"This is obviously not foolproof, but it seems like a substantial bulwark against obvious confounders.If you can show that 1) the mortality rate in the vaccinated communities was lower in the age-eligible children than not-age-eligible[0] and 2) this effect was absent in unvaccinated communities that seems like it goes quite far towards proving that it&#x27;s real and not an artifact. It probably even underestimates how protective it is at an individual level.(communities which had the vaccine offered also had fewer cases of severe malaria recorded in their hospitals, so there&#x27;s a straightforward reason to think it does something)[1] okay probably age-ineligible children have a different mortality rate regardless. You&#x27;d be taking the difference between those two groups of children and comparing it to the same difference in communities without the vaccination offered. This difference-of-difference would tell you whether the vaccine is doing anything. It wouldn&#x27;t matter if only the richer children received the vaccine if the communities have basically the same distribution of wealth since you&#x27;re comparing differences between age cohorts, not between vaccinated and unvaccinated. reply timr 17 hours agorootparent> This is obviously not foolproof, but it seems like a substantial bulwark against obvious confounders.I mean...they had controls? That&#x27;s good. But otherwise, there&#x27;s no way you can tell from what is written. Even if the controls are perfect (which I don&#x27;t grant without more detail), the implementation of the controls can still allow for confounding.> they were comparing children who were eligible for the vaccine and those who weren&#x27;t, and that couldn&#x27;t have been easily confoundedYou can trivially get confounding based on that. Just pick the kids who are healthier, and call them \"eligible\". Or pick the ones who are older (which they did, as you note), and voila...infinite time bias! Kids who make it to age N are more likely to survive to age N+1 than kids who make it to age N-1 (I mostly disregarded the between-group differences based on age, for this exact reason. It&#x27;s too easily confounded.)More commonly, bias of this form sneaks into a study. Particularly in a place like sub-saharan Africa, the set of people who are even willing to engage with you, mysterious doctor-magician, are of a fundamentally different nature than the ones you never see. They probably do all sorts of things that make them a little bit healthier, on average.It&#x27;s hard to correct for that, and it&#x27;s a real problem when the primary metric is \"community survey of all-cause mortality\". For example: are the community surveyors also magical stranger doctor-magicians, or are they just regular people? It matters. reply cycomanic 15 hours agorootparent> > This is obviously not foolproof, but it seems like a substantial bulwark against obvious confounders.> I mean...they had controls? That&#x27;s good. But otherwise, there&#x27;s no way you can tell from what is written. Even if the controls are perfect (which I don&#x27;t grant without more detail), the implementation of the controls can still allow for confounding.> > they were comparing children who were eligible for the vaccine and those who weren&#x27;t, and that couldn&#x27;t have been easily confounded> You can trivially get confounding based on that. Just pick the kids who are healthier, and call them \"eligible\". Or pick the ones who are older (which they did, as you note), and voila...infinite time bias! Kids who make it to age N are more likely to survive to age N+1 than kids who make it to age N-1 (I mostly disregarded the between-group differences based on age, for this exact reason. It&#x27;s too easily confounded.)They did use two control groups, that&#x27;s the whole point so you compare the difference between the age groups for the area where they vaccinated and the area where they didn&#x27;t. That reduces confounding factors, e.g. based on area.> More commonly, bias of this form sneaks into a study. Particularly in a place like sub-saharan Africa, the set of people who are even willing to engage with you, mysterious doctor-magician, are of a fundamentally different nature than the ones you never see. They probably do all sorts of things that make them a little bit healthier, on average.And you base that assertion on what? Your prejudice (\"mysterious doctor-magician\", do you think about what you&#x27;re implying here?!). In reality based on the studies I have read people in underdeveloped nations are significantly more likely to engage with health professionals and less likely to believe in anti vax or other anti science prkpaganda across all classes than in developed nations. Also one should note that in developed nations the effect is the other way around, anti vax sentiments are strongest (and therefore less likely to get vaccinated) in richer classes, who tend to generally have healthier lifestyles.> It&#x27;s hard to correct for that, and it&#x27;s a real problem when the primary metric is \"community survey of all-cause mortality\". For example: are the community surveyors also magical stranger doctor-magicians, or are they just regular people? It matters.It&#x27;s much easier to look at all cause mortality than cause specific mortality, because you include more confounding factors. It&#x27;s the much better study. reply timr 13 hours agorootparent> And you base that assertion on what?Lots and lots of prior research, as well as direct experience talking to people who run these kinds of experiments. It&#x27;s practically the #1 most common theme you will hear from anyone who has run a public health campaign in a third-world country.Just for example [1]: \"From the onset, Northern Nigeria presented an extreme challenge. The transmission of polio in Northern Nigeria was due to complex health, economic and social issues such as poor demand for and access to health services, low immunization coverage, few available skilled health workers, extreme poverty, low literacy, and community resistance to immunization and government services. Other factors such as the safety of the vaccine, religious factors, and community distrust of government health systems played a major role in increasing transmission. This led to a reemergence of polio in Nigeria, especially in the Northern states. Even in areas where polio immunization was not controversial, failure to engage parents and discuss why a fully vaccinated child may develop polio disease, for instance, reinforced and increased parents’ negative perceptions of the polio program.\"> \"mysterious doctor-magician\", do you think about what you&#x27;re implying here?!I&#x27;m not implying anything. I&#x27;m saying it explicitly. I&#x27;m certainly exaggerating for effect, but I&#x27;m saying it explicitly: lots of people in poor countries are fearful of medical professionals.I don&#x27;t know why that&#x27;s surprising -- it&#x27;s true right here in the USA, as well, and one of the reasons why certain ethnic groups have disproportionately bad medical outcomes.> less likely to believe in anti vax or other anti science prkpaganda across all classesOh, stop. Nobody in this discussion is \"anti science\" -- I have a doctorate, in a biological science. Nor am I \"anti-vax\".It&#x27;s helpful if you don&#x27;t characterize people who critically analyze research with an entire class of fictional villains. Because that actually is what scientists do.[1] https:&#x2F;&#x2F;www.ajtmh.org&#x2F;configurable&#x2F;content&#x2F;journals$002ftpmd... reply cycomanic 11 hours agorootparentJust a quick clarification, I was not accusing you of being anti-science or anti-vax. I was using that as a short-hand for people the who don&#x27;t want to get vaccinated, I&#x27;m sorry if I gave you the impression that I&#x27;m talking about you.Regarding the \"reaching only people based on certain educational background\" I think choosing a citation about northern Nigeria is quite selective. The assertion that people in Africa are more vaccination skeptical seems to be a gross overgeneralisation and is vaccination acceptance rates vary greatly between countries (not surprising as this is the same in the developed world as well).> I&#x27;m not implying anything. I&#x27;m saying it explicitly. I&#x27;m certainly exaggerating for effect, but I&#x27;m saying it explicitly: lots of people in poor countries are fearful of medical professionals.Well your choice of language certainly makes an association to stereotypes of \"superstitious primitives\"> I don&#x27;t know why that&#x27;s surprising -- it&#x27;s true right here in the USA, as well, and one of the reasons why certain ethnic groups have disproportionately bad medical outcomes.Yes some ethnic groups, would these somehow be more likely to engage with the medical professionals that engage with the control groups, or go to the hospitals while being opposed to the \"mysterious doctor-magicians\"? Also the modern \"health-suspicious\" population in the USA (and other developed nations) is primarily composed of well off, well educated socio-economic backgrounds, e.g. just look at where recent measles outbreaks happened. reply roywiggins 17 hours agorootparentprev> Just pick the kids who are healthier, and call them \"eligible\".Sure, yeah. Or whatever. But there&#x27;s no evidence for that in the article, it says it was done based on age, and then matched between comparable communities. You&#x27;d have to not only mess with the eligibility, but only do so in the vaccinated communities. Because they compared eligible and ineligible children in the unvaccinated communities, too. And again, the cohorts were split apart by age. Maybe a bunch of unhealthy children didn&#x27;t get the vaccine for that reason, but they&#x27;d be included in the age-cohort anyway.Of course they could maliciously juice the study but the \"what if richer, healthier children were the ones that got the vaccine\" just doesn&#x27;t seem a reasonable criticism at least as described. It seems like a perfectly good design to avoid being confounded that sort of thing. reply timr 17 hours agorootparent> You&#x27;d have to not only mess with the eligibility, but only do so in the vaccinated communities. Because they compared eligible and ineligible children in the unvaccinated communities, too.Yes, I get that. I&#x27;m not suggesting malfeasance here [1]. I&#x27;m just saying controls are hard, and these problems pop up in the best studies.The difference between the clinical trials and this was that the clinical trials were an actual RCT, and this is an observational study. Observational studies almost always have confounding issues.[1] I do think the immortal time bias is real, however. Whether or not the bias was consistent between groups is a separate question, but I almost don&#x27;t really care. The fact that they&#x27;re reporting that older children survive a bit longer than younger children, and not mentioning this issue, is sketchy to me. They either don&#x27;t understand the problem (bad), or are exaggerating (typical, but still bad), or they&#x27;re hiding something (really bad).Honestly stuff like this just makes me exhausted for the state of medical science. You spent a crapload of money on this. Immortal time bias is confounding 101. We know how to avoid it. Do the damned RCT! reply roywiggins 16 hours agorootparent> Kids who make it to age N are more likely to survive to age N+1 than kids who make it to age N-1Look, maybe I&#x27;m just giving them credit because this is filtered through journalism, but isn&#x27;t that the point of the control communities? You can subtract out this bias using the control community. It&#x27;s all down to picking comparable controls, obviously. If I had to point to a place you could screw up it would be picking the wrong control communities. Ideally you&#x27;d probably pair communities and then assign them at random to get the vaccines or not.I&#x27;m not objecting to the idea that there could be confounders, just that it&#x27;s probably not sampling bias along the lines of \"richer and healthier children probably got the vaccine.\" If all you&#x27;re saying is, \"it&#x27;s not an RCT\" then... yeah, it&#x27;s not? reply gus_massa 14 hours agorootparentThe question is how hard is to pick good control communities. During the pandemic I&#x27;ve read a lot of preprints about cures for covid-19 (like Ivermectin) and many of them used a similar aproach. It looks very hard. I&#x27;ve seen too many bad results with this kind of controls. Double blind randomized controled trial or it didn&#x27;t happen. replymichaelrpeskin 19 hours agorootparentprevActually, all cause is the right metric. Let&#x27;s say the vaccine stops 100% of malaria but causes severe heart attacks. You&#x27;d probably want to know that. I didn&#x27;t review _this_ study, so I won&#x27;t comment on the quality of analysis, but what you want to know about a vaccine is \"effectivity\" does it stop contraction and spread of the illness and \"safety\" does it not cause any other problems that in aggregate are worse than the illness (all cause mortality is one metric here). reply Fomite 14 hours agorootparentAnd indeed there are a number of trials that show a decrease in all cause mortality (mass childhood administration of azithromycin comes to mind) that we&#x27;d miss if we were just looking at already known endpoints. reply eigenket 20 hours agoparentprevHere is the relevant text from the article> The comparison, covering 46 months, revealed the 13% decline in mortality—excluding accidental deaths—attributed to RTS,S.Thats a 13% decline in all cause morality, excluding accidental deaths. The 13% number isn&#x27;t just in deaths from malaria, its in deaths including all diseases. reply lopis 18 hours agorootparentFrom the article, yes. Where&#x27;s the report? reply chmod600 18 hours agoparentprev\"I guess when you&#x27;re up against anti-vax fear mongering, you need to fight fire with fire.\"That&#x27;s seems like a dubious strategy likely to backfire. I hope you&#x27;re not serious. reply skybrian 20 hours agoparentprevThe significance seems to be that it shows real-world results from a malaria vaccine that’s only moderately effective:> In clinical trial results published in 2015, RTS,S showed 36.3% efficacy against clinical malaria a median of 4 years after toddlers were vaccinated.Some possible side-effects seem to be ruled out:> Giving RTS,S to 5-month-olds to 24-month-olds did not hurt the uptake of other childhood vaccines, which had been a concern. And it didn’t cause a decline in bed net use due to a false sense of security. reply dgacmu 19 hours agoparentprev13% of all toddler deaths by any (non-accident) cause. That&#x27;s very substantial. reply saalweachter 18 hours agorootparentQuick googling says that there are around 3.4 million child ( What would fight it is honestyTo a degree. After a certain point, people have freedom to choose and society natural selection to benefit from. reply swader999 19 hours agorootparentSociety pays a huge cost from premature death. reply pmarreck 19 hours agorootparentprevhow do you expect to counterargue sensationalistic cherry-picked click-seeking malinformation with plain old boring facts, in a populace that was never taught any critical thinking skill? reply bluSCALE4 12 hours agorootparentbut... but... it&#x27;s settled science. reply TimPC 13 hours agoparentprevThe article doesn&#x27;t say but my understanding is this was a 13% reduction in all-cause mortality as in they measured the number of children who died during the time period and that went down by 13%. Not that 87% of malaria related deaths still occurred. A 13% reduction in all-cause mortality is quite large. To know how effective the vaccine is at stopping malaria related deaths you&#x27;d need to know what % of those who were dying were dying to malaria. If it was 14% then the vaccine is performing insanely well if it was 50% more work needs to be done. reply Lordarminius 14 hours agoparentprev> I guess when you&#x27;re up against anti-vax fear mongering, you need to fight fire with fire.You do know the vax is associated with a myriad of side effects including clots, strokes, reduced fertility and increase in turbo cancers, contains dna contaminants and was not properly tested don&#x27;t you ? reply VoodooJuJu 18 hours agoparentprev> I guess when you&#x27;re up against anti-vax fear mongering, you need to fight fire with fire.Comment was great until this. Rent-free. Don&#x27;t start fires and you won&#x27;t have to fight them. reply Slava_Propanei 18 hours agoparentprevPeople are opposed to being forced into injections of experimental mRNA.Very few people were ever opposed to the standard-type vaccines we have been using for 100 years.That is why the vast majority of people are happy to vaccinate themselves against polio and tetanus, but only 2% of people were interested in the latest Pfizer booooster experiment.I would suggest against making up imaginary enemies. reply smileysteve 12 hours agorootparentSeems inaccurate where vaccines were correlated to autism in a 2016 GOP debate. (And the doctor on stage said nothing to rebut, and turned out to be anti mRNA as well) reply kbelder 10 hours agorootparentDon&#x27;t make it partisan. Remember, for decades prior to covid, antivax had been more predominate on the left. Both parties have plenty of ignorant members. reply acdha 9 hours agorootparentIt wasn’t so much a question of skew but visibility: people saw celebrities opposing vaccination a lot more than, say, the Christian homeschoolers who were doing the same things but not holding press conferences back then. reply smileysteve 9 hours agorootparentprevThis is a readily citable nationally televised recent singular event with many elected officials on stage, ~3 years before mRNA was rolled out for a major eventDecades and smaller advocacy groups are less distinct. reply lost_tourist 7 hours agorootparentprevThe problem with your assessment is that you aren&#x27;t being injected with experimental mRNA, it is well tested and proven on billions of people. It&#x27;s fine to not want to be a part of that, but saying it is experimental is misinformation. reply vehementi 19 hours agoprevWow I thought there already was a Malaria vaccine and that that was what the Gates foundation had been deploying to eradicate the disease, but they&#x27;ve only so far been able to (go to great lengths to) mess with mosquitos, protect people from symptoms, remove people from conditions, etc. to otherwise prevent it by conventional means. A vaccine is huge! reply crossroadsguy 15 hours agoparentIt is indeed huge. It might be coming as a shock that there was no vaccine for this, but it would make sense if you look at the demographics and geography that gets affected by malaria, dengue. And that truly makes it huge. Hope this is accessible as well. Now I hope my country gets an approved dengue vaccine. I had it once, won’t wish to my enemies. I’d rather take covid any day. reply Fomite 14 hours agorootparentBeyond demographics and geography, malaria is just hard. It&#x27;s not a virus with fairly stable antigenic targets - it&#x27;s a parasite that readily develops resistance to things.This is indeed huge, even if the effect is only modest on a per-person basis, because we&#x27;re still talking about a tremendous number of the world&#x27;s population being protected. reply epups 19 hours agoprevI find these results extremely promising. If I understand the numbers correctly, about 450,000 children die of malaria alone every year. That means a 13% reduction in deaths would save over 50,000 children per year. This is a lower bound estimate as well, as there are other sources of child mortality and the 13% figure is for all deaths.I think some of the other commenters were expecting higher numbers. It has been very difficult to produce a malaria vaccine in the past, and we already knew this particular one was not very effective. If you had this as a prior, you should be able to see this as the breakthrough it ultimately is. reply freeone3000 16 hours agoparent13% is the reduction in all-cause mortality — ie, if every death this prevented was a death from malaria, this reduced deaths from malaria by over 99%. reply saberdancer 14 hours agorootparentThis would mean that a lot of malaria related deaths are unaccounted for or that the vaccine is helping in another way. reply freeone3000 12 hours agorootparentOne hypothesis is that some people who caught malaria but did not die from malaria, did die more frequently to another cause where having had malaria was a contributing factor to that death. reply lettergram 19 hours agoprevWould love to see independent research, not the company presenting their own.It’s insane to me that we let people with massive financial incentives run their own trials. reply dbdmxjxnx 19 hours agoparentWho&#x27;d pay to run a trial if they didn&#x27;t have an interest in the outcome?A company running their own trial doesn&#x27;t preclude other trials later on. Would you feel better if the African Union nations bucked up for a trial? Because they have a massive financial incentive too, though it&#x27;s based on efficacy rather than sales. reply lettergram 19 hours agorootparentImo most trials should have two parts (1) do a blind bid so competitors can conduct trial (2) fund trial yourself as well. Hide names of both people conducting trial.Keep results hidden and send both results to FDA for review. Publish both results after review. Only attach names of entities who conducted the trial at the end.This enables for a full replication and evaluation without anyone knowing who did anything. And at the very least reduces risk of corruption. reply billythemaniam 18 hours agorootparentDrug trials are already double-blind and highly regulated, particularly stage 3, so further controlling for the corruption you are suggesting doesn&#x27;t seem necessary. If there is evidence (hard evidence not hearsay or conspiracy theories) of that sort of corruption, then I think what you suggest is a good improvement. reply londons_explore 17 hours agorootparentWhen lots of money is on the line, all kinds of people involved find ways to subvert the blinding process. reply billythemaniam 17 hours agorootparentWithout hard evidence, that&#x27;s a great example of a conspiracy theory. reply natechols 19 hours agorootparentprevDo you have a more recent example than Vioxx in mind where your approach might have made enough of a difference to be worth the longer review process? reply Ensorceled 19 hours agoparentprev> It’s insane to me that we let people with massive financial incentives run their own trials.The alternative is for some other organization to be on the hook for the HUGE costs a large scale trial. And then the incentives to not run useless expensive trials goes away. reply anoxor 19 hours agorootparentConsider your argument and opioids, where nearly 1000 people a week overdosed on at the peak?Also consider \"a scientist is as easy to buy as a politician\".Cigarette were considered to not cause cancer backed by science.On top of that, the replication crisis in even chemistry and physics is seeing 30% of results can&#x27;t be replicated.The system is far more busted than people think. reply Ensorceled 16 hours agorootparent> Consider your argument and opioids, where nearly 1000 people a week overdosed on at the peak?What does that have to do, at all, with the process for getting medications approved?These drugs were clearly being oversubscribed, intentionally and for profit, and people should have been sent to jail for this.> Also consider \"a scientist is as easy to buy as a politician\".What does this have to do with anything at all? This is why the FDA has fairly strict guidelines for approvals.> Cigarette were considered to not cause cancer backed by science.Cigarette&#x27;s were never approved in a clinical trial.> On top of that, the replication crisis in even chemistry and physics is seeing 30% of results can&#x27;t be replicated.Clinical trials are not \"chemistry and physics\" papers.> The system is far more busted than people think.I agree, but you are talking about a bunch of unrelated \"systems\", not clinical trials. reply anoxor 13 hours agorootparentif 30% of chemistry and physics papers can&#x27;t be replicated, and something more like 70% of sociology and phycology papers can&#x27;t be replicated, do you think that clinic trials might have a less than 100% trustworthy due to the possible monetary gains from the company conducting them?opioids went through clinical trials, no? reply Ensorceled 9 hours agorootparentOpioids didn’t cause harm because they should have failed their clinical trials. reply unshavedyak 19 hours agorootparentprevTo add to your point, this erodes trust in science too. Public perception of complex topics is very, very important. People effectively have to \"trust\" science. When it&#x27;s corrupted there are ripples of distrust sown through the populace. Vaccine deniers, climate deniers, etcetc - distrust is just one of the fuels that fan these flames. reply Ensorceled 15 hours agorootparentThe people sowing distrust ARE the vaccine deniers and climate deniers. People comparing vaccine trials to cigarettes, like the person you are agreeing with here, ARE the problem; they were not created by \"corporate funded vaccine trials\". reply unshavedyak 11 hours agorootparentYou don&#x27;t think perverse incentivized trials&#x2F;studies&#x2F;etc do damage to public perception? I&#x27;m not well versed in this subject (or versed at all), but if anything i feel like i am the public we&#x27;re speaking about. Pro science, but scared of bad faith science.For example, my perception is that the push for pro-sugar doctrine \"back in the day\" has caused significant health problems and a distrust in the process.Do you view this as not the case? reply anoxor 13 hours agorootparentprevI have a Ph.D. in a hard science, so I guess I&#x27;m not totally unaware of how science works. Let&#x27;s say, I have lived experience as to why 30% of physics and chemistry research can&#x27;t be replicated.Putting 100% faith and trust in a \"corporate funded vaccine trials\" is something I would suggest against given the potential monetary gains from those conducting it. replyrefurb 9 hours agoparentprevThey don&#x27;t run their own trial. Hundreds of doctors and clinics sign up to run trials on the companies behalf. reply linuxftw 20 hours agoprev> To calculate mortality in the three countries, where death registry statistics are unreliable, the researchers employed tens of thousands of community reporters—more than 14,000 of them in Kenya alone—to conduct household surveys of childhood deaths in 79 areas where the RTS,S vaccine was administered and 79 comparator areas where it was not available.That doesn&#x27;t sound remotely close to reliable.> The mortality benefit was documented even in the areas with the lowest RTS,S coverageThe report doesn&#x27;t provide any actual data, so it&#x27;s impossible to make sense of this statement. reply SubiculumCode 18 hours agoparent13% is a large effect size, you&#x27;d have to presuppose a systematic bias in the unreliability between the comparator districts. Also, this is the case where research needs to be conducted but reality makes it hard but you can&#x27;t just +not+ do the research. Field tests are always messy, and I&#x27;d posit that community reporting is probably more reliable thn politically motivated reporting from some governments. reply timr 18 hours agorootparent> 13% is a large effect size,You can&#x27;t just say that. Depends on what you&#x27;re measuring, how you measure it, and how big the denominator is.The fact that they saw the same effect size in groups that didn&#x27;t get the vaccine is a reason to doubt the results, regardless of effect size. It was weird&#x2F;credulous that they called it out as some kind of mysterious woo-woo advantage (\"maybe it helps their immune system somehow!\"). When you see stuff like that in a paper, it makes you scrutinize the results. When you hear it in a conference talk, it makes you reserve judgment until you see the paper. reply roywiggins 17 hours agorootparent> The fact that they saw the same effect size in groups that didn&#x27;t get the vaccine is a reason to doubt the resultWhere does it say that in the article? The closest it gets is \"The mortality benefit was documented even in the areas with the lowest RTS,S coverage\" but the lowest coverage was 62% (the highest was 75%). reply timr 17 hours agorootparentYep, but then they go on to make the credulous woo-woo argument. None of us know what the actual results are here (since this is a conference talk, translated by a reporter), so I can only work with what they say.In any well-done study with an effective treatment, you&#x27;d expect, a priori, that a reduction in intervention produces a reduction in effect. In other words, you don&#x27;t benefit if you don&#x27;t get the drug. reply roywiggins 17 hours agorootparentThe article is actually silent on whether the mortality effect was reduced, or whether the study was powerful enough to reliably detect that the mortality effect was reduced in lower-vaccinated communities. It just says the effect \"was documented\" in those communities, not whether it was exactly as strong. replyyieldcrv 20 hours agoprevinteresting article, many things left me skeptical throughout but I’m glad they’re doing itit seems like a nice stride is occurring in the cheap malaria vaccine marketthe actual malaria part seems to have limited efficacy - which is what was studied initially - while simply having preventative healthcare at all is improving everything, with this vaccine being a useful component on its own in boosting the immune system reply tiahura 20 hours agoprevnext [16 more] [flagged] mchanson 20 hours agoparentThis is a super messed up view point. Eugenics by horrible disease?In any case lower childhood mortality actually reduces birth rates. So your goal of less people will be met through a moral and ethical action of creating medicines rather than purposely not. reply galangalalgol 19 hours agorootparentAlso, it should be considered that one of the causes for decreased gdp in a region is disease burden. I don&#x27;t know anyone with malaria, but from what I have read, it is not conducive to extreme productivity. The global north may get a taste of this with long covid. I don&#x27;t know how it would be studied given the lack of a reliable diagnosis, but I suspect quiet quitting amongst other post pandemic attitude shifts is related to mild cases of this fatigue. We just seemingly all care less about things, which is maybe good for gdh, but not for gdp. reply concordDance 16 hours agorootparentprev> In any case lower childhood mortality actually reduces birth rates.The confounders are way too strong to conclude this. Too many things correlate together. reply cycomanic 14 hours agorootparentThe (strong) correlation has been shown again and again over many different populations, geographical areas and historical data, so this is in no way a controversial conclusion. reply Vecr 8 hours agorootparentWell, it&#x27;s correlated, but generally household income is considered to be more causal for both reduced mortality and reduced fertility. reply sdfghswe 19 hours agorootparentprev> Aren’t there unintended consequences to raising the reproduction rate of a population that is already incapable of effectively supporting itself?He sounds like he&#x27;s just one step short of picking up a gun and start shooting the undesirables. reply badcppdev 19 hours agoparentprevThere are very very strong historical precedents indicating that a decrease in childhood mortality leads to a decline in birth rates. You should google this.\"The child survival hypothesis states that if child mortality is reduced, then eventually fertility reduction follows, with the net effect of lower growth of population. In populations living under low socioeconomic conditions, other factors have also been observed. The question arises whether fertility reduction could be influenced by family planning. Bangladesh data have demonstrated that if not a single child died in a family then the average total fertility rate (TFR) was 2.6 children; when 1 child died the number was 4.7 children; 2 child deaths meant 6.2 children; and more than 3 child deaths boosted the TFR to 8.3 children.\"[0]0 - https:&#x2F;&#x2F;pubmed.ncbi.nlm.nih.gov&#x2F;1670537&#x2F; reply somenameforme 18 hours agorootparentI think there are too many extreme exceptions to this correlation for it to be anything but a correlation. For just one among many, look to any of the countless religious groups within developed countries. These range from Muslims who continue have children at a healthy rate, to the Haredi in Israel who are popping out 6 kids per woman on average. Even Africa&#x27;s blushing there.The obvious and logical explanation, which fits seemingly all data, is simply culture. An obvious one is extreme consumerism. Extreme consumerism is going to drive big economies which makes healthcare widely available, driving down infant mortality. At the same time it&#x27;s also going to drive people to spend their lives trying to earn money instead of raising families, driving down fertility.Without culture playing a largely dominant role it would also have been much harder for countries to artificially manipulate their fertility rates, as Iran and South Korea both did - and later came to severely regret. I&#x27;m leaving China out of the examples as they took more of a legal than cultural approach to try to change their fertility rates. reply usrusr 19 hours agorootparentprevTechnically, that&#x27;s also an unintended consequence.Certainly an observation optimism can cling to, but the mechanisms of evolution suggest that eventually most humans will have some form of immunity to this effect (we pass on more than genes) reply braza 19 hours agoparentprevHonest question: What do you mean by that?Considering the last 220 years and all the evolution that we had in medicine, global trade, and socio-economics (to name a few), on average, it&#x27;s better to be born in South America today than to be a European king or queen 150 years ago.The whole point of my argument is that everyone can have a chance in the world.[1] - https:&#x2F;&#x2F;vizzlo.com&#x2F;gallery&#x2F;time-series-graph&#x2F;example&#x2F;global-... reply somenameforme 19 hours agorootparentImagine I had a little dial I could move, and it would somehow magically change the population of an area. What would you think of me if I took the only remaining area in the world that still struggles to feed their population, and started cranking it up? At the same time imagine I took that same dial, and start sending it lower and lower in the richest and most bountiful places that could afford to support vastly larger populations?What would you think of me? reply xkbarkar 19 hours agoparentprevThere is a fantastic book after Hans Rosling called factfulness. You should read it. It explains a lot of misunderstandings on poverty.A very cruel and poorly informed comment imho. Poverty is not a crime. reply Tao3300 19 hours agoparentprevVerbatim quote from Scrooge telling off the charity workers. reply gosub100 19 hours agoparentprevMany villages were \"supporting themselves\" just fine before western terrorists took over their land. reply concordDance 16 hours agorootparentMass starvation and malnutrition was extremely common all around the world before the industrial revolution. reply fwungy 17 hours agoprevnext [2 more] [flagged] freeopinion 17 hours agoparentAmen. Especially if some of those people help develop a cure for cancer. Or more efficient irrigation techniques. Or a better Ubuntu. reply shipscode 20 hours agoprev [–] 13% over 4 years sounds pretty weak. reply Someone 20 hours agoparentFTA: “the first vaccine approved to fight malaria cut deaths among young children by 13% over nearly 4 years”I read that as 13% of all young children deaths.https:&#x2F;&#x2F;www.sciencedirect.com&#x2F;science&#x2F;article&#x2F;pii&#x2F;S240584402...:“Malaria was the fourth highest cause of mortality in Sub-Saharan Africa, accounting for 10% of children&#x27;s deaths”“In 2013, malaria in Malawi was the leading cause of hospital admissions and death in children under five years of age and pregnant women. The disease accounted for 20% of all deaths of children under five”⇒ I guesstimate this decreased mortality by malaria in those regions by 50-ish percent. reply djoldman 20 hours agoparentprevIt&#x27;s presumably all-cause mortality. So deaths solely attributed to malaria might have seen a far larger drop. reply Fomite 14 hours agoparentprev13% over 4 years for a novel vaccine against a disease we have been trying and failing to eradicate for the better part of several centuries sounds like a pretty significant step forward to me. reply dang 17 hours agoparentprevThanks—we&#x27;ve s&#x2F;slash&#x2F;reduc&#x2F;&#x27;d the title above to make this point clearer. reply Teever 20 hours agoparentprev [–] What numbers would your layman mind cosider acceptable? replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The first malaria vaccine, Mosquirix (RTS,S), has shown a 13% reduction in toddler mortality and a 22% decrease in severe malaria in children over nearly 4 years, as per a significant study carried out in Africa.",
      "Despite safety and efficacy concerns during clinical trials, the World Health Organization (WHO) approved Mosquirix for broad use in 2021, with rollout starting in 2022 for 17 sub-Saharan African countries, affirming its potential in saving lives.",
      "Cost and implementation issues in resource-limited nations are concerns, though a second, possibly more affordable and abundant malaria vaccine, R-21, has recently received WHO's green light."
    ],
    "commentSummary": [
      "The first malaria vaccine, RTS,S, reportedly reduces early childhood mortality by 13% according to a recent study, highlighting a significant advance in malaria prevention.",
      "However, critics argue for additional research before widespread implementation, raising concerns about potential side effects and the reliability of the study due to possible uncontrolled factors and biases.",
      "The post also sparks discussions on broader issues such as the integrity of drug trials, the replication crisis in scientific research, and the necessity of healthcare improvement."
    ],
    "points": 347,
    "commentCount": 111,
    "retryCount": 0,
    "time": 1698236415
  },
  {
    "id": 38019231,
    "title": "Was Rust Worth It?",
    "originLink": "https://jsoverson.medium.com/was-rust-worth-it-f43d171fb1b3",
    "originBody": "Write Sign up Sign In An unsure crab Was Rust Worth It? From JavaScript to Rust, three years in. Jarrod Overson · Follow 8 min read · 14 hours ago 113 2 A few years ago, I dropped everything to focus 100% on WebAssembly. At the time, Rust had the best support for compiling into WebAssembly, and the most full-featured WebAssembly runtimes were Rust-based. Rust was the best option on the menu. I jumped in, eager to see what all the hype was about. Since then, I (along with some other awesome people) built Wick, an application framework and runtime that uses WebAssembly as its core module system. Wick was the primary target of our Rust experimentation After three years, multiple production deployments, an ebook, and ~100 packages deployed on crates.io, I feel it’s time to share some thoughts on Rust. The Good You can maintain more with less I am a massive proponent of test-driven development. I got used to testing in languages like Java and JavaScript. I started writing tests in Rust as I would in any other language but found that I was writing tests that couldn’t fail. Once you get to the point where your tests can run – that is, where your Rust code compiles – Rust has accounted for so many errors that many common test cases become irrelevant. If you avoid unsafe {} blocks and panic-prone methods like .unwrap(), you start with a foundation that sidesteps many problems by default. The aggressiveness of Rust’s borrow checker, the richness of Rust’s type system, the functional patterns and libraries, and the lack of “null” values all lead to maintaining more with less effort spent in places like testing. I’ve maintained the 70,000+ lines of code in the Wick project with far fewer tests than I would need in other languages. When you need to write tests, adding them on the fly is easy without thinking about it. Rust’s integrated test harness lets you add tests right next to code with barely a second thought. I code better in other languages now Programming in Rust is like being in an emotionally abusive relationship. Rust screams at you all day, every day, often about things that you would have considered perfectly normal in another life. Eventually, you get used to the tantrums. They become routine. You learn to walk the tightrope to avoid triggering the compiler’s temper. And just like in real life, those behavior changes stick with you forever. Emotional abuse is not generally considered a healthy way to encourage change, but it does effect change nonetheless. I can’t write code in other languages without feeling uncomfortable when lines are out of order or when return values are unchecked. I also now get irrationally upset when I experience a runtime error. What do you mean “done\" is not a function? Why didn’t you let me know \"done” might not be a function?? Clippy is great! Clippy is Rust’s linter, but calling it a linter is a disservice. In a language where the compiler can make you cry, Clippy is more of a gentle friend than a linter. The Rust standard library is enormous. It’s hard to find functions you know probably exist when so much functionality is spread across myriad granular types, traits, macros, and functions. Many Clippy rules (e.g., manual_is_ascii_check) look for common patterns that stdlib methods or types would better replace. Clippy has hundreds of rules that tackle performance, readability, and unnecessary indirection. It will frequently give you the replacement code when possible. It also looks like (soon) you’ll finally be able to configure global lints for a project. Until now, you had to hack your solution to keep lints consistent for projects. In Wick, we use a script to automatically update inline lint configurations for a few dozen crates. It took years for the Rust community to land on a solution for this, which brings us to… The Bad There are gaps that you’ll have to live with I questioned my sanity every time I circled back around to the Clippy issue above. Surely, I was wrong. There must be a configuration I missed. I couldn’t believe it. I still can’t. Surely there must be a way to configure lints globally. I quadruple-checked when I wrote this to make sure I wasn’t delusional. Those issues are closed now, but they had been open for years. Clippy’s awesome, but this use case is one example of many around the Rust world. I frequently come across libraries or tools where my use cases aren’t covered. That’s not uncommon in newer languages or projects. Software takes time (usage) to mature. But Rust isn’t that new. There’s something about Rust that feels different. In open source, edge cases are frequently addressed by early adopters and new users. They’re the ones with the edge cases. Their PRs refine projects so they’re better for the next user. Rust has been awarded the “most loved language” for the better part of a decade. It’s got no problem attracting new users, but it’s not resulting in dramatically improved libraries or tools. It’s resulting in one-off forks that handle specific use cases. I’m guilty of that, too, but not for lack of trying to land PRs. I don’t know why. Maybe the pressure to maintain stable APIs, along with Rust’s granular type system, makes it difficult for library owners to iterate. It’s hard to accept a minor change if it would result in a major version bump. Or maybe it’s because writing Rust code that does everything for everyone is exceedingly difficult, and people don’t want to deal with it. Cargo, crates.io, and how to structure projects I modeled the Wick repository structure around some other popular projects I saw. It looked reasonable and worked fine until it didn’t. You can build, test, and use what feels like a module-sized crate easily with Cargo. Deploying it to crates.io, though? That’s a whole different story. You can’t publish packages to crates.io unless every referenced crate is also published individually. That makes some sense. You don’t want to depend on a crate that depends on packages that only exist on the author’s local filesystem. However, many developers break large projects down into smaller modules naturally, and you can’t publish a parent crate that has sub-crates that only exist within itself. You can’t even publish a crate that has local dev dependencies. You must choose between publishing random utility crates or restructuring your project to avoid this problem. This limitation feels arbitrary and unnecessary. You can clearly build projects structured like this, you just can’t publish them. Cargo does have excellent workspace support, though! Cargo’s workspaces offer a better experience managing large projects than most languages. But they don’t solve the deployment problem. Turns out, you can set workspaces up in any of a dozen ways, none of which make it easy to deploy. You can see the problem manifest in the sheer number of utility crates designed to simplify publishing workspaces. Each works with a subset of configurations, and the “one true way” of setting workspaces up still eludes me. When I publish Wick, it’s frequently an hour+ of effort combining manual, repetitive tasks with tools that only partially work. Async Rust added async-iness to the language after its inception. It feels like an afterthought, acts like an afterthought, and frequently gets in your way with errors that are hard to understand and resolve. When you search for solutions, you have to filter based on the various runtimes and their async flavors. Want to use an async library? There’s a chance you can’t use it outside of a specific async runtime. After two decades of JavaScript and decent experience with Go, this is the most significant source of frustration and friction with Rust. It’s not an insurmountable problem, but you must always be ready to deal with the async monster when it rears its head. In other languages, async is almost invisible. The Ugly Refactoring can be a slog Rust’s rich type system is a blessing and a curse. Thinking in Rust types is a dream. Managing Rust’s types can be a nightmare. Your data and function signatures can have generic types, generic lifetimes, and trait constraints. Those constraints can have their own generic types and lifetimes. Sometimes, you’ll have more type constraints than actual code. Constraints that outweigh logic You also need to define all your generics on every impl. It’s tedious when writing it the first time. When refactoring though, it can turn a minor change into a cascading mess. Simple generic IDs are duplicated over and over again. It’s hard to make rapid progress when you need to tweak 14 different definitions before you can take a single step forward. The Verdict I love Rust. I love what it can do and how versatile it is. I can write system-level code in the same language as CLI apps, web servers, and web clients. With WebAssembly, I can use the same exact binary to run an LLM in the browser as on the command line. That still blows my mind. I love how rock-solid Rust programs can be. It’s hard to return to other languages after you learn to appreciate what Rust protects you from. I went back to Go for a brief period. I quickly became intoxicated with the speed of development again. Then I hit the runtime panics, and the glass shattered. But Rust has its warts. It’s hard to hire for, slow to learn, and too rigid to iterate quickly. It’s hard to troubleshoot memory and performance issues, especially with async code. Not all libraries are as good about safe code as others, and dev tooling leaves much to be desired. You start behind and have a lot working against you. If you can get past the hurdles, you’ll leave everyone in the dust. That’s a big if. Was Rust worth it for us? It’s too early to tell. We’ve done amazing things with a small team but also had immense roadblocks. We also had technical reasons that made Rust more viable. Will it be worth it for you? If you need to iterate rapidly, probably not. If you have a known scope, or can absorb more upfront cost? Definitely consider it. You’ll end up with bulletproof software. With the WebAssembly angle becoming stronger every month, the prospect of writing perfect software once and reusing it everywhere is becoming a reality sooner rather than later. Sign up to discover human stories that deepen your understanding of the world. Free Distraction-free reading. No ads. Organize your knowledge with lists and highlights. Tell your story. Find your audience. Sign up for free Membership Access the best member-only stories. Support independent authors. Listen to audio narrations. Read offline. Join the Partner Program and earn for your writing. Try for $5/month Rust JavaScript Programming Development Software Development 113 2 Written by Jarrod Overson 2K Followers I write about JavaScript, Reverse Engineering, Security, and Credential Stuffing. Also a speaker, O'Reilly Author, creator of Plato, Director at Shape Security. Follow More from Jarrod Overson Jarrod Overson Bypassing CAPTCHAs with Headless Chrome Using 2Captcha and Puppeteer to automate through CAPTCHAs 9 min read · Dec 3, 2018 2.1K 24 Jarrod Overson Using Chrome Devtools Protocol with Puppeteer Intercepting and Modifying Responses with Chrome 5 min read · Feb 26, 2019 306 2 Jarrod Overson How to bypass “Access Denied” pages with Headless Chrome Some websites block Headless Chrome, here’s how to get around it. 4 min read · Mar 26, 2019 433 6 Jarrod Overson From Zero to Deepfake Exploring deepfakes with DeepFaceLab 8 min read · Sep 17, 2019 299 2 See all from Jarrod Overson Recommended from Medium Shawn.Yang Fury: 170x faster, a new multi-language serialization framework powered by jit and zero-copy Author: chaokunyang 10 min read · Jul 26 213 8 Dotan Nahum How to easily implement a configuration-first provider pattern in Rust 🦀 In this post we’ll review a way to build a provider pattern in Rust which is dynamic, extensible, and fun to maintain, while as statically… 7 min read · Oct 16 12 Lists General Coding Knowledge 20 stories · 476 saves It's never too late or early to start something 15 stories · 176 saves Stories to Help You Grow as a Software Developer 19 stories · 489 saves Coding & Development 11 stories · 232 saves Technocrat in CoderHack.com Rust: Functional Programming & Monads This article expands earlier covered topic further. · 11 min read · Oct 3 23 Lucas Scott in Stackademic “Rust is Hard to Learn” Just a Lie Rust has grown in popularity in recent years, but its steep learning curve has always seemed daunting. However, an internal survey by… · 7 min read · Sep 27 162 2 Luis Soares in Dev Genius Implementing a Network Traffic Analyzer in Rust In this article, we’ll delve into the intricacies of working with network traffic using Rust. We’ll explore capturing packets, parsing… · 11 min read · Oct 8 116 2 TechHara Rust — what #[inline] can do for your program Me being myself, I have been working on writing pure Rust implementation of gunzip program. One of my goals is to get its speed comparable… 3 min read · Sep 8 38 See more recommendations Help Status About Careers Blog Privacy Terms Text to speech Teams",
    "commentLink": "https://news.ycombinator.com/item?id=38019231",
    "commentBody": "Was Rust Worth It?Hacker NewspastloginWas Rust Worth It? (jsoverson.medium.com) 330 points by todsacerdoti 11 hours ago| hidepastfavorite466 comments kuon 7 hours agoI wrote a lot of rust, but after some years it still feels unproductive. I do a lot of zig now and I am like 10 times more productive with it. I can just concentrate on what I want to code and I never have to wonder what tool or what library to use.I know rust gives memory safety and how important that is, but the ergonomic is really bad. Every time I write some rust I feel limited. I always have to search libraries and how to do things. I cannot just \"type the code\".Also the type system can get out of control, it can be very hard to actually know what method you can call on a struct.I still think rust is a great tool, and that it solves tons of problem. But I do not think it is a good general purpose language. reply ernst_klim 47 minutes agoparentI agree. I feel far more productive in C and C++ than in Rust at that point.Rust feels like totally missing the sweet spot for me. It&#x27;s way too pedantic about low level stuff for writing higher level applications, but way too complicated for embedded or writing an OS. In the former case I would rather take a C++, Java, Haskell, OCaml or even Go, and maybe sprinkle some C, and in the latter case C in macroassembly mode is far more suitable.I still have a feeling that original vision of Graydon Hoare (i.e. OCaml&#x2F;SML with linear types, GC, stack allocations, green threads and CPS) would be a much better language. reply cztomsik 48 minutes agoparentprevThis. I have exactly the same experience, I can&#x27;t believe how much I was able to ship with Zig and the code mostly feels like \"done\".You can always improve it, but there&#x27;s no need to. With Rust, I was never happy, even after 5 years, I was still thinking about better abstractions and implementing more traits, making it more generic, etc. reply freilanzer 26 minutes agorootparentWhy is there no need to improve Zig code but there is for Rust code? You&#x27;d need the same abstractions in Zig as well, no? reply cztomsik 2 minutes agorootparentNo, usually you don&#x27;t. Rust has closures, iterators, generics, different traits for operator overloading, smart pointers, etc.Zig doesn&#x27;t have any of that. It&#x27;s very interesting combination of low-level, predictable code, with meta-programming, where you get some of that abstraction back.i.e. Zig does not have generics, but your function can return type, so generic list is just a function which returns a newly created struct. reply goku12 5 hours agoparentprev> but the ergonomic is really bad. Every time I write some rust I feel limited.> But I do not think it is a good general purpose language.Remember that this is not a sentiment that&#x27;s shared by everyone. I use Rust for tasks that need anything more complicated than a shell script. Even my window manager is controlled from a Rust program. I say this as someone who has been programming in Python for nearly two decades now. At this point, I&#x27;m about as fast in Rust as I am in Python. reply pizza234 1 hour agorootparent> At this point, I&#x27;m about as fast in Rust as I am in Python.This is factually impossible.For anything larger than (very) small programs, Rust requires an upfront design stage, due to ownership, that it&#x27;s not required when developing in GC&#x27;ed languages.This is not even considering more local complexities, like data structures with cyclical references. reply goku12 58 minutes agorootparent> This is factually impossible.How do you outright deny something as subjective as my personal experience? Besides, I&#x27;m not the only one in this discussion that made the same opinion.> For anything larger than (very) small programs, Rust requires an upfront design stage, due to ownership, that it&#x27;s not required when developing in GC&#x27;ed languages.While GC&#x27;ed languages allow you to skip a proper initial design stage, it&#x27;s a stretch to claim that it&#x27;s not required at all. In my experience using Python, while the initial stages are smooth, such design oversights come back and bite at a later stage - leading to a lot of debugging and refactoring. This is one aspect where Rust saves you time.> This is not even considering more local complexities, like data structures with cyclical references.I&#x27;m not going to dwell on cyclical references, since there&#x27;s another thread that addresses it. They point out a way to make it as easy in Rust as it is in GC&#x27;ed languages.Meanwhile, the upfront architecture and data structure design isn&#x27;t as complicated as you project it. Rust is mostly transparent about those - even compared Python. How well do you understand how Python manages Lists, dictionaries or even objects in general? I often find myself thinking about it a lot when programming in Python. While you need to think upfront about these in Rust, there&#x27;s actually less cognitive overhead as to what is happening behind the scenes. reply steinuil 39 minutes agorootparentprevThat is also not shared by everyone. If you have written enough Rust to have internalized designing for the borrow checker, you don&#x27;t have to spend much time in a design phase.The only time I find I have to \"fight the compiler\" is when I write concurrent code, and you can sidestep a lot of issues by starting with immutable data and message passing through channels as a primitive. It&#x27;s a style you have to get used to, but once you build up a mental library of patterns you can reasonably be as fast in Rust as you are in Python. reply raincole 57 minutes agorootparentprevOf course it&#x27;s possible. You just need to write Python very slowly :) reply pg_1234 19 minutes agorootparentprev> For anything larger than (very) small programs, Rust requires an upfront design stage, due to ownership, that it&#x27;s not required when developing in GC&#x27;ed languages.Every language requires this (if you want robust code), most just let you skip it upfront ... but you pay dearly for doing so later. reply lumost 5 hours agorootparentprevI tried to get into rust for many years, I&#x27;m now in a C&#x2F;CPP job (after Java&#x2F;Python&#x2F;Ruby and other gigs). What I&#x27;ve come to understand is that Rust&#x27;s lifetime model is very difficult to work with whenever you have a cyclic reference. In C&#x2F;CPP the same holds, but you deal with it through clever coding - or ignoring the problem and cleaning up memory later. Java, and other GC&#x27;d languages just work for these structures.While the Rust devs believe such cyclic references are rare - I think this speaks mostly to the problem domain they are focused on. Relational models are everywhere in Apps, they are often common in complex systems software like databases, and they are fairly rare in firmware&#x2F;drivers&#x2F;system code code.There are a few patterns for dealing with cyclic references, but they all end up requiring either unsafe or a main \"owner\" object which you clean up occassionally (effectively arena allocation). Having now worked in C&#x2F;CPP - the idea of having unsafe blocks sprinkled around the code doesn&#x27;t bother me, and many C&#x2F;CPP components have some form of arena allocation built-in. I just wish Rust learning resources would be more upfront about this. reply lifthrasiir 4 hours agorootparent> Relational models are everywhere in Apps, they are often common in complex systems software like databases, and they are fairly rare in firmware&#x2F;drivers&#x2F;system code code.It&#x27;s not like that you can&#x27;t write relational models in the safe Rust. The only forbidden thing is a reference pointing arbitrary memory, which is typically worked around via indices and often more performant in that way. It is much rarer to find applications that need an absolutely random pointer that can&#x27;t be hidden in abstractions in my opinion. reply goku12 4 hours agorootparentprev> I just wish Rust learning resources would be more upfront about this.While beginner resources don&#x27;t dwell too much upon cyclic references, they don&#x27;t consider unsafe blocks as unusual. All the material I&#x27;ve seen say that there are certain domains where Rust&#x27;s compile-time safety model simply won&#x27;t work. What Rust allows you to do instead, is to limit the scope of unsafe blocks. However, the beginner material often won&#x27;t give you too much details on how to analyze and decide on these compromises.Anyway, compile-time safety checks (using borrow checker) and manual safety checks (using unsafe) aren&#x27;t the only way to deal with safety. Cyclic references can be dealt with runtime safety checks too - like Rc and Weak. reply mtsr 3 hours agorootparent> Cyclic references can be dealt with runtime safety checks too - like Rc and Weak.Indeed. Starting out with code sprinkled with Rc, Weak, RefCell, etc is perfectly fine and performance will probably not be worse than in any other safe languages. And if you do this, Rust is pretty close to those languages in ease of use for what are otherwise complex topics in Rust.A good reference for different approaches is Learn Rust With Entirely Too Many Linked Lists https:&#x2F;&#x2F;rust-unofficial.github.io&#x2F;too-many-lists&#x2F; reply pncnmnp 2 hours agorootparentAlso, take a look at GhostCell (https:&#x2F;&#x2F;plv.mpi-sws.org&#x2F;rustbelt&#x2F;ghostcell&#x2F; and https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=jIbubw86p0M). If anyone&#x27;s used this in a project or production environment, I&#x27;d love to hear your firsthand experiences and insights. reply pjmlp 1 hour agorootparentprevExcept in those other languages the compiler types .clone() for me. reply worik 28 minutes agorootparentprev> While the Rust devs believe such cyclic references are rare -They are.I have not had to use cyclic references ever, except once doing experiments with fully connected graphs, that was very unusualIf you&#x27;re doing a lot cyclic references Rust is not the right choice. Horses for coursesBut are you sure you&#x27;re using the best algorithm? reply mjevans 4 hours agorootparentprevWhat&#x27;s a frequently encountered case for such cyclic loops? Without details I&#x27;m drawn to trying to break the cycle, either by promoting the shared state to a container object for the set, or by breaking it out into it&#x27;s own object that multiple things can point at. reply rurban 3 hours agorootparenta parent field.a doubly linked list reply tialaramex 1 hour agorootparentYour parent said \"frequently encountered\" and while it&#x27;s probably true that doubly linked lists may be \"frequently encountered\" in some people&#x27;s code they&#x27;re usually a bad idea and \"don&#x27;t use a list here\" is often the right fix, not \"conjure a way to make that safe in Rust\".It&#x27;s very noticeable how often people who \"need\" a linked list actually only wanted a queue (thus Rust&#x27;s VecDeque) or even a growable array (ie Vec).Aria has a long list of excuses people offer for their linked lists, as well as her discussion of the time before Rust 1.0 when she sent lots of Rust&#x27;s standard library collections to that farm up-state but wasn&#x27;t able to send LinkedList.https:&#x2F;&#x2F;rust-unofficial.github.io&#x2F;too-many-lists&#x2F; reply littlestymaar 2 hours agorootparentprevDoubly-linked list is something you have almost no reason to ever write.Parent field is something where you have a clear hierarchy (it&#x27;s not really “cyclic”, so it&#x27;s the perfect use-case for weak references).When coming from a managed-memory language, this obviously requires some conceptual effort to understand why this is a problem at all and how to deal with it, but when compared to C or C++, the situation is much better in Rust. reply jacobgorm 1 hour agorootparentAlso, a parent field is something you should be able to infer, e.g, keep a stack of parents as you traverse down a search tree following the child pointers, instead of storing parent pointers in the tree nodes. reply akoboldfrying 51 minutes agorootparentThat&#x27;s assuming you traverse the tree down from the root each time. Often you do, but there are cases where you don&#x27;t -- e.g., if your goal is to determine the lowest common ancestor of two given nodes. reply solomonb 4 hours agorootparentprevASTs reply SkiFire13 2 hours agorootparentAn abstract syntax tree can&#x27;t have cycles by definition. reply foldr 2 hours agorootparentTechnically true, but sometimes you want parent pointers. You then have a more general graph in the underlying representation, but it still represents a tree structure. reply lifthrasiir 3 hours agorootparentprevASTs are one of \"nicely behaving\" data structures. It is like a archetype of abstract data types pervasive in functional programming languages. reply mordae 39 minutes agorootparentprevYou usually solve this by using a traversal helper that keeps the stack and next&#x2F;prev for you without storing them inside the AST explicitly. reply mjevans 3 hours agorootparentprevAn Abstract Syntax Tree &#x2F; or Double-Linked List both qualify, but they&#x27;re also a lower level implementation detail than I&#x27;d expect to frequently interact with in a reference safety focused language.I&#x27;ve still been meaning to write something in &#x2F; learn Rust&#x27;s ways of thinking; is there not an intended replacement for these data structures? Or do they expect it all to go under Unsafe? reply littlestymaar 2 hours agorootparent> is there not an intended replacement for these data structures? Or do they expect it all to go under Unsafe?For linked-lists, there&#x27;s one in std and the majority of people should never have to write their own as it&#x27;s error prone and requires unsafe.For graph use-case then you can either use ECS, arena, ref counting or unsafe, but you&#x27;re probably better off using&#x2F;developing a dedicated crate that optimizes it and abstract it away behind an easy to use (and safe) interface. reply zabzonk 21 minutes agorootparentprevto be a bit pedantic, i assume the language you a referring to as CPP is actualy C++? cpp to me means the c (and c++) preprocessor. reply hiAndrewQuinn 3 hours agorootparentprevI&#x27;ve finally set my mind to properly learning a new language after Python, Haskell, and typescript. I&#x27;m looking into Rust especially because of how I&#x27;ve heard it interoperates with Python (and also because it&#x27;s maybe being used in the Linux kernel? Is that correct?). reply tinco 2 hours agorootparentRust is an excellent follow up to those languages. It&#x27;s got many influences from Haskell, but is designed to solve for a very different task that&#x27;s not yet in your repertoire so you&#x27;ll learn a ton.And yes the Python interop is excellent. reply hiAndrewQuinn 1 hour agorootparentI&#x27;m sold, thank you. Yes, it felt like a great \"missing quadrant\" to my generalist skillset. reply PartiallyTyped 3 hours agorootparentprevLinux kernel has support for rust userland drivers, and rust interops with python with pyo3. reply maccam94 2 hours agorootparentNot sure what you mean by \"userland\" drivers here, but support for kernel modules written in rust is actively being developed. It&#x27;s already being used for kernel drivers like the Asahi Linux GPU driver for M1 Macs. reply PartiallyTyped 2 hours agorootparentI am referring to userspace &#x2F; userland drivers.https:&#x2F;&#x2F;www.kernel.org&#x2F;doc&#x2F;html&#x2F;v4.18&#x2F;driver-api&#x2F;uio-howto.h... reply PartiallyTyped 3 hours agorootparentprevSurprisingly, I am faster in Rust than any other language. Something about my prior experiences just made it click just the right way.I don&#x27;t want to program in anything else anymore. I don&#x27;t want to deal with obscure C++ error messages, C footguns and lack of ergonomics, I don&#x27;t want to deal with abstraction hell of Java, or the poor person&#x27;s typing that python has.I have been programming in Python for the past 6 years, I know all sorts of obscure details, and with rust, I just don&#x27;t need to think about all of those issues. reply goku12 1 hour agorootparent> Surprisingly, I am faster in Rust than any other language.Not really surprising, given that you have C and C++ background. That&#x27;s what I was trying to highlight. Rust isn&#x27;t a confusing or unproductive language as many project it to be - if you have the conceptual understanding of what happens on the hardware. Especially about stack frames and RAII. If you know those, the borrow checker complaints will immediately make sense and you will know how to resolve them.Add rust-analyzer (Rust&#x27;s language server) to it, you get real-time type annotations and a way to match types correctly in the first attempt. In my experience Rust also helps structure your program correctly and saves a ton of time in debugging. All in all, Rust is a fast way to write correct programs. reply PartiallyTyped 1 hour agorootparentI&#x27;d add that if you have some understanding of how memory ownership should be such that you don&#x27;t end up with memory leaks, you are fine. The borrow checker just verifies that your mental model is correct, and removes some of the cognitive load from you. reply ostenning 3 hours agoparentprevOpposite experience for me. Writing Rust on embedded systems greatly improved my confidence and speed. When using C a small mistake often leads to undefined behaviour and headaches. Rust theres none of that - its been a game changer for me. reply conradev 4 hours agoparentprevI agree with this general feeling, and it is hard to articulateRust forces you to figure out ahead of time where each bit or byte is going to go and on which thread and using which mutation scheme. I’m happy to play the game, but it feels tedious for anything short of a parser or a microcontroller.It messes with my process because I like to get something working before I determine the best API structure for itI can get 90% of the performance with Swift and it flows much more easily, even though Rust’s type system is more powerful. reply csomar 3 hours agoparentprevWait, I am a bit confused. Does Zig have more&#x2F;better libraries than Rust? I thought it&#x27;s a pretty new language. The most limiting thing for me with Rust was the lack of libraries (vs. say Python or Node&#x2F;JavaScript). reply Quekid5 3 hours agorootparentIt interops seamlessly with C libraries. reply csomar 3 hours agorootparentDepending on what seamlessly means, Rust can also interop with C libraries. I wrapped a bunch of them. reply GuestHNUser 2 hours agorootparentTruly seamless because the zig compiler is also a C compiler, so the type information and calling convention works across languages at a level above any other I&#x27;ve encountered. reply littlestymaar 1 hour agorootparentTrue, but I think that the person you&#x27;re responding argued that rust&#x2F;C integration is also seamless. (In the general discussion I&#x27;d say they&#x27;re right as C to Rust integration isn&#x27;t much of an problem and you can use C libraries relatively easily in Rust as well, but at the same time when talking about Zig I don&#x27;t think it&#x27;s fair to put it on the same ground). reply hailruda 2 hours agorootparentprevSeamlessly as in @cInclude(\"raylib.h\") reply littlestymaar 2 hours agorootparentprevIt doesn&#x27;t. The ecosystem is very immature and even the official tooling is very unstable. It has a bunch of interesting design ideas but at this point it&#x27;s more of an experimental language than a production ready one by most metrics. (And unless it finds some kind of corporate backing, this is unlikely to ever change). reply anon-3988 5 hours agoparentprevI am curious what kind of code you are writing? Is it very low level or very high?>I know rust gives memory safety and how important that is, but the ergonomic is really bad. Every time I write some rust I feel limited. I always have to search libraries and how to do things. I cannot just \"type the code\".You don&#x27;t have to search libraries and figure out how to do things in Zig? reply dharmab 4 hours agorootparentIt&#x27;s hard to describe, but in some languages, you spend a lot less time looking at reference docs and more time just naturally writing the solution. Lisp is a great example of that, if you get through the learning curve. reply pjmlp 3 hours agoparentprevI rather use compiled managed languages like Swift, D and C# instead, they provide enough low level coding knobs for C and C++ style coding, while being high level productive.Would add Go to the list, but only when I really have to.Nim and Crystal could be alternatives, but don&#x27;t seem to have big enough communities, at least for what I do.However I do agree with the conclusion, Rust is a great language for scenarios where no form of automatic memory management is allowed, kernels, specific kinds of drivers, GPGPU programming, as general purpose, there are more productive alternatives, equally safe. reply hiAndrewQuinn 3 hours agorootparentC# is underrated by the HN crowd, I find. I quite like how mid sized firms (100-1000 employees) use it. reply tkubacki 3 hours agorootparentI used to be .NET dev and don&#x27;t agree. Couple of reaons:1) Modern Java is almost as good as C# with some things I can&#x27;t give up in Java (static imports => succint code, Groovy Spock => succint tests)2) Kotlin is better than C#3) JVM has much much bigger ecosystem (almost all the apache projects are JVM oriented) and default web framework is much less code to type (SpringBoot) is much more productiv4) JVM has wider variety of langsFor those reasons IMHO if you are small-mid company (or startup) it&#x27;s wiser to choose JVM. reply pjmlp 2 hours agorootparentKind of, maybe you need to do some low level coding and don&#x27;t want to wait for Valhala, or make use of JNI and native libraries, GraalVM&#x2F;OpenJ9 still aren&#x27;t as integrated as .NET Native or Native AOT, e.g. writing native shared libraries.Also Java lost the attention span of the gaming industry, besides Android casual games and Minecraft, there are hardly anyone else paying attention to it. reply Ygg2 1 hour agorootparentTo be fair, C# is ok for game dev, but not great. C# libraries are lagging heavily behind Java.Want a fastest possible library? It&#x27;s in C++, and not portable to Win&#x2F;Mac. So good luck with wrap + porting it.Want a decent implementation of an algo? It usually exists for Java but not for C#. Hope you like writing it from scratch.Want a C# implementation of an algo that doesn&#x27;t allocate to the Nth degree. Again, write it yourself.But ok, maybe Unity has a good ecosystem... And they fucked it over a barrel. reply pjmlp 1 hour agorootparentIt is widely better recieved in the AAA gaming developer community than Java, and that is what matters.I also like Java, but c&#x27;mon no decent algorithms being implemented in C#? That is already approaching zealotry. reply Ygg2 40 minutes agorootparentI didn&#x27;t say no decent algorithm in C#, but for each performance sensitive algorithm&#x2F;data structure there is a C and Java implementation at the least ( in my case Roaring Bitmaps).In C# the solution is half baked or archived or abuses allocation.I think Unity has way more with C# adoption in game dev than innate C# qualities. reply neonsunset 22 minutes agorootparentThis is a classic case of goalpost moving. The reason why so many algorithms are written in Java especially closer to academic side is because most curriculums in comp-sci often straight up not allow using anything else except Java, Python or sometimes C++. Having C# as an alternative in these is a luxury. There are also more people using Java in general. However, this does not make it a better language at solving these tasks, nor it is any suitable for writing high performance implementations for advanced vectorized algorithms which would push hardware, which is actually what you want when you start caring about such scenarios, which C# excels at. replympawelski 1 hour agorootparentprevJava is surely keeping up but I can&#x27;t name single Java feature that I miss in C# or is implemented better in Java. I haven&#x27;t used Java in a long time though, just occasionally I read about new Java features and I&#x27;ve never said to myself \"cool, I wish I had it in C#\".Static import are also available in C# for quite some time now (c# 6, released in 2015, and in C# 10 you can even make this import global for for project).I haven&#x27;t used Kotlin, is there any killer feature compared to C#? (except more succinct code in certain cases?) reply pjmlp 16 minutes agorootparentDepending on how you look at it, better extension everything support on Kotlin&#x27;s case, and a way to do DU, while it keeps being discussed for C#, people should just add F# to their codebase, but alas. reply lenkite 46 minutes agorootparentprevAlso with JDK 21 - you can use virtual threads. No need for async&#x2F;await which IMHO is a design mistake. Java copied Go here instead of C#. reply leeman2016 1 hour agorootparentprevC# is a lovely language to work with.The only issue I have is with the .NET ... that is, building self-contained binaries to distribute.For comparison:* Hello World win-x64 binary self-contained in .NET 7 is around 70 MB* The same for Go results in 1.2 MBEdit: Missed &#x27;trimming&#x27; in .NET, which would result in a binary of size around 11 MB in win-x64 reply pjmlp 1 hour agorootparentUsually that means you aren&#x27;t using trimming, .NET speak for dead code removal during linking.Also remember that standard .NET runtime does a little bit more than Go&#x27;s runtime, so it might happen that even with trimming, for basic applications Go ends up having an upper hand on file size.On the other hand, I have had Go static binaries grow up to 200 MB and being require to use UPX to make it manageable, e.g. trivy. reply leeman2016 1 hour agorootparentYou&#x27;re right. But even with trimming I get around 10x the size of the Go binary reply pjmlp 1 hour agorootparentSince I edited my comment, see my additional remarks regarding runtime capabilities, and the counterpoint of big Go binaries.Also note that triming only works properly if the libraries have taken the effort to be trimmable, as the linker errs on the safe side and won&#x27;t trim unless certain that it is really dead code, and not called via reflection. reply neonsunset 1 hour agorootparentprevnext [–]dotnet publish -c release -p:PublishAot=true reply leeman2016 42 minutes agorootparentprevLet me give a real world example from my own experience.I have built a Win32 desktop app with its core logic in Go; and then re-built from scratch using .NET (v7). The core logic involved a fairly complicated keyboard input processing based on bunch of config files.- Final binary of .NET ~ 14 MB- Final binary of Go ~ 2 MB reply neonsunset 1 hour agorootparentprevThis is an unfair comparison of apples to oranges by building the binary with the wrong flags. .NET produces smaller binaries than Go with NativeAOT (despite including more features). reply leeman2016 50 minutes agorootparentYea, I missed trimming. But still NativeAOT results in 10x the size of the Go binary in Windows (win-x64) reply neonsunset 44 minutes agorootparentTwo aspects:- There is no point in chasing smallest possible binary size if it trades off performance and features one wants to use in production scenario, or comes with other tradeoffs that sacrifice developer productivity. I don&#x27;t see anyone complaining about the size of GraalVM native images. As long as binaries are reasonably sized, it&#x27;s not an issue.- dotnet publish -c release -p:PublishAot=true definitely produces smaller binaries than Go as of .NET 8 (and no, you cannot use the argument that it&#x27;s not released yet - it&#x27;s in RC.2 which is intended for evaluation for adopting .NET 8 scheduled for release next month) reply leeman2016 41 minutes agorootparentThat&#x27;s awesome, honestly. Can&#x27;t wait. replyeddtries 3 hours agorootparentprevI&#x27;ve always found those sort of firms with C#, in my experience, have the best architected code. Proper domain-driven design, onion architectures, clean testable code... Some have legacy issues where they might not have the most cutting edge CI&#x2F;CD pipeline or high automated test coverage, but the code itself can be very nice. I&#x27;ve never really experienced that level of consistency with a different language&#x2F;company size. reply hutattedonmyarm 2 hours agorootparentprevIs it? Every time I see C# being mentioned here people agree how awesome it is. Not that I&#x27;m complaining, I love C# reply GuestHNUser 2 hours agorootparentAgreed. I feel C# is appropriately rated on HN and other programming forums. It has perfomant memory options that other GC languages lack, and great builtin packages to use. Overall, it is a good language.My biggest issue with C# though is how badly exceptions are handled given that it is a statically typed langauge. I wish functions explicitly defined the exceptions it can throw since a minor package bump could add an exception without your compiler warning you that it isn&#x27;t handled. I much prefer Rust, Go and Zig&#x27;s error handling to C#&#x27;s since those kind of issues don&#x27;t happen. reply pjmlp 1 hour agorootparent> It has perfomant memory options that other GC languages lack, and great builtin packages to use.As clarification for the audience, it isn&#x27;t the only GC enabled language with C and C++ like capabilities, in fact there are several examples since the early 1980&#x27;s.The adoption push for Java and scripting languages distorced the understanding of what was already available out there. reply Rapzid 1 hour agorootparentprevWell, I see it as lack of fanboyism which is interesting and almost unique to the Java&#x2F;C# ecosystem. A lot C# experts(and I mean REAL, low level experts) seem to also have very high Java expertise..And those that have Java expertise but not C# seem to demur to those that do; image!But it&#x27;s still niche(around here and in the startup world) and gets lumped in with Java and together they are not \"hip\" or \"agile\" or whatever. reply Ygg2 1 hour agorootparentprevC# is fine, but it feels like a slightly better Java, just without the huge ecosystem of libraries. reply Rapzid 1 hour agorootparentSlightly... The difference in type erasure is pretty huge IMHO.But what libraries are you lacking? reply Ygg2 35 minutes agorootparentType reification is planned and so is value types.And type erasure isn&#x27;t as negative as you seem to make it.Bunch of really obscure use cases - fluent localization, roaring bitmaps and so on. replypush-f 5 hours agoparentprev> it can be very hard to actually know what method you can call on a structThe rust-analyzer language server can autocomplete the available methods for a value. reply n3storm 5 hours agorootparentdepending on the autocompleter feels like asking to code to Chatgpt to me. reply push-f 5 hours agorootparentI disagree, there&#x27;s a big difference: rust-analyzer is deterministic and 100% accurate while ChatGPT is non-deterministic and hallucinates. reply samus 2 hours agoparentprevIt somehow seems that Zig has most of the qualities that people like about C: clear, crisp, no huge Stdlib, good old straightforward imperative semantics, and readonably fast. But without lots of the cruft. reply oneshtein 49 minutes agoparentprevBy \"wrote\" you are meaning just coding or coding+debugging? Because other languages are easier to code, but hard to make error free, while Rust is hard to write but much easier to make bug free. reply nlnn 1 hour agoparentprevI use Rust a lot, and have been really keen on getting into Zig.Not sure if much has changed (it was a while back), but my biggest problem was with finding and using 3rd party libraries (mostly for the boring stuff like DB connectivity, JSON&#x2F;YAML parsing, logging, etc.).E.g. even now if I search for \"zig mysql library\", the tops hits are all about people discussing it on reddit, than any actual library. reply lifthrasiir 4 hours agoparentprevSince you have previously said that you are using Zig to do embedded programming for medical devices, I assume that it is your main pain point. I largely agree that the current Rust embedded story is not exactly for existing embedded programmers (and I guess you are one of them). Rather it looks more like a solution for existing application programmers. I don&#x27;t think it&#x27;s an intrinsic limitation of Rust the programming language, rather a specific community at this point happens to prefer this way. Still it is a weakness in some sense and Zig will be a good alternative. reply synergy20 6 hours agoparentprevnim could be another option which defaults to c backend with python syntax reply darthrupert 4 hours agoparentprevYou should try diving into num for like a month and see how you like it. It&#x27;s different enough that you need to go past a certain kind of ledge to start liking it. Or at least that was my experience.For me, it shares the most important benefits of Rust but with quite a lot more ergonomic coding model. reply darthrupert 15 minutes agorootparentWoopsie. I meant s&#x2F;num&#x2F;nim&#x2F; of course. reply renox 2 hours agoparentprevGiven that Zig is memory unsafe it isn&#x27;t either a good general purpose language.IMO a good GPR is memory safe (no C, C++, Zig), is easy to use(no Rust), has strong static typing (no Perl, Python, Ruby) and is \"stable\" (no Scala). Lots of choices remain: Java, Kotlin, Ada, D, OCaml.. reply AbuAssar 2 hours agorootparentc# reply chungy 10 hours agoprevPerhaps my biggest critique is that crates.io has no namespacing. Anyone can just claim a global and generic package name and we mostly have to deal with it (unless you avoid using the crates.io repository, but then you&#x27;ll probably have more problems...). Some of these globally-claimed generic packages are not really the best package to use.Maybe it was a reaction against the Java-style reverse DNS notation, which is verbose and annoying, but a more GitHub-style user&#x2F;group namespace prefixing package names would have been the nice middle ground. reply fawadasaurus 9 hours agoparentI did some analysis on crates.io to find the top name squatters. Then I did some calculations and found that the top name squatter created their crates at a rate of about one ever 30 seconds for a period of a week straight.I send the analysis to the crates.io team and pointed that they have a no-automation policy.They told me that it was not sufficient proof that someone was squatting those names. That&#x27;s my problem with crates.io is that they have a clear policy and they don&#x27;t enforce it so all the short&#x2F;easy to remember names for crates are already taken and there is nothing you can do to get it. reply nindalf 2 hours agorootparentIn July 2023 the crates.io team started asking for feedback around changing their policy around name squatting - https:&#x2F;&#x2F;rust-lang.zulipchat.com&#x2F;#narrow&#x2F;stream&#x2F;318791-t-crat... reply ogoffart 5 hours agorootparentprev> they have a no-automation policyWhat&#x27;s that? I have scripts that automate publishing of new release of my crates. And I think many projects have. reply hobofan 4 hours agorootparentOf course that&#x27;s permitted.What they stated was only regarding claiming new ownership over crate names:> Using an automated tool to claim ownership of a large number of package names is not permitted. reply serial_dev 2 hours agorootparentprevWrite some automated analysis that looks up popular packages on npm, pub.dev, rubygems, nuget. \"Rustify\" the package names. Add to it frequently used words, maybe popular names, etc. Then, write a script that creates an empty package, registers a name on crates.io every thirty seconds, and then you have about 20k package names after a week that nobody can use. reply echelon 9 hours agorootparentprevThere&#x27;s a secret effort in the Rust community to supplant Crates.io and create an entirely new package ecosystem with proper namespacing, security, and much better community.Not naming names, but I know several people working to put Crates.io out to pasture.There&#x27;s a level of playing nice with them for the time being (eg. build reproducibility), but it&#x27;s only KTLO.Crates.io needs to die for Rust to thrive. They&#x27;re a bungled, mismanaged liability. New code, new leadership. reply jeroenhd 9 hours agorootparentCrates.io doesn&#x27;t need to die necessarily. It needs some competition as a wake-up call.Once a better alternative is out there, crates.io will either wither and die or improve. If it matches its competition in terms of quality and reliability, everyone is better off. If not, the alternative solution will take over.I&#x27;m eager for this crates.io alternative to land, assuming they don&#x27;t break too many projects in their improvements. reply solardev 9 hours agorootparentprevWhy does something like that need to be secret...? Isn&#x27;t it in the community&#x27;s best interest? reply TylerE 9 hours agorootparentDrama avoidance and avoiding bikeshedding seem obvious. Much easier to present a working system than a design that will get nitpicked into irrelevancy. reply solardev 9 hours agorootparentYeah, that makes sense. reply sapling-ginger 8 hours agorootparentprevThat quite funny. Just like when some people formed a violent militant group to take down a violent tyranical dictatorship. Of course they would promise that they would absolutely de-arm right after the dictatorship has been overthrown, and immediately establish a peaceful democratic government with fair election. They absolutely would, would they? They would never turn into what they were formed to replace, would they? reply Conscat 8 hours agorootparentIf one tyranny has namespaces and the other doesn&#x27;t, I&#x27;ll prefer the former. reply wyldfire 6 hours agorootparentnext [–]pub use std::sic::semper; replyepage 7 hours agorootparentprevI find this interersting as most namespacing solutions would need the cargo team involved and I&#x27;ve heard nothing about this. reply bluejekyll 6 hours agorootparentThis was my first thought too. And there are a lot of questions that will get asked, like, will all crate library names start being prefixed as well? So you end up withuse::bar; &#x2F;&#x2F; changing touse::foo::bar;I assume the library names that can be overridden in cargo would still be accepted, and then it all gets a little messy. The transition would be very messy. reply awesome_dude 9 hours agorootparentprevHow secret is it now that you&#x27;ve posted on HN about it? reply fullarr 9 hours agorootparentWait I thought only I could read the secret reply fsckboy 7 hours agorootparentyes, HN hides secrets automatically******* is my password, but you can&#x27;t see it. Type your password back, and I won&#x27;t be able to see it. Try it! reply wyldfire 6 hours agorootparentI&#x27;m not sure it&#x27;s working the way you described:hunter2 reply kaycey2022 5 hours agorootparentIt’s working. I really can’t see it. All I see is **** reply overtomanu 3 hours agorootparentprevMaybe you are getting tricked to give out your password... reply WJW 1 hour agorootparenthttps:&#x2F;&#x2F;knowyourmeme.com&#x2F;memes&#x2F;hunter2 replyechelon 8 hours agorootparentprevIt&#x27;s an open secret. reply nindalf 5 hours agorootparentHilarious. reply csomar 3 hours agorootparentprevcrates.io is fine. reply lolinder 10 hours agoparentprev> Maybe it was a reaction against the Java-style reverse DNS notationI suspect it was less a reaction against anything and more just following the norms established by most other package managers. NPM, PyPI, RubyGems, Elixir&#x27;s Hex, Haskell&#x27;s Cabal... I&#x27;m having a hard time thinking of a non-Java package manager that was around at the time Rust came out that didn&#x27;t have a single, global namespace. Some have tried to fix that since then, but it was just the way package managers worked in 2014&#x2F;2015. reply lucideer 10 hours agorootparent> I&#x27;m having a hard time thinking of a non-Java package manager that was around at the time Rust came out that didn&#x27;t have a single, global namespaceThe implication here is that namespaces in package managers weren&#x27;t a known concept. Outside Java, NPM - probably the biggest at the time - not only supported them but was actively encouraging them due to collective regret around going single-global in the beginning. Composer is another popular example that actually enforced them.Not only was namespacing a known widespread option, with well documented benefits, it was one that was enthusiastically argued for within the Rust community, and rejected. reply lolinder 10 hours agorootparentNPM added namespaces in version 2, which was released in Sep 2014, just 2 months before cargo was announced. I don&#x27;t remember anyone making a big deal about using scopes in NPM for several years after that, it was just there as an option. The announcement blog post of v2 only gives two paragraphs to scoped packages and explicitly frames the feature as being for enterprises and private modules [0]:> The most prominent feature driving the release of npm 2 didn’t actually need to be in a new major version at all: scoped packages. npm Enterprise is built around them, and they’ll also play a major role when private modules come to the public npm registry.My memory is that the industry as a whole didn&#x27;t really start paying attention to the risks posed by dependencies in package managers until the left pad incident.To be clear, I&#x27;m not saying that it was a good idea to not have a better namespace system or that they were completely ignorant of better options, just that they were very much following the norms at the time.[0] https:&#x2F;&#x2F;blog.npmjs.org&#x2F;post&#x2F;98131109725&#x2F;npm-2-0-0.html reply devman0 6 hours agorootparentThe left pad issue was kind of wild coming from the enterprise Java space. Supply chain attacks against open source software were already being taken pretty seriously, my last company had it&#x27;s own Maven repository manager running that was used to stage and vet packages before they could be used in production. reply cmrdporcupine 6 hours agorootparentYeah it&#x27;s all a bit of revisionist history here, or I guess a bit ignorant. I had a friend who worked at Sonatype from pretty early days and they were, as I understand it, specifically working in this area of infrastructure for vetting, signing, license checking, etc. for corporate environments that needed to be extra careful about this stuff.That crates.io launched without explicitly acknowledging this whole problem is either naivety or worse: already by then Java wasn&#x27;t \"cool\" and the \"cool kids\" were not paying attention to what happened over there.It&#x27;s not that the industry wasn&#x27;t paying attention until the &#x27;left pad incident&#x27; -- that only holds if one&#x27;s definition of \"the industry\" is \"full stack developers\" under the age of 30; I remember when that happened and I was working in a shop full of Java devs and we all laughed at it...Maven&#x27;s biggest problem was being caked in XML. In other respects it was very well thought out. That and it arrived at the tail-end of the period in which Java was \"cool\" to work in. reply lolinder 5 hours agorootparentIt&#x27;s not revisionist history, the wording I chose was meant to acknowledge that there were segments of the industry that did take dependencies seriously. I&#x27;m very much aware that the Java world had a much more robust approach to dependencies before this, but \"the industry as a whole\" includes all the Node shops that were hit by leftpad as well as all the Python and Ruby shops that were using equally lousy dependency management techniques.Rust chose to follow the majority of languages at the time. Again, as I noted in my previous comment, I&#x27;m not defending that decision, just pointing out that most of the widely-used languages in 2014 had a similar setup with similar weaknesses. reply rat87 3 hours agorootparentprevI don&#x27;t think the left-pad problem wasn&#x27;t about package namespacing it was about the ability to unpublish packages as well the prevalence of micropackages caused by lack of a decent standard library.Also npm&#x27;s bad policy&#x2F;decision to transfer control of package in the name of predictability(this should probably be avoided for packages that aren&#x27;t malicious. You could argue for seizing broken&#x2F;trivial and unmaintained packages that have a good name but even then it might be best to leave well enough alone).I suppose you&#x27;re talking about the original dispute which led the developer to unpublish his libraries (which npm stupidly allowed, and cargo didn&#x27;t). There&#x27;s a smaller chance of a company wanting a random package namespace then a package name but its not impossible (think Mike Rowe Soft vs Microsoft) reply rat87 3 hours agorootparentprevWhat are the benefits? reply rcxdude 1 hour agorootparentmainly, you can trust that anything under the foo&#x2F; namespace is controlled by only a smaller group of people, as opposed to the current situation on cargo where people pseudo-namespace by making a bunch of packages called foo-bar, foo-baz, and you can&#x27;t trust that foo-bin wasn&#x27;t just inserted by someone else attempting to appear to be part of the foo project. It also helps substantially with naming collisions, especially squatting. reply stcroixx 9 hours agorootparentprevPerl’s CPAN was around in the 90’s and all modules were namespaced. reply lolinder 9 hours agorootparentFair enough. As I noted to another commenter, I&#x27;m not trying to say there was no prior art (if nothing else there was Maven), just that they were following the overwhelming majority of mainstream languages at the time. reply jeremyjh 8 hours agorootparent> just that they were following the overwhelming majority of mainstream languages at the time.They were trying to do better than mainstream languages in other areas and succeeded. IIRC on this front they just decided Ruby&#x27;s bundler was the bee&#x27;s knees. reply nindalf 5 hours agorootparentThe same developer who worked on bundler also worked on the initial version of cargo. That’s why they’re similar.And at that time, it was a good idea. Ruby was popular and bundler + gem ecosystem was a big reason for its popularity. No one was worried that Rust might become so popular that it might outgrow the bundler model. That was only a remote possibility to begin with. reply jiggawatts 10 hours agorootparentprevYes, and all of those have had major security issues caused by their lack of foresight.\"We&#x27;re pretending security is not an issue.\" has been the feedback every time this is raised with the Cargo team.To be honest, it&#x27;s turned me off Rust a little bit.The attitude of \"Rust is memory-safe, so we don&#x27;t need any other form of security.\" is not a good one. reply pcwalton 10 hours agorootparent> \"We&#x27;re pretending security is not an issue.\" has been the feedback every time this is raised with the Cargo team.Literally nobody has said this.> The attitude of \"Rust is memory-safe, so we don&#x27;t need any other form of security.\" is not a good one.Fortunately it&#x27;s an attitude that nobody in the Rust project has! reply Freedom2 6 hours agorootparent> Literally nobody has said this.I know of a few people, personally, who have said this. reply worik 18 minutes agorootparent> I know of a few people, personally, who have said thisjiggawatts reply FridgeSeal 6 hours agorootparentprevOk, but like, were any of them people of note, actively working on the project?Because it seems like the people who are working on the project aren’t saying that. reply jiggawatts 3 hours agorootparentThe people that are working on the project haven&#x27;t implemented namespaces, or any other security feature really, so what they say is immaterial. What they do is the only thing that matters. reply muldvarp 10 hours agorootparentprev> \"We&#x27;re pretending security is not an issue.\" has been the feedback every time this is raised with the Cargo team.Do you have a specific link where I can read this response, because this is not at all the responses I have read. reply jiggawatts 8 hours agorootparentJust some random Cargo security-related issues I noticed:- No strong link between the repo and the published code.- Many crates were spammed that were just a wrapper around a popular C&#x2F;C++ library. There&#x27;s no indication of this, so... \"surprise!\"... your compiled app is now more unsafe C&#x2F;C++ code than Rust.- Extensive name squatting, to the point that virtual no library uses the obvious name, because someone else got to it first. The aformentioned C&#x2F;C++ libraries were easy to spit out, so they often grabbed the name before a Rust rewrite could be completed and published. So you now go to Cargo to find a Rust library for &#x27;X&#x27; and you instead have to use &#x27;X-rs&#x27; because... ha-ha, it&#x27;s actually a C&#x2F;C++ package manager with some Rust crates in there also.- Transitive dependencies aren&#x27;t shown in the web page.- No enforcement or indication of safe&#x2F;unsafe libs, nostd, etc...- No requirement for MFA, which was a successful attack vector on multiple package managers in the past.DISCLAIMER: Some of the above may have been resolved since I last looked. Other package managers also do these things (but that&#x27;s not a good thing).In my opinion, any package manager that just lets any random person upload \"whatever\" is outright dangerous and useless to the larger ecosystem of developers in a hurry who don&#x27;t have the time to vet every single transitive dependency every month.Package managers need to grow up and start requiring a direct reference to a specific Git commit -- that they store themselves -- and compile from scratch with an instrumented compiler that spits out metadata such as \"connects to the Internet, did you know?\" or \"is actually 99% C++ code, by the way\". reply bjourne 8 hours agorootparentSure, but all the drawbacks you enumerate are also advantages for gaining critical mass. A free-for-all package repository is attractive to early adopters because they can become the ones to plug the obvious holes in the standard library. Having N developers each trying to make THE datetime&#x2F;logging&#x2F;webframework&#x2F;parsing library for Rust is good for gaining traction. You end up with a lot of bad packages with good names though. reply rat87 3 hours agorootparentprev> Extensive name squatting, to the point that virtual no library uses the obvious name, because someone else got to it first.Maybe the obvious names should have been pre banned. But I don&#x27;t see the issue with non-obvious names either way you&#x27;re going to have to get community recommendation&#x2F;popularity to determine ifbrandonq&#x2F;xml is better or worse then parsers&#x2F;xml reply jiggawatts 3 hours agorootparentIn ASP.NET land, I regularly work on projects where there is an informal rule that only Microsoft-published packages can be used, unless there&#x27;s good reason.You don&#x27;t want to be using Ivan Vladimir&#x27;s OAUTH package to sign in to Microsoft Entra ID. That probably has an FSB backdoor ready to activate. Why use that, when there&#x27;s an equivalent Microsoft package?When any random Chinese, Russian, or Israeli national can publish \"microsoftauth\", you just know that some idiot will use it. That idiot may be me. Or a coworker. Or a transitive dependency. Or a transitive dependency introduced after a critical update to the immediate dependency. Or an external EXE tool deployed as a part of a third-party ISV binary product. Or...Make the only path lead to the pit of success, because the alternative is to let people wander around and fall into the pit of failure. reply Fluorescence 30 minutes agorootparentfwiw but when I saw a 3rd party library pretty much exactly like \"microsoftauth\" on nuget, I reported it and it was swiftly removed.I think we need to encourage a culture that package managers are our shared garden and we must all help in the weeding. replyselcuka 10 hours agorootparentprev> I&#x27;m having a hard time thinking of a non-Java package manager that was around at the time Rust came out that didn&#x27;t have a single, global namespace.Technically not in the same category, but Docker Hub (2014) had namespaces. reply thirdplace_ 10 hours agorootparentprevphp&#x27;s composer[0] in 2012 had package namespaces[0] https:&#x2F;&#x2F;getcomposer.org&#x2F; reply lolinder 10 hours agorootparentSorta—it looks like they were mostly just using that system by convention until May 2015, when they finally become enforced [0]. Still, that&#x27;s a good one that I hadn&#x27;t thought of, and they at least had the convention in place.[0] https:&#x2F;&#x2F;github.com&#x2F;composer&#x2F;packagist&#x2F;issues&#x2F;163#issuecommen... reply jmyeet 9 hours agorootparentprevI&#x27;m honestly astounded at how badly many languages have implemented dependency management, particularly when Java basically got this right almost 20 years ago (Maven) and others have made the mistakes that Java fixed. With Maven you get:1. Flexible version (of requirements) specification;2. Yes, source code had domain names in packages but that came from Java and you can technically separate that in the dependency declaration;3. You can run local repos, which is useful for corporate environments so you can deploy your own internal packages; and4. Source could be included or not, as desired.Yes, it was XML and verbose. Gradle basically fixed that if you really cared (personally, I didn&#x27;t).Later comes along Go. No dependency management at the start. There ended up being two ways of specifying dependencies. At least one included putting github.io&#x2F;username&#x2F;package into your code. That username changes and all your code has to change. Awful design.At least domains forced basically agreed upon namespacing. reply beautron 7 hours agorootparent> Later comes along Go. No dependency management at the start. There ended up being two ways of specifying dependencies. At least one included putting github.io&#x2F;username&#x2F;package into your code. That username changes and all your code has to change. Awful design.\"github.io&#x2F;username&#x2F;package\" is using a domain name, just like Java. Changing the username part is like changing the domain name--I don&#x27;t see how this is any worse in Go than in Java.If you don&#x27;t like that there&#x27;s a username in there, then don&#x27;t put one in there to begin with. Requiring a username has nothing to do with Go vs. Java, but rather is because the package&#x27;s canonical location is hosted on Github (which requires a username).I don&#x27;t know why so many programmer&#x27;s use a domain they don&#x27;t control as the official home of their projects--it seems silly to me (especially for bigger, more serious projects). reply PhilipRoman 1 hour agorootparentNote that in Java it is merely a convention to use domain names as packages. There is no technical requirement to do so. So moving to a different domain has no impact whatsoever on dependency resolution. Many people use non-existent domain names.To be honest I really like how Java advocated for verbose namespaces. Library authors have this awful idea that their library is a special little snowflake that deserves the shortest name possible, like \"http\" or \"math\" (or \"_\"...). reply devman0 6 hours agorootparentprevSlight difference is that it wouldn&#x27;t break existing builds if you changed namespaces in Java. The maven central repo does not allow packages to be rescinded once they are published.So that old version of package xyz will still resolve in your tagged build years from now even if the project rebrands&#x2F;changes namespaces. reply marcus_holmes 6 hours agorootparentprev> I don&#x27;t know why so many programmer&#x27;s use a domain they don&#x27;t control as the official home of their projectsNot only that, but a commercial, for-profit domain that actively reads all the code stored on it to train an AI. Owned and run by one of the worst opponents of the OS community in the history of computing.At least move to Gitlab if you must store your project on someone else&#x27;s domain. reply cgh 9 hours agorootparentprevYes, #3 in particular is important for many large corps where one team develops a library that may be pulled in by literally thousands of other developers. reply WatchDog 9 hours agoparentprevMaven and Java really don’t get enough credit for how well it’s dependency management works.So many inferior dependency management systems for other languages have come along later, and learned nothing from those that came before it. reply pjmlp 3 hours agorootparentAnd NuGET, which was inspired on them. reply tootie 7 hours agorootparentprev100% agree. It&#x27;s unbelievable what a PITA it is dealing with pip or npm compared to Maven even 10 years ago. The descriptors could get convoluted but you could also edit them in an IDE that knew the expected tokens to make things happen. reply symlinkk 7 hours agorootparentWhat’s so hard about “npm install” and “package.json”. It’s dead simple reply FridgeSeal 5 hours agorootparentNo you see Java devs have stockholm-syndromed themselves into believe that a giant stack of XML, or some unhinged mini-language are actually good, and much better than something the humans involved can actually read and parse easily and now to compensate with other ecosystems providing 85% of the functionality, with 5% of the pain, they’ve got to find some reason to complain about them. reply dingi 4 hours agorootparentwhat&#x27;s wrong with XML? Maven XML is a configuration not a programming language. reply xtremegoose 38 minutes agorootparentIs this a joke? XML is horrible to work with, more boilerplate than information. Compare your average maven file to a cargo.toml and tell me which is easier to work with... replybaby 9 hours agorootparentprevIs this a joke? reply speed_spread 7 hours agorootparentHaving tried Java and other languages, no, it&#x27;s not a joke. Other than XML Maven got a lot of things right. reply chii 6 hours agorootparentand i dont particularly think that using xml is that bad. The schema is well defined, and gives you good autocompletion in any competent IDE (such as intellij).It took some iterations before maven 3 became \"good\", so people forget that it wasn&#x27;t as nice before now! Unfortunately, it seems that the lessons learned there is never really disseminated to other ecosystems - perhaps due to prejudice against \"enterprisey\" java. Yet, these package managers are now facing the sorts of problems solved in java. reply kitd 3 hours agorootparentprevAnd you don&#x27;t even need to use XML with Polyglot Mavenhttps:&#x2F;&#x2F;github.com&#x2F;takari&#x2F;polyglot-maven reply bsder 8 hours agorootparentprevNot even remotely a joke.The inverse-style domain name thing does a really good job of removing the whole issue of squatting from the ecosystem. You have to demonstrate some level of commitment and identity through control of a domain name in order to publish.I would also say that this puts just enough friction so that people don&#x27;t publish dogshit.crates.io demonstrates quite clearly that you either have to go all the way and take responsibility for curation or you have to get completely out of the way. There is no inbetween. reply theendisney2 9 hours agorootparentprevI think the correct approach is to do full-real-name_good-package-name it might not be practical but it would be legendary. reply jrockway 10 hours agoparentprevURLs for packages makes a lot of sense. It works well in the land of Go. It also conveniently eliminates the need for the language to have a global packages database. Upload your package to example.com&#x2F;your-thing and it&#x27;s released! (You can, of course, still offer a cache and search engine if you want to.) reply swatcoder 10 hours agorootparentNo, URL&#x27;s don&#x27;t make sense because your application shouldn&#x27;t care where on the internet your dependency happened to be hosted when you integrated it. It&#x27;s location has nothing to do with what it is.By the time you&#x27;re going to production, your vetted and locked dependency should be living in your own cache&#x2F;mirror&#x2F;vendored-repo&#x2F;whatever so that you know exactly what code you built your project around and know exactly what the availability will be when you build&#x2F;instantiate your project.Your project shouldn&#x27;t need to care whether GitHub fell out of fashion and the project moved to GitLab, and definitely shouldn&#x27;t be relying on GitHub being available when you need to build, test, deploy, or scale. That&#x27;s a completely unnecessary failure point for you to introduce.Systems that use URL-identified packages can work around some of this, but just reinforce terrible habits. reply kitd 15 minutes agorootparentYou can use the `replace` option in the Go mod file to redirect your dependency references elsewhere if you need to. reply andiareso 9 hours agorootparentprevIsn’t that why GOPROXY exists though? Not sure why you would need an internet connection. URLs don’t necessarily equate to the internet. Our internal and external packages are all locally hosted and work regardless of the internet being available. reply taberiand 9 hours agorootparentprevURLs are well structured and unique, with a sensible default - sourcing the file from the internet - and ubiquitous processes for easily mapping the URL to an alternative location.I.e., when you&#x27;re going to run the production build, the URLs are mapped to fetch from the vetted cache and not the internet.I don&#x27;t see any downsides to allowing them as a source, or making them the default approach reply ants_everywhere 8 hours agorootparent> and ubiquitous processes for easily mapping the URL to an alternative location.This seems strange to me because the whole point of a Uniform Resource Locator is to specify where a resource can be located.It&#x27;s a bit like saying \"My project depends on the binder on shelf 7 in Room 42, sixth binder from the left. Except when I go into production, then use....\" Don&#x27;t tell me what binder it&#x27;s in, tell me what it is.I can see a case made for URIs, which is basically what Java did. reply devman0 6 hours agorootparentThis was a big annoyance for me back in the day when I was dealing with XML namespaces. URLs never made sense for that use case and too many tools tried to pull XSDs from the literal URL which was always generally out of date, some projects switch to URIs like tag uris or URNs and it was much better, imo. reply jowea 9 hours agorootparentprevIsn&#x27;t that just delegating the problem? URL dependencies do not replace what crates.io does, and a modern language will still want something like it. You&#x27;d just end up with most every dependency being declared as crates.io&#x2F;foo. reply kevincox 9 hours agorootparentprevURLs form a nice global namespacing system. But yes, I agree that it should be possible to actually get the source from anywhere.Basically the URL of a package name should be primarily the ID, not the locator (even if it is used for location by default). reply jrockway 9 hours agorootparentprevIt worked for the rest of the Internet. reply ethbr1 9 hours agorootparentThere is something to be said for separating {unique piece of content} and {hosted location}.E.g. doi&#x27;s https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Digital_object_identifier reply awesome_dude 9 hours agorootparentprev> By the time you&#x27;re going to production, your vetted and locked dependency should be living in your own cache&#x2F;mirror&#x2F;vendored-repo&#x2F;whatever so that you know exactly what code you built your project around and know exactly what the availability will be when you build&#x2F;instantiate your project.In the Go world this would be \"vendored\" dependencies, that is, the dependencies are within your source tree, and your CICD can build to its hearts content with no care in the world about the internet because it has the deps.The URL is useful for determining which version of a specific project is being used - \"Oh we switched to the one hosted on gitlab because the github one went stale\"The advantage of using gitlab, or github, or whatever public code repository is that you get to piggy back off their naming policies which ensure uniqueness.But, at the same time, there&#x27;s no reason that the repo being referred to cannot be in house (bob.local) or private.Having said all of that, the Go module system is a massive improvement on what they did have originally (nothing) and the 3rd party attempts to solve the problem (dep, glide, and the prototype for modules, vgo), but it&#x27;s not without its edge cases. reply jeroenhd 9 hours agorootparentprevYou can, though. From a random Cargo package I have downloaded to my computer: [dependencies] uniffi = { git = \"https:&#x2F;&#x2F;github.com&#x2F;mozilla&#x2F;uniffi-rs\" }You can also specify revision&#x2F;branch&#x2F;etc.Alternatively, you can do: [registries] maven = { index = \"https:&#x2F;&#x2F;rust.maven.org&#x2F;git&#x2F;index\" } [dependencies] some-package = { index = \"maven\", version = \"1.1\" }Obviously Maven doesn&#x27;t host any Rust crates (yet?), this is just a theoretical example. Very few projects bother to host their own registry, partially because crates.io doesn&#x27;t allow packages that load dependencies from other indices (for obvious security reasons). The registry definition can also be done globally through environment variables: CARGO_REGISTRIES_MAVEN=\"https:&#x2F;&#x2F;rust.maven.org&#x2F;git&#x2F;index\". Furthermore, the default registry can be set in a global config file.In theory, all you need to do is publish a crate is to `git push upstream master`, and your package will become available on https:&#x2F;&#x2F;github.com&#x2F;username&#x2F;crate-name (or example.com&#x2F;your-package if you choose to host your git repo on there).Personally, I don&#x27;t like using other people&#x27;s URL packages, because your website can disappear any moment for any reason. Maybe you decide to call it quits, maybe you get hit by a car, whatever the reason, my build is broken all of the sudden. The probability of crates.io going down is a lot lower than the probability of packages-of-some-random-guy-in-nebraska.ddns.net disappearing reply estebank 10 hours agorootparentprevIt doesn&#x27;t help with the failure mode of dependencies disappearing, which forces people that care about it to vendor, which in turn brings its own set of issues. reply alpaca128 10 hours agorootparentprevCargo does support URLs to git repos for dependencies. But crates.io is the official platform and almost every search I do on it returns at least one generically named entry with an empty repository that someone snatched away and never used. reply corytheboyd 8 hours agoparentprevI don’t work with rust on the regular, but this is so annoying with package repositories in general. No don’t use http-server, it’s bad, instead you have to use MuffinTop, it’s better. And then you just have to know that. The concept of sanctioned package names would be interesting, but probably chaotic in practice as the underlying code behind this sort of alias changes over time. This will remain a part of being a domain expert in any given ecosystem forever I think, hooray! reply ReactiveJelly 3 hours agorootparent(You probably agree with me but I&#x27;m going to just write one big comment instead of replying to every slightly incorrect comment in the thread)Naming things really is one of the hardest problems. This crates thing is a special case of Zooko&#x27;s Triangle: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Zooko%27s_triangleCrates.io names are human-meaningful and everyone sees the same names, but it&#x27;s vulnerable to squatting, spamming, and Sybil attacks.You could tie a name to a public key, like onion addresses do, but it&#x27;s unwieldy for humans. (NB, nothing stops you from doing this inside of crates.io if you really wanted)You could use pet names where \"http-server\" and \"http-client\" locally map to \"hyper\" and \"reqwest\", but nobody likes those, because they don&#x27;t solve the bootstrap problem.It&#x27;s a problem with all repos because when you say \"http-server should simply be the best server that everyone likes right now\", you have to decide who is the authority of \"best\", and \"everyone\", and \"now\". Don&#x27;t forget how much useless crap is left in the Python stdlib marked as \"don&#x27;t use this as of 2018, use the 3rd-party lib that does it way better.\"So yeah... probably will be a problem forever. As a bit of fun here are some un-intuitive names, and my proposed improvements:- Rename Apache to \"http-server\"- Rename Nginx to \"http-server-2\"- Rename Caddy to \"http-server-2-golang\"- Rename libcurl to \"http-client\"- Rename GTK+ to \"linux-gui\"- Rename Qt to \"linux-gui-2\"- Rename xfce4 to \"linux-desktop-3\"Then you only need to remember which numbers are good and which numbers are bad! Like how IPv4 is the best, IPv6 is okay, but IPV5 isn&#x27;t real, and HTTP 1.1 and 3 are great but 2 kinda sucked.Very simple. If a company as big as Apple can have simple names like \"WebKit\", \"CoreGraphics\", and \"CoreAudio\" then surely a million hackers competing in a free marketplace can do the same thing. reply Conscat 5 hours agorootparentprevI think if you get three to five developers who are enthusiastic about X language, their collective knowledge will select good packages. reply pjmlp 3 hours agoparentprevWhile Java made that notation famous, it was already used in NeXTSTEP and Objective-C, hence why you will see this all over the place in macOS and derived platforms, on configuration files and services. reply lifthrasiir 4 hours agoparentprevI don&#x27;t think a lack of namespace is that much problem. Sure, it is often annoying, but people are creative enough to create a short enough and still available crate name for most cases. Namespacing only makes sense for a large group of related crates---and it wouldn&#x27;t give much benefit over a flat namespace.As other mentioned though, a typosquatting is a much bigger problem and namespacing offers only a partial solution. (You can still create a lookalike organization name, both in npm and in Github.) reply rat87 3 hours agorootparentId argue typesquatting a namespace is arguably easier then type squatting a package name since you will often ignore the namespace name reply SCLeo 9 hours agoparentprevIf you have a namespace, can&#x27;t people just globally-claim namespaces instead? like serde&#x2F;serde or something similar. I feel if you really don&#x27;t want people claim whatever they want, you have to do the Java package style where namespaces are tied to domain names. reply throwawaaarrgh 5 hours agoparentprevCPAN has the best model IMHO. Hierarchy that starts with categories. You build on top of the base stuff and extend it, rather than reinvent&#x2F;fork something with a random name. Result is a lot more improvement and reuse, and more functionality with less duplication. Plus it&#x27;s easy to find stuff.Perl&#x27;s whole ecosystem is amazing compared to other languages. It&#x27;s a shame nobody knows it. reply rochak 10 hours agoparentprevGo made a great decision to namespace packages via this Github style. reply treyd 10 hours agorootparentAnd the horrible decision to not make library-level (\"module\") and code-unit-level (\"package\") namespacing orthogonal. The former was an afterthought tacked on since the package system was designed to be used only within Google&#x27;s monorepo and little care was paid to how it would work when it was released to the public and used more generally. reply starttoaster 10 hours agorootparentI want to understand what you just said, but I fear watering your language down a bit might be a tall ask with some people. Would you be willing to eli5 what you believe Go did that was a horrible decision with regards to module&#x2F;package namespacing? reply cdelsolar 9 hours agorootparentI think he wants them to be treated differently for some reason. reply baby 9 hours agorootparentprevHow is this a good decision? You have to alias packages when names collide reply tapirl 6 hours agorootparentWhat is the better decision to avoid name colliding? reply yarg 10 hours agoparentprevThis needs to be resolved by every damned language. Just make signed dependencies a universal default, point to an https page for the package vendor and use the signing key from there.Neither node nor maven ever bothered to solve this, so we end up wandering the Wild West wondering when it will be that HR, or legal, or architecture comes knocking on the door to ask what we were thinking having a dependency on a dynamic version of Left Pad.I&#x27;d kinda like to see what Cloudflare and Let&#x27;s Encrypt could come up with if they worked together on at very least a white paper and an MVP POC. reply lesuorac 10 hours agorootparentI don&#x27;t think that&#x27;s the real solution.Pay somebody either internally or externally to maintain a repo of all your dependencies and point your code at that. You won&#x27;t get a left-pad incident. You won&#x27;t get a malicious .so incident (unless you mirror binaries instead of source code).Like if you ran out of screws to make your product with do you walk around the street and scrounge up some? No, you go to a trusted vendor and buy the screws. reply yarg 10 hours agorootparentI&#x27;m not suggesting scrounging.I&#x27;m suggesting that the guys who&#x27;ve repeatedly proven themselves technically competent around security at scale might have a couple of useful ideas regarding how the industry might go about crawling its way out of this little security clusterfuck.And perhaps even stop treating something as simple as a BOM as an enterprise feature, given that the overhead on such things is damned near zilch and the security implications are staggering.https:&#x2F;&#x2F;www.cisa.gov&#x2F;sbom reply cmrdporcupine 5 hours agorootparentprevThere&#x27;s reasons why Google projects don&#x27;t go out on the internet to get their 3rd party deps.They&#x27;re all checked into Google3 (or chromium, etc.). One version only. With internal maintainers responsible for bringing it in and multiple people vetting it, and clear ownership over its management. E.g. you don&#x27;t just get to willy nilly depend on a new version -- if you want to upgrade what&#x27;s there, you gotta put a ring on it. If you upgrade it, you&#x27;re likely going to be upgrading it for everyone, and the build system will run through the dependent tests for them all, etc.And the consequence is more responsible use of third party deps and less sprawling dependency trees and less complexity.And additional less security concerns as the code is checked in, its license vetted, and build systems are hunting around on the Internet for artifacts. reply lmm 8 hours agorootparentprevMaven has signing and you can check the signatures on your dependencies if you care to. Most don&#x27;t, sadly. reply spullara 10 hours agorootparentprevTo be fair, all the dependencies in the maven central repository require a signature to publish them. reply yarg 10 hours agorootparentThat&#x27;s a workaround.I&#x27;m not a fan of those - if the engine&#x27;s in the wrong place, then why the hell did you fucking put it there?Don&#x27;t hack a patch into place to stop people from holding it wrong; design it in such a way that it&#x27;s impossible to hold wrong in the first place. reply dhosek 10 hours agoparentprevAgreed. The other thing I don’t really like is that you can’t split up things in the rust namespace hierarchy between crates (something that’s natural with jars in JVM). I would have liked to have defined things so that I could have the unicode handlers for finl live in finl::unicode, the parser in finl::parser, etc. but because they’re in separate crates rust gets upset about finl being defined twice and there’s no workaround for it. There are likely pitfalls I don’t see in what I want, so I live with it. reply ramranch 10 hours agorootparentWould re-exporting partially solve your problem? reply dhosek 6 hours agorootparentAs I recall, I could do something where I could have a common root crate that would import and re-export the other crates with the namespaces modified on the exports and then control which crates are exported through feature gates, but it just seemed more hassle than it was worth. reply satvikpendem 1 hour agoparentprevI like that there are no namespaces, it forces people to come up with unique names rather than naming their calendar crate to be `calendar`. reply thayne 7 hours agoparentprev> Some of these globally-claimed generic packages are not really the best package to use.Or it is just a placeholder from a squatter. reply baby 9 hours agoparentprevI love this lack of namespacing personally, because it means that whatever crate you see in a project is going to be the same as the crate your see in another one. Never need to alias crate names. It happens in Golang all the time and I really think namespacing packages was a mistake there. reply lolinder 9 hours agorootparentGolang&#x27;s problems aren&#x27;t due to using namespaces, they&#x27;re due to delaying too many decisions until too late.Go has namespacing mostly because for a long time it didn&#x27;t have a package manager at all, so people just used a bunch of ad hoc URL-based solutions mostly revolving around GitHub, which happens to have namespaces and also happened to lend itself to aliasing (because a whole GitHub URL is too long).If you want to look at an actual example of namespacing done well, Maven&#x2F;Java is the place to look. There is no aliasing—the same imports always work across projects. reply Grimburger 9 hours agoparentprevYet to see any proof that namespacing has made things better in other ecosystems, are go style links or other types of namespaced imports any less prone to supply chain risks?It&#x27;s definitely a good thing that people choose new unique names for crates rather than dijan&#x2F;base64 vs dljan&#x2F;base64Do understand the desire of having a crate for audio manipulation called \"audio\" but at the same time how often do we end up with \"audio2\" anyway? It&#x27;s an imperfect solution for an imperfect world and I personally think the crates team got it right on this one. reply chungy 7 hours agorootparent> Yet to see any proof that namespacing has made things better in other ecosystemsIt&#x27;s really as simple as this: many libraries are generic enough implementing something that already exists. Let&#x27;s say you want a library to manage the SMTP protocol. On crates.io, of course someone has already taken the \"smtp\" crate (ironically, this one is abandoned, but has the highest download counts, because it&#x27;s the most obvious name). Let&#x27;s say you disagree with the direction this smtp crate has gone, and you make your own. What do you call it?Namespaces solve this problem. You&#x27;d instead of have user1&#x2F;smtp and user2&#x2F;smtp competing in feature sets. You can even be user3&#x2F;smtp if you don&#x27;t like the first two.This is precisely what Java enables too. The standard library is in com.java.*; if you don&#x27;t like how the standard library does something, you can make com.grimburger.smtp and do it yourself. If you choose to publish to the world, all the more power to you. It doesn&#x27;t conflict with the standard library&#x27;s smtp implementation. reply Jalad 10 hours agoparentprevThis is a common critique, and although I don&#x27;t have insight into why the original decision to not have namespaces was made, the current outlook is that until issues related to continuity are resolved, it&#x27;s a no go:https:&#x2F;&#x2F;samsieber.tech&#x2F;posts&#x2F;2020&#x2F;09&#x2F;registry-structure-infl... reply sigwinch28 10 hours agorootparentThat article starts with the premise that “it’s a feature, not a bug” then goes on to describe a whole bunch of things I consider to be anti-features of a packaging system that has a flat namespace.The first section says it discourages forking. I consider this to be bad. Nobody’s code should be more important purely because it squatted a better name.The Identity section actually makes the case that flat registries make naming harder.The section on Continuity is “we’ve tried nothing and we’re all out of ideas”. Make up an org name and grandfather all packages in the flat namespace into that special org. Also this is already a problem because packages in the flat namespace do get abandoned, then forked, and then we have the associated issues.The section on Stability seems to take it as a given that crates.io should be the only registry. I don’t. It also seems to conflate cargo with rustc for the benefit of the argument.The squatting section describes only anti-features and I don’t consider the author’s legitimate use cases to be legitimate reasons to squat.I think the only legitimate problems that need addressing are the ergonomics of accessing namespaced packages throughout transient dependencies and backwards compatibility with non-namespaced code. But the fact that these are real problems does not, to me, make a flat namespace a “feature”. It’s just easier to implement.It’s okay for it to be a mistake that takes effort and time to fix. reply kevincox 9 hours agorootparentAnother option would be to grandfather all packages into their own org. So serde becomes serde&#x2F;serde. This way you don&#x27;t need to manage permission rules in the legacy \"all\" namespace.You get some oddities such as serde-derive&#x2F;serde-derive but the package owners can choose if they want to move to serde&#x2F;derive or leave it in a separate namespace. reply rat87 3 hours agoparentprevI don&#x27;t see the problem. Even with namespaces you&#x27;ll havebrandonq&#x2F;xml vs parsers&#x2F;xml with no clue if one is better then another.Also possibly with some confusion over whether things with the same name are forks or not. May make it a little more difficult to Google. Why not just have brandon_xml vs xml-parser and have a community list of best and most popular libraries?I guess the only issue is that some generic&#x2F;obvious package names are bad packages. That can have been avoided if they banned&#x2F;self-squated most of the names. I suppose if you use dns namespaces and actually tie it to ownership of the domain name it might make sense but that would also cause issues(what if you forgot to renew the domain?). reply xtremegoose 35 minutes agorootparentThe advantage is one of trust. If the `abc` developers build well known library `abc.pqr` are well trusted then I know I can use `abc.xyz` and everything else under the same namespace without (much) vetting.We could even have `rust.xyz` for crates that are decoupled from `std` but still maintained by rust core devs such as `regex`. reply cetra3 10 hours agoparentprevI think most people are in support of namespacing but it&#x27;s a big change and will take a while to see through. reply q8840 2 hours agoprevI&#x27;m glad to see there&#x27;s a wide range of opinions here.I&#x27;m not too concerned with performance or safety (since my code hasn&#x27;t been seen very often).I use rust just because it has a lot of \"libraries that help me develop\".While other language libraries have a poor search experience and ranking system, Rust has a great library search system.I use it because I don&#x27;t have to read blog posts like C&#x2F;C++ or java to find libraries that help me develop, or wade through unnecessary libraries like C# or go, I can use the rankings, and it has a good documentation system. reply nlnn 1 hour agoparentThis has mostly been my experience too. I like using Rust because it reduces the cognitive load I have to deal with for many things (performance&#x2F;safety are nice, but not a priority).As you&#x27;ve said, finding great libraries is easy, and so is adding&#x2F;building them. I find this a nice change from e.g. Python (where there are so many way of different competing ways dealing with packaging&#x2F;dependencies).Also thanks to the error handling, sum types and the like, I don&#x27;t have to worry so much that I&#x27;ve deal with all errors, handled all enum variants, etc., the compiler takes care of that. reply veber-alex 10 hours agoprev> It also looks like (soon) you’ll finally be able to configure global lints for a project. Until now, you had to hack your solution to keep lints consistent for projects.> I questioned my sanity every time I circled back around to the Clippy issue above. Surely, I was wrong. There must be a configuration I missed. I couldn’t believe it. I still can’t. Surely there must be a way to configure lints globally. I quadruple-checked when I wrote this to make sure I wasn’t delusional.You create a .cargo&#x2F;config.toml in the workspace root so it covers all your crates.inside the file: [build] rustflags = [\"-Wclippy::lint_name_to_warn\", \"-Dclippy::lint_name_to_deny\"]The only limitation is that rustflags are not additive, so if you have other sources of rustflags like the RUSTFLAGS environment variable it will overwrite this setting. reply mplanchard 7 hours agoparentWe just have a script that adds the lints to any lib.rs or main.rs files that runs on commit. ezpz reply Animats 2 hours agoprevSome days I have misgivings, but not about the language. About the crate situation. Too many important low-level crates stuck at 0.x. I&#x27;ve previously written about problems with the high-performance 3D graphics libraries, but only game devs care about those.At the language level, the big problem is back references. Sometimes you do need them, and the only safe way to do them at present involves reference counts in the forward direction and weak references in the back direction. Then you have to call .borrow() and .upgrade() too much. I&#x27;d love to see a static analysis solution to that.(Rough outline of such a solution: Owning object belongs to Owner trait. Owned object belongs to Owned trait. Owned object has .owner() and .owner_mut() functions which retrieve references to the owner. Owners probably have to be pinned, so they can&#x27;t move while a back-reference exists. If an Owner changes a reference to an Owned object, the back reference is automatically updated.That&#x27;s the easy part. Now figure out how to prove by static analysis that a specific use of this does not violate Rust&#x27;s no-aliasing rules (N read-only, or 1 mutable). This looks do-able for the non-mutable case, because having a non-mutable reference to both owned and owner is OK. Mutability, though, is tough. Anybody thinking about this?) reply Asraelite 2 hours agoparent> Now figure out how to prove by static analysis that a specific use of this does not violate Rust&#x27;s no-aliasing rules (N read-only, or 1 mutable).Out of curiosity, is there any existing language (including research languages) that can do this already? reply cratermoon 2 hours agoparentprev> Too many important low-level crates stuck at 0.x.Is it fair to say that Rust failed to supply a robust set of standard libraries comparable to other modern languages? Or was the language aimed at level geared towards implementing rather than providing libraries? If it&#x27;s truly a systems language, then what library features are essential, and what are &#x27;nice to have&#x27;? reply nindalf 2 hours agorootparentThere was a conscious decision to avoid providing a vast standard library because those inevitably become outdated with time. Building a standard library is relatively easy, maintaining for decades is hard.But it’s a trade off because there are concrete upsides to a large standard library. I wrote about this more - Rust has a small standard library (and that’s ok) - https:&#x2F;&#x2F;blog.nindalf.com&#x2F;posts&#x2F;rust-stdlib&#x2F; reply carlmr 2 hours agorootparentprevIMHO a lot of these 0.x libraries would be called 3.. In other languages S.They often have better quality than what I find in \"mature\" packages in npm or PyPi.Rust kind of has a perfectionist touch to it which makes it really hard to say \"this public API is stable\". So people stay at 0.. way longer than normal.I&#x27;m fine with that.The lack of namespacing and heavy namesquatting is rather what&#x27;s annoying. reply sunshowers 10 hours agoprevProgramming in Rust is really not like being in an abusive relationship. The compiler is trying to help out as much as possible, especially since rustc has the best error messages in the world. reply Tade0 3 minutes agoparentRust&#x27;s compiler is the first one I&#x27;ve seen to use the word perhaps.My main gripe is that I still don&#x27;t fully comprehend lifetimes and the compiler can&#x27;t really help me every time, because it (understandably) errs on the side of caution. reply emporas 9 hours agoparentprevThe OSes want programmers to handle resources correctly, and the Rust compiler makes that task a breeze. We are in a more abusive relationship with our OSes, than the Rust compiler. How about the hardware? Doesn&#x27;t that need to run assembly in a correct way? That counts as an abusive relationship as well.Rust&#x27;s error messages are one of a kind. There no other compiler which comes even close.As a side note, i used latex lately, it&#x27;s error messages are horrendous. What a nightmare to figure out what&#x27;s wrong by inspecting the error. reply Aerbil313 2 hours agorootparentRustc is so good I learnt a lot about the language by just reading errors. reply CGamesPlay 7 hours agoparentprev> The compiler is trying to help out as much as possible, especially since rustc has the best error messages in the world.Generally good, but man do I hate how any error in my async function causes every recursive call site to generate an error about how the Future is no longer Send and Sync. Literally an entire console scrollback of errors with the actual syntax error buried somewhere in the middle. reply estebank 6 hours agorootparentI believe this is in our radar and waiting on the new trait solver, but just in case if you have a repro I would appreciate a ticket to improve the diagnostic. reply CGamesPlay 1 hour agorootparenthttps:&#x2F;&#x2F;play.rust-lang.org&#x2F;?version=stable&mode=debug&editio...In this case, the first two errors are clear. The next 3 provide multiple, redundant context blocks. The upshot is that this simple example results in rustc printing 11 lines of useful error messages and 86 lines of useless messages. Add to that the fact that the useful error messages need not be at the top or bottom of the error list, they can be anywhere inside of it, depending on the declaration order. reply tantalor 10 hours agoprev> I started writing tests in Rust as I would in any other language but found that I was writing tests couldn’t fail.This is a common refrain in C++ testing: if it compiles then it&#x27;s probably correct.> Rust has accounted for so many errors that many common test cases become irrelevantIn practice, if you think this way I think it&#x27;s a sign that you aren&#x27;t testing the right things in those other languages. You should be testing business logic, not language stuff.If you look at your test code and think \"I would test this in JavaScript, but I don&#x27;t need to do that in Rust\" then just delete the test. reply adastra22 10 hours agoparent> This is a common refrain in C++ testing: if it compiles then it&#x27;s probably correct.I’ve heard this in Haskell and in Rust. I’ve never heard it applied to C++… reply jeremyjh 7 hours agorootparentI’ve definitely experienced it in Haskell and Rust. I can believe some C++ could be that way, but I’ve never experienced it, but then again those projects didn’t have useful tests either. I think with C++ a lot of this depends on domain and the quality of the code and libraries. reply xhainingx 5 hours agorootparentprevIt&#x27;s truer in C++ than java or similar languages ime since java relies more on exceptions, but it&#x27;s certainly not as true as Haskell or rust reply Skunkleton 5 hours agorootparentIs it true enough in c++ to be useful though? reply ModernMech 10 hours agorootparentprevI think they meant Rust? Rust definitely has that property to an extent; C++ is so far from it it’s not even funny. reply Sharlin 9 hours agoparentprevA null pointer exception is a bug that breaks business logic. There&#x27;s no \"business logic instead of language stuff\" because the language stuff is the foundation that business logic rests on. If you don&#x27;t test against failure modes, what&#x27;s even the point in testing? reply rightbyte 17 minutes agorootparentA null pointer exception is a free runtime check. I really don&#x27;t understand the fuss about null. The \"most expansive design mistake in computer science\" and whatever. reply maxbond 9 hours agorootparentprevTo close the loop, Rust doesn&#x27;t include a `null` type and you wouldn&#x27;t encounter something comparable in idiomatic Rust (because you&#x27;d be using eg Option::map to handle None cases gracefully), so this is a class of test that would be common in Java and C that is close to irrelevant in Rust. reply tialaramex 8 hours agorootparentTo be more specific, Rust does have among other things:std::ptr::null() - an actual null pointer, probably the zero address on your hardware, and this isn&#x27;t even an unsafe function. On the other hand, you won&#x27;t find many uses for a null pointer so, I mean, congrats on obtaining one and good luck with that.std::ptr::null_mut() - a mutable null pointer, similarly unlikely to be of any use to you in safe Rust, but also not an unsafe thing to ask for.But, these are pointers, so they&#x27;re not values that say, a String could take, or a Vec or whatever, only actual raw pointers can be null. reply pornel 8 hours agorootparentAnd even for raw pointers you can use NonNull. reply tialaramex 9 hours agoparentprevThere is surely something wonderful about the kind of C++ programmer who figures that, since their unusable broken garbage compiled it&#x27;s probably correct.Remember unlike most languages you&#x27;d be familiar with C++ has IFNDR, which has been jokingly referred to as \"False positives for the question: Is this a C++ program?\". A conforming C++ compiler is forbidden from telling you in some† unknown number of cases that it suspects what you&#x27;ve written is nonsense, it just has to press on and output... something. Is it a working executable? Could be. Or maybe it&#x27;s exactly like a working executable except it explodes catastrophically on Fridays. No way to know.† The ISO standard does identify these cases, but they&#x27;re so vague that it&#x27;s hard to pin down everything which is covered. My guess is that all or most non-trivial C++ software is actually IFNDR these days. Just say No to the entire language. reply lmm 8 hours agorootparent> A conforming C++ compiler is forbidden from telling you in some† unknown number of cases that it suspects what you&#x27;ve written is nonsense, it just has to press on and output... something.It&#x27;s not quite that bad - a conforming C++ compiler is permitted to error out and not compile the program. It just doesn&#x27;t have to. reply _gabe_ 8 hours agorootparentprevCan you give an example of non-C++ code that a modern compiler (MSVC, clang, g++ or something) successfully compiles with no diagnostics? I’m genuinely curious. If not, this just sounds like more C++ FUD because the spec doesn’t define everything under the sun and allows a certain amount of leeway to compilers for things like emitting different error diagnostics. reply LegionMammal978 5 hours agorootparentConsider: #define _FOO int main() {}Per the C++ standard ([lex.name]&#x2F;3), this program is ill-formed:> In addition, some identifiers appearing as a token or preprocessing-token are reserved for use by C++ implementations and shall not be used otherwise; no diagnostic is required. [...] Each identifier that contains a double underscore __ or begins with an underscore followed by an uppercase letter is reserved to the implementation for any use.Thus, the compiler theoretically has the liberty to emit whatever it wants for this program.Neither GCC nor Clang produces a warning under -std=c++20 -Wall -Wextra (Clang only produces a -Wreserved-macro-identifier under -Weverything), and MSVC doesn&#x27;t produce a warning under &#x2F;std:c++20 &#x2F;Wall.In practice, most examples of ill-formed programs where compilers issue no warnings occur with discrepancies between different source files that are linked together; e.g., declaring a function as inline in one file but non-inline in another, or declaring a function with two different sets of default arguments in different files, or defining the same non-inline variable or function in different files, or defining the same inline function differently in different files. reply211 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The author expresses their experience using Rust for web development over a three-year period, highlighting its strong type system, borrow checker, and integrated testing framework.",
      "However, Rust's downsides are also mentioned, such as gaps in functionality, limitations in library enhancement, project structuring challenges, and issues with executing asynchronous code.",
      "The author concludes that despite Rust's valuable features, it might not be ideal for projects requiring swift iteration due to certain hurdles and its suitability for projects where an upfront cost can be accommodated."
    ],
    "commentSummary": [
      "The discourse examines a variety of programming language subjects, including Rust's productivity and effectiveness, managing cyclic references, and the contrast between Python and Rust.",
      "The conversation addresses the ecosystem, libraries of different languages, Rust's package manager's absence of namespaces, and security concerns pertaining to the Cargo package manager.",
      "It incorporates the pros and cons of various package management systems, dependency use, package naming, namespacing issues in Go, debate on namespaces in Rust's package registry, and the benefits and drawbacks of Rust's small standard library, along with the capacity of C++ compilers to produce error diagnostics."
    ],
    "points": 329,
    "commentCount": 464,
    "retryCount": 0,
    "time": 1698273426
  },
  {
    "id": 38012662,
    "title": "Web components will outlive JavaScript frameworks",
    "originLink": "https://jakelazaroff.com/words/web-components-will-outlive-your-javascript-framework/",
    "originBody": "jake lazaroff blog projects Web Components Will Outlive Your JavaScript Framework October 25, 2023 #javascript #react #recurse #svelte #webcomponents If you’re anything like me, when you’re starting a project, there’s a paralyzing period of indecision while you try to figure out how to build it. In the JavaScript world, that usually boils down to picking a framework. Do you go with Ol’ Reliable, a.k.a. React? Something slimmer and trendier, like Svelte or Solid? How about kicking it old school with a server-side framework and HTMX? When I was writing my CRDT blog post series, I knew I wanted to include interactive demos to illustrate the concepts. Here’s an example: a toy collaborative pixel art editor. Even though I’ve written before — and still believe — that React is a good default option, the constraints of a project should determine the technology decisions. In this case, I chose to use vanilla JS web components. I want to talk about why. There was one guiding principle for this project: although they happened to be built with HTML, CSS and JS, these examples were content, not code. In other words, they’d be handled more or less the same as any image or video I would include in my blog posts. They should be portable to any place in which I can render HTML. As of 2023, this blog is built with Astro. Before that, it was built with my own static site generator. Before that, Hugo; before that, a custom CMS written in PHP; before that, Tumblr, Movable Type and WordPress — and I’m sure I’m missing some in between. I really like Astro, but it’s reasonable to assume that this website won’t run on it forever. One thing that has made these migrations easier in recent years is keeping all my content in plain text files written in Markdown. Rather than dealing with the invariably convoluted process of moving my content between systems — exporting it from one, importing it into another, fixing any incompatibilities, maybe removing some things that I can’t find a way to port over — I drop my Markdown files into the new website and it mostly Just Works. Most website generators have a way to include more complex markup within your content, and Astro is no different. The MDX integration allows you to render Astro components within your Markdown files. Those components have access to all the niceties of the Astro build system: you can write HTML, CSS and JS within one file, and Astro will automagically extract and optimize everything for you. It will scope CSS selectors and compile TypeScript and let you conditionally render markup and do all sorts of other fancy stuff. The drawback, of course, is that it all only works inside Astro. In order to switch to a different site generator, I’d have to rewrite those components. I might need to split up the HTML, CSS and JS, or configure a new build system, or find a new way to scope styles. So Astro-specific features were off limits — no matter how convenient. But Markdown has a secret weapon: you can write HTML inside of it! That means any fancy interactive diagrams I wanted to add would be just as portable as my the rest of my Markdown as long as I could express them as plain HTML tags. Web components hit that nail square on the head. They’re a set of W3C standards for building reusable HTML elements. You use them by writing a class for a custom element, registering a tag name and using it in your markup. Here’s how I embedded that pixel art editor before:That’s the honest-to-goodness HTML I have in the Markdown for this post. That’s it! There’s no special setup; I don’t have to remember to put specific elements on the page before calling a function or load a bunch of extra resources.1 Of course, I do need to keep the JS files around and link to them with a tag. But that goes for any media: there needs to be some way to reference it from within textual content. With web components, once the script is loaded, the tag name gets registered and works anywhere on the page — even if the markup is present before the JavaScript runs. Web components encapsulate all their HTML, CSS and JS within a single file, with no build system necessary. Having all the code for a component in one place significantly reduces my mental overhead, and I continue to be a huge fan of single-file components for their developer experience. While web components aren’t quite as nice to write as their Astro or Svelte counterparts, they’re still super convenient.2 In case you’re not familiar with web components, here’s the code for thatcomponent above:3 import PixelEditor from \"./PixelEditor.js\"; class PixelArtDemo extends HTMLElement { constructor() { super(); this.shadow = this.attachShadow({ mode: \"closed\" }); this.render(); const resolution = Number(this.getAttribute(\"resolution\")) || 100; const size = { w: resolution, h: resolution }; const alice = new PixelEditor(this.shadow.querySelector(\"#alice\"), size); const bob = new PixelEditor(this.shadow.querySelector(\"#bob\"), size); alice.debug = bob.debug = this.hasAttribute(\"debug\"); } render() { this.shadow.innerHTML = ` .wrapper { display: grid; grid-template-columns: 1fr 1fr; grid-template-rows: 1fr auto; gap: 1rem; margin: 2rem 0 3rem; } .canvas { grid-row: 1; width: 100%; aspect-ratio: 1 / 1; border: 0.25rem solid #eeeeee; border-radius: 0.25rem; cursor: crosshair; } .color { grid-column: 1 / span 2; }`; } } customElements.define(\"pixelart-demo\", PixelArtDemo); Everything is nicely contained within this one file. There is that one import at the top, but it’s an ES module import — it doesn’t rely on any sort of build system. As long as I keep all the files together, the browser will sort everything out. Another nice thing about Web components is shadow DOM, which isolates the component from the surrounding page. I think shadow DOM is often awkward when you want to share styles between your components and the rest of your app, but it’s perfect when you do truly want everything to be isolated. Just like images and videos, these components will look and act the same no matter where they’re used. Sorry — they’re not just like images and videos. Web components can expose attributes that allow you to configure them from the outside. You can think of them as native props. Voilà: Two input ranges with different accent colors. In this case, I’m just setting a CSS variable, which is one of the few things allowed into the shadow DOM:Here’s a more complex example: And here’s the markup. It uses attributes to alter the component’s behavior, setting the resolution to 20 and showing debug information on every pixel:If you were wondering what those calls to getAttribute and hasAttribute were doing in the web component class, now you know. This was particularly useful when reusing the same component for different stages of a tutorial, allowing me to enable certain features as the tutorial progressed. The other part of the equation was using vanilla JS. There are frameworks that compile to web components — most notably Lit (although I’d call it more of a library) but also Stencil, Svelte, and probably others. I’m sure they’re all wonderful tools that would have made my life easier in a lot of ways. But frameworks are dependencies, and dependencies have a bunch of tradeoffs. In this case, the tradeoff I’m most worried about is maintenance.4 That goes for TypeScript, too. By my count, the last 15 versions of TypeScript have had breaking changes — many of them new features that I was happy to have, even though I had to change my code to accommodate them. But as much as I love TypeScript, it’s not a native substrate of the web. It’s still a dependency. There’s a cost to using dependencies. New versions are released, APIs change, and it takes time and effort to make sure your own code remains compatible with them. And the cost accumulates over time. It would be one thing if I planned to continually work on this code; it’s usually simple enough to migrate from one version of a depenency to the next. But I’m not planning to ever really touch this code again unless I absolutely need to. And if I do ever need to touch this code, I really don’t want to go through multiple years’ worth of updates all at once. I learned that lesson the hard way when I built my online museum, wiping the cobwebs off of code saved on laptops that hadn’t been turned on in a full decade. The more dependencies a website had, the more difficult it was to restore. I’ve been building on the web for almost 20 years. That’s long enough to witness the birth, rise and fall of jQuery. Node.js was created, forked into io.js and merged back into Node. Backbone burst onto the scene and was quickly replaced with AngularJS, which was replaced with React, which has been around for only half that time and has still gone through like five different ways to write components. But as the ecosystem around it swirled, the web platform itself remained remarkably stable — largely because the stewards of the standards painstakingly ensured that no new change would break existing websites.5 The original Space Jam website from 1996 is famously still up, and renders perfectly in modern browsers. So does the first version of the website you’re reading now, made when I was a freshman in college 15 years ago. Hell, the first website ever created — built closer to the formation of the Beatles 6 than to today! — still works, in all its barebones hypertext glory. If we want that sort of longevity, we need to avoid dependencies that we don’t control and stick to standards that we know won’t break. If we want our work to be accessible in five or ten or even 20 years, we need to use the web with no layers in between. For all its warts, the web has become the most resilient, portable, future-proof computing platform we’ve ever created — at least, if we build with that in mind. Like what you read? Subscribe to my RSS feed, or follow me on Mastodon or Twitter. Want to become a better programmer? Join the Recurse Center!",
    "commentLink": "https://news.ycombinator.com/item?id=38012662",
    "commentBody": "Web components will outlive JavaScript frameworksHacker NewspastloginWeb components will outlive JavaScript frameworks (jakelazaroff.com) 281 points by cdme 20 hours ago| hidepastfavorite217 comments recursivedoubts 19 hours agojust because htmx (which is a library, not a framework) was mentioned, I&#x27;m going to respond to some stuff in the articlefirst and foremost, the article doesn&#x27;t talk about synchronizing state w&#x2F;a server, which is what htmx is focuses on (via hypermedia exchanges), so htmx is orthogonal to WebComponents in this regard> There’s a cost to using dependencies. New versions are released, APIs change, and it takes time and effort to make sure your own code remains compatible with them.This is why htmx is dependency-free and focuses intensely on backwards compatibility (e.g. it is IE11 compatible). intercooler.js, which was htmx 1.0 and has one dependency, jQuery, was released in 2013 and is still supported. A lot of other javascript libraries have a culture of API rewrites and difficult upgrades, but htmx is explicitly not like that and shouldn&#x27;t be heaped into that general culture. In htmx 2.0, our only breaking change is likely to be dropping IE support.Will web components outlive htmx? Well, they are part of the browser, so presumably yes. But, insofar as I can help it, htmx should be very stable and churn free going forward. The API is basically correct (yes, w&#x2F; a few warts and mistakes) and I see no need to rewrite everything for the sake of purity or sexiness.And, most importantly, htmx answers a different question than Web Components: how should I synchronize state w&#x2F; the server. reply jakelazaroff 19 hours agoparentAuthor here — I’ll remove that sentence since it looks like it’s being received in a way I didn’t intend. Sorry about that! I actually mentioned on Twitter [1] that web components are a natural fit for hypermedia-friendly scripting as described in your essay [2] (which I like a lot).[1] https:&#x2F;&#x2F;x.com&#x2F;jlazaroff&#x2F;status&#x2F;1717176726248108469[2] https:&#x2F;&#x2F;htmx.org&#x2F;essays&#x2F;hypermedia-friendly-scripting&#x2F; reply recursivedoubts 18 hours agorootparentWell, I think that the article (and sentence) is correctly pointing out an issue w&#x2F;many JS frameworks, I just don&#x27;t think it applies to htmx necessarily. I don&#x27;t mind you keeping it up and having a debate around the topic: in as much as htmx does cause upgrade pain that&#x27;s a burden of using it that deserves to be called out.I don&#x27;t think you need to change the article, I just want to give my perspective as the author of htmx. It isn&#x27;t realistic to expect everyone to write perfectly precise articles at all times, especially when the htmx reference in the article isn&#x27;t a focus (likely included just because you kinda like htmx :) reply al_potato 18 hours agoparentprevWe&#x27;re replacing React with Htmx at work (about a year into it) and have found WebComponents to be very useful to re-use some of the React components that we want to preserve and treat a bit like using native browser widgets (input, select, textarea). Specifically, a WebComponent lets you hook into the lifecycle of a DOM element that is being modified by the outside world (morphdom via Htmx). In the event of attributes changing, you want to tell the React component about that. And in the event of the node being removed from the DOM, you want to tell React to run its cleanup procedures. I think that we weren&#x27;t able to do this in a clean, efficient way without WebComponents.The end result is that we can stick to Htmx&#x27;s way of doing things, i.e. keeping all business logic state on the server, and only a few conservative things are client-side (such as currently focused element, text being typed in an input, things like that). Every step we take towards this, it offers a much better user experience with fewer bugs and race conditions, so it&#x27;s worth the effort. reply recursivedoubts 17 hours agorootparentthat&#x27;s great to hear and confirms my intuition that web components and htmx would go very well together reply synergy20 14 hours agorootparentprevwhat about alpine.js, seems great to me and more natural(not mixing html and js behind the scene like some black magic)both are really for SSR applications, a modern jQuery to some extent. For CSR(client side rendering), you still have to use react&#x2F;vue&#x2F;mithril&#x2F;etc reply rprenger 17 hours agoparentprevI kind of hoped the long term result of htmx, instead of just being a Javascript library, was to become a standard in a newer version of HTML itself. The constraints of only forms being able to do POSTs, and the only way to handle the response is to rewrite the entire page seems arbitrarily limiting. If htmx were just HTML6 or whatever, it&#x27;d outlive all the Javascript frameworks. reply candiddevmike 17 hours agorootparentYou&#x27;d have to merge JavaScript and HTML to get htmx in any usage capacity. HTML is not a programming language, it&#x27;s a markup language. reply recursivedoubts 16 hours agorootparentI have thrown together a minimalist extension to HTML that I think captures the core ideas of htmx, although you are right that there are still some outstanding issues that probably need additional thinking to make it widely useful:https:&#x2F;&#x2F;gist.github.com&#x2F;1cg&#x2F;d1ad1ddd5f43a8a993cd9f711135edc9Here is an example button using these proposed extensions to HTMLThis is an example button hypermedia controlreply flir 15 hours agorootparentI&#x27;d vote for being able to put an href attribute on any element (egand ), and maybe binningentirely. That seems like such an obvious enhancement to me, I figure there&#x27;s probably a deep reason it hasn&#x27;t been done. reply candiddevmike 16 hours agorootparentprevSo you want to inline JavaScript, similar to CSS and the `style` attribute? reply recursivedoubts 16 hours agorootparentI would prefer something more like what htmx has in hx-trigger:https:&#x2F;&#x2F;htmx.org&#x2F;attributes&#x2F;hx-trigger&#x2F;w&#x2F; an explicit and declarative syntax, but that attribute is fairly involvedthis was a brief exercise in thinking about the minimal changes necessary to HTML to support something like htmx, and unfortunately there isn&#x27;t any attribute that maps to hx-trigger in the same way there is for other htmx attributes, so I resorted to the on* attributes + generalizing the submit() function on forms. reply Spivak 12 hours agorootparentprevYes and no. You wouldn&#x27;t call ainlining JS while it does come with some degree of interaction. It would be an expansion of HTML to include a few new things to (ideally) enable a wider rage of lightly-interactive websites to be HTML only. reply mjburgess 16 hours agorootparentprevaccording to the people who write standards, but not the people who write browsers reply GenerocUsername 17 hours agorootparentprevI think this is still possible.It took a decade for JQuery to be nearly completely absorbed by browser standards. reply candiddevmike 17 hours agorootparentFor the most part, jQuery was absorbed into ES&#x2F;JavaScript, not HTML. reply jitl 16 hours agorootparentThe most visible part of jQuery for me was always querying selectors - $(&#x27;.some > a.selector&#x27;); and that certainly was something integrated into HTML&#x2F;the DOM as document.querySelectorAll(&#x27;.some > a.selector&#x27;). reply nkozyra 17 hours agorootparentprevWell yeah, that&#x27;s still under \"browser standards.\" reply weo3dev 16 hours agorootparentThe difference is that the internet can exist (and did) quite well without JavaScript. Without HTML there is no internet. Furthermore, ECMAScript is a language and W3C&#x2F;WHATWG are a consortium that maintain HTML. reply Gud 16 hours agorootparentSorry to nitpick, but there is a lot more to the internet than the web. reply troupo 4 hours agorootparentprevAnd the browser APIs still have significantly worse ergonomics than jQuery reply buildbot 16 hours agorootparentprevI literally just started with htmx, but can’t you override both of those behaviors? hx- on the form will switch the verb it uses, and you can swap outerhtml, innerhtml, or some other css target?Or am I incorrect? reply fwip 16 hours agorootparentI think you&#x27;ve slightly misread - they specified only forms can do POSTs, not that forms can do only POSTs. (Also, they&#x27;re talking about vanilla HTML, not HTMX). reply buildbot 14 hours agorootparentOh I did not catch that … oops reply meiraleal 15 hours agorootparentprev> The constraints of only forms being able to do POSTsHTML elements shouldn&#x27;t do POSTs, that&#x27;s why JavaScript exists.andare elements that do HTTP requests but the same can be added to any other html or custom element. html integration with JS doesn&#x27;t need another layer. reply johnmaguire 18 hours agoparentprev> But, insofar as I can help it, htmx should be very stable and churn free going forward. The API is basically correct (yes, w&#x2F; a few warts and mistakes) and I see no need to rewrite everything for the sake of purity or sexiness.This is awesome to hear. I&#x27;ve been eyeing htmx a bit lately for some pet projects, but as a primarily backend-focused engineer, most JS libraries I import tend to be a large maintenance burden moving forward, with major API changes happening regularly.I&#x27;ll definitely take htmx out for a spin. reply infecto 17 hours agorootparentI have been using HTMX a lot and would highly recommend it as a backend engineer.Historically I have constantly had an issue following JS frameworks and more importantly their build processes. Too much mental overhead when the majority of things I am building don&#x27;t really benefit from a SPA style. I started my journey using Backbone.js a decade ago and enjoyed the relatively simple apis. Everything that came after for me has been a nightmare. Finally with HTMX I am in the groove and able to easily build what I want in a pattern that I enjoy. reply pseudosavant 18 hours agoparentprevI&#x27;ve been wanting to rewrite a side project SPA using htmx. I&#x27;ve never been that interested in Web Components, but it is an intriguing idea to use with htmx. It&#x27;d certainly make generating the HTML fragments server-side less complex to template.On a side note about htmx. Really compelling concept, I wish there was a larger community around it. Chicken and the egg kind of a problem, but there just aren&#x27;t a lot of resources (blog posts, videos, etc) compared to many other web frameworks. Basic stuff like how do integrate something like Auth0 auth into an htmx app. reply traverseda 17 hours agorootparentThere is no \"htmx app\". You&#x27;d search for how to include auth0 in, say, a django app. reply pseudosavant 15 hours agorootparentIt seems like examples are usually oriented around specific popular SPA frameworks (e.g. React) or focused on an existing server side rendered app that you are adding interactivity into. I understand extending server-side way. The kind of stuff I used to do with jQuery back in the day adding interactivity into otherwise SSR pages.In a world of either SPAs or SSRs, htmx straddles the two. That is what makes it so interesting and unique, but it is also a different enough model to not always cleanly map from my pre-existing skills&#x2F;patterns.For the app I&#x27;m doing, I&#x27;d really prefer to keep it an SPA. In that the URL never changes, and there is never a full page reload (outside of OIDC&#x2F;sign-in). I&#x27;m sure I can get there, I just need to think about the architecture a bit.I&#x27;m kind of obsessive in this app about loading the app being nearly instant (I personally use it countless times a day). I really love the idea of returning back a full rendered page of HTML that wouldn&#x27;t require any other API calls before showing the content.The current stack (which I hate, but it works, I wrote it, and so who am I going to blame?) - is PHP&#x2F;MySQL. My concept for something that will be lower maintenance going forward (keeping up on PHP versions...ugh.) is to use Deno + oak + SQLite (running in Deno using WASM) on the server to render HTML fragments&#x2F;pages, and htmx on the front end. With no build step and no database server to maintain. reply infecto 17 hours agorootparentprevThe community is relatively large but I understand what you are saying.I think really all you need to do is start using it. The HTMX api is minimal but powerful. At the end of the day you are requesting chunks of html that replace existing sections in your html.You are building an HTML driven app so your auth workflow is going to be whatever HTML can handle. reply candiddevmike 17 hours agorootparentprevIf your SPA is written in Typescript, you&#x27;re going to throw away a lot of safety checks moving to htmx. reply hudon 15 hours agorootparentA move from SPA means business logic moves to the backend and becomes hypermedia-driven, so the correct comparison if you want to think about type safety is if the backend server is type-safe. htmx is mostly declarative and its correct use could be statically checked with basic tools--it&#x27;s not meant to contain complex logic. reply jjcm 18 hours agoprevI wrote all of non.io with vanilla webcomponents - it&#x27;s a full SPA built on them. A few learnings I&#x27;ll share with going beyond just a simple nested blog component:State management is still unanswered. You&#x27;ll end up having to do a lot of this yourself if you aren&#x27;t using a wrapper framework. One nice thing about React is state management is mostly solved and there are existing patterns for it. There&#x27;s expectations of how it&#x27;s done. With web components it&#x27;s the wild west, and since you can&#x27;t pass complex objects as attributes like you can in jsx, you end up doing a mix of attributes, events, and calling class functions directly.Performance isn&#x27;t as big of a win as I&#x27;d have hoped. I actually reverted some smaller atomic elements (i.e. icons) away from being web components as their instantiation cost wasn&#x27;t worth it when I had hundreds of these elements on the page. Static elements, despite the readability they provide in code (i.e. ), just aren&#x27;t worth using web components for, which was fairly disappointing.That said, there are things I REALLY enjoy about web components. As the author shared, it&#x27;s incredibly easy to add a component to new pages, regardless of the framework being used. If something is built using web components, you can truly use it anywhere. This has been really nice when building supporting sites like api docs for nonio, where I can easily pick and choose what components I want despite having a different stack. Need to embed acomponent? Import the js, add the html, you&#x27;re golden.Style encapsulation of shadowroots is quite nice. I really love not having to worry about breaking styling of any component as I work on a page. It means less guesses and checks of clobbering styling of other elements, and less of a need for a visual diff framework to ensure this hasn&#x27;t happened.The other aspect I enjoy is how slim the package sizes are. No libraries or anything extra to load, everything is baked in. Because you can pick and choose components you need so easily as well, it&#x27;s incredibly easy to keep package sizes down.If anyone is curious, source components for nonio are here: https:&#x2F;&#x2F;github.com&#x2F;jjcm&#x2F;nonio-frontend&#x2F;tree&#x2F;master&#x2F;component... reply mdhb 17 hours agoparentRegarding the point you mentioned about not being able to pass objects via attributes, you can however pass them via properties on the element.Also as for the state management side of things there is nothing at all stopping you from hooking up whatever state management solution you want. I’ve even seen a bunch of solutions that use the browsers built in event model as well if keeping dependencies to a minimum is your goal.Finally, the last thing I would suggest is that writing an entire app in vanilla web components is kind of crazy talk in my opinion. For 5kb you can have a super nice developer experience using Lit (https:&#x2F;&#x2F;lit.dev) reply jjcm 16 hours agorootparent> Finally, the last thing I would suggest is that writing an entire app in vanilla web components is kind of crazy talk in my opinion. For 5kb you can have a super nice developer experience using Lit (https:&#x2F;&#x2F;lit.dev)I 100% agree with this. For me it was more of a question of \"can I do it\", and that was something I wanted to find out. You notice that I ended up having to recreate a significant chunk of lit-like functionality on my own via a base class: https:&#x2F;&#x2F;github.com&#x2F;jjcm&#x2F;nonio-frontend&#x2F;blob&#x2F;master&#x2F;component...I would very much recommend not going full vanilla. Using a library like lit will definitely help making things easier&#x2F;more polished, and will integrate better with existing tooling. reply claytongulick 15 hours agorootparentprev> writing an entire app in vanilla web components is kind of crazy talk in my opinionWhy?I&#x27;ve done many.My guiding principles:- Avoid shadow dom unless it&#x27;s a library. Stick with the light DOM and css system of your choice.- Use lit-html or similar for rendering- Use class properties for reactivity (add a render() call to setters, as needed)- Ignore attributes entirely. Just use properties.- Don&#x27;t bother with composable components and slots. You generally don&#x27;t need them- Use a nice router like vaadin or ionic or similar to hoist components and support deep linking- Let components maintain their own state. Structure the dom so that it&#x27;s easy to grab state from a component with querySelector. If this doesn&#x27;t work, I have a little state lib called ApplicationState[1] that works great.- Really think about what needs to be a component vs normal html. Don&#x27;t overdo it with components.- Structure the app with high level \"scene\" components that map to URL deep links, and app components that you use to build the scenes. Scenes are targets of the router.I&#x27;ve been doing this for years for many apps for many clients. Blazing fast, simple, no framework churn, no compilation, no framework download or overhead...It&#x27;s pretty tough to make myself use a framework at this point.[1] https:&#x2F;&#x2F;claytongulick.github.io&#x2F;applicationstate&#x2F; reply mdhb 14 hours agorootparentI didn’t suggest for a moment you couldn’t. I said it was a bit of a crazy decision to take.The entire reason I said that was because there is going to come a time after you have built probably your 5th component where you are going to start moving a whole bunch of shared logic into a base class that extends HTMLElement and that is the point you should probably stop and just bring in Lit at around 5kb total because they already did exactly what you’re doing and they almost certainly have done a better job with a bigger team and access to browser engineers with thousands of existing users and a bigger test suite with better documentation and well.. you get the point.A lot of your argument seems to be quite focused on the idea that frameworks are some heavy weight thing which is perfectly true in many cases. But other options exist, and with a 5kb-10kb library download budget those arguments don’t carry a lot of weight. reply claytongulick 14 hours agorootparent> after you have built probably your 5th component where you are going to start moving a whole bunch of shared logic into a base class that extends HTMLElementI kind of thought this too at first, and started down that path several times. I actually wrote a whole framework similar to Lit early on, thinking the same thing.What I&#x27;ve found over time, is 99% of that is YAGNI (You ain&#x27;t gonna need it).All my components just extend HTMLElement directly.I explicitly dislike Lit because you lose control over the component lifecycle. I don&#x27;t find it easier, I find it harder - especially when you&#x27;re mixing in pure js libraries like draggable or whatever.I prefer having to call render() explicitly, and controlling when&#x2F;how that&#x27;s done. At the end of the day, it&#x27;s not actually any more code.> a better job with a bigger team and access to browser engineers with thousands of existing users and a bigger test suiteYeah, I don&#x27;t need all that to show some interactive markup on the screen and organize code well. That&#x27;s really what WC&#x27;s are for me - just a convenient unit of encapsulation for vanilla JS&#x2F;DOM stuff.Lit is cool, so&#x27;s stencil. I just don&#x27;t need it.lit-html, however, is probably my favorite piece of tech in the last 5 years. I&#x27;ve been using it since it was originally created and was only like 200 lines of code.All that code I wrote is still working great, and hasn&#x27;t needed any sort of update. On the other hand, if I&#x27;d gone with the Web Components Framework Of The Day, I&#x27;d have done Polymer and caused a massive headache for my clients.Many people were making the exact same arguments you were about Polymer back then.And then LitElement.And then Lit.Lit 2.0.Now Lit 3.0.Same story with .Angular 1.5 anyone?Framework churn can kill a company.I code to standards, keep it as vanilla as possible, and prefer libraries over frameworks (though sometimes the lines get blurry there - looking at you Ionic). reply mdhb 12 hours agorootparentWhat churn are you referring to?I’m quoting directly from here: https:&#x2F;&#x2F;lit.dev&#x2F;docs&#x2F;v3&#x2F;releases&#x2F;upgrade&#x2F;“For the *vast majority* of users there should be no required code changes to upgrade from Lit 2 to Lit 3. Most apps and libraries should be able to extend their npm version ranges to include both 2.x and 3.x, like \"^2.7.0 || ^3.0.0\".“And here is v1 to v2 for completeness sake: https:&#x2F;&#x2F;lit.dev&#x2F;docs&#x2F;v2&#x2F;releases&#x2F;upgrade&#x2F;Most of your examples are kind of odd. One of them was a brand change that involves no code at all.There is only one meaningful bit of churn in there which also was an overlay of the Web Platform itself.Polymer was a WebComponentsv0 libraryLit is a WebComponentsv1 library. reply claytongulick 7 hours agorootparent> What churn are you referring to?I think most developers are very familiar with the framework churn that I&#x27;m referring to.In my case, I&#x27;ve been dealing with it since the 90s.So my biases are there for a reason. reply troupo 4 hours agorootparentprev\"vast majority of users\", \"should be able to extend\".What are the cases when this easy no code upgrade fails?And yes, v2 update is quite a breaking change> Polymer was a WebComponentsv0 libraryIt wasn&#x27;t. It got upgraded to v1 almost immediately replynicoburns 16 hours agoparentprev> Performance isn&#x27;t as big of a win as I&#x27;d have hoped.Is performance a win at all? I would expect performance to be worse than using a regular web framework (React, Vue, Svelte, etc). Because these tend to get their performance from batching DOM manipulations across the entire page, and you can&#x27;t do that will web components.I figure web components are pretty much dead in the water for this reason alone. I guess they can be useful if you just want small \"islands\" of functionality rather a fully client-rendered page. reply nevir 16 hours agorootparentThese days, batching DOM updates doesn&#x27;t give you as big of a win as it did in the past (browser tech has improved, browser engines do more batching under the covers, etc).Also web components tend to use more modern layers of the web stack (style isolation, shadow DOM, etc) - which allow the browser to perform more optimizations, as well. I think we&#x27;ll find that they become more performant over time. Also consider that some \"native\" html components are effectively implemented the same way as web components these days.Often you&#x27;ll find that React&#x2F;etc are perf hits (vs finely tuned components) because their declarative nature tends to lead to unnecessary work …which is totally fine 99% of the time, because the productivity win from that is HUGE. reply Joeri 16 hours agoparentprevDid you see the performance issues also on web components that didn’t use shadow dom? I noticed this performance wall as well, but I always put it down to shadow dom being heavy. Now I’m wondering if it is the instantiation itself that’s heavy.For state mgmt I have noticed the same problem and was thinking about trying to take a page out of desktop development’s playbook by having a window-level message bus that all components subscribe to and filter data from, and every state change being published on that message bus. reply mdhb 15 hours agorootparentShadowDOM is actually a big part of the reason where the perf comes from because the universe of what actually needs to be considered in order to get to the eventual answer of what style properties should any given element actually have is tiny due to the fact that it is encapsulated.That and the the other big win comes from using native compiled C++ browser code to implement large chunks of what libraries typically provide in userland JS.React is probably the worst offender here as it for all intents and purposes brings its own implementation of both DOM and events. It’s just an outdated architecture choice that made a huge amount of sense at the time but nobody would do that today if they were building a front end library from scratch.Finally regarding your point about the message bus idea you might want to take a look at the BroadcastChannel API if you aren’t already familiar with it. Sounds like it might be what you’re looking for. reply wg0 14 hours agorootparentBroadcast Channel API - unbelievable that it has such a wide support.Really amazing. Thank you for this. Didn&#x27;t know that.OP above or anyone else can say anything about routing in context of web components? Deep linking? Any pointers?Noob backend guy here. reply mdhb 14 hours agorootparentOne approach I don’t mind is to just make a HTML file per screen in the application and route like the rest of the web.When you bring in modern things like service workers and the prefetch API you can still very much keep the speed that is traditionally associated with SPAs.Otherwise I’ve seen good things said about both of these options:1. https:&#x2F;&#x2F;github.com&#x2F;vaadin&#x2F;router2. https:&#x2F;&#x2F;github.com&#x2F;lit&#x2F;lit&#x2F;tree&#x2F;main&#x2F;packages&#x2F;labs&#x2F;routerBoth follow the mental model of mapping a URL pattern to a component fairly intuitively. reply wg0 13 hours agorootparentOne file per screen is actually awesome. That&#x27;s the \"MPA\" many frameworks are boasting about.The big win here would be that if you have a huge app (let&#x27;s say an ERP kind of app that has too many screens and dialogs and what not) then that can be easily decomposed into separate pages that are far more manageable.You can easily wrap these pages up as Electron&#x2F;Tauri app or Capacitor etc for mobile.Deep linking however would be interesting in that if someone pastes a URL, we have to load the exact screen&#x2F;dialog etc. reply mdhb 12 hours agorootparentI like to keep a mental model that a page level component uses URL parameters the same way I would write a CLI application reads in arguments.Not at all meaningfully different from sayvoid main(List arguments) {runApp(MyApp(arguments));} replybreadwinner 15 hours agoparentprev> since you can&#x27;t pass complex objects as attributes like you can in jsxBut you can!Here&#x27;s an example of passing complex objects as attributes (look for zx-listeditor): https:&#x2F;&#x2F;github.com&#x2F;wisercoder&#x2F;uibuilder&#x2F;blob&#x2F;master&#x2F;WebCompo...And here&#x27;s the web component itself: https:&#x2F;&#x2F;github.com&#x2F;wisercoder&#x2F;uibuilder&#x2F;blob&#x2F;master&#x2F;WebCompo...And here&#x27;s the tiny (500-line) lib that enables it: https:&#x2F;&#x2F;github.com&#x2F;wisercoder&#x2F;uibuilder&#x2F;#jsx-for-web-compone... reply crooked-v 14 hours agorootparent\"You can pass complex objects using web components, if you also use something other than web components\" isn&#x27;t really all that much of a defense of web components. reply breadwinner 14 hours agorootparentIt is 223 lines of code: https:&#x2F;&#x2F;github.com&#x2F;wisercoder&#x2F;uibuilder&#x2F;blob&#x2F;master&#x2F;dist&#x2F;uib...You object to this tiny amount of code? reply skrebbel 14 hours agorootparentprevHow do you make this work with frameworks like Svelte which, when server side rendering, cast all props to string (!) attributes? reply breadwinner 13 hours agorootparentThat should be an easy bug fix in Svelte. reply akira2501 14 hours agoparentprev> With web components it&#x27;s the wild west, and since you can&#x27;t pass complex objects as attributes like you can in jsx, you end up doing a mix of attributes, events, and calling class functions directly.Or you just write a &#x27;value&#x27; getter and setter and be done with it. I write most of my web components to operate like a form component. Forms have state. Forms have mechanisms for gathering state from all components and saving them into a single object. Forms have a means of restoring all that state.You _barely_ need a layer of abstraction to handle all this. I&#x27;ve honestly never understood the \"state management problem\" or why anyone would think a framework is the way to solve it. reply gitaarik 56 minutes agoprevFrom the comments I see here, it seems like many people expect the Web Components API to be a complete replacement for a JS framework. The thing is, our frameworks should start making more use of modern web APIs, so the frameworks will have to do less heavy lifting themselves, so they can become smaller, so our projects are dependent on less framework code.Lit [0] for example is doing this. It&#x27;s a very small library, making use of the Web Components APIs. Using Lit is very similar to using React. Some things work different, and you have to get used to some web component specific things, but once you get it, I think it&#x27;s way more pleasant to work with than React. It feels more natural, native, less framework-specific.For state management, I created LitState [1], a tiny library (really only 258 lines), which integrates nicely with Lit, and which makes state management between multiple components very easy. It&#x27;s much easier than the Redux&#x2F;flux workflows found in React.So my experience with this is that it&#x27;s much nicer to work with, and that your total project size is much smaller.[0] https:&#x2F;&#x2F;lit.dev&#x2F;[1] https:&#x2F;&#x2F;github.com&#x2F;gitaarik&#x2F;lit-state reply onion2k 18 hours agoprevI don&#x27;t expect my preferred JS framework to remain the same though. I know that it&#x27;s short-lived. I like that. Moving forwards, making progress, and improving are why I use React, Vue, Svelte, etc. I don&#x27;t want something that&#x27;s static right now, because none of the available frameworks (including Web Components) solve problems particularly elegantly.If the argument is that a site made with Web Components will outlast a site built with a JS framework then I&#x27;d be tempted to take that bet. I honestly think it&#x27;s more likely that some part of the Web Components tech stack will be removed from Chrome, Safari, and Firefox in the next 20 years, consequently breaking apps built with them, than JavaScript will change in a way that means a React 16 app I wrote 2 years ago will break. reply ble 17 hours agoparent> I [...] think it&#x27;s more likely that some part of the Web Components tech stack will be removed from Chrome, Safari, and Firefox in the next 20 years, consequently breaking apps built with them, than JavaScript will change in a way that means a React 16 app I wrote 2 years ago will break.Hmm. I think you&#x27;ve specified a bet you are likely to win, but one that&#x27;s nearly meaningless. Perhaps if you fully lock down all dependency versions your React 16 app will not break, but that&#x27;s a little more like running an old program in a VM or an emulator than \"I can still work and hack on my React 16 app.\"A more meaningful bet would be, \"can you still develop on a React ZZZ app vs. can you still develop on an app built with web components.\"If I got to pick the terms of the bet (to favor my viewpoint XD but also to make it more meaningful), they&#x27;d be \"would updating a React app to catch up on N years of dependency updates be more or less effort than updating a web-components built app to catch up on N years of dependency updates\"; if you keep your web-components built app from having a bunch of weird dependencies, I think the odds are very much in favor of the React app taking more effort to update.Basically, betting on browser vendors to be less likely to break backwards compatibility than the authors of React. reply troupo 17 hours agoparentprev> I honestly think it&#x27;s more likely that some part of the Web Components tech stack will be removed from Chrome, Safari, and Firefox in the next 20 years, consequently breaking apps built with themThat already happened.HTML Imports got deprecated (in favor of a JS-only solution), though Firefox already implemented them.Custom Elements v0 was deprecated even though Chrome implemented it and hastily re-wrote Youtube with it. They had to wait ~4 years to remove the implementation because it took Youtube that much to switch. reply mdhb 17 hours agorootparentThe v0 part of it should mean none of that was a big surprise. It was an early prototype, it’s stable now. reply svieira 15 hours agorootparentv0 (IIRC) was not called v0 when it was released. It was called \"custom web components\". The release of a new version of custom web components is what caused the re-name to `v0`, with the new version being called `v1`. So you built on top of one version to be told later that you&#x27;d participated in a beta (unbeknownst to you). reply ble 9 hours agorootparenthmm. doesn&#x27;t stuff like this happen every time that chrome implements some interface but other browser vendors don&#x27;t get on board with that specific version? doesn&#x27;t this happen... kind of often? isn&#x27;t it apparent that there&#x27;s a risk of this happening whenever chrome implements something before there&#x27;s standards agreement? reply troupo 4 hours agorootparent> doesn&#x27;t stuff like this happen every time that chrome implements some interface but other browser vendors don&#x27;t get on board with that specific version?Yes. What rarely happens though is that Youtube gets immediately rewritten with the new tech. replynpteljes 16 hours agoprevI shifted my focus from technology to people. If I&#x27;m starting a new project, I&#x27;ll look at what the people who&#x27;ll work on the project know. If there&#x27;s a common denominator or best practice, like how React is nowadays for frontends, I&#x27;ll just go with that. I don&#x27;t really sweat these technical decisions, because the team composition, or the job seekers&#x27; market, or StackOverflow&#x27;s technology top list answers there questions with ease. reply josephg 15 hours agoparentI get that and I think it’s pragmatic. But if everyone thinks like you’re suggesting, we’ll all be using react forever, even if there are better answers out there for how to build our software. If you want to use whatever is popular, that means you depend on others to find good technology solutions and make them popular in order to improve your tech stack.Put another way, this strategy puts you firmly in the “mid to late adopter” part of the adoption curve. Articles like this (and indeed much of this discussion) is largely targeting people who are earlier adopters. reply pier25 18 hours agoprevYeah. The JS world is still so hung up about fat clients having all the control that it&#x27;s missing all the interesting stuff happening in the server world. Rails Hotwire, Phoenix Liveviews, Laravel Livewire, etc. These solutions can solve 80% of your front end with minimal JS and almost no DX complexity. reply toddmorey 17 hours agoparentIsn&#x27;t it possible that both the frontend and backend are maturing & more capable? Isn&#x27;t that what we want?I&#x27;ve built some feature-rich FE apps that read and write to dbs & object stores with no servers needed! Very portable, the only install step is to upload a few files. They can be run right from a simple CDN. And they are super fast.Most FE devs I know are actually familiar with Hotwire and friends but to them those stacks would add DX complexity. I think sometimes people say \"complexity\" when they just mean \"unfamiliar\". Both FE and BE can be way overly complex, but neither needs to be. reply pier25 11 hours agorootparent> I think sometimes people say \"complexity\" when they just mean \"unfamiliar\".I do mean actual complexity.With something like Hotwire&#x2F;Livewire you don&#x27;t need APIs anymore. You also can scrap client-side fetch() code and state management. There are some features that will still need some client JS but these will be a minority of use cases (if at all). reply metadaemon 18 hours agoparentprevComplexity has to exist somewhere, either in the engineer&#x27;s hands, or swept under the rug for the framework to perform its magic on (really thinking about the Rails ecosystem here). When things go wrong, it&#x27;s nicer, in my opinion, to have more control, especially in this fast paced clients-want-it-now environment. reply bob1029 17 hours agorootparentIn my experience, the complexity with most frontend development is accidental by way of splitting state between client & server.If you manage to consolidate nearly all state to the server, complexity reduces by an entire dimension. There is nothing to synchronize anymore. You don&#x27;t need these universes of delta-detection tools, frameworks, protocols, etc.In most of our modern SSR apps, the only state the client needs to hold onto is a session token. If we find the client has a wrong session token, correcting this is quite simple. Everything else happens on the server.Certainly there are holes with SSR (latency), but we haven&#x27;t run into a real-world scenario where this actually matters enough to introduce entire new universes of hell into our lives. reply pier25 17 hours agorootparentprev> especially in this fast paced clients-want-it-now environmentBut wouldn&#x27;t a solution that makes you more productive allow you to deliver faster?That&#x27;s what Livewire&#x2F;Hotwire&#x2F;etc are trying to achieve. Make developers more productive.When going full on SPA there&#x27;s so much complexity you need to solve. Crossing the client&#x2F;server barrier with APIs, managing state in the client, etc. reply toddmorey 17 hours agorootparentprevYes. Definitely been bit here with ORMs and custom query languages. reply worthless-trash 17 hours agorootparentprev> Complexity has to exist somewhere,What is the complexity you are talking about here, is this the human (programmers) understanding of the system or the design of a complex system itself ? reply candiddevmike 17 hours agoparentprevYou either write HTML in JavaScript or write JavaScript in HTML. Personally, I would rather write everything in JavaScript&#x2F;TypeScript than sprinkle syntactic sugar over HTML. reply pier25 17 hours agorootparentNo offense, but you&#x27;re thinking from the JS bubble.Yes, ultimately you need JS to interact with the DOM but if you look at eg Livewire the orchestration is in the server. I&#x27;d be happy to use a similar fullstack solution in JS&#x2F;TS but afaik it doesn&#x27;t exist. And it doesn&#x27;t exist because the JS world is still hung up on full on fat reactive clients which are overkill for the immense majority of use cases. reply tomjakubowski 17 hours agorootparentLiveview and similar frameworks are cool but not great for everything. It&#x27;s not easy to build an &#x27;offline first&#x27; application with it, for example reply pier25 17 hours agorootparentI agree. These solution are not meant to solve all the front end needs. But they can solve the majority of it (forms, modals with dynamic content, filtered lists, etc). reply 0xblinq 3 hours agorootparentprevNothing is great for everything. reply pixelsort 15 hours agorootparentprev> I&#x27;d be happy to use a similar fullstack solution in JS&#x2F;TS but afaik it doesn&#x27;t exist.If you mean, a fully TypeScript full stack solution then you might be correct. I wouldn&#x27;t know because I tried Deno earlier this year and it wasn&#x27;t great.If you mean, a full stack solution that utilizes TS to for both the API and for the frontend then that is a much easier find. Vercel&#x27;s Next.js provides this out-of-the-box and various other full stack starters and boilderplates exist.I recently built one using PgTyped and typescript-rest. reply BiteCode_dev 16 hours agorootparentprevIt&#x27;s not about writing the HTML, it&#x27;s about managing the state only in one place . reply klysm 17 hours agoparentprevIs it not just the same tradeoff space we&#x27;ve been exploring since the beginning of UIs about how thin the UI is? It&#x27;s not like putting stuff on the server side via livewire doesn&#x27;t have strong disadvantages around latency etc. reply pier25 17 hours agorootparent> It&#x27;s not like putting stuff on the server side via livewire doesn&#x27;t have strong disadvantages around latency etc.It&#x27;s exactly the same latency that a request to an API will have.Obviously Livewire is not a good option for interactivity that happens exclusively in the client. reply klysm 15 hours agorootparent> It&#x27;s exactly the same latency that a request to an API will have.Every interaction in a livewire type system requires a round trip - that&#x27;s not true for SPAs. Let&#x27;s say I&#x27;m developing a node based editing UI with drag and drop that lets me connect things. How on earth are you going to make that work with livewire? reply 0xblinq 2 hours agorootparent> Every interaction in a livewire type system requires a round tripYou’re wrong on this. You’d use Alpine and do the interactivity client side. If you don’t miss use the tool, Livewire is supposed to reach to the server in the same situations an SPA would reach to the server (updating or refreshing server state) reply pier25 11 hours agorootparentprevObviously Livewire wouldn&#x27;t be a good fit for that (extremely rare) use case. reply 0xblinq 1 hour agorootparentIn those cases you use alpine, and do the interactivity on the client side. replyTheCapeGreek 18 hours agoparentprevPreach!I&#x27;m still keen to learn more on the Inertia side of Laravel, but Livewire (and especially with Filament in the mix) just feels insanely productive as a Laravel dev. reply ng12 17 hours agoparentprevWhy do people keep hiring front-end specialists, in that case? reply pier25 17 hours agorootparentBecause front end specialists only think about the front end.The tide is slowly turning though with Next, SvelteKit, Remix, etc. But still these frameworks are basically just rendering HTML and going full on fat client which is overkill for 80% of interactivity in web app but adds a lot of unnecessary complexity. reply dboreham 17 hours agorootparentprevBecause a) they&#x27;re available and b) people think it&#x27;s a black art. reply evilduck 15 hours agorootparentc) backend devs often proudly hold contempt for front end work and do the job poorly reply esafak 15 hours agorootparentThey don&#x27;t want to get involved with tech that goes out of date every year. reply evilduck 12 hours agorootparentI love that trope honestly. It&#x27;s a great way to discover bad developers without having to test them first. replybastawhiz 19 hours agoprev> But Markdown has a secret weapon: you can write HTML inside of it! That means any fancy interactive diagrams I wanted to add would be just as portable as my the rest of my Markdown as long as I could express them as plain HTML tags.You can also use MDX and achieve exactly the same thing. Web components the technology don&#x27;t actually help here; what the author cares about is the interface between their markup and some piece of code that applies runtime functionality. Web components are an implementation detail here: whether you&#x27;re referencing a React component or an Astro thing or a web component when you type a name between some angle brackets, it really doesn&#x27;t matter: the point is that _some other thing_ is invoked.The downside to web components here is that they can only be run on the client, for all intents and purposes. There&#x27;s no way to pass server-rendered shadow dom content on the server to the client, so even if your web component is fully non-interactive, you still need JS on the client in order to render it. That&#x27;s not the case with other frameworks.I&#x27;ll say that the author&#x27;s point isn&#x27;t wrong: web components as a way to codify interfaces between chunks of code is quite possibly the best, most durable way to accomplish that goal. BUT! On the server, web components do you no favors. They don&#x27;t render, they are a cumbersome interface, and your code is already entirely written in a way that you can (hopefully!) work with. Which is to say, if you have Astro on the server, please keep using Astro! Or react, or vue, or whatever.Where web components shine is on the client, when you have a component from a third party that might not be written in your framework of choice. You don&#x27;t need to know about the framework the component you&#x27;re putting on the page was built with. You just use a HTML tag and it works. The mechanism of the interface is uplifted to the browser level, so you don&#x27;t need two frameworks to speak each others&#x27; implementation details. reply azangru 18 hours agoparent> The downside to web components here is that they can only be run on the client, for all intents and purposes. There&#x27;s no way to pass server-rendered shadow dom content on the server to the client, so even if your web component is fully non-interactive, you still need JS on the client in order to render it. That&#x27;s not the case with other frameworks.I thought you were going to argue that there is no way that a tag likemagically acquires all its inner html on the server all by itself. That it would need some kind of tool to help it. In that, I suppose, you are right. Although that tool can be literally any server-side templating engine that will fillwith the initial html it needs to bootstrap.But server-rendered shadow dom can absolutely be passed to the client. It is called declarative shadow DOM; and it works in all major browsers other than Firefox; and Firefox is working on it right now. There&#x27;s also a polyfill. reply bastawhiz 17 hours agorootparent> Although that tool can be literally any server-side templating engine that will fillwith the initial html it needs to bootstrap.If you need to add a templating engine to generate your markup, you&#x27;re really just replacing a framework with web components...and another framework. Which is half of my point: you aren&#x27;t getting rid of a framework by choosing web components.> it works in all major browsers other than Firefox; and Firefox is working on it right now. There&#x27;s also a polyfill.https:&#x2F;&#x2F;bugzilla.mozilla.org&#x2F;show_bug.cgi?id=1712140\"Obviously not a commitment to implement, but potentially worth reevaluation\" is not \"working on it right now\", unfortunately.Here we are again, however, in that a completely non-interactive web component still needs JavaScript to render because you need a polyfill to take static, server-rendered HTML and put it in the shadow root. Again, it begs the question of what purpose web components are serving here anyway. The developer has to bend over backwards for both the server side and the client side and there&#x27;s no meaningful reduction in code at all for either the client or the server. reply ElevenLathe 18 hours agoparentprev>> But Markdown has a secret weapon: you can write HTML inside of it! That means any fancy interactive diagrams I wanted to add would be just as portable as my the rest of my Markdown as long as I could express them as plain HTML tags.> You can also use MDX and achieve exactly the same thing.I would like to point out that plain HTML also has this property. reply bastawhiz 18 hours agorootparentSure, and you could hand-write your blog posts in a hex editor so that the binary data can just be pumped out over the wire. Markdown generates HTML. MDX generates HTML. Use the tool that brings you joy and makes your life easy.In any case, the point is that referencing another piece of code from your markup can be done in a number of ways, and the way the author chose has an upside but also a significant downside. reply brainbag 11 hours agoparentprevI like web components especially with the nice tooling that comes with lit, but agree that the lack of server-side rendering and hydration makes them impractical to use compared to other server side progressive enhancement libraries like Stimulus and Alpine. Server-side renderable web components would open up a lot of possibilities for better user experience for multi-page apps. reply mmis1000 14 hours agoparentprev> There&#x27;s no way to pass server-rendered shadow dom content on the server to the client,There is a proposal for that, although nobody knows whether it will survive in the long run. https:&#x2F;&#x2F;developer.chrome.com&#x2F;articles&#x2F;declarative-shadow-dom...BTW: the polyfill for this is rather easy, so you may be able to use it even browser today haven&#x27;t support it now. reply locallost 17 hours agoprevThe title is probably correct, but not sure it matters. Most applications will not live that long. I recently tried using Web Components, and something that is very simple in any framework like using awas, um, eh, incredibly confusing and complicated to setup. This maybe doesn&#x27;t matter if your component is just a , but if you&#x27;re building an application in JS then using slots is for me a critical feature because it allows me to have composable components. Debugging with \"shadow dom\" was also really confusing in dev tools. reply mmis1000 14 hours agoparent> incredibly confusing and complicated to setup.And some being almost impossible to work correctly without MutationObserver or some polyfill of it. The renderProp in react (or scoped slot in vue) is so commonly used to inject data from the parent component into child component. But replicate such behavior in webcomponent is simply... impossible without MutationObserver hacks. The assumption of web component that child&#x2F;parent component never need to know the info of each other just don&#x27;t make sense in real world.And the assumption that child component is always loaded and initiated regardless of parent component is also falsy in most frameworks. In most frameworks, the parent component decided whether child should be actually loaded or initiated. reply Pesthuf 17 hours agoprevWeb components might be better for writing isolated and reusable components, but for gluing stuff together to make your application work, the DOM API is just garbage. It was made to edit XML documents and it shows.Also, one reason I don&#x27;t make web components even for isolated, reusable components: No editor properly picks them up for things like autocompletion of attributes and event names or checks for typos. reply rglover 19 hours agoprevI was excited for web components, but the API was lacking (the final tipping point that led me to build Joystick [1]). I just couldn&#x27;t get on board with a web-standard that eschewed HTML in favor of stuff like this [2] where list items are attributes. The hyphenated namespace thing has always made my eye twitch, too (silly, I know).[1] https:&#x2F;&#x2F;github.com&#x2F;cheatcode&#x2F;joystick[2] https:&#x2F;&#x2F;github.com&#x2F;mdn&#x2F;web-components-examples&#x2F;blob&#x2F;main&#x2F;edi... reply fkyoureadthedoc 18 hours agoparentYou could easily do this a different way, if you still wanted it to be an attributeand pass json to a single attribute. Or make child &#x27;s.One thing about web components though, having shipped web components for an internal design system, is that a lot of people don&#x27;t understand the difference between html attributes and the properties of the underlying javascript objects. In plain HTML, or most server rendered templates afaik, there&#x27;s no way to pass non-string data declaratively like you could with say Vue where you can choose property vs attribute to bind data. reply rglover 17 hours agorootparent> You could easily do this a different wayYes, but that you have to make a choice means the design is poor. That&#x27;s why stuff like React (imo) is a failure: there&#x27;s a kajillion ways to do the same thing which end up creating dogma and sloppy&#x2F;inconsistent code (read: bugs). Web Components—as far as I&#x27;ve seen—are making the same mistakes, but even worse, as a standard.As a web standard, Web Components should have been more carefully crafted. There&#x27;s zero reason the spec couldn&#x27;t have allowed me to wrap a normaltag in the example above. That it doesn&#x27;t means, somewhere along the road, a compromise was made that shouldn&#x27;t have been made.The problem with all of that is when you introduce new web developers (who start by learning vanilla HTML, CSS, and JavaScript), as soon as they get to wanting to build more complex stuff (read: components), they essentially have to \"unlearn\" much of what they learned.Why does that matter? Paraphrasing Uncle Bob: because the rate of new developers doubles roughly every five years, that means half the programmers in the world haveand have everything behave as expected. reply rglover 5 hours agorootparent> There are many issues with Web Components, but I don&#x27;t think this is one of them.You described another version of the problem I&#x27;m getting at. You should be able to use vanilla HTML, but you can&#x27;t without hoop jumping. reply spankalee 16 hours agorootparentprevYou could do the same weird attributes thing with props in React. Does that make React&#x27;s design equally poor?I don&#x27;t know how you can prevent bad component designs like this. reply rglover 16 hours agorootparenthttps:&#x2F;&#x2F;github.com&#x2F;cheatcode&#x2F;joystick#writing-a-component reply spankalee 16 hours agorootparentnext [–]const EditableList = ui.component({ render: ({ props }) => { return `${each(Object.keys(props).filter((p) => p.startsWith(&#x27;list-item-&#x27;)), (p) => `${props[p]}` )}`; }, }); &#x2F;&#x2F; Usage: ${component(EditableList, { [&#x27;list-item-0&#x27;]: &#x27;First item on the list&#x27;, [&#x27;list-item-1&#x27;]: &#x27;Second item on the list&#x27;, [&#x27;list-item-2&#x27;]: &#x27;Third item on the list&#x27;, [&#x27;list-item-3&#x27;]: &#x27;Fourth item on the list&#x27;, [&#x27;list-item-4&#x27;]: &#x27;Fifth item on the list&#x27;, })}edit: used each(), which doesn&#x27;t change the point that you can make a bad component API in any framework. reply rglover 16 hours agorootparenthttps:&#x2F;&#x2F;github.com&#x2F;cheatcode&#x2F;joystick#each-and-e reply rglover 7 hours agorootparentprevRe: your edit, that&#x27;s not a bad component API, that&#x27;s bad JavaScript (intentionally written by the author, in this case). replyspankalee 18 hours agoparentprev[2] Is just a bad example that you could build with anything, and had nothing to do with the spec. They could have chosen to take data as child elements, or as a JS object. Individual attributes like that is a bizarre choice and shouldn&#x27;t reflect on web components.The web component APIs are low-level and what you need to achieve interop with the browser. Most developers use something like https:&#x2F;&#x2F;Lit.dev reply troupo 17 hours agorootparent> Is just a bad example that you could build with anythingThis is the go to \"defense\" I often hear from web component proponents.If even MDN cannot come up with a better example, something&#x27;s wrong with tech, not with how people use it.> The web component APIs are low-levelIt&#x27;s not. It only got labeled low-level after the initial failure to attract any developer mindshare. And then it got rebranded as \"aimed at library and framework developers\". Though it barely got traction there either because it offers nothing lib and framework developers want.> Most developers use something like https:&#x2F;&#x2F;Lit.devThe irony of writing this under \"Web Components will outlast your framework\"... reply spankalee 17 hours agorootparent> This is the go to \"defense\" I often hear from web component proponents. > > If even MDN cannot come up with a better example, something&#x27;s wrong with tech, not with how people use it.It&#x27;s not a \"defense\" it&#x27;s a very wacky demo and I can&#x27;t think of a single reason why you&#x27;d ever design a component this way. You could also design a React component or Angular component this way, and just like with web components, no one does, because it doesn&#x27;t make sense.I can&#x27;t say why MDN decided to do this, but this is literally the only time I&#x27;ve ever seen a list represented as individual attributes.> It&#x27;s not. It only got labeled low-level after the initial failure to attract any developer mindshareThis... just isn&#x27;t true. Web component APIs are things like customElements.define(), HTMLElement.attachShadow(), HTMLElement.connectedCallback(). These are objectively low-level compared to things that frameworks give you. Branding (whose?) has nothing to do with it. reply troupo 4 hours agorootparent> It&#x27;s not a \"defense\" it&#x27;s a very wacky demo and I can&#x27;t think of a single reason why you&#x27;d ever design a component this wayBecause it literally is the example on MDN?> This... just isn&#x27;t true. Web component APIs are things likeYes, yes they define those APIs. They are both too verbose, badly designed and low-level to use them directly, and they are too high-level, badly designed and useless for most frameworks to use them as the foundation for anything.However, even if we view them as \"low-level compared to frameworks\" they are still:- extremely high-level (as all DOM APIs)- were lauded as high-level and the end of all frameworks for years before being rebranded as \"these are for framework authors akshually\"Or, to put it simply, they are as \"low level\" as React&#x27;s class-based APIs of yesteryear. replymorbicer 17 hours agoprevI would like to love web components but they are still quite sucky to use (stringy attributes, bleh), especially if it&#x27;s not your team who produces them.And some super basic stuff like buttons in forms is still an unsolved problem: > Form-associated custom elements: being a submit buttonhttps:&#x2F;&#x2F;github.com&#x2F;WICG&#x2F;webcomponents&#x2F;issues&#x2F;814opened 4 years ago and representatives of major browsers still don&#x27;t have an answer reply mdhb 16 hours agoparentThat form issue is actually resolved with full cross browser support already https:&#x2F;&#x2F;developer.mozilla.org&#x2F;en-US&#x2F;docs&#x2F;Web&#x2F;API&#x2F;ElementInte...Also you don’t need to pass objects as HTML attributes, I think people pick that up coming from React but the browser lets you pass around objects between components just fine by using properties reply morbicer 16 hours agorootparentCan you provide me with an example please? I&#x27;ve seen the ElementInternals api but still don&#x27;t understand how it should help with the case of being able to submit the form by hitting enter in one of the inputs (which is standard html behavior).I wasn&#x27;t able to find working example anywhere and all the discussions around the issue are still open which leads me to an assumption that this is in fact, still unsolved.https:&#x2F;&#x2F;lit.dev&#x2F;playground&#x2F;#project=W3sibmFtZSI6InNpbXBsZS1n... reply otikik 19 hours agoprevAn adult mayfly will outlive most Javascript frameworks. reply nfRfqX5n 17 hours agoparentReact is 10 years old reply klysm 17 hours agorootparentI enjoy and use react, but I wouldn&#x27;t call the modern react api (hooks etc) 10 years old. reply s-lambert 1 hour agorootparentEven hooks are almost 5 years old, there&#x27;s been some changes to the hooks API but it&#x27;s largely the same. reply otikik 16 hours agorootparentprevIt is good that I wrote \"most\" and not \"all\", then. reply strogonoff 18 hours agoprevI often see novice developers making the mistake of comparing React to Web Components, to htmx, to Qwik, etc.React is not an equivalent of Web Components, but neither it is a front-end Web framework: it is neither a framework, nor it is specifically for the Web. What it is is a fairly small and general reactive GUI library[0]. Together with ReactDOM—a separate library—it can be used on the Web, but React itself can be used to render anything anywhere if you provide a suitable reconciler.As such, React (itself as old as Web Components) may well still be there whether or not the state of the art in front-end Web development moves on to whatever the next stack might be.[0] The distinction between frameworks and libraries, which tends to be lost on many fresh developers as well, is out of scope here but vital when it comes to software architecture. reply azangru 18 hours agoparent> React is not an equivalent of Web Components, but neither it is another web framework. What it is is a tiny and very general reactive GUI library.As for tiny, react-dom currently stands at 42kb minified gzipped. A tiny library would be about 1&#x2F;10th the size (compare with preact or svelte).Also, react has nasty rerendering habits, which makes if feel not so tiny at times.But more importantly, have you read React docs recently? Have you seen how the official position of the core team is that if you are starting out with react, you should just pick a framework (Next or Remix)? Have you seen the extra complexities that these frameworks start to introduce (client-side state management in the age of server components, anyone)? React is no longer a tiny and very general reactive GUI library. For a tiny and general reactive GUI library, look at Lit. React, meanwhile, is attempting to become a kitchen-sink. reply steve_adams_86 17 hours agorootparentReact promoting the use of frameworks by default is especially problematic because these frameworks are maintained by people who have profit incentives (either due to investor funding and&#x2F;or because they sell products based around the framework). They aren’t just open source React frameworks; they’re open source products for companies using them as business engines. reply strogonoff 8 hours agorootparentprevThis is factually incorrect. React is 6.4kB minified. What you are talking about is a bundle of React and ReactDOM.Remember: these are libraries. They compose. You can use one and not the other, e.g., if you are not rendering to DOM (and in fact even if you are rendering to DOM, but you come up with something smaller and more performant than ReactDOM that suits your requirements).If you are saying “React is bigger than X”, you are comparing apples to oranges unless X can also do what React does. Which, per my previous comment, none of those frameworks can.> more importantly, have you read React docs recently? Have you seen how the official position of the core team is that if you are starting out with react, you should just pick a framework (Next or Remix)?It’s a combination of two factors:1. Being a library, it’s by definition open to frameworks being built on top of it that facilitate library’s integration in specific solutions in specific ways. Without getting into the nitty-gritty of what it means to be a library or a framework, those frameworks add constraints on how the library is used, but they add value by providing scaffolding and streamlining some use cases. Therefore, it could sort of make sense to tell a novice front-end Web developer to just use a framework to get things done.2. Unfortunately, React is increasingly being influenced by commercial platforms that use those React-based frameworks (e.g., Vercel). I believe some of the original React developers moved from Facebook to some of those companies. Those companies have vested interest in sending people their way, and I suppose they are or they feel entitled to use React’s reputation for that. I also think they are incentivised to not make React’s documentation particularly easy to use, to keep some features private while using it themselves (cf. RSC) for as long as they can get away with, etc. reply azangru 2 hours agorootparent> This is factually incorrect. React is 6.4kB minified. What you are talking about is a bundle of React and ReactDOM.If you look at my comment again, you may notice that I wrote \"react-dom\". I checked before writing.> If you are saying “React is bigger than X”, you are comparing apples to oranges unless X can also do what React does. Which, per my previous comment, none of those frameworks can.Does preact need a preact-dom library ten times its own size? Does lit? What is it that they do not do? reply strogonoff 1 hour agorootparent> Does preact need a preact-dom library ten times its own size? Does lit? What is it that they do not do?No, but neither does it work outside of DOM. As I wrote in my first comment, you can use React anywhere (native apps, embedded LCDs[0], etc.), as long as you provide a suitable reconciler. It’s a tiny general reactive library that is neither a framework, nor is geared towards DOM&#x2F;Web in particular. As far as I know, the same cannot be said about Preact.[0] https:&#x2F;&#x2F;github.com&#x2F;doodlewind&#x2F;react-ssd1306&#x2F;blob&#x2F;master&#x2F;docs... reply azangru 19 minutes agorootparent> No, but neither does it work outside of DOM.I know. This thread was specifically about the web though. Web components?If you put React on the web, it is only fair to consider it together with react-dom in all the comparisons. Without a rendering library, React by itself, however small or generic, is not of much use. So what the absolute majority of people mean when they say \"react\" in the context of building things for the web, is the react&#x2F;react-dom combination. reply wg0 14 hours agorootparentprevReact is the Spring framework of the frontend world. reply troupo 17 hours agoparentprev> I often see novice developers making the mistake of comparing React to Web Components, to htmx, to Qwik, etc.> React is not an equivalent of Web ComponentsThe only people who promote these comparisons and draw these equivalencies are the people who promote web components under the weird mantra of \"use the platform\". reply raspo 16 hours agoprevI think the author was referring about the specific use-case of building a website using static file generators.In that context I 100% agree with him that if you want to sprinkle some interactivity while keeping your content \"portable\" and be able to move to the next \"CMS\" of the future, sticking with web components is a much wiser choice, rather than embracing whatever fancy convenient feature your tool provides (like Astro&#x27;s islands).(It is good advice and a well written article btw, thank you for sharing)I don&#x27;t think he was suggesting to build your next SPA entirely with web components.. reply jakelazaroff 14 hours agoparentAuthor here — yes, this is exactly correct (and thank you for the kind words). I think the maintenance cost of dependencies is important to consider, and with web components we have a \"native\" solution for encapsulating HTML, CSS and JS. That doesn&#x27;t mean that every project needs to have that as its top priority! Sometimes development velocity&#x2F;shared patterns&#x2F;ease of finding other developers is more important, and that&#x27;s perfectly fine. reply merelysounds 16 hours agoprevI also like reducing dependencies, but I’ve picked a different approach.When I use an external library, I link to static production scripts, without webpack or other bundler. I do use babel to handle jsx if needed, but I do it by linking babel via a script tag in dev mode (and with a simple shell script in production).It’s more radical, not recommended for production use and impractical for anything other than a hobby project. But it’s a way to limit adding new dependencies, or limit reliance on package managers. Additionally, the project can work with as much as a static file server, also for development - so I won’t get stuck on an “npm update” when I return to a project after a break.Most recent website I’ve built like this is: https:&#x2F;&#x2F;merely.xyz&#x2F;lenses , list of Sony E Mount FF lenses.Again, for most cases web components sound like a more practical approach, I plan to explore that long term too. reply DrScientist 17 hours agoprevThe web component idea originally had something like 4 basic components.- custom elements - shadow DOM - html imports ( now dead or at the very least &#x27;resting&#x27; ) - html templatesI think it&#x27;s important to note that you can build&#x2F;use custom elements ( defining your own tags with encapsulated behaviour ) without having to use shadow DOM nor html templates.So a simple way to start, in my view, is plain custom elements, mixed in with ES modules and import maps.Shadow DOM and html templates are not compulsory to get yourreply HatchedLake721 18 hours agoprevNo they won&#x27;t.Because React is a view library, not a framework.Yes, web components might outlive React.But no, they will not outlive my JavaScript framework, because web components don&#x27;t replace routing, data layer, testing, authz, server-side rendering, rehydration and whatever else frameworks like Angular&#x2F;Ember&#x2F;Next.js&#x2F;etc do these days.Rendering a view is a small part of what front-end frameworks do. reply spankalee 18 hours agoparentReact is a framework because it calls into the the components to make them go, not the other way around - the Holywood Principle.This shows up with restrictions like that you can&#x27;t mix and match components with different versions of React in the same tree. reply HatchedLake721 18 hours agorootparentEven React homepage calls itself a library, and mentions Next.js&#x2F;Remix&#x2F;Gatsby&#x2F;Expo as React frameworks you can use. reply edgyquant 18 hours agorootparentDoesn’t change that framework has a definition that react meets. The renderer runs your code, that’s a framework reply a_wild_dandan 17 hours agorootparentYour definition is very...unintuitive to me. Control inversion (the Hollywood Principle) isn&#x27;t relevant -- many systems which use it aren&#x27;t remotely frameworks.Most people view libraries as tools which target narrowly scoped sub-problems of a given solution&#x2F;application. In React&#x27;s case, it&#x27;s a view library -- the V in MVC, for instance. Frameworks are generally considered holistic set of tools which tightly integrate together to form a structured & opinionated approach to the larger solution, e.g the entire MVC approach.React is widely considered a library. React doesn&#x27;t tell you how to structure your project, manage its backend communication, handle application state, routing, etc. React is just...not a framework. For any standard notion of what engineers mean when using the term. If you use IoC to distinguish libs&#x2F;frameworks, you&#x27;re going to confuse the hell outta people. There are certainly technologies which straddle the line between these terms, but React is not one of them. reply Tade0 14 hours agorootparent> React doesn&#x27;t tell you how to structure your project, manage its backend communication, handle application state, routing, etc. React is just...not a framework.Technically it doesn&#x27;t, but the conventions that grew around it and the availability of learning material effectively produced same default choices, making it a framework via convention.And I see it as a good thing, because having several competing router implementations is an unnecessary headache.The React crowd would do good to stop being in denial about this. reply throwaway290 1 hour agorootparentReact is not a web framework... You think of things like Next or Remix, those are. There&#x27;s no inversion of control, it&#x27;s not a framework. Words mean things replysebringj 17 hours agoprevIMO Web Components generally suck in developer experience but are good for bridging different js projects or web frameworks as the web components are very compatible between js frameworks. You can literally make a thin wrapper to expose your js flavored framework-based component such as react for example and expose it as a web component to another system such as angular 1 for example and it will work pretty well. You could potentially use this strategy to have parallel tracks of development where you can create an entirely new framework from scratch and start to share that functionality in the legacy project while you&#x27;re in the process of upgrading which could take a long long time in some cases. At least you won&#x27;t be continually working on the old one and adding more tech debt... although one could argue this wrapper approach is tech debt. reply Devasta 19 hours agoprevAnd jQuery will likely outlive both. reply recursivedoubts 19 hours agoparentas i pass through my incarnations at every conference & youtube influencer king,i make my proper prostrations to the gods of the hot new thingpeering through reverent fingers I watch them flourish and fall,and reliable silent old jquery, I notice, outlasts them all reply joelfried 18 hours agorootparentSelecting an element right from the DOM,With syntax so simple (and not a fork bomb),No matter the changes in chorus and verse,Every new framework . . . will make it all worse.Within your questions and inner for loop,Is readable syntax (not alphabet soup),Give up on your promises, avoid callback hell,Just keep using jQuery - I promise, it&#x27;s swell! reply morbicer 17 hours agoparentprevMaybe COBOL as well. That doesn&#x27;t mean I want to use it in my day-to-day life.Washboards might outlive washing machines but I still prefer the latter to do my laundry. reply klysm 17 hours agoparentprevI wouldn&#x27;t really consider it alive in the grand scheme of things. reply caseyohara 16 hours agorootparentAccording to https:&#x2F;&#x2F;w3techs.com&#x2F;technologies&#x2F;details&#x2F;js-jquery:> jQuery is used by 94.5% of all the websites whose JavaScript library we know. This is 77.5% of all websites.This appears to be current data too (Oct 2023). I&#x27;m not sure how reliable the data is, but it is congruent with my experience that _a lot_ of websites still use jQuery. It&#x27;s easy to forget the HN crowd is also in a bubble. If you only read articles here, you&#x27;d think everyone is using the latest JS framework du jour, but lots of the web still runs on PHP and jQuery. reply Kiala 15 hours agorootparentNot that surprising actually, since jQuery is bundled with WordPress. reply klysm 15 hours agorootparentprevyes, but why on earth would you pick it for something greenfield? The only justification I could see is it being a tool you are personally familiar with. reply yellow_lead 16 hours agoprevMy problem with web components is the jitter they introduce when rendering the page. Sure, you can hide this or fade it with CSS, but it&#x27;s kind of a dealbreaker for me. Maybe someone can suggest a better workaround? For instance, on the submitted page, I see a jitter for the pixelart-demo component. reply taeric 17 hours agoprevBut will Web Components of tomorrow be the same as the ones today? I see that, in today&#x27;s parlance, this is 3 core ideas. Custom elements, shadow DOM, and templates. I fully expect things to be added to that list as time goes on. Not the least because of so many obvious things that are not covered there.To that end, the question will have to be if you can run the same web components of today on a browser of tomorrow. With the very notable fact that though you can&#x27;t run components on browsers of yesterday, you can run that old jquery site on browsers of today. reply btbuildem 16 hours agoprevI find it interesting that the author&#x27;s premise seems motivated by a self-inflicted churn. Having migrated a simple blog across a dozen of technologies, their conclusion is thatwill outlast any trend?Surely, yes. But I&#x27;d like to observe that a blog like this, one of the simplest web-based entities, could have remained implemented in some of the decades-old technologies and delivered the same experience to the end user. reply ent101 17 hours agoprevWe wrote Puter.com in vanilla js and it&#x27;s been pretty straight forward. tbh most of the complexity is coming from the backend rather than the frontend. reply miohtama 18 hours agoprevWhy Web Components have not yet taken off?They always sounded like a beautiful solution how to make all the various web frontend frameworks to live peacefully on the same page. reply rk06 17 hours agoparentBecause they don&#x27;t come with router, state management and other support.When you start adding them, you will be writing enough glue code that will offset a lot of benefits of web components. reply klysm 17 hours agoparentprevbecause they have a shitty API reply diob 18 hours agoprevBut will the JavaScript Framework I&#x27;m using outlive my application? Most folks would answer yes I think.The lifetime of apps is surprisingly short. reply EliasToft 17 hours agoparentI dont know about that. The very first project I worked on after graduating is still very much alive last I checked, and I was actually promised that it should only have a lifetime of a few years as it was an incredible fast developed prototype - the feature set and scope considering. I actually left the company because we were two devs and the owner of the company constantly wanted us to work on new features instead of improving the foundation of the obviosuly rushed prototype, but here we are almost 15 years later and the core of it is pretty much still the same thing as when I left (SaaS). reply namtab00 17 hours agorootparentI&#x27;ve recently found out stuff I&#x27;ve built 16 years ago, in ColdFusion and Classic ASP (anybody remember Macromedia Dreamweaver, later Adobe?) is still in use, never mind more \"recent\" WebForms + jquery stuff... reply franciscop 19 hours agoprevWhich web components, the ones that were deprecated and no browser implements anymore? Ah wait no, you mean the new ones that virtually no one uses, right? While the point of view that ESM and DOM APIs live long-term is pretty good, the specific example is maybe the most infamous for how not true this has been and many call web components Dead On Arrival.Newer technology on the web does break more often than old JS (maybe, Flash?), for example I have a project that for security reasons doesn&#x27;t work anymore, Cookies famously also had a big change for security like that, fetch() defaults changed, and AFAIK even performance.now() was capped for Spectre. reply fassssst 18 hours agoparentBing Chat is built entirely with Web Components.(I work at Microsoft on it. You can verify with F12.) reply franciscop 16 hours agorootparentI tried to try Bing Chat (https:&#x2F;&#x2F;www.microsoft.com&#x2F;en-us&#x2F;edge&#x2F;features&#x2F;bing-chat here, right?) and ironically it asks me to download the whole Edge, AND from the screenshots it seems like it&#x27;s a browser part? extension? No, thanks. reply fassssst 14 hours agorootparenthttp:&#x2F;&#x2F;www.bing.com&#x2F;chat reply tuzemec 18 hours agorootparentprevAFAIK - also the browser version of Photoshop. reply spankalee 18 hours agorootparentAnd Chrome OS, Firefox, Reddit, Internet Archive, YouTube, and a long list of others... reply franciscop 16 hours agorootparentI checked a couple of those quickly;Reddit doesn&#x27;t seem to use web components at all? https:&#x2F;&#x2F;imgur.com&#x2F;a&#x2F;kzLoGnVYoutube seems to use 1 web component for every 10 normal components, which is fair: https:&#x2F;&#x2F;imgur.com&#x2F;a&#x2F;YIBhLh8 reply spankalee 15 hours agorootparentThe \"normal components\" you&#x27;re referring to are just elements. I don&#x27;t see the need to track a ratio there. All of YouTube desktop&#x27;s components are web components.Reddit doesn&#x27;t use web component on all pages yet. They have them on certain types of comment pages now and are incrementally porting the rest of their site from React to web components with Lit. They&#x27;ve also built this year&#x27;s r&#x2F;place with Lit, and are building other things like embeds on web components. reply megaman821 15 hours agorootparentprevReddit has a whole other site if you go there without being logged in. That one is built with web components. reply wg0 13 hours agorootparentprevGitHub also uses web components. reply azangru 18 hours agoparentprev> Ah wait no, you mean the new ones that virtually no one uses, right?This is exactly the point. Virtually no-one is using them (well, except for Microsoft, and Google, and Adobe, and Github, and Reddit, and NordHealth, and a bunch of others), whereas they are far more future-proof than any of the much more popular frameworks.It will all change with time, of course. Just like there is no reason now to depend on jQuery. If only I could restart our app again, I would never have chosen React for it. And it worries me when I think how we are going to migrate off of it. reply nfRfqX5n 17 hours agorootparentMost of those use Lit right? I’d be afraid to choose a library created by Google reply azangru 17 hours agorootparent> I’d be afraid to choose a library created by GoogleI wouldn&#x27;t :-) Lit is just a tiny wrapper over native web components to add reactivity to their behaviour; but what is more important, Lit positions itself as a gradually disappearing library, intended to be replaced with native browser apis as they are introduced into the platform (e.g. DOM parts to help with templating, etc.). Compare this ethos to any other library out there. reply simonw 17 hours agoparentprev\"the ones that were deprecated and no browser implements anymore?\"Which spec is that? reply bastawhiz 17 hours agorootparentHTML imports is a good one.https:&#x2F;&#x2F;www.w3.org&#x2F;TR&#x2F;html-imports&#x2F;The v0 spec is also vastly different than how it was implemented, though I don&#x27;t think it ever shipped out from behind a flag:https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20130608123733&#x2F;http:&#x2F;&#x2F;www.w3.org... reply franciscop 16 hours agorootparentI mean v0, I learned and experimented a lot with it and suddenly everything changed and was dropped and it was a mess. IIRC in Firefox or Chrome it shipped? At least part of them? Or I might have turned on a flag back in the day, I don&#x27;t remember too much, I just know \"web components are the future\" and for 2-4 years they were the biggest mess I&#x27;ve seen with the web. reply sandreas 16 hours agoprevIf you combine native WebComponents with scss and JSX&#x2F;TSX, it gets even better.As an example you could take a look at an older project on github: https:&#x2F;&#x2F;github.com&#x2F;cyco&#x2F;WebFun&#x2F;Here is some example code:https:&#x2F;&#x2F;github.com&#x2F;cyco&#x2F;WebFun&#x2F;blob&#x2F;ec42d59b99d62daafea3ccce...https:&#x2F;&#x2F;github.com&#x2F;cyco&#x2F;WebFun&#x2F;blob&#x2F;ec42d59b99d62daafea3ccce... reply demondemidi 18 hours agoprevIf a framework can support a major revision for longer than 6 months--more like 6 years--they will survive. Otherwise, the road to JavaScript madness is paved with frameworks that never learned LTS is a real thing. reply morbicer 17 hours agoparentThere&#x27;s no LTS in React but the components you wrote 10 years ago still works today in latest React. (there are some deprecations but very few) reply ramesh31 19 hours agoprevThey will also require a cobbled together list of dependencies to make useful, and those dependencies will probably not be maintained as well as React.I worked in a shop that followed this philosophy. Every single UI component was a web component with its own npm package to install. It worked fine. There was zero benefit. There&#x27;s still zero benefit today 6 years later. You&#x27;re optimizing for a future which will most likely never come. reply wg0 19 hours agoprevnot to mention, web components come with their own complexity around shadow tree and the question of how to style&#x2F;interact within the component tree from outside etc. reply megaman821 18 hours agoparentYou don&#x27;t have to use the shadow DOM, you can use the light DOM, but then you lose slots. I think they should really prioritize using slots with the light DOM as it would make it easier to incorporate web components into existing sites. reply coxmi 15 hours agorootparentI don’t see how light DOM slots could work since it’s just replacing element.innerHTML, but a non-style-encapsulating shadow DOM option would be great.That, and some progress on template instantiation, reactive DOM primitives or DOM partials, so we don’t have to concatenate strings and overwrite el.shadowRoot.innerHTML, or do direct DOM manipulation for any updates.Until that all exists, and there’s a simple API to bring it all together, other frameworks will eat this space completely. reply miguelxt 19 hours agoparentprevNot mandatory to use the Shadow DOM. And you can easily add public methods to the component for external interaction. reply wg0 14 hours agoprevI just got to know that svelte components can be complied into web components.If so, then probably using svelte as a compiler for web components can be one way to do things.Not sure about routing though. Maybe page.js or something.Even for vanilla js, till might need vite, postcss, tailwind in some cases. reply superkuh 18 hours agoprevHTML&#x2F;CSS sites will outlive it all. Because they&#x27;re actually the text, images, layout all in static things that can live forever without being touched and without any need for complicated execution of code or mantaining of obscure rapidly changing pseudo-standards. (*1)If you want to make sites and have a skillset that last, learn how to make progressively enhanced HTML websites. Anything like Web Components (where you invent useless non-defined HTML-elements-with-hyphens and then define them after executing a bunch of Javascript), Javascript frameworks (where you don&#x27;t even pretend to involve HTML) will last only a handful of years.(1*: at least until HTTP&#x2F;1.1 support is removed from browsers) reply mdhb 16 hours agoparentWhat part of web components don’t meet the definition of progressively enhanced? reply superkuh 10 hours agorootparentYou might be able to do progressive enhancement with web components but the vast majority, every web components site I&#x27;ve ever encountered, just end up with blank gray areas when the JS is not run to define them. That is far from progressive enhancement.It&#x27;s a bit like \"communism\". You can say web components can be great or whatever, but everyone&#x27;s every experience with it is very bad. reply jakelazaroff 14 hours agoparentprevDid you see what I used them for, though? How would you make a tutorial article with interactive demos without JavaScript? reply mark242 17 hours agoprev[Insert the \"now you have 16 standards\" joke here] reply tubthumper8 17 hours agoparentTools and standards aren&#x27;t really the same thing reply troupo 17 hours agoparentprevWeb Components is at least 10 already, and will need at least 20 more.No, this is not a joke. reply skybrian 18 hours agoprevES modules have a problem: do they import the source code or the \"binary\" (minified code). As long as you&#x27;re writing demos where the source code is the executable, it&#x27;s fine. This is great for browser demos.But when you start using Typescript or npm modules that export minified code, or there&#x27;s a CDN involved, finding the original source for a function gets increasingly difficult, the type definitions are in a different file, and breakpoints don&#x27;t work. It&#x27;s almost like debugging a binary.Compiled languages like Go do a better job of making sure you can actually read the source code, because imports always import source code. reply spankalee 18 hours agoparentI don&#x27;t understand the problem here, or why it&#x27;s JS module specific.Source maps with pretty great, and if you&#x27;re in a development setup where you say only compile out types and resolve import specifiers, they work spectacularly well, including in debuggers. reply skybrian 17 hours agorootparentSource maps are indeed very helpful when they work, but in my experience, often they don’t for third-party modules. This seems to be an ecosystem thing. The documentation for package.json doesn’t mention sourcemaps?According to this bug [1], even the typescript compiler’s npm doesn’t include source or sourcemaps.[1] https:&#x2F;&#x2F;github.com&#x2F;microsoft&#x2F;TypeScript&#x2F;issues&#x2F;32207 reply brainbag 11 hours agorootparentprevYeah, other than a project that was still on webpack, I can&#x27;t think of any time in the last few years where this was a problem. Vite has made JavaScript apps nearly effortless for years now. reply zubairq 15 hours agoprevGreat article. Really made me think. But don’t webcomponents lack properties and functions that can be embedded in tooling ? reply joduplessis 16 hours agoprevIn adjacent news, I love that typeface. reply esafak 14 hours agoparentIt&#x27;s Peachi: https:&#x2F;&#x2F;www.mycreativeland.com&#x2F;peachi-serif-font-familyApparently based on https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Souvenir_(typeface)See also https:&#x2F;&#x2F;fly.io&#x2F; reply gedy 19 hours agoprevMaybe, but while I love UI components, I really dislike that \"web components\" conflate and combine multiple things like custom elements, and shadow DOM, etc.So working with them in real apps, you get a mess of opinions and assumptions like completely isolated styles (no I don&#x27;t want this! let me use my site&#x27;s Bootstrap theme!), etc.Also dealing with string-based attributes&#x2F;props is a pain. I greatly prefer React&#x2F;Svelte&#x2F;Vue for not having to deal with all this. reply zaphar 19 hours agoparentIt&#x27;s an umbrella term for a set of technologies. Each of them can be used in isolation from the others if you want though. You don&#x27;t have to use shadow DOM if you don&#x27;t want it. You don&#x27;t have to use custom elements if you don&#x27;t want to either. You are correct though that almost every tool that works with them sort of assumes you are going to use both. reply tuzemec 18 hours agorootparentI kinda like this approach. You can change the combination of used APIs for different cases.\"Widget\" that you provide for partners to put on their web pages? Of course you&#x27;ll use shadow DOM, because you don&#x27;t know the page context, surrounding styles, etc.A component to share on different parts of your site - you can skip the shadow DOM, because you share common styles everywhere, and probably you want to inherit some of them. reply zaphar 17 hours agorootparentI think in terms of the implementation keeping them separate and composable is very useful. I think the marketing around it could have emphasized it a little more but that&#x27;s water under the bridge really. reply jjcm 19 hours agoparentprevIt&#x27;s fairly easy to choose between style isolation and no style isolation though. Just change the `this.shadow.innerHTML` in the render to `this.innerHTML`. The encapsulation aspect provides some really nice benefits in many scenarios, so having the option of this is quite nice.A classic example of why this is beneficial is when creating design system components - you typically want these to not be affected by styling on the page, and if you do want them to be styled, you only want them to be styled in specific ways which you can build in via css custom property values (see the accent example the author provides). reply gedy 18 hours agorootparent> you typically want these to not be affected by styling on the page, and if you do want them to be styled, you only want them to be styled in specific ways which you can build in via css custom property valuesIronically, this proves my point about opinions a bit - our design system is themeable and needs to cover a number of technologies and we want to inherit the app&#x27;s CSS, not embed the styles or have to specify colors on every component. reply jjcm 17 hours agorootparentThere&#x27;s a strong difference between styles and themes. Theming is quite easy with web components, as long as you have a semantic layer to your design tokens. Since custom properties do cascade, it&#x27;s quite easy to automatically switch themes while still preventing css-selector clobber issues with styles.If you&#x27;re curious on this approach, my site non.io has light&#x2F;dark theming via this method, and Figma&#x27;s light&#x2F;dark mode was loosely based on this approach. reply nathias 16 hours agoprevThere are so many downsides of choosing web components you really need a very rare usecase to justify them. They are an artefact of a time we&#x27;re all glad to be done with, they force you into OOP so you&#x27;re doing inheritance acrobatics, add TS and now you&#x27;re feeding two hierarchies of inheritance that don&#x27;t quite match and bloat to a 80% of your codebase, making it unreadable, prone to hacks and bugs, impossible to maintain etc. The point of web components was to make components more shareable between frameworks, and code more reusable, but now code written in any of the major FE frameworks is more reusable (a component looks pretty much the same in React, Vue, Svelte, but not with web components). reply troupo 17 hours agoprevThe only reason web components are alive is because Google is pouring literally millions into them.A technology that cannot submit forms without Javascript, still can&#x27;t create a submit button and whose proponents agree that it still needs 20 more standards to be generally working [1] would be dead within a year. And yet we&#x27;re here in year 12 of this dumpster fire.[1] Instead of producing a report every year, Web Component Group seems to just update the same document in place, so now it inly lists \"4 standards we agreed need to be done ASAP\" reply shadowgovt 18 hours agoprevProbably not as long as there&#x27;s a reason to transpile my project into minified, consolidated JavaScript, no. As long as I&#x27;m doing that, I can stick any framework I choose to into the pipe. reply spankalee 18 hours agoparentThat&#x27;s all orthogonal to web components. Like frameworks, there are some web components libraries that require a build step and some that don&#x27;t. reply very_good_man 17 hours agoprev [–] Is this a joke? html and css as one big JS string? reply hyperhello 14 hours agoparent [–] Well, yea.All pointless frameworking is based on the fact that HTML doesn’t natively nest in other HTML or natively color in JavaScript editors. So we have ridiculous bloat, when that was all we had to fix: the ability to put HTML in JavaScript in a satisfyingly official way.Instead, we have everything in fragments that have to be mechanically transformed, and fight over which giant IDE is best. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The author promotes the use of web components in blog projects, citing benefits like portability, longevity, and compatibility with various website generators.",
      "The author's preference for web components is based on their ability to be rendered in any HTML environment and their simplistic nature.",
      "Importance is placed on using plain HTML within web components, employing shadow DOM for isolation of components, and adhering to web standards for future accessibility and upkeep."
    ],
    "commentSummary": [
      "The article explores the longevity, benefits, and shortcomings of using web components as opposed to JavaScript frameworks, touching on topics such as state management, performance, and complex object handling.",
      "It elaborates on the risk, complexity, and limitations of various frameworks, debates around the role of front-end specialists, with a particular focus on the use of React, and the comparison with web components.",
      "The discussion also addresses the concerns about the API and its support for web components, their adoption, usage across sites and frameworks, and challenges with debugging, styling, and themeability."
    ],
    "points": 281,
    "commentCount": 217,
    "retryCount": 0,
    "time": 1698241244
  },
  {
    "id": 38018917,
    "title": "How to find a lost phone in a no-cell-coverage camping site?",
    "originLink": "https://manas.tech/blog/2023/10/25/approaching-unconventional-problems/",
    "originBody": "HELLO WORK LABS BLOG CRYSTAL CULTURE JOIN US START YOUR PROJECT Matías García Isaía Approaching unconventional problems culture Oct 25 2023 5 min Or \"How to find a lost phone in a no-cell-coverage camping site?\" A few weeks ago, I went on a trip with my dad, uncle, cousin and a couple of their friends in order to share an off-road trip on ATVs across the jungle. There were about twelve of us enjoying the landscape in Misiones, northern Argentina, with its tea, tobacco and yerba mate plantings. Not that you could expect to see lots of wild animals around those noisy ATVs. Ready... set... go! Largely beautiful as this country is, as you get into more rural areas, there's a high chance you won't have cell phone coverage there - I'll leave it as an exercise to the reader to choose if that's a feature or a bug. So there we were, making an asado (think \"barbeque\", if you must) in the cabins we've rented in the middle of nowhere, when my cousin started to look around for his phone. In the hour after the last time we knew he had the phone, he took a 50km trip to the closest town to shop for some fuel and beverages - so we really hoped he didn't lose the phone there. We'd already called and sent some WhatsApp messages, so we knew the phone wasn't reachable. So we checked the area around the grill, we checked the cabins, we checked around the place where we were playing some cards (yes, it had to be Truco), we checked in the truck in which he went to the town - all to no avail. Using the “Find my device” feature of the phone wasn’t really an option, since there was no way the signal was going to reach the phone. So... was there anything else to try? There were lots of butterflies around - but I think the pattern on this one is not actually a serial number. It turns out - there was. After having lived in a rural area for almost two years, I’ve learnt to save battery by switching my phone’s wifi off whenever I go into the woods or mountain - but I also know that people don’t usually do that. After confirming this assumption with him, I’ve used my own phone’s tethering feature to create a wifi network with the same name & password as my cousin’s home network - and we started walking around the place. We made sure the other guy helping us with the search had his own wifi off, to avoid false positives, and waited to find a new connection to the hotspot. And it worked! The connection was made when walking nearby the parked truck, but it turns out that the phone wasn’t in the truck - it was lying on one of the ATVs that was parked by its side. Should we not have found it so “soon” with this strategy, we would have started walking in different ways from that zone to try to triangulate the signal - but we were lucky to not need that. There’s that nice feeling in being able to combine your techie knowledge and the lessons learnt from constrained environments just for fun - double that when it helps to help someone solve a real problem. Any time is a good time to enjoy a nice sunset - but more specifically right after the afternoon. Using neural networks to predict protein functions AUG 22 2023 Reach out to us at hello@manas.tech Manas Technology Solutions This website is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License",
    "commentLink": "https://news.ycombinator.com/item?id=38018917",
    "commentBody": "How to find a lost phone in a no-cell-coverage camping site?Hacker NewspastloginHow to find a lost phone in a no-cell-coverage camping site? (manas.tech) 256 points by mgarciaisaia 12 hours ago| hidepastfavorite168 comments semireg 4 hours agoI had AirPods Max stolen from our car a few months ago. A week later they popped up on Find My a block away. I hopped on my bike and tracked to a small apartment building. Using Find My will show you a “warmer … warmer … colder” kind of UI and whenever I lifted my phone to a particular window (shades drawn) Find My would say “Nearby.” I called the police and they were genuinely excited to knock on the door. A guy answered and denied having headphones that fit the description. Another police officer brought me around to the window and had me “play sound to locate” and sure enough you could hear the beep-boops through the window. The officer went back and said “listen, we know they are in your apartment, we can hear them, either go get them or we are getting a search warrant.” The guy said “ohhhh well I did have a party last week and there’s this backpack…”Uh huh. Headphones returned.Another officer returned to this scene and asked if we got the headphones back. I held them up and he says: “OH $&@# YEAH!” reply baz00 2 hours agoparentLucky there. UK here. A couple of years back I had a macbook pro delivered to me. It was delivered to the correct number on a different road. The POD had a photo of the front door and the person. I recognised the front door as it was on a local estate. Phoned delivery company up (DPD) and they said that they delivered it to the correct location and wouldn&#x27;t do anything about it. Went round there and the guy said \"um, it&#x27;s mine now. Finders keepers. What are you going to do about it?\".So I phoned the police. They never turned up.I opened up a credit card chargeback. But I was complaining about this to someone in the school playground and someone else overheard it. Turns out she was his next door neighbour. Said \"I&#x27;ll get it back for you\". Sure enough that afternoon she turned up with it! Turns out the guy was a convicted paedophile and she knew that and said if he didn&#x27;t give it back she&#x27;d tell everyone on the estate.You need leverage or a good police force against criminals. The latter is rare so I suspect that taking matters in to your own hands is sometimes required. reply INTPenis 1 hour agorootparent>a good police forceWhat do you expect the police to do in this situation? They can&#x27;t just walk into people&#x27;s homes over your word. OP at least had a noise which in the states I assume is probable cause or something. And even then they&#x27;d have to come back with a warrant but got the headphones because the suspect felt defeated.Your situation is bizarre, the helpless feeling of knowing where your stolen item is and not be able to do anything about it. But it&#x27;s not solvable by the police unless you have more evidence. For example you could have recorded your neighbor saying those things to you.Here in Sweden petty theft is 99% an insurance issue. I even heard one case where their boat was stolen with an airtag on it and it was traced to a particular driveway.The police here won&#x27;t even pick up the case, it goes into a pile of other theft cases and the owner can use the ID to file an insurance claim.It&#x27;s very sad on the surface. But maybe they have their reasons. reply yardstick 12 minutes agorootparent> OP at least had a noise which in the states I assume is probable cause or something.Isn’t a signal that is within a few feet of the door you want to enter good enough? It’s more authenticate than some random noise - you know it’s your device and not some random device emitting find my data.Sounds like policing or judicial approach is outdated. If a police officer sees the stolen goods inside via a window, they can enter right? How are RF waves that they can see coming inside the property, and uniquely identify the property, any different? reply Wytwwww 13 minutes agorootparentprev> But maybe they have their reasons.Like what reasons? It&#x27;s somewhat understandable that police might not want to investigate theft of relatively cheap item because they have to prioritize. But a stolen boat? At the very least it warrants some further investigation. Them dismissing it outright just seems bizarre since they do have some evidence they at least should come and talk to the owner. reply stef25 38 minutes agorootparentprev> They can&#x27;t just walk into people&#x27;s homes over your wordOfficer I was kidnapped, taken to this address and violently raped. \"Sorry we just walk in to people&#x27;s homes over your word\" ? Half a dozen other scenarios come to mind. reply guntherhermann 1 hour agorootparentprev>The POD had a photo of the front door and the person. I recognised the front door as it was on a local estate.What more evidence do you need? reply INTPenis 40 minutes agorootparentOk I just read on a delivery company website that they have in fact started taking photos of the moment of delivery. Wow. That is incredible.Here I always opt for delivery at a pick up location and use my electronic ID to pick it up so I had never expected delivery drivers to take, and store, photos of people. reply bloqs 41 minutes agorootparentprevThey have no reasons other than budget induced apathy. The evidence of a crime is available and their lack of willingness to act is seriously telling reply gadders 2 hours agorootparentprevThis is like an episode of Shameless. Sounds a lot like when I grew up. Except we didn&#x27;t have macbooks or online shopping. reply hinkley 2 hours agorootparentprevYou did a cryptographically secure deletion of that hard drive, right? Even odds there were bad things in that drive. reply baz00 2 hours agorootparentIt was still sealed. It was probably on Facebook marketplace. reply squokko 1 hour agorootparentprevI hope she still told everyone on the estate... reply chrischen 4 hours agoparentprevWasn’t expecting that. Was expecting an “even if you located them the cops won’t bother to help you recover just $XX dollars worth of stolen goods. reply eru 4 hours agorootparentI think that attitude really depends on where you are, and how overworked your local police is. reply megablast 4 hours agorootparentAnd the police you get. And when in the shift they are. reply eiiot 2 hours agorootparentprevSan Francisco reply p00dles 1 hour agoparentprevI had a similar situation in Paris with an iPhone. The Police were so helpful, knew exactly what to do, and were also very excited, but ultimately the Find My location wasn’t granular enough to find the phone. In an urban environment like Paris with big apartment buildings directly adjacent to each other, I think Find My is difficult. I’d have to be lucky and catch the phone during transit from one place to another, I think.Edit: being able to use my iPad with Find My was an amazing experience, it’s almost worth having one just for that situation, where I didn’t have to bumble around with 2FA and logging in from my laptop, which isn’t Apple. I could also erase my stolen phone remotely, which gave me so much peace of mind. reply ahepp 4 hours agoparentprevWhat city do you live in? reply radres 1 hour agoparentprevReally would like to know which city this is. As others commented many of the police force would&#x27;ve responded \"tough luck\" reply bryanrasmussen 4 hours agoparentprev>I had AirPods Max stolen from our car a few months ago. A week later they popped up on Find My a block away.>The officer went back and said “listen, we know they are in your apartment, we can hear them, either go get them or we are getting a search warrant.” The guy said “ohhhh well I did have a party last week and there’s this backpack…”>Uh huh. Headphones returned.I mean from your description sounds like the guy was telling the truth, or is your theory that he stole your airpods, went on vacation and came back home after several weeks - which of course is also a possibility, but I think backpack left over from party sounds also reasonable.on edit: hmm, early in the morning, so now I understand it was a week after being stolen they showed up on Find My..guess need more coffee. reply ant6n 27 minutes agorootparentOr perhaps resist the „well actually“-urge ;-) reply ridgeguy 6 hours agoprevFind My came to the rescue when my wife unknowingly dropped her phone during a pullover to take some pix. The turnout was on New Priest Grade, the best way to Yosemite from our home.Next morning, after the frenzied \"Where&#x27;s my phone\" search petered out, we remembered Find My. No way, I thought. Rural road, many miles away, etc. Which new phone would you like, Dear?Find My immediately found it 43 miles away. My wife looked at Google Earth, identified the likely turnout and high-tailed it. She found it about five minutes after stopping at that turnout.There were enough passers-by with iOS devices that Find My worked as hoped. It amazed me that we got a little piece of our property back through operation of planetary-scale infrastructure. reply Maxion 5 hours agoparentEven with all the hate Apple gets in the tech sphere, they do have a lot of very handy features in their products. reply hunter2_ 4 hours agoparentprev> infrastructureImagine if anyone, not just Apple, could build on that, creating an automatic sneakernet. Populous areas without cell towers would come online, with ultra high latency. Throughput would also need to be throttled by the owner of each device to accommodate battery consumption preferences. reply audunw 4 hours agorootparentWe’re not that far off from the planet being covered with low bandwidth internet anyway.NB-IOT and LTE-M, along with the possibility that SpaceX can use Starlink satellites to provide low bandwidth LTE coverage, seems to give a viable path for global coverage soonOnly problem is that in the short term NB-IoT&#x2F;LTE-M devices are rather expensive, both upfront and monthly costs. Guess that will come down over time though reply AceJohnny2 2 hours agorootparentprev> Throughput would also need to be throttled by the owner of each device to accommodate battery consumption preferences.Ay, there&#x27;s the rub! reply LeoPanthera 1 hour agorootparentprevThird parties are allowed to use the Find My network. I have a Find My \"credit card\" in my wallet made by Chipolo. reply stavros 1 hour agorootparentNo they are not. They are allowed to create devices that can be found, but I can&#x27;t use my Android phone to find an AirTag. reply fastball 2 hours agorootparentprevApple let&#x27;s you build products for the Find My network. reply tinus_hn 2 hours agorootparentprevTile did exactly that. Except of course according to the privacy policy they track where everything and everyone is. reply spuz 2 hours agoparentprev> There were enough passers-by with iOS devices that Find My worked as hopedI&#x27;m not sure I understand why you would need nearby devices to locate your phone. The phone itself already had GPS and a network connection, right? reply katbyte 1 hour agorootparentFind my works without a network connection. So if the phone is lost without signal and another iOS device comes in range it will remember seeing it, and then upload the location to apple for the devices owner to see when it has internet again. reply gauravphoenix 9 hours agoprevThis reminds me of the kind of hack I came up with, almost 20 years back. I used to work in Bangalore, and now and then, we would have a power outage in the evening that lasts for a few hours. I was single and used to live alone. I did not want to go home from the office and find myself without power. So how do I find out there is power at home? During those days, there were no IOT devices so checking them is that&#x27;s out of the question. But I did have a landline phone that was powered by electricity and had a replaceable battery as a backup. I used the phone only to connect to the internet. So I just removed the batteries and when the power goes out, my phone wouldn&#x27;t &#x27;t work. So before leaving work, all I had to do was call my landline. If it rings, it means there is power. reply darkwater 2 hours agoparentHow long was the commute from office to home? Depending on this you still had risks of phone working while at the office, power out when back home, no? reply codetiger 6 hours agoparentprevGood one, Living in a place like that, I can understand how important it is. :) reply jen729w 3 hours agoprevBack in the mid-90s my dad lost his car keys. Turns out they were in his dressing gown (we’re British) pocket, in the wardrobe.So he bought one of those keyrings where you whistle and it beeps. This was a Saturday and we were visiting my grandparents, his parents. He told his dad, by now with a mild case of the Alzheimers, that he’d got this thing and that “you beep and it tells you where your keys are”.Well my grandad, who never drove a car let alone used a computer, his mind was blown. He just had no idea how this thing could do that.This went on for a few minutes.Dad, increasingly frustrated: “you just beep and it tells you where your keys are!”Grandad, increasingly confused: “... but ... how?!”It turns out that my grandad was imagining that you whistled and that this little device shouted out, “they’re in your dressing-gown pocket!” reply stavros 1 hour agoparentTo be fair, if someone said to me \"you just beep\", I&#x27;d also be confused as to how exactly I can beep. reply tgsovlerkhgsel 1 hour agoprevIf you ever connected to a network with a hidden SSID (or one where the phone thought the SSID was hidden for some reason), the phone will actively beacon for that WiFi, including the \"hidden\" SSID.This is obviously harder to use for searching for the phone than the method they used, but it&#x27;s a privacy nightmare you should be aware of. Hiding SSIDs is almost always a really bad idea for this reason. reply speedgoose 58 minutes agoparentThat’s an interesting design flaw. You connect to a hidden wifi network once and then your device will emit the ssid when you are not connected to a wifi network, or all the time? reply janus 9 hours agoprevHa, last winter I lost my phone while snowboarding in the last 300-500m before mountain base. I noticed because I was listening to music with my airpods when I got to the bottom the music had gone silent. Thankfully I had my Apple watch with me, so I immediately got off the board and start running uphill while incessantly spamming the \"ping my phone\" button. At some point I saw in the watch screen it briefly connected and then immediately disconnected again. I realized somebody had probably grabbed it and skied by me. I went back running to the chairlift while still spamming the button and finally found the person who had grabbed it, a few seconds before he got into the chairlift. I felt that day that the watch investment had been worth it hah. reply lxgr 9 hours agoparentMy friend was able to retrieve his phone that had just been pickpocketed out of his backpack that way!\"Hey, did you just grab my phone\" can take some courage to say to a stranger; \"Hey, I can hear my phone ringing in your bag when I press this button!\" was much more convincing. reply pestatije 8 hours agorootparentcan you not power-off an iphone without unlocking? reply lxgr 8 hours agorootparentYou can; the thief just didn’t get to do that because they were busy getting away in a non-conspicuous way.But even turned off, “Find my” stays active these days (although you can no longer make it ring, I believe). reply oldbbsnickname 7 hours agorootparentThat option can be disabled by turning off \"Find My network\" such that the phone will be off and radio silent. With it on, it will continue to beacon until the battery reaches the final BMS low voltage point. reply oldbbsnickname 7 hours agorootparentprevDisassemble and remove the battery. I can do this in about 1-2 minutes, others more skilled can do it inImagine like, an airtag, but the ID only needs to be 1 byte long,Well, then you could only ever track 255 different tags :)AirTags are already pretty minimal. Their battery lasts about a year, and I imagine an open source equivalent should be possible to build for under $5.This is purely guesstimated based on the fact that I have a couple of Bluetooth LE thermometer&#x2F;hygrometers that cost me about $3 a piece that last about a year on the same battery (CR2032) – and these run custom firmware and need to run a display and data logger (to on-chip flash) as well! reply juanuicich 8 hours agorootparentApparently there are Find My compatible generic tags coming out of China already, and they cost less than $5, shipping included. I say apparently because I’m still waiting for one to arrive and test. reply lxgr 8 hours agorootparentInteresting! I would have thought that Apple would add some sort of tamper-proof hardware authentication mechanism, given how expensive and privacy-sensitive AirTags are. reply sroussey 5 hours agorootparentThey opened it up to avoid anti-trust issues. reply r00fus 8 hours agorootparentprevThis sounds awesome - got a link? reply Guest71022 7 hours agorootparenthttps:&#x2F;&#x2F;a.aliexpress.com&#x2F;_mrvl4Xq reply ornornor 5 hours agorootparentInteresting. Although your link is 11.70$ with 50% off for me, but if you search for “find my Apple” you get many more results with lots of options around 5$ reply hrrsn 4 hours agorootparentThey seem to come up in the home page deals section quite often for me. I grabbed a couple that were $3.50 a pop, and so far they&#x27;ve behaved exactly like an Airtag (albeit with a worse speaker) reply ornornor 4 hours agorootparentNeat. Are they also water resistant (splashes&#x2F;rain)? reply petemir 2 hours agorootparentprevThat link is less than 2usd (1.62chf) for me. I’ll never understand Ali’s pricing. replyimp0cat 5 hours agorootparentprevA year is a long time, but you can also get a CR2032 to USB converter and use that as a constant power source.Why? If you&#x27;re using your smart tag to track your car, you can hide it somewhere deep inside and connect it to the vehicle&#x27;s battery so it always has power. Then you never have to worry about changing batteries. reply eternityforest 6 hours agorootparentprevYou&#x27;d just have to have IDs repeat, and software that could tell the difference based on signal strength. If you have two on the same ID that have different RSSI, show them as two tags.You&#x27;d have to do some guesswork though to figure out what&#x27;s going on but it would be better than nothing, and you might be able to get the size down below what CR2032 allows. reply alexwasserman 10 hours agoprevI assumed it would be Bluetooth. Walking&#x2F;driving around with headphones powered on waiting to pair.WiFi network mirroring is smart. reply grepfru_it 8 hours agoparent>wifi network mirroring is smartYep, so smart that I used to name my WiFi “McDonald’s Free WiFi” when I lived half a block from McDonald’s. Everyone’s phones would connect but to my goatse’d image network.I thought devices would start remembering the base station MAC addresses to avoid hijacking but I guess not.. maybe I should start doing this again at my local Home DepotEdit: just remembered I used to do this on planes too. I would MiTM the AP and people would connect to my WiFi device. Then I would serve an obvious incorrect Bank of America page. No one logged in to it though :( reply userbinator 8 hours agorootparentI thought devices would start remembering the base station MAC addresses to avoid hijackingThe use of multiple APs with the same SSID is a feature, not a bug. It enables roaming between them. reply oldbbsnickname 7 hours agorootparentCreating rogue APs is criminal-adjacent, unethical behavior because it denies and interferes with a network. It could even be criminalized in some jurisdictions. reply mensetmanusman 7 hours agorootparentTell that to Xfinity. reply oldbbsnickname 6 hours agorootparentComcast can die screaming, fiery deaths with rapid reincarnation between them.The were the only ISP in a certain suburban wooded area. During planned power outages they would go out after ~16 hours because they failed to engineer survivability (choice of electrical circuits and backup power) as the cell phone networks, municipal water, and other critical services did. reply olyjohn 6 hours agorootparentprevWell they are exempt from most laws. reply deathanatos 7 hours agorootparentprev… I suppose an unprotected network is always unprotected, but it is still possible¹ to have AP roaming while detecting that you&#x27;re switching to a different network of APs, even if the name is the same.¹within a protocol design \"possible\". WiFi can&#x27;t, AFAIK, actually do it. reply hunter2_ 4 hours agorootparentThe client could be made to drop a connection if various things are too different (default gateway not matching, for example) but it would be pretty janky with false positives and false negatives... replyjukea 9 hours agoprevI once found my phone buried in the sand on a beach with no coverage. I had a year worth of pictures on it, so I stewed in anguish for almost a day until we thought about installing a Bluetooth signal monitor on a friend’s phone . Given the sluggish update frequency, we resorted to triangulating the phone’s position. As we were pulling it from its sandy grave, I swear it felt like we were cheating fate itself. reply lxgr 9 hours agoparentI recovered a lost device (satellite messenger in my case) via Bluetooth as well! It had just fallen into some ferns a meter or so off the trail, but without Bluetooth I&#x27;m sure I&#x27;d have never found it again. reply WanderPanda 9 hours agoparentprevNot to nitpick but I think you mean trilaterate ;) reply lxgr 9 hours agorootparentIf we&#x27;re being nitpicky it was probably neither – multilateration requires taking multiple measurements, drawing circles&#x2F;lines of equal signal strength (or timing advance) and then intersecting these.If you just want to home in on a transmitter, there&#x27;s a much simpler algorithm: Try walking into various directions and keep heading into the one that makes the signal strength nunber go up :) Not sure if there&#x27;s a name for that. reply dharmab 9 hours agorootparentDirection finding! https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Direction_finding reply lxgr 9 hours agorootparentI was looking at that too, but doesn&#x27;t that usually imply using a directional antenna, rather than just measuring the received signal strength at different locations? reply aarghh 8 hours agorootparentNope - as everyone who has looked for a buried avalanche beacon knows. As a matter of fact, depending on the number of burials and the searchers, your optimal search technique may be different. reply jffry 9 hours agorootparentprev> Not sure if there&#x27;s a name for that.Hill climbing! https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Hill_climbingBasically: Go in any direction that makes the number go up. Repeat. reply petemir 2 hours agorootparentGradient ascent? reply fsckboy 8 hours agorootparentprevyou need a second rule: \"Don&#x27;t go in any direction that makes the number go down.\" That way, when you&#x27;re on top of it, you know to stop. reply freshboy69 7 hours agorootparentNo you don&#x27;t. Go in the upward direction implies don&#x27;t go in the downward direction reply smegsicle 6 hours agorootparentprev\"warmer colder\" reply jukea 8 hours agorootparentprevNice one, Yep this is it. We drew 3 rough circles and found the intersection reply tkk13909 7 hours agoparentprevAnd this, kids, is why we back up everything reply nehal3m 1 hour agoprev>Largely beautiful as this country is, as you get into more rural areas, there&#x27;s a high chance you won&#x27;t have cell phone coverage there - I&#x27;ll leave it as an exercise to the reader to choose if that&#x27;s a feature or a bug.>We&#x27;d already called and sent some WhatsApp messages, so we knew the phone wasn&#x27;t reachable.How did they do that without coverage? reply speedgoose 1 hour agoparentYou call from an area with coverage. Sometimes it’s enough to walk a little bit to be on the other side of a hill for example. reply itpcc 1 hour agoparentprevMaybe with their place&#x27;s Wi-Fi? reply squarefoot 4 hours agoprevEmbedding a LoRa module in the phone could come handy in similar situations; it could trigger a timed transmission of the latest known position before a given event, say a big bump followed by no movement or usage for X time, too long exposition to temperature and humidity incompatible with a house, etc. LoRa allows transmission at impressive distances using very low power compared to WiFi and other systems; a phone configured to turn itself off and use just the LoRa module to repeat a very short + say every 10 minutes wouldn&#x27;t tax the spectrum too much (RF in that context is a very scarce resource) and its battery would likely last weeks. reply andromaton 9 hours agoprevIf all else fails, build your own Stingray.https:&#x2F;&#x2F;www.hackers-arise.com&#x2F;post&#x2F;software-defined-radio-pa... reply monsterofcookie 10 hours agoprevWait until dark, shine a flashlight around and look for reflection off the glass. Or use a metal detector... reply Scoundreller 10 hours agoparentNote to self: put a piece of retroreflective tape on my phone.(I already have a roll of DOT stuff for bicycles, required on the front and rear forks if riding at night) reply kgabis 13 minutes agorootparentI did that with my dji drone, figured that when I eventually crash it and it ends up in some dense foliage, I could just go back at night and look for it with my torch looking for shiny 3M reflective tape. reply m463 11 hours agoprevI thought \"find my\" on newer iphones could do local non-cellular location services, like airtags. reply dan_linder 10 hours agoparentThey can, but the AirTag has to be \"seen\" by another connected device and that device must relay the GPS position it was \"seen\" at.I don&#x27;t know if Apple IOS is correct enough to log the time and position of AirTags when the device itself is disconnected from a network... reply solardev 10 hours agorootparentThe newer devices can locate each other via ultrawideband triangulation too, completely detached from the cell network. They have special chips for this built-in: https:&#x2F;&#x2F;www.pocket-lint.com&#x2F;phones&#x2F;news&#x2F;apple&#x2F;149336-how-app... reply acdha 9 hours agorootparentprevIt’ll show up in Find My even if it can’t connect to the internet. BLE and UWB both work offline. reply sergers 10 hours agorootparentprevSamsung has their own \"offline finding\" as they call it, if enabled other Samsung devices&#x2F;wearables can locate it somehow, brief on how that&#x27;s done on their site reply Scoundreller 10 hours agorootparentprevI wonder how well the relay phone does store and forward, I guess it does otherwise AirTags are useless outside of cellular footprint territory.I guess sometimes a late ping is better than no ping. reply marcod 10 hours agoprevSo, there is no security feature that prevents a phone from connecting to a cloned wifi network?? reply nineteen999 10 hours agoparentIf the SSID and password are the same, how would the phone tell the difference? I don&#x27;t know.My Fitbit has a \"find my phone\" feature that uses Bluetooth to tell the Fitbit app on the phone to make a loud whistle. It&#x27;s kind of handy and ive made use of it several times around my house, but obviously isn&#x27;t useful outside Bluetooth range. reply flashback2199 10 hours agorootparent> If the SSID and password are the same, how would the phone tell the differenceMAC address, but devices don&#x27;t care, by design they will connect if the SSID and encryption type are the same, actually, you can create a mesh wifi network at your house with regular routers or access points by doing so, connecting them with wired ethernet. reply eternityforest 10 hours agorootparentWhich is a very good thing, otherwise you wouldn&#x27;t be able to replace a router and have stuff just work. reply pests 9 hours agorootparentThe last time I did we did a WiFi password change at my house there were near 100 devices that had to be updated. Such a hassle. Thankfully it&#x27;s stayed the same over 4 routers and about 7 years. reply dclowd9901 5 hours agorootparentprevOrrrrr the protocol would just be smart enough to say “hey, we are thinking of connecting to this network but the MAC address is different — did you recently switch base stations?” reply eternityforest 4 hours agorootparentAs long as screenless devices and other unattended things like light bulbs didn&#x27;t need manual intervention, and it was easy to turn off the checks on a Linux server, it would be cool.But it would probably be an annoyance in large multi hotspot environments, and could become another thing to train people to mindlessly click through like cookie prompts. reply HPsquared 10 hours agorootparentprevMAC address can of course be spoofed easily as well. reply namibj 9 hours agorootparentprevESSID != BSSID. The former meant for UX, the latter to uniquely identify. Wpa_didn&#x27;t allows fixing the latter, for example, as needed when you hang out at multiple locations where the wifi has the default ESSID, but of course with distinct passwords. Causes authentication timeout&#x2F;lockout annoyance if left alone. reply lxgr 9 hours agorootparentThat&#x27;s a pretty annoying situation, yes.Fortunately many default network names at least contain some randomness these days, e.g. three bytes of an access point&#x27;s BSSID, to make this less likely.That&#x27;s also the proper fix – pinning a WPA password to an individual BSSID would go against the concept of encryption being scoped to an ESS&#x2F;ESSID, not individual APs. reply dhosek 10 hours agoparentprevHow can you tell a wifi network is cloned if the SSID&#x2F;password match? After all, it might legitimately be a new legitimate access point in the network. reply rkachowski 45 minutes agorootparentThe BSSID won&#x27;t match reply redox99 10 hours agorootparentprevObivously using certificates and TOFU. APs would share the certificate.(That&#x27;s how it should work, not how it does in practice) reply cj 10 hours agorootparentI’ve always wondered how commonly black hats clone and exploit mass deployed public SSIDs like the “xfinitywifi” network you see in all major US cities with xfinity.Presumably you could get a lot of random devices to automatically connect and then hijack DNS to cause trouble. reply solardev 10 hours agorootparentEven if you hijacked DNS, most things are HTTPS now and you&#x27;d have to get a copy of a certificate from a trusted CA. reply lazide 9 hours agorootparentprevAt least 50% of such APs I ran across didn’t work right. I chalk it up to broken implementation on the ISP side, but a decent number may be issues like this. reply lxgr 9 hours agorootparentprevIt&#x27;s not that easy, unfortunately: Many networks span more than one access point, either simultaneously or across time (mediocre CPEs are notoriously being swapped out all the time by cable providers, in my experience).Initially loading and then synchronizing certificates across APs would be anything but trivial.I&#x27;ve surprised my friends a few times by keeping my SSID + password constant over the years and across several moves within the city (and across ISPs) and even internationally – whenever they come to my place, they have Wi-Fi the second they step through the door :)It&#x27;s also nice not having to re-configure various embedded devices, many without a sane user interface to type a passphrase or even accept a new TOFU public key, every time I set up a new router at my family&#x27;s place. reply lxgr 9 hours agorootparentprevExactly, if the SSID and password match, it is the same network by definition. reply jeroenhd 9 hours agoparentprevEither \"enterprise\" WiFi or, if your device supports it, locking down the MAC address. That&#x27;ll give you range issues if you use mesh wifi, range extenders, or additional access points, though.I don&#x27;t know why more devices don&#x27;t support WPA Enterprise, it&#x27;s not _that_ complicated a protocol. I can imagine a \"secure router\" product with a normal WPA3 network for management and an \"enterprise\" network with a simple username&#x2F;password list selling quite well in some niche circles.You can build such a network yourself, though, with almost any OpenWRT device, though it&#x27;s clearly not something most end users can manage themselves: https:&#x2F;&#x2F;github.com&#x2F;ouaibe&#x2F;howto&#x2F;blob&#x2F;master&#x2F;OpenWRT&#x2F;802.1xOn... reply lxgr 9 hours agoparentprevThere&#x27;s not really such thing as a cloned wifi network conceptually: If you set up a new access point using the same SSID and encryption settings, you didn&#x27;t clone a network – you just extended it by one more access point&#x2F;location where it&#x27;s available!A Wi-Fi network is the abstract concept of \"all access points using the same name and passphrase\", not an individual instance of an access point.If you connect the two access points (e.g. using wired Ethernet), clients can actually roam between the two fairly seamlessly without any other setup required, and this even works across brands! reply progman32 4 hours agorootparentOne thing to keep in mind re: roaming - devices tend to \"stick\" with their current AP even though there&#x27;s a perfectly good same-SSID AP with much better strength available. There are protocols that can orchestrate between APs to \"kick\" stubborn devices to better APs: 802.11r, 802.11k, and 802.11v. reply brink 10 hours agoparentprev99.9% of people don&#x27;t consider this an issue, I&#x27;d rather there not be one in the spec. It&#x27;s just unnecessary complication. If you&#x27;re the genuinely paranoid 0.1%, write a script. reply JCharante 9 hours agoparentprevEnterprise networking hardware has protections against this by attacking other access points. Example from cisco: https:&#x2F;&#x2F;community.cisco.com&#x2F;t5&#x2F;wireless&#x2F;wlc-quot-rogue-conta... reply solardev 10 hours agoparentprevYeah, back in the day before HTTPS was common, this used to be a viable attack where people would set up rogue hotspots at cafes and whatnot and intercept all your traffic. reply lxgr 9 hours agorootparentThat&#x27;s only possible for unencrypted networks&#x2F;SSIDs, though. reply solardev 8 hours agorootparentI think that&#x27;s a different attack, where you could passively sniff wifi traffic from networks without WEP. I meant more just hosting your own hotspot with a popular name, forcing clients to connect to it via disconnect&#x2F;reconnect attacks, and then you&#x27;re essentially a tiny MITM ISP that can monitor all their unencrypted traffic reply lxgr 8 hours agorootparent> hosting your own hotspot with a popular name, forcing clients to connect to it via disconnect&#x2F;reconnect attacksYou can only do that for unencrypted networks or those for which you know the passphrase, though. reply solardev 8 hours agorootparentYes, like most public hotspot in cafes, schools, libraries, etc where the password is readily shared. replydarkarmani 9 hours agoparentprev802.1x. At least that was what could be used 12 years ago. I don&#x27;t know about state of the art now. reply LordShredda 10 hours agoparentprevAssuming you kept the password a secret, how would you create an identical wifi clone? reply addandsubtract 9 hours agorootparentLAX_FREE_AIRPORT_WIFI reply ruined 10 hours agoparentprev802.1x eap reply atoav 2 hours agoprevMy brother dropped his iPhone during a powder snow traversal down the back of the mountain to a hut.We found it accidentally during a hike in the summer, when the snow was gone.Always be prepared to lose everything. reply askvictor 10 hours agoprevWhat&#x27;s the difference in signal strength between bluetooth and wifi? I had assumed since they use the same frequency, and usually the same chip and antenna, they would be much the same (perhaps there are regulatory differences between them?) If anything, I&#x27;d guess that BLE would be more useful in this case as there is less handshaking, which means on a very poor connection you&#x27;ve got more of a chance of getting some data through. reply Someone 2 hours agoparent> I had assumed since they use the same frequency, and usually the same chip and antennaYes and no. Bluetooth is 2.4GHz, WiFi has many bands, including one around 2.4GHz. Those can share an antenna, but I think that means only one can be sending at a time (they could mix the signals, but I guess that would mean connection would fail for the less powerful Bluetooth signal)https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Bluetooth:“It employs UHF radio waves in the ISM bands, from 2.402 GHz to 2.48 GHz”https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;List_of_WLAN_channels:“The 802.11 standard provides several distinct radio frequency bands for use in Wi-Fi communications: 860&#x2F;900 MHz, 2.4 GHz, 3.6 GHz, 4.9 GHz, 5 GHz, 5.9 GHz, 6 GHz, 45 GHz and 60 GHz. Each range is divided into a multitude of channels. In the standards, channels are numbered at 5 MHz spacing within a band (except in the 45&#x2F;60 GHz band, where they are 0.54&#x2F;1.08&#x2F;2.16 GHz apart), and the number linearly relates to the centre frequency of the channel. Although channels are numbered at 5 MHz spacing, transmitters generally occupy at least 20 MHz, and standards allow for channels to be bonded together to form wider channels for faster throughput.Countries apply their own regulations to allowable channels, allowed users and maximum power levels within these frequency ranges. The ISM band ranges are also often used.” reply sllabres 5 hours agoparentprevI&#x27;ve been using three AirTags and two of the cheaper clones mentioned above. I can activate both about 100m away in the forest, if there is a line of sight.On the other hand, i can walk an entire day through the forest (with some other people around every now and then) without a single position update from the tag. reply lxgr 9 hours agoparentprevDepends on the Bluetooth device class.Most devices are Class 2, with a maximum transmit power of only 2.5 mW; that&#x27;s not a lot compared to Wi-Fi&#x27;s ~20-30 mW.AirPods are notably Class 1, which goes up to almost 20 mW! They accordingly have much better range as a result.Bluetooth LE in newer version has new low-bitrate coding methods to allow for even greater ranges (called \"Coded PHY\"). Assuming Bluetooth LE classes are the same as for EDR (I don&#x27;t know if they are!), this source [1] claims a 4 times greater range using coded PHY, which would be in the range of several hundred meters.[1] https:&#x2F;&#x2F;www.bluetooth.com&#x2F;blog&#x2F;exploring-bluetooth-5-going-t... reply willcipriano 9 hours agoparentprev> What&#x27;s the difference in signal strength between bluetooth and wifi?Big in my experience. 15 - 20 feet vs 100+ feet for wifi out in the open like that. reply secsubsc 6 hours agoprevI did something very similar to connect my Amazon Fire-stick with my new TV at a different place when I had lost the remote (of Fire-stick). The TV remote was helpful, but only after I could connect the Fire-stick with a working Internet connection.I remembered my old home&#x27;s wifi SSID and password, so created a hotspot on my phone with the same SSID and password, and the Fire-stick got connected. All went good after that. reply eternauta3k 5 hours agoprevI thought he was going to find it by its local oscillator emissions like the TV detector vans https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;TV_detector_van reply wslh 7 hours agoprevA few years ago I also found my mobile phone in Mar del Plata, Argentina, after a young horse passed over my daughter... it was using the find me option in a Fitbit watch linked to a Samsung mobile phone.My daughter was perfectly fine, but that is another story: fingers crossed, she has some special powers. reply userbinator 8 hours agoprevBefore reading, I thought it would be about a https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Nonlinear_junction_detector ; but then again, that can find not just lost phones but other electronics too. reply derelicta 1 hour agoprevThis is surprisingly smart reply dzhiurgis 10 hours agoprevWalk around shouting Hey Siri reply theendisney2 8 hours agoprevIn my job I regularly wonder how to get a found phone laptop or notebook back to their owner. The notebook is the easiest. The apple laptop the most stupid. I have the locked laptop i have my iphone you would think, with the closed eco-system, there to be some magic ritual i can perform for the laptop to register on the owners \"find my device\"???? Or at least let me type a number for them to call?Sometimes, (if i charge the phone) eventually contacts real names appear on the home screen. This seems just the information one shouldn&#x27;t be sharing?It is really odd how garbage the tech is here. reply dicknuckle 8 hours agoparentOn my Android phone, the homescreen can have a short message, I changed it to \"If found, call {wife&#x27;s phone number}\" reply theendisney2 8 hours agorootparentI know, great in theory but i havent seen one where it was configured. You can also configure a phone number to call. No one apparently does that.The solution needs to not require any configuration.You can call your own phone of course but then i have to keep it charged. If it dies the sim locks. reply bayesianbot 7 hours agoprevI use this sometimes when I can&#x27;t find my daughter in a large shop - just turn on my wifi tethering and when I have a device connected, I know she&#x27;s nearby. reply Agent766 7 hours agoprevHere&#x27;s a fun question, after the device connected to the wifi hotspot, would the \"find my\" feature work? reply gwill 11 hours agoprevthis is pretty smart, i didn&#x27;t realize the hotspot tells you how many connections there are although i don&#x27;t really use mine. my mind went straight to bluetooth pairing. reply stevage 4 hours agoprev [–] Wow, that&#x27;s pretty creative. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The author recounts their story of locating a misplaced phone in a remote, cell-service-less area during camping via clever use of tech.",
      "Using the tethering function of their own phone, they replicated the home wifi network of the lost phone, assigning it the same name and password.",
      "They moved around the area until a connection to the hotspot was detected, which directly led them to the lost phone, indicating an ingenious and practical application of technical expertise."
    ],
    "commentSummary": [
      "The article reviews personal experiences of using Apple's 'Find My' feature to track stolen items, like AirPods and a MacBook, emphasizing both successful and unsuccessful endeavors.",
      "It delves into the technological aspects of 'Find My', specifically the use of Bluetooth and WiFi, as well as the potential of developing open-source trackers for enhanced tracking capabilities.",
      "Despite lauding the convenience offered by 'Find My', it points out the limitations of the current technology and expresses individuals' frustration with them."
    ],
    "points": 255,
    "commentCount": 168,
    "retryCount": 0,
    "time": 1698271082
  },
  {
    "id": 38013477,
    "title": "Internet Artifact Museum",
    "originLink": "https://neal.fun/internet-artifacts/",
    "originBody": "1977 1982 1983 1985 1987 1988 1989 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 Internet Artifacts YOU MAY TOUCH THE ARTIFACTS Enter Map of ARPANET A map of ARPANET, the precursor to the internet, showing the 111 computer terminals connected to the network in 1977. ARPANET was created by the Department of Defense to allow researchers to share information and resources. The network was initially limited to universities and research institutions. By 1983, ARPANET had over 4,000 connected computers and a growing number of e-mail users. The ARPANET completion report concluded that \"the full impact of the technical changes set in motion by this project may not be understood for many years.\" MAIL-FROM: DEC-MARLBORO RCVD AT 3-MAY-78 0955-PDT DATE: 1 MAY 1978 1233-EDT FROM: THUERK AT DEC-MARLBORO SUBJECT: ADRIAN@SRI-KL TO: DDAY@SRI-KL, DAY@SRI-KL, DEBOER@UCLA-CCN... CC: BPM@SU-AI DIGITAL WILL BE GIVING A PRODUCT PRESENTATION OF THE NEWEST MEMBERS OF THE DECSYSTEM-20 FAMILY; THE DECSYSTEM-2020, 2020T, 2060, AND 2060T. THE DECSYSTEM-20 FAMILY OF COMPUTERS HAS EVOLVED FROM THE TENEX OPERATING SYSTEM AND THE DECSYSTEM-10COMPUTER ARCHITECTURE. BOTH THE DECSYSTEM-2060T AND 2020T OFFER FULL ARPANET SUPPORT UNDER THE TOPS-20 OPERATING SYSTEM. THE DECSYSTEM-2060 IS AN UPWARD EXTENSION OF THE CURRENT DECSYSTEM 2040 AND 2050 FAMILY. THE DECSYSTEM-2020 IS A NEW LOW END MEMBER OF THE DECSYSTEM-20 FAMILY AND FULLY SOFTWARE COMPATIBLE WITH ALL OF THE OTHER DECSYSTEM-20 MODELS. WE INVITE YOU TO COME SEE THE 2020 AND HEAR ABOUT THE DECSYSTEM-20 FAMILY AT THE TWO PRODUCT PRESENTATIONS WE WILL BE GIVING IN CALIFORNIA THIS MONTH. THE LOCATIONS WILL BE: TUESDAY, MAY 9, 1978 - 2 PM HYATT HOUSE (NEAR THE L.A. AIRPORT) LOS ANGELES, CA THURSDAY, MAY 11, 1978 - 2 PM DUNFEY'S ROYAL COACH SAN MATEO, CA (4 MILES SOUTH OF S.F. AIRPORT AT BAYSHORE, RT 101 AND RT 92) A 2020 WILL BE THERE FOR YOU TO VIEW. ALSO TERMINALS ON-LINE TO OTHER DECSYSTEM-20 SYSTEMS THROUGH THE ARPANET. IF YOU ARE UNABLE TO ATTEND, PLEASE FEEL FREE TO CONTACT THE NEAREST DEC OFFICE FOR MORE INFORMATION ABOUT THE EXCITING DECSYSTEM-20 FAMILY. First SPAM Email The first spam email was sent by Gary Thuerk, a marketing manager for the Digital Equipment Corporation. Thuerk sent the email to 320 recipients on ARPANET, advertising a product presentation of the new DECSYSTEM-20 mainframe computers. The reaction to the email was overwhelmingly negative: one user claimed it broke his computer system, and the US Defense Communications Agency called his company to complain. Thuerk claims he sold $13 to $14 million worth of mainframe computers through the campaign. The term \"spam\" would not be used until years later, after being inspired by a Monty Python sketch. 17-SEP-82 15:15 ANTHONY AT CMU-780G (*%) HOW ABOUT USING * FOR GOOD JOKES AND % FOR BAD JOKES? WE COULD EVEN USE *% FOR JOKES THAT ARE SO BAD, THEY'RE FUNNY. 019-SEP-82 11:44 SCOTT E FAHLMAN :-) I PROPOSE THAT THE FOLLOWING CHARACTER SEQUENCE FOR JOKE MARKERS: :-) READ IT SIDEWAYS. ACTUALLY, IT IS PROBABLY MORE ECONOMICAL TO MARK THINGS THAT ARE NOT JOKES, GIVEN CURRENT TRENDS. FOR THIS, USE :-( First Smiley The first recorded use of a smiley on the internet came in 1982, when computer scientist Scott Fahlman proposed the use of :-) and :-( to distinguish between jokes and serious posts online. The proposal came in response to a post on the Carnegie Mellon University bulletin board, where a student joked that there was a mercury spill in the physics department’s elevator. Other students missed context for the joke and thought a spill actually occurred. The smileys were slowly adopted throughout Carnegie Mellon and later to the broader internet. The Hacker's Dictionary @BEGIN (primarily CMU) with @END, used humorously in writing to indicate a context or to remark on the surrounded text. From the SCRIBE command of the same name. For example: @Begin(Flame) Predicate logic is the only good programming language. Anyone who would use anything else is an idiot. Also, computers should be tredecimal instead of binary. @End(Flame) ANGLE BRACKETS (primarily MIT) n. Either of the characters \"\". See BROKET. AOS (aus (East coast) ay-ahs (West coast)) [based on a PDP-10 increment instruction] v. To increase the amount of something. \"Aos the campfire.\" Usage: considered silly. See SOS. ARG n. Abbreviation for \"argument\" (to a function), used so often as to have become a new word. AUTOMAGICALLY adv. Automatically, but in a way which, for some reason (typically because it is too complicated, or too ugly, or perhaps even too trivial), I don't feel like explaining to you. See MAGIC. Example: Some programs which produce XGP output files spool them automagically. BAGBITER 1. n. Equipment or program that fails, usually intermittently. 2. BAGBITING: adj. Failing hardware or software. \"This bagbiting system won't let me get out of spacewar.\" Usage: verges on obscenity. Grammatically separable; one may speak of \"biting the bag\". Synonyms: LOSER, LOSING, CRETINOUS, BLETCHEROUS, BARFUCIOUS, CHOMPER, CHOMPING. BANG n. Common alternate name for EXCL (q.v.), especially at CMU. See SHRIEK. BAR 1. The second metasyntactic variable, after FOO. \"Suppose we have two functions FOO and BAR. FOO calls BAR...\" 2. Often appended to FOO to produce FOOBAR. BARF [from the \"layman\" slang, meaning \"vomit\"] 1. interj. Term of disgust. See BLETCH. 2. v. Choke, as on input. May mean to give an error message. \"The function `=' compares two fixnums or two flonums, and barfs on anything else.\" 3. BARFULOUS, BARFUCIOUS: adj. Said of something which would make anyone barf, if only for aesthetic reasons. BELLS AND WHISTLES n. Unnecessary but useful (or amusing) features of a program. \"Now that we've got the basic program working, let's go back and add some bells and whistles.\" Nobody seems to know what distinguishes a bell from a whistle. BIGNUMS [from Macsyma] n. 1. In backgammon, large numbers on the dice. 2. Multiple-precision (sometimes infinitely extendable) integers and, through analogy, any very large numbers. 3. EL CAMINO BIGNUM: El Camino Real, a street through the San Francisco peninsula that originally extended (and still appears in places) all the way to Mexico City. It was termed \"El Camino Double Precision\" when someone noted it was a very long street, and then \"El Camino Bignum\" when it was pointed out that it was hundreds of miles long. BIN [short for BINARY; used as a second file name on ITS] 1. n. BINARY. 2. BIN FILE: A file containing the BIN for a program. Usage: used at MIT, which runs on ITS. The equivalent term at Stanford is DMP (pronounced \"dump\") FILE. Other names used include SAV (\"save\") FILE (DEC and Tenex), SHR (\"share\") and LOW FILES (DEC), and EXE (\"ex'ee\") FILE (DEC and Twenex). Also in this category are the input files to the various flavors of linking loaders (LOADER, LINK-10, STINK), called REL FILES. BINARY n. The object code for a program. BIT n. 1. The unit of information; the amount of information obtained by asking a yes-or-no question. \"Bits\" is often used simply to mean information, as in \"Give me bits about DPL replicators\". 2. [By extension from \"interrupt bits\" on a computer] A reminder that something should be done or talked about eventually. Upon seeing someone that you haven't talked to for a while, it's common for one or both to say, \"I have a bit set for you.\" BITBLT (bit'blit) 1. v. To perform a complex operation on a large block of bits, usually involving the bits being displayed on a bitmapped raster screen. See BLT. 2. n. The operation itself. BIT BUCKET n. 1. A receptacle used to hold the runoff from the computer's shift registers. 2. Mythical destination of deleted files, GC'ed memory, and other no-longer-accessible data. 3. The physical device associated with \"NUL:\". BLETCH [from German \"brechen\", to vomit (?)] 1. interj. Term of disgust. 2. BLETCHEROUS: adj. Disgusting in design or function. \"This keyboard is bletcherous!\" Usage: slightly comic. BLT (blit, very rarely belt) [based on the PDP-10 block transfer instruction; confusing to users of the PDP-11] 1. v. To transfer a large contiguous package of information from one place to another. 2. THE BIG BLT: n. Shuffling operation on the PDP- 10 under some operating systems that consumes a significant amount of computer time. 3. (usually pronounced B-L-T) n. Sandwich containing bacon, lettuce, and tomato. BOGOSITY n. The degree to which something is BOGUS (q.v.). At CMU, bogosity is measured with a bogometer; typical use: in a seminar, when a speaker says something bogus, a listener might raise his hand and say, \"My bogometer just triggered.\" The agreed-upon unit of bogosity is the microLenat (uL). BOGUS (WPI, Yale, Stanford) adj. 1. Non-functional. \"Your patches are bogus.\" 2. Useless. \"OPCON is a bogus program.\" 3. False. \"Your arguments are bogus.\" 4. Incorrect. \"That algorithm is bogus.\" 5. Silly. \"Stop writing those bogus sagas.\" (This word seems to have some, but not all, of the connotations of RANDOM.) [Etymological note from Lehman/Reid at CMU: \"Bogus\" was originally used (in this sense) at Princeton, in the late 60's. It was used not particularly in the CS department, but all over campus. It came to Yale, where one of us (Lehman) was an undergraduate, and (we assume) elsewhere through the efforts of Princeton alumni who brought the word with them from their alma mater. In the Yale case, the alumnus is Michael Shamos, who was a graduate student at Yale and is now a faculty member here. A glossary of bogus words was compiled at Yale when the word was first popularized (e.g., autobogophobia: the fear of becoming bogotified).] BOUNCE (Stanford) v. To play volleyball. \"Bounce, bounce! Stop wasting time on the computer and get out to the court!\" BRAIN-DAMAGED [generalization of \"Honeywell Brain Damage\" (HBD), a theoretical disease invented to explain certain utter cretinisms in Multics] adj. Obviously wrong; cretinous; demented. There is an implication that the person responsible must have suffered brain damage, because he should have known better. Calling something brain-damaged is really bad; it also implies it is unusable. BREAK v. 1. To cause to be broken (in any sense). \"Your latest patch to the system broke the TELNET server.\" 2. (of a program) To stop temporarily, so that it may be examined for debugging purposes. The place where it stops is a BREAKPOINT. BROKEN adj. 1. Not working properly (of programs). 2. Behaving strangely; especially (of people), exhibiting extreme depression. BROKET [by analogy with \"bracket\": a \"broken bracket\"] (primarily Stanford) n. Either of the characters \"\". (At MIT, and apparently in The Real World (q.v.) as well, these are usually called ANGLE BRACKETS.) BUCKY BITS (primarily Stanford) n. The bits produced by the CTRL and META shift keys on a Stanford (or Knight) keyboard. Rumor has it that the idea for extra bits for characters came from Niklaus Wirth, and that his nickname was `Bucky'. DOUBLE BUCKY: adj. Using both the CTRL and META keys. \"The command to burn all LEDs is double bucky F.\" BUG [from telephone terminology, \"bugs in a telephone cable\", blamed for noisy lines; however, Jean Sammet has repeatedly been heard to claim that the use of the term in CS comes from a story concerning actual bugs found wedged in an early malfunctioning computer] n. An unwanted and unintended property of a program. (People can have bugs too (even winners) as in \"PHW is a super winner, but he has some bugs.\") See FEATURE. BUM 1. v. To make highly efficient, either in time or space, often at the expense of clarity. The object of the verb is usually what was removed (\"I managed to bum three more instructions.\") but can be the program being changed (\"I bummed the inner loop down to seven microseconds.\") 2. n. A small change to an algorithm to make it more efficient. BUZZ v. To run in a very tight loop, perhaps without guarantee of getting out. CANONICAL adj. The usual or standard state or manner of something. A true story: One Bob Sjoberg, new at the MIT AI Lab, expressed some annoyance at the use of jargon. Over his loud objections, we made a point of using jargon as much as possible in his presence, and eventually it began to sink in. Finally, in one conversation, he used the word \"canonical\" in jargon-like fashion without thinking. Steele: \"Aha! We've finally got you talking jargon too!\" Stallman: \"What did he say?\" Steele: \"He just used `canonical' in the canonical way.\" CATATONIA (kat-uh-toe'nee-uh) n. A condition of suspended animation in which the system is in a wedged (CATATONIC) state. CDR (ku'der) [from LISP] v. With \"down\", to trace down a list of elements. \"Shall we cdr down the agenda?\" Usage: silly. CHINE NUAL n. The Lisp Machine Manual, so called because the title is wrapped around the cover so only those letters show. CHOMP v. To lose; to chew on something of which more was bitten off than one can. Probably related to gnashing of teeth. See BAGBITER. A hand gesture commonly accompanies this, consisting of the four fingers held together as if in a mitten or hand puppet, and the fingers and thumb open and close rapidly to illustrate a biting action. The gesture alone means CHOMP CHOMP (see Verb Doubling). CLOSE n. Abbreviation for \"close (or right) parenthesis\", used when necessary to eliminate oral ambiguity. See OPEN. COKEBOTTLE n. Any very unusual character. MIT people complain about the \"control-meta-cokebottle\" commands at SAIL, and SAIL people complain about the \"altmode-altmode-cokebottle\" commands at MIT. COM MODE (variant: COMM MODE) [from the ITS feature for linking two or more terminals together so that text typed on any is echoed on all, providing a means of conversation among hackers] n. The state a terminal is in when linked to another in this way. Com mode has a special set of jargon words, used to save typing, which are not used orally. CONNECTOR CONSPIRACY [probably came into prominence with the appearance of the KL-10, none of whose connectors match anything else] n. The tendency of manufacturers (or, by extension, programmers or purveyors of anything) to come up with new products which don't fit together with the old stuff, thereby making you buy either all new stuff or expensive interface devices. CONS [from LISP] 1. v. To add a new element to a list. 2. CONS UP: v. To synthesize from smaller pieces: \"to cons up an example\". CRASH 1. n. A sudden, usually drastic failure. Most often said of the system (q.v., definition # 1), sometimes of magnetic disk drives. \"Three lusers lost their files in last night's disk crash.\" A disk crash which entails the read/write heads dropping onto the surface of the disks and scraping off the oxide may also be referred to as a \"head crash\". 2. v. To fail suddenly. \"Has the system just crashed?\" Also used transitively to indicate the cause of the crash (usually a person or a program, or both). \"Those idiots playing spacewar crashed the system.\" Sometimes said of people. See GRONK OUT. CRETIN 1. n. Congenital loser (q.v.). 2. CRETINOUS: adj. See BLETCHEROUS and BAGBITING. Usage: somewhat ad hominem. CRLF (cur'lif, sometimes crul'lif) n. A carriage return (CR) followed by a line feed (LF). See TERPRI. CROCK [probably from \"layman\" slang, which in turn may be derived from \"crock of shit\"] n. An awkward feature or programming technique that ought to be made cleaner. Example: Using small integers to represent error codes without the program interpreting them to the user is a crock. Also, a technique that works acceptably but which is quite prone to failure if disturbed in the least, for example depending on the machine opcodes having particular bit patterns so that you can use instructions as data words too; a tightly woven, almost completely unmodifiable structure. CRUFTY [from \"cruddy\"] adj. 1. Poorly built, possibly overly complex. \"This is standard old crufty DEC software\". Hence CRUFT, n. shoddy construction. Also CRUFT, v. [from hand cruft, pun on hand craft] to write assembler code for something normally (and better) done by a compiler. 2. Unpleasant, especially to the touch, often with encrusted junk. Like spilled coffee smeared with peanut butter and catsup. Hence CRUFT, n. disgusting mess. 3. Generally unpleasant. CRUFTY or CRUFTIE n. A small crufty object (see FROB); often one which doesn't fit well into the scheme of things. \"A LISP property list is a good place to store crufties (or, random cruft).\" [Note: Does CRUFT have anything to do with the Cruft Lab at Harvard? I don't know, though I was a Harvard student. - GLS] CRUNCH v. 1. To process, usually in a time-consuming or complicated way. Connotes an essentially trivial operation which is nonetheless painful to perform. The pain may be due to the triviality being imbedded in a loop from 1 to 1000000000. \"FORTRAN programs do mostly number crunching.\" 2. To reduce the size of a file by a complicated scheme that produces bit configurations completely unrelated to the original data, such as by a Huffman code. (The file ends up looking like a paper document would if somebody crunched the paper into a wad.) Since such compression usually takes more computations than simpler methods such as counting repeated characters (such as spaces) the term is doubly appropriate. (This meaning is usually used in the construction \"file crunch(ing)\" to distinguish it from \"number crunch(ing)\".) 3. n. The character \"#\". Usage: used at Xerox and CMU, among other places. Other names for \"#\" include SHARP, NUMBER, HASH, PIG-PEN, POUND-SIGN, and MESH. GLS adds: I recall reading somewhere that most of these are names for the # symbol IN CONTEXT. The name for the sign itself is \"octothorp\". CTY (city) n. The terminal physically associated with a computer's operating console. CUSPY [from the DEC acronym CUSP, for Commonly Used System Program, i.e., a utility program used by many people] (WPI) adj. 1. (of a program) Well-written. 2. Functionally excellent. A program which performs well and interfaces well to users is cuspy. See RUDE. DAEMON (day'mun, dee'mun) [archaic form of \"demon\", which has slightly different connotations (q.v.)] n. A program which is not invoked explicitly, but which lays dormant waiting for some condition(s) to occur. The idea is that the perpetrator of the condition need not be aware that a daemon is lurking (though often a program will commit an action only because it knows that it will implicitly invoke a daemon). For example, writing a file on the lpt spooler's directory will invoke the spooling daemon, which prints the file. The advantage is that programs which want (in this example) files printed need not compete for access to the lpt. They simply enter their implicit requests and let the daemon decide what to do with them. Daemons are usually spawned automatically by the system, and may either live forever or be regenerated at intervals. Usage: DAEMON and DEMON (q.v.) are often used interchangeably, but seem to have distinct connotations. DAEMON was introduced to computing by CTSS people (who pronounced it dee'mon) and used it to refer to what is now called a DRAGON or PHANTOM (q.v.). The meaning and pronunciation have drifted, and we think this glossary reflects current usage. DAY MODE See PHASE (of people). DEADLOCK n. A situation wherein two or more processes are unable to proceed because each is waiting for another to do something. A common example is a program communicating to a PTY or STY, which may find itself waiting for output from the PTY/STY before sending anything more to it, while the PTY/STY is similarly waiting for more input from the controlling program before outputting anything. (This particular flavor of deadlock is called \"starvation\". Another common flavor is \"constipation\", where each process is trying to send stuff to the other, but all buffers are full because nobody is reading anything.) See DEADLY EMBRACE. DEADLY EMBRACE n. Same as DEADLOCK (q.v.), though usually used only when exactly two processes are involved. DEADLY EMBRACE is the more popular term in Europe; DEADLOCK in the United States. DEMENTED adj. Yet another term of disgust used to describe a program. The connotation in this case is that the program works as designed, but the design is bad. For example, a program that generates large numbers of meaningless error messages implying it is on the point of imminent collapse. DEMON (dee'mun) n. A portion of a program which is not invoked explicitly, but which lays dormant waiting for some condition(s) to occur. See DAEMON. The distinction is that demons are usually processes within a program, while daemons are usually programs running on an operating system. Demons are particularly common in AI programs. For example, a knowledge manipulation program might implement inference rules as demons. Whenever a new piece of knowledge was added, various demons would activate (which demons depends on the particular piece of data) and would create additional pieces of knowledge by applying their respective inference rules to the original piece. These new pieces could in turn activate more demons as the inferences filtered down through chains of logic. Meanwhile the main program could continue with whatever its primary task was. DIABLO (dee-ah'blow) [from the Diablo printer] 1. n. Any letter- quality printing device. 2. v. To produce letter-quality output from such a device. DIDDLE v. To work with in a not particularly serious manner. \"I diddled with a copy of ADVENT so it didn't double-space all the time.\" \"Let's diddle this piece of code and see if the problem goes away.\" See TWEAK and TWIDDLE. DIKE [from \"diagonal cutters\"] v. To remove a module or disable it. \"When in doubt, dike it out.\" DMP (dump) See BIN. DO PROTOCOL [from network protocol programming] v. To perform an interaction with somebody or something that follows a clearly defined procedure. For example, \"Let's do protocol with the check\" at a restaurant means to ask the waitress for the check, calculate the tip and everybody's share, generate change as necessary, and pay the bill. DOWN 1. adj. Not working. \"The up escalator is down.\" 2. TAKE DOWN, BRING DOWN: v. To deactivate, usually for repair work. See UP. DPB (duh-pib') [from the PDP-10 instruction set] v. To plop something down in the middle. DRAGON n. (MIT) A program similar to a \"daemon\" (q.v.), except that it is not invoked at all, but is instead used by the system to perform various secondary tasks. A typical example would be an accounting program, which keeps track of who is logged in, accumulates load- average statistics, etc. At MIT, all free TV's display a list of people logged in, where they are, what they're running, etc. along with some random picture (such as a unicorn, Snoopy, or the Enterprise) which is generated by the \"NAME DRAGON\". See PHANTOM. DWIM [Do What I Mean] 1. adj. Able to guess, sometimes even correctly, what result was intended when provided with bogus input. Often suggested in jest as a desired feature for a complex program. A related term, more often seen as a verb, is DTRT (Do The Right Thing). 2. n. The INTERLISP function that attempts to accomplish this feat by correcting many of the more common errors. See HAIRY. ENGLISH n. The source code for a program, which may be in any language, as opposed to BINARY. Usage: slightly obsolete, used mostly by old-time hackers, though recognizable in context. At MIT, directory SYSENG is where the \"English\" for system programs is kept, and SYSBIN, the binaries. SAIL has many such directories, but the canonical one is [CSP,SYS]. EPSILON [from standard mathematical notation for a small quantity] 1. n. A small quantity of anything. \"The cost is epsilon.\" 2. adj. Very small, negligible; less than marginal (q.v.). \"We can get this feature for epsilon cost.\" 3. WITHIN EPSILON OF: Close enough to be indistinguishable for all practical purposes. EXCH (ex'chuh, ekstch) [from the PDP-10 instruction set] v. To exchange two things, each for the other. EXCL (eks'cul) n. Abbreviation for \"exclamation point\". See BANG, SHRIEK, WOW. EXE (ex'ee) See BIN. FAULTY adj. Same denotation as \"bagbiting\", \"bletcherous\", \"losing\", q.v., but the connotation is much milder. FEATURE n. 1. A surprising property of a program. Occasionally documented. To call a property a feature sometimes means the author of the program did not consider the particular case, and the program makes an unexpected, although not strictly speaking an incorrect response. See BUG. \"That's not a bug, that's a feature!\" A bug can be changed to a feature by documenting it. 2. A well-known and beloved property; a facility. Sometimes features are planned, but are called crocks by others. An approximately correct spectrum: FEEP 1. n. The soft bell of a display terminal (except for a VT-52!); a beep. 2. v. To cause the display to make a feep sound. TTY's do not have feeps. Alternate forms: BEEP, BLEEP, or just about anything suitably onomatopoeic. The term BREEDLE is sometimes heard at SAIL, where the terminal bleepers are not particularly \"soft\" (they sound more like the musical equivalent of sticking out one's tongue). The \"feeper\" on a VT-52 has been compared to the sound of a '52 Chevy stripping its gears. FENCEPOST ERROR n. The discrete equivalent of a boundary condition. Often exhibited in programs by iterative loops. From the following problem: \"If you build a fence 100 feet long with posts ten feet apart, how many posts do you need?\" (Either 9 or 11 is a better answer than the obvious 10.) FINE (WPI) adj. Good, but not good enough to be CUSPY. [The word FINE is used elsewhere, of course, but without the implicit comparison to the higher level implied by CUSPY.] FLAG DAY [from a bit of Multics history involving a change in the ASCII character set originally scheduled for June 14, 1966] n. A software change which is neither forward nor backward compatible, and which is costly to make and costly to revert. \"Can we install that without causing a flag day for all users?\" FLAKEY adj. Subject to frequent lossages. See LOSSAGE. FLAME v. To speak incessantly and/or rabidly on some relatively uninteresting subject or with a patently ridiculous attitude. FLAME ON: v. To continue to flame. See RAVE. This punning reference to Marvel comics' Human Torch has been lost as recent usage completes the circle: \"Flame on\" now usually means \"beginning of flame\". FLAP v. To unload a DECtape (so it goes flap, flap, flap...). Old hackers at MIT tell of the days when the disk was device 0 and microtapes were 1, 2,... and attempting to flap device 0 would instead start a motor banging inside a cabinet near the disk! FLAVOR n. 1. Variety, type, kind. \"DDT commands come in two flavors.\" See VANILLA. 2. The attribute of causing something to be FLAVORFUL. \"This convention yields additional flavor by allowing one to...\" 3. On the LispMachine, an object-oriented programming system (\"flavors\"); each class of object is a flavor. FLAVORFUL adj. Aesthetically pleasing. See RANDOM and LOSING for antonyms. See also the entry for TASTE. FLUSH v. 1. To delete something, usually superfluous. \"All that nonsense has been flushed.\" Standard ITS terminology for aborting an output operation. 2. To leave at the end of a day's work (as opposed to leaving for a meal). \"I'm going to flush now.\" \"Time to flush.\" 3. To exclude someone from an activity. FOO 1. [from Yiddish \"feh\" or the Anglo-Saxon \"fooey!\"] interj. Term of disgust. 2. [from FUBAR (Fucked Up Beyond All Recognition), from WWII, often seen as FOOBAR] Name used for temporary programs, or samples of three-letter names. Other similar words are BAR, BAZ (Stanford corruption of BAR), and rarely RAG. These have been used in Pogo as well. 3. Used very generally as a sample name for absolutely anything. The old `Smokey Stover' comic strips often included the word FOO, in particular on license plates of cars. MOBY FOO: See MOBY. FRIED adj. 1. Non-working due to hardware failure; burnt out. 2. Of people, exhausted. Said particularly of those who continue to work in such a state. Often used as an explanation or excuse. \"Yeah, I know that fix destroyed the file system, but I was fried when I put it in.\" FROB 1. n. (MIT) The official Tech Model Railroad Club definition is \"FROB = protruding arm or trunnion\", and by metaphoric extension any somewhat small thing. See FROBNITZ. 2. v. Abbreviated form of FROBNICATE. FROBNICATE v. To manipulate or adjust, to tweak. Derived from FROBNITZ (q.v.). Usually abbreviated to FROB. Thus one has the saying \"to frob a frob\". See TWEAK and TWIDDLE. Usage: FROB, TWIDDLE, and TWEAK sometimes connote points along a continuum. FROB connotes aimless manipulation; TWIDDLE connotes gross manipulation, often a coarse search for a proper setting; TWEAK connotes fine-tuning. If someone is turning a knob on an oscilloscope, then if he's carefully adjusting it he is probably tweaking it; if he is just turning it but looking at the screen he is probably twiddling it; but if he's just doing it because turning a knob is fun, he's frobbing it. FROBNITZ, pl. FROBNITZEM (frob'nitsm) n. An unspecified physical object, a widget. Also refers to electronic black boxes. This rare form is usually abbreviated to FROTZ, or more commonly to FROB. Also used are FROBNULE, FROBULE, and FROBNODULE. Starting perhaps in 1979, FROBBOZ (fruh-bahz'), pl. FROBBOTZIM, has also become very popular, largely due to its exposure via the Adventure spin-off called Zork (Dungeon). These can also be applied to non-physical objects, such as data structures. FROG (variant: PHROG) 1. interj. Term of disgust (we seem to have a lot of them). 2. Used as a name for just about anything. See FOO. 3. n. Of things, a crock. Of people, somewhere inbetween a turkey and a toad. 4. Jake Brown (FRG@SAIL). 5. FROGGY: adj. Similar to BAGBITING (q.v.), but milder. \"This froggy program is taking forever to run!\" FROTZ 1. n. See FROBNITZ. 2. MUMBLE FROTZ: An interjection of very mild disgust. FRY v. 1. To fail. Said especially of smoke-producing hardware failures. 2. More generally, to become non-working. Usage: never said of software, only of hardware and humans. See FRIED. FTP (spelled out, NOT pronounced \"fittip\") 1. n. The File Transfer Protocol for transmitting files between systems on the ARPAnet. 2. v. To transfer a file using the File Transfer Program. \"Lemme get this copy of Wuthering Heights FTP'd from SAIL.\" FUDGE 1. v. To perform in an incomplete but marginally acceptable way, particularly with respect to the writing of a program. \"I didn't feel like going through that pain and suffering, so I fudged it.\" 2. n. The resulting code. FUDGE FACTOR n. A value or parameter that is varied in an ad hoc way to produce the desired result. The terms \"tolerance\" and \"slop\" are also used, though these usually indicate a one-sided leeway, such as a buffer which is made larger than necessary because one isn't sure exactly how large it needs to be, and it is better to waste a little space than to lose completely for not having enough. A fudge factor, on the other hand, can often be tweaked in more than one direction. An example might be the coefficients of an equation, where the coefficients are varied in an attempt to make the equation fit certain criteria. GABRIEL [for Dick Gabriel, SAIL volleyball fanatic] n. An unnecessary (in the opinion of the opponent) stalling tactic, e.g., tying one's shoelaces or hair repeatedly, asking the time, etc. Also used to refer to the perpetrator of such tactics. Also, \"pulling a Gabriel\", \"Gabriel mode\". GARBAGE COLLECT v., GARBAGE COLLECTION n. See GC. GARPLY n. (Stanford) Another meta-word popular among SAIL hackers. GAS [as in \"gas chamber\"] interj. 1. A term of disgust and hatred, implying that gas should be dispensed in generous quantities, thereby exterminating the source of irritation. \"Some loser just reloaded the system for no reason! Gas!\" 2. A term suggesting that someone or something ought to be flushed out of mercy. \"The system's wedging every few minutes. Gas!\" 3. v. FLUSH (q.v.). \"You should gas that old crufty software.\" 4. GASEOUS adj. Deserving of being gassed. Usage: primarily used by Geoff Goodfellow at SRI, but spreading. GC [from LISP terminology] 1. v. To clean up and throw away useless things. \"I think I'll GC the top of my desk today.\" 2. To recycle, reclaim, or put to another use. 3. To forget. The implication is often that one has done so deliberately. 4. n. An instantiation of the GC process. GEDANKEN [from Einstein's term \"gedanken-experimenten\", such as the standard proof that E=mc^2] adj. An AI project which is written up in grand detail without ever being implemented to any great extent. Usually perpetrated by people who aren't very good hackers or find programming distasteful or are just in a hurry. A gedanken thesis is usually marked by an obvious lack of intuition about what is programmable and what is not and about what does and does not constitute a clear specification of a program-related concept such as an algorithm. GLASS TTY n. A terminal which has a display screen but which, because of hardware or software limitations, behaves like a teletype or other printing terminal. An example is the ADM-3 (without cursor control). A glass tty can't do neat display hacks, and you can't save the output either. GLITCH [from the Yiddish \"glitshen\", to slide] 1. n. A sudden interruption in electric service, sanity, or program function. Sometimes recoverable. 2. v. To commit a glitch. See GRITCH. 3. v. (Stanford) To scroll a display screen. GLORK 1. interj. Term of mild surprise, usually tinged with outrage, as when one attempts to save the results of two hours of editing and finds that the system has just crashed. 2. Used as a name for just about anything. See FOO. 3. v. Similar to GLITCH (q.v.), but usually used reflexively. \"My program just glorked itself.\" GOBBLE v. To consume or to obtain. GOBBLE UP tends to imply \"consume\", while GOBBLE DOWN tends to imply \"obtain\". \"The output spy gobbles characters out of a TTY output buffer.\" \"I guess I'll gobble down a copy of the documentation tomorrow.\" See SNARF. GORP (CMU) [perhaps from the generic term for dried hiker's food, stemming from the acronym \"Good Old Raisins and Peanuts\"] Another metasyntactic variable, like FOO and BAR. GRIND v. 1. (primarily MIT) To format code, especially LISP code, by indenting lines so that it looks pretty. Hence, PRETTY PRINT, the generic term for such operations. 2. To run seemingly interminably, performing some tedious and inherently useless task. Similar to CRUNCH. GRITCH 1. n. A complaint (often caused by a GLITCH (q.v.)). 2. v. To complain. Often verb-doubled: \"Gritch gritch\". 3. Glitch. GROK [from the novel \"Stranger in a Strange Land\", by Robert Heinlein, where it is a Martian word meaning roughly \"to be one with\"] v. To understand, usually in a global sense. GRONK [popularized by the cartoon strip \"B.C.\" by Johnny Hart, but the word apparently predates that] v. 1. To clear the state of a wedged device and restart it. More severe than \"to frob\" (q.v.). 2. To break. \"The teletype scanner was gronked, so we took the system down.\" 3. GRONKED: adj. Of people, the condition of feeling very tired or sick. 4. GRONK OUT: v. To cease functioning. Of people, to go home and go to sleep. \"I guess I'll gronk out now; see you all tomorrow.\" GROVEL v. To work interminably and without apparent progress. Often used with \"over\". \"The compiler grovelled over my code.\" Compare GRIND and CRUNCH. Emphatic form: GROVEL OBSCENELY. GRUNGY adj. Incredibly dirty or grubby. Anything which has been washed within the last year is not really grungy. Also used metaphorically; hence some programs (especially crocks) can be described as grungy. GUBBISH [a portmanteau of \"garbage\" and \"rubbish\"?] n. Garbage; crap; nonsense. \"What is all this gubbish?\" GUN [from the GUN command on ITS] v. To forcibly terminate a program or job (computer, not career). \"Some idiot left a background process running soaking up half the cycles, so I gunned it.\" HACK n. 1. Originally a quick job that produces what is needed, but not well. 2. The result of that job. 3. NEAT HACK: A clever technique. Also, a brilliant practical joke, where neatness is correlated with cleverness, harmlessness, and surprise value. Example: the Caltech Rose Bowl card display switch circa 1961. 4. REAL HACK: A crock (occasionally affectionate). v. 5. With \"together\", to throw something together so it will work. 6. To bear emotionally or physically. \"I can't hack this heat!\" 7. To work on something (typically a program). In specific sense: \"What are you doing?\" \"I'm hacking TECO.\" In general sense: \"What do you do around here?\" \"I hack TECO.\" (The former is time-immediate, the latter time-extended.) More generally, \"I hack x\" is roughly equivalent to \"x is my bag\". \"I hack solid-state physics.\" 8. To pull a prank on. See definition 3 and HACKER (def #6). 9. v.i. To waste time (as opposed to TOOL). \"Watcha up to?\" \"Oh, just hacking.\" 10. HACK UP (ON): To hack, but generally implies that the result is 1-2. 11. HACK VALUE: Term used as the reason or motivation for expending effort toward a seemingly useless goal, the point being that the accomplished goal is a hack. For example, MacLISP has code to read and print roman numerals, which was installed purely for hack value. HAPPY HACKING: A farewell. HOW'S HACKING?: A friendly greeting among hackers. HACK HACK: A somewhat pointless but friendly comment, often used as a temporary farewell. [The word HACK doesn't really have 69 different meanings. In fact, HACK has only one meaning, an extremely subtle and profound one which defies articulation. Which connotation a given HACK-token has depends in similarly profound ways on the context. Similar comments apply to a couple other hacker jargon items, most notably RANDOM. - Agre] HACKER [originally, someone who makes furniture with an axe] n. 1. A person who enjoys learning the details of programming systems and how to stretch their capabilities, as opposed to most users who prefer to learn only the minimum necessary. 2. One who programs enthusiastically, or who enjoys programming rather than just theorizing about programming. 3. A person capable of appreciating hack value (q.v.). 4. A person who is good at programming quickly. Not everything a hacker produces is a hack. 5. An expert at a particular program, or one who frequently does work using it or on it; example: \"A SAIL hacker\". (Definitions 1 to 5 are correlated, and people who fit them congregate.) 6. A malicious or inquisitive meddler who tries to discover information by poking around. Hence \"password hacker\", \"network hacker\". HACKISH adj. Being or involving a hack. HACKISHNESS n. HAIR n. The complications which make something hairy. \"Decoding TECO commands requires a certain amount of hair.\" Often seen in the phrase INFINITE HAIR, which connotes extreme complexity. HAIRY adj. 1. Overly complicated. \"DWIM is incredibly hairy.\" 2. Incomprehensible. \"DWIM is incredibly hairy.\" 3. Of people, high-powered, authoritative, rare, expert, and/or incomprehensible. Hard to explain except in context: \"He knows this hairy lawyer who says there's nothing to worry about.\" HAKMEM n. MIT AI Memo 239 (February 1972). A collection of neat mathematical and programming hacks contributed by many people at MIT and elsewhere. HANDWAVE 1. v. To gloss over a complex point; to distract a listener; to support a (possibly actually valid) point with blatantly faulty logic. 2. n. The act of handwaving. \"Boy, what a handwave!\" The use of this word is often accompanied by gestures: both hands up, palms forward, swinging the hands in a vertical plane pivoting at the elbows and/or shoulders (depending on the magnitude of the handwave); alternatively, holding the forearms still while rotating the hands at the wrist to make them flutter. In context, the gestures alone can suffice as a remark. HARDWARILY adv. In a way pertaining to hardware. \"The system is hardwarily unreliable.\" The adjective \"hardwary\" is NOT used. See SOFTWARILY. HELLO WALL See WALL. HIRSUTE Occasionally used humorously as a synonym for HAIRY. HOOK n. An extraneous piece of software or hardware included in order to simplify later additions or debug options. For instance, a program might execute a location that is normally a JFCL, but by changing the JFCL to a PUSHJ one can insert a debugging routine at that point. HUMONGOUS, HUMUNGOUS See HUNGUS. HUNGUS (hung'ghis) [perhaps related to current slang \"humongous\"; which one came first (if either) is unclear] adj. Large, unwieldy, usually unmanageable. \"TCP is a hungus piece of code.\" \"This is a hungus set of modifications.\" IMPCOM See TELNET. INFINITE adj. Consisting of a large number of objects; extreme. Used very loosely as in: \"This program produces infinite garbage.\" IRP (erp) [from the MIDAS pseudo-op which generates a block of code repeatedly, substituting in various places the car and/or cdr of the list(s) supplied at the IRP] v. To perform a series of tasks repeatedly with a minor substitution each time through. \"I guess I'll IRP over these homework papers so I can give them some random grade for this semester.\" JFCL (djif'kl or dja-fik'l) [based on the PDP-10 instruction that acts as a fast no-op] v. To cancel or annul something. \"Why don't you jfcl that out?\" [The licence plate on Geoff Goodfellow's BMW is JFCL.] JIFFY n. 1. Interval of CPU time, commonly 1/60 second or 1 millisecond. 2. Indeterminate time from a few seconds to forever. \"I'll do it in a jiffy\" means certainly not now and possibly never. JOCK n. Programmer who is characterized by large and somewhat brute force programs. The term is particularly well-suited for systems programmers. J. RANDOM See RANDOM. JRST (jerst) [based on the PDP-10 jump instruction] v. To suddenly change subjects. Usage: rather rare. \"Jack be nimble, Jack be quick; Jack jrst over the candle stick.\" JSYS (jay'sis), pl. JSI (jay'sigh) [Jump to SYStem] See UUO. KLUGE (kloodj) alt. KLUDGE [from the German \"kluge\", clever] n. 1. A Rube Goldberg device in hardware or software. 2. A clever programming trick intended to solve a particular nasty case in an efficient, if not clear, manner. Often used to repair bugs. Often verges on being a crock. 3. Something that works for the wrong reason. 4. v. To insert a kluge into a program. \"I've kluged this routine to get around that weird bug, but there's probably a better way.\" Also KLUGE UP. 5. KLUGE AROUND: To avoid by inserting a kluge. 6. (WPI) A feature which is implemented in a RUDE manner. LDB (lid'dib) [from the PDP-10 instruction set] v. To extract from the middle. LIFE n. A cellular-automata game invented by John Horton Conway, and first introduced publicly by Martin Gardner (Scientific American, October 1970). LINE FEED (standard ASCII terminology) 1. v. To feed the paper through a terminal by one line (in order to print on the next line). 2. n. The \"character\" which causes the terminal to perform this action. LINE STARVE (MIT) Inverse of LINE FEED. LOGICAL [from the technical term \"logical device\", wherein a physical device is referred to by an arbitrary name] adj. Understood to have a meaning not necessarily corresponding to reality. E.g., if a person who has long held a certain post (e.g., Les Earnest at SAIL) left and was replaced, the replacement would for a while be known as the \"logical Les Earnest\". The word VIRTUAL is also used. At SAIL, \"logical\" compass directions denote a coordinate system in which \"logical north\" is toward San Francisco, \"logical west\" is toward the ocean, etc., even though logical north varies between physical (true) north near SF and physical west near San Jose. (The best rule of thumb here is that El Camino Real by definition always runs logical north-and-south.) LOSE [from MIT jargon] v. 1. To fail. A program loses when it encounters an exceptional condition. 2. To be exceptionally unaesthetic. 3. Of people, to be obnoxious or unusually stupid (as opposed to ignorant). 4. DESERVE TO LOSE: v. Said of someone who willfully does the wrong thing; humorously, if one uses a feature known to be marginal. What is meant is that one deserves the consequences of one's losing actions. \"Boy, anyone who tries to use MULTICS deserves to lose!\" LOSE LOSE - a reply or comment on a situation. LOSER n. An unexpectedly bad situation, program, programmer, or person. Especially \"real loser\". LOSS n. Something which loses. WHAT A (MOBY) LOSS!: interjection. LOSSAGE n. The result of a bug or malfunction. LPT (lip'it) n. Line printer, of course. LUSER See USER. MACROTAPE n. An industry standard reel of tape, as opposed to a MICROTAPE. MAGIC adj. 1. As yet unexplained, or too complicated to explain. (Arthur C. Clarke once said that magic was as-yet-not-understood science.) \"TTY echoing is controlled by a large number of magic bits.\" \"This routine magically computes the parity of an eight-bit byte in three instructions.\" 2. (Stanford) A feature not generally publicized which allows something otherwise impossible, or a feature formerly in that category but now unveiled. Example: The keyboard commands which override the screen-hiding features. MARGINAL adj. 1. Extremely small. \"A marginal increase in core can decrease GC time drastically.\" See EPSILON. 2. Of extremely small merit. \"This proposed new feature seems rather marginal to me.\" 3. Of extremely small probability of winning. \"The power supply was rather marginal anyway; no wonder it crapped out.\" 4. MARGINALLY: adv. Slightly. \"The ravs here are only marginally better than at Small Eating Place.\" MICROTAPE n. Occasionally used to mean a DECtape, as opposed to a MACROTAPE. This was the official DEC term for the stuff until someone consed up the word \"DECtape\". MISFEATURE n. A feature which eventually screws someone, possibly because it is not adequate for a new situation which has evolved. It is not the same as a bug because fixing it involves a gross philosophical change to the structure of the system involved. Often a former feature becomes a misfeature because a tradeoff was made whose parameters subsequently changed (possibly only in the judgment of the implementors). \"Well, yeah, it's kind of a misfeature that file names are limited to six characters, but we're stuck with it for now.\" MOBY [seems to have been in use among model railroad fans years ago. Entered the world of AI with the Fabritek 256K moby memory of MIT-AI. Derived from Melville's \"Moby Dick\" (some say from \"Moby Pickle\").] 1. adj. Large, immense, or complex. \"A moby frob.\" 2. n. The maximum address space of a machine, hence 3. n. 256K words, the size of a PDP-10 moby. (The maximum address space means the maximum normally addressable space, as opposed to the amount of physical memory a machine can have. Thus the MIT PDP-10s each have two mobies, usually referred to as the \"low moby\" (0-777777) and \"high moby\" (1000000-1777777), or as \"moby 0\" and \"moby 1\". MIT-AI has four mobies of address space: moby 2 is the PDP-6 memory, and moby 3 the PDP-11 interface.) In this sense \"moby\" is often used as a generic unit of either address space (18. bits' worth) or of memory (about a megabyte, or 9/8 megabyte (if one accounts for difference between 32.- and 36.-bit words), or 5/4 megacharacters). 4. A title of address (never of third-person reference), usually used to show admiration, respect, and/or friendliness to a competent hacker. \"So, moby Knight, how's the CONS machine doing?\" 5. adj. In backgammon, doubles on the dice, as in \"moby sixes\", \"moby ones\", etc. MOBY FOO, MOBY WIN, MOBY LOSS: standard emphatic forms. FOBY MOO: a spoonerism due to Greenblatt. MODE n. A general state, usually used with an adjective describing the state. \"No time to hack; I'm in thesis mode.\" Usage: in its jargon sense, MODE is most often said of people, though it is sometimes applied to programs and inanimate objects. \"If you're on a TTY, E will switch to non-display mode.\" In particular, see DAY MODE, NIGHT MODE, and YOYO MODE; also COM MODE, TALK MODE, and GABRIEL MODE. MODULO prep. Except for. From mathematical terminology: one can consider saying that 4=22 \"except for the 9's\" (4=22 mod 9). \"Well, LISP seems to work okay now, modulo that GC bug.\" MOON n. 1. A celestial object whose phase is very important to hackers. See PHASE OF THE MOON. 2. Dave Moon (MOON@MC). MUMBLAGE n. The topic of one's mumbling (see MUMBLE). \"All that mumblage\" is used like \"all that stuff\" when it is not quite clear what it is or how it works, or like \"all that crap\" when \"mumble\" is being used as an implicit replacement for obscenities. MUMBLE interj. 1. Said when the correct response is either too complicated to enunciate or the speaker has not thought it out. Often prefaces a longer answer, or indicates a general reluctance to get into a big long discussion. \"Well, mumble.\" 2. Sometimes used as an expression of disagreement. \"I think we should buy it.\" \"Mumble!\" Common variant: MUMBLE FROTZ. 3. Yet another metasyntactic variable, like FOO. MUNCH (often confused with \"mung\", q.v.) v. To transform information in a serial fashion, often requiring large amounts of computation. To trace down a data structure. Related to CRUNCH (q.v.), but connotes less pain. MUNCHING SQUARES n. A display hack dating back to the PDP-1, which employs a trivial computation (involving XOR'ing of x-y display coordinates - see HAKMEM items 146-148) to produce an impressive display of moving, growing, and shrinking squares. The hack usually has a parameter (usually taken from toggle switches) which when well-chosen can produce amazing effects. Some of these, discovered recently on the LISP machine, have been christened MUNCHING TRIANGLES, MUNCHING W'S, and MUNCHING MAZES. MUNG (variant: MUNGE) [recursive acronym for Mung Until No Good] v. 1. To make changes to a file, often large-scale, usually irrevocable. Occasionally accidental. See BLT. 2. To destroy, usually accidentally, occasionally maliciously. The system only mungs things maliciously. N adj. 1. Some large and indeterminate number of objects; \"There were N bugs in that crock!\"; also used in its original sense of a variable name. 2. An arbitrarily large (and perhaps infinite) number. 3. A variable whose value is specified by the current context. \"We'd like to order N wonton soups and a family dinner for N-1.\" 4. NTH: adj. The ordinal counterpart of N. \"Now for the Nth and last time...\" In the specific context \"Nth-year grad student\", N is generally assumed to be at least 4, and is usually 5 or more. See also 69. NIGHT MODE See PHASE (of people). NIL [from LISP terminology for \"false\"] No. Usage: used in reply to a question, particularly one asked using the \"-P\" convention. See T. OBSCURE adj. Used in an exaggeration of its normal meaning, to imply a total lack of comprehensibility. \"The reason for that last crash is obscure.\" \"FIND's command syntax is obscure.\" MODERATELY OBSCURE implies that it could be figured out but probably isn't worth the trouble. OPEN n. Abbreviation for \"open (or left) parenthesis\", used when necessary to eliminate oral ambiguity. To read aloud the LISP form (DEFUN FOO (X) (PLUS X 1)) one might say: \"Open def-fun foo, open eks close, open, plus ekx one, close close.\" See CLOSE. PARSE [from linguistic terminology] v. 1. To determine the syntactic structure of a sentence or other utterance (close to the standard English meaning). Example: \"That was the one I saw you.\" \"I can't parse that.\" 2. More generally, to understand or comprehend. \"It's very simple; you just kretch the glims and then aos the zotz.\" \"I can't parse that.\" 3. Of fish, to have to remove the bones yourself (usually at a Chinese restaurant). \"I object to parsing fish\" means \"I don't want to get a whole fish, but a sliced one is okay.\" A \"parsed fish\" has been deboned. There is some controversy over whether \"unparsed\" should mean \"bony\", or also mean \"deboned\". PATCH 1. n. A temporary addition to a piece of code, usually as a quick-and-dirty remedy to an existing bug or misfeature. A patch may or may not work, and may or may not eventually be incorporated permanently into the program. 2. v. To insert a patch into a piece of code. PDL (piddle or puddle) [acronym for Push Down List] n. 1. A LIFO queue (stack); more loosely, any priority queue; even more loosely, any queue. A person's pdl is the set of things he has to do in the future. One speaks of the next project to be attacked as having risen to the top of the pdl. \"I'm afraid I've got real work to do, so this'll have to be pushed way down on my pdl.\" See PUSH and POP. 2. Dave Lebling (PDL@DM). PESSIMAL [Latin-based antonym for \"optimal\"] adj. Maximally bad. \"This is a pessimal situation.\" PESSIMIZING COMPILER n. A compiler that produces object code that is worse than the straightforward or obvious translation. PHANTOM n. (Stanford) The SAIL equivalent of a DRAGON (q.v.). Typical phantoms include the accounting program, the news-wire monitor, and the lpt and xgp spoolers. PHASE (of people) 1. n. The phase of one's waking-sleeping schedule with respect to the standard 24-hour cycle. This is a useful concept among people who often work at night according to no fixed schedule. It is not uncommon to change one's phase by as much as six hours/day on a regular basis. \"What's your phase?\" \"I've been getting in about 8 PM lately, but I'm going to work around to the day schedule by Friday.\" A person who is roughly 12 hours out of phase is sometimes said to be in \"night mode\". (The term \"day mode\" is also used, but less frequently.) 2. CHANGE PHASE THE HARD WAY: To stay awake for a very long time in order to get into a different phase. 3. CHANGE PHASE THE EASY WAY: To stay asleep etc. PHASE OF THE MOON n. Used humorously as a random parameter on which something is said to depend. Sometimes implies unreliability of whatever is dependent, or that reliability seems to be dependent on conditions nobody has been able to determine. \"This feature depends on having the channel open in mumble mode, having the foo switch set, and on the phase of the moon.\" PLUGH [from the Adventure game] v. See XYZZY. POM n. Phase of the moon (q.v.). Usage: usually used in the phrase \"POM dependent\" which means flakey (q.v.). POP [based on the stack operation that removes the top of a stack, and the fact that procedure return addresses are saved on the stack] dialect: POPJ (pop-jay), based on the PDP-10 procedure return instruction. v. To return from a digression. By verb doubling, \"Popj, popj\" means roughly, \"Now let's see, where were we?\" PPN (pip'in) [DEC terminology, short for Project-Programmer Number] n. 1. A combination `project' (directory name) and programmer name, used to identify a specific directory belonging to that user. For instance, \"FOO,BAR\" would be the FOO directory for user BAR. Since the name is restricted to three letters, the programmer name is usually the person's initials, though sometimes it is a nickname or other special sequence. (Standard DEC setup is to have two octal numbers instead of characters; hence the original acronym.) 2. Often used loosely to refer to the programmer name alone. \"I want to send you some mail; what's your ppn?\" Usage: not used at MIT, since ITS does not use ppn's. The equivalent terms would be UNAME and SNAME, depending on context, but these are not used except in their technical senses. PROTOCOL See DO PROTOCOL. PSEUDOPRIME n. A backgammon prime (six consecutive occupied points) with one point missing. PTY (pity) n. Pseudo TTY, a simulated TTY used to run a job under the supervision of another job. PTYJOB (pity-job) n. The job being run on the PTY. Also a common general-purpose program for creating and using PTYs. This is DEC and SAIL terminology; the MIT equivalent is STY. PUNT [from the punch line of an old joke: \"Drop back 15 yards and punt\"] v. To give up, typically without any intention of retrying. PUSH [based on the stack operation that puts the current information on a stack, and the fact that procedure call addresses are saved on the stack] dialect: PUSHJ (push-jay), based on the PDP-10 procedure call instruction. v. To enter upon a digression, to save the current discussion for later. QUES (kwess) 1. n. The question mark character (\"?\"). 2. interj. What? Also QUES QUES? See WALL. QUUX [invented by Steele. Mythically, from the Latin semi-deponent verb QUUXO, QUUXARE, QUUXANDUM IRI; noun form variously QUUX (plural QUUCES, Anglicized to QUUXES) and QUUXU (genitive plural is QUUXUUM, four U's in seven letters).] 1. Originally, a meta-word like FOO and FOOBAR. Invented by Guy Steele for precisely this purpose when he was young and naive and not yet interacting with the real computing community. Many people invent such words; this one seems simply to have been lucky enough to have spread a little. 2. interj. See FOO; however, denotes very little disgust, and is uttered mostly for the sake of the sound of it. 3. n. Refers to one of four people who went to Boston Latin School and eventually to MIT: THE GREAT QUUX: Guy L. Steele Jr. THE LESSER QUUX: David J. Littleboy THE MEDIOCRE QUUX: Alan P. Swide THE MICRO QUUX: Sam Lewis (This taxonomy is said to be similarly applied to three Frankston brothers at MIT.) QUUX, without qualification, usually refers to The Great Quux, who is somewhat infamous for light verse and for the \"Crunchly\" cartoons. 4. QUUXY: adj. Of or pertaining to a QUUX. RANDOM adj. 1. Unpredictable (closest to mathematical definition); weird. \"The system's been behaving pretty randomly.\" 2. Assorted; undistinguished. \"Who was at the conference?\" \"Just a bunch of random business types.\" 3. Frivolous; unproductive; undirected (pejorative). \"He's just a random loser.\" 4. Incoherent or inelegant; not well organized. \"The program has a random set of misfeatures.\" \"That's a random name for that function.\" \"Well, all the names were chosen pretty randomly.\" 5. Gratuitously wrong, i.e., poorly done and for no good apparent reason. For example, a program that handles file name defaulting in a particularly useless way, or a routine that could easily have been coded using only three ac's, but randomly uses seven for assorted non-overlapping purposes, so that no one else can invoke it without first saving four extra ac's. 6. In no particular order, though deterministic. \"The I/O channels are in a pool, and when a file is opened one is chosen randomly.\" n. 7. A random hacker; used particularly of high school students who soak up computer time and generally get in the way. 8. (occasional MIT usage) One who lives at Random Hall. J. RANDOM is often prefixed to a noun to make a \"name\" out of it (by comparison to common names such as \"J. Fred Muggs\"). The most common uses are \"J. Random Loser\" and \"J. Random Nurd\" (\"Should J. Random Loser be allowed to gun down other people?\"), but it can be used just as an elaborate version of RANDOM in any sense. [See also the note at the end of the entry for HACK.] RANDOMNESS n. An unexplainable misfeature; gratuitous inelegance. Also, a hack or crock which depends on a complex combination of coincidences (or rather, the combination upon which the crock depends). \"This hack can output characters 40-57 by putting the character in the accumulator field of an XCT and then extracting 6 bits -- the low two bits of the XCT opcode are the right thing.\" \"What randomness!\" RAPE v. To (metaphorically) screw someone or something, violently. Usage: often used in describing file-system damage. \"So-and-so was running a program that did absolute disk I/O and ended up raping the master directory.\" RAVE (WPI) v. 1. To persist in discussing a specific subject. 2. To speak authoritatively on a subject about which one knows very little. 3. To complain to a person who is not in a position to correct the difficulty. 4. To purposely annoy another person verbally. 5. To evangelize. See FLAME. Also used to describe a less negative form of blather, such as friendly bullshitting. REAL USER n. 1. A commercial user. One who is paying \"real\" money for his computer usage. 2. A non-hacker. Someone using the system for an explicit purpose (research project, course, etc.). See USER. REAL WORLD, THE n. 1. In programming, those institutions at which programming may be used in the same sentence as FORTRAN, COBOL, RPG, IBM, etc. 2. To programmers, the location of non-programmers and activities not related to programming. 3. A universe in which the standard dress is shirt and tie and in which a person's working hours are defined as 9 to 5. 4. The location of the status quo. 5. Anywhere outside a university. \"Poor fellow, he's left MIT and gone into the real world.\" Used pejoratively by those not in residence there. In conversation, talking of someone who has entered the real world is not unlike talking about a deceased person. RECURSION n. See RECURSION, TAIL RECURSION. REL See BIN. RIGHT THING, THE n. That which is \"obviously\" the correct or appropriate thing to use, do, say, etc. Use of this term often implies that in fact reasonable people may disagree. \"Never let your conscience keep you from doing the right thing!\" \"What's the right thing for LISP to do when it reads '(.)'?\" RUDE (WPI) adj. 1. (of a program) Badly written. 2. Functionally poor, e.g. a program which is very difficult to use because of gratuitously poor (random?) design decisions. See CUSPY. SACRED adj. Reserved for the exclusive use of something (a metaphorical extension of the standard meaning). \"Accumulator 7 is sacred to the UUO handler.\" Often means that anyone may look at the sacred object, but clobbering it will screw whatever it is sacred to. SAGA (WPI) n. A cuspy but bogus raving story dealing with N random broken people. SAV (save) See BIN. SEMI 1. n. Abbreviation for \"semicolon\", when speaking. \"Commands to GRIND are prefixed by semi-semi-star\" means that the prefix is \";;*\", not 1/4 of a star. 2. Prefix with words such as \"immediately\", as a qualifier. \"When is the system coming up?\" \"Semi-immediately.\" SERVER n. A kind of DAEMON which performs a service for the requester, which often runs on a computer other than the one on which the server runs. SHIFT LEFT (RIGHT) LOGICAL [from any of various machines' instruction sets] 1. v. To move oneself to the left (right). To move out of the way. 2. imper. Get out of that (my) seat! Usage: often used without the \"logical\", or as \"left shift\" instead of \"shift left\". Sometimes heard as LSH (lish), from the PDP-10 instruction set. SHR (share or shir) See BIN. SHRIEK See EXCL. (Occasional CMU usage.) 69 adj. Large quantity. Usage: Exclusive to MIT-AI. \"Go away, I have 69 things to do to DDT before worrying about fixing the bug in the phase of the moon output routine...\" [Note: Actually, any number less than 100 but large enough to have no obvious magic properties will be recognized as a \"large number\". There is no denying that \"69\" is the local favorite. I don't know whether its origins are related to the obscene interpretation, but I do know that 69 decimal = 105 octal, and 69 hexadecimal = 105 decimal, which is a nice property. - GLS] SLOP n. 1. A one-sided fudge factor (q.v.). Often introduced to avoid the possibility of a fencepost error (q.v.). 2. (used by compiler freaks) The ratio of code generated by a compiler to hand-compiled code, minus 1; i.e., the space (or maybe time) you lose because you didn't do it yourself. SLURP v. To read a large data file entirely into core before working on it. \"This program slurps in a 1K-by-1K matrix and does an FFT.\" SMART adj. Said of a program that does the Right Thing (q.v.) in a wide variety of complicated circumstances. There is a difference between calling a program smart and calling it intelligent; in particular, there do not exist any intelligent programs. SMOKING CLOVER n. A psychedelic color munch due to Gosper. SMOP [Simple (or Small) Matter of Programming] n. A piece of code, not yet written, whose anticipated length is significantly greater than its complexity. Usage: used to refer to a program that could obviously be written, but is not worth the trouble. SNARF v. To grab, esp. a large document or file for the purpose of using it either with or without the author's permission. See BLT. Variant: SNARF (IT) DOWN. (At MIT on ITS, DDT has a command called :SNARF which grabs a job from another (inferior) DDT.) SOFTWARE ROT n. Hypothetical disease the existence of which has been deduced from the observation that unused programs or features will stop working after sufficient time has passed, even if \"nothing has changed\". Also known as \"bit decay\". SOFTWARILY adv. In a way pertaining to software. \"The system is softwarily unreliable.\" The adjective \"softwary\" is NOT used. See HARDWARILY. SOS 1. (ess-oh-ess) n. A losing editor, SON OF STOPGAP. 2. (sahss) v. Inverse of AOS, from the PDP-10 instruction set. SPAZZ 1. v. To behave spastically or erratically; more often, to commit a single gross error. \"Boy, is he spazzing!\" 2. n. One who spazzes. \"Boy, what a spazz!\" 3. n. The result of spazzing. \"Boy, what a spazz!\" SPLAT n. 1. Name used in many places (DEC, IBM, and others) for the ASCII star (\"*\") character. 2. (MIT) Name used by some people for the ASCII pound-sign (\"#\") character. 3. (Stanford) Name used by some people for the Stanford/ITS extended ASCII circle-x character. (This character is also called \"circle-x\", \"blobby\", and \"frob\", among other names.) 4. (Stanford) Name for the semi-mythical extended ASCII circle-plus character. 5. Canonical name for an output routine that outputs whatever the the local interpretation of splat is. Usage: nobody really agrees what character \"splat\" is, but the term is common. SUPDUP v. To communicate with another ARPAnet host using the SUPDUP program, which is a SUPer-DUPer TELNET talking a special display protocol used mostly in talking to ITS sites. Sometimes abbreviated to SD. STATE n. Condition, situation. \"What's the state of NEWIO?\" \"It's winning away.\" \"What's your state?\" \"I'm about to gronk out.\" As a special case, \"What's the state of the world?\" (or, more silly, \"State-of-world-P?\") means \"What's new?\" or \"What's going on?\" STOPPAGE n. Extreme lossage (see LOSSAGE) resulting in something (usually vital) becoming completely unusable. STY (pronounced \"sty\", not spelled out) n. A pseudo-teletype, which is a two-way pipeline with a job on one end and a fake keyboard-tty on the other. Also, a standard program which provides a pipeline from its controlling tty to a pseudo-teletype (and thence to another tty, thereby providing a \"sub-tty\"). This is MIT terminology; the SAIL and DEC equivalent is PTY. SUPERPROGRAMMER n. See \"wizard\", \"hacker\". Usage: rare. (Becoming more common among IBM and Yourdon types.) SWAPPED adj. From the use of secondary storage devices to implement virtual memory in computer systems. Something which is SWAPPED IN is available for immediate use in main memory, and otherwise is SWAPPED OUT. Often used metaphorically to refer to people's memories (\"I read TECO ORDER every few months to keep the information swapped in.\") or to their own availability (\"I'll swap you in as soon as I finish looking at this other problem.\"). SYSTEM n. 1. The supervisor program on the computer. 2. Any large-scale program. 3. Any method or algorithm. 4. The way things are usually done. Usage: a fairly ambiguous word. \"You can't beat the system.\" SYSTEM HACKER: one who hacks the system (in sense 1 only; for sense 2 one mentions the particular program: e.g., LISP HACKER) T [from LISP terminology for \"true\"] 1. Yes. Usage: used in reply to a question, particularly one asked using the \"-P\" convention). See NIL. 2. See TIME T. TAIL RECURSION n. See TAIL RECURSION. TALK MODE See COM MODE. TASTE n. (primarily MIT-DMS) The quality in programs which tends to be inversely proportional to the number of features, hacks, and kluges programmed into it. Also, TASTY, TASTEFUL, TASTEFULNESS. \"This feature comes in N tasty flavors.\" Although TASTEFUL and FLAVORFUL are essentially synonyms, TASTE and FLAVOR are not. TECO (tee'koe) [acronym for Text Editor and COrrector] 1. n. A text editor developed at MIT, and modified by just about everybody. If all the dialects are included, TECO might well be the single most prolific editor in use. Noted for its powerful pseudo-programming features and its incredibly hairy syntax. 2. v. To edit using the TECO editor in one of its infinite forms; sometimes used to mean \"to edit\" even when not using TECO! Usage: rare at SAIL, where most people wouldn't touch TECO with a TENEX pole. [Historical note: DEC grabbed an ancient version of MIT TECO many years ago when it was still a TTY-oriented editor. By now, TECO at MIT is highly display-oriented and is actually a language for writing editors, rather than an editor. Meanwhile, the outside world's various versions of TECO remain almost the same as the MIT version of ten years ago. DEC recently tried to discourage its use, but an underground movement of sorts kept it alive.] [Since this note was written I found out that DEC tried to force their hackers by administrative decision to use a hacked up and generally lobotomized version of SOS instead of TECO, and they revolted. - MRC] TELNET v. To communicate with another ARPAnet host using the TELNET protocol. TOPS-10 people use the word IMPCOM since that is the program name for them. Sometimes abbreviated to TN. \"I usually TN over to SAIL just to read the AP News.\" TENSE adj. Of programs, very clever and efficient. A tense piece of code often got that way because it was highly bummed, but sometimes it was just based on a great idea. A comment in a clever display routine by Mike Kazar: \"This routine is so tense it will bring tears to your eyes. Much thanks to Craig Everhart and James Gosling for inspiring this hack attack.\" A tense programmer is one who produces tense code. TERPRI (tur'pree) [from the LISP 1.5 (and later, MacLISP) function to start a new line of output] v. To output a CRLF (q.v.). THEORY n. Used in the general sense of idea, plan, story, or set of rules. \"What's the theory on fixing this TECO loss?\" \"What's the theory on dinner tonight?\" (\"Chinatown, I guess.\") \"What's the current theory on letting losers on during the day?\" \"The theory behind this change is to fix the following well-known screw...\" THRASH v. To move wildly or violently, without accomplishing anything useful. Swapping systems which are overloaded waste most of their time moving pages into and out of core (rather than performing useful computation), and are therefore said to thrash. TICK n. 1. Interval of time; basic clock time on the computer. Typically 1/60 second. See JIFFY. 2. In simulations, the discrete unit of time that passes \"between\" iterations of the simulation mechanism. In AI applications, this amount of time is often left unspecified, since the only constraint of interest is that caused things happen after their causes. This sort of AI simulation is often pejoratively referred to as \"tick-tick-tick\" simulation, especially when the issue of simultaneity of events with long, independent chains of causes is handwaved. TIME T n. 1. An unspecified but usually well-understood time, often used in conjunction with a later time T+1. \"We'll meet on campus at time T or at Louie's at time T+1.\" 2. SINCE (OR AT) TIME T EQUALS MINUS INFINITY: A long time ago; for as long as anyone can remember; at the time that some particular frob was first designed. TOOL v.i. To work; to study. See HACK (def #9). TRAP 1. n. A program interrupt, usually used specifically to refer to an interrupt caused by some illegal action taking place in the user program. In most cases the system monitor performs some action related to the nature of the illegality, then returns control to the program. See UUO. 2. v. To cause a trap. \"These instructions trap to the monitor.\" Also used transitively to indicate the cause of the trap. \"The monitor traps all input/output instructions.\" TTY (titty) n. Terminal of the teletype variety, characterized by a noisy mechanical printer, a very limited character set, and poor print quality. Usage: antiquated (like the TTY's themselves). Sometimes used to refer to any terminal at all; sometimes used to refer to the particular terminal controlling a job. TWEAK v. To change slightly, usually in reference to a value. Also used synonymously with TWIDDLE. See FROBNICATE and FUDGE FACTOR. TWENEX n. The TOPS-20 operating system by DEC. So named because TOPS-10 was a typically crufty DEC operating system for the PDP-10. BBN developed their own system, called TENEX (TEN EXecutive), and in creating TOPS-0 for the DEC-20 DEC copied TENEX and adapted it for the 20. Usage: DEC people cringe when they hear TOPS-20 referred to as \"Twenex\", but the term seems to be catching on nevertheless. Release 3 of TOPS-20 is sufficiently different from release 1 that some (not all) hackers have stopped calling it TWENEX, though the written abbreviation \"20x\" is still used. TWIDDLE n. 1. tilde (ASCII 176, \"~\"). Also called \"squiggle\", \"sqiggle\" (sic--pronounced \"skig'gul\"), and \"twaddle\", but twiddle is by far the most common term. 2. A small and insignificant change to a program. Usually fixes one bug and generates several new ones. 3. v. To change something in a small way. Bits, for example, are often twiddled. Twiddling a switch or knob implies much less sense of purpose than toggling or tweaking it; see FROBNICATE. UP adj. 1. Working, in order. \"The down escalator is up.\" 2. BRING UP: v. To create a working version and start it. \"They brought up a down system.\" USER n. A programmer who will believe anything you tell him. One who asks questions. Identified at MIT with \"loser\" by the spelling \"luser\". See REAL USER. [Note by GLS: I don't agree with RF's definition at all. Basically, there are two classes of people who work with a program: there are implementors (hackers) and users (losers). The users are looked down on by hackers to a mild degree because they don't understand the full ramifications of the system in all its glory. (A few users who do are known as real winners.) It is true that users ask questions (of necessity). Very often they are annoying or downright stupid.] UUO (you-you-oh) [short for \"Un-Used Operation\"] n. A DEC-10 system monitor call. The term \"Un-Used Operation\" comes from the fact that, on DEC-10 systems, monitor calls are implemented as invalid or illegal machine instructions, which cause traps to the monitor (see TRAP). The SAIL manual describing the available UUO's has a cover picture showing an unidentified underwater object. See YOYO. [Note: DEC sales people have since decided that \"Un-Used Operation\" sounds bad, so UUO now stands for \"Unimplemented User Operation\".] Tenex and Twenex systems use the JSYS machine instruction (q.v.), which is halfway between a legal machine instruction and a UUO, since KA-10 Tenices implement it as a hardware instruction which can be used as an ordinary subroutine call (sort of a \"pure JSR\"). VANILLA adj. Ordinary flavor, standard. See FLAVOR. When used of food, very often does not mean that the food is flavored with vanilla extract! For example, \"vanilla-flavored wonton soup\" (or simply \"vanilla wonton soup\") means ordinary wonton soup, as opposed to hot and sour wonton soup. VAXEN [from \"oxen\", perhaps influenced by \"vixen\"] n. pl. The plural of VAX (a DEC machine). VIRGIN adj. Unused, in reference to an instantiation of a program. \"Let's bring up a virgin system and see if it crashes again.\" Also, by extension, unused buffers and the like within a program. VIRTUAL adj. 1. Common alternative to LOGICAL (q.v.), but never used with compass directions. 2. Performing the functions of. Virtual memory acts like real memory but isn't. VISIONARY n. One who hacks vision (in an AI context, such as the processing of visual images). WALDO [probably taken from the story \"Waldo\", by Heinlein, which is where the term was first used to mean a mechanical adjunct to a human limb] Used at Harvard, particularly by Tom Cheatham and students, instead of FOOBAR as a meta-syntactic variable and general nonsense word. See FOO, BAR, FOOBAR, QUUX. WALL [shortened form of HELLO WALL, apparently from the phrase \"up against a blank wall\"] (WPI) interj. 1. An indication of confusion, usually spoken with a quizzical tone. \"Wall??\" 2. A request for further explication. WALLPAPER n. A file containing a listing (e.g., assembly listing) or transcript, esp. a file containing a transcript of all or part of a login session. (The idea was that the LPT paper for such listings was essentially good only for wallpaper, as evidenced at SAIL where it was used as such to cover windows.) Usage: not often used now, esp. since other systems have developed other terms for it (e.g., PHOTO on TWENEX). The term possibly originated on ITS, where the commands to begin and end transcript files are still :WALBEG and :WALEND, with default file DSK:WALL PAPER. WATERBOTTLE SOCCER n. A deadly sport practiced mainly by Sussman's graduate students. It, along with chair bowling, is the most evident manifestation of the \"locker room atmosphere\" said to reign in that sphere. (Sussman doesn't approve.) [As of 11/82, it's reported that the sport has given way to a new game called \"disc-boot\", and Sussman even participates occasionally.] WEDGED [from \"head wedged up ass\"] adj. To be in a locked state, incapable of proceeding without help. (See GRONK.) Often refers to humans suffering misconceptions. \"The swapper is wedged.\" This term is sometimes used as a synonym for DEADLOCKED (q.v.). WHAT n. The question mark character (\"?\"). See QUES. Usage: rare, used particularly in conjunction with WOW. WHEEL n. 1. A privilege bit that canonically allows the possessor to perform any operation on a timesharing system, such as read or write any file on the system regardless of protections, change or or look at any address in the running monitor, crash or reload the system, and kill/create jobs and user accounts. The term was invented on the TENEX operating system, and carried over to TOPS-20, Xerox-IFS and others. 2. A person who posses a wheel bit. \"We need to find a wheel to unwedge the hung tape drives.\" WHEEL WARS [from LOTS at Stanford University] A period during which student wheels hack each other by attempting to log each other out of the system, delete each other's files, or otherwise wreak havoc, usually at the expense of the lesser users. WIN [from MIT jargon] 1. v. To succeed. A program wins if no unexpected conditions arise. 2. BIG WIN: n. Serendipity. Emphatic forms: MOBY WIN, SUPER WIN, HYPER-WIN (often used interjectively as a reply). For some reason SUITABLE WIN is also common at MIT, usually in reference to a satisfactory solution to a problem. See LOSE. WINNAGE n. The situation when a lossage is corrected, or when something is winning. Quite rare. Usage: also quite rare. WINNER 1. n. An unexpectedly good situation, program, programmer or person. 2. REAL WINNER: Often sarcastic, but also used as high praise. WINNITUDE n. The quality of winning (as opposed to WINNAGE, which is the result of winning). \"That's really great! Boy, what winnitude!\" WIZARD n. 1. A person who knows how a complex piece of software or hardware works; someone who can find and fix his bugs in an emergency. Rarely used at MIT, where HACKER is the preferred term. 2. A person who is permitted to do things forbidden to ordinary people, e.g., a \"net wizard\" on a TENEX may run programs which speak low-level host-imp protocol; an ADVENT wizard at SAIL may play Adventure during the day. WORMHOLE n. A location in a monitor which contains the address of a routine, with the specific intent of making it easy to substitute a different routine. The following quote comes from \"Polymorphic Systems\", vol. 2, p. 54: \"Any type of I/O device can be substituted for the standard device by loading a simple driver routine for that device and installing its address in one of the monitor's `wormholes.'* ---------- *The term `wormhole' has been used to describe a hypothetical astronomical situation where a black hole connects to the `other side' of the universe. When this happens, information can pass through the wormhole, in only one direction, much as `assumptions' pass down the monitor's wormholes.\" WOW See EXCL. XGP 1. n. Xerox Graphics Printer. 2. v. To print something on the XGP. \"You shouldn't XGP such a large file.\" XYZZY [from the Adventure game] adj. See PLUGH. YOYO n. DEC service engineers' slang for UUO (q.v.). Usage: rare at Stanford and MIT, has been found at random DEC installations. YOYO MODE n. State in which the system is said to be when it rapidly alternates several times between being up and being down. YU-SHIANG WHOLE FISH n. The character gamma (extended SAIL ASCII 11), which with a loop in its tail looks like a fish. Usage: used primarily by people on the MIT LISP Machine. Tends to elicit incredulity from people who hear about it second-hand. ZERO v. 1. To set to zero. Usually said of small pieces of data, such as bits or words. 2. To erase; to discard all data from. Said of disks and directories, where \"zeroing\" need not involve actually writing zeroes throughout the area being zeroed. The Hacker's Dictionary The Hacker's Dictionary—also known as The Jargon File—was a collection of hacker terminology, jokes, and folklore from the early internet. It became an essential reference for hackers and computer scientists, and helped shape early online culture. First created in 1975 by Raphael Finkel at Stanford's AI lab, the dictionary quickly spread to MIT and eventually to the broader internet community. It became a collaborative effort as hackers and computer scientists crowdsourced new editions of the dictionary to reflect the ever-changing culture. Line 17 of 153 Path: utzoo!watmath!clyde!burl!ulysses!gatech!usenet From: use...@gatech.CSNET Newsgroups: mod.newslists,net.announce.newusers,net.news.group Subject: List of Active Newsgroups Message-ID:Date: Mon Dec 16 19:05:14 1985 The following is a list of currently active USENET newsgroups as of 16 December 1985. There are two basic subcategories of netwide newsgroups: \"net\" and \"mod\". \"net\" groups consist of USENET bulletin-board newsgroups that are (usually) circulated around the entire USENET -- this implies world-wide distribution. Not all \"net\" groups actually enjoy such wide distribution, however. The European Usenet sites (Eunet) take only a selected subset of the more \"technical\" groups, and controversial \"noise\" groups are often not carried by many sites in the US and Canada. \"mod\" groups are moderated or are monitored mailing lists. They can only be posted to by mailing submissions to the coordinator (provided in a companion posting). Some of the \"mod\" groups are gatewayed to USENET from the ARPA Internet and appear as \"mod\" groups to facilitate distribution and posting from the Usenet. net.ai Artificial intelligence discussions. net.analog Analog design developments, ideas, and components. net.announce Moderated, general announcements of interest to all. net.announce.newusers Moderated, explanatory postings for new users. net.announce.arpa-internet Announcements from the Arpa world net.arch Computer architecture. net.astro Astronomy discussions and information. net.astro.expert Discussion by experts in astronomy. net.audio High fidelity audio. net.auto Automobiles, automotive products and laws. net.auto.tech Technical aspects of automobiles, et. al. net.aviation Aviation rules, means, and methods. net.bicycle Bicycles, related products and laws. net.bio Biology and related sciences. net.books Books of all genres, shapes, and sizes. net.bugs General bug reports and fixes. net.bugs.2bsd Reports of UNIX* version 2BSD related bugs. net.bugs.4bsd Reports of UNIX version 4BSD related bugs. net.bugs.usg Reports of USG (System III, V, etc.) bugs. net.bugs.uucp Reports of UUCP related bugs. net.bugs.v7 Reports of UNIX V7 related bugs. net.cog-eng Cognitive engineering. net.college College, college activities, campus life, etc. net.columbia The space shuttle and the STS program. net.comics The funnies, old and new. net.consumers Consumer interests, product reviews, etc. net.cooks Food, cooking, cookbooks, and recipes. net.crypt Different methods of data en/decryption. net.cse Computer science education. net.cycle Motorcycles and related products and laws. net.database Database and data management issues and theory. net.dcom Data communications hardware and software. net.decus DEC* Users' Society newsgroup. net.emacs EMACS editors of different flavors. net.eunice The SRI Eunice system. net.followup Followups to articles in net.general. net.games Games and computer games. net.games.board Discussion and hints on board games. net.games.chess Chess & computer chess. net.games.emp Discussion and hints about Empire. net.games.frp Discussion about Fantasy Role Playing games. net.games.go Discussion about Go. net.games.hack Discussion, hints, etc. about the Hack game. net.games.pbm Discussion about Play by Mail games. net.games.rogue Discussion and hints about Rogue. net.games.trivia Discussion about trivia. net.games.video Discussion about video games. net.garden Gardening, methods and results. net.general *Important* and timely announcements of interest to all. (Note the description of net.misc.) net.graphics Computer graphics, art, animation, image processing, pattern recognition, and machine vision. net.ham-radio Amateur Radio practices, contests, events, rules, etc. net.ham-radio.packet Discussion about packet radio setups. net.info-terms All sorts of terminals. net.internat Discussion about international standards net.invest Investments and the handling of money. net.jobs Job announcements, requests, etc. net.jokes Jokes and the like. May be somewhat offensive. net.jokes.d Discussions on the content of net.jokes articles net.kids Children, their behavior and activities. net.lan Local area network hardware and software. net.lang Different computer languages. net.lang.ada Discussion about Ada*. net.lang.apl Discussion about APL. net.lang.c Discussion about C. net.lang.f77 Discussion about FORTRAN. net.lang.forth Discussion about Forth. net.lang.lisp Discussion about LISP. net.lang.mod2 Discussion about Modula-2. net.lang.pascal Discussion about Pascal. net.lang.prolog Discussion about PROLOG. net.lang.st80 Discussion about Smalltalk 80. net.legal Legalities and the ethics of law. net.lsi Large scale integrated circuits. net.mag Magazine summaries, tables of contents, etc. net.mail Proposed new mail/network standards. net.mail.headers Gatewayed from the ARPA header-people list. net.math Mathematical discussions and puzzles. net.math.stat Statistics discussion. net.math.symbolic Symbolic algebra discussion. net.med Medicine and its related products and regulations. net.micro Micro computers of all kinds. net.micro.16k National Semiconductor 32000 series chips net.micro.6809 Discussion about 6809's. net.micro.68k Discussion about 68k's. net.micro.apple Discussion about Apple micros. net.micro.amiga Talk about the new Amiga micro. net.micro.atari Discussion about Atari micros. net.micro.att Discussions about AT&T microcomputers net.micro.cbm Discussion about Commodore micros. net.micro.cpm Discussion about the CP/M operating system. net.micro.hp Discussion about Hewlett/Packard's. net.micro.mac Material about the Apple Macintosh & Lisa net.micro.pc Discussion about IBM personal computers. net.micro.ti Discussion about Texas Instruments. net.micro.trs-80 Discussion about TRS-80's. net.misc Various discussions too short-lived for other groups. Also items of a general nature not important enough for net.general or net.announce. net.motss Issues pertaining to homosexuality. net.movies Reviews and discussions of movies. net.music Music lovers' group. net.music.classical Discussion about classical music. net.music.folk Folks discussing folk music of various sorts net.music.gdead A group for (Grateful) Dead-heads net.music.synth Synthesizers and computer music net.net-people Announcements, requests, etc. about people on the net. net.news Discussions of USENET itself. net.news.adm Comments directed to news administrators. net.news.b Discussion about B news software. net.news.config Postings of system down times and interruptions. net.news.group Discussions and lists of newsgroups net.news.newsite Postings of new site announcements. net.news.notes Notesfile software from the Univ. of Illinois. net.news.sa Comments directed to system administrators. net.news.stargat Discussion about satellite transmission of news. net.nlang Natural languages, cultures, heritages, etc. net.nlang.africa Discussions about Africa & things African net.nlang.celts Group about Celtics. net.nlang.greek Group about Greeks. net.nlang.india Group for discussion about India & things Indian net.origins Evolution versus creationism (sometimes hot!). net.periphs Peripheral devices. net.pets Pets, pet care, and household animals in general. net.philosophy Philosophical discussions. net.physics Physical laws, properties, etc. net.poems For the posting of poems. net.politics Political discussions. Could get hot. net.politics.theory Theory of politics and political systems. net.puzzle Puzzles, problems, and quizzes. net.railroad Real and model train fans' newsgroup. net.rec Recreational/participant sports. net.rec.birds Hobbyists interested in bird watching. net.rec.boat Hobbyists interested in boating. net.rec.bridge Hobbyists interested in bridge. net.rec.nude Hobbyists interested in naturist/nudist activities. net.rec.photo Hobbyists interested in photography. net.rec.scuba Hobbyists interested in SCUBA diving. net.rec.ski Hobbyists interested in skiing. net.rec.skydive Hobbyists interested in skydiving. net.rec.wood Hobbyists interested in woodworking. net.religion Religious, ethical, and moral implications of actions. net.religion.christian Discussion about form and nature of Christianity net.religion.jewish Information and discussion about Judaism. net.research Research and computer research. net.roots Genealogical matters. net.rumor For the posting of rumors. net.sci General purpose scientific discussions. net.sf-lovers Science fiction lovers' newsgroup. net.singles Newsgroup for single people, their activities, etc. net.social Like net.singles, but for everyone. net.sources For the posting of software packages & documentation. net.sources.bugs For bug fixes and features discussion pertaining to items in net.sources net.sources.games Postings of recreational software net.sources.mac Software for the Apple Macintosh net.space Space, space programs, space related research, etc. net.sport Spectator sports. net.sport.baseball Discussion about baseball. net.sport.football Discussion about football. net.sport.hockey Discussion about hockey. net.sport.hoops Discussion about basketball. net.startrek Star Trek, the TV show and the movies. net.suicide Suicide, laws, ethics, and its causes and effects (!). net.taxes Tax laws and advice. net.test For testing of network software. Very boring. net.text Text processing. net.travel Traveling all over the world. net.tv The boob tube, its history, and past and current shows. net.tv.drwho Discussion about Dr. Who. net.tv.soaps Postings about soap operas. net.unix UNIX neophytes group. net.unix-wizards Discussions, bug reports, and fixes on and for UNIX. Not for the weak of heart. net.usenix USENIX Association events and announcements. net.veg Vegetarians. net.video Video and video components. net.wanted Requests for things that are needed. net.wanted.sources Requests for software, termcap entries, etc. net.wines Wines and spirits. net.wobegon \"A Prairie Home Companion\" radio show discussion. net.women Women's rights, discrimination, etc. net.works Assorted workstations. mod.ai Discussions about Artificial Intelligence mod.computers Discussion about various computers and related. mod.computers.apollo Apollo computer systems. mod.computers.ibm-pc The IBM PC, PC-XT, and PC-AT. mod.computers.laser-printers Laser printers, hardware and software. mod.computers.macintosh Apple Macintosh micros. mod.computers.pyramid Pyramid 90x computers. mod.computers.ridge Ridge 32 computers and ROS. mod.computers.sequent Sequent systems, (esp. Balance 8000). mod.computers.sun Sun \"workstation\" computers mod.computers.vax DEC's VAX* line of computers & VMS. mod.computers.workstations Various workstation-type computers. mod.graphics Graphics software, hardware, theory, etc. mod.human-nets Computer aided communications digest. mod.legal Discussions of computers and the law. mod.map Various maps, including UUCP maps mod.motss Moderated newsgroup on gay issues and topics mod.movies Moderated reviews and discussion of movies mod.music Moderated reviews and discussion of things musical mod.newprod Announcements of new products of interest to readers mod.newslists Postings of news-related statistics and lists mod.politics Discussions on political problems, systems, solutions. mod.politics.arms-d Arms discussion digest. mod.protocols Various forms and types of FTP protocol discussions. mod.protocols.appletalk Applebus hardware & software discussion. mod.protocols.kermit Information about the Kermit package. mod.protocols.tcp-ip TCP and IP network protocols. mod.rec Discussions on pastimes (not currently active) mod.rec.guns Discussions about firearms mod.recipes A \"distributed cookbook\" of screened recipes. mod.risks Risks to the public from computers & users. mod.sources Moderated postings of public domain sources. mod.std Moderated discussion about various standards mod.std.c Discussion about C language standards mod.std.mumps Discussion for the X11.1 committee on Mumps mod.std.unix Discussion for the P1003 committee on Unix mod.telecom Telecommunications digest. mod.test Testing of moderated newsgroups -- no moderator mod.unix Moderated discussion of Unix* features and bugs mod.vlsi Very large scale integrated circuits. Usenet Newsgroups Developed by Tom Truscott and Jim Ellis, Usenet was dubbed the \"poor man’s ARPANET\" because it was more accessible to the average person. The network allowed users to post messages and articles in different topic-specific newsgroups. Usenet had no central authority, instead news servers exchanged articles with each other at set intervals. The platform quickly evolved beyond its initial focus on technical topics, expanding to host newsgroups ranging from music to philosophy. By 1985, around 375 articles were posted a day on Usenet to over 100 active newsgroups. The network helped shape early Internet culture, popularizing terms like FAQ, flame wars, and spam. First MP3 The first ever MP3 was the a cappella version of \"Tom's Diner\" by Suzanne Vega. Karlheinz Brandenburg, who worked on the MP3 format, used the song as a benchmark to see how the compression algorithm would handle the human voice. Instrumental music had been easier to compress, but Vega's voice sounded distorted and unnatural in early versions of the format. Brandenburg would end up making hundreds of tweaks to the MP3 compression algorithm to make Vega's voice clearer. He would later even get to meet Suzanne Vega and hear the song performed live. Morris Worm On November 2nd, 1988, a computer worm was released onto the internet. Created by Robert Tappan Morris, a 23-year-old Cornell University graduate student, it was designed as an experiment to measure the internet's size, but a programming error caused it to propagate wildly. Within 24 hours, close to 10% of the 88,000 computers on the internet were disabled. After learning that his experiment had gone awry, Morris asked a friend to anonymously relay an apology and instructions for removing the worm to internet users, but ironically those most impacted didn’t get his message because of the damage the worm did to the network. Morris became the first person convicted under the Computer Fraud and Abuse Act. Dave Rhodes Chain Letter One of the earliest chain letters to spread on the internet was titled \"Make Money Fast.\" It promised readers that they would receive $50,000 in cash after sixty days if they followed the given instructions. The letter worked like a pyramid scheme, where each person had to pay those before them. It quickly spread through email and Usenet groups after being posted by an unknown creator in 1988. Many variations of the letter also spread with titles like \"Make Beer Fast\", making it an early internet meme. Internet Relay Chat Created by Jarkko Oikarinen as a side-project while working at the University of Oulu in Finland, IRC, or Internet Relay Chat, is a text-based communication protocol that lets users chat in real-time group conversations, known as channels. The initial IRC server consisted mostly of Jarkko's friends, but the protocol slowly spread when others started hosting their own servers. Other schools, like Oregon State University also started using the protocol. By mid-1989, around 40 servers existed worldwide, and IRC was adopted by early internet communities as a chat alternative to message boards. Earliest LOL The acronym \"LOL\" made its first documented appearance on the internet in a FidoNet newsletter. FidoNet was a network of BBSs - or bulletin board systems. Messages were transferred over phone calls during off-peak hours to minimize toll costs. This edition of the FidoNet newsletter attempts to catalog the increasing number of emoticons and acronyms that were spreading on the network at the time. It also contained conventions that never really caught on - like ODM for \"On De Move\". AOL Dial Up America Online debuted in 1991 and quickly became the largest dial-up service provider. The start screen and iconic dial-up sound became many people's first introduction to the Internet. Dial-up internet worked by using the existing telephone infrastructure. Modems connected in a way similar to phone conversations, with the dial-up sound serving as a handshake between machines. The dial-up sound was a choreographed dance of beeps and boops that exchanged all the information needed to connect to the network. First Website In March 1989, Tim Berners-Lee wrote the initial proposal for the World Wide Web, envisioning it as a \"universal linked information system\" to help researchers share information. In December 1990, he launched the world’s first website, info.cern.ch. The site featured details about the WWW project, including an explanation of hypertext and instructions for setting up a web server. Tim Berners-Lee created the first web browser, called WorldWideWeb, to display the site. He hosted the first website on a NeXT computer, attaching a handwritten note to the computer: \"This machine is a server. DO NOT POWER IT DOWN!!\" Early Web Photo One of the very first photos uploaded to the World Wide Web was of Les Horribles Cernettes, an all-female band founded by employees at CERN. The band—whose name pays homage to the world’s largest particle accelerator—sang parody pop songs with lyrics like \"You never spend your nights with me… you only love your collider.\" The band was based out of the same lab where the Web was invented, and Tim Berners-Lee was such a fan that he uploaded this photo to the first website. The band later said the picture \"was one of those that changed the web, from a platform for physics documentation to a media for our lives.\" First Webcam The first webcam was set up in the Trojan Room of the Computer Laboratory at the University of Cambridge, its lens focused on a coffee pot. Researchers created the feed so they could check the coffee pot's status without leaving their desks. Initially, a program called XCoffee had to be downloaded to watch the stream, but in 1993, the black and white feed – which only had a frame rate of 3 frames per minute – was made available on the web. Millions of people ended up watching the coff",
    "commentLink": "https://news.ycombinator.com/item?id=38013477",
    "commentBody": "Internet Artifact MuseumHacker NewspastloginInternet Artifact Museum (neal.fun) 252 points by meetpateltech 19 hours ago| hidepastfavorite54 comments gadtfly 16 hours agoNote that many of the artifacts are interactive: buttons and links are clickable (effectful within the museum, does not leave page), text is scrollable, videos play, etcFantastic work. reply crtasm 11 hours agoparentThat explains why I couldn&#x27;t see LOL (lol!) reply Lammy 14 hours agoparentprevTry the Napster download button. Love it. reply my12parsecs 4 hours agorootparentI was like cool! But then... reply MilStdJunkie 16 hours agoprevI hate to be that guy, but the smiley&#x2F;emoticon was invented on the PLATO platform circa 1972https:&#x2F;&#x2F;webcache.googleusercontent.com&#x2F;search?q=cache:tPjEJH...The CDC hardware platform didn&#x27;t adapt to personal computing architectures, but many of the PLATO alumnus went on to futures with PARC and Apple. reply boomboomsubban 14 hours agoparentThis is probably going to spark a dumb argument that&#x27;s been done to death, but aren&#x27;t emoticons typographical based? Those look like pictograms or arguably early emoji. reply MilStdJunkie 14 hours agorootparentThey&#x27;re actually overstrikes of existing characters! The PLATO terminal had some wack stuff built into it, courtesy, I suspect, of the vector buffers it was initially designed with. That kind of computational overhead limited the expansion of the system into commodity equipment, a definite cloud of doom.We can really, really go down the rabbit hole with encoding. Wireless morse had several equivalents to \"emoticons\" in its text encoding, and typesetters had zillions of different emoticons they could and did fabricate. Indeed, these are the first documented examples.PLATO is an oddball system, pre-ASCII, pre-everything. That overstrike trick kind of hints at that. So if we mean ASCII-encoded emotions, yeah, PLATO loses to CM&#x27;s BBS circa 1982. reply wkat4242 15 hours agoparentprevLink broken. But I read about Plato in that book the Happy Orange Glow or something like it. Didn&#x27;t make it all the way through but it sounded groundbreaking reply hcs 14 hours agorootparentThe Friendly Orange GlowThe author also had an article on PLATO emoticons as the book was in development: http:&#x2F;&#x2F;www.platohistory.org&#x2F;blog&#x2F;2012&#x2F;09&#x2F;plato-emoticons-rev... reply MilStdJunkie 10 hours agorootparentprevArs did a really great overview of the system back in March.https:&#x2F;&#x2F;arstechnica.com&#x2F;gadgets&#x2F;2023&#x2F;03&#x2F;plato-how-an-educati...It&#x27;s incredible what they got out of those CDC machines. I wish I had the EE skills to figure out how they did it. I suspect that the vacuum tubes might have yielded some compute capabilities far beyond transistors of the era, given the very high power levels you can get in tubes. But I don&#x27;t know. It might just be very open-ended approaches to memory registers, or simply letting the plasma display do its own thing rather than wipe it back to its initial state. reply tptacek 8 hours agoprevAfter learning that his experiment had gone awry, Morris asked a friend to anonymously relay an apology and instructions for removing the worm to internet usersI&#x27;m like 80% sure this friend was Paul Graham. reply teach 14 hours agoprevI&#x27;m virtually certain the audio clip that plays when you connect to AOL Dial-Up is not a modem from 1991. To my ear it sounds like a 28.8 or 33.6 modemflips table@Begin(Comic Book Guy) worst website ever @End reply toast0 12 hours agoparentWell, it says connected at 52kbps... and the handshake was pretty short, I think it may be a 56k accelerated handshake that could happen if the line characteristics were similar to a previous call. Not sure if that&#x27;s in all of x2&#x2F;kflex&#x2F;v.90&#x2F;v.92, but it&#x27;s in some of them. reply ProllyInfamous 12 hours agorootparent14.4kbps club, checking in...Everything this neal.fun -guy does is golden.His last HN forey [password game] left me bureaucratic for weeks. reply pictureofabear 12 hours agoprevThey should add to the emoji page a blurb about them also being called \"emoticons.\" I remember a big debate about this, and we collectively decided to call them emojis.Also, the helicopter game was going around on DOS well before 2002. I was playing that around 1993 on a Gateway 386. reply msla 11 hours agoparentEmoji and emoticons are not the same thing.Emoticons are things like :) or :D which can be done purely in ASCII. Emoji are actual pictures.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Emoticonhttps:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Emoji reply pictureofabear 9 hours agorootparentThey were the same thing at one time. \"Emoticons\" came first.[1] When someone replaced :-) with a smiley picture, there was a debate about whether they should be called emoticons or emojis. Emoji won out.1. https:&#x2F;&#x2F;www.independent.co.uk&#x2F;tech&#x2F;happy-30th-birthday-emoti... reply jameshart 6 hours agorootparent> When someone replaced :-) with a smiley picture, there was a debate about whether they should be called emoticons or emojis[citation needed].The history of the word emoji isn&#x27;t some mysterious thing - the wikipedia article linked in your parent post has it all laid out.Emoji is a Japanese word meaning pictograph, it isn&#x27;t derived from the word &#x27;emoticon&#x27;. They were developed by Japanese phone companies as an idiomatic expressive addition to Japanese writing, not because &#x27;someone replaced :-) with a smiley picture&#x27;. There was no time when they might have ended up being called emoticons. reply rmwaite 4 hours agorootparentI don’t have a citation but I remember Yahoo! Chat calling them emoticons. reply ggm 6 hours agorootparentprevI recommend https:&#x2F;&#x2F;www.amazon.com&#x2F;gp&#x2F;product&#x2F;B01L6SI74U&#x2F;ref=kinw_myk_ro... reply msla 6 hours agorootparentprevIt seems like some people are claiming emoticons are retroactively emoji because emoji is the term people know now. reply donut 9 hours agoparentprevI loved that game. Played it on my 8086 with CGA graphics in the early 1990s.Check this out:> Chopper Commando, a DOS game written by Mark Currie using Turbo Pascal in 1990https:&#x2F;&#x2F;blog.loadzero.com&#x2F;blog&#x2F;chopper258&#x2F; reply RecycledEle 15 hours agoprevThey are missing Altavista, Stick Figure Death, and a few more. reply DonHopkins 17 minutes agoparentCMU&#x27;s Internet Confessional Booth was great reading, too.I recall there was a dropdown for confessing \"fish in microwave\", which was the original sin that inspired the CMU grad students who created it.Here&#x27;s Bennet Yee&#x27;s old page at CMU (last update 4 April 1996) with a link to it and other classic stuff, but it&#x27;s long gone and not in the internet archive:https:&#x2F;&#x2F;www.cs.cmu.edu&#x2F;afs&#x2F;cs&#x2F;usr&#x2F;bsy&#x2F;www&#x2F;fun.html reply daveslash 15 hours agoparentprevAnd telnet towel.blinkenlights.nl reply sillywalk 14 hours agoparentprevBuffy&#x27;s Swearing Keyboardhttps:&#x2F;&#x2F;www2.b3ta.com&#x2F;buffyswear&#x2F;VRML, MIDI players, reply jedberg 14 hours agoparentprevMaybe the Museum accepts donations of artifacts. reply daveslash 15 hours agoprev\"The Whitehouse Page\"I had to read that to ensure it was talking about Whitehouse.gov and not Whitehouse.com - the latter of which fooled many-a-schoolteacher in the 90s. reply Ographer 12 hours agoparentI had that thought too! I double checked the URL. I remember my friends trying desperately to convince me to go to the .com and I refused because they were so obviously suspicious. reply sanqui 15 hours agoprevI with the website used proper URLs so it would be possible to use permalinks as a reference for individual items... reply JeremyNT 15 hours agoparentGood news for you - it does (for some parts).Once you reach the Internet era, you can copy&#x2F;paste the links within the embedded browser to access them directly. e.g.: https:&#x2F;&#x2F;internet-artifacts.neal.fun&#x2F;sites&#x2F;y2k&#x2F;index.html reply ehsankia 12 hours agorootparentI think they meant linking to the museum itself, at a specific artifact. Not the embed itself. reply wkat4242 15 hours agoparentprevIt&#x27;s also using a color scheme that&#x27;s almost unreadable here with dark reader. Will check again in the morning lol reply Lammy 14 hours agoprevPlease add SomethingAwful and 4chan :)needs moar yellow van https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=kkAngvkWVkk reply omoikane 10 hours agoparent> 4chanIn that vein, I would have expected 2ch[1] to be included in the list of artifacts. 2ch inspired 2chan[2], which inspired 4chan later. 2ch is an enormous anonymous bulletin board system that was home to many communities.[1] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;2channel[2] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Futaba_Channel reply ehsankia 12 hours agoparentprevdefinitely seems very like in the post-2000s section, especially considering the exponential growth of the internet (that it itself alludes to), it seems to focus a lot more on the pre-2000 content, with a small handful of misc stuff from after. reply petepete 3 hours agoprevI love this, plenty of things I&#x27;d forgotten about in there presented in a way non-needs like me (us) might appreciate too.I think there should be an every l entry for ICQ. reply goodboyjojo 1 hour agoprevi always loved seeing stuff like this. it&#x27;s a pretty neat. reply coleca 17 hours agoprevNo \"Punch the Monkey\"?https:&#x2F;&#x2F;twitter.com&#x2F;meyerweb&#x2F;status&#x2F;1454563559577370635?lang... reply wkat4242 15 hours agoparentEven if it doesn&#x27;t the internet has seen more than enough of its share of monkeys being spanked ;) reply eterm 14 hours agoprevHelicopter game gave me flashbacks. IIRC my high score was around 44,000.ALong side that I&#x27;d hall of fame a \"3d pong\" game which was available only in \"Macromedia shockwave\". Impossible to even find a screenshot of it now, it was beautiful 3d for its time. reply markx2 16 hours agoprevHelicopter game! I&#x27;d forgotten about that.Club Penguin. I was so very very happy when that shut down. I - and others - were doing Support at wordpress.com. Kids (I assume) constantly exploiting other kids to get into their accounts. Kids doing anything to get traffic, using popunder scripts and more. reply safog 9 hours agoprevI think HN should come up with its own Internet Artifact Museum :)I&#x27;m happy to collab if folks want to. reply grouphoot 13 hours agoprevNeed to add Mahir - I Kiss You! reply qingcharles 10 hours agoparentYes, I came here to add this. That was the biggest thing missing for me; 2nd, Altavista. reply latexr 14 hours agoprevWhen you get to Napster (1999), be sure to interact with it and download a song. reply twism 11 hours agoprevReminds of how slack was&#x2F;is an IRC clone reply DonHopkins 12 minutes agoparentNo not really, more of a spiritual descendent of Habitat, and a direct descendent of two other games and Flickr, developed by Stewart Butterfield:https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37978755DonHopkins 3 days agoparentcontextfavoriteon: The Lessons of Lucasfilm&#x27;s Habitat (1990)Stewart Butterfield developed a 2d massively multi player game called \"Game Neverending\":https:&#x2F;&#x2F;gamicus.fandom.com&#x2F;wiki&#x2F;Game_NeverendingIt let users create and upload content like text and pictures, so it had a nice image uploader component and content management system.That didn&#x27;t work out, so they took the image uploader and cms and pivoted to making an app called \"Flickr\", which Yahoo bought.Later on he redeveloped a new version of GNE in Flash called \"Glitch\", that was a whole lot like Habitat, in that it had these long horizontal areas you could walk left and right around, and chat with other people with avatars, and do fun stuff.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Glitch_(video_game)That didn&#x27;t work out either, so he took the rooms based chat messaging back-end, and pivoted to an app named \"Slack\". reply ape4 16 hours agoprevAnd its a single page app. reply barroomhero 16 hours agoprevMan, I&#x27;m really feeling the enshitification of the internet right now. Those early to mid years were great. reply libraryatnight 16 hours agoprevWaves and waves of nostalgiauniversal internet surveillance systemQuestionIs the web still suitable to help researchers share information if so-called \"tech\" companies intermediate access to all information and seek to commercialise all web use. reply shepherdjerred 4 hours agoparent [–] > Is the web still suitable to help researchers share information if so-called \"tech\" companies intermediate access to all information and seek to commercialise all web use.Yes, plenty of researchers share information via the web.There was some original vision for the web, and of course that vision has changed in the past 30 years. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The text is a comprehensive collection of computer-related terms and slang used prevalently among computer scientists.",
      "It offers a historical timeline highlighting key milestones on the internet, from the inception of the first website and webcam to the first spam email.",
      "It presents an overview of numerous subjects such as programming, hacker culture, and early internet communication practices."
    ],
    "commentSummary": [
      "The Internet Artifact Museum presents interactive elements from the history of the internet, stimulating discussions among Hacker News users about their origins and historical context.",
      "The conversation further expands to include references to prominent websites and games of the past, along with suggestions for more artifacts to showcase.",
      "Also, the forum sees debates around the transformation of the web over time and the role that tech companies play in this evolution."
    ],
    "points": 250,
    "commentCount": 54,
    "retryCount": 0,
    "time": 1698245673
  },
  {
    "id": 38015169,
    "title": "Adding crushed rock to farmland pulls carbon out of the air",
    "originLink": "https://www.ucdavis.edu/climate/news/adding-crushed-rock-farmland-pulls-carbon-out-air",
    "originBody": "Skip to main content UC Davis Open Search quick links Main navigation (extended config) ABOUT US Administration Diversity and Inclusion Rankings Locations Sustainability Visit UC Davis UC Davis Health Campus Safety ADMISSIONS Undergraduate Admissions Undocumented Applicants Graduate Admissions Professional Admissions Cost & Aid Apply to UC Davis ACADEMICS Majors Minors Graduate Programs Professional Programs Colleges and Schools Our Faculty Study Abroad RESEARCH Undergraduate Research Graduate Research Office of Research Library Museums and Collections Research Partners UC Davis Discoveries CAMPUS LIFE California’s College Town Housing Dining Things to Do Student Jobs Clubs and Communities Athletics NEWS Latest News In Focus Features University News Social Media Student News Blogs Podcasts and Shows Adding Crushed Rock to Farmland Pulls Carbon Out of the Air Field Test Finds Carbon Stored in Soils Even in Dry Climates by Amy Quinton October 24, 2023 News UC Davis researchers find adding crushed volcanic rock to farmlands can remove carbon dioxide from the air. This 'enhanced' rock weathering works even in dry climates. (Amy Quinton/UC Davis) Adding crushed volcanic rock to cropland could play a key role in removing carbon from the air. In a field study, scientists at the University of California, Davis, and Cornell University found the technology stored carbon in the soil even during an extreme drought in California. The study was published in the journal Environmental Research Communications. Rain captures carbon dioxide from the air as it falls and reacts with volcanic rock to lock up carbon. The process, called rock weathering, can take millions of years — too slow to offset global warming. But by crushing the rock into a fine dust, rock weathering speeds up. Previous studies have estimated this “enhanced” rock weathering could store 215 billion tons of carbon dioxide over the next 75 years if spread across croplands globally. But until now the technology hasn’t been field-tested in dry climates. “These reactions require water,” said lead author Iris Holzer, a doctoral candidate in soils and biogeochemistry in the Department of Land, Air and Water Resources at UC Davis. “Since we’re interested in the global carbon storage potential of enhanced weathering, we need to understand if it can work in these drier climates and if different measurement approaches are effective. We were excited to observe carbon removal in this environment.” California as a test case for storing carbon Researchers applied crushed rock, both metabasalt and olivine, on 5 acres of a fallowed cornfield in the Sacramento Valley. They collected measurements during the winter months of 2020-2021. California was experiencing extreme drought at the time, with rainfall at 41% of its historical average. A spreader unloads crushed metabasalt rock on a fallowed corn field in the Central Valley. (Amy Quinton/ UC Davis) The study found the plots with crushed rock stored 0.15 tons of carbon dioxide per hectare (2.47 acres) during the study compared to plots without crushed rock. Though researchers expect different weathering rates in different environments, if this amount of carbon was removed across all California cropland, it would be equivalent to taking 350,000 cars off the road every year. “We’re definitely seeing evidence of weathering processes taking place on short time scales,” said Holzer. “Even the infrequent heavy rains we get in the West might be enough to drive enhanced rock weathering and remove carbon dioxide.” Holzer said measuring and verifying that carbon storage at larger scales and following it over time is the next challenge. Forty-one percent of Earth’s land surface is covered by drylands that are expanding due to climate change. Researchers said this makes investigating enhanced rock weathering in drylands increasingly important. “When it comes to bending the global carbon curve, we are in a race against time,” said senior author Benjamin Z. Houlton, Ronald P. Lynch Dean of the Cornell University College of Agriculture and Life Sciences. “Our study demonstrates a new way to verify carbon dioxide removal via enhanced weathering, which is a critical leap forward for scaling this technology in croplands worldwide.” Other authors include Mallika Nocco, in the Department of Land, Air and Water Resources at UC Davis. The research, part of the Working Lands Innovation Center, was funded by the California Strategic Growth Council and the Grantham Foundation, Roger Sant and Doris Matsui. Aggregates and mining company, SGI, a Standard Industries company, donated the crushed metabasalt rock from its site in Ione, California. Media Resources Media Contacts: Iris Holzer, Department of Land, Air and Water Resources, UC Davis, ioholzer@ucdavis.edu Benjamin Z. Houlton, College of Agriculture and Life Sciences, Cornell University, bzhoulton@cornell.edu Amy Quinton, UC Davis News and Media Relations, cell 530-601-8077, amquinton@ucdavis.edu Photos and B-Roll Media Kit Primary Category Science and Climate Secondary Categories Feeding a Growing Population Tags crushed rock rock dust carbon storage UC Davis uc davis health veterinary medicine uc davis continuing and professional education uc davis stores uc davis arts uc davis mobile apps hiring uc davis students and alumni make a gift to uc davis Students orientation student resources graduate students student parents commencement internship and career center jobs and internships parents Alumni cal aggie alumni association career connections member benefits transcripts uc davis magazine Faculty resources teaching research benefits faculty governance Staff resources training benefits jobs staff assembly website feedback University of California, Davis, One Shields Avenue, Davis, CA 95616530-752-1011 Questions or comments? Privacy & Accessibility Principles of Community University of California Last update: October 24, 2023 Copyright © The Regents of the University of California, Davis campus. All rights reserved. This site is officially grown in SiteFarm.",
    "commentLink": "https://news.ycombinator.com/item?id=38015169",
    "commentBody": "Adding crushed rock to farmland pulls carbon out of the airHacker NewspastloginAdding crushed rock to farmland pulls carbon out of the air (ucdavis.edu) 245 points by geox 17 hours ago| hidepastfavorite249 comments jlhawn 16 hours ago> Previous studies have estimated this “enhanced” rock weathering could store 215 billion tons of carbon dioxide over the next 75 years if spread across croplands globally.This is an average rate of 2.8 Billion tons of CO2 per year. We currently emit over 35 Billion tons of CO2 every year so this could potentially offset about 8% of global emissions. Obviously not enough to get us to net zero but that is very significant in my opinion.I&#x27;m not certain how the economics of this solution would work. Is it easy to source, produce, and distribute this crushed volcanic rock? Would farmers get carbon credits for doing so? Or direct subsidies paid for by taxes on net-positive CO2 generating industries (which ironically is a lot of Ag itself)? reply chinchilla2020 15 hours agoparentLet&#x27;s not forget the massive CO2 generated by mining, processing, and transporting crushed rock.I used to work on SAG (semiautonomous grind) mills for fine grind on copper-bearing ore. Grinding rock is incredibly energy inefficient. I would suspect this entire process is carbon-positive despite the atmospheric capture.It seems we will do anything to avoid the obvious - we need to reduce energy use and transition to green generation. reply matznerd 12 hours agorootparentI don&#x27;t know why you have to \"suspect,\" when you can read the linked papers or any others...\"A life cycle assessment (LCA) about the potential of basaltic rocks for enhanced weathering and soil carbonation (Section 5.1.) found transportation (related to the distance between the quarry and the place of application) as the major process negatively affecting CO2 sequestration, whereas grinding had less effects on the CO2 budget, which could however be related to the relative coarseness (Grinding rock is incredibly energy inefficient. I would suspect this entire process is carbon-positive despite the atmospheric capture.Grinding the olivine to this study&#x27;s grain size of 83 microns[0] will consume roughly ~14 kWh&#x2F;tonne[1]. One tonne of olivine absorbs about 1.25 tonne of CO2, so that&#x27;s 11 kWh&#x2F;tonne for grinding, which is indeed likely to be the majority energy consumer.Clearly the solution is... build roads from olivine! :D Collectively, roadways are \"naturally\" subject to a huge amount of mechanical weathering, which currently mostly just generates asphalt microplastics.No doubt the cost&#x2F;geotechnics doesn&#x27;t work out, but it&#x27;s an amusing thought nonetheless. Maybe it could even be made workable, somehow...[0] https:&#x2F;&#x2F;iopscience.iop.org&#x2F;article&#x2F;10.1088&#x2F;2515-7620&#x2F;acfd89&#x2F;...[1] https:&#x2F;&#x2F;worksinprogress.co&#x2F;issue&#x2F;olivine-weathering&#x2F; reply danans 13 hours agorootparent> Grinding the olivine to this study&#x27;s grain size of 83 microns[0] will consume roughly ~14 kWh&#x2F;tonne[1]. One tonne of olivine absorbs about 1.25 tonne of CO2, so that&#x27;s 11 kWh&#x2F;tonne for grinding11kWh per tonne of CO2 sequestered is 2 orders of magnitude less energy per tonne than other DAC methods [1]. Assuming it is scalable (i.e. there is enough open land near the olivine deposits), then it is far cheaper.1. https:&#x2F;&#x2F;www.mcc-berlin.net&#x2F;en&#x2F;news&#x2F;information&#x2F;information-d... reply schiffern 12 hours agorootparentThe \"gotcha\" is that at 83 microns, this study showed only 0.15% of the theoretical CO2 capacity absorbed in the first year. Worse, the authors expect this rate to taper significantly in the second and subsequent years.This is why most EW proposals specify a smaller grain size, but that also has the effect of dramatically increasing the grinding energy required. See [1] (included again below) for a more complete and nuanced discussion of these tradeoffs.[1] https:&#x2F;&#x2F;worksinprogress.co&#x2F;issue&#x2F;olivine-weathering&#x2F; reply danans 10 hours agorootparent> The \"gotcha\" is that at 83 microns, this study showed only 0.15% of the theoretical CO2 capacity absorbed in the first yearAccording to the study [1] (and the article), that&#x27;s because the experiment was purposely conducted in a dry climate (inland northern CA) and during a drought to determine a lower bound on the CO2 absorption capacity. More well suited (wetter) climates are expected to result in more CO2 absorption.\"Given that climate change impacts such as heatwaves and droughts are already widespread, knowledge of the robustness of enhanced weathering under extreme conditions is essential to understanding its future efficacy. Here we show that enhanced weathering maintains modest carbon dioxide (CO2) removal in a multi-acre field trial under an extreme drought in California, one of the largest agricultural producers globally.\"1. https:&#x2F;&#x2F;iopscience.iop.org&#x2F;article&#x2F;10.1088&#x2F;2515-7620&#x2F;acfd89 reply InSteady 7 hours agorootparentprevShowing yet again that there is no free lunch, and we continue to eat the earth&#x27;s future with abandon. reply civilitty 11 hours agorootparentprevI think the second \"gotcha\" is that even at 83 microns, that particle size is likely unsafe. That&#x27;s about the size of gypsum dust used in drywall and you can&#x27;t cut or sand or do anything without PPE for long without serious health consequences. Make it any smaller and it&#x27;ll be well into the asbestos size range, which would probably be carcinogenic based on the mechanical damage it causes alone (a lot of nanoparticles are toxic for this reason). That&#x27;s safe in a controlled industrial environment with everyone using fitted respirators but spread out on fields exposed to wind, near residential areas? Dumping that much fine dust everywhere would probably create a similar hazard to the dried out beds of the Great Salt Lake or the Salton Sea or Blackrock Desert* except everywhere there is farmland.It&#x27;d have to be combined with a binder to form much larger particle sizes so that the natural weathering safely exposes the olivine slowly over decades. I suspect that once one does the math on the whole lifecycle, it&#x27;s net carbon positive only after decades if it is to be done safely.* People who have been to Burning Man can testify to just how much trouble dust that small causes, not to mention the frequent dust storms with zero visibility. reply lostlogin 1 hour agorootparent> I think the second \"gotcha\" is that even at 83 microns, that particle size is likely unsafe.It’s a bit dark, but wouldn’t a death toll improve the situation from an emissions perspective? reply WitCanStain 1 hour agorootparentIf you execute all the staff at every power plant in the world and then keep executing the subsequent replacement cohorts, every power plant would have to shut down and we would dramatically reduce global CO2 production. Similarly, if you position machine guns at major roads and keep shooting every car that comes through, you will eventually reduce the environmental toll of driving cars. replys0rce 13 hours agorootparentprevSeems like US average is 0.855 pounds of CO2 emissions per kWh so this process looks like a significant win. Also grinding a ton of rocks doesn&#x27;t use much energy if its just 14 kwh...https:&#x2F;&#x2F;www.eia.gov&#x2F;tools&#x2F;faqs&#x2F;faq.php?id=74&t=11 reply bagels 12 hours agorootparentHard to follow all the units, but, just for grinding, using these numbers:grinding: ~14 kWh&#x2F;tonne olivineabsorption: 1.25 tonne of CO2 per tonne of olivineemissions: 0.855 lbs CO2 &#x2F; kWhemissions: 5.4 kg CO2 per 1.25 tonne CO2 (1250 kg) absorbed reply pfdietz 7 hours agorootparent> emissions: 0.855 lbs CO2 &#x2F; kWhWhy do there have to be CO2 emissions? reply bagels 1 hour agorootparentYou could solar power it, or whatnot. I was just trying to contextualize the numbers others had written. reply oldbbsnickname 4 hours agorootparentprevThere don&#x27;t. The problem is a lack of remote industrial equipment that are EVs powered by renewable electricity sources rather than diesel fuel. reply defrost 4 hours agorootparentThat&#x27;s not really that much of a problem to be honest.If this is to be an industrial mining scale operation that goes in with a 600 million tonne per annum target (similar scale to iron ore for steel mining operations) then the company building out the capital assets will setup EV&#x27;s and solar on the grounds of both economy and PR.You can see this with Rio Tinto Iron, Fortescue Metals, etc. replyelproxy 13 hours agorootparentprevOr let oceans do some of the work: https:&#x2F;&#x2F;www.withouthotair.com&#x2F;c31&#x2F;page_246.shtml reply oldbbsnickname 4 hours agorootparentprev> Clearly the solution is... build roads from olivine! :DHaha. I&#x27;m glad you didn&#x27;t include \"solar\" or \"freakin&#x27;\". ;D reply mschuster91 12 hours agorootparentprev> Clearly the solution is... build roads from olivine! :D Collectively, roadways are \"naturally\" subject to a huge amount of mechanical weathering, which currently mostly just generates asphalt microplastics.Nah, asphalt microparticles are in the end just very viscose oil and rock dust from the filler. The microplastics from roads come from tire wear and brake dust. reply schiffern 11 hours agorootparent>asphalt microparticles are in the end just very viscose oilBitumen is still a plastic. In fact there are also increasing efforts to use post-consumer recycled plastic as an additive.Microplastics from road transport mainly come from tire dust, but also include road markings[0] (which are plastic mixed with glass microbeads), bitumen from asphalt[1], and yes a bit of brake dust.[0] https:&#x2F;&#x2F;resourcelab.dk&#x2F;plastics&#x2F;pollution&#x2F;oceans&#x2F;2018&#x2F;10&#x2F;11&#x2F;...[1] https:&#x2F;&#x2F;www.sciencedirect.com&#x2F;science&#x2F;article&#x2F;pii&#x2F;S004896972... reply onetimeuse92304 1 hour agorootparentprev> Grinding rock is incredibly energy inefficient.Fortunately, there is a relatively cheap way of producing that energy with solar or wind installations. Your rock grinding machine can actually improve electrical grid by using excess energy and being a first candidate to be turned off in case of electricity shortage.Another way of looking at this is that a rock grinding machine is a way to convert excess renewable electricity into oil. By converting renewable electricity into sequestered carbon you can allow amount of oil being used for net zero carbon footprint.Yes, it costs more (but not as much as some people think -- excess energy is actually much cheaper and in some cases can have negative value). We kinda now there isn&#x27;t going to be a solution that will be as cheap as what we have been doing up to this point. reply silentsanctuary 13 hours agorootparentprev> It seems we will do anything to avoid the obvious - we need to reduce energy use and transition to green generation.The idea behind carbon capture projects is this: for years, we have been given warnings that \"if we cut all emissions now, we will still be okay\", to \"if we cut all emissions now, it won&#x27;t be too bad\", and now we&#x27;re at the stage where even if we meet our emission targets, things are still going to be bad.If we want to avert disaster, we now need not only to cut emissions, but ALSO to actively remove carbon from the atmosphere. So, these projects are here to try and fill that unfortunate new need, because just cutting emissions will no longer... cut it. reply meandmycode 13 hours agorootparentSure, but where does the energy come from to actively remove? Because that&#x27;s usually the point, the energy creation created more than the removal removed. reply silentsanctuary 12 hours agorootparentIt&#x27;ll depend on the specific project in question (there are quite a few methods under investigation), but for enhanced weathering (the type under discussion), I found some articles in a quick search that suggest the energy cost of grinding and transporting the rocks is significantly smaller than the carbon removed by the programme, e.g. https:&#x2F;&#x2F;www.researchgate.net&#x2F;publication&#x2F;322664372_Potential... reply ipqk 12 hours agorootparentprevArbitrage it from places where green energy is cheap or free. For example, iceland has pretty much 100% renewable energy sources. Already it has an extensive aluminum industry because energy there is cheap, and aluminum is energy-intensive to use it.So, in theory, if you use green energy to produce a carbon-offset product, it&#x27;s still a useful product. reply vasco 2 hours agorootparentMaybe, you now have to produce that aluminum somewhere else. reply hinkley 7 hours agorootparentprevSurplus energy from wind farms over land with the right kind of rock.Anything you can’t shove into the grid grinds rock. reply oldbbsnickname 4 hours agorootparentprevIt&#x27;s about scalability of any particular process minimizing net $&#x2F;t (which includes kWh&#x2F;t). reply oldbbsnickname 4 hours agorootparentprevIn general, to be scalable and cheap, CCS needs to be mostly passive activities relying on biology and large surface areas. This would then usually involve farmlands, forests, or oceans. (Not necessarily trees because they lack automatic sequestration.) reply LeonB 9 hours agorootparentprevIn theory, you might be right. But in practice the biggest investors (and boosters) in carbon capture are oil and gas companies — and for them it’s a way to continue business as usual (i.e., continue to increase carbon output) while hand waving about some future CC project that will make this all ok. reply BurningFrog 14 hours agorootparentprev> It seems we will do anything to avoid the obvious - we need to reduce energy use and transition to green generation.Most of the world is doing just that.It&#x27;s much, much easier said than done. reply xmprt 14 hours agorootparentIt&#x27;s pretty easily done too. It&#x27;s just that it&#x27;s not a very fun thing to do. Like eating vegetables. It&#x27;s pretty easily done but that doesn&#x27;t mean everyone does it. reply BurningFrog 13 hours agorootparentThat&#x27;s a very rich world perspective.Fossil fuels have - at the same time as the pollution - caused a huge improvement of living standards. A substantial part of the human population tripling in size comes from that, and huge number of people would die if fossil fuels magically disappeared. reply ajuc 13 hours agorootparentIn the limit almost all people die in both extremes (if we stop all fossil fuel use today and if we don&#x27;t limit fossil fuel use at all).There is middleground that saves most of people. We&#x27;re not doing that because we value our comfort now more than other people&#x27;s lives later. reply te_chris 13 hours agorootparentprevLiving standards increases right the way to extinction. Ultimate tragedy of the commons. reply drekk 13 hours agorootparentprevThe richest 1% is responsible for 49% of lifestyle emissions. The poorest 50% are responsible for just 10% of emissions. It&#x27;s really disingenuous to act like most of our CO2 emissions are being spent lifting people out of poverty rather than on luxuries like meat consumption or fast fashion. https:&#x2F;&#x2F;journals.sagepub.com&#x2F;doi&#x2F;abs&#x2F;10.1177&#x2F;001391651771068... reply gruez 8 hours agorootparentYour link doesn&#x27;t work. I&#x27;m getting \"The requested article is not currently available on this site.\"Also the studies I&#x27;ve seen to this effect use a questionable form of attribution when it comes to the \"1%\". Specifically they include emissions from companies that they invest in. reply mcpackieh 10 hours agorootparentprev> \"The richest 1% is responsible for 49% of lifestyle emissions. [...] luxuries like meat consumption or fast fashion\"How many megatons of meat do you think Musk eats a month? Does Bezos put a billion burgers into his belly? The vast majority of meat is consumed by people in that bottom 99%. For that matter, how many fast-fashion trendy patterned stockings do you think these men wear? It&#x27;s really disingenuous to act like you&#x27;re against luxuries for the 1% and then use meat and cheap clothing as your examples of great evils to be eliminated. Who would be sacrificing if large scale production of these cheap goods were banned? Not the 1%. What you are proposing is not to tear down the 1%, but to suppress the standard of living for the 99%.Maybe you just chose bad examples by accident though, do you have any proposals that would actually limit emissions from the 1% instead of capping the quality of life for the other 99%? reply coderenegade 4 hours agorootparentIt&#x27;s in the pattern of consumption. Obviously Elon Musk can&#x27;t eat orders of magnitude more beef than the rest of us, but in 2017 he announced that the boring tunnel would dig a tunnel directly to his house. Now I don&#x27;t know if he ever did that, but it&#x27;s not particularly far fetched for someone with his resources to do. For arguments sake, the emissions of such a tunnel would be ludicrous when you calculate on a per person basis. Then you have emissions associated with luxury yachts, helicopter rides, private jets, etc. on top of elevated normal consumption (i.e. able to travel more often via normal means, while occasionally also taking the jet for a spin).The very wealthy are able to afford to not go through the same public channels as the rest of us, and so their emissions don&#x27;t get amortized over vast numbers of users. This is on top of the fact that they can already consume more anyway, which is to say, I have one car, but the very wealthy might collect them (buying new! another thing I&#x27;ve never done), and just the process of manufacturing a new car releases more CO2 than I could produce in several years of driving. reply oivey 9 hours agorootparentprevHe’s not taking about the richest 1% of Americans.Even if he was your examples are disingenuous. Musk and Bezos aren’t representative of even the richest 1% of Americans. reply mcpackieh 8 hours agorootparentI knew this was coming, all Americans are the global 1% right? Did I even say anything about America? Regardless...Get a napkin and sanity check yourself. 1% of 8 billion people is 80 million. There are 330 million people in America. If all of the global 1% are in America and not also in Europe and Asia, which is obvious bullshit, then only 24% of Americans are in that 1% and the remaining 76% are in the lower 99%.And do you really think only Americans eat meat and wear cheap clothing? Get real. reply oivey 8 hours agorootparentWhat are you even talking about? The person you replied to didn’t say Americans. Were you trying to use Bezos and Musk as representative of the top 1% of the worldwide population? That’s even worse. replyClumsyPilot 10 hours agorootparentprev> Fossil fuels have - at the same time as the pollution - caused a huge improvement of living standards.And before that we used Whale oil, which we got through a global slaughter of whales and we nearly drove them to extinction. Then it was time to move on. reply gruez 8 hours agorootparentThere&#x27;s a huge difference between migrating off something because there&#x27;s something objectively better (oil is cleaner and cheaper compared to whale oil), and migrating off something for environmental reasons. The former doesn&#x27;t require any sacrifices and will happen voluntarily. The same can&#x27;t be said for the latter. reply uoaei 12 hours agorootparentprevIt&#x27;s a rich world perspective to buy new cars every couple years, including electric cars which massively frontload the emissions borne of those cars, or to go home every night and stream 1080p video into your living room for hours on end while serving up gigs of photos and video to your phone through Instagram and TikTok. Datacenters are something like 20% of all energy consumption.In many parts of the world, even places you&#x27;ve heard of, people walk or bike everywhere they need to go and spend their free time sitting around chatting with neighbors.No one&#x27;s arguing to delete fossil fuels, but it makes sense to minimize usage to freight and public transit. reply sokoloff 9 hours agorootparent> Datacenters are something like 20% of all energy consumption.Do you have a source for that? It didn&#x27;t sound right and my quick Googling suggests that it&#x27;s off by around a factor of 20 or more. (Some put datacenters as low as 1% of total electricity consumption, which is a subset of all energy consumption.) reply uoaei 8 hours agorootparentIt was admittedly hearsay. My research says it&#x27;s about 2% of energy use in the US and 1% of electricity use worldwide with remarkable constancy in electricity demands due to storage and computing efficiency gains. Thanks for the reality check. reply harimau777 14 hours agorootparentprevMost people&#x27;s lives suck and the only thing that they have going for them is consumerism. So it&#x27;s reasonable that they are unwilling to give up consumerism.Therefore, the hard part is changing the structure of society so that people&#x27;s lives don&#x27;t suck. reply carapace 10 hours agorootparentThe solution there is the same thing: living in harmony with nature. It&#x27;s carbon-neutral or -negative and very fun and fulfilling. reply jl6 1 hour agorootparentVery fun, up to the point you get ill and start wishing industrial society still existed to manufacture modern medicines. reply gruez 8 hours agorootparentprevThis is as realistic as peace in the Middle East by getting both sides to sit on a beach and sing kumbya reply bheadmaster 14 hours agorootparentprevAre you implying that living a life without fun is easy? reply xmprt 14 hours agorootparentMaybe I should have rephrased it. There are fun ways to live a life without emitting a bunch of carbon just as there are tasty ways to cook vegetables. It&#x27;s just that people don&#x27;t want to and more importantly, governments don&#x27;t want to. reply CalRobert 49 minutes agorootparentI used to live in LA, spend tons of money on my car, not be able to do things because they were on the wrong side of the 405, and eat tons of low quality meat. Now I live in the Netherlands, bike or take the train everywhere, and occasionally eat high quality meat. My emissions are much, much, much lower here. I&#x27;m tired of being told how great my quality of life would be with cheaper gas and a bigger house. reply bheadmaster 14 hours agorootparentprevSo, it&#x27;s easy, but people don&#x27;t want to do it because... they&#x27;re evil? reply NumberWangMan 13 hours agorootparentIt’s multipolar trap&#x2F; coordination problem. The costs of carbon emissions are diffuse and borne by everyone, while the costs of changing your behavior are mostly borne by you. It’s just a sad fact of life, and to solve it the only feasible way is to change the rules to making decarbonizing cheaper than continuing to use fossil fuels. reply gruez 8 hours agorootparentThis has nothing to do with what the parent and grandparent comment was talking about, which is that carbon emissions can somehow be made without sacrificing lifestyle quality. Your comment implicitly admit that sacrifices have to be made. replytacocataco 11 hours agorootparentprevVegetables are delicious if you cook them right.Maybe the solutions we have on how to cut on emissions is canned. reply oldbbsnickname 4 hours agorootparentprevExactly. There is little-or-no desire to eliminate animal agriculture despite the obvious data that it is killing us as much as FF private vehicles. There are many luxuries and senses of entitlements that cannot be curtailed politically short of authoritarian decree. reply codr7 14 hours agorootparentprevThere&#x27;s no profit in saving the planet.Dig deep enough into any initiative that claims to be doing that and you&#x27;ll find that it has far reaching consequences that negate whatever positive impact it has on the planet, and dealing with them would reduce profits. reply gibolt 14 hours agorootparentNot true. True green technologies are already profit drivers. EVs, solar, wind, heat pumps... are becoming so cheap and efficient that not switching for industrial use (and often personal) costs more. reply sokoloff 9 hours agorootparentFor heating use only, heat pumps are more expensive than natural gas in my area (MA, with ~$0.25&#x2F;kWh electricity and $0.85&#x2F;therm gas supply plus ~$1.13&#x2F;therm delivery).I tried to make a heat pump make sense for heating here. I couldn&#x27;t make it economically pencil out. I hope I&#x27;m around and I hope the economics are different in 20 years when it comes time to replace the heat source in my house again. reply hex4def6 12 hours agorootparentprevThat&#x27;s not (automatically) true.If you change the rules of the game, you change the winning strategies. By extension, you&#x27;re changing which industries may be in competition with each other (or end up being completely obsolete), and which companies may end up having an advantage. If you ban (say) natural gas water heating, the losers will be gas supplier companies, perhaps all the peripheral industry dedicated to creating gas pipes and fittings, the pipe fitters, companies that specialize &#x2F; have IP around efficient gas heat exchangers, etc.On the other hand, the winners may now be companies that have IP &#x2F; manufacturing capabilities for heat-pump technology, electricity producers, copper mines (increased load on the grid), etc etc.Each rule change may have a net positive or negative on the greater economy in general both in the near term and far term.In my example, heat pump water heaters are $$$ compared with conventional ones and would increase the demand on electricity (increasing its price). These hit people&#x27;s pocket books, and reduce discretionary income to spend on other stuff.On the other hand, the significant increases in complexity might result in a higher-skilled workforce requirement (with increased wages), fewer deaths due to carbon monoxide &#x2F; gas explosions, fewer nitrous oxide related illnesses (decrease in healthcare costs), and maybe a hundred other knock-on effects. reply NumberWangMan 13 hours agorootparentprevThere absolutely could be (profit I mean), if we taxed fossil fuels enough. reply ClumsyPilot 10 hours agorootparentprev> There&#x27;s no profit in saving the planet.Why does this sound like a suicide cult? reply oldbbsnickname 4 hours agorootparentprevClinker manufacturing for cement and concrete is amongst the worst offenders. This can be made greener with closed-loop production and CCS, and there are already efforts nearing or at commercial production with it. reply Muromec 1 hour agorootparentOr reduce cement consumption by building with wood, which carbon negative reply BenFranklin100 8 hours agorootparentprevI think the lesson is that must accept the inevitable - worldwide energy usage will continue to increase, especially as the third world modernizes, and the only way to manage this increase in a low carbon manner is to accept that nuclear along with renewables will play an integral part in this green transition. reply forgetfreeman 3 hours agorootparentprevThere&#x27;s the obvious thing everyone&#x27;s trying to avoid: reduce energy usage, and then there&#x27;s the obvious thing everyone&#x27;s REALLY trying to avoid: cut global population by 2&#x2F;3. reply Muromec 1 hour agorootparentIsn’t it what we had 5g with Covid sponsored by WEF for? reply klysm 15 hours agorootparentprevwhat about using rock that&#x27;s already being crushed for processes like that? Still have the transport but may as well use the ground stuff for something. reply kansface 15 hours agorootparentWe are talking about adding it to farmland so we really care about yields and safety. reply chinchilla2020 15 hours agorootparentprevPossibly. I am not familiar with the sort of basalt they are using here.It may very well make sense under those conditions. reply kisamoto 15 hours agorootparentOlivine is in ready supply as a by-product from the mining industry. There are piles of it laying around (which don&#x27;t have the same effect as spreading it out) although they do need to be transported to projects. reply klysm 13 hours agorootparentBy-product is the word I was looking for. Hopefully there isn’t a need for primary production reply ilyt 14 hours agorootparentprev> It seems we will do anything to avoid the obvious - we need to reduce energy use and transition to green generation.Well if you haven&#x27;t noticed yet, that&#x27;s the hard part and some emission is inevitable at least for near future. We won&#x27;t get rid of fossil fueled planes or cargo ships anytime soon reply stronglikedan 13 hours agorootparentprevOnce they&#x27;re there, they keep doing their thing for years, so maybe only carbon-positive for a limited time. reply fudged71 14 hours agorootparentprevDo you think gravity-assisted rock crushing could be feasible? reply dessimus 14 hours agorootparentYes, drop a large enough rock from, say, orbital height and there might be zero carbon emissions going forward. reply progne 14 hours agorootparentFor a rock to extinguish all life on and in Earth from an orbital drop it would have to be quite large. I suppose Jupiter would be big enough. reply mkl 11 hours agorootparentJust human life would do, not all life. But just a drop wouldn&#x27;t have the relative speed of most asteroid impacts. reply chinchilla2020 12 hours agorootparentprevYou just invented block cave mining https:&#x2F;&#x2F;www.e-education.psu.edu&#x2F;geog000&#x2F;node&#x2F;911It&#x27;s been in use for a long time and is great for fragmenting large rocks and boulders. It does still need grind after the main fragmentation is done.SAG Mills use the same concept to grind rock to a finer level. Most of the abrasion is rock-on-rock inside the mill. reply CityOfThrowaway 14 hours agorootparentprevTo use gravity, you only have two options:1. Knock things down that are already high up and hope they break at the bottom. Or,2. Haul things up and then knock them down.#1 only works in an extremely limited number of cases and gets exhausted quickly. #2 spends more energy hauling up than it gains. reply oldbbsnickname 4 hours agorootparentprevAs long as it&#x27;s not a Sisyphean task. reply salynchnew 14 hours agorootparentprev\"Join my asteroid bombardment startup....\"&#x2F;s reply NoMoreNicksLeft 13 hours agorootparentprev>It seems we will do anything to avoid the obvious - we need to reduce energy use and transitioI&#x27;m not sure how this is supposed to be obvious. It&#x27;s using vague language that makes it sound as if this is a trivial lifestyle change. \"reduce energy use\" at the rate you&#x27;re hinting at strongly means things like:* Eat less food, and worse food * Wear worse clothes longer, perhaps until they fall apart * Live in smaller, cramped housing that is colder in the winter and hotter in the summer * Go fewer places, but not just as a tourist, also for practical needs, limiting the job opportunities of many * Have less entertainment * Use less water, the bulk of which for any given person is used for hygieneNow that I have done the actual work of making it obvious what you suggest, are you still saying we need to do those things, and if you aren&#x27;t saying that, just where do you imagine energy can be reduced? reply dTal 11 hours agorootparentI don&#x27;t agree with most of those bullet points. Some of them don&#x27;t follow at all, but in every category there is at least a 90th percentile change we could make that wouldn&#x27;t be some terrible imposition. It boils down to class war: the people who would have to make the most sacrifice are the people who are already using way more than their fair share. So for each of your points where you use words like \"less\" and \"worse\", we must ask:Less than, worse than? First world people eat entirely too much, and unhealthily. Not hard to imagine diets better for humans and the ecosystem. Hell, 1.5 billion people are already vegetarian and doing fine. People will complain about eating less steak but it&#x27;s a first world problem.Worse than? Durable clothes are better for the environment, and classier. Disposable \"fast fashion\", made of plastic and sewn by quasi-slaves in sweatshops is the real problem. People will complain about losing a dopamine button but it&#x27;s a first world problem.Smaller than? It&#x27;s completely possible to improve thermal efficiency without altering size. Maybe, if you live in a sprawling poorly insulated McMansion, you should invest in better insulation - or a better house - instead of powering through by burning energy. Apartment blocks are already far more efficient for climate control (square&#x2F;cube law), so it&#x27;s squarely a rich person&#x27;s problem.Fewer places than? Are people taking jet airplanes to work every day? Yeah, they should probably stop that. People taking the train are probably in the clear. This isn&#x27;t even a first world problem, it&#x27;s a superrich problem. Of course they&#x27;ll complain...What \"entertainment\"? This doesn&#x27;t follow at all. \"Entertainment\" isn&#x27;t a particularly energy-hungry category. Maybe if you&#x27;re entertained by mining bitcoin? The most entertaining thing I own, besides my laptop, is a Synthstrom Deluge Groovebox, which runs for 9 hours on a single 18650 lithium cell.Water: Another one that doesn&#x27;t follow. I suspect the bulk of water for a given person is actually agricultural, so see point 1. But as important as it is to preserve freshwater ecosystems, I don&#x27;t see the direct bearing on energy consumption. Most municipal water comes from reservoirs, not desalination. reply gruez 6 hours agorootparent>Less than, worse than? First world people eat entirely too much, and unhealthily. Not hard to imagine diets better for humans and the ecosystem. Hell, 1.5 billion people are already vegetarian and doing fine. People will complain about eating less steak but it&#x27;s a first world problem.That might be true, but people also know they&#x27;re eating too much and unhealthily, yet they continue doing so. Clearly getting them to stop requires much more effort and sacrifice than you make it out to be.>People will complain about losing a dopamine button but it&#x27;s a first world problem.So you admit that it&#x27;s actually worse? You&#x27;re just hand waving it away by inserting your own value judgement.>Smaller than? It&#x27;s completely possible to improve thermal efficiency without altering size. Maybe, if you live in a sprawling poorly insulated McMansion, you should invest in better insulation - or a better house - instead of powering through by burning energy. Apartment blocks are already far more efficient for climate control (square&#x2F;cube law), so it&#x27;s squarely a rich person&#x27;s problem.See above.>Fewer places than? Are people taking jet airplanes to work every day? Yeah, they should probably stop that. People taking the train are probably in the clear. This isn&#x27;t even a first world problem, it&#x27;s a superrich problem. Of course they&#x27;ll complain...You&#x27;re ignoring going to far away places for tourism, visiting friend and family across the country, and going to the Costco on the other side of town. reply sokoloff 9 hours agorootparentprev> Less than, worse than?Less than&#x2F;worse than that person is doing now. (But I&#x27;m pretty sure you knew that.) reply NoMoreNicksLeft 4 hours agorootparentprev> What \"entertainment\"? This doesn&#x27;t follow at all. \"Entertainment\" isn&#x27;t a particularly energy-hungry category.You&#x27;re disingenuous, or naive. One&#x27;s as bad as the other.This isn&#x27;t 400 BC. When anyone here wants to be entertained, they don&#x27;t ride the donkey cart down to the stone amphitheater and watch a play in torchlight (and you probably wouldn&#x27;t allow the torches either, too many particulates).For any sort of entertainment anyone might conceive, there is a manufactured good involved.> Less than, worse than? First world people eat entirely too much, and unhealthily. Not hard to imagine diets better for humans and the ecosystem.We&#x27;re engineers here. It doesn&#x27;t work like that. One parameter of the other, and we already heard you say which one you&#x27;d pick.> Worse than? Durable clothes are better for the environment,But they won&#x27;t be durable. They&#x27;ll just get worn out, but you&#x27;ll wear it anyway because you can&#x27;t get it replaced. As it was centuries ago. When someone dies, they&#x27;ll fight over the clothes, they&#x27;ll be that precious again. At least if you have your way.>Fewer places than? Are people taking jet airplanes to work every day?Those people are connected. It&#x27;s the guy who drives a shitbeater car that you&#x27;re worried about.All of my bullet points follow. They&#x27;re just shining the poorest possible light on your political agenda. reply chinchilla2020 12 hours agorootparentprev* less consumption of manufactured goods * less travel, both of humans and freight * high density housing instead of SFHsThat can significantly reduce CO2 in the short term. Sure you won&#x27;t be able to buy as many widgets on Amazon - but we won&#x27;t be on hackernews discussing silly carbon capture methods to make marginal gains that will never feasibly happen on a global scale. reply scythe 14 hours agorootparentprev>I would suspect this entire process is carbon-positive despite the atmospheric capture.Consider the napkin math. One mole of MgSiO3 reacts with one mole of CO2 to give MgCO3 + SiO2. The embodied energy in CO2 from C + O2 is 393 kJ&#x2F;mol. One mole of MgSiO3 weighs 100 grams (almost exactly) and has a specific heat of roughly 1 kJ&#x2F;kg-K. That works out to roughly the amount of energy required to heat the olivine by 3930 Kelvins, although this is well beyond the point at which specific heat becomes nonlinear and would most likely melt the sample.Since it is uncommon for rocks to melt when grinding we can conclude that the embodied energy in the carbon absorbed is way larger than the energy required to grind the material. The inefficiency of electric generation certainly comes into play but even if we use a factor of 1&#x2F;5 we still find a temperature rise of 786 Kelvin which would be extremely damaging to equipment if it actually occurred, and the actual temperature rise is probably less than 100 Kelvin. This still gives a comfortable margin of inefficiency for the carbonation process. And we have assumed that all of the energy is coming from inefficient coal-burning plants, which are in reality a minority of the global energy mix.Consequently, we can conclude unequivocally that olivine grinding absorbs more carbon than it emits even under relatively pessimistic assumptions, and dramatically more carbon than it emits under realistic assumptions. While the energy of grinding is large, the embodied energy of CO2 is very large — this is why carbonaceous fuels became popular.There are downsides to the process — most obviously but with a distant horizon, sequestration of carbon in this manner is precisely the process expected to eventually destroy the biosphere by carbon starvation in a few hundred million years, and using olivine to stop global warming is slightly accelerating the inevitable doom of all life on Earth. Also, it takes up a lot of space and costs a lot of money. And inevitable doom. But you know, priorities. reply saalweachter 14 hours agorootparentYou&#x27;re probably looking for the fracture energy -- the energy required to create a fracture with a unit surface area.Take the grain size you&#x27;re looking to end up with, compute the surface area and mass, combine it with the fracture energy, and you should have a pretty decent estimate for the energy required to grind a particular substance to a particular size. reply euroderf 14 hours agorootparentprevThe US has a very high imprisonment rate. How &#x27;bout we create lots more laws that specify sentences of hard labor... breaking up olivine ? reply thereisnospork 11 hours agorootparentprevYour energy math, or its explanation, is incorrect. the embodied energy in CO2 is irrelevant - the comparison is of products and reactants, of which &#x27;C&#x27; and &#x27;O2&#x27; are neither. reply kisamoto 15 hours agoparentprevVery significant impact. There is no silver bullet that can remove the excess emissions on it&#x27;s own, however combinations of these removal methods (coupled with decarbonization of course) will be essential to addressing excess atmospheric CO₂.Regarding economics; there is plenty of olivine rock already available as a mining by-product. Disadvantages are that it takes up to 1000 years to fully sequester however this is logarithmic with a large portion of this achievable in the first century (why they mention 75 years in this article). This can be accelerated with further grinding to increase surface area.I would imagine that regulations for net-zero will push for carbon removals to be sold similar to carbon credits have been (as net-zero can only be achieved with removals, not credits). These could either be sold as they are created annually or pre-purchased as the mineralization is a pretty sure thing to happen.Whether this (as in CO₂ removal, not limited to enhanced rock weathering) evolves into a public service equivalent to garbage collection or a utility like water is yet to be seen. reply oldbbsnickname 4 hours agorootparentI would bet seaweed or phytoplankton plus floating farm rigs would readily lead to scalable CCS. A few small regions of Earth&#x27;s oceans would need to be sacrificed for sequestration.https:&#x2F;&#x2F;www.businessinsider.com&#x2F;sargassum-turning-smelly-sea... reply spankalee 16 hours agoparentprevThe collective will we&#x27;d need to deploy this globally would probably indicate that we also somehow magically gained the collective will to reduce emissions.This is the problem with some of the geo-engineering approaches. We&#x27;ve shown that we can&#x27;t really change how society and industry operate enough to reduce emissions, so what makes us think we can do the same for carbon capture? How do you actually get every farm to do this? reply bluGill 15 hours agorootparentDon&#x27;t be so down. We have solved the ozone hole problem - it will take years to heal, but we emit very little ozone destroying things anymore. Last year my local utility generated more power from wind than there was demand. People do care and are making change. Change is slow to come, and even after it happens takes a long time to make a difference, but there are signs of change and the cause is being taken care of.Don&#x27;t take that too far: there is a lot of work to do. However we have a good idea what that work is we just need to apply it. reply ilyt 14 hours agorootparentOzone hole was \"just\" replacing one chemical with another and changing refrigerator units a bit; CO2 emissions are orders of magnitude bigger as near-everything related to industry or standards of living emits CO2 in direct or indirect way. reply bluGill 14 hours agorootparentMy utility generated electric power via wind last year than all customers combined used. Electric cars are obviously taking over. Those are very encouraging signs since a large portion of CO2 comes from electric or transport uses. There are other uses aw well to work on, and some challenges in those areas, but things are looking very good. reply mrkeen 15 hours agorootparentprevIt&#x27;s big againhttps:&#x2F;&#x2F;www.esa.int&#x2F;Applications&#x2F;Observing_the_Earth&#x2F;Coperni... reply neon_electro 15 hours agorootparentBut still on track to shrink? From your source (thank you for the read):> Claus concludes, “Based on the Montreal Protocol and the decrease of anthropogenic ozone-depleting substances, scientists currently predict that the global ozone layer will reach its normal state again by around 2050.” reply arrowsmith 14 hours agorootparentprevThere was a discussion about this on the front page the other day:https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37949994If I understand correctly then the ozone hole fluctuates with the seasons but on average it&#x27;s still shrinking. reply PeterisP 14 hours agorootparentprevThe hope (and IMHO only reason) for geo-engineering approaches is that they can enable achieving a large effect with a much smaller political sacrifice than cutting people&#x27;s consumption or preventing some countries from increasing their consumption to \"first-world\" levels, and at a smaller cost than that.If someone finds a plausible way to reduce a major part of global greenhouse gases that costs merely, say, 10 or 100 billion, then that&#x27;s something that a few major countries can do (and fund) unilaterally and doesn&#x27;t need global consensus, unlike major emissions reductions which have the tragedy of commons problem where if you do that and other major emitters don&#x27;t, then you&#x27;ve crippled your economy but haven&#x27;t prevented any of the bad consequences. reply delecti 15 hours agorootparentprevThe comment you replied to suggested carbon credits. That seems like a pretty obviously good answer. We&#x27;re bad at forcing people to make broad changes, but nudging with money like that is often effective. reply marcosdumay 15 hours agoparentprev> metabasalt and olivineWell, yes, a lot of farmers (not all, probably most) are interested on adding those to their soil and will do it if it&#x27;s cheap enough.I&#x27;m not sure we can mine, pulverize, and distribute it in a carbon-negative way. But yeah, coupled with large scale implantation of renewables and decarbonization of transportation, it may be enough to even roll climate change back a little bit. reply vonwolfhausen 15 hours agorootparentOlivine comes from Norway, which uses hydro power. The energy in extracting and crushing is around 4kg CO2&#x2F;ton. Pulverizing is around 30-50kgCO2&#x2F;ton rock. Majority of transport is on water (ocean, river), which is low emissions. In the end, for every ton of rock around 850kg of CO2 are removed.For basalt, it&#x27;s around 200kg net, so the supply chains have to be shorter.I checked my math with the DOE&#x27;s experts, and it checks out. reply gattilorenz 14 hours agorootparentSource for the numbers? reply matznerd 11 hours agorootparentSibelco&#x27;s Aheim mine essentially supplies a large part of the world&#x27;s olivine today. It is located in a Fjord with its own port. The transportation distance is very small.See their website here: https:&#x2F;&#x2F;www.sibelco.com&#x2F;en&#x2F;150-years&#x2F;aheim\"The proximity of Aheim’s mine, processing facility and shipping terminal enables Sibelco to run a highly efficient operation with minimal transport or double-handling of materials. Quarried olivine is moved via conveyor belt through a 4km tunnel to the processing plant where it is crushed, dried and screened into different grades.\"When transporting mostly by ship, olivine ERW efficiency can remain >90% even with 1000+ kilometers of sea transit.See this working paper: Environmental life cycle assessment of CO2 sequestration through enhanced weathering of olivine https:&#x2F;&#x2F;legacy.projectvesta.org&#x2F;wp-content&#x2F;uploads&#x2F;2019&#x2F;06&#x2F;E... reply euroderf 14 hours agorootparentprevYes, further details would be very illuminating ! reply ben_w 15 hours agoparentprev8% sounds good to me.The required reduction in emissions is 99.9% (net), which is approximately \"everything everywhere except maintaining grassland\"[0] if done by reducing gross emissions; the last percentage point of a problem is usually the most difficult, so if we can get a whole 8% by making a cheap sink, that&#x27;s probably for the best.Just so long as it&#x27;s in the sweet spot of \"cheap enough\" without crossing over into the realm of \"people can make money mining the CO2 out of the air\", because if that happens then the same economic pressure that means we have too much CO2 now will become one of too little CO2.[0] https:&#x2F;&#x2F;ourworldindata.org&#x2F;ghg-emissions-by-sector reply jamescrowley 13 hours agoparentprevI thought it worth mentioning that a startup called UNDO (https:&#x2F;&#x2F;un-do.com&#x2F;) is already doing this - and have designed a carbon credit methodology with Puro.earth (https:&#x2F;&#x2F;puro.earth&#x2F;accelerate&#x2F;undo-enhanced-rock-weathering-...)The crushed basalt they use is already a byproduct from quarries they partner with from what I understand. reply epistasis 16 hours agoparentprevWe need to get to negative emissions in the second half of this century. From 5-10Gton&#x2F;year, IIRC.So this should not be used to offset new emissions, but thought of as a way to claw back the damage we are still creating today. reply mjan22640 15 hours agorootparentThose emitting CO2 will pay, and those capturing will receive the money. reply PeterisP 14 hours agorootparentPerhaps that&#x27;s how it should be in a perfect world, but in the world we live in that isn&#x27;t the case and doesn&#x27;t seem likely to be the case - there are some local markets for CO2 incentives, but on the international level there&#x27;s no willingness for major emitter countries to pay other countries, no evidence that (or why) this willingness might appear, and there&#x27;s no global government that could make or enforce any rules unless countries opt-in; nobody can force nuclear countries to pay others. reply mschuster91 11 hours agorootparentAgree on the rest, but on none of this:> but on the international level there&#x27;s no willingness for major emitter countries to pay other countries, no evidence that (or why) this willingness might appearOf course no one wants to pay, but courts have already begun shifting their attitude in a number of historic rulings against large emitters, and there are a ton of cases being in progress at the moment [1]. IMHO it&#x27;s only a matter of time until the first court orders direct international financial damage payments, particularly to countries that threaten to be literally flooded from the map like Vanuatu [2]. For what it&#x27;s worth, most Western countries already pay large sums of money to the Global South as part of general development aid.> and there&#x27;s no global government that could make or enforce any rules unless countries opt-inThe US absolutely can, like they did with anti money-laundering legislation. Everything and everyone that touches the US dollar is, in the end, accountable to the US and its will.Besides, who would have thought that the world would eventually converge on getting rid of tax havens? To force the Swiss of all people to dismantle the holy grail of bank secrecy? Almost no one, given the absurd amounts of money at stake, and yet it happened (partially though as a consequence of the various leaks of tax evader data).[1] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Climate_change_litigation[2] https:&#x2F;&#x2F;www.washingtonpost.com&#x2F;climate-solutions&#x2F;2023&#x2F;03&#x2F;29&#x2F;... reply PeterisP 11 hours agorootparentI understand your position, however, I feel there&#x27;s lots of wishful thinking there. The key issue is whether the industrialized first world countries would be forced to compensate the &#x27;global south&#x27; for the damage of the global warming beyond anything they willingly choose to donate as part of their foreign aid budgets, and for that I strongly believe the answer is negative.Of the examples you provide, there are a ton of cases but not a lot of judgments, and furthermore these cases are overwhelmingly against specific companies and many of them for violating obligations they have under USA law. USA permits that as long as they feel that it matches their interests (e.g. having British Petroleum pay a compensation to some USA city is a good thing) and it can and will alter the laws of this liability if they start threatening USA interests.The Vanuatu example you state is (a) explicitly not asking for any financial damages[1], (b) the only thing that was agreed was to forward it to the ICJ; and (c) the decisions of ICJ are not binding, and USA has an explicit policy since 1986 to choose on a per-case basis whether they&#x27;ll want to consider themselves under ICJ jurisdiction for that case or not, and so do other countries.W.r.t the lack of global government - yes, you provide examples of how diplomatic and trade pressure from powerful countries can push smaller ones to concede. That doesn&#x27;t work in the opposite direction - the same mechanisms can&#x27;t force USA (or China) to change their policies or fund global change.Fundamentally, USA (just as any sovereign country) doesn&#x27;t legally owe Vanuatu anything beyond those obligations that they willingly take on, international law is simply about controlling adherence to a set of voluntary contracts between countries. And even for the existing conventions, international law is clear that countries can abandon them when they don&#x27;t like the obligations, and that has happened many times in the past - so I&#x27;ll repeat my point that any compensations will happen only if (and to the extent of) that the western governments opt-in, and as the consequences of the climate crisis increases, their willingness to do so will be even more limited by the needs of their own voters.[1] Quoting the same washingtonpost article, \"As Vanuatu gained support for the U.N. action, it was careful to try to build consensus, with its leaders saying they are not suing anyone nor seeking to create new international obligations. Instead, they say, they are seeking to clarify how preexisting international agreements apply to climate change.\" replysupergeek 15 hours agoparentprevAgriculture is currently massively carbon intensive and is one of the hardest modern technologies to decarbonize. It relies on fertilizer production that is currently completely reliant on fossil fuels. If this can decarbonize agriculture, that&#x27;s a massive win for our chances to reach net zero carbon emissions on time. reply mhandley 15 hours agoparentprevIf 2.8 billions tonnes isn&#x27;t enough, can we just spray additional olivine powder over the surface of the ocean? Presumably it would lock up CO2 in the seawater just fine, allowing more CO2 to be absorbed by the ocean from the air. reply matznerd 12 hours agorootparentNeed very fine particles for that and its usually classed then as ocean alkalinity enhancement (OAE). A hybrid method has been proposed in the literature, to use beaches and is currently being implemented via a project I started (but which I am no longer with) that has been turned into a company called Vesta -> https:&#x2F;&#x2F;vesta.earthRolling stones; fast weathering of olivine in shallow seas for cost-effective CO2 capture and mitigation of global warming and ocean acidification https:&#x2F;&#x2F;esd.copernicus.org&#x2F;preprints&#x2F;2&#x2F;551&#x2F;2011&#x2F;esdd-2-551-2...https:&#x2F;&#x2F;smartstones.nl&#x2F;research&#x2F;publications-2&#x2F; reply reaperman 16 hours agoparentprevAnd how much would it affect agriculture? Do the plants thrive if you do this every year? reply philipkglass 15 hours agorootparentAdding ground silicates can significantly increase agricultural productivity on various kinds of land. Here&#x27;s one review article about the subject:\"Remineralizing soils? The agricultural usage of silicate rock powders: A review\"https:&#x2F;&#x2F;www.sciencedirect.com&#x2F;science&#x2F;article&#x2F;pii&#x2F;S004896972...IIRC the soils that benefit the most include:- Soils depleted in micronutrients- Acidic soil- Silica depleted soil (significant for rice farming and other silica-sensitive crops)Most of the world&#x27;s acidic and depleted soils that could benefit the most are in warm tropical regions with heavy rainfall. That&#x27;s also where fresh mineral applications would weather most rapidly to draw down CO2. Unfortunately, it may also be harder (logistically and culturally) to encourage silicate applications on those soils than on the temperate climate soils of North America.After a certain point adding more silicates doesn&#x27;t help increase soil productivity. The one thing that I haven&#x27;t found any reporting on is where the \"too much\" point is reached for soil amendment with crushed silicates. I have seen that yields stop increasing with ever-increasing addition of ground rock. I haven&#x27;t seen a point where they go down. I would guess that there&#x27;s some point where yields actually start dropping, and that would mark the upper limit for agricultural soil amendments.Up to the point where yields keep increasing, you could expect farmers to spread crushed silicates on their fields for their own benefit, depending on the cost. In the high-application case where yields flatten out but carbon sequestration continues to increase, you&#x27;d need to pay subsidies to get higher application rates. You&#x27;d also need to pay subsidies in the lower-application-rate cases if yields increase but not enough to justify the expense on a yield basis. reply rmason 12 hours agoparentprevYou have to ask yourself the question why would farmers allow you to spread crushed rock on their farmland? There is no positive benefit for them. The academics didn&#x27;t study the long term effects of it on the land. The land is the tool the farmers use to make their living. reply matznerd 12 hours agorootparentActually, this incorrect, soils naturally acidify through nutrient loss (e.g. natural minerals) and the breakdown of nitrogen fertilizers. And soil have been amended with limestone (and volcanic soils) for a very long time.In fact, terrestrial enhanced rock weathering (ERW) was created to replace the cost of liming fields for farmers, which leads to the release of carbon. Many farmers are open to it because they need to balance their soil&#x27;s ph. Which as you said, is important to farmers because the land \"is the tool the farmers use to make their living\" therefore, you can consider ERW&#x2F;liming as the maintianence on their tool... reply oldbbsnickname 4 hours agoparentprevNit: Confusing units. The proper unit for this field is Gt (Gigatonnes). reply TaylorAlexander 14 hours agoparentprev> if spread across croplands globallyThat’s a big if! Reminds me of “the market for comics is $32 billion a year. If NFTs can capture just 1% of the market that’s $320 million per year.”Also what are the CO2 emissions of transporting all these rocks?? reply awb 9 hours agorootparentNo kidding. I’m struggling to think of any technology or technique that’s ubiquitous globally. Not to mention the labor and emissions required to harvest, transport and spread heavy rock across even a small percentage of fields. reply globular-toast 2 hours agoparentprevWe&#x27;ll compensate for that by emitting more carbon. But hey, someone got a job out of spreading rocks. reply api 16 hours agoparentprevIt would more than offset global aviation, which is one of the areas where replacing fossil fuels is the most difficult. reply ruiisnwn 11 hours agoparentprevWhom decided we need to reach the rediculous Net Zero target? We dont need to get anywhere near 0 to solve the problem reply hn_throwaway_99 16 hours agoprevI think this is cool from an academic perspective, but I have a very difficult time believing the energy needed to crush rock, and distribute it over fields, makes this a net benefit. reply DennisP 16 hours agoparentThat depends on the energy source, and how much is available. If for example we convert to 100% wind&#x2F;solar&#x2F;battery, we&#x27;ll end up with a large oversupply of zero-carbon electricity in the summer. reply aziaziazi 14 hours agorootparentThat is only true if we also convert to 100% w&#x2F;s&#x2F;b the w&#x2F;s&#x2F;b material sourcing, fabrication, distribution… reply brianbreslin 16 hours agorootparentprevThis may be a dumb question, but if we&#x27;re collecting volcanic rock, could we not tap into geothermal energy from the volcano to get cheap energy? reply pacaro 15 hours agorootparentIt seems reasonable to assume that many places where there is easily accessible volcanic rock are also places where geothermal is possible, but the connection between rocks like basalt and volcanoes can be more temporally distant that you may be thinking.If I go to a beach in the US Pacific North West, I can pick up basalt rocks&#x2F;boulders&#x2F;pebbles, but they last were in contact with an active volcano millions of years ago (approx 12mya is the usual number given locally, if memory serves) reply rogerkirkness 16 hours agorootparentprevThe argument is basically that we will need extra energy to go towards carbon capture one way or the other. Energy in, carbon reduced. This may or may not be a feasible way to do that. reply matznerd 12 hours agoparentprevThe energy use is surprisingly low and distances of 100-300 km can remain highly efficient, even with diesel trucks and avg grid power. By intentionally developing&#x2F;utilizing crushing plants near clean energy and farmland, this can be made even more efficient.See Potential and costs of carbon dioxide removal by enhanced weathering of rocks https:&#x2F;&#x2F;iopscience.iop.org&#x2F;article&#x2F;10.1088&#x2F;1748-9326&#x2F;aaa9c4Environmental life cycle assessment of CO2 sequestration through enhanced weathering of olivine https:&#x2F;&#x2F;legacy.projectvesta.org&#x2F;wp-content&#x2F;uploads&#x2F;2019&#x2F;06&#x2F;E...Enhanced Weathering: An Effective and Cheap Tool to Sequester Co2 https:&#x2F;&#x2F;link.springer.com&#x2F;article&#x2F;10.1007&#x2F;s10584-005-3485-y reply svara 16 hours agoparentprevWe&#x27;ll need to remove CO_2 from the atmosphere on a massive scale.Both the low and intermediate IPCC scenarios, SSP1-2.6 and SSP- 2-4.5, rely on it. It will be essential to keep our planet recognizable by 2100.Luckily the jittery&#x2F;cyclic output of renewables is ideal for this. In the grand scheme of things it also solves the storage issue to a large degree, since massive overbuilding of (peak) capacity is necessary. reply ClumsyPilot 10 hours agorootparent> Both the low and intermediate IPCC scenarios, SSP1-2.6 and SSP- 2-4.5, rely on it.This is a huge issue that people do not understand, there is currently no plan for this CO2 removal and I was horrified when I realised that all our climate projections assume that a massive industry will just spring into existence reply chris_va 15 hours agoparentprevLiming is pretty common in agriculture already. If you need 10um particles it&#x27;ll be a problem. If 100um is ok, then it&#x27;s not a big deal (and transport dominates). reply throwawayoaky 16 hours agoparentprevdunno! it&#x27;s gonna be rich in iron and magnesium, which you need to grow plants anyway. I would think transportation cost would be the dominant factor but olivine is common everywhere reply kisamoto 15 hours agoparentprevThere&#x27;s already a large amount of this available and energy can be sourced from renewable supplies.Also worth noting that life cycle assessments take into account the gray emissions produced while sequestering CO₂ so the removal should be the net CO₂ removal (although not sure if that&#x27;s the case in this article). reply Belopolye 16 hours agoparentprevHydro-powered rock crushers? Wikipedia gives an example of a waterwheel-powered machine that crushed tin ore in Cornwall in the 1800s.Maybe mixing the crushed rock in with seeds when they’re already being planted? reply the_sleaze9 15 hours agorootparentMore than likely using the water source to generate electricity that then powers whatever modern machinery you&#x27;d ever need is going to be significantly more efficient.Windmills were used to crush grain too, but wind turbines are orders of magnitude better in terms of a solution. reply vonwolfhausen 15 hours agorootparentprevIndeed, the largest active olivine quarry is in Norway, it&#x27;s all hydro! reply stronglikedan 13 hours agoparentprevMaybe not at first, but over 75 years? Maybe so. reply vonwolfhausen 15 hours agoparentprevIt depends on the feedstock, and how far you truck it (last mile) but in general this is one of the most bang-for-the-buck CDR approaches, with yields of 5-10x CO2 removed vs CO2 required. reply AndreSobolewski 14 hours agoprevEnhanced Weathering, as the practice is called, has merit and is being investigated by a dozen startups. The idea of spreading Olivine (a magnesium iron silicate) or Brucite (magnesium hydroxide) or Wollastonite (calcium inosilicate) has been floated around for a while.There are three aspects relating to its feasible application - as distinct from theoretical considerations.1. Is the process feasible? The slow reaction rate seems to be a significant obstacle. Additionally, these minerals are rarely pure and may vary significantly in quality from source to source, leading to a QA&#x2F;QC problem.2. Can the process be scaled-up? Contrary to earlier comments, there is no wide availability of these minerals, not at the scale needed to make an impact. Moreover, the material-handling side of the issue is not well addressed. It isn&#x27;t a simple question of drawing a distribution network on a diagram: it&#x27;s working out the economics of the mass mining, transport, distribution and application of these materials. People are working on this, but I have not yet heard a compelling solution.3. Are there undesirable side reactions? This is what farmers will worry about. It&#x27;ll be good if these amendments increase soil fertility, but that has to be demonstrated. Do these amendments alter the physical structure of soils or reduce their capacity to retain water, especially after carbon is absorbed? Do they form concretions over time that would make soils less permeable? Does the exposure to plant exudates release contaminants in soil?I was involve in a project at a Canadian diamond mine in which the host rock - Kimberlite - absorbed CO2. This caused a decrease in its alkaline pH and allowed small quantities of sulphides to oxidize and release contaminants. Clearly, this is the kind of undesirable outcome that must be avoided.Lots more to say, but perhaps some EW experts will chime in. reply unlikelymordant 10 hours agoparentThis whole &#x27;undesireable side reactions&#x27; thing is completely overblown for basalts. The effects to soil of volcanic ash from eruptions is quite well studied, not to mention crushed basalt is a recognised fertiliser in organic and biodynamic farming, and there have been places spreading it each year for the last 40 years (purely as a fertliser). You cant use rocks with significant sulphides or other heavy metals though, that has to be tested before spreading. Basalt is quite wide spread. reply pfdietz 7 hours agoparentprevMy concern would be nickel pollution. reply vosper 16 hours agoprevThis study is about whether the rock weathering we’ve seen posted here before (crushed olivine etc) works in dry climates like California. The answer appears to be “yes, but more slowly”> The study found the plots with crushed rock stored 0.15 tons of carbon dioxide per hectare (2.47 acres) during the study compared to plots without crushed rock. Though researchers expect different weathering rates in different environments, if this amount of carbon was removed across all California cropland, it would be equivalent to taking 350,000 cars off the road every year. reply hedora 16 hours agoparentThey don&#x27;t say how much rock they added to each field, but note that the 0.15 tons of CO2 they remove is only 300 lbs. A gallon of gasoline emits 20 lbs of CO2 when burnt.So, if they use more than 15 gallons of gasoline to mine, crush, transport and spread the rock over 2.47 acres, then this process emits more CO2 than it captures.I think they&#x27;d need to use electric high-tonnage dump trucks and electric tractors to make this process actually capture carbon. Electric tractors are stating to become available, but I don&#x27;t know of any high-tonnage electric truck manufacturers. reply londons_explore 15 hours agorootparentRemember that if you&#x27;re already distributing something else (eg. fertilizer) over the field, the added money and CO2 costs of distributing this might be negligible.You could just mix the fertilizer and the rock together at the fertilizer factory, and automatically a large chunk of the worlds farmland gets this added. reply vlovich123 14 hours agorootparentIt&#x27;s only negligible if the rock is a negligible amount of extra weight. Otherwise, the energy to transport will still come from somewhere & not be negligible unless all that energy is from a non-carbon fuel source (bulk transportation is nowhere near decarbonized). reply dgacmu 15 hours agorootparentprevThe spreading is ok but the transport is high. The key thing is: how many years of weathering do you get out of one load of 47 tons (or 27t)?The paper provides a very course estimate that what they measured over the year was only 0.15% of total weathering potential, which if we handwave a little turns into 6,000 lbs CO2 over 20 years, or 300 gallons of gas offset, which is probably a net gain. Though there are a ton of \"it depends\"es in there and it probably only makes sense with further electrification.(Obviously, the weathering would go on for a lot longer than 20 years, but the unknowns get large there and I&#x27;m assuming we&#x27;re mostly interested in a shorter time frame) reply hedora 15 hours agorootparentOK, with something something like the F-550 (on the small side for this use case, but also a reasonable choice for an ICE dump truck that&#x27;s driving to&#x2F;from agricultural fields), it could work:https:&#x2F;&#x2F;www.ford.com&#x2F;commercial-trucks&#x2F;chassis-cab&#x2F;models&#x2F;f5...That can move 14,870 lbs (minus the weight of the driver and the dump truck bed) per trip, so it would take more than 6.7 trips to deliver rock to treat an acre. At 6.7 trips per acre it would have to use less than 44 gallons of gasoline per trip for breakeven. It should use significantly less than that for fields that are somewhat close to an appropriate quarry &#x2F; rockery.The lightning can only move 7000 lbs per trip, so it would have to make 13.5 trips per acre. reply jhardcastle 15 hours agorootparentprevHow does 6lb of gas release 20lbs of CO2?I found this[1] link from the EPA with a number similar to yours, 8.8kg per gallon of gas, but they say it \"creates\" rather than \"emits.\" I&#x27;m still struggling with this creation of mass out of thin air...[1] https:&#x2F;&#x2F;www.epa.gov&#x2F;greenvehicles&#x2F;greenhouse-gas-emissions-t... reply jakobnissen 15 hours agorootparentIt&#x27;s because the majority of the mass of CO2 comes from the oxygen from the air used to burn the carbon. So in this case, it&#x27;s quite literally creating mass out of thin air. reply kbelder 14 hours agorootparentSpecifically, the atomic mass of carbon is 12 and oxygen is 16. So for CO2, 12&#x2F;44 of the mass is carbon, or about 27%. So of that 20 pounds of CO2, about 5 1&#x2F;2 pounds are carbon, the other 15 pounds is oxygen sucked out of the atmosphere. reply philipkglass 15 hours agorootparentprev\"Out of thin air\" is right :-)The CO2 contains mass from the atmospheric oxygen consumed during combustion. 12 grams of carbon becomes roughly 44 grams of carbon dioxide when it burns. reply lostapathy 12 hours agorootparentprev\"produce\" is probably a better verb than \"release\" in this case, for the common person to understand what&#x27;s going on. reply deathanatos 13 hours agorootparentprev> but note that the 0.15 tons of CO2 they remove is only 300 lbsYour point stands, but it was 600 lbs.They quoted figure is a rate, not an absolute amount removed:> 0.15 tons of carbon dioxide per hectarePer hectare. They spread it over 5 acres, or roughly 2 hectares, for a total of 0.3 tons, or 600 lbs. reply freeone3000 16 hours agorootparentprevDepends on how high “high tonnage” is. Kennworth is offering a 680hp full-electric with a 3 hour range. Volvo offers an electric VNR with identical performance to its standard VNR. Freightliner sells the eCascadia, matching its regular Cascadia. reply Karrot_Kream 15 hours agorootparentThese vehicles would need to be charged on fully renewables or non emitting sources (like hydro) to offset this. Even if Natgas or Gas plants are much more efficient than engines, the calculation still needs to account for amortized emissions. reply freeone3000 12 hours agorootparentYes? Obviously yes? Idk why everyone is assuming we’re going to keep dragging our feet on something that, at this point, is merely a matter of buying a few batteries and setting up a few more solar panels. Provinces have done it; heck, entire countries have done it. Switch to renewables already. reply Karrot_Kream 10 hours agorootparentBecause we&#x27;re still not there yet. In the US, California&#x27;s grid hits near-100% solar only around midday for an hour and then at night becomes mostly natgas, and can&#x27;t handle peak demand on hotter days. If you&#x27;re talking about the load of adding BEV trucks then that&#x27;s adding a whole different dimension to the equation. I&#x27;d like to be optimistic about these things but we&#x27;re far from it in the US. reply hedora 15 hours agorootparentprevThose are semi-trucks. You&#x27;d need to attach a compatible dump trailer to them. (Those might exist, but I don&#x27;t think I&#x27;ve ever seen one). reply peteradio 13 hours agorootparentThey exist, its how animal manures are applied to fields. Likely this would be shipped via trains long distance and last mile with semi. reply jacobgorm 14 hours agorootparentprevThe metric system is really handy for calculations like these. reply jeffbee 16 hours agoparentprevTaking only 3% of California&#x27;s cars off the road seems way easier. reply philipkglass 16 hours agorootparentIt is, but consider the future. We need net negative emissions to stabilize the climate because we didn&#x27;t decarbonize early&#x2F;fast enough to achieve this goal with emissions cuts alone. The vast majority of climate progress must come from energy system decarbonization, but active carbon dioxide removal approaches like this one will be necessary to draw down the excess atmospheric CO2 accumulated so far.\"IPCC Report: Carbon Removal is Now Required to Meet Climate Mitigation Targets\"https:&#x2F;&#x2F;www.carbon-direct.com&#x2F;insights&#x2F;ipcc-report-carbon-re...Also see this IPCC fact sheet about carbon dioxide removal, which includes enhanced rock weathering (the technique under discussion here):https:&#x2F;&#x2F;www.ipcc.ch&#x2F;report&#x2F;ar6&#x2F;wg3&#x2F;downloads&#x2F;outreach&#x2F;IPCC_A... reply bluGill 15 hours agorootparentWithout human actives the earth is slightly net negative. We need to be more net negative than that in the short term to fix some problems (ice melt), but we don&#x27;t need that forever. reply vlovich123 14 hours agorootparent> Without human actives the earth is slightly net negativeSource? AFAIK greenhouse warming has the capacity to be a runaway effect. It&#x27;s not immediately obvious that if you remove all current human carbon emissions, that temperatures would level off & start declining vs continue increasing because of the feedback loop. reply philipkglass 13 hours agorootparentThe Earth slowly depletes excess atmospheric CO2 due to the geological carbon cycle of silicate weathering. This is the slow, natural counterpart of the accelerated silicate weathering discussed above. It is too slow to reverse global warming on human time scales, but it means that if anthropogenic emissions ceased Earth would reach its peak temperature in less than a thousand years (ice melting and other reactions to this change would go on for several thousands of years) and gradually decline back to the pre-industrial atmospheric CO2 and climate within about 100,000 years.My source for this recollection is David Archer&#x27;s 2009 book The Long Thaw: How Humans Are Changing the Next 100,000 Years of Earth&#x27;s Climate. reply unlikelymordant 10 hours agorootparentHumans are currently on track for around 4 degrees of warming by 2100 assuming we hit all our current emission reduction targets (i.e. reaching net zero when governments have said they would). So removals are quite necessary. replyMrDresden 2 hours agoprev> 215 billion tons of carbon dioxide over the next 75 years if spread across croplands globally.But for how long does the rock &#x27;function&#x27; before needing to be replaced? I&#x27;m doubtful that it would work at the same rate over just a few years, let alone 75.With the need for massive mining, transportation and application of the rock at regular intervals I wonder if it would erode what ever gains this gives us. reply jeron 16 hours agoprevCan anyone speak to whether this helps or hurts the fertility of the soil? reply tastyfreeze 16 hours agoparentThe sand and rocks in the soil is where phosphorus and trace minerals come from. Ideal soil has a combination of living carbon, dead carbon, and minerals. The fungi and bacteria breakdown the minerals along with weathering and make it available to plants. All the living carbon builds itself from the dead carbon. The dead carbon came from dead plants that pulled the carbon from the air with photosynthesis. reply brianbreslin 16 hours agoparentprevvolcanic soil is often considered very fertile for agricultural purposes. [1][1] https:&#x2F;&#x2F;www.bgs.ac.uk&#x2F;discovering-geology&#x2F;earth-hazards&#x2F;volc.... reply marcosdumay 15 hours agoparentprevDepends on the soil. But it helps often enough that there is no lack of places. reply Sparkyte 16 hours agoparentprevNot too sure, but some plants greatly benefit from rock in soil. reply UncleOxidant 16 hours agoparentprevIt should help replenish certain minerals in the soil. reply thsksbd 15 hours agoparentprevThey&#x27;re dumping alkalinity into the soil. What could go wrong? reply mcpackieh 13 hours agoparentprevIf it were a good idea from the perspective of farmers, then farmers would already be paying to do it themselves. This isn&#x27;t the case though, so you will have to pay farmers to do it.Why does it even have to be on farmland in the first place? If it&#x27;s such a great idea with no environmental downsides, then dump the crushed rock onto other land instead. Then you can dump more of it without being limited by whatever is optimal for farm yields. reply londons_explore 15 hours agoprevCrushed anything in air or water can be bad for the environment though. In air, it is effectively PM2.5&#x2F;PM10 pollution. In water, I bet it gets into fishes gills just like it gets into our lungs. reply kisamoto 15 hours agoparentThe crushed rocks in this case mineralize into stable silicates which can be beneficial as they flow down rivers into the sea. As they are alkaline they can combat ocean acidity and the minerals help crustaceans harden their shells. reply londons_explore 14 hours agorootparentAre those super finely crushed stable silicates those same ones which cause silicosis? reply slowhand09 12 hours agoprev\"crushed rock stored 0.15 tons of carbon dioxide per hectare (2.47 acres)\". (.15 * 2000lb)&#x2F;2.47 = 300lb&#x2F;2.47 = ~121.5lbs&#x2F;acre of carbon uptake. After applying 41tons&#x2F;acre of olivine. How is this feasible? You ship railroad cars of volcanic rock dust, spread it on a field, and watch it take up a sandbag size amount of carbon per acre. Is it continuous or a onetime thing? reply the_sleaze9 15 hours agoprevI&#x27;m reading this a single-use carbon sequestration solution, is that not correct?As in - you pay the carbon to crush it, ship it and spread it. Then it captures carbon exactly once, and then what do you do with it? reply willtemperley 15 hours agoprevThis has been known for a while:https:&#x2F;&#x2F;www.nature.com&#x2F;articles&#x2F;s41586-020-2448-9 reply 8bitsrule 5 hours agoprevWe&#x27;re addicted to stuff that runs on fossil fuels. Keep running into ideas about how to offset that. We need to wake and stop. If there hasn&#x27;t already been enough climate Narcan sprayed to wake us up by now, we&#x27;ll keep dreaming until we can&#x27;t. Then we will stop. reply jacobgorm 14 hours agoprevRelated idea, but for oceans https:&#x2F;&#x2F;www.vesta.earth&#x2F; reply SteveGreaseBoss 9 hours agoprevCrushing rock is very energy intensive, transporting rock to farms is energy intensive. Placing rock in the soil is energy intensive. Its hard to see how this passes the B&#x2F;S test. reply oldbbsnickname 4 hours agoparentYep. It&#x27;s easy to skip the TCO analysis to make it seem like it&#x27;s \"helping\" in the context of a study trying to sell another study.The Bill Gates-associated method of spraying fine lye in a hyperboloid tower seems the most effective, perhaps at a slightly higher pressure of 2-3 atm to both increase the temperature and reactivity. The lye would be produced in a closed carbon cycle process using renewable energy sources. reply JoshTko 14 hours agoprev1. Tax companies for their portion of CO2 generation. Let costs trickle down to customers. 2. Split tax collected evenly to each citizen&#x2F;perm resident via monthly check. 3. Let market figure out Co2 reduction solutions. 4. Create whistleblower process to keep carbon sequestration companies in check. reply Willish42 10 hours agoparent#2 seems like a ludicrous misalignment &#x2F; conflict of interest. Why would I as a taxpayer&#x2F;voter want CO2 emissions to decrease if I&#x27;m essentially getting a monthly bonus for their existence? reply totetsu 9 hours agorootparentPresumably if there is an option that is more C02 efficient, it would have less tax so could be cheaper. If you spend your monthly bonus on the cheaper option it’s still a net positive reply ericjmorey 12 hours agoparentprevThat industries fight hardest against this approach tells me that it&#x27;s probably the most effective and efficient approach. reply twic 15 hours agoprevThe two-step plan to fix more carbon into soil:1. Rocks2. Ants! https:&#x2F;&#x2F;www.scientificamerican.com&#x2F;article&#x2F;ants-may-boost-co... reply fsckboy 12 hours agoprevin New England (and other places I assume), rocks are light enough to float.There are many rocks under the surface of the soil, and over time they work their way upward and pop out of the ground. Every spring when the fields are being tilled for planting, these rocks get in the way and they need to be removed (for the convenience of the farmer and his plow). Today&#x27;s New England forests are all 2nd or 3rd growth; the land was previously completely cleared for farmland, before the farmland of the Great Plains opened up and was found more efficient for scale farming (and not least because the human population there was smaller).If you walk through the New England woods today, you will periodically&#x2F;frequently come across old \"abandoned\" stone walls among the trees. Farmers built these stone walls to mark their property from the stones that were handy because they were removed from their nearby fields, where these stones had \"floated\" to the surface. The reason these stones are under the surface is because the grinding and bulldozing of glaciation, and then the subsequent outwashing of ice-melt carrying stones and sediment.All of that (from memory, apologies for any mistakes) to ask: won&#x27;t adding crushed rocks to farmland result in a lot of those rocks popping back out of the ground? Will plowing just keep them turned under, but even so, wouldn&#x27;t the population of rocks keep increasing? reply lucb1e 12 hours agoparent> these rocks get in the way and they need to be removed [...] you will periodically&#x2F;frequently come across old \"abandoned\" stone walls [made] from the stones that were handy because they were removed from their nearby fieldsYou didn&#x27;t mention what size these rocks&#x2F;stones are (to my non-native ears, a rock is at least several centimetres), but if you can build walls from them, I take it they&#x27;re not sand-sized. If you click the link in the first paragraph of the article, leading to the source, it mentions in the introduction> Crushed metabasalt and olivine soil amendments were used to investigate changes in soil pore water alkalinity as a proxy for bicarbonate production. The metabasalt (median grain size: 102 ± 22 μm) was selected because of its benign elemental composition and modest weathering potential (the parent volcanics includes felsic facies, yielding an overall silica content in the intermediate-to-felsic range). The olivine (median grain size: 83 ± 12 μm), in contrast, was chosen for its potential to weather rapidlyTL;DR the remains of the crushed rock they tested is measured in micrometers reply fsckboy 11 hours agorootparentooooh, micrometers. I was thinking pebble sized. I wouldn&#x27;t call it crushed, it&#x27;s pulverized powder (polvare which is powder in Italian, you see it in reference to minerals in wine vineyards) reply hownottowrite 10 hours agoprevThere’s so much more to soil conservation. Our reliance on manmade chemicals over good stewardship of the land has resulted in so many problems.Highly recommend looking into Louis Bromfield. A very accessible book: The Planter of Modern Life: How an Ohio Farm Boy Conquered Literary Paris, Fed the Lost Generation, and Sowed the Seeds of the Organic Food Movement reply danieloj 16 hours agoprevThere are interesting positive&#x2F;negative (it hasn’t been researched enough yet) side effects on the effects this has in raising the pH of the ocean, potentially reversing ocean acidification reply CrzyLngPwd 14 hours agoprevAs a land owner all I can think of is; I wonder what the unforseen outcomes of this might be?Will it turn my soil acidic? Will it kill off bacteria? Will reduce drainage or will my soil suddenly be unable to hold water? Will it harm the nematodes, will it create a nutrient imbalance that is only corrected by some monsanto&#x2F;bayer patented soil amendment? reply earth2jason 5 hours agoparentPeculiar as to why this is pitched at farmers. Maybe there could be a question of ulterior motives. reply AndreSobolewski 13 hours agoparentprevThese are the same questions I raised in an earlier comment. They are pertinent. reply fuzztester 13 hours agoprevGabe Brown: treating the farm as an ecosystemhttps:&#x2F;&#x2F;youtu.be&#x2F;uUmIdq0D6-A?si=RnMka7Nnx0yZ3Tqm reply m3kw9 6 hours agoprevFor any one that need to squeeze out that extra carbon credits reply avodonosov 15 hours agoprevWhat is the risk to get silicosis caused by that rock dust?https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Silicosis reply vonwolfhausen 15 hours agoparentDust is never good, but olivine specifically was introduced as a foundry sand specifically because it doesn&#x27;t cause silicosis (vs quartz). reply pfdietz 7 hours agorootparentOlivine is a kind of silicate where the silicon atoms are in isolated tetrahedra (with four oxygen atoms), rather than linked into large chains, sheets, or 3d lattices. This makes it weather more quickly (for CO2 absorption), but I suspect also makes it dissolve more quickly in the body. reply avodonosov 14 hours agorootparentprevThe article also mentions metabasalt reply vonwolfhausen 9 hours agoprevI&#x27;ve been enjoying this thread. I have a company that does this (Eion). We are recruiting for a data engineer role to implement the algorithms for quantifying carbon removal, if these questions are interesting to you. Touches on nearly every aspect in this thread. reply natch 13 hours agoprevAre they claiming that microbes and other life forms don&#x27;t just harvest the carbon (directly or indirectly) putting it right back into the air? reply matznerd 13 hours agoparentThe CO2 storage is inorganic as bicarbonate dissolved in seawater and is considered permanent (60,000-100,000+ years). This process occurs as rocks weather and release magnesium or calcium cations. The \"enhanced rock weathering\" (ERW) process is all about speeding up the rate of release of these cations. Taking them out of a closed mountain not in the tropics and grinding them up, increasing their reactive surface area, speeds up the weathering process by many millions of years or more.See: The role of soils in the regulation of ocean acidification - https:&#x2F;&#x2F;royalsocietypublishing.org&#x2F;doi&#x2F;full&#x2F;10.1098&#x2F;rstb.202... reply natch 5 hours agorootparentInteresting. I don’t know enough to judge the veracity of this, but it will lead me to learn more, so thanks.And geology is fascinating, so that’s another reason to learn more. reply denton-scratch 16 hours agoprevSo I guess you end up with finely-divided carbonate.I didn&#x27;t notice any mention of how long it takes powdered basalt to weather down. Is that over a year? reply denton-scratch 12 hours agoparentI seem to be wrong about the result of basalt-weathering being carbonates.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Basalt#WeatheringIt seems that basalt consists mainly of metal oxides, predominantly Fe, Ca, Mg and Al. How does carbonic acid from rain get bound into basalt, without dissolving in the next rainstorm?(My knowledge of chemistry is restricted to \"A\" level, what Americans would call High School; and I&#x27;ve forgotten it all, because it was 40 years ago).The article says that basalts weather down into clays, which aren&#x27;t carbonates. reply vonwolfhausen 15 hours agoparentprevCan be 20 years if it is coarse (minus 3&#x2F;8\" fines). reply kisamoto 15 hours agorootparentTo reach maximum sequestration rate I thought it was much longer than that (~95% within 30 years at 3um). Where did you get your numbers from (curious, always looking for more sources)? reply garrickvanburen 13 hours agoprevHow do we get it distributed across suburban backyards? reply pfdietz 7 hours agoparentIt could be sold as a magnesium and iron supplement, to make lawns greener when those elements are in short supply. reply orthecreedence 10 hours agoparentprevSimple: https:&#x2F;&#x2F;cloudfront-us-east-1.images.arcpublishing.com&#x2F;archet... reply RecycledEle 15 hours agoprevI thought humans spent thousands of years removing rock from dirt to create framland.Are they trying to reverse that?Certainly destroying the farmland and letting people starve would result in decreased carbon dioxide emissions. reply PeterisP 14 hours agoparentIt depends on the soil pH, where it&#x27;s needed, crushed olivine is already used to increase crop yields (see e.g. https:&#x2F;&#x2F;modernfarmer.com&#x2F;2023&#x2F;09&#x2F;enhanced-rock-weathering&#x2F; ) where it&#x27;s close enough &#x2F; cheap enough.Bringing it everywhere where it could be useful, though, is unlikely to happen without subsidies to cover the transport costs, but the need for carbon capture might support that. reply trhway 11 hours agoprev>The study found the plots with crushed rock stored 0.15 tons of carbon dioxide per hectare (2.47 acres) during the study compared to plots without crushed rock.According to the article it took several months of winter. Say, even though there is less rain in the summer, it is 0.3 tons per hectare per year.To put into perspective - trees sequester more than 6 tons of carbon dioxide per hectare per year. reply coding123 12 hours agoprevIn other news the Mining industry rushes to produce 3000 trillion tons of crushed rock, causing 1b cubic tons of rock dust over the world. reply luxuryballs 14 hours agoprevWhy are we even thinking of doing this? I am more than a little concerned that it may not be wise to assume the answer to biome engineering is even more biome engineering… reply m0llusk 13 hours agoparentBefore we blew past 400 ppm carbon in the atmosphere this might have made sense. Now it would probably be more accurate to phrase the implicit proposal as asserting the answer to rampant biome disruption may include some cautious biome engineering. reply anonymous344 15 hours agoprevhow about u just dont cut all the trees because of greed?? reply kisamoto 15 hours agoparentNot enough for what we need.Even if we covered all the possible area we could with trees we couldn&#x27;t capture enough CO₂. And that ignores the fact that climate change increases the chances of wildfires. reply ruiisnwn 11 hours agorootparentWhom decided we need to reach this rediculous Net Zero target?Why not aim for minus 101 percent why we are at it reply kisamoto 1 hour agorootparentMinus is the long term goal. Net zero is purely a stepping stone on the journey there. reply ruiisnwn 11 hours agoprevnext [3 more] [flagged] orthecreedence 10 hours agoparentCrushed rock is communism...? Someone should have told Lenin. reply oldbbsnickname 4 hours agorootparentIn Soviet Russia, Gulag break you into rocks. reply redavni 15 hours agoprevnext [2 more] [flagged] sunday_serif 15 hours agoparentA good idea is a good idea, regardless of where it comes from. reply robomartin 15 hours agoprevTypical \"Assume a cow is a uniform sphere of milk one meter in diameter\" proposal.> \"adding crushed VOLCANIC ROCK to cropland\" ... \"by crushing the rock into a FINE DUST\"Emphasis mine.So... - Mine massive far-away lava fields - Generate massive amounts of CO2 through this process - Cause serious environmental damage - Transport what you mined - Generate massive amounts of CO2 through transportation - Crush it into a fine dust - Generate massive amounts of CO2 through this process - Transport massive quantities again - Generate massive amounts of CO2 again - Likely need for massive amounts of chemicals as part of all of the above - Use a high carbon footprint process to distribute the dust - Use a high carbon footprint process to bury the dust to the required depth - Hope and pray for enough rain - Hope and pray you don&#x27;t destroy the fields for agricultural useRight.And that&#x27;s not even a full accounting of what the process at scale would look like. It is far more likely to add massive amounts of CO2 to the atmosphere than the opposite. Not to mention potential ecological damage across every region the project might touch, from mining to deployment.We are not going to surface real solutions until we are willing to be honest about the full and real accounting behind proposals. Most so-called solutions barely pass basic high school science and economics tests. That&#x27;s where we are. Still. I mean, we are still talking about stuff like huge fan-powered filters? Have we gone mad?All we are doing is wasting time and money looking at false supernatural solutions to a planetary scale problem that requires real solutions.> if this amount of carbon was removed across all California cropland, it would be equivalent to taking 350,000 cars off the road every year.OK. Then forget volcanic dust and focus on the infrastructure and power generation required to enable a million electric cars per year. If this volcanic powder nonsense is good for 350K cars per year, well, doing THREE TIMES BETTER with electric cars is a realistic objective that isn&#x27;t in fantasy-land at all and does not create the potentially horrific ecological danger of mining and spreading volcanic dust. One is realistic and attainable. The other is, at best, a dangerous fantasy. reply djtriptych 14 hours agoparentI can imagine a geothermal-based extraction process to mine + a wind&#x2F;solar transportation method. This works fine even if it takes 100x longer to transport. Can be fully robotic piloting for instance.Bottom line I&#x27;m not sure it MUST be a C02-generating process once bootstrapped.Also no reason we can&#x27;t focus on both electric cars and this soil method. reply robomartin 14 hours agorootparentThe problem with these assumptions is that you are asking for yet-to-be-invented solutions to mining, transportation and processing problems. As a friend of mind is fond of saying, at some point we have to recognize that we took a problem from boiling a pot of water to trying to boil the ocean.None of these proposals qualify as solutions, because they are never aligned with reality. Or, another way to put it: Reality is always far more complex than recognized by these experiments. reply huytersd 14 hours agoprev [–] So ruin farmland with crushed rock? Why would you even study such things? reply jamescrowley 13 hours agoparentIt can actually have benefits to the soil as a fertiliser - https:&#x2F;&#x2F;www.ncbi.nlm.nih.gov&#x2F;pmc&#x2F;articles&#x2F;PMC10011191&#x2F; reply huytersd 13 hours agorootparentAnything bigger than a pebble is going to ruin harvesters and planters. reply ksenzee 12 hours agorootparentThey’re using rock crushed to ~100 microns. reply lucb1e 12 hours agorootparentprevThe person you&#x27;re replying to posted a link which mentions in the \"materials and methods\" section that the particles in the study were all smaller than 2mm (and 99.6% smaller than 1mm).To compare with your pebble, which wikipedia says is> A pebble is a clast of rock with a particle size of 4-64 mm reply lucb1e 12 hours agoparentprev [–] If you open the article and click the only link in the first paragraph, leading to the source, it will tell you in the introduction> Crushed metabasalt and olivine soil amendments were used to investigate changes in soil pore water alkalinity as a proxy for bicarbonate production. The metabasalt (median grain size: 102 ± 22 μm) was selected because of its benign elemental composition and modest weathering potential (the parent volcanics includes felsic facies, yielding an overall silica content in the intermediate-to-felsic range). The olivine (median grain size: 83 ± 12 μm), in contrast, was chosen for its potential to weather rapidlyTL;DR scan for the digits in that quote. This stuff is measured in micrometers.> Why would you even study such things?Because if everyone were willing to read sources and get to understandings, we would probably not have climate problems in the first place reply ruiisnwn 11 hours agorootparent [–] I doubt that. You yourself are just going along with this rediculous Net Zero target. Who decided on 0 why not minus 101 percent while we are at it replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Researchers from the University of California, Davis, and Cornell University have discovered that crushed volcanic rock added to farmland can absorb carbon dioxide, even in arid climates.",
      "The method is called rock weathering, which traps carbon in soil. This process is hastened by crushing the rock into fine dust.",
      "During an intense drought in California, a field study revealed that areas with crushed rock stored 0.15 tons of carbon dioxide per hectare, suggesting enhanced rock weathering as a productive instrument for carbon capture and mitigation."
    ],
    "commentSummary": [
      "The passage discusses the potential of using crushed rock, like olivine or basalt, for carbon dioxide removal from the atmosphere, which could help combat climate change.",
      "There are, however, concerns about the carbon emissions generated during the mining and transport of these rocks, the long-term effectiveness of this method, and possible impacts on soil health.",
      "The text debates the feasibility, scalability, and economic viability of this approach, along with its implications on renewable energy sources, industries, and societal structures."
    ],
    "points": 244,
    "commentCount": 249,
    "retryCount": 0,
    "time": 1698253738
  },
  {
    "id": 38014069,
    "title": "Wait, what's a bookmarklet?",
    "originLink": "https://thehistoryoftheweb.com/postscript/wait-whats-a-bookmarklet/",
    "originBody": "The History of the Web Timeline Archives Read the Latest Post The Book Wait, what’s a bookmarklet? Written by Jay Hoffmann on October 25, 2023. It takes place somewhere between 1995 and 2008. How this one small browser quirk turned into a tool used by countless people for decades. In 1995, Brendan Eich demoed what would eventually become JavaScript to a room full of engineers at Netscape. It was met with instant enthusiasm. For his demo, Eich opened up his version of the browser and typed a command right into the address bar, which opened up a console and allowed him to demonstrate an alert box. Six months later, the first version of JavaScript shipped with Netscape Navigator 2. JavaScript in the address bar, as a protocol for a URL, was possible virtually from day one of the language, effectively creating JavaScript URLs. And even in the first version, “visiting” a JavaScript URL triggered a change on the current page, rather than opening up an entirely new one. Eich even added the void operator to an early version of JavaScript to make it possible to create arbitrary functions with values right in that URL. To introduce new developers to JavaScript, Netscape released a comprehensive guide on how to use it. And in that guide, they included a short snippet about these JavaScript URLs: You are probably familiar with the standard types of URLs: http:, ftp:, file:, and so on. With Navigator, you can also use URLs of type javascript: to execute JavaScript statements instead of loading a document. You simply use a string beginning with javascript: as the value for the HREF attribute of anchor tags. Reload Now In general, you can put any statements or function calls after the javascript: URL prefix. So you ended up with this JavaScript quirk where it was possible to create unique URLs that ran a bit of JavaScript on whatever page you happened to be looking at. It could even make changes to that page. Move things around. Replace words. Open links. And pretty early on, people realized that these JavaScript URLs were also bookmarkable, just like any other URL. And, crucially, easily shareable as links. As rapid iteration spread through the early web, one corner of that world began experimenting with these bookmarkable, shareable JavaScript URLs to manipulate and transform web pages. Some early examples were used to quickly open all the links on a page, for instance, or run the current page through a validator. But there were also plenty of unique utilities as well, like interacting with online services, manipulating images on a page, or even tipping the website owner. Early versions of the browser also featured something which has faded away in recent years. The bookmarks bar (or sometimes, the favorites bar). Up at the top of the browser window, below the URL, was a list of bookmarks. The easiest way to share a JavaScript URL was to drag one into your bookmarks bar, and then use it as you were surfing around. It is difficult to trace the exact moment that all of this began, but there did come a time when the concept—a shareable JavaScript URL that acted as some sort of personal utility—needed a name. In December of 1998, Steve Kangas did just that, when he launched Bookmarklets.com. And the bookmarklet (or Favlet, as it was called by Tantek Çelik) started spreading. Even in the first few months, Kangas had a list of over a hundred bookmarklets to share, that he had compiled and created. Some could be used to search a page for specific links or text. Others could alter the appearance of a page, removing images, changing the color or making things more readable. Some were fun (a bookmarklet that could make a Valentine’s Day heart dance across the page) and some were unadorned and simple (turn text underlines on or off). Bookmarklets are interesting. They are generally limited by browsers to a certain number of characters, which means they require efficient code that make use of the quirks of the language. They can’t be too complex or verbose. They usually have to be minified, which is a process of taking human readable JavaScript code and removing as many complicated variable names and whitespace as is needed. A Bookmarklet generally wasn’t able to do ten things at once. Each one did one thing, and did it well. That directness and focus made it all the more easy to share them around and instantly understand their utility. And bookmarklets became very popular. Browsers have also typically featured another way to change and manipulate a page. They’ve been called add-ons, plugins, and extensions, but they are an officially supported way of interacting with a browser and extending its functionality. For a long time, however, they were difficult to manage and install. You had to find what you were looking for, download it, and find the right place to put it on your computer. They were useful cases, but not necessarily a viable alternative to Bookmarklets, which were easily shareable and dead simple. In 2007, Moziilla Firefox released its Add-ons Gallery, a much simpler way to discover and install official Firefox add-ons. It was a searchable and categorized index of add-ons that any developer could add to. Add-ons were officially supported, were reviewed for security, and could be installed with one click. In 2009, Chrome added an extension gallery with similar features. As those browsers rose in market share, extensions began to overtake bookmarklets in popularity. The Bookmarks bar faded to the background more. Bookmarklets are still in use, and still quite useful, but they are …. Learn your history Prefer RSS? Fine by me Share this on Facebook, Twitter, Reddit, or Pocket Sources Now an Ebook! I took the best posts from The History of the Web, over sixty of them, and compiled them into a single volume. So now you can read about the web's history wherever you go. Read a bit more history When the wizards of the web met On July 28, 1993, a group of web pioneers met in a small room for a few days. For many, it was the first time they had ever met. The History of the Web is a project by Jay Hoffmann. Get in touch.",
    "commentLink": "https://news.ycombinator.com/item?id=38014069",
    "commentBody": "Wait, what&#x27;s a bookmarklet?Hacker NewspastloginWait, what&#x27;s a bookmarklet? (thehistoryoftheweb.com) 219 points by Brajeshwar 18 hours ago| hidepastfavorite149 comments rav 17 hours agoThree bookmarklets I made for my bookmarks toolbar:\"Don&#x27;t mess with paste\" - for when signup forms expect you to hand-type your email address twice. javascript:void [\"contextmenu\",\"copy\",\"paste\",\"selectstart\"].map(e=>document.addEventListener(e,e=>e.stopPropagation(),true))\"Nebula no-alt-#\" - Nebula&#x27;s video viewer annoying captures e.g. alt-3 to do the same as plain 3 (seek to 3&#x2F;10 of the video currently playing), but I expect it to switch to the 3rd browser tab instead. YouTube doesn&#x27;t do this. Luckily I can just activate this bookmarklet: javascript:void document.addEventListener(\"keydown\",(e)=>void(e.altKey&&!isNaN(+e.key)&&e.stopPropagation()))\"canvas DL\" - when playing skribbl.io and someone has made a nice drawing, this lets you download the current drawing as a PNG. javascript:var w=window.wdq||(window.wdq=document.createElement(\"a\"));var p=&#x2F;The word was &#x27;([^&#x27;]*)&#x27;&#x2F;g,pp=&#x2F;([^]+) is drawing now!&#x2F;g,tt=document.body.innerHTML;var mm,nn,xx;while(mm=p.exec(tt))nn=mm;while(mm=pp.exec(tt))xx=mm;w.download=location.host+\"_\"+(nn?nn[1]+\"_\":\"\")+(xx?xx[1]+\"_\":\"\")+new Date().toISOString().replace(&#x2F;:&#x2F;g,\"_\");w.href=document.querySelector(\"canvas\").toDataURL();w.click(); reply ashtonmeuser 15 hours agoparentI took the liberty of making your bookmarklets easier to edit&#x2F;share with my tool bookmarkl.ink [1].Don&#x27;t Mess With Paste: https:&#x2F;&#x2F;bookmarkl.ink&#x2F;ashtonmeuser&#x2F;6e3869d8e468e016f22a4b4de...Nebula No-Alt-#: https:&#x2F;&#x2F;bookmarkl.ink&#x2F;ashtonmeuser&#x2F;6e3869d8e468e016f22a4b4de...Canvas DL: https:&#x2F;&#x2F;bookmarkl.ink&#x2F;ashtonmeuser&#x2F;6e3869d8e468e016f22a4b4de...[1] https:&#x2F;&#x2F;bookmarkl.ink&#x2F; reply idonotknowwhy 13 hours agorootparentThanks for your site, and to the GP who made Don&#x27;t Mess With Paste!Feel free to add this if you want, I have it in my firefox called \"UnfuckSlack\" which puts the old slack UI back:javascript:(function() { localStorage.setItem(\"localConfig_v2\", localStorage.getItem(\"localConfig_v2\").replace(&#x2F;\\\"is_unified_user_client_enabled\\\":true&#x2F;g, &#x27;\\\"is_unified_user_client_enabled\\\":false&#x27;)); location.reload(); })(); reply anonymous344 15 hours agorootparentprevyou have listing page to browse these? reply ashtonmeuser 15 hours agorootparentUnfortunately, no. This is a simple pet project aimed at easing sharing&#x2F;versioning of bookmarklets. The site is entirely static. Listing bookmarklets is, however, something I&#x27;d love to add.A simple and sensible way to list bookmarklets may be scraping GitHub&#x27;s own search [1]. Using a flag in gists such as `&#x2F;&#x2F; bookmarklink-index` or similar may be a good way to go.[1] https:&#x2F;&#x2F;gist.github.com&#x2F;search?q=extension%3Ajs+bookmarklet_... reply drittich 9 hours agorootparentThe proper way would be a bookmarklet that renders a list of bookmarklets. reply natpalmer1776 14 hours agorootparentprevLove seeing cool stuff like this, thank you. reply knodi123 12 hours agoparentprevI have \"increment\" and \"decrement\" bookmarklets, that look for the last-most number in a url and make it go up or down by one. I&#x27;m always surprised at how often it&#x27;s useful. Oh, and I have this one called \"kill sticky\", javascript:( function(){ let i, elements = document.querySelectorAll(&#x27;body *&#x27;); for (i = 0; i {[...e.querySelectorAll(\"body\")].forEach((e=>{[\"fixed\",\"sticky\"].includes(l(e).position)&&e.parentNode.removeChild(e)})),[...e.querySelectorAll(&#x27;html,[style\\*=\"overflow\"]&#x27;)].forEach((e=>{[\"hidden\"].includes(l(e).overflow)&&(e.style.overflow=\"visible\"),[\"hidden\"].includes(l(e)[\"overflow-x\"])&&(e.style[\"overflow-x\"]=\"visible\"),[\"hidden\"].includes(l(e)[\"overflow-y\"])&&(e.style[\"overflow-y\"]=\"visible\")}));let o=e.querySelector(\"html\");o.style.overflow=o.style[\"overflow-x\"]=o.style[\"overflow-y\"]=\"visible\"})(document,getComputedStyle);https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;4c6710b5-9c81-415b-85fc-b33e69... reply skylanh 8 hours agorootparentprevThis used to be a feature in Opera a decade ago IIRC. reply jaipilot747 8 hours agorootparentIt is still a feature in Vivaldi, Opera&#x27;s spiritual successor. reply rtkwe 17 hours agoparentprevFor things you need to always run Grease Monkey seems like a prime choice. You could have your script run automatically for every visit to a nebula page. reply sbierwagen 16 hours agorootparentBy default Greasemonkey can access all data on all pages. With extensions being routinely compromised to steal crypto that’s starting to look like a bad deal. (If you limit it to a single domain in Chrome it will nag you to unlock it on Chrome startup forever) reply account42 1 hour agorootparentBy default Chrome can access all data on all pages. With browsers being routinely compromised by advertising companies working against your interest that&#x27;s starting to look like a bad deal. reply rtkwe 15 hours agorootparentprevI only use a few and they&#x27;re simple enough I can read them before updating to see if they&#x27;re bringing in something weird. Also in GP&#x27;s case they could just write their own since they&#x27;re already making them. No exploitable surface there if it&#x27;s not a remote updatable script. reply lolinder 14 hours agorootparentIt&#x27;s not the bookmarklets that OP is warning about, it&#x27;s the risk that the GreaseMonkey extension itself becomes compromised. Basically, it&#x27;s good browser hygiene to keep the number of extensions you have installed to an absolute minimum.A bookmarklet alone isn&#x27;t so much a concern, both because it doesn&#x27;t run automatically on all pages (only when clicked) and because, as you note, you can usually pretty easily audit what you add and you don&#x27;t get automatic updates. reply gabrielsroka 13 hours agorootparent> you don&#x27;t get automatic updatesUnless the bookmarklet updates itself by loading code from another URL. This is blocked by some websites but not all. reply wodenokoto 15 hours agorootparentprevI am weirdly more afraid of installing chrome extensions than executables on my machine reply baal80spam 14 hours agorootparentVioletmonkey is opensource. reply illiac786 4 hours agoparentprevForce pasting is something that is unfortunately required in many places, not just the browser. For example a Citrix session where the Citrix admin decided that pasting was a security risk and hence blocked it. Or some very poorly written apps.For all of these I use an apple script that emulates typing one letter at a time, with a small delay because Citrix can&#x27;t deal with typing which is too fast.It&#x27;s based on Force Paste: https:&#x2F;&#x2F;github.com&#x2F;EugeneDae&#x2F;Force-PasteI invoke it with a shortcut (Alfred on macOS for example) and it&#x27;s a life saver multiple times a day. Weirdly satisfying to watch happening =) reply stalfosknight 15 hours agoparentprevWhy do some sign up forms block pasting from the clipboard? reply drbawb 14 hours agorootparentMy city does this, as well as preventing right clicks, as a \"copy protection mechanism\", complete with an `alert()` shaming you every time you have the audacity to try and cut and paste some text. reply ScottEvtuch 13 hours agorootparentprevThey are worried about someone copying a mistyped email from the first form field and pasting it into the \"confirm email\" field, thus making the confirmation field pointless. I would suspect in the real world most people are typing their email by hand and not using a password manager or auto-fill so this becomes an actual problem.A nice implementation of this would detect that you pasted&#x2F;auto-filled the original field and not prompt you to confirm unless you typed it slowly by hand. reply mdekkers 15 hours agoparentprev> \"Don&#x27;t mess with paste\"You are my hero reply tonetheman 17 hours agoparentprevOh that first one... that is sweet. reply karaterobot 17 hours agoprevAt a previous company, we got to the point where we were considering making a Chrome extension to support an out-of-band workflow for our app. I, being in my 40s, suggested the prototype could just be a bookmarklet. All the younger devs were like \"what&#x27;s a bookmockler?\" and I felt very old.Almost as old as when I started singing The Wreck of the Edmund Fitzgerald when asked if I could name all the Great Lakes. reply ics 16 hours agoparentThey&#x27;re so simple that it&#x27;s hard to believe they just work. I&#x27;m almost surprised that browser vendors haven&#x27;t pushed the functionality out of existence just because, in favor of ever more complicated solutions.Similarly, while prototyping an internal company wiki I made bookmarklets to fix some Sharepoint shenanigans and add features that otherwise would&#x27;ve required mucking about with extensions (tough when half the company was forced to use IE) or even worse, Sharepoint apps. The entire IT staff had a major WTF moment after explaining just how simple the whole thing was. reply fiddlerwoaroof 16 hours agorootparentThe annoying thing to me is that browsers often enforce CSP on bookmarklets and so they have started being less reliable.Firefox fixed this in a limited way: https:&#x2F;&#x2F;bugzilla.mozilla.org&#x2F;show_bug.cgi?id=1478037 but other browsers don’t care or won’t reply yawaramin 12 hours agorootparentprevI&#x27;m told Opera doesn&#x27;t support bookmarklets.I made one to collapse all comments in a BitBucket PR page (just find each comment and nest it inside atag, with acontaining the first line of the comment). It&#x27;s widely used in PRs that deal with Atlantis&#x2F;Terraform, because Atlantis leaves huge comments on PRs. reply alexpotato 14 hours agoparentprev> and I felt very old.I was debugging a database issue the other day [0] and, being new to the firm, I asked \"Hey, who is our DBA?\"Every junior SRE on the call asked \"What&#x27;s a DBA??\"0 - Client process hung and left an open transaction reply mixmastamyk 12 hours agorootparentWhy do you two feel \"old,\" instead of experienced? Aka \"teachable moment\". reply flobosg 16 hours agoprevA few ones I use often:* Get Markdown link of the current page as [Title](url): javascript:void function(){function e(){var e=\"\";if(window.getSelection)e=window.getSelection().toString();else if(document.getSelection)e=document.getSelection().toString();else{if(!document.selection)return null;e=document.selection.createRange().text}return e}var t=e(),n=window.document.title,o=window.location.href,i=[];if(t){i.push(\"[\"+t+\"]\")}else{i.push(\"[\"+n+\"]\"),i.push(\"(\"+o+\")\")}window.prompt(\"created link\",i.join(\"\"))}();* See current page on the Wayback Machine: javascript:void(window.open(&#x27;https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;*&#x2F;&#x27;+location.href.replace(&#x2F;\\&#x2F;$&#x2F;, &#x27;&#x27;)));* Twitter to Nitter: javascript:h=[&#x27;nitter.it&#x27;,&#x27;nitter.snopyta.org&#x27;,&#x27;nitter.net&#x27;]; location.href=location.href.replace(window.location.host,h[Math.floor(Math.random()*h.length)]); reply ashtonmeuser 15 hours agoparentI took the liberty of making your bookmarklets easier to edit&#x2F;share with my tool bookmarkl.ink [1].Markdown Link: https:&#x2F;&#x2F;bookmarkl.ink&#x2F;ashtonmeuser&#x2F;6e3869d8e468e016f22a4b4de...Wayback Machine: https:&#x2F;&#x2F;bookmarkl.ink&#x2F;ashtonmeuser&#x2F;6e3869d8e468e016f22a4b4de...Nitter: https:&#x2F;&#x2F;bookmarkl.ink&#x2F;ashtonmeuser&#x2F;6e3869d8e468e016f22a4b4de...[1] https:&#x2F;&#x2F;bookmarkl.ink&#x2F; reply account42 1 hour agorootparentWouldn&#x27;t it be more in the spirit of bookmarklets to share tham as data: URLs containing a link with the bookmarklet? reply swyx 15 hours agorootparentprevfantastic service. thank you reply asielen 15 hours agoparentprevAlso add current page snapshot to the wayback machine:javascript:void(window.open(&#x27;https:&#x2F;&#x2F;web.archive.org&#x2F;save&#x2F;&#x27;+location.href)); reply drdeca 15 hours agoparentprevWhat’s the purpose of the randomization in the Twitter to nitter one? reply branon 15 hours agorootparentI bet you it&#x27;s to make spamming the button a useful action if one of the instances is overloaded or rate limited, you can click a few more times until a page loads reply grumblehound 17 hours agoprevI made a little bookmarklet a while back that allows you to spawn a little man that walks along the top of elements: https:&#x2F;&#x2F;divwalker.arbitrarydata.co.uk&#x2F;I&#x27;m still not bored of it. reply twic 12 hours agoparentThis is giving me flashbacks to Lode Runner on the Mac. reply wolverine876 13 hours agoparentprevAwesome! reply idonotknowwhy 12 hours agoparentprevlmao make me want to play lemmings reply ashtonmeuser 16 hours agoprevI created a tool [1] to easily convert GitHub gists into bookmarklets and share them. Includes versioning, multi-file gists, etc. Some of my favourite examples hide images until mouseover [2] and play a procedural Brian Eno tune [3].[1] https:&#x2F;&#x2F;bookmarkl.ink&#x2F;[2] https:&#x2F;&#x2F;bookmarkl.ink&#x2F;ashtonmeuser&#x2F;21427841853c9f2292c8f7d7a...[3] https:&#x2F;&#x2F;bookmarkl.ink&#x2F;ashtonmeuser&#x2F;5e696524d986ba6c25af0df89... reply SushiHippie 13 hours agoparentThanks, would be cool to have a quick copy button, as these \"bookmark me\" buttons never work on mobile. With a simple copy button I could create a new bookmark easily on mobile. reply o11c 17 hours agoprevOne of the first bookmarklets I made was a simple one that just went up one directory.It worked gloriously for a year or two, and then the internet decided to stop using structure and broke everything. reply jessekv 16 hours agoprevIs there a good bookmarklet for a HN dark theme?Edit: I made one. Its based on:https:&#x2F;&#x2F;github.com&#x2F;UserStyles&#x2F;hacker-news-zenburn-dark javascript:(()=>{var s=document.createElement(&#x27;style&#x27;);s.innerText=`*{color:#dcdccc!important;background-color:#404040!important}body%3Ecenter%3Etable%3Etbody%3Etr:first-child{background-color:#505050!important}body%3Ecenter%3Etable%3Etbody%3Etr:first-childa:hover{background:#404040!important}code,pre,input,textarea{background:#505050!important}a{color:#7F9F7F!important}.subtext%20a{color:#dcdccc!important}a:visited,a:visited%20span{color:#CC9393!important}a:hover,a:hover%20span{background:#505050!important}%60;document.head.appendChild(s)})();Edit 2: It works on several other sites too. Cool! reply bloopernova 9 hours agoparentyou can also use ublock origin to filter html to create a dark mode:https:&#x2F;&#x2F;gist.github.com&#x2F;aclarknexient&#x2F;c39c83f2f97c3c6b1c307c... reply leoff 11 hours agoparentprevThis is just a small crocheting website, they don&#x27;t have expertise to make such a fancy feature natively reply darekkay 17 hours agoprevMy most used bookmarklet is one to call \"debugger\" after a short timeout to debug dynamic elements that would otherwise disappear as soon as I try to inspect them.https:&#x2F;&#x2F;darekkay.com&#x2F;blog&#x2F;debugging-dynamic-content&#x2F; reply epivosism 16 hours agoprevForce narrow page - this one just shrinks body width, useful for handling pages which simultaneously don&#x27;t allow zooming and also want to be 100% width on a giant monitor javascript:(function(){var newSS, styles=&#x27;body { width: 25em !important; overflow: wrap; margin-left: auto; margin-right: auto; }&#x27;; if(document.createStyleSheet) { document.createStyleSheet(\"javascript:&#x27;\"+styles+\"&#x27;\"); } else { newSS=document.createElement(&#x27;link&#x27;); newSS.rel=&#x27;stylesheet&#x27;; newSS.href=&#x27;data:text&#x2F;css,&#x27;+escape(styles); document.getElementsByTagName(\"head\")[0].appendChild(newSS); } })();Kill sticky: javascript:(function()%7B(function%20()%20%7Bvar%20i%2C%20elements%20%3D%20document.querySelectorAll(&#x27;body%20*&#x27;)%3Bfor%20(i%20%3D%200%3B%20i%20%3C%20elements.length%3B%20i%2B%2B)%20%7Bif%20(getComputedStyle(elements%5Bi%5D).position%20%3D%3D%3D%20&#x27;fixed&#x27;)%20%7Belements%5Bi%5D.parentNode.removeChild(elements%5Bi%5D)%3B%7D%7D%7D)()%7D)() reply gwern 17 hours agoprev> As those browsers rose in market share, extensions began to overtake bookmarklets in popularity. The Bookmarks bar faded to the background more. Bookmarklets are still in use, and still quite useful, but they are ….Is this article not finished? reply CamperBob2 17 hours agoparentNo, it&#x27;s not finished, but ChatGPT was. reply idonotknowwhy 13 hours agorootparentWeirdly, I learned about bookmarklets last week when ChatGPT was giving me a solution to put the old slack ui back reply bambax 15 hours agoprev> As those browsers rose in market share, extensions began to overtake bookmarklets in popularityHalfway between bookmarklets and browser extensions sit user scripts: arbitrary long scripts that are run by a specialized extension (usually, today, TamperMonkey).They are incredibly powerful and can customize pretty much any webpage, with none of the limitations of bookmarklets, and very little of the hassle of creating a proper extension.They&#x27;re quite addictive. reply rrrrrrrrrrrryan 8 hours agoparentI&#x27;m old enough to remember when Opera supported userscripts by default. I thought they were the future, but today it seems most would-be userscripts are just turned into extensions instead. Now that browsers have more granular permissions control, from a user perspective, I suppose it doesn&#x27;t matter much whether it&#x27;s called an extension or a userscript. But from a developer perspective it makes it&#x27;s a little more tough to build a simple thing and throw it out into the world. reply bambax 4 hours agorootparentIt&#x27;s much easier to write a userscript than an extension -- the problem is distribution: almost no one know what they are or how to install them, etc.But I have been making them at work to bypass and improve some quirks of Atlassian products for instance (JIRA and Confluence), and there they spread like wildfire. reply yubiox 9 hours agoparentprevI wrote userscripts to speed up annoying MS and okta logins, like the ones where you have to click to send a 2FA text or click a stupid checkbox to stay logged in. I also wrote one to show what I call \"spending cash available\" (cash minus credit card balances) on personalcapital. Plus I found one that turns youtube shorts into normal videos. Fun stuff. reply kevlened 17 hours agoprevBookmarklets are great in mobile browsers. This is handy if you want to avoid writing an extension for a simple script.I often use a bookmarklet I wrote to remove the extra content from online recipes: https:&#x2F;&#x2F;github.com&#x2F;kevlened&#x2F;foodmarkletIt’s based on https:&#x2F;&#x2F;github.com&#x2F;poundifdef&#x2F;plainoldrecipe, but it works entirely in the client. reply raspo 16 hours agoparentRecipe websites are some of the worst things on the web these days, with autoplaying videos, ads, newsletter box, cookie notice, while the actual recipe is buried down after a bunch of useless preamble... I tested this foodmarklet in a few places and so far it seems to work amazingly. Thank you for sharing! reply bloopernova 10 hours agorootparentKagi.com, a $10&#x2F;month search engine, has \"lenses\" that \"focus\" your search. One of the lenses is \"recipe sites that are high quality and don&#x27;t have loads of useless crap\" reply nfriedly 13 hours agorootparentprevI&#x27;ve taken to copy-pasting recipes into a google doc and then cleaning up the formatting if I use it more than once or twice. reply jtbayly 16 hours agoparentprevAgreed.I have one I use on my iPhone that shows page source. Comes in handy sometimes.javascript:(function()%7Bvar%20a=window.open(&#x27;about:blank&#x27;).document;a.write(&#x27;%3C!DOCTYPE%20html%3E%3Chtml%3E%3Chead%3E%3Ctitle%3ESource%20of%20&#x27;+location.href+&#x27;%3C&#x2F;title%3E%3Cmeta%20name=%22viewport%22%20content=%22width=device-width%22%20&#x2F;%3E%3C&#x2F;head%3E%3Cbody%3E%3C&#x2F;body%3E%3C&#x2F;html%3E&#x27;);a.close();var%20b=a.body.appendChild(a.createElement(&#x27;pre&#x27;));b.style.overflow=&#x27;auto&#x27;;b.style.whiteSpace=&#x27;pre-wrap&#x27;;b.appendChild(a.createTextNode(document.documentElement.innerHTML))%7D)(); reply lgats 7 hours agorootparentthis is awesome! I&#x27;ve added the page title to the source: javascript:!function(){var e=window.open(\"\",\"_blank\");e.document.write(\"Source of \"+location.href+\"\"),e.document.body.querySelector(\"pre\").textContent=document.documentElement.outerHTML,e.document.close()}(); reply notatoad 10 hours agoparentprevoh, this is great. i&#x27;ve never thought to even try bookmarklets on mobile. reply gabrielsroka 12 hours agoprevFun fact, I found, mostly by accident, that adding a comment to the beginning of a bookmarklet Chrome will set it to the name. I&#x27;d love to see the source code in Chrome that does this.Eg javascript:&#x2F;* name: &#x2F;awesome# *&#x2F;alert(2+2) reply davchana 12 hours agoparentDoes it have to be two lines? Going to try this from home. reply gabrielsroka 12 hours agorootparent2 lines? reply davchana 5 hours agorootparentEdit: my bad, it was my mobile layout.I mean does it need a line break as it is seen in your code? reply gabrielsroka 5 hours agorootparentI don&#x27;t see a line break. Are you on mobile? Turn it sideways. replyp1mrx 11 hours agoprevThis is texed, the plainest text editor: data:text&#x2F;html,texed reply Khoth 17 hours agoprevI use one to get rid of fixed headers on a page javascript:(function()%20{%20var%20s,e,i,ee=document.getElementsByTagName(&#x27;*&#x27;);%20for(i=0;%20e=ee[i];%20i++)%20{%20s=getComputedStyle(e);%20if%20(s%20&&%20s.position%20==%20&#x27;fixed&#x27;)%20e.style.position=&#x27;static&#x27;;%20}%20})(); reply colinprince 17 hours agoparentya, same, I don&#x27;t know where I got this one but I modified it to include stickyjavascript:var ni%3Ddocument.createNodeIterator(document.documentElement,NodeFilter.SHOW_ELEMENT,function(node)%7Breturn document.defaultView.getComputedStyle(node,null).getPropertyValue(\"position\").match(&#x2F;sticky|fixed&#x2F;) %3F NodeFilter.FILTER_ACCEPT : NodeFilter.FILTER_REJECT%3B%7D)%3Bwhile(currentNode%3Dni.nextNode())%7Bconsole.log(currentNode.remove())%3B%7D reply dmlerner 14 hours agorootparentCan&#x27;t live without this. The 10% of the time it doesn&#x27;t work makes me sad. Super useful from cVim&#x2F;Vimmium etc, I keep it mapped to &#x27;gh&#x27; reply williamdclt 17 hours agoparentprevI use that all the time (to get rid of any fixed element, incl footers and floating sidebars) reply mastazi 9 hours agoprevI still regularly use the \"Post to HN\" bookmarklet. I seem to remember (if memory serves me right) that this used to be in the footer of the actual HN website many years ago. Is anyone else still using it?EDIT: it can still be accessed from here https:&#x2F;&#x2F;news.ycombinator.com&#x2F;bookmarklet.htmlEDIT 2: the bookmarklet is also linked from HN&#x27;s \"submit\" page, just below the form. javascript:window.location=%22http:&#x2F;&#x2F;news.ycombinator.com&#x2F;submitlink?u=%22+encodeURIComponent(document.location)+%22&t=%22+encodeURIComponent(document.title) reply madacol 12 hours agoprevedit any text on the page: javascript: (function() { document.body.contentEditable = true; document.body.spellcheck = false; })();---Longer bookmarklets: https:&#x2F;&#x2F;github.com&#x2F;madacol&#x2F;web-automation&#x2F;tree&#x2F;master&#x2F;bookma... - Highlight selected text - chatgpt to markdown - Convert images to base64 DataURL markdown embedding reply suvadivian 16 hours agoprevBase 64 decode. This is the only one I use frequently.javascript:function%20c(){}c.prototype.get=function(){var%20a=\"\";window.getSelection?a=window.getSelection().toString():document.selection&&\"Control\"!=document.selection.type&&(a=document.selection.createRange().text);return%20a};c.prototype.set=function(a){if(window.getSelection){var%20b=window.getSelection();b.rangeCount&&(b=b.getRangeAt(0),b.deleteContents(),b.insertNode(document.createTextNode(a)))}else%20document.selection&&document.selection.createRange&&(b=document.selection.createRange(),b.text=a)};try{var%20d=new%20c,e=atob(d.get());d.set(e)}catch(a){alert(a.message)}; reply Lammy 16 hours agoprevI used the \"Readability\" bookmarklet a lot back in The Day before that functionality was built-in https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20090303150113&#x2F;http:&#x2F;&#x2F;lab.arc90.... reply arkush 13 hours agoprevArchive current page with Internet Archive&#x27;s The Wayback Machine: javascript:void(open(\"https:&#x2F;&#x2F;web.archive.org&#x2F;save&#x2F;\" + document.location))Archive current page with archive.today: javascript:void(open(\"https:&#x2F;&#x2F;archive.ph&#x2F;?run=1&url=\" + encodeURIComponent(document.location)))Search Google Cache for current page: javascript:void(open(\"https:&#x2F;&#x2F;webcache.googleusercontent.com&#x2F;search?q=cache:\" + document.location))Open current Reddit post in Reveddit: javascript:void(open(\"https:&#x2F;&#x2F;www.reveddit.com&#x2F;\" + document.location.pathname)) reply kccqzy 17 hours agoprevTwo of my most used bookmarklets are to reset the viewport or force a desktop viewport. Annoyances like websites not allowing you to zoom in using the viewport meta element `user-scalable=no` can be mitigated by deleting that element. Sometimes I&#x27;ve found it also useful to force a desktop viewport because the mobile view hides too many controls. reply ceritium 3 hours agoprevI think it&#x27;s appropriate to share a small tool I did for creating and sharing bookmarkletshttps:&#x2F;&#x2F;bookmarklet.jose.grEverything is stored in the URL, actually I am just thinking I should add offline first support. reply joshu 17 hours agoprevthe idea of using a bookmarklet to snap the current page was the entire basis of the prototype i built before del.icio.us reply ralphc 16 hours agoparentpinboard carries on this tradition reply k__ 13 hours agoprevFew years ago, I created the undefined gooselet.https:&#x2F;&#x2F;kay-is.github.io&#x2F;undefined-gooselet&#x2F; reply jstrieb 9 hours agoprevA while ago, I came up with a way to use bookmarklets to make bookmarks that open to different pages depending on the order in which you click them.https:&#x2F;&#x2F;jstrieb.github.io&#x2F;projects&#x2F;hidden-bookmarks&#x2F;Every clicked bookmarklet concatenates a character to a passphrase used for AES decryption. The encrypted text and current passphrase are stored as intermediate state in the URL hash. When it decrypts, it redirects. If it doesn&#x27;t decrypt, it goes to a fallback page as if it was a regular bookmark.It was mostly a fun proof-of-concept, but I am hopeful that the technique has actually been useful to someone. reply maxglute 16 hours agoprevProtip is named bookmarklets can be triggered on Android Chrome if you search the name and tap it on the omnibar. Very useful for setting playback speed on mobile. I have desktop bookmarklets that increment &#x2F; decrements playback speed, and mobile bookmarklets with fixed playback speed.Wish there was easier way to customize&#x2F;set favicon for bookmarklet. Right now you can export bookmark, edit indata, and import. If you have multiple chrome sessions you need to import on all devices within short period or icon will reset to default globe. reply marban 17 hours agoprevQuick plug for my HN bm: https:&#x2F;&#x2F;thomas.me&#x2F;hnb&#x2F; reply williamdclt 17 hours agoprevMake webpage fullscreen:`javascript:(()=>{b=document.createElement(\"button\");b.onclick=()=>{document.documentElement.requestFullscreen();b.remove()};b.style=\"all:reset;position:fixed;z-index:9999;left:0%;top:0%;width:100%;height:100%;background-color:lightpink\";b.innerText=\"Full Screen\";document.body.appendChild(b)})()`It pops up a giant red button, as user interaction is required for fullscreen reply rendleflag 14 hours agoprevI use a \"Go To Root\" bookmarklet for both going to the root url of the current URL; or going to the subreddit if I&#x27;m in a reddit story. It&#x27;s far from perfect, but I use it daily:```javascript:var url = new String(location.href); var re = new RegExp(&#x27;(https?:\\&#x2F;\\&#x2F;)([a-zA-Z0-9.]+)((\\&#x2F;r\\&#x2F;.\\&#x2F;)(comments.))?&#x27;); var res = url.match(re); &#x2F;&#x2F; go to the root URL root_url = res[1] + res[2]; &#x2F;&#x2F; If we are in a subreddit, go to the subredditre = new RegExp(&#x27;.*reddit.com&#x27;); if( res[2].match(re)) { if (typeof res[3] !== &#x27;undefined&#x27; && typeof res[4] != &#x27;undefined&#x27;) { root_url = root_url + res[4]; } } location.href=root_url;``` reply tpmx 17 hours agoprevWasn&#x27;t there some fundamental web&#x2F;javascript security policy change a decade or so ago that broke many bookmarklets? reply tpmx 14 hours agoparentThis is probably the post I&#x27;m thinking of:https:&#x2F;&#x2F;medium.com&#x2F;making-instapaper&#x2F;bookmarklets-are-dead-d...https:&#x2F;&#x2F;archive.ph&#x2F;hDumY reply ris 14 hours agoparentprevThat&#x27;s what I was thinking - most bookmarklets I ever wrote one by one stopped working and I got tired of fixing them. reply TheRealPomax 12 hours agoparentprevThe advent of CSP really ruined the bookmarklet party, because the browser would obey the CSP headers, rather than the user whose computer the browser was running on, preventing a slew of bookmarklets from working due to script loading being \"forbidden\" by the server whose pages you were trying to run your bookmarklet on. By the time browser makers finally tried to address that, the damage was already done. reply invalidator 14 hours agoprevI use a kinda hacky bit of JS to do a number of actions based on the current URL. I create bookmarks like this, and set a keyword (this one is &#x27;gt&#x27;, for Google Translate): javascript:location=\"https:&#x2F;&#x2F;translate.google.com&#x2F;translate?hl=&sl=auto&tl=en&u=\"+locationOn any page, I can type ctrl-L (select address bar), gs, enter, and I get the page translated to English.A couple more: Wayback machine: javascript:location=\"https:&#x2F;&#x2F;archive.md&#x2F;submit&#x2F;?url=\"+location 12 foot ladder: javascript:location=\"https:&#x2F;&#x2F;12ft.io&#x2F;proxy?q=\"+location reply TeMPOraL 16 hours agoprevAt work my team uses a bookmarklet I wrote the other day, to be able to add descriptions of Gerrit patchsets (iterations on a changeset for review). This was in response to Gerrit devs deciding, in their infinite wisdom, to just drop ability to set those descriptions from the UI. reply thirdplace_ 16 hours agoprevwayback machine for current url:javascript:window.location=&#x27;https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;*&#x2F;&#x27;+document.location reply QuantumGood 10 hours agoprevI frequently share Google Doc links, and I prefer the toolbar collapsed, which hides the share button (which takes a bit to load anyway). I triple click and Ctrl-C the link that pops up from this bookmarklet: javascript:(function(){alert(window.location.href.replace(&#x2F;\\&#x2F;edit.*$&#x2F;, &#x27;&#x2F;edit?usp=sharing%27));})() reply dvh 17 hours agoprevIt would be great if snippets could be used in bookmarklets. Instead of: javascript:some_codeYou would write: snippet:nameSnippets are much easier to write because snippets are edited in normal multiline editor with console and stuff. reply digging 17 hours agoparent> Snippets are much easier to write because snippets are edited in normal multiline editor with console and stuff.Most of my bookmarklets are specific to work projects and I save them in the repo itself in a top-level bookmarklets.js file so I can use VSCode to edit them. (Then I just copy and paste them into the browser bookmark.) reply SushiHippie 13 hours agoparentprevhttps:&#x2F;&#x2F;bugzilla.mozilla.org&#x2F;show_bug.cgi?id=1315549Mhm, snippets seem to be chrome only reply gabrielsroka 12 hours agoparentprevI use snippets all the time. When I&#x27;m ready to make a bookmarklet, I just add javascript: to the front and then drag them to my toolbar. reply 01100011 16 hours agoprevI use a bookmarklet along with a keyword in Firefox to allow querying a bug number in our internal bugzill db. So I can type &#x27;b &#x27; in the URL bar and it takes me right to the bug.Firefox doesn&#x27;t directly support bookmarklets, IIRC, so instead I use a custom search engine with a bookmarklet for the URL to accomplish the same thing. reply woodruffw 15 hours agoparentBookmarklets work correctly for me in Firefox on Linux. It may be a site-specific CSP setting? reply 01100011 8 hours agorootparentD&#x27;oh, I meant Chrome reply indus 10 hours agoprevReading comments makes me feel that we need a monthly..\"All the new bookmarklets.\":-) reply a_c 17 hours agoprevMy favouritesSpeed up video&#x2F;audio on youtube javascript:(function() { (document.querySelector(&#x27;video&#x27;) || document.querySelector(&#x27;audio&#x27;)).playbackRate = (+prompt(&#x27;How many times normal speed?&#x27;) || 1); })();Bypass paywall javascript:location.href=&#x27;https:&#x2F;&#x2F;archive.is&#x2F;?run=1&url=%27+encodeURIComponent(document.location.href) reply swyx 15 hours agoparentjust use video speed controller https:&#x2F;&#x2F;chrome.google.com&#x2F;webstore&#x2F;detail&#x2F;video-speed-contro... reply baal80spam 14 hours agorootparentI&#x27;ve used this extension for several years now. I honestly can&#x27;t imagine browsing without it. reply Yujf 17 hours agoparentprevI use an extension that lets me quickly jump to bookmarks and have a bunch of yt speed bookmarklets (named 1.25x, 1x, 2x etc) and it is so nice to quickly change playback speed with the keyboard reply abhinavk 17 hours agorootparentThere are builtin keyboard shortcuts in the YouTube player. Shift+, or . for changing the speed.They cannot be customized though. reply a_c 17 hours agorootparentprevActually same here. I use vimium for jumping between x1, x2, etc bookmarks reply starshadowx2 12 hours agoprevI&#x27;m a bit confused, does this article just end like this or is there something I&#x27;m missing?\"The Bookmarks bar faded to the background more. Bookmarklets are still in use, and still quite useful, but they are ….\"They are what? reply colinprince 17 hours agoprevI use this one on my phone to boost text size when my eyes are tiredjavascript:var%20p=document.getElementsByTagName(&#x27;*&#x27;);for(i=0;i%3Cp.length;i++)%7Bif(p%5Bi%5D.style.fontSize)%7Bvar%20s=parseInt(p%5Bi%5D.style.fontSize.replace(%22px%22,%22%22));%7Delse%7Bvar%20s=12;%7Ds+=8;p%5Bi%5D.style.fontSize=s+%22px%22%7D reply sbierwagen 16 hours agoparentiOS Safari has this in the aA menu inside the address bar. reply alexcaza 17 hours agoprevI haven&#x27;t used them heavily, but when I was doing user-research for a small startup, I needed to get timestamped links from Google Drive videos to add to interview notes. It was a huge pain in the ass. So I wrote a little bookmarklet to copy the URL with timestamp to clipboard. reply sieste 12 hours agoprevI&#x27;d like to have a shortcut that appends currently highlighted text, current url and timestamp to a text file on my disk. Can this be done with a bookmarklet? reply jabbequbs 9 hours agoparentI&#x27;ve found it really handy to just have a local Python webserver running on my workstation. Then my bookmarklets can just hit eg http:&#x2F;&#x2F;localhost:8000&#x2F;cgi-bin&#x2F;script.py to modify a local file or open up my notes for a certain Jira ticket or whatever else I can think of. There are security considerations with that approach though, since any random site you load can start sending requests to your local webserver. reply davchana 12 hours agoparentprevCannot append. Can do everything else you ask. Either will download that one text content as text file, or can put it in the clipboard, and you manually have to open it & paste it. reply LeonB 10 hours agorootparentPerhaps if the bookmarklet opened a new url containing the text as a query parameter, and the url had a weird protocol instead of https:&#x2F;&#x2F; — say it was snippy:&#x2F;&#x2F; … and then you created a protocol handler on your machine for the “snippy” protocol …. And it saved the relevant query param to a file.I can’t remember if I’ve done this before. It seems like something I’ve done. reply jabbequbs 9 hours agorootparentI&#x27;ve done that too. I ended up just using a local webserver with some Python cgi scripts instead though. I found it more flexible and easier to remember how things worked that way. reply davchana 5 hours agorootparentprevYes, the other easy way I have used multiple times is, bookmarklet simply sends the text via a POST request to Google Apps Script, which simply appends it to a sheet or doc. reply Brajeshwar 17 hours agoprevThe Mouseover DOM Inspector from the early 00s was an awesome dev tool.http:&#x2F;&#x2F;slayeroffice.com&#x2F;?c=&#x2F;content&#x2F;tools&#x2F;modi.html reply PaulHoule 15 hours agoprevIt&#x27;s like browser extensions but not toxic, malware-infected, browser performance destroying, compatibility with websites breaking, killing your web browser with \"pluginitis\", ... reply slater 17 hours agoprevAlways good to have some of these in your bookmarks toolbar:https:&#x2F;&#x2F;www.squarefree.com&#x2F;bookmarklets&#x2F;zap.html reply LeonB 9 hours agoparentSquare free … there’s a name I haven’t heard in a long time.They had a simple wysiwyg in the browser html editor, in the pre-Ajax era. reply uoaei 17 hours agoprevThe only bookmarklet I use regularly is SciHubIfy: javascript:location.href=\"https:&#x2F;&#x2F;sci-hub.se&#x2F;\"+location.href; reply egorpv 12 hours agoparentSame, but my version uses a different approach. It takes the selected (or entered via prompt) text, strip spaces and opens the sci-hub in a separate tab. javascript: Qr = window.getSelection ? window.getSelection().toString() : document.selection.createRange().text; if (Qr) { void(window.open(&#x27;https:&#x2F;&#x2F;sci-hub.se&#x2F;&#x27; + String(Qr).replace(&#x2F;^\\s+|\\s+$&#x2F;g, &#x27;&#x27;))); } else { void(Qr = prompt(&#x27;Enter URL&#x2F;DOI to sci-hub it&#x27;, &#x27;&#x27;)); location.href = &#x27;https:&#x2F;&#x2F;sci-hub.se&#x2F;&#x27; + String(Qr).replace(&#x2F;^\\s+|\\s+$&#x2F;g, &#x27;&#x27;); } reply laughy 14 hours agoparentprevThe one I use is slightly more advanced, can&#x27;t copy it for some strange reason, but I use a service that checks for a valid domain first reply zipzup 16 hours agoprevFor watching chess I use one on chess24 and lichess that displays the current score and first four characters of the players’ names in the title bar. reply desertlounger 14 hours agoprevFWIW, javascript:&#x2F;&#x2F; bookmarklets don&#x27;t work on the standard Chrome home &#x2F; new tab page, but data URL bookmarklets work everywhere. Here&#x27;s my bookmarklet for Day Of Year...data:text&#x2F;html,now=new Date();alert(`Today is DOY ${1+Math.floor((now.getTime()-new Date(now.getFullYear(),0,1).getTime())&#x2F;8.64E7)}`); reply louisbuchbinder 16 hours agoprevclick those skip ads buttons on you tubejavascript:eval(atob(&#x27;c2V0SW50ZXJ2YWwoZnVuY3Rpb24gKCkgewogICAgdmFyIGVsZW0gPSBkb2N1bWVudC5nZXRFbGVtZW50c0J5Q2xhc3NOYW1lKCd5dHAtYWQtc2tpcC1idXR0b24geXRwLWJ1dHRvbicpWzBdOwogICAgaWYgKGVsZW0pIHsKICAgICAgICBlbGVtLmNsaWNrKCk7CiAgICB9Cn0sIDEwMDApOw==&#x27;)) reply hnrodey 16 hours agoparentsetInterval(function () { var elem = document.getElementsByClassName(&#x27;ytp-ad-skip-button ytp-button&#x27;)[0]; if (elem) { elem.click(); } }, 1000); reply poxrud 16 hours agoprevI made one that uses openai api to summarize the current page that I’m on. reply undebuggable 14 hours agoprevThe pinnacle of bookmarklets was Firebug Lite. reply threeio 12 hours agoprevI feel very old right now. reply ulrischa 16 hours agoprevSadly bookmarklets do not work in mobile Browsers. Would be great. reply _iven_ 15 hours agoparentBookmarklets can work in mobile browsers.For mobile Chrome:- Create a new bookmark- Replace the bookmarked link with the bookmarklet javaScript code, e.g., javascript:alert(&#x27;hello world&#x27;)- To use the bookmarklet, start typing the bookmark name in the address bar until the auto-complete displays the bookmark, and then click on it.For mobile Safari,- Create a new bookmark and replace the URL with your javaScript code- To use the bookmarklet, tap on the bookmarklet name from the bookmarks menu(The edit was to better format my comment) reply maxglute 15 hours agoparentprevSome do for chrome on android. They have to be named, you can search for the same in omnibar and tap. Works for things like changing playback speed. reply shmerl 17 hours agoprevHere is one of the few I use:Rotate images 90° clockwise: javascript:(()=>{var imgs = document.getElementsByTagName(\"img\");for (var img of imgs){img.setAttribute(\"style\",\"transform:rotate(90deg);\");}})(); reply gabrielsroka 12 hours agoparentThis one is a little shorter. javascript:document.querySelectorAll(&#x27;img&#x27;).forEach(img => img.setAttribute(&#x27;style&#x27;,&#x27;transform:rotate(90deg);&#x27;)) reply lloydatkinson 18 hours agoprev [–] I wonder if people use them very often today. Anyway, https:&#x2F;&#x2F;github.com&#x2F;marcobiedermann&#x2F;awesome-bookmarklets reply teddyh 17 hours agoparentMissing:• http:&#x2F;&#x2F;kathack.com&#x2F;• https:&#x2F;&#x2F;kay-is.github.io&#x2F;undefined-gooselet&#x2F; reply gregsadetsky 17 hours agorootparentah, kathack is amazing but doesn&#x27;t work on https sites since it loads a script from an http server. and is broken by CSP too... a real shame. it&#x27;s really beautiful! reply RandallBrown 16 hours agoparentprevThe website Babylist (a baby registry site) uses a bookmarklet for adding things to your registry that they don&#x27;t sell themselves. It was the first real world use of a bookmarklet I had seen in a loooong time. reply frandroid 17 hours agoparentprevI post to Facebook and Twitter using bookmarklets and i just made a bookmarklet to use newsproxy.ca to get around Facebook&#x27;s news blockade in Canada.These you posted are really great reply gxs 17 hours agoparentprev [–] Nothing fancy, or special, but I use them so that I don’t have go to a site first and then search.Over the years I’ve built one up that recognizes various record ID formats or other record numbers and automatically takes you to that record or forwards you to the site if you paste the entire url.It has a few other keyword shortcuts to save on monotonous clicks.Nowadays with slack and people being a bit web savvier in general it’s not as useful as it once was, but you’d be surprised how annoying it is to enter jira ticket ids over and over. reply jtokoph 17 hours agorootparent [–] I feel like you’re talking about custom site search that the browser search bar supports and not bookmarklets reply gxs 7 hours agorootparent [–] I’m not, guess it wasn’t clear what I meant. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The article details the history and evolution of JavaScript URLs, also referred to as bookmarklets, and how they were implemented into web browsers.",
      "It describes how JavaScript URLs were initially used to manipulate and alter web page content, and the expansive sharing tools made them popular amongst users.",
      "The piece further explores the emergence of browser extensions as an alternative to bookmarklets, signifying their rising prominence."
    ],
    "commentSummary": [
      "The post primarily focuses on bookmarklets, which are small JavaScript code snippets that can be stored as bookmarks for different functionalities in web browsers.",
      "Commenters highlight their favored bookmarklets and discuss their applicability in tasks like customization, productivity enhancement, and website alteration.",
      "The discussion also encompasses potential risks and constraints of bookmarklet use, along with resources for discovering and crafting them. Hence, bookmarklets are seen as valuable tools to enrich web browsing experiences."
    ],
    "points": 219,
    "commentCount": 149,
    "retryCount": 0,
    "time": 1698249022
  },
  {
    "id": 38016849,
    "title": "I think GCP is better than AWS (2020)",
    "originLink": "https://nandovillalba.medium.com/why-i-think-gcp-is-better-than-aws-ea78f9975bda",
    "originBody": "Write Sign up Sign In Top highlight Why I think GCP is better than AWS AWS is the best platform to showcase how great GCP is… Fernando Villalba · Follow 27 min read · May 9, 2020 5.1K 78 I originally posted this on Reddit so I could get a good sample of opinions from other engineers to see how they compared to mine before posting and expanding here. This is my opinion based on my experience with both platforms (two years in each). My bias towards GCP is mostly based on the superior experience I have gotten with it and I am in no way affiliated with Google. AWS is still my second choice as an enterprise option for cloud platform and it would be nice for them to do better. I welcome your comments and corrections, especially if they are informed and constructive, I am happy to learn from you. Ikea for Cars If AWS (Amazon Web Services) and GCP (Google Cloud Platform) were both car companies and you wanted to purchase a car, AWS would give you the wheel, a chunky verbose manual and the keys and then tell you to go to twenty different shops they also own to get the rest of the components to put them together yourself the best you can. Sure, maybe you can hire a service and get tools to automate this part, but it still falls on you to assemble these components together and maintain the automation. The experience of GCP on the other hand is more like collecting the car keys and driving off from the parking lot, with the option of dismantling and customising the car if you wish, but the default is a fully built functioning car with cohesive parts so you can quickly achieve your objectives, which is driving around, not assemble the car. My first experience working with AWS, before I had much to compare it to, was brief and I didn’t like it; I felt the interface and the way tools and settings were organised was counter-intuitive and weird. For example assigning a static ip to a server was just bizarre, I kept looking for ways to assign the static ip without knowing that it was meant to be called elastic ip and hidden away in a separate set of menus. These elastic ips were part of a different pool of ips than the ones that were assigned dynamically, so I had to stop a production server to change the ip and also change the DNS pointing to that new ip, this was because my predecessor hadn’t assigned an static ip to the server, my bet is that he probably gave up after ten minutes trying to figure out that it was called an elastic ip. My second experience working with AWS was after a year and a half working with GCP, and now by comparison I really couldn’t stand AWS, it took me a few months to get accustomed back to use it and I remember that in my first few weeks I actually considered quitting and just accepting GCP roles. It’s not that AWS is harder to use than GCP, it’s that it is needlessly hard; a disjointed, sprawl of infrastructure primitives with poor cohesion between them. A challenge is nice, a confusing mess is not, and the problem with AWS is that a large part of your working hours will be spent untangling their documentation and weeding through features and products to find what you want, rather than focusing on cool interesting challenges. Let’s just go over a few of the things that make AWS such a pain to use and how it compares with GCP. Accounts vs Projects One of the first differences that strikes you when going from GCP to AWS is accounts vs projects. In GCP you have one master account/project that you can use to manage the rest of your projects, you log in with your company google account and then you can set permissions to any project however you want. So you can have a dev project, a production project, etc. All of this works out of the box and there is absolutely nothing additional for you to do. In AWS you have accounts, and each account has a separate set of users. There are ways to connect these accounts so your user has permissions on other accounts. One way of doing this is creating a master users account and then adding roles that can be assumed in all other accounts by this master account. This is not only a pain to set up, it’s very painful to use as well. For example when using terraform scripts you need to coordinate multiple roles across several modules if you need to work across multiple accounts. Command Line Interface Tools (CLI tools) Let’s just compare what you have to do in order to use GCP cli compared to AWS provided we are using 2FA and a couple of different projects/accounts. In GCP after you install the Google SDK, all you need to do is run gcloud init, which redirects you in the browser to a Google login page. Here you can login with your 2FA (which if you have an android phone is as easy as unlocking the phone and pressing okay) and you are done. Your login session is attached to your Google session so when you kill this session you are logged out— very simple. In AWS you need to create a token that you can use to login with your CLI, simple enough, right? But now we want to use 2FA, and this is where the fun begins. After you login with your token you then need to create a script to give you a 12 hour session, and you need to do this every day, because there is no way to extend this. Okay, but that’s not a big deal, you say, after all it’s just a code that you need to input once a day and you can get on with your day after that. But wait, there is more! If you need to assume roles in another account, you need to create yet another script that creates another profile for you to use. That’s one step plus two scripts, plus many steps in between. And sure, you can automate much of this or use someone else’s tools you find online (that you most likely will need to tweak), but why? Why do we have to do so much work to use AWS? Why can’t AWS abstract away this pain away from you in the way that Google has done? Web User Interface If using the CLI is too painful for you, you can always log in to the portal and use their user interface, although I don’t recommend you do this for everything, in fact I recommend you use it the least possible and only for reference and to check status of your services, always do infrastructure as code as much as you can The AWS interface looks like it was designed by a lonesome alien living in an asteroid who once saw a documentary about humans clicking with a mouse. It is confusing, counterintuitive, messy and extremely overcrowded. I can’t even count the times I’ve gotten lost or stumped in the AWS console, sometimes over the most stupid details, like missing that there was a next button hidden on a weird corner. Or trying to use search bars that can only search prefixes (WTF?) But the biggest frustration I have from the AWS console is how you are always overwhelmed with scores of settings and options you need to fill in before actually provisioning anything. One example that comes to mind is when someone at work said we should use codebuild/codedeploy to replace Jenkins for ECS deployments. The first engineer tried, he got stuck, the second engineer tried, he got stuck, I tried for hours and I got stuck… in the end I just gave up for lack of wanting to spend any more time on a tool that doesn’t seem to be that popular for CI/CD that I thought was meant to make life easier. Amazon seems to be particularly terrible at interfaces in almost all of their products though. For example in my Smart TV the Netflix app works flawlessly and is intuitive to use whereas the Amazon Prime app is an abomination, you are constantly accidentally pressing the wrong button or getting lost or the subtitles are often out of sync. In a rant that a Google engineer who had worked at Amazon wrote a while back he explained the issue with Amazon and Bezos not understanding interfaces (or is it human interaction?) like this: Jeff Bezos is an infamous micro-manager. He micro-manages every single pixel of Amazon’s retail site. He hired Larry Tesler, Apple’s Chief Scientist and probably the very most famous and respected human-computer interaction expert in the entire world, and then ignored every goddamn thing Larry said for three years until Larry finally — wisely — left the company. Larry would do these big usability studies and demonstrate beyond any shred of doubt that nobody can understand that frigging website, but Bezos just couldn’t let go of those pixels, all those millions of semantics-packed pixels on the landing page. They were like millions of his own precious children. So they’re all still there, and Larry is not. GCP’s user interface is on the other hand very intuitive to use and whenever you want to provision anything you are given sane defaults so you can deploy anything in a couple of clicks, I have never gotten lost using GCP or needed to consult a million pages of documentation to find out what I needed to do. This however does not mean that GCP is taking away from you the power to configure things to an intricate detail, it just means they are giving you an example of a working configuration that you can then tweak to your purposes. There are also other things you can do from the UI in GCP that either work really badly in AWS or are non-existent. For example you can easily open a terminal and ssh into any instance you have spun (provided you set permissions for it) and it works really well. Another feature you have in GCP that I absolutely LOVE is the ability to view the CLI command that would do whatever settings you have in the console. That makes learning the cli so much easier, it’s far better than scouring the net for examples on how to do anything or trying to make sense of AWS’s gorgeous documentation… Documentation You can forgive the documentation in AWS being a nightmare to navigate for being a mere reflection of the confusing mess that is trying to describe. Whenever you are trying to solve a simple problem far too often you end up drowning in reference pages, the experience is like asking for a glass of water and being hosed down with a fire hydrant. Great documentation is contextual, not referential. If you wanted to learn how to cook a dish, you don’t want someone to point you to a list of ingredients, you want a recipe describing how to use them, and this is where AWS documentation too often fails; it exhaustively describes everything that they have (which is not bad), but they don’t always do a good job at putting the documentation into context. To be perfectly fair to whoever is tasked to document anything in AWS, it is a lot harder to document something that’s confusing and messy than something that’s simple to use. Extensive and overly verbose documentation is often a sign of complicated and over convoluted software or processes, so in this sense Google Cloud already has an advantage to begin with. The big problem here is not that AWS doesn’t document enough, in fact it may even document more than GCP, the problem is that documentation is not a substitute for automation. Take this example of long document (that leads to many other documents) telling you how to deploy the alb controller in EKS. All of this incredibly long and tedious process should have been automated by AWS so when you run EKS you can opt whether to have this controller installed or not with a tick box or a cli parameter or an extra option in terraform, as it’s the case in GCP. Instead AWS forces you to go through this lengthy documentation and put this together yourself, which can easily take you a day or more if you want to test and understand everything thoroughly. The documentation in GCP is generally more clear and concise because they don’t need to teach you how to build everything from scratch like the above example, and while it may not always be perfect I generally found it useful and to the point. If you want other good examples of great documentation look at DigitalOcean — they are great. GKE vs EKS If your intent is to use Kubernetes, don’t even bother with AWS, their implementation is so bad I can’t even comprehend how they have the gall to call it managed, especially when compared with GCP In GCP if you want to spin a cluster, no problem, just a couple of clicks and you are there. The defaults are easy and sane and the entire product feels very cohesive with all the ugly, tedious bits abstracted away from your experience. With GKE you don’t need to join the nodes, you don’t need to plan or automate for an upgrade of these nodes either, or go through this abomination to use ingress, it’s done automatically or with a couple of easy clicks, and this does not mean you are sacrificing complexity. You can customise a lot, but when presented with sane, simple defaults, it’s a lot easier to understand a product that when being overwhelmed with a barrage of options and trying to figure out how everything fits together as it’s the case with EKS. ̶S̶p̶i̶n̶n̶i̶n̶g̶ ̶a̶n̶ ̶E̶K̶S̶ ̶c̶l̶u̶s̶t̶e̶r̶ ̶g̶i̶v̶e̶s̶ ̶y̶o̶u̶ ̶e̶s̶s̶e̶n̶t̶i̶a̶l̶l̶y̶ ̶a̶ ̶b̶r̶i̶c̶k̶.̶ ̶Y̶o̶u̶ ̶h̶a̶v̶e̶ ̶t̶o̶ ̶s̶p̶i̶n̶ ̶y̶o̶u̶r̶ ̶o̶w̶n̶ ̶n̶o̶d̶e̶s̶ ̶o̶n̶ ̶t̶h̶e̶ ̶s̶i̶d̶e̶ ̶a̶n̶d̶ ̶m̶a̶k̶e̶ ̶s̶u̶r̶e̶ ̶t̶h̶e̶y̶ ̶c̶o̶n̶n̶e̶c̶t̶ ̶w̶i̶t̶h̶ ̶t̶h̶e̶ ̶m̶a̶s̶t̶e̶r̶,̶ ̶w̶h̶i̶c̶h̶ ̶a̶ ̶l̶o̶t̶ ̶o̶f̶ ̶w̶o̶r̶k̶ ̶f̶o̶r̶ ̶y̶o̶u̶ ̶t̶o̶ ̶d̶o̶ ̶o̶n̶ ̶t̶o̶p̶ ̶o̶f̶ ̶t̶h̶e̶ ̶p̶r̶o̶m̶i̶s̶e̶ ̶o̶f̶ ̶“̶m̶a̶n̶a̶g̶e̶d̶”̶ EDIT: From the time I worked with EKS to the time I wrote this article, AWS added managed node groups. However when going through the console creating EKS resources you still have to go through a lot of options and screens. Also managed nodes need to be created after provisioning the cluster going through yet another set of options and screens. While this is definitely a welcomed improvement, the underlining design ethos that applies to most of AWS is still in EKS, which is what I am ranting about here. Thank you to the EKS team for bringing this to my attention and please don’t take this as a personal attack, I have every confidence of your competence and you are not to blame for the organisational structures that may compel you build products this way. And yes, I know that there are official terraform modules that take care of most of this work for you and make the job a lot easier and there is also a tool called eksctl developed by Weaveworks which is great, but these aim to simplify a complex solution that should have been abstracted away by AWS by design, not rely on others to make sense of the mess with complex scripts and tools. Even if you use those tools to create your automation on top of AWS, the fact remains that there are a lot of moving parts underneath that you will always be responsible to orchestrate and make sure that are working and up to date. eksctl for example uses cloudformation templates in the background. Product Overload At the time of writing this, there are 169 AWS products compared to 90 in GCP. AWS has been around for longer and therefore they have more offering, and in good Amazon spirits, they constantly and aggressively are expanding this offering to give you more of what you may need (and a lot of what you don’t need) at breakneck speed. This sounds like a good thing, until you start seeing the amount of half cooked products or near duplicates they have. One good example is Parameter Store and Secret Manager, which are different, but from a practical point of view they can look very similar with Secret Manager mostly just adding rotation of secrets. Another case of insane product overload is queues, explained well in this article by deps: GCP has done well integrating their different services together. GCP provides a smaller set of core primitives that are global and work well for lots of use cases. Pub/Sub is probably the best example I have for this. In AWS you have SQS, SNS, Amazon MQ, Kinesis Data Streams, Kinesis Data Firehose, DynamoDB Streams, and maybe another queueing service by the time you read this post. 2019 Update: Amazon has now released another streaming service: Amazon Managed Streaming Kafka. GCP has Pub/Sub. Pub/Sub seems flexible enough to replace most (all?) of AWS’ various queues. AWS product naming and packaging is also very confusing. For example AWS Control Tower, Landing Zone and AWS Organisations seem like they should be consolidated into one product, and it seems they name these products in parallel, without talking to each other; apparently Control Tower creates landing zones, but they are not the “Landing Zone”. I watched a couple of talks on this and I still don’t fully understand it, like this one, notice the speaker struggling to try to make sense of this mess in three different points. And then in another talk about AWS Organisations, a different speaker explaining what the difference is between Control Tower and AWS Organisations… GCP on the other hand has fewer products but the ones they have (at least in my experience) feel more complete and well integrated with the rest of the ecosystem, and choosing one product over other doesn’t become an agonising choice that requires extensive research (okay, you still need to research, but not nearly as much) I used to mock Apple in the past for how limiting they were and how very few features they had compared to Windows and Linux Distros until I started using a Macbook, it was then that it became so clear to me that having an opinionated approach on a few products and tighter integration of the various components often yields a far superior and more stable experience which is similar to the experience that I am having with GCP vs AWS. GCP gives you less and is slower delivering, but what it gives you is far better integrated, simple to use and often works better than its AWS counterpart. AWS is a lot more Expensive AWS charges substantially more for their services than GCP does, but most people ignore the real high cost of using AWS, which is; expertise, time and manpower. With GCP, a relatively inexperienced engineer in platforming tools can pick it up and get his work done in a relatively short time because most of the tedious tasks of piecing all the parts together have been done by Google already. A task that may take you a day or less to do in GCP, you may spend a week to do the same thing in AWS. One example I can give here is VPC Endpoints. I was working with a terraform cluster installation and I wanted to restrict outbound traffic to the internet. The problem is that if you do this then you are also cutting off traffic to AWS, in order to address this problem you need to set up endpoints. Endpoints essentially allow you to connect to AWS via the AWS intranet as opposed to the internet (Don’t ask me why cloud providers don’t do this by default, it makes no sense to me). So simple enough, I just add these endpoints and then my job is done. Problem is that I was working with a cluster provisioner in terraform with a lot of moving parts and using multiple AWS services and you cannot set up an endpoint that applies to all AWS services, you can only do one endpoint per service and I had to do a lot of digging trying to figure out exactly all the services that the provisioner was using and add endpoints for each one of them, every time I added an endpoint, I found out I had to add another endpoint, I ended up adding about five of them and then I found out that a couple of the services that I was using didn’t have endpoints for them, so in the end I just had to allow outgoing traffic via a NAT. Out of curiosity I investigated how to do this in Google Cloud because I had never done it before, just to see how difficult it would be in comparison to AWS and I wasn’t surprised to find out that you can accomplish the same thing just by clicking on a checkbox or activating a setting, and it applies to all services. Also, doing this in GCP is free whereas in AWS you have to pay for each endpoint The above is just one example, but I have found that generally any task that I want to do in AWS requires far more energy and effort to do than GCP, meaning you are probably going to need to hire far more engineers and need more time and more money on human resources if you are using AWS than if you are using GCP. The Cost of interrupted Flow Another significant cost to your organisation if you decide to use AWS is the continuous interrupted flow. Flow is the state where you ideally want your engineers to be a good portion of their time at your company, not only they will be much happier, they will also be a lot more productive. The problem with using AWS is that because everything is so confusing and complicated to use you will have to spend a lot of time reading documentation and testing to figure out how things work, and the irritating thing is that it won’t be fun experimentation, it will be tedious and trivial issues that should not exist, like the endpoint issue I described above. Even after you are seasoned in the use of AWS you still spend an inordinate amount of time doing tedious things that you never have to do in GCP. Like inputting your 2FA code every 12 hours, or assuming roles, or just going over pieces and services and putting them together. The more tedious obstacles between you and the task you want to achieve, the harder it is to achieve flow. Performance I am not going to do extensive testing in both platforms and post benchmarks for this article since it’s a lot more work than I want to spend on this but I’ll just say that in my experience I felt that performance was almost always better in GCP, for example copying from instances to buckets in GCP is INSANELY fast, I remember being shocked by this because in a previous job I had to do a lot of hourly backups to buckets of large chunks of data in AWS and I always felt the copying was very slow, but this was not the case at all for GCP. One good example I experienced recently is how slow it is to spin clusters up with EKS. In GKE you can have a fully functional cluster in less than 4 minutes. In EKS it takes about 16 minutes to create just the control plane (and even then it’s not ready!!) and then you have to add another 3 minutes or longer to spin the nodes, although sometimes I had to wait much longer than this for the workers. This may not matter that much to some, but when I am creating new infrastructure I tear it down and recreate it a lot to test that everything is working correctly and to save the company money on weekends and evenings so for me this matters a lot. There are some latency tests in this article that clearly show that GCP does better across almost all areas when it comes to Network performance. This article also compares some services between AWS and GCP. Security Both AWS and GCP are very secure and you will be okay as long as are not careless in your design. However GCP for me has an edge in the sense that everything is encrypted by default. For example their buckets and their logs are encrypted in transit and at rest. For some bizarre reason AWS does not encrypt buckets or logs by default, you have to enable this. Who the hell would NOT want their data encrypted on AWS servers? GCP is also continuously publishing its internal models for security like BeyondCorp and BeyondProd, and designing GCP so it’s easier to integrate them for other companies. These security models are generally way ahead of the curve; for example BeyondCorp’s model has just been recently adopted by the National Cyber Security Center, and Google has published this six years ago while providing tools to implement it for quite some time. I am not saying that it is impossible to do the same with AWS, but it wasn’t designed with this intent in mind and it is a lot more difficult to implement. AWS on the other hand seems to have opted for supporting more traditional models of security. This is a good talk if you are interested in hearing more about GCP security: And here is an interesting tour of GCP’s datacenter security. Google is a world leader of Scalable Infrastructure. I would argue that there isn’t any other company on the planet that does scalability and global infrastructure better than Google (although CloudFlare definitely gives it a run for its money in some areas). Just to get a grasp of how incredible Google’s infrastructure is, In 2013 Google went down for 5 minutes and the internet traffic of the entire world went down by 40% because people assumed their Internet was broken when Google wouldn’t open. People trust google a lot more than they do their own internet connections because Google rarely ever goes down, and yet their combined services serve the most amount of traffic in the world. Google is constantly on the edge developing new technologies that can scale, and once these technologies have been tried and tested enough, they often open source them and put them as part of their cloud offering. These technologies include kubernetes, Golang, Hadoop, and many more So what’s better about AWS? There has to be something! As I mentioned I think that AWS certainly offers a lot more features, configuration options and products than GCP does, and you may benefit from some of them. Also AWS releases products at a much faster speed. You can certainly do more with AWS, there is no contest here. If for example you need a truck with a server inside, then AWS is for you. AWS also has more flexibility in terms of location of your data centres. Other than that… I would chose GCP any day, and I think GCP will cover the vast majority of your cases. Typical Objections to using GCP These are some of the objections I heard from people who pick AWS and are weary of choosing GCP as their provider. But wait, there are lots of third party tools to automate AWS so it’s not a problem Yes, like the aforementioned eksctl, some of them do an amazing job at this but they are still third party tools. I firmly believe AWS needs to work a lot on their abstraction of needless complexity so there is no need to have so many tools on top of it. So if GCP is so much better, why so many more people use AWS? I want to cover some of the reasons that hold back GCP from overtaking AWS, some of them are reasonable, other are pure myths or misperceptions. They were the first The principal reason why more people use AWS more than any other platform is that it has been around substantially longer than others. But that alone is not enough to make it king. Even though AWS is over-convoluted and mired with all the problems I just described, it is still a very decent product with excellent uptime and performance so if you are using it, you may not be compelled enough to move another platform, no matter how much better that other platform is. Aggressive expansion of product line AWS is much quicker at releasing new products than GCP, although as I mentioned previously, this can be good and bad, in my opinion is mostly bad. Following the Crowd Whenever you start working in a DevOps field you are bombarded with the idea that you must study and know how to use AWS in order to fail proof your career. AWS certifications for example are a very popular topic and every other engineer has at least one. And so it happens that most engineers made a commitment to AWS right from the beginning, spending years of their lives learning this platform and ignoring or glossing over others. Imagine if you are an engineer with 5 years of experience in AWS with lots of money and effort spent on AWS certifications and you are tasked to do infrastructure at greenfield project, what are you going to chose? Probably not GCP. Fear that you won’t be able to get another job if you chose GCP It’s true that there are a lot more jobs that use AWS, but there are also very, very few engineers with extensive experience in GCP compared to AWS. Taking a GCP job or getting a GCP certification will not make you disposable any time soon. Also, many employers are smart enough to recognise that a tool alone is not enough to define the quality of an engineer. I made a transition into another AWS role after having more experience with GCP fine, and even if some employers won’t like this, many others won’t mind. If you are still doubting that learning and dedicating yourself to GCP is a bad idea, maybe this will change your mind: Source Fear that GCP may be abandoned by Google Google will very often release products to see how the market reacts to them and if they don’t work well, they will abandon them. This is deliberate and a strategy that revolves around trying new things as a source of innovation and also not wasting resources on products that don’t work, which makes sense. Now that the company has started to release paid products like Stadia or GCP there is a perception that they will soon be abandoned. I highly doubt this will apply to GCP for three reasons: First, GCP is not just one product, but many products, all of which have involved a monumental amount of engineering effort and time invested. Second, it would be a PR disaster if Google were to leave out in the cold all the companies that rely on them, especially the big ones like Evernote, Coca Cola, Apple, Spotify, etc. It just won’t happen. Finally and most importantly, there is absolutely no sign of GCP’s business slowing down, which would make it even more unlikely for them to abandon the platform. Why would you throw out a part of your business that’s generating 2.6 billion as of 2020 and growing each year? Google doesn’t “eat their own dog food” with GCP This point doesn’t prove anything in my opinion, but I am just bringing it up here because it seems to be where AWS enthusiasts lean heavily on when promoting the platform, as if it was irrefutable proof that AWS is superior. There is a perception that because Google doesn’t use GCP for all their products and projects internally, they are not good enough for the public to use. Alternatively there is a perception that Amazon uses AWS for everything so that automatically makes them the most reliable choice — neither of them is accurate. Google does use GCP for a lot of things internally, including YouTube and Gmail as explained in this page: Internally, Google uses this infrastructure for several high-traffic and global-scale services, including Gmail, Maps, YouTube, and Search. Because of the size and scale of these services, Google has put a lot of work into optimizing its infrastructure and creating a suite of tools and services to manage it effectively. Google Cloud puts this infrastructure and these management resources at your fingertips. Amazon also uses AWS to power itself internally but this is not always the case. It’s true that Google does not use GCP internally for everything but there is a good reason for it. Google is always on the edge trying and testing new innovative technologies, these are extensively tested until they work great and later open sourced and made part of their cloud offering. This is not a bad thing, because as a customer you will rarely get a half cooked product with teething issues. AWS on the other hand will release a lot more products faster, and as a consequence products will not be as complete as their GCP counterparts which can also be good in the sense they may release some tool that meets your needs and works acceptably well at a faster speed than Google would. I don’t think neither approach is wrong, but I would prefer to use something that works more reliably than being a guinea pig, especially if I am paying good money for it, which is why I favour Google’s approach in this case. Another thing I will point out here is that Google contributes way more to the Open Source community and industry overall than Amazon does, which happens thanks to the experimentation going on inside Google. “You can’t get fired for choosing AWS” Meaning that AWS is such a safe bet as a platform provider that you could not get fired as a result of choosing it. This is what some people say in the industry to justify picking AWS as the default. All I can say here is that if your employer fires you for choosing GCP, he is probably not a very good employer to begin with and you deserve a better job, which I am sure you can easily get giving the demand for your skills. Jokes aside though, if the engineering talent in your company is good, they will make it work both in AWS and GCP, so I wouldn’t worry too much about your choices. Chose the platform that you feel suits your needs best, and yes, GCP is also a very safe bet. Disdain for Google For some reason, some people really seem to hate Google. I can completely understand that Google sometimes will do things that are objectionable (and occasionally toying with the very objectionable), but I would argue that Google is not the worst of the lot by a long shot, they are in many ways more ethical than Microsoft, Amazon and Facebook. Some people may disagree with me, but I would argue that Google has not abused its monopoly nearly as much as Microsoft did back in the day (like for example hustling PC vendors to only accept MS Office Suite or withdraw Windows from their machines), and their monopoly has been earned by genuinely being the very best at what they do, which is architecture of scale and search, rather than by locking you down in their ecosystem. Some of this disdain comes from Google’s attitude towards users and that’s something I can agree that Google can do better, but I wouldn’t say that by choosing AWS you are being more ethical than by choosing Google at all. Google’s approach is to create products that are so well engineered that they don’t need as much support, and in many ways I prefer this approach to having a nice sales rep buddy who is friendly but I need to contact all the time with issues. But this AWS complexity is creating so many jobs for us! Yes, and it does sound like I am shooting myself on the foot by posting this because this is my job. AWS definitely creates a lot more jobs for DevOps, SRE, Sysadmin, Platform Engineers etc. than GCP due to this extra complexity and the lack of desire for the developers themselves wanting to tackle this complexity. But personally I am not afraid of learning new things, I embrace it and I enjoy it, especially if those new technologies are well designed and simple. So I am okay making this transition. So will GCP ever catchup to AWS on market share? It’s hard to tell. One thing that AWS has going for it is that it churns out products like churros, and while I don’t think this is necessarily that great of a thing, it does meet the needs of most businesses, even if fragmented and tedious to work with. Also migrating from one platform to another is such an onerous task that many companies will never bother to do so. That being said, the increasing market share and profits coming from GCP look promising and this ex-googler author of this article, seem very confident that GCP will eventually reign: My friends ask me if I think Google Cloud will catch up to its rivals. Not only do I think so — I’m positive five years down the road it will surpass them. Because today, Cloud is about helping other companies build software like Google does. All those great things about working at Google? Making them available to other companies — that’s the product market fit. While I am not so sure if I am as confident as he is that it will just take five years to get there. I believe that down the road people who chose to specialise in GCP today won’t regret it. Conclusion So I should always pick GCP then? No, you should pick whatever fits your needs. If you are a very small company or an independent developer you may even want to give these two a miss and go with DigitalOcean or Linode or some of the smaller companies which are even easier to use and will cover your most basic needs for less money. AWS is still my second choice as an enterprise cloud provider after GCP. I know there is also Azure, but being a little harsh here, I have a little PTSD from using and supporting Microsoft products in the past, my memories from growing up using windows are daily blue screens and continuous Outlook issues. I just feel that Microsoft has historically been very much focused on the sale, not the quality of the product, they have the capacity to do great things, but they only do them when competition pushes them to do it, and/or have someone to copy from and they stop putting an effort once they reach monopoly. This is a stark contrast from Google or Apple who are very driven by engineering finesse and product design first respectively, not purely sales. Of course, there are exceptions to this (I love VSCode) and some people swear that Microsoft has gotten much better over the years, but I still feel that this is only a consequence of pressure from the fierce and much better qualified competition, not because of a cultural pivot. Based on that, if I can help it, I will avoid using Azure, but I can also respect that some people may love it, so I’ll leave it up to them to write their thoughts on it. Okay then, GCP is perfect, let’s go for it! Nothing is perfect. You will surely come across things in GCP that you will hate, as I have in the past, but for most people the amount of headaches will be fewer and farther in between than with AWS, and that alone is a good reason to pick it. Additional Resources Google Cloud Platform - The Good, Bad, and Ugly (It's Mostly Good) Looking for a cloud hosted Maven repository when working with Google Cloud? Sign up for a free 14-day trial of Deps… www.deps.co Google Cloud for AWS Professionals This guide is designed to equip professionals who are familiar with Amazon Web Services (AWS) with the key concepts… cloud.google.com Google Cloud vs AWS in 2020 (Comparing the Giants) It's no surprise that cloud computing has literally taken the world by storm. For most businesses and enterprises, gone… kinsta.com https://kinsta.com/google-cloud-market-share/ aws vs gcp - The HFT Guy This story relates my experience at a typical web startup. We are running hundreds of instances on AWS, and we've been… thehftguy.com https://sada.com/blog/google-cloud/gcp-vs-aws-why-gcp-better-option-2019/ Sign up to discover human stories that deepen your understanding of the world. Free Distraction-free reading. No ads. Organize your knowledge with lists and highlights. Tell your story. Find your audience. Sign up for free Membership Access the best member-only stories. Support independent authors. Listen to audio narrations. Read offline. Join the Partner Program and earn for your writing. Try for $5/month Gcp AWS Google Cloud Platform DevOps 5.1K 78 Written by Fernando Villalba 953 Followers https://twitter.com/nandoyum Follow More from Fernando Villalba Fernando Villalba in Contino Engineering Platform Engineering: Creating your Internal Developer Platform (Part 2) In the first part of this article I gave an introduction to platform engineering and explained what an internal developer platform is. In… 14 min read · Sep 28, 2022 767 4 Fernando Villalba Docker-compose Tricks and Best Practices Maximize your usage of docker-compose for your environments 3 min read · Oct 17, 2018 160 1 Fernando Villalba in The Startup Design Principles and Practices for Terraform Some Terraform principles and practices I follow in order to make my work more likeable. 4 min read · Apr 29, 2020 218 Fernando Villalba UX on Platform Engineering Design an Internal Developer Platform that your users love using 20 min read · Jan 2 29 1 See all from Fernando Villalba Recommended from Medium Mahdi Mallaki in ITNEXT Replace Dockerfile with Buildpacks Exploring the Pros and Cons of Replacing Dockerfile with Buildpacks 6 min read · Oct 14 609 6 Dipan Saha Creating Professional AWS Architecture Diagrams: Tools and Techniques Amazon Web Services (AWS) offers a wide range of services that can be used to build robust and scalable applications. However, with the… 4 min read · Apr 26 221 Lists General Coding Knowledge 20 stories · 475 saves New_Reading_List 174 stories · 158 saves Natural Language Processing 743 stories · 334 saves Productivity 230 stories · 151 saves Matteo Bianchi 2023 DevOps is terrible. My analysis of modern DevOps evolution into Platform Engineering. Just a new trend or a revolution in the IT industry? 7 min read · Sep 21 1.7K 29 Cloudmize in AWS in Plain English Become a High-Paid Cloud Engineer: Your Ultimate Guide Unlock lucrative opportunities in the cloud computing industry 5 min read · Oct 14 612 5 Santiago González in AWS Tip Say goodbye to Terraform: infrastructure as code for humans with Pulumi Let it be clear, this is not another article to criticize the changes in Terraform’s licensing by HashiCorp. 4 min read · Oct 6 170 5 James Berger Say Goodbye to Visio: The Future of Diagram Design is Here! Meet Azure Analytics Architecture Advisor – the latest architect tool that is set to revolutionise your approach to system architecture… 5 min read · Jun 23 456 7 See more recommendations Help Status About Careers Blog Privacy Terms Text to speech Teams",
    "commentLink": "https://news.ycombinator.com/item?id=38016849",
    "commentBody": "I think GCP is better than AWS (2020)Hacker NewspastloginI think GCP is better than AWS (2020) (nandovillalba.medium.com) 209 points by hui-zheng 15 hours ago| hidepastfavorite336 comments Ameo 13 hours agoMy two cents, GCP has a few excellent gems which are better than pretty much any competing cloud offering:- Cloud Run. Best way to deploy containers hands down. All of the benefits of a serverless&#x2F;containerized workload with all the ease of a traditional VPS deployment. Extremely cheap (pay $0 for side projects with little traffic).- BigQuery. Very easy to use with immense power without having to deal with the details yourself. Billing can be either extremely cheap or rather expensive depending on what you&#x27;re doing, though.- GCS Archive Storage. 1&#x2F;3 the cost of glacier for storage ($0.0012&#x2F;GB&#x2F;Month lol), but more for retrieval. Has none of the annoyances of Glacier (you can download your files instantly, upload using normal APIs). Perfect for extremely cheap backups.- Cloud Spanner. I&#x27;ve not had a reason to use this yet myself, but there really aren&#x27;t any comparable offerings that I know of. reply gigatexal 7 minutes agoparentAs a consultant (side gig) I have to use both based on what the company that I’m assigned to is using.AWS S3 and GCP GCS are basically the same in my head.Where things fall apart are actually the cost estimator. GCP’s is far simpler. AWS’s makes me wish I had Corey Quinn on speed dial.Redshift is far too complicated and has too many knobs. Give me BigQuery all day long even with its quirks. reply JSavageOne 13 hours agoparentprevYes Google Cloud Run is my go-to for all my side projects, and AWS doesn&#x27;t have anything equivalent. Never saw any reason to use AWS for that reason as Google has everything else I&#x27;d need. And if I just want a cheap VPS, would prefer to use something cheaper like Linode or Digital Ocean. reply Beijinger 2 hours agorootparentIs google so cheap?I am a small fish in the big sea but I use this for my personal projects:https:&#x2F;&#x2F;www.nearlyfreespeech.net&#x2F; reply dewey 18 minutes agorootparentAs always it depends what you need. If you think you might need a database that&#x27;s not MySQL and maybe a bucket to host your images and static assets then nearlyfreespeech is already not a good match any more if you prefer to have everything in one place.For small projects or Wordpress installations you can of course find a lot of very cheap or even free options as it&#x27;s such a commodity by now. reply neurostimulant 1 hour agorootparentprevGCP and AWS are cheap for small and low traffics applications. But once your usage passes a certain point, you&#x27;ll quickly find out they&#x27;re more expensive than other vendors. The problem is, once you reached that point, you&#x27;re probably already locked yourself in by using their specific offerings not found anywhere else. Limiting yourself to plain vps&#x2F;containers&#x2F;k8s might help preventing lock in. reply siquick 11 hours agorootparentprevIn my experience of using both, AWS AppRunner is as good as Cloud Run except you can’t scale AppRunner down to 0 instances so it has an ongoing cost. reply pid-1 11 hours agorootparentIt basically doesn&#x27;t have the main thing that makes Cloud Run so valuable.Speaking more generally, it seems AWS is allergic to creating products that scale to zero nowadays. reply ramraj07 41 minutes agorootparentScaling down to zero appeals to amateur side project folks - no enterprise customer probably cares about that marginal expense here.. reply starfallg 5 minutes agorootparentIt really depends on which workloads. We have teams working only on FinOps to optimize our architecture to take advantage of various cloud pricing models.Enterprise spend on cloud is a massive topic right now and definitely in the spotlight. A consensus is developing that the current implementation of public cloud promotes lock-in and overall much more expensive at scale.Cloud is complex and engineers are expensive. Instead of throwing CPU cycles and disk at the problem (which is cheap compared to engineer time), we are nickel-and-dimeing everything, and changing our architectures to hack the cloud pricing models. It&#x27;s pretty silly. leptons 40 minutes agorootparentprevI&#x27;ve paid $0.00 for my many AWS Lambda functions, and will always pay $0 so long as I keep it under 1 million executions per month (and AWS keeps this free tier going). I also use SimpleDB, SES, and other services that also cost $0.00&#x2F;mo. The only thing I pay for is S3, which totals about $0.30 per month, for a few gigs of data. And I&#x27;m very happy with AWS, It&#x27;s been costing me less than $6 per year to build out and run a complex web app, albeit with no users. But still, AWS absolutely does scale down to zero very nicely. reply slrainka 7 hours agorootparentprevApp Runner is an abstraction on top of FarGate designed to compete with Cloud Run, which is why it doesn’t scale down to zero. I too haven’t found anything that beats the simplicity of a GCP deployment sigh.. reply badrequest 6 hours agorootparentIf it doesn&#x27;t scale down to zero, then it doesn&#x27;t compete with Cloud Run. reply fomine3 3 hours agorootparentIt depends on use case. Some corps don&#x27;t care about down to zero. reply aenis 1 hour agorootparentIn fact, I was waiting for years for them to add a min instances option. But otherwise, agree, been running large and small production workloads since it launched and its been great. replylatchkey 13 hours agoparentprevCloud Functions, Cloud Tasks and Cloud SQL Postgres are fantastic too. Very low cost that scales with you and essentially zero lockin. reply sz4kerto 3 hours agorootparentCloud Postgres had some issues last year though -- when some UK datacenters stopped because of HVAC failure then HA PSQL instances got stuck during failover and there was no manual way of resolving this .https:&#x2F;&#x2F;status.cloud.google.com&#x2F;incidents&#x2F;fmEL9i2fArADKawkZA...\"Customers experienced downtime on Tuesday, 19 July 2022 starting at 09:25 US&#x2F;Pacific. 36% of zonal (non-HA) instances in europe-west2-a were affected. Additionally, 31% of regional (HA) instances whose primaries were located in europe-west2-a experienced extended downtime because they were unable to successfully fail over to another zone. Finally, customers experienced some failures during the incident for backup, instance creation, update, delete, restart, export, and Database Migration Service operations. The total impact duration was 17 hours, 30 minutes.\"(This hit us hard.) reply n_e 3 hours agorootparentprev> Cloud SQL PostgresAlthough it works and is solid, I wouldn’t say it’s fantastic. My impression is that Google makes limited investment in it to steer customers towards their own services such as Cloud Spanner.- Major versions are 6 months late - Small instances are horribly slow - Integration with other services is poor (e.g. the Cloud Run integration doesn’t work with a database private IP, so you have to fallback to configuring a VPC and connecting the standard way) - IAM authentication, although great when it works, is complicated and poorly documented - The UI has very few features, for example it isn’t possible to query the database from it - Although I’ve never seen any provider have it, automatic upgrades between major versions would have been nice. reply r3trohack3r 11 hours agorootparentprevHas Cloud Functions solved their logging issues yet?Last I checked, the lifetime of the function was bound to the lifetime of the request. So you have to fully flush your logs to their log ingress service before you respond to a request, otherwise GCP will suspend the function and eat your logs.Originally, this resulted in me having - to my surprise - very few logs coming from my functions.Once I discovered what was going on, it resulted in me having to increase the latency of responding to the request while I waited for logging to flush to GCP&#x27;s log ingress service. reply inlined 7 hours agorootparentAre you using a log service directly, or stdout? Stdout has no such issue. On Run (and therefore functions 2nd gen) you get a SIGINT before the container is shut down. Open Telemetry is pretty easy to configure to flush on SIGINT in the background. reply heyoni 3 hours agorootparentMy guess would be that their app isn’t running with PID 1. This can happen when services are launched from an entrypoint script in docker without using exec. If the request is fulfilled and the system sends a sigint to the container, docker will relay that to whatever is running on pid 1. If that’s their app, it’ll flush logs and quit. If their app is using another pid, docker will kill the container by force. reply latchkey 11 hours agorootparentprevI built a service with a few functions (golang based) that ran just fine for over a year with no log flushing issues.I did actually have an issue where it was logging two blank lines, which was annoying. It definitely wasn&#x27;t coming from my code and it got fixed at one point, then reappeared later on. I gave up trying to resolve it.That said, their logging system is fantastic. I found it really easy to deal with. reply derefr 9 hours agoparentprev> GCS Archive StorageHave you considered Backblaze B2? (It has free egress!)I think GCS is pretty good as a coherent offering that includes the various storage tiers + auto-classing + lifecycle notifications to pub&#x2F;sub to feed Cloud Dataflow, etc. But if you&#x27;re storing data purely for retention or disaster recovery, you should consider a service architected as a backup provider that happens to present an object-store abstraction, rather than an object-storage provider that happens to support your backup software — often you&#x27;ll find very different that the provider themselves have made very different CapEx trade-offs, resulting in very different pricing models, that can favor your use-case heavily.(I say this as someone who uses GCP for elastic load, but has non-IaaS bare-metal for base load; and where the DB instances living on that bare metal do their pgbackrest backups + WAL streaming against a B2 bucket.)But, of course, if your data-to-be-archived is originating in GCP, it may well cost you more to send it over an external provider like Backblaze, than it costs to just keep it in GCS. That is, as they say, \"where they get ya.\" reply ramoz 15 minutes agoparentprevAsset Inventory is slept on. reply jillesvangurp 3 hours agoparentprevWe used cloud run for a while and it&#x27;s great. It does not allow for background threads though and that caused us to upgrade the setup eventually.Upgrading from cloud run to use proper vms was very easy because vms can be booted with a docker container as one of the arguments. It will just go off and run that with a default OS. Running docker containers in gcloud is super easy.And scaling that is easy too. Basically you define an instance template that defines vm details; including the docker container url. And then you update your instance group with that template and all the instances are replaced one by one. You use the instance group as a service for your load balancer and with the right health checks configured this basically gives you zero down time deployments, auto scaling, etc. If there&#x27;s an issue starting the container, it just aborts the restart and continues running the old containers.The closest thing in AWS would be ECS but it&#x27;s a lot more hassle to setup.One great feature in gcloud is \"copy this screen&#x2F;dialog&#x2F;whatever as a gcloud command\". That made scripting the above super easy. We use github actions for all this. For each service, we use 1 command to update the template and 1 command to deploy it. reply QasimK 2 hours agorootparentI’ve used Cloud Run and it does allow for background threads. reply anisov 2 hours agorootparentI think they introduced this feature lately: https:&#x2F;&#x2F;cloud.google.com&#x2F;run&#x2F;docs&#x2F;configuring&#x2F;cpu-allocationyou can set --no-cpu-throttling which keeps the cpu allocated even if the request lifetime is over. Used it for Background tasks reply datadrivenangel 9 hours agoparentprevBigQuery is very pleasant. It just works serverlessly.Apparently some of the key people behind BQ are now working on MotherDuck, which is a cloud data warehouse version of DuckDB. reply ramraj07 40 minutes agorootparentI’ll have to try this just for the name! reply Beijinger 2 hours agoparentprev$0.0012&#x2F;GB&#x2F;MonthThat is interesting. How to you access this API? Can you do SFTP?This has about the same pricing:https:&#x2F;&#x2F;www.opendrive.com&#x2F;pricing(Yes, it says unlimited, but they told me, they significantly slow it down after 10 TB) reply aravindajju 5 hours agoparentprevCloud Run is the only reason to use GCP for me. I haven&#x27;t seen any product&#x2F;service that simple to use. It even offers mapping domain names. All my projects run on Cloud Run. reply code_runner 11 hours agoparentprevbigquery is a joy to use! I really don&#x27;t hate the editor in the browser either. reply gnarlouse 11 hours agoparentprevHonestly Cloud Run is so well designed, it really puts AWS Lambda & Fargate to shame. reply pyrophane 11 hours agoprevWe use GCP at my current company and I&#x27;ve used AWS a lot in the past.Managing IAM users and roles on GCP is much more pleasant than AWS, and if you happen to use Google Workspace for you org, it approaches (as an infra engineer) the sublime.GCP projects are a really intuitive way to isolate resources that you don&#x27;t want to be able to talk to each other by default.GKE has been very reliable.BigQuery got expensive faster than I was expecting, but it works and integrates well with GCP IAM and makes managing access to datasets easy.On the less positive side, support is lackluster, and GA doesn&#x27;t necessarily mean what you want it to mean.Edit: Almost forgot! Again, if you use Google Workspace, then IAP is fantastic. reply ramoz 14 minutes agoparentIAM &#x2F; Asset Inventory was always very useful as well. reply lantry 9 hours agoparentprevThis matches my experience. Google workspace + GCP IAM almost makes it a joy to manage permissions reply te_chris 1 hour agoparentprevI miss the glory days a few years ago when getting someone on the phone across your org as $400. From what I&#x27;ve read the Oracle boys flooded in and \"sorted\" that \"problem\"... reply mitaphane 5 hours agoprevI think YRMV depending on what you&#x27;re trying to do, but I think the DX & web console experience is much more pleasant on GCP.On GCP, their services are cleanly organized and have distinct icons that tell me what it does with minimal reading. On AWS, often I&#x27;m left scratching my head (see https:&#x2F;&#x2F;awsiconquiz.com&#x2F;)The web console design on AWS is catching up (for a long time the UI just looked like an offshoot of the e-commerce site design and wasn&#x27;t very clean) to GCP, but occasionally you still find elements of the old AWS console design.Often, it seems like AWS has more leaky abstractions that require you to be more aware of all the other connecting components of their infra services.For example, trying running managed Airflow on AWS&#x2F;GCP. Both services require some VPC & storage infra setup to get your Airflow container services running. On GCP, you can spin up Cloud Composer without specifying your VPC or storage bucket details and they&#x27;ll default them for you.AWS however, you&#x27;ll need to have your VPC&#x2F;S3 already setup ahead and if you&#x27;ve not configured your private&#x2F;public subnets or S3 IAM policy, you can put your Airflow environment into a non-workable state.Overall, I think GCP has some advantages of not being saddled with legacy baggage that AWS has with making sure their services are interoperable. reply s-xyz 14 hours agoprevI share the same experience and opinion. I cannot imagine what a significant argument would be to use AWS instead of GCP that outweighs the benefits and the seemingly integrated services. GCP has so far covered 99% of my use cases, and I can testify that I have a lot of advanced cases linked to data management, information security, networking and more. I am open and do not judge AWS, and perhaps its also a matter of what you are used to. However my style and approach to problems is more in alignment with GCP. I am for example of the opinion that the cloud provider should take care of everything linked to infrastructure, maintenance and as well scaling. And all of that should be as simple as possible. There is no need to overcomplicate. In this way I can focus on what makes my product unique, rather than spending my time on over-engineering repetitive features with zero value added. reply nerdjon 13 hours agoparentFor a fairly simple setup AWS automates a lot of things. If I just want an EC2 instance and a database, the VPC already exists and there is now even a button on an RDS that says something like \"connect to ec2\" which sets up the security groups on both for you.However the argument against using GCP has already been stated in this thread multiple times.- Will it exist in 3-5 years. Google has a reputation for a reason.- Will the cost increase in the next year. Google (including google cloud) has a reputation for a reason.- Here we have seen time and time again problems reaching support with Google Cloud.Meanwhile my personal AWS account that I spend maybe $5 a month on... I emailed support about a billing problem and got a response about a day later.I would not risk my job by using Google Cloud and being at the whims of Google being Google. The last thing I want is to have to go to my leadership and explain why the cost is going up or why suddenly we need to spend a bunch of engineering effort because google is discontinuing something.If I really didn&#x27;t want to support AWS&#x2F;Amazon (which is fair) I would go Azure long before going GCloud. Hell I might be convinced to go IBM but thankfully I don&#x27;t have to make that decision with Azure. reply kstrauser 13 hours agorootparentNailed it. When we&#x27;ve had problems with AWS, I could drop our rep an email and be on a conference call with the engineers who run the service a day later. That not for a giant account, either.They&#x27;d also periodically reach out to offer free consulting services that would cut our monthly bill. They were upfront about the motivation: they wanted us to integrate more of their services. The upside for us was that we could get better, cheaper service. If you&#x27;re planning on sticking with them anyway, that&#x27;s a very attractive offer.Meanwhile, the support venue for our enterprise Google Workspace account was a mutual support web forum as far as I could tell.Unless you&#x27;ve experienced both, it&#x27;s hard to believe how radically differently the 2 companies handle customer support. reply cassianoleal 11 hours agorootparentInteresting.A previous client was all-in on GCP. They were not a huge operation and in fact were slowly migrating on-prem stuff to it. GCP support was pretty good. The account manager was always on point and whenever we needed we could have an actual engineer or two on a call with us to troubleshoot stuff and give us advice and general support.Of course, for less urgent and less severe issues it would generally be done over the course of a couple days to a week in support ticket messages &#x2F; email but that was perfectly fine.I&#x27;ve been back to using AWS for a little while now and I miss how much simpler it is to set up things in GCP. Even IAM which I remember bitching about so much during those days, now I just miss how much simpler it was and I didn&#x27;t realise.Also if you need Kubernetes, no other offering compares to GKE. reply jsnell 13 hours agorootparentprevThe argument being stated multiple times doesn&#x27;t mean it is valid.Amazon, Microsoft and Google have all launched roughly as many products in the last couple of decades, and killed roughly as many of them unceremoniously after the products failed. (Amazon execs used to outright brag to the media about how many products they killed, since it showed that they were daring to take risks.)AWS, Azure and GCP have also all launched roughly the same product portfolios, and each of them killed basically none of those products. reply imwillofficial 11 hours agorootparentThis isn’t my experience.Amazon supports most stuff roughly forever. reply jsnell 10 hours agorootparentSure, sure. I totally get where you&#x27;re coming from.By the way, how&#x27;s the Fire Phone holding up for you these days? I assume it&#x27;s still working well and powerful enough to do your web searches on a9.com, and read sites like the Amapedia and DPReviews. Do you happen to know how many of the Alexa.com top500 sites it can browse, or do you need to ask on Amazon Askville? But I know it won&#x27;t be able to play Amazon&#x27;s hit game Crucible, that&#x27;s a PC game!If you need to play some tunes on your Amazon Tap speaker and don&#x27;t have them on the phone, all your mp3s are right there on Amazon Music Storage, just where you left them with the Amazon Music Importer to be played with the Amazon Cloud Player. And the files are safely backed up on Amazon Drive just in case! It&#x27;s the same thing with all the digital movies you bought on Amazon Unbox, they&#x27;ll just be waiting in the cloud for you to download them. (Watching DVDs rented from LoveFilm is just so yesterday.) [0]And let&#x27;s not forget Amazon&#x27;s initial core competency of retail!Just use your Dash Button to order some more books from Book Depository, it&#x27;d be a bother to have to go to one of the physical Amazon Books stores. It&#x27;s just crazy how much stuff you can buy online these days! Shoes from endless.com, food delivered straight to your doorstep by Amazon Restaurants, concert tickets from Amazon Tickets, flash fashion from MyHabit.com, hotel bookings from Amazon Destinations, and all kinds of daily necessities for the family from places like diapers.com and soap.com. And don&#x27;t worry, if you&#x27;re bored of these normal online stores (like those set up with Amazon Webstore) and want a different experience, there&#x27;s always Amazon Spark or Amazon Light for fresh takes on shopping! And for the really rare stuff, there&#x27;s a good chance that there&#x27;s some listings on Amazon Auction. Really, the only time I have to deal with local businesses is when I get one of those amazing group deals from Amazon Local (the code for that can surely be stored in Amazon Wallet).I wonder what the right way to pay in one of those local stores is though... Will they take Amazon WebPay, or will I need to have my credit card scanned by one of those Amazon Local Register payment terminals?But let&#x27;s not think that it&#x27;s all about consumption. I&#x27;m actually working on a screenplay myself, using Amazon Storywriter! Once I get it printed using BookSurge, it&#x27;ll look professional af. reply raffraffraff 3 hours agorootparentThose are almost (if not all) consumer facing products. I get it though - most of the complaints leveled at Google relate to their shutting down of consumer facing products. What&#x27;s Google&#x27;s track record for removing cloud infrastructure services? In the context of this thread, that comparison would be interesting. reply physicsguy 2 hours agorootparentThem offloading domain registration is pretty bizarre reply rossjudson 9 hours agorootparentprevPossibly the best comment I have read on this topic...like ever. Do Microsoft next! reply jnwatson 2 hours agorootparentThat would be a novel. reply ahepp 6 hours agorootparentprevI bet if you combine every single one of those products, they have less users than stadia reply progbits 3 hours agorootparentBook Depository alone was much more popular. reply gerash 4 hours agorootparentprevThis was eye opening reply badrequest 6 hours agorootparentprevI&#x27;ve been watching folks here on HN speculate that Google will kill GCP \"any minute now\" for at least the last 4 years, so ya&#x27;ll can keep holding your breath, I will be having fun deploying things for 1&#x2F;10th the price of AWS. reply acdha 12 hours agoparentprev> However my style and approach to problems is more in alignment with GCP. I am for example of the opinion that the cloud provider should take care of everything linked to infrastructure, maintenance and as well scaling.You get that on AWS, too. The difference in my experience has been that once you’re out of a narrow range of features you’re more likely to hit something which is builtin on AWS but has a GCP ticket from 5 years ago with no progress. If you have any kind of security compliance requirements that gets brutal on GCP since you have to take on running an entire service to get that one missing feature. reply marcinzm 10 hours agoparentprevGCP is overall a good product. Support is so atrocious and they break things often enough that it more than offsets that in any larger scale use case in my experience. reply zepolen 10 hours agoparentprevGCP support is a joke compared to AWS. reply pirsquare 9 hours agorootparentYep shutdown our production servers and take 1 whole week to get it resolved. Nothing fraudulent on our end. Just missing out on KYC form. reply HideousKojima 14 hours agoparentprev> cannot imagine what a significant argument would be to use AWS instead of GCP that outweighs the benefits and the seemingly integrated services.Confidence that it will continue to exist in the next 3-10 years? reply Eridrus 13 hours agorootparentWhat odds would you like to bet that GCP is going to be gone in 10 years? reply perelin 13 hours agorootparentThe sentiment is probably not abou GCP as a whole, but about its trigger happiness when it comes to deprecating services.Fun read:https:&#x2F;&#x2F;steve-yegge.medium.com&#x2F;dear-google-cloud-your-deprec... reply Eridrus 13 hours agorootparentI&#x27;m not going to read yegge&#x27;s rants.Name the odds and condition you think gcp will violate. reply judge2020 13 hours agorootparentprevIf they do want to kill it, I can see them giving as little as a 5 year window before everything is shut down.Odds? Nobody&#x27;s a fortune teller, but it was still being subsidized by ads with 3B loss in its FY22[0 p. 70], only increasing 100M in profit despite cloud revenue growing from 19B to 26B overall [0 p. 66]. They&#x27;re either going to need to increase costs or add more \"killer\" products with large margins if they want to become profitable.0: https:&#x2F;&#x2F;abc.xyz&#x2F;assets&#x2F;d4&#x2F;4f&#x2F;a48b94d548d0b2fdc029a95e8c63&#x2F;20... reply Eridrus 13 hours agorootparentAt what odds are you willing to make a bet on this? Do you think there&#x27;s a 20% chance it&#x27;s gone in 5 years? Do you think it&#x27;s 5%? Do you think it&#x27;s 30%?People keep saying things will be shut down and I think they should put their money where their mouth is. reply seanthemon 12 hours agorootparentWhat an oddly aggressive comment - perhaps the problem isn&#x27;t prediction but extrapolation of past experiences with Google, would you not agree that it gives you a sliver of worry that they may cut the service off?You seem very intense about Google&#x27;s offering, maybe you feel attacked by the points made in the thread, but the way you&#x27;re approaching this discussion is very strange. reply Eridrus 11 hours agorootparentI&#x27;m tired of reading the same thing over and over where people prognosticate based on poor readings of events and I think people should put there money where their mouth is.I really do not think the chance of GCP discontinuing a core service is high enough to warrant the level of comments this gets and if I find myself constantly reading these comments, maybe I can at least be compensated by people making bad bets or maybe people will admit the chance is really low.So if you are so worried about this, please give me a number that represents how worried you are about this. reply snoman 9 hours agorootparentNonzero is enough to choose an alternative. reply Eridrus 8 hours agorootparentLol, ok man, sounds like you&#x27;re real good at making rational choices. I&#x27;m sure there&#x27;s exactly zero chance AWS or Azure will ever have any problems. reply gkbrk 11 hours agorootparentprevEridrus used to work at Google. Not sure if it would be good to disclose before aggressively asking people to bet on the lifespan of Google products, I certainly would err on the side of disclosing. reply Eridrus 10 hours agorootparentSure, I used to work at Google, I used to work at Microsoft, some of my best friends worked at Amazon, I own stock in all of them.Are you interested in making a bet on the chance GCP will be discontinued? reply heyodai 11 hours agorootparentprevEven 5% is uncomfortably high if you&#x27;re planning to build your mission-critical infrastructure around it. reply Eridrus 11 hours agorootparentA 5% chance of needing to do a migration in 10 years is very small in comparison to other technical risks.And lets be clear, this is not a catastrophic risk; your contract with GCP guarantees they will not discontinue services without 12 months of notice so you will have time to do an orderly migration unless Alphabet itself goes under.I am a GCP user; I have found their offering (actually having GPU quota) significantly better than the other clouds and GCP shutting down does not keep me up at all. reply 878654Tom 7 hours agorootparent12 months notice is too short for big non-tech enterprises. They plan their infrastructure needs in 5-year terms. Changing to a new environment takes re-educating a lot of people, going through a lot of legal and audit meetings, finding enough manpower to do the transfer, putting things on hold purely for the migration,...12 months is the time for the contracts to settle between these enterprises and cloud-vendors. reply Eridrus 6 hours agorootparentIf your company is that big and unwieldy that a tiny chance of needing to do a migration in 12 months is unacceptable, you can stick to the key services which offer 36 months of notice. For all I know at that point you can negotiate your own guarantee if you&#x27;re so big.If you work at a company that can&#x27;t do a cloud infra migration in 36 months, I don&#x27;t have any good advice for you, but I doubt most commenters on here fall into that bucket. Frankly, I would expect companies that large to be in all the clouds so that you could negotiate them against each other, but I doubt that impacts many people here, and the chance of any of these worst case scenarios happening is vanishingly small. reply 878654Tom 1 hour agorootparentThis isn&#x27;t a tiny change, if GCloud says \"we quit in a year\". That is a huge change. Applications using GCloud SDK for services suddenly need to be reworked and redrawn. That alone is a huge change for non-tech companies.Some companies even need to check with the laws they reside in if the new cloud vendor can even be used.Just work in any financial, medical, pharmaceutical, government-related... company and you&#x27;ll understand that a year is nothing for these companies. replyRebelgecko 2 hours agorootparentprevIt&#x27;s already profitable (although the Q2 profits were apparently a few million below wall street&#x27;s expectation) reply HideousKojima 11 hours agorootparentprevIf it can&#x27;t get profitable (or at least within $1B&#x2F;year of profitable, or have some sort of major loss leader value to Google) then I&#x27;d give it 90% likelihood they they announce a shutdown within 10 years.Whether or not they&#x27;ll continue to lose billions a year for Google I can&#x27;t say. reply Eridrus 11 hours agorootparentIf you want to give me 10:1 odds GCP is not going to be around in 10 years, I will bet you any amount of money you are willing to name lol. reply elijaht 11 hours agorootparentprevCloud was profitable during the last quarter reply VirusNewbie 11 hours agorootparentprevThey had a net profit of 266M this quarter, so like, as of today they&#x27;re on track to go past 1B in profit. reply unethical_ban 11 hours agoparentprevI used to work in cloud security, mostly AWS but got to hear about experiences with GCP.AWS IAM is much better than GCP, or was 3 years ago. If you are in an industry where fine-tuned RBAC per service is a thing you want, it&#x27;s better to go AWS, all things equal.Also, GCP reps suck compared to AWS in terms of responsiveness and general give-a-shits. Hearsay. reply asmor 3 hours agorootparentYeah, no. GCP actually allows you to give developers full permissions on their project. This sort of separation doesn&#x27;t exist on AWS, at least not without making it very hard to impossible to share resources. So on AWS, you either have a really good platform team that handles permissions &#x2F; terraform review &#x2F; all infra setup (unlikely), a bad or understaffed team doing the same so everyone waits a week or two on specific things being set up (and everyone will hate them for killing their velocity), or you let everyone run wild with way too many permissions so they can actually use the console, hoping they&#x27;ll stick to best practices (they wouldn&#x27;t). At least developers doing unsafe things is contained in GCP.But all that aside, AWS is better. It&#x27;s much more predictable which things will work together from the documentation, the support is better and the IAM is better on paper, if you actually have that unicorn platform&#x2F;infrastructure team. reply unethical_ban 2 hours agorootparentWell, I was on a unicorn team, then. Guardrails on all AWS resources, developers deployed via gitlab&#x2F;terraform to AWS accounts mapped to departments.You can share resources across AWS accounts. I don&#x27;t know for easy that is on gcp, but it didn&#x27;t seem crazy on Amazon. reply 0xbadcafebee 7 hours agoprevI use both. GCP sucks, AWS rocks.GCP is theoretically superior because it has more features and integrations built in. But in practice it&#x27;s a big mess, and if you want to do anything the \"not GCP way\", you&#x27;re better off just not using it at all. People talk about GCP \"getting X right\", which might be true, except to actually use the thing that they \"got right\" you have to use everything else they have, and good luck figuring out how to do that with their insanely bad&#x2F;missing docs. Let&#x27;s not even get into how they overload the same concept in multiple places, have tons of arbitrary limitations of naming conventions for different components, navigating the console is a pain (and again arbitrarily limiting), and services are weirdly implemented so the SDK is inconsistent. They tried really hard to pretend they had some unified, Enterprise-ready, perfect system&#x2F;design, and of course failed at implementation, because perfect systems don&#x27;t exist. Their support is crap and their services are down a lot, and very slow to orchestrate.AWS is less feature-filled by default, but everything that is there works, isn&#x27;t complicated, can be used a-la-carte, and docs are easy to find. Support is insanely reliable. They take a one-useful-piece-at-a-time approach rather than making you use the kitchen sink, and it&#x27;s not hard to get things working (well, not any harder than for any other cloud provider). Pretty much everything they do is simpler and more reliable. reply negus 1 hour agoparentCan you be more specific? I experience no problems navigating the GCP Console UI. Though I mostly do not do it -- I have stuctured bookmarklets for everything I use and it works really great. And also I use gcloud and Terraform a lot.GCP support also provides the answers I need. reply bng5 1 hour agorootparentI have very little experience with GCP as not much of an infra person. However, for me the most annoying bit is how the profiler is using its welcome screen as a loading indicator as well as &#x27;there is no data&#x27; page. Makes it very hard to browse data. reply sovnade 8 hours agoprevTo everyone saying GCP will be gone - it generates over $8 billion in revenue per year and $400 million in profit. There&#x27;s no chance they kill it any time soon.Yes it posted heavy losses in the past, but any major infrastructure does, and obviously there is a major amount of potential - and they have around 10% of the total cloud market share, not insignificant by any means. reply hncommenter13 4 hours agoparentOne correction. It&#x27;s not $8B per year, it&#x27;s $8.4B in the last quarter--which is over $32B annualized, especially considering the last quarter&#x27;s revenue grew over 20% from the same time last year. GCP&#x27;s profit margins are low (for now) but positive. [1]Moreover, per its filings, Google had almost $65B of contracted backlog representing customer commitments for future purchases (over multiple years), primarily related to Google Cloud. That is not to say those can&#x27;t ever be unwound or delayed, but it&#x27;s a pretty meaningful amount, even to a company the size of Google. [2][1] https:&#x2F;&#x2F;www.sec.gov&#x2F;Archives&#x2F;edgar&#x2F;data&#x2F;1652044&#x2F;000165204423...[2] https:&#x2F;&#x2F;www.sec.gov&#x2F;Archives&#x2F;edgar&#x2F;data&#x2F;1652044&#x2F;000165204423...edit: formatting reply skadamat 14 hours agoprevMy biggest challenge with GCP is that I&#x27;m still not convinced Google cares that much about this division.They acquired Looker, fired the customer service staff, and then set it out to crumble. Looker used to be LOVED by its customers but now they were forced to make their semantic layer work with Tableau.Also, I&#x27;m still not convinced Google cares about divisions that aren&#x27;t linked to advertising. Google Search, Gmail (kinda), Maps, Android, and YouTube are their darlings.Will GCP be around in 5 years? I honestly am not sure. reply danielmarkbruce 13 hours agoparentI used to work in GCP. They are definitely committed to it. Search, Android, Google Cloud, YouTube - definitely committed.It&#x27;s the random little things they build too many of and hence close down. They never really understood branding. Slapping Google on everything doesn&#x27;t help, it hurts. Many things are actually experiments and shouldn&#x27;t be marketed as more than that. reply mvdtnz 11 hours agorootparent> They are definitely committed to it.Google on Stadia:October 2019 - \"It is a long term view that Google is taking\"November 2020 - \"roadmap of about 400 games in development right now from 200 developers [...] 2023 is really kind of where we’re aiming our sights\"February 2021 - \"building Stadia into a long-term, sustainable business [...] remain committed to Stadia as a platform\"September 2021 - \"gaming is an incredibly important vertical at Google\"November 2021 - \"eager to continue working on bringing the best games and new features to our community of players so that we can help build a bright future for cloud gaming\"February 2022 - \"we are still focused on bringing great games to Stadia in 2022 [...] more feature goodness coming to Stadia too - stuff we can’t talk about just yet\"September 2022 - \"You might have seen one last game arrive on Stadia today. It&#x27;s a humble :heart: thanks :heart: for playing from our team.\"https:&#x2F;&#x2F;www.theverge.com&#x2F;2022&#x2F;9&#x2F;30&#x2F;23378757&#x2F;google-stadia-co...Bonus comment from Google regarding Inbox:\"With respect to the upcoming Gmail announcement, there are no changes to Inbox by Gmail. It remains a great product for users with specific workflows and one in which we test innovative features for email.\" reply danielmarkbruce 10 hours agorootparentYup, hence the \"Many things are actually experiments and shouldn&#x27;t be marketed as more than that\" and&#x2F;or \"random little things\". reply mvdtnz 9 hours agorootparentGoogle very clearly stated in no uncertain terms that Stadia was a real product that they were committed to for the long term. Stating, after the fact, that it was \"actually\" an \"experiment\" or a \"random little thing\" is not just dismissive - it&#x27;s pure revisionist history. reply danielmarkbruce 9 hours agorootparentWhat folks at google think and what they say publicly aren&#x27;t the same thing. It&#x27;s naive to think otherwise. Look to what actually makes sense for them to do and you&#x27;ll have your answer.Internal folks knew google would walk away in a few years if it didn&#x27;t work. Stadia was largely a group of people out of the failed and left behind Daydream (VR) project. reply solatic 5 hours agorootparentSo why are we to believe statements that GCP is here to stay? They are, after all, statements to customers who need to hear it to make the purchase. But who knows how they actually think?The whole reason why Google cannot be trusted here is precisely because of their tendency to be inauthentic in their public statements. reply danielmarkbruce 5 hours agorootparentI wouldn&#x27;t believe anything they say. Just look at the numbers. They aren&#x27;t going to walk away from a business doing about $35 billion per year run rate, growing at 20%+. It isn&#x27;t in their interest to do so. reply jiggawatts 1 hour agorootparentUnless competition picks up and they have to cut prices and stop being profitable.And then they&#x27;ll turn it off as casually as you or I might turn off a garden tap. reply white_dragon88 6 hours agorootparentprev\"Internal folks\" who gives a rats ass about what they think? A company&#x27;s reputation has little to do with how people on the inside perceive it, its actions and track record do the talking.Stadia was a classic reason I couldn&#x27;t trust GCP or any Google product aside from Gmail cause I&#x27;ve been using it so long, because unlike you I&#x27;m NOT in the know, I just see a bunch of stuff spun out, hyped (calling it &#x27;little stuff&#x27; is a highly subjective assertion) and axed without warning. And I won&#x27;t mention what an absolute mess the android development journey has been, a related symptom of a haphazard, disorganized product strategy. These things are uniquely Google, and it&#x27;s a terrible look. reply danielmarkbruce 5 hours agorootparentAgree, nobody cares. But it was pointed out in response to a suggestion it&#x27;s revisionist to say it was an experiment. It was correct (ie it was an experiment), albeit not understood by people who believe at face value what companies say.I haven&#x27;t been in the know for years, but I learned enough - don&#x27;t look at what they say, look at where the money is. It&#x27;s the same for almost every company.Product strategy is a mess at most companies. The developer experience sucks for most products. Stripe built a multi-billion dollar business off of developer experience because the standard experience sucks so bad. reply timmytokyo 6 hours agorootparentprevSo we as customers need to read tea leaves in order to figure out which services Google considers \"real\" and which are \"experiments\"?No thanks. reply danielmarkbruce 5 hours agorootparentNo, read the financials.https:&#x2F;&#x2F;www.sec.gov&#x2F;Archives&#x2F;edgar&#x2F;data&#x2F;1652044&#x2F;000165204423...Look at page 12. reply simoncion 9 hours agorootparentprevYeah... Google employees just _do_ that sort of shitty redirection, and it&#x27;s obnoxious as fuck.Maybe it works in a \"We&#x27;re too polite to disrupt whatever political game you&#x27;re playing in the hopes that you&#x27;ll reciprocate when we splash obvious bullshit when we play ours.\" snakepit that seems to be most of Google, but out here, we&#x27;re unchained by that political nonsense.Bonus chatter: We get that you&#x27;d like die for your coworkers or whatever, but as people who have no social (or political) investment in either the services or how they&#x27;re made, these \"But they&#x27;re run by GOOD, PASSIONATE people! I have personal experience with this!\" appeals are simply irrelevant. reply LargeTomato 5 hours agorootparentYou were just able to articulate what I hated about Google. Thank you. reply danielmarkbruce 8 hours agorootparentprevThere is a reason contracts, contract law and the court system all exist.Most people and companies don&#x27;t do things which aren&#x27;t in their interest after stating they will. It isn&#x27;t a Google thing. reply mvdtnz 7 hours agorootparentNo one is saying Google has broken contracts or the law. What is it with you Google defenders and your constant goalpost shifting? We are saying, Google is not to be trusted with claims like \"we are committed to this product\" because they have been caught in that lie several times before. Why are you going on about contract law and \"most people and companies\"? What you&#x27;re saying is irrelevant. reply danielmarkbruce 7 hours agorootparentThe point is: don&#x27;t expect companies or people to act against their interests. They generally haven&#x27;t, don&#x27;t and won&#x27;t. Google isn&#x27;t unique here. The problem is so pervasive in society that humans created contracts and courts to force people&#x2F;companies to do things they wouldn&#x27;t otherwise do. replyAlupis 11 hours agorootparentprevIt&#x27;s not entirely a fair take, since nobody figured out how to make cloud gaming feasible. They have all given up, or are in the process of giving up. reply mvdtnz 11 hours agorootparentHuh? Microsoft and nVidia (and I think Sony? not sure) are continuing to run their cloud gaming services as we speak. reply Alupis 11 hours agorootparentThe market is tiny (relatively) for all of these players. Motley Fool estimates the entire cloud gaming industry is ~$2.5B in total revenue for 2023.Many of the current services are likely running at a loss, hoping for the hype-train to get people into it.The reality is, most people wanting to play AAA titles either have a console, or a gaming computer alreadyThe cross-section of people with a 10 year old macbook, that want to play the latest AAA title, have expensive high-bandwidth internet, and are willing to pay ~$30+ a month is just not that large. reply mvdtnz 11 hours agorootparentI&#x27;m sorry what does any of this have to do with Google&#x27;s lies with regards to their commitment to cloud gaming? All gaming platforms run at a loss in their early days.> The cross-section of people with a 10 year old macbook, that want to play the latest AAA title, have expensive high-bandwidth internet, and are willing to pay ~$30+ a month is just not that large.This is frankly an idiotic summary of what you believe to be the cloud gaming addressable market. reply Alupis 10 hours agorootparent> I&#x27;m sorry what does any of this have to do with Google&#x27;s liesGoogle is not a charity. If something is not working out financially, or the market has failed to grow at the pace Google initially thought, it is in their best interest to exit that market and re-allocate resources. You know... like any rational business.> This is frankly an idiotic summaryWell then perhaps you can enlighten us on why the market has failed to materialize? $2.5B for 4+ industry-heavyweights to fight over is pathetically small.The R&D costs alone to deliver this type of service likely outweigh several years of total industry revenue... yet each of these companies is trying to blaze their own path more-or-less independently.In short, there is no addressable market, and the numbers clearly tell us that. Do not be surprised when more of the players exit this market as well.Just because you love a service doesn&#x27;t make it a reasonable or sustainable offering. reply mvdtnz 7 hours agorootparent> If something is not working out financially, or the market has failed to grow at the pace Google initially thought, it is in their best interest to exit that market and re-allocate resources.Correct, Google can&#x27;t be trusted to commit to a product long-term. Even a product with paying customers.> Well then perhaps you can enlighten us on why the market has failed to materialize?Because like I said, it&#x27;s a young market. It has absolutely enormous upsides for those that can win it.> there is no addressable marketThis is laughable. You&#x27;re a clown.> Just because you love a serviceNone of the cloud gaming vendors have ever even offered the service in my country. I have no dog in this hunt. replymattferderer 8 hours agorootparentprevDidn&#x27;t Microsoft just spend a year in court with their top VPs & CEO fighting against the UK & US governments over cloud gaming so that they could buy Activision for roughly $70 billion?I believe they had to make concessions with the UK to somewhat outsource the cloud gaming aspect of the deal so that it could go through. This was something they didn&#x27;t seem to want to do but also forced them to extend their merger & pay additional dividends to shareholders of Activision. reply notyourwork 7 hours agorootparentprevIt is 100% fair because it supports a trend. Amazon didn’t have to continue support for a myriad of AWS products yet still do and maintain backwards compatibility. reply idunno246 12 hours agorootparentprevi dont doubt gcp will continue existing. but individual services&#x2F;products&#x2F;apis&#x2F;pricing break way too frequently, and the response from google is deal with it. small companies dont really notice it, and how anti-customer it is, but when once a month youre dealing with some firefight because gcp decided to change something its tiring, since at a big company it means tracking down ten different teams. ive not experienced anywhere near the churn in aws reply danielmarkbruce 11 hours agorootparentYep, it&#x27;s a fair criticism. reply latchkey 12 hours agoparentprev> Will GCP be around in 5 years? I honestly am not sure.AppEngine is going on, checks notes, 15 years now. reply fhoffa 11 hours agorootparentAppEngine today is wildly different to the App Engine I fell in love with 15 years ago.Since you&#x27;re checking notes, please check out all the AE service deprecation notes.Disclosure: I worked for Google for ~10 years, and I fought internally many of those deprecation decisions. I did not succeed. reply dekhn 9 hours agorootparentGoogle making AppEngine in the first place always felt weird to me. It was great for some web developers, but outside that use case, really not so much. But it came with a great collection of side technologies, which got unbundled (Datastore, etc) because there were folks (like me) who wanted to use the side tech but not AE itself (for many, many years you couldn&#x27;t \"import numpy\" but people would still say \"see? We have a cloud, it&#x27;s called AppEngine\").Once enough things were unbundled from AE, and containers became popular, it wasn&#x27;t really clear what AE provided that wasn&#x27;t better solved by more standard tech.Often times, Google leadership simply didn&#x27;t understand what its own engineers and product managers knew. People told me for years \"we can&#x27;t do cloud because the profit margins are too small\", and now look: Google is a perenially third-place in Cloud but has committed itself so much they can&#x27;t even shut it down if they want to. reply latchkey 8 hours agorootparentNo, we all just migrated the decision of using GAE to using Cloud Functions &#x2F; Run &#x2F; Tasks, which is fine. Those are easier for Google to scale over time, than AppEngine.The problem with AppEngine was that they had to heavily modify the runtimes for isolation... the JVM needed to be secured and that meant maintaining a separate fork, which also meant being perpetually always behind in versions. It also meant any upgrade had to go through a huge security evaluation.So, moving to another process model, containers, worked much better. reply latchkey 11 hours agorootparentprev> AppEngine today is wildly different to the App Engine I fell in love with 15 years ago.I see that as a good thing, it means they are still working on it. reply fhoffa 10 hours agorootparentHave you actually been using it for 15 years?My guess is not, or you would have a different opinion. But that&#x27;s just a guess reply latchkey 9 hours agorootparentPoor comment and poor guess.My best friend Jeff started working on Objectify in 2009 after I convinced him to use GAE. I have built two businesses on it. One did $80m in revenue in the first year and I guarantee we couldn’t have done it without GAE.Now give me back my downvote please. reply fhoffa 8 hours agorootparentWait, you just said in a separate comment that you migrated away from App Engine.You also just said that you used it very effectively back when it was a different thing.I think we agree in many more ways than we disagree.Source: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38020604 reply latchkey 8 hours agorootparentUgh, now you&#x27;re making me explain myself due to your poor understanding of what I was saying and taking different comments in different threads out of context.\"We migrated\"... meaning that over time, everyone is migrating from the concept of using GAE as a first choice, to using things like Run&#x2F;Functions. Not that I actually physically took code for GAE and moved it to R&#x2F;F. For example, my last project, I choose to use GCF, instead of GAE. The reason I went straight to GCF is because it is effectively what GAE has morphed into today. This isn&#x27;t a slight on GAE at all. I&#x27;ve updated previous comment to hopefully clarify this for you.Again, I have used GCP extensively since about 2009. By the way, much of what you use today was a result of things I did back when I co-founded the Jakarta Apache project, open sourced Tomcat from Sun, brought Lucene under the umbrella, blah blah blah... I&#x27;ve been around the internet since 1991. reply fhoffa 8 hours agorootparentThis is awesome, thanks for all the background info. Now let me give you an example of App Engine deprecating stuff:- In 2012 App Engine deprecated the \"Conversion API\".- They notified this deprecation in August 2012, and they told users it would stop working only 3 months afterwards.- You were affected by this deprecation.- You created an alternative to it, that worked on Heroku.Source: https:&#x2F;&#x2F;groups.google.com&#x2F;g&#x2F;google-appengine&#x2F;c&#x2F;-JJccGx5RRk&#x2F;m...Did I get this right?You are awesome. We are just choosing to remember the past with different colored glasses. reply latchkey 7 hours agorootparentYea, they deprecated something. I even noted that the market is small for it in the thread. I built another solution in a short amount of time, and even gave it away because it really wasn&#x27;t something people were using a lot of. It was a super niche product. That also wasn&#x27;t even AppEngine, it was just a nice to have, for me, sub-service.There was a point where people were upset about GCP and Google changed their whole deprecation policies to be more vocal and longer term about things.I really don&#x27;t understand your point. What&#x27;s the big deal? reply fhoffa 7 hours agorootparentYou think we are disagreeing, meanwhile I just love how much I&#x27;ve learned (and confirmed) thanks to your replies. Thanks for sharing! replynathants 10 hours agorootparentprevbackwards compatibility is a big deal in infrastructure. when a serious provider has bold new ideas, you release appengine2. reply acdha 11 hours agorootparentprevA better question is whether it’ll have improved or had price increases. GCP has had a bunch of increases lately, and you never know what will be next so you always have to guess at whether you’ll regret locking yourself more to a proprietary service. reply latchkey 8 hours agorootparentA good friend just migrated off of GCS to R2. Hard to compete with what is essentially free. reply willsmith72 13 hours agoparentprevI generally prefer AWS except for the good experience I&#x27;ve had with cloud run, but GCP getting shut down is not something I would worry about. These cloud services are highly profitable reply alphalima 13 hours agoparentprevYes, especially around Looker. It&#x27;s so strange&#x2F;non-cloud. The 0-users 0-usage price is $5,000 per month. reply christkv 14 hours agoparentprevConsidering their earnings today being down in cloud I think I would rightfully worry about their long term commitment. reply resolutebat 13 hours agorootparentGCP revenue is up 28% YoY, and it went from a $440M quarterly loss in 2022 Q3 to a $266M profit 2023 Q3. Who&#x27;d shut down a business like that? reply x86x87 13 hours agorootparentLol. You&#x27;re new around here?Google has closed time after time things that were profitable and&#x2F;or loved by their customer. At this point I don&#x27;t see how anyone would be willing to bet the farm on anything Google reply h1fra 19 minutes agoprevI personally enjoy GCP much more because it&#x27;s easier. You can do almost everything from the UI and products are named the way you expect them to be named (except for a few exceptions).When you are doing devops on the side not as your main job, it&#x27;s really a game changer compared to the cryptic AWS UI. The only part lacking imo is the log&#x2F;monitoring which is definitely subpar, just logging proper json is a mess. reply donatj 2 hours agoprevWe still use AWS but it&#x27;s been a couple years since I&#x27;ve really needed to dig into it because we have very competent people who&#x27;se job that is now.My memories of having to find the right form, paste the right ID of the right server&#x2F;bucket&#x2F;lambda into are pretty traumatic. A TON of guesswork. Lot of what felt like duct taping things together.If you don&#x27;t have a full mental model of how everything works, they&#x27;re certainly not going to help you get one without reading documentation. Their documentation is for the most part top tier, but the UX makes it more important than it arguably should be.There&#x27;s a difference between not handholding and just being obtuse, and I feel like so much of AWS&#x27;s UI&#x2F;general design philosophy falls into the latter camp. reply te_chris 1 hour agoparentMost of that stuff is far better managed with Terraform or similar as you have a record of which values go where that&#x27;s mostly pretty easy to consume later. Using the console for anything beyond trivial admin is definitely an anti-pattern given how complicated the major cloud platforms are. reply craigmcnamara 14 hours agoprevI find the GCP documentation to be lacking compared to AWS. Specifically while using GCP with Terraform I hit more frustrating nonsense error messages with little to no google hits or undocumented behavior around IAM config compared to my experience doing similar things on AWS. reply div_zero 13 hours agoparentI&#x27;m a technical writing manager on GCP, and we are actively working on improving Terraform documentation. Thank you for bringing up two significant problems with using TF on GCP.If you are willing (and of course have the time), we would love to hear other issues you - or anyone else who reads this thread - are having with TF documentation on GCP as we try and make things better. reply rendaw 3 hours agorootparentRinse and repeat - someone complains about cloud provider, a cloud provider person shows up and makes a \"we want to hear more about your problems\" statement, people reply, they do nothing. How many times has this happened? I&#x27;m more disgusted by the farce than by the lack of action.Don&#x27;t you have feedback buttons on the docs? What happens to the feedback from those? Please prove you consider feedback before asking people for more of it. reply clutchdude 5 hours agorootparentprevThis is probably more a request at the compute team&#x2F;gke teams but...spot management.For example, managing a spot fleet in AWS via terraform is filled with features and levers I can pull. It&#x27;s easy to manage basic scale-out&#x2F;scale-in procedures and allows me to set thresholds.In GCP, as I understand it, I can only manage a node pool at a basic level.EDIT: Also, yell at the people who manage the python library.https:&#x2F;&#x2F;cloud.google.com&#x2F;python&#x2F;docs&#x2F;reference&#x2F;container&#x2F;lat...Generated samples suck - take a look at the boto3 docs and see if they tell you to go look at code generated samples. reply nknealk 6 hours agorootparentprevCan you please update the terraform docs for google batch? In [1] it’s really difficult to know what everything in the json configuration is under the base64encode() call. What levers can I pull? How do I run something more complex than hello world? Do I need my CICD to upload scripts to GCS and have the instance download them at runtime and hardcode that path into the batch script?[1] https:&#x2F;&#x2F;cloud.google.com&#x2F;batch&#x2F;docs&#x2F;create-run-job-using-ter... reply robmsmt 8 hours agorootparentprevI am about to go through this so happy to give feedback reply mdaniel 12 hours agorootparentprevGiven: https:&#x2F;&#x2F;registry.terraform.io&#x2F;providers&#x2F;hashicorp&#x2F;google&#x2F;5.3...how would any reasonable person know what https:&#x2F;&#x2F;registry.terraform.io&#x2F;providers&#x2F;hashicorp&#x2F;google&#x2F;5.3... to enable without (a) trying it and squinting at the error message (b) clicking on the API documentationthen realizing it, also, does not mention run.googleapis.com, click on \"supported service endpoints\"and only then learning about https:&#x2F;&#x2F;cloud.google.com&#x2F;run&#x2F;docs&#x2F;reference&#x2F;rest#service:-ru...Repeat for https:&#x2F;&#x2F;registry.terraform.io&#x2F;providers&#x2F;hashicorp&#x2F;google&#x2F;5.3... although in both cases I guess the astute reader may have spotted the run.googleapis.com in the forbidden service labels and cloudidentity.googleapis.com in the exampleSince, to the best of my knowledge those bindings are auto generated , I would hypothesize it is not insurmountable drop in the seemingly existing declaration of APIs required: https:&#x2F;&#x2F;github.com&#x2F;GoogleCloudPlatform&#x2F;magic-modules&#x2F;blob&#x2F;7d... https:&#x2F;&#x2F;github.com&#x2F;GoogleCloudPlatform&#x2F;magic-modules&#x2F;blob&#x2F;7d... reply gorjusborg 12 hours agoparentprevI had the same gripe when I worked with GCP. Their stuff is exotic, and had weird behaviors in corners, but the docs didn&#x27;t give you enough context to steer away from them.However, over the last 5 years or so, AWS docs have gotten worse.So I guess now that they are both bad I can&#x27;t complain? reply denvrede 2 hours agorootparentDid they? Do you have an example at hand? We ran into \"weird\" issues a lot of times with AWS services just to discover afterwards that almost all of them were covered by their documentation.It was totally our fault and these were also no \"hidden\" docs. reply slotrans 10 hours agoparentprevEvery GCP product is poorly documented.There are often no examples at all, and when there are they only cover the \"hello world\" case.Last I tried, the documented examples for Cloud Functions v2 simply did not work. reply shell0x 14 hours agoparentprev100%. My experience has been the same. The docs have their shortcomings and I ended up reading through so many Github issues and random blog posts trying to resolve the issues.From a documentation perspective, AWS is still the best. reply s-xyz 13 hours agorootparentWow I would literally say the opposite. I even use GCP docs as an example for my engineers on how to write proper docs, and did several workshops using the GCP docs as reference. Happy to share the presentation if interested. reply aaarrm 13 hours agoparentprevI&#x27;ve not used AWS but have been continuously curious if their docs are as scattered as GCP&#x27;s, this is good to finally know. reply adrr 13 hours agoparentprevGoogle&#x27;s support is the worst. Have an issue like those random nonsense error messages, good luck getting it resolved. AWS is complete the opposite. I had an issue Aurora Postgres and got to chat with the product manager of the product.Google could have the best products on the market but no one is going to use them if the support isn&#x27;t there.I was sad when Looker got bought by google. I remember having issues with setting up looker and using their chat functionality and having the CEO of Looker answer my question. reply latchkey 12 hours agorootparent> Google&#x27;s support is the worst.5 minutes later, the \"technical writing manager on GCP\", makes a helpful comment on this thread. reply mdaniel 12 hours agorootparentWell, AIUI \"reach the front page of HN\" was always the only cited way of getting any help with a Google problem, so in that way this is a derivative of that scenario reply mdhb 11 hours agorootparentAlso I never see this mentioned but just for anyone who isn’t clear…Google do actually offer great support, I pay like $30 a month for it and I can speak with real engineers who give super detailed answers.It’s just not free. But the paid offering is great in my experience. reply asmor 2 hours agorootparentI&#x27;ve used GCP support on accounts with huge support contracts and enterprise agreements and it&#x27;s still a bit of a wash if you get good support on your first, second or even third run around the reply button.At least it isn&#x27;t (paid) Azure Support - that one is noticeably outsourced to people that sometimes lack basic comprehension for the problem. I once asked about their VPN Gateway and got a random API Gateway response, then nothing for a week, and then a new rep. reply latchkey 11 hours agorootparentprevYea, that&#x27;s not true at all of GCP... you&#x27;re just propagating a myth. reply adrr 11 hours agorootparentWhy is GCP a distance 3rd with cloud providers? They used to be second. They literally will throw tens of thousands of dollars of free development to get you to switch. Amazon may give some service credits if you&#x27;re willing to switch an application over to them. EKS and GKE are on par with each other. So its not technology holding them back. reply latchkey 11 hours agorootparent> Why is GCP a distance 3rd with cloud providers?Honestly, it boggles my mind. Bad marketing seems to be the driving force here.“Nobody ever gets fired for buying IBM.”If you&#x27;ve actually spent time building on their platform though, it feels like you&#x27;re in some sort of inner circle of knowledge. The stuff works, and works really well. replyTNWin 11 hours agoprevWe unfortunately have three vendors (AWS, GCP, Azure) at my company because of acquisitions and the cost involved to consolidate.I am part of the central team that manages the provisioning users and accounts and billing.AWS is miles ahead of how we can express what we want in accounting.AWS reps are much much more knowledgeable and a pleasure to work with when it comes to billing. reply Jgrubb 22 minutes agoparentCould you elaborate on the accounting part? I&#x27;m deeply involved with billing on all three and while AWS seems to have all the data you&#x27;re looking for in the CUR, it can be a multi-quarter job to build up the expertise to understand that fact.GCP has different notions, like multiple credits applying to any given charge but again once you build up the expertise you can work with it. Azure seems by far the simplest to deal with and require the least wrangling. reply flowingfocus 50 minutes agoparentprevShameless plug: At the company I work for (meshcloud) we have developed a freely available model that describes the capabilities your central team is building up: https:&#x2F;&#x2F;cloudfoundation.org&#x2F;maturity-model&#x2F;Disclaimer: meshcloud sells a product for teams in that space reply notfried 14 hours agoprevI don&#x27;t buy the article&#x27;s argument around the \"Fear that GCP may be abandoned by Google\". Yes, it is highly unlikely that Google will wake-up one day and announce a deprecation day for GCP, like they did with dozens of other products. What is not unlikely though is that they under-invest in it compared to AWS, and being a 2nd or 3rd player, they would fall behind in products and&#x2F;or reliability, unable to compete on price or features due to better economies of scale of the competitors.Before Google kills products, they lose interest in them. reply splix 13 hours agoparentIt can create problems from a different angle, though. Google might lock your account for no reason for a week, without any explanation. If that happens, it&#x27;s your problem if you lose your whole business after a week of downtime. Since it&#x27;s Google, you can&#x27;t even contact support.This has happened to me a couple of times. Once, my account was locked for a day because their system flagged one of my servers for suspicious traffic. They locked all my servers, databases, and everything else, not just that one server. Another time, they locked a different project for a week. It actually took me a week to find a human who could unlock it; otherwise, it could have been even longer. I still don&#x27;t know the reason for the lock.So the main problem is that Google don&#x27;t care about GCP at all, and threat paid customers in same way as free users (i.e., hostile to both) reply apetresc 13 hours agorootparentGCP doesn&#x27;t really have the Google problem of lacking support contacts. I&#x27;ve managed relationships with GCP for a couple of different companies now (from startup to mid-size enterprise), and in all cases I had multiple dedicated account reps that I could not only get on a phone, but frequently met with in person.Maybe the story is different for very very small fish, but I had decent experiences with support even at the ~20-person company spending ~5k&#x2F;month level. reply gnfargbl 11 hours agorootparentMy company spends maybe $4k&#x2F;mo with GCP, and I have absolutely no idea who my \"dedicated account rep\" is. I did have someone contact me way back when, but after finding out we aren&#x27;t VC funded they literally ghosted me.I don&#x27;t really enjoy being on GCP for that reason, but I need it for BigQuery, so... reply splix 12 hours agorootparentprevAfter the last incident (with a week of downtime) I learned that they have a paid support, which you have to sign up in advance so it didn&#x27;t work for us at that moment.Now we signed up for it, though I still not sure how it works and how I supposed to contact them in case of an emergency. All I see they charge us something for that support agreement, hope I will never need it. reply vlastik 13 hours agorootparentprevMaybe it also depends on a country? In my country the AWS support is incomparable. reply vlastik 13 hours agorootparentprevThat&#x27;s exactly why would I newer support opting for GCP.With AWS, we have our account manager, whom I can call and he actually has some powers and can fix and do stuff for us. reply resolutebat 13 hours agorootparentSurprise surprise, paid GCP customers get the same. reply vlastik 13 hours agorootparentNot in my experience, unfortunately. The reps we got with GCP could give us advice, but no real powers to push stuff or solve problems, it felt more like L1 support. As described bellow, maybe it depends on a company size and&#x2F;or a country. reply dacryn 1 hour agorootparentour account manager definitely opened doors for us and got us in touch with experts that could solve our issues.150 sized company in a small EU country. We have a silver enterprise contract. replyesafak 14 hours agoparentprevNot going to happen; they kill consumer- not enterprise products. I searched https:&#x2F;&#x2F;killedbygoogle.com&#x2F; for \"Google Cloud\" and the only dead enterprise products that stood out were Google Cloud Messaging and Google Cloud Prediction API. But they replaced those with Firebase Cloud Messaging and the AI Platform Prediction API. reply slimsag 8 hours agorootparentAnd Enterprise Hangouts:> Workspace customers (the paid business version of Google apps) finally had Hangouts removed in March 2022And Google Domains..And Google Cloud IoT Core..And Google Go Links..And Google Maps Coordinate..... reply firebaze 14 hours agoparentprevIt&#x27;s not highly unlikely. Google has so much ad money at hand, anything else hardly matters. reply Shakahs 11 hours agoprevGCP has some nice things but AWS is simply more reliable.The GCP outage [1] in April is a great example. A fire in europe-west9-a \"zone\" took down the entire europe-west9 \"region\" (because this entire \"region\" is actually housed in a single datacenter), which then caused a global GCP console&#x2F;API outage because GCP&#x27;s single global control plane couldn&#x27;t reach europe-west9.The fact that a zonal issue escalated to a regional and then global outage shows that GCP is not serious about limiting blast radius and all their talk of independent regional&#x2F;zonal infrastructure is marketing fluff.In comparison, AWS AZs can be up to 60 miles apart, share no physical infrastructure, and every region hosts its own API&#x2F;console&#x2F;control plane.Also, Nitro. AWS has essentially eliminated the performance overhead of virtualization with Nitro, and years later GCP still has no equivalent so GCP customers still have to pay for that overhead.1: https:&#x2F;&#x2F;status.cloud.google.com&#x2F;incidents&#x2F;dS9ps52MUnxQfyDGPf... reply esprehn 8 hours agoparentThat Incident Report is phrased awkwardly.GCP does not have a single global control plane. Each product has a separate control plane, and many&#x2F;most of those are regional. GCE (Compute) does have a global control plane today.The GCP Console, unlike other cloud providers, displays an aggregated view over all the regions. That means calling the control plane for a particular service which then in turn will do fan-out to all regions and merge the results.For example a page might call the GCE global control plane:https:&#x2F;&#x2F;cloud.google.com&#x2F;compute&#x2F;docs&#x2F;reference&#x2F;rest&#x2F;v1&#x2F;inst...Or a different page might call this with - as the location to globally fan-out instead of talking to a particular region&#x27;s control plane:https:&#x2F;&#x2F;cloud.google.com&#x2F;functions&#x2F;docs&#x2F;reference&#x2F;rest&#x2F;v2&#x2F;pr...(Specifying the location would call that particular region though)During the incident the small (but critical) subset of Console pages which needed aggregated data from GCE&#x27;s global control plane failed to load.I agree it&#x27;s unacceptable that the Console doesn&#x27;t handle regional failures more gracefully, and it&#x27;s very much been a priority to improve region down handling.Source: I work on the GCP Console. reply rwiggins 4 hours agoparentprev> because this entire \"region\" is actually housed in a single datacenterFrom the incident report you linked:\"a cooling system water pipe leak occurred in one of the data centers in the europe-west9 region [...] Europe-west9 contains three buildings with independent cooling, power, and networking\"Also,> a global GCP console&#x2F;API outage because GCP&#x27;s single global control plane couldn&#x27;t reach europe-west9.again, from that page,\"A small number of methods within the GCE control plane API must collect information from multiple regions or zones by making requests to each regional control plane (called fanout requests). Google Cloud services including Cloud Console depend on these methods. When the GCE control plane for the europe-west9 region and zones went offline, some of these fanout methods did not operate correctly. During the outage, this led to global unavailability for some pages and control plane operations within Cloud Console\"It&#x27;s certainly not great that a regional problem had global impact, but there is some nuance. For example, that paragraph talks about \"each\" regional control plane, in addition to a global control plane.I don&#x27;t mean to belittle the importance of the incident. Suffice it to say lessons were learned and follow-up changes were made.As for Nitro - take a look at C3. https:&#x2F;&#x2F;cloud.google.com&#x2F;blog&#x2F;products&#x2F;compute&#x2F;introducing-c...Disclosure: I work on GCE. reply deadmutex 1 hour agoparentprev> Nitro. AWS has essentially eliminated the performance overhead of virtualization with Nitro, and years later GCP still has no equivalentFYI, per https:&#x2F;&#x2F;cloud.google.com&#x2F;blog&#x2F;products&#x2F;compute&#x2F;introducing-c...The Compute Engine C3 machine series, now available in Private Preview, is the first VM in the public cloud with the 4th Gen Intel Xeon Scalable processor and with Google’s custom Intel IPU. C3 machine instances use offload hardware for more predictable and efficient compute, high-performance storage, and a programmable packet processing capability for low latency and accelerated, secure networkingDisclosure: I work for GCP reply nathants 10 hours agoprevi’ve built bespoke automation at the api level for azure, gcp, and aws.using azure makes you want to watch the world burn.using gcp makes you want to give alcoholism a fair try.using aws makes you wonder why we can’t have nice things.ime those who prefer gcp tend to use a web interface. those who don’t have a preference tend to use iac. you want to work directly with the api, for innumerable reasons.aws is the canonical example of use boring tech. nobody cares which database you use, not even a little. if you’re talking about your stack choices, your product likely has negative value.of all the projects i pull into my rss reader, github commits on the aws-go-sdk-v1 are the most consistent and unsurprising. ive been following aws api and service changes since boto1.there’s a lot i wish was different about aws, but nothing that’s urgent.someday we’ll get better providers. it won’t be azure or gcp. it will be a new player.by 2030 i’d expect to see someone disrupting aws by offering api compatible clones of the core services without egress fees. r53, dynamo, ec2, ec2 spot, lambda, s3, apigateway, sqs. reply catlover76 7 hours agoparentI defer to your expertise, esp when it comes to actually using these different services at scale, but as someone who used to deploy only to Heroku and wanted to learn real cloud deployment, AWS was pretty unapproachable. I almost laughed out loud at how unnecessarily arcane and difficult they made things when all I wanted to do was set up a simple Python app on EC2.Google Cloud felt easier and intuitive to get started with, so that&#x27;s what I use now. reply nathants 4 hours agorootparenttoo much maybe? yelling at clouds just feels so good sometimes. apologies. i do actually wish we could have nice things.this is how aws became easy and fun for me[1]. a similar interface could exist for any provider.heroku is right about picking the good parts and exposing only that as an interface.1. https:&#x2F;&#x2F;github.com&#x2F;nathants&#x2F;libaws reply MrBuddyCasino 1 hour agorootparentThats sounds sweet. I suppose its just for when you really love lambdas (I don&#x27;t)? reply nathants 1 hour agorootparentconsider lambdas for managing ec2 spot instances, and other low volume tasks. replygrahamgooch 8 hours agoprevPerhaps from a technology standpoint (debateable).But from the perspective of a CEO, we want1. Talent hiring should be easy, so we can plan growth2. There should be a good self service support for developers3. Need good sales support in architecture and tech selection (when needed)4. Need to be able to get through to support engineer in 5 mins or less (we use aws premium support)5. Need single vendor (as much as possible).We consume a lot if what aws has to offer - we use their workspaces, mac cloud, device farm, code commit etcWe did a proper shoot out. While aws has its idiosyncrasies- it’s light years ahead of Google and MicrosoftPs. We use Gsuite (for the last decade) - teaching a live human used to a challenge - now it’s a major pain.If we find a better alternative to Gmail, Gdocs (etc). I’d switch in a heartbeat. reply theshrike79 14 hours agoprevWith even a medium level investment in AWS, I can get actual human people from Amazon on my company Slack on a channel and I can talk to them directly. I can get them to fly to our office to train people or workshop on how to use the resources more effectively.On GCP I get some AI bot that doesn&#x27;t answer anything and if I anger it by accident, my account and my business is gone. Then my only option is getting on the HN front page to get some help. reply pirsquare 9 hours agoprevGCP will shutdown your production servers and take one whole week to get it back. All for missing out on a KYC form.Our story: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=35133917Forget about the initial shutdown, how can you take 1 whole week to resolve something critical like this.Even if Google is offering me $1mil cloud credits today I wouldn&#x27;t risk my business with them anymore. reply negus 1 hour agoparentConfirm. I like GCP and I&#x27;m going to use it for the new projects as well, but the situation with their antifraud checks is really troublesome reply bloppe 8 hours agoprevA lot of people (understandably) complain about longevity of various Google products. One thing that&#x27;s nice about their overall cloud strategy is their focus on interoperability.As the incumbents, AWS and Azure strive for lock-in. As the relative upstart, GCP aims to grease the wheels of switching to their platform. To that end, they&#x27;ve pioneered technologies like Kubernetes and the golang CDK to enable people implement their services in a vendor-agnostic way so they can easily switch around. GCP encourages that, which is nice, especially in the worst cases. reply zoomzoom 13 hours agoprevMy view is that there are areas where GCP is better and areas where AWS is better. AWS has a much bigger community, and better business continuity story. GCP has a better developer experience and more uniquely-amazing best-in-class products (e.g. Spanner, Cloud Run, BigQuery). In the end, I don&#x27;t believe Google will shut down GCP.At Coherence (withcoherence.com) - I&#x27;m a cofounder - we deliver a developer platform that lets use use either cloud in a developer-friendly way. It also gives you some protection against lock-in to either cloud. reply pyrophane 10 hours agoprevOne fundamental difference between GCP and AWS is that AWS puts zones in different buildings in the same, well, \"region,\" whereas GCP just isolated them in the same building.Not the end of the world, but you shouldn&#x27;t assume that by deploying things regionally with GCP you will be protected against, idk, a fire or water issue that has building-wide impact. reply negus 1 hour agoparentWho told you that GCP AZs typically coexist in the same building? Can you provide the source of this information?If you open for example one site of us-central1 region ( 41.17425599375981, -95.80193009453644 ) you will see that just this one site has several buildings. reply dang 14 hours agoprevRelated:Many ways where GCP excels over AWS - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=23124350 - May 2020 (39 comments) reply PaulHoule 13 hours agoprevI did a shootout of a number of cloud visual recognition APIs. All of them took less then 20 minutes to have a demo running except for GCP which rudely required me to install special software to log in which trashed the Python installation on my machine and overall took an order of magnitude more time than all the others... No thanks. reply jeffbee 12 hours agoparentPython inside and outside of Google is a disaster. They broke their own API last year with a release of their own project.https:&#x2F;&#x2F;status.cloud.google.com&#x2F;incidents&#x2F;2uFuNdeK9xXSwY9w7c... reply thiht 3 hours agoprevAs much as I don’t like using a Google product, I have to admit GCP is wonderful. I really think GCP is the best UX Google has to offer. My favorite feature is that whatever you do on the web console, GCP will show you the equivalent gcloud CLI command. It can also give you the Terraform plan for some already created resources (maybe it’s even everywhere? Not sure)The configuration and naming of the services is also wayyy more sane than AWS overall, you actually know what they do from the name only most of the time. reply mdaniel 13 hours agoprevnon-slimey link: https:&#x2F;&#x2F;nandovillalba.scribe.rip&#x2F;why-i-think-gcp-is-better-t...and, as an AWS-er having to now support GCP, I violently and emphatically disagree with this:> The experience of GCP on the other hand is more like collecting the car keys and driving off from the parking lot, with the option of dismantling and customising the car if you wish, but the default is a fully built functioning car with cohesive parts so you can quickly achieve your objectives, which is driving around, not assemble the car.Oh, really? I invite the GCP newcomer to click on https:&#x2F;&#x2F;console.cloud.google.com&#x2F; create a new Project, and then run $(gcloud functions list) or, as the sibling comment pointed out, $(gcloud run jobs list) and watch it cheerfully tell you that you must turn on those services for each and every Project. And not just cloudfunctions.googleapis.com or run.googleapis.com, it&#x27;s for damn near everything a sane person would want to use cloud computing forI reiterate: you cannot turn on those APIs for your GCP \"account,\" you must do it for each and every Project you createOh, you&#x27;re the Super Admin for your Google account? Well, be sure you grant yourself the resourcemanager.projectCreator Role because as super admin you don&#x27;t automatically have itA reasonable person may retort that these are \"secure by design\" by opt-ing-in to surface area and permissions that one wishes to have, but as compared to \"create AWS Account, start using ELB like it ain&#x27;t no thing and I have AdministratorAccess granting me * permissions\" -- let&#x27;s not start talking about collecting car keys and driving off the lot reply eximius 11 hours agoprevWhile I never spent a lot of time in GCP, it seemed like it was harder to understand GCP itself as a platform compared to AWS.That is to say that Google APIs and services seem fine, but figuring out project management and infrastructure management feel incredibly weird. Not necessarily bad, but arcane and awkward where in AWS I can just hit the ground running.Arguably, debatably, GCP might have the \"more correct\" model with resources scoped to projects and such, but it does make the learning curve harder. reply mdaniel 10 hours agoparent> figuring out project management and infrastructure management feel incredibly weirdIt&#x27;s not just you, and the situation is worse than if they had no configuration management offering because, as Google is wont to do, they have several of them in various states of disrepair- they cite terraform as their go-to deployment solution in damn near every blog post, but if you&#x27;re trying to create something for (new usersdeployment into _someone else&#x27;s project_) the instructions start with \"well, open a Terminal and ...\"- they now have some kind of \"hosted terraform runner + state\" whose name escapes me but is hiding somewhere in this list of a bazillion similarly named Cloud Somethings https:&#x2F;&#x2F;cloud.google.com&#x2F;products?hl=en#section-14 (\"Infrastructure Manager\" is the one I was trying to think of https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37548639 and is, ha ha, not on that products page which is why I could not find it)- they started to have a CloudFormation replacement with Deployment Managerbut, again, I cannot stress enough how GODDAMN STUPID this is: one must enable deployment manager to use it, and the way one does that is via gcloud, click ops , or terraform -- then, ha ha, you went through all that trouble but you can&#x27;t create an IAM Role with itpartially because it&#x27;s not a supported resource type and partially because MUTATING ROLE BINDINGS IS A RACE-CONDITION EVENTAnd speaking of, there is, of course, no way to enable project services via Deployment Manager, so pound sand if your Project was not already carefully configured in advance of Deployment Manager- cloud shell tutorials, which is basically the union of all of those: https:&#x2F;&#x2F;cloud.google.com&#x2F;shell&#x2F;docs&#x2F;cloud-shell-tutorials&#x2F;ov... although in that case they do actually go out of their way to allow one to create a Project, with the activated service APIs, during the tutorial: https:&#x2F;&#x2F;cloud.google.com&#x2F;shell&#x2F;docs&#x2F;cloud-shell-tutorials&#x2F;di... reply bjord 9 hours agoprevTo me, GCP does seem easier to use, but I&#x27;ve recently had some instances where I had externally-hosted services (Zaps) make calls to my cloud functions there and inexplicably fail, with no logs whatsoever. While I was trying to figure out what went wrong, I found some other people online who said that their Google rep had mentioned \"service instability\" or something of the sort to them. Thinking that must&#x27;ve been the case, I went to reach out to GCP support (as nothing was mentioned on their outages page), only to find that it costs $30 &#x2F; month to get help with anything other than issues with billing (and their pricing page threatens to ban you from support access entirely if you are caught buying it and canceling it after use). reply ggm 4 hours agoprevAWS: there is a specific option to fix your specific problem, but it&#x27;s buried in a menu with 258 choices in CamelCaseButWhichOne?GCP: gcloud --butwhichone --orIsitThisOne --No-Dammit-Its-In-YAML=.&#x2F;yaml-file reply esafak 14 hours agoprevDoes anyone have recent experience with both? I&#x27;m in the market, for a startup, and I need to decide. My priorities are the data warehouse (BigQuery vs. Redshift) and ML (Vertex AI vs. SageMaker).This article is three years old. Vertex did not even exist then. reply opjjf 14 hours agoparentDon&#x27;t know enough about Vertex AI, SageMaker is great though. But on BigQuery v Redshift: Having used both over many years, BigQuery is the clear winner. It&#x27;s a much better, much more modern product.BigQuery is also a central part of GCP, with almost all services having integrations to it (PubSub, CloudSQL, Bigtable, etc). It also seems to get a lot of resources and is continuously improved. That is not the case for Redshift, which is not as important to AWS. reply MisterPea 14 hours agoparentprevI&#x27;ve worked in AWS before and also in a company that uses GCP.Funnily enough, I would recommend AWS over GCP in every single category except for the two that you mentioned.Although Snowflake is my choice for DW and it is cloud agnostic reply mardifoufs 11 hours agoparentprevChoose whoever gives you the biggest startup credits. The UX and UI experience is secondary to that imo, and the other technical differences aren&#x27;t something you will care about as a smaller startup. reply slotrans 10 hours agoparentprevI would choose Redshift over BigQuery but that&#x27;s because I know how to use it. Actual skill at databases is increasingly rare, so BigQuery wins this one for most. Watch your bill. reply js4ever 14 hours agoparentprevOne of the 2 never deprecate anything and ensure your workload will run untouched for 10y or more. The other one will force you every 6 months to update sdk, api endpoints or even kill a service you need in weeks. I let you guess who&#x27;s who reply bullen 3 hours agoprevThe only real reason is GCP has a central US region.How AWS is still stuck at the coasts is beyond me. reply Jgrubb 13 minutes agoparentUs East 2 is in Ohio. Not sure which GCP region is central US, they have VA and SC in the East.Edit: looks Iowa and Texas and Ohio as well for GCP reply ianpenney 8 hours agoprevTell me what your company’s existing IAM strategy is and I’ll tell you what cloud you should go all in on. reply raxxorraxor 1 minute agoparentWhat about the \"I am the admin of everything and I grant specific users admin rights until they stop nagging\"-strategy?Medium sized company with low fluctuation of engineers. reply kristianpaul 4 hours agoprevTheir kms offering is cheaper and that alway free tier for a small vm still helps. reply slantedview 5 hours agoprevIs there any good data comparing cloud provider uptimes? I know GCP had an outage recently that impacted me. reply kitallis 3 hours agoprevGCP allows editing memory and CPU on VMs, which is super handy. reply mixmastamyk 13 hours agoprevTechnology isn&#x27;t a weakness with Google... never was. Most of their stuff is top-notch technology-wise. The problems are from a business-angle and being their customer.Meaning, even if you&#x27;re a F500 company you are an insignificant gnat on the windshield of the gigantic G-machine that makes its money elsewhere.Now, I don&#x27;t believe think they&#x27;d actually shut GCP down. Cloud is just too damn strategic in a post Y2k world.Complain about Amazon if you wish, and there are many reasons to. They are not as tech-oriented and the task-master culture of Bezos is well-known by now. But at the very least they are sales and customer focused, and retail and cloud is where they make their money. So incentives are better aligned with them. Even if their customer service is not amazing, the fact that it actually exists is a large factor in their favor. reply ctvo 9 hours agoparent> Technology isn&#x27;t a weakness with Google... never was. Most of their stuff is top-notch technology-wise. The problems are from a business-angle and being their customer.There&#x27;s very little technologically impressive with GCP. It&#x27;s the same products from all three vendors with few exceptions.What&#x27;s a clear weakness with GCP is Google&#x27;s lack of seriousness as operators. Regions in the same data center, outages that take down a whole region for 3+ days. It&#x27;s not good. reply mixmastamyk 7 hours agorootparentI remember early on G was doing several second billing, while AWS was on minutes. There are other things like better performance, authoring K8s and http2&#x2F;3 etc that gave them the edge. AWS was earlier and had greater breadth of course. reply deanCommie 4 hours agoprev> GCP has done well integrating their different services together. GCP provides a smaller set of core primitives that are global and work well for lots of use cases. Pub&#x2F;Sub is probably the best example I have for this. GCP has Pub&#x2F;Sub. Pub&#x2F;Sub seems flexible enough to replace most (all?) of AWS’ various queues.I feel like if you&#x27;re going to spend this much time writing something in this much detail, the least you can do is try to understand some of the things you&#x27;re criticizing and not say things so wildly incorrect.> In AWS you have SQS, SNS, Amazon MQ, Kinesis Data Streams, Kinesis Data Firehose, DynamoDB Streams, and maybe another queueing service by the time you read this post.The most accurate criticism would be that Pub&#x2F;Sub combines AWS&#x27;s SQS and SNS. AWS had SQS first for 1-to-1 async queuing integrations. Then they added SNS for fan-out. GCP just started with fan-out from the start and said \"well if you don&#x27;t want to fan out, and just have one subscription, it&#x27;s basically fine.That&#x27;s actually also true with AWS too - nobody is stopping you from using SNS this way. SQS was the first AWS service (S3 went \"GA\" first, though), and AWS doesn&#x27;t deprecate things that are popular with customers.Amazon MQ is Amazon&#x27;s managed Apache MQ. You can criticize Amazon for hosting managed open source software, but there is a reason why it exists for customers that want to use an industry standard queueing service but not worry about operating it.GCP&#x27;s competitor to Kinesis isn&#x27;t Pub&#x2F;Sub, it&#x27;s Dataflow -> https:&#x2F;&#x2F;cloud.google.com&#x2F;dataflow Both are described as for the same use case - streaming, analytics, batch processing.Kinesis Data Firehose may be another valid criticism. It can be thought of a \"Simplified Kinesis that can push data instead of pulling it\". It is clearly coupled tightly with Kinesis Data Streams itself, so in another company that cared less about not breaking backwards compatibility maybe they would&#x27;ve bolted those features on top of Kinesis.DynamoDB Streams is also not a separate service. It&#x27;s a feature of DynamoDB - streams data capture streams from a database. Exactly like... https:&#x2F;&#x2F;cloud.google.com&#x2F;bigtable&#x2F;docs&#x2F;change-streams-overvi...> 2019 Update: Amazon has now released another streaming service: Amazon Managed Streaming Kafka.GCP also has a Managed Kafka service only theirs is a collaboration with Confluent: https:&#x2F;&#x2F;cloud.google.com&#x2F;learn&#x2F;what-is-apache-kafka\"Confluent Cloud on Google Cloud provides fully managed Apache Kafka as a service so you can focus on building apps and not managing clusters.\" reply QuinnyPig 9 hours agoprevThey shut down Google Cloud IoT Core. Y’know, the thing you need to update all of your field devices to be aware of? reply vasili111 11 hours agoprevHow GCP support compares to AWS support? What is your personal experience with support? reply pirsquare 9 hours agoparentAmazon is A-tier.GCP is F-tierGCP - Shutdown our production servers and took 1 whole week to get it resolved. Nothing fraudulent on our end. Just for missing out on KYC form. reply pyrophane 11 hours agoparentprevHaving had experience with both at the level of companies spending $50-100k&#x2F;mo I can say both were pretty equally bad. reply throwaway2990 8 hours agorootparentI doubt you were experiencing bad support with aws. You’re just bias. reply balls187 10 hours agoprevGCP lost me when I had to enable API errors from the console in order to see actual error in the console rather than a user hostile “Something went wrong” type message.There is probably a rational reason for this behavior, but I don’t care. Just tell me the error. reply syndicatedjelly 8 hours agoprevWhat are people&#x27;s thoughts on DigitalOcean compared to AWS and&#x2F;or GCP? reply lowbloodsugar 10 hours agoprevI mean, the author makes the arbitrary decision to equate AWS accounts with GCP projects, and then from there determines that this is unsatisfactory. This is not my experience at all, and it wasn&#x27;t until I joined a Fortune 500 company that I ever came across the idea of separate accounts - and they were split along corporate accounting divisions. reply preommr 11 hours agoprevI&#x27;ll continue beating the dead horse: I don&#x27;t trust Google.At best GCP is slightly better than AWS (debatable), which is not enough to offset the risk because of how much of a pain it is to switch cloud providers.Even if GCP shutting down is one in a million, aws shutting down is 1 in ten million.Also, I keep getting the feeling that Google keeps trying to automate their customer service through bots. I have use quite a few google services from youtube, to google workspaces (a paid service) - I have never talked to a Google representative. I have talked to AWS service reps multiple times, I have talked to Amazon reps multiple times. Amazon as a company has real people you can talk to.I don&#x27;t trust google to not shut down my gcp account because my gmail was connected to some project where I accidentally sent a bunch of spam emails to a test account. And if that did I happen, I feel like I would just get an automated message and a bunch of hoops to jump through before I could talk to a real person.",
    "originSummary": [
      "The article presents the author's personal experiences with Google Cloud Platform (GCP) and Amazon Web Services (AWS), commending GCP for its user-friendliness, advanced Kubernetes implementation, security, and scalability.",
      "Despite acknowledging AWS's broader range of features, the author deems GCP as more reliable and innovative, while criticizing AWS for its complex interface and lack of automation.",
      "The author briefly mentions their dislike for Microsoft Azure, discusses the transformation of DevOps into Platform Engineering, and introduces a new tool known as Azure Analytics Architecture Advisor."
    ],
    "commentSummary": [
      "The discussions compare various features of Google Cloud Platform (GCP) and Amazon Web Service (AWS), including service offerings, support, reliability, ease of use, cost, documentation, long-term commitment, and user experiences.",
      "Participants have raised concerns about the potential discontinuation of certain GCP services and the reliability of Google's commitments.",
      "Opinions are mixed: some users prefer GCP for its unique features and user-friendly interface, while others lean towards AWS for its reliable support and stability."
    ],
    "points": 208,
    "commentCount": 333,
    "retryCount": 0,
    "time": 1698260514
  },
  {
    "id": 38017146,
    "title": "AI 'breakthrough': neural net has human-like ability to generalize language",
    "originLink": "https://www.nature.com/articles/d41586-023-03272-3",
    "originBody": "Your Privacy We use cookies to make sure that our website works properly, as well as some optional cookies to personalise content and advertising, provide social media features and analyse how people use our site. By accepting some or all optional cookies you give consent to the processing of your personal data, including transfer to third parties, some in countries outside of the European Economic Area that do not offer the same data protection standards as the country where you live. You can decide which optional cookies to accept by clicking on \"Manage preferences\", where you can also find more information about how your personal data is processed. Further information can be found in our privacy policy. Accept all cookies Manage preferences Skip to main content Advertisement View all journals Search Log in Explore content About the journal Publish with us Subscribe Sign up for alerts RSS feed nature news article NEWS 25 October 2023 AI ‘breakthrough’: neural net has human-like ability to generalize language A neural-network-based artificial intelligence outperforms ChatGPT at quickly folding new words into its lexicon, a key aspect of human intelligence. Max Kozlov & Celeste Biever Twitter Facebook Email A version of the human ability to apply new vocabulary in flexible ways has been achieved by a neural network.Credit: marrio31/Getty Scientists have created a neural network with the human-like ability to make generalizations about language1. The artificial intelligence (AI) system performs about as well as humans at folding newly learned words into an existing vocabulary and using them in fresh contexts, which is a key aspect of human cognition known as systematic generalization. The researchers gave the same task to the AI model that underlies the chatbot ChatGPT, and found that it performs much worse on such a test than either the new neural net or people, despite the chatbot’s uncanny ability to converse in a human-like manner. The work, published on 25 October in Nature, could lead to machines that interact with people more naturally than do even the best AI systems today. Although systems based on large language models, such as ChatGPT, are adept at conversation in many contexts, they display glaring gaps and inconsistencies in others. The neural network’s human-like performance suggests there has been a “breakthrough in the ability to train networks to be systematic”, says Paul Smolensky, a cognitive scientist who specializes in language at Johns Hopkins University in Baltimore, Maryland. Language lessons Systematic generalization is demonstrated by people’s ability to effortlessly use newly acquired words in new settings. For example, once someone has grasped the meaning of the word ‘photobomb’, they will be able to use it in a variety of situations, such as ‘photobomb twice’ or ‘photobomb during a Zoom call’. Similarly, someone who understands the sentence ‘the cat chases the dog’ will also understand ‘the dog chases the cat’ without much extra thought. But this ability does not come innately to neural networks, a method of emulating human cognition that has dominated artificial-intelligence research, says Brenden Lake, a cognitive computational scientist at New York University and co-author of the study. Unlike people, neural nets struggle to use a new word until they have been trained on many sample texts that use that word. AI researchers have sparred for nearly 40 years as to whether neural networks could ever be a plausible model of human cognition if they cannot demonstrate this type of systematicity. DeepMind AI learns simple physics like a baby To attempt to settle this debate, the authors first tested 25 people on how well they deploy newly learnt words to different situations. The researchers ensured the participants would be learning the words for the first time by testing them on a pseudo-language consisting of two categories of nonsense words. ‘Primitive’ words such as ‘dax,’ ‘wif’ and ‘lug’ represented basic, concrete actions such as ‘skip’ and ‘jump’. More abstract ‘function’ words such as ‘blicket’, ‘kiki’ and ’fep’ specified rules for using and combining the primitives, resulting in sequences such as ‘jump three times’ or ‘skip backwards’. Participants were trained to link each primitive word with a circle of a particular colour, so a red circle represents ‘dax’, and a blue circle represents ‘lug’. The researchers then showed the participants combinations of primitive and function words alongside the patterns of circles that would result when the functions were applied to the primitives. For example, the phrase ‘dax fep’ was shown with three red circles, and ‘lug fep’ with three blue circles, indicating that fep denotes an abstract rule to repeat a primitive three times. Finally, the researchers tested participants’ ability to apply these abstract rules by giving them complex combinations of primitives and functions. They then had to select the correct colour and number of circles and place them in the appropriate order. Cognitive benchmark As predicted, people excelled at this task; they chose the correct combination of coloured circles about 80% of the time, on average. When they did make errors, the researchers noticed that these followed a pattern that reflected known human biases. Next, the researchers trained a neural network to do a task similar to the one presented to participants, by programming it to learn from its mistakes. This approach allowed the AI to learn as it completed each task rather than using a static data set, which is the standard approach to training neural nets. To make the neural net human-like, the authors trained it to reproduce the patterns of errors they observed in humans’ test results. When the neural net was then tested on fresh puzzles, its answers corresponded almost exactly to those of the human volunteers, and in some cases exceeded their performance. A test of artificial intelligence By contrast, GPT-4 struggled with the same task, failing, on average, between 42 and 86% of the time, depending on how the researchers presented the task. “It’s not magic, it’s practice,” Lake says. “Much like a child also gets practice when learning their native language, the models improve their compositional skills through a series of compositional learning tasks.” Melanie Mitchell, a computer and cognitive scientist at the Santa Fe Institute in New Mexico, says this study is an interesting proof of principle, but it remains to be seen whether this training method can scale up to generalize across a much larger data set or even to images. Lake hopes to tackle this problem by studying how people develop a knack for systematic generalization from a young age, and incorporating those findings to build a more robust neural net. Elia Bruni, a specialist in natural language processing at the University of Osnabrück in Germany, says this research could make neural networks more-efficient learners. This would reduce the gargantuan amount of data necessary to train systems such as ChatGPT and would minimize ‘hallucination’, which occurs when AI perceives patterns that are non-existent and creates inaccurate outputs. “Infusing systematicity into neural networks is a big deal,” Bruni says. “It could tackle both these issues at the same time.” doi: https://doi.org/10.1038/d41586-023-03272-3 References Lake, B. M. & Baroni, M. Nature https://doi.org/10.1038/s41586-023-06668-3 (2023). Article Google Scholar Download references Reprints and Permissions Latest on: Computer science Technology Neuroscience All-analog photoelectronic chip for high-speed vision tasks ARTICLE 25 OCT 23 Human-like systematic generalization through a meta-learning neural network ARTICLE 25 OCT 23 Living guidelines for generative AI — why scientists must oversee its use COMMENT 19 OCT 23 Jobs Teaching Faculty and Lab Manager Positions Non-tenure Track, Open Rank, Full-Time Teaching Faculty Positions Hangzhou, Zhejiang, China Westlake University Postdoctoral Associate- Translational Cancer Research Houston, Texas (US) Baylor College of Medicine (BCM) Postdoctoral Positions Postdoctoral positions at Rutgers Cancer Institute of New Jersey New Brunswick, New Jersey Rutgers Cancer Institute of New Jersey PhD Position - Deciphering the mechanisms of polymicrobial infections using Drosophila melanogaster The Iatsenko lab is looking to recruit one PhD student for a project at the MPIIB starting 2024 within the IMPRS-IDI graduate program. Berlin (DE) Max Planck Institute for Infection Biology Tenure-Track Assistant Professor, Associate Professor, and Professor Founded at Hangzhou, China in 2018, Westlake University is a new type of non-profit research-oriented university, creating a stimulating, world-cla... Hangzhou Westlake Center for Genome Editing, Westlake University You have full access to this article via Shaw University Related Articles ChatGPT broke the Turing test — the race is on for new ways to assess AI If AI becomes conscious: here’s how researchers will know How ChatGPT and other AI tools could disrupt scientific publishing AI bot ChatGPT writes smart essays — should professors worry? Subjects Computer science Technology Neuroscience Sign up to Nature Briefing An essential round-up of science news, opinion and analysis, delivered to your inbox every weekday. Email address Yes! Sign me up to receive the daily Nature Briefing email. I agree my information will be processed in accordance with the Nature and Springer Nature Limited Privacy Policy. Sign up Nature (Nature) ISSN 1476-4687 (online) ISSN 0028-0836 (print) nature.com sitemap About Nature Portfolio About us Press releases Press office Contact us Discover content Journals A-Z Articles by subject Nano Protocol Exchange Nature Index Publishing policies Nature portfolio policies Open access Author & Researcher services Reprints & permissions Research data Language editing Scientific editing Nature Masterclasses Live Expert Trainer-led workshops Research Solutions Libraries & institutions Librarian service & tools Librarian portal Open research Recommend to library Advertising & partnerships Advertising Partnerships & Services Media kits Branded content Career development Nature Careers Nature Conferences Nature events Regional websites Nature Africa Nature China Nature India Nature Italy Nature Japan Nature Korea Nature Middle East Privacy Policy Use of cookies Your privacy choices/Manage cookies Legal notice Accessibility statement Terms & Conditions Your US state privacy rights © 2023 Springer Nature Limited",
    "commentLink": "https://news.ycombinator.com/item?id=38017146",
    "commentBody": "AI &#x27;breakthrough&#x27;: neural net has human-like ability to generalize languageHacker NewspastloginAI &#x27;breakthrough&#x27;: neural net has human-like ability to generalize language (nature.com) 178 points by drcwpl 14 hours ago| hidepastfavorite56 comments vessenes 13 hours agoI actually read the (first half) of the paper.I can&#x27;t speak to whether or not Nature should publish this, but I don&#x27;t find the outcomes in the paper spectacular. In brief, they create an ontology -- in the initial examples, four made up color words, each corresponding to a real color and then three made up &#x27;function&#x27; words, representing &#x27;before&#x27;, &#x27;in the middle of&#x27; and &#x27;triple&#x27;.They then ask humans and their AI to generate sequences of colors based on short and progressively longer strings of color words and functions.The AI is about as good at this as humans, which is to say 85% successful for instructions longer than three or four words.The headline says that GPT4 is worse at this than MLC. I am doubtful about this claim. I feel a quality prompt engineer could beat 85% with GPT4.The claims in the document are that MLC shows similar error types to humans, and that this backs some sort of theory of mind I don&#x27;t know anything about. That&#x27;s as may be.I would be surprised if this becomes a radical new architecture based on what I&#x27;m reading. I couldn&#x27;t find a lot of information as to size of the network used; I suppose if its very small that might be interesting. But this read to me very like an &#x27;insider&#x27; paper, its target other academics who care about some of these theories of mind, not people who need to get sentences like &#x27;cax kiki pup wif gep&#x27; turned into real color circles right away. reply og_kalu 13 hours agoparent>I feel a quality prompt engineer could beat 85% with GPT4.I generally don&#x27;t pull the \"you&#x27;re not prompting it good enough\" card unless i have direct experience with the task but this does raise a few flags - \"between 42 and 86% of the time, depending on how the researchers presented the task.\"I would have liked them to show how they presented this task, at least something more than a single throw away line, given how integral it is to the main claim. reply PumpkinSpice 12 hours agorootparentI don&#x27;t find this argument persuasive. If you need to engineer the prompt in order for the model to give you the answer you want, and if it&#x27;s performing poorly without that kind of assistance from a human who understands the task and the desired outcome... then it&#x27;s perfectly OK to not bother and give the LLM a low mark on a benchmark. After all, the whole point was to test the LLM&#x27;s language and reasoning skills.\"Prompt engineering\" makes sense if your goal is more utilitarian, but it&#x27;s not a license to cheat on tests. If you want a machine learning model to generate aesthetically pleasing images, or to follow certain rules in a conversation, then it&#x27;s OK to rely on hacky solutions to get there. reply og_kalu 12 hours agorootparentI kind of dislike the term \"Prompt Engineering\". It mystifies what to me is an ordinary process. I&#x27;m not talking about chanting magic words, i&#x27;m just talking about taking the structure of an LLM into account, even taking how humans would approach the problem into account.In microsoft&#x27;s agi paper, there is a test for planning they put out for GPT-4. They give detailed instructions on the constraint of a poem and expect it to spit out the constrained poem in one shot. Of course it fails and the conclusion is that it can&#x27;t plan. But if you think about it, this is a ridiculous assertion. No human on earth would have passed that test with working memory alone. Even by our standards, it&#x27;s a weird way to present the information but they did so anyway. This is actually a major issue for most plan benchmark assessment for LLMs i&#x27;ve come across.These are the kind of problems i&#x27;m talking about. If i changed the request to encourage for a draft&#x2F;revise generation process and it consistently passed these tests then it&#x27;s very fair to say it can plan. That&#x27;s not \"hacky\". It&#x27;s just truth. and saying otherwise is denying real world usage for a misplaced sense of propriety to benchmarks. a benchmark is only as useful as the capabilities it can assess.a \"this is how this is presented, this is how the model performed\" would have been very prudent in my opinion. Maybe these guys already covered the kind of things i&#x27;m talking about(i can accept that!)....but i can&#x27;t know that if they don&#x27;t tell us. reply haskellandchill 10 hours agorootparenthow is \"Engineering\" \"about chanting magic words\"? The wires may be getting crossed on if it&#x27;s an engineering discipline or just the use of the word engineer, meaning to build mindfully, I feel the latter is appropriate and the former more misguided but still it&#x27;s not \"Prompt Wizarding\" ;) reply Guthur 3 hours agorootparentWell you&#x27;re building nothing, your poking at a black box and hoping it spits out something close to what you want. reply og_kalu 10 hours agorootparentprevFair Enough. Just that discussion around the term feels like that sometimes especially with image generation. reply viraptor 9 hours agorootparentprevI think adjusting the prompt makes sense. We have to keep in mind that this implicitly happens on the human side as well. The person creating the initial question will consider how understandable it is for them and edit until they&#x27;re happy. Then the questions will be reviewed by co-authors and possibly tested on a few people before running the full experiment. They&#x27;d probably review the explanation again or change the task if they realised half the people can&#x27;t follow the instructions.We just call it \"editing for clarity\" rather than \"prompt engineering\" when we write for other people. reply quitit 9 hours agorootparentprevWhile I think that&#x27;s a valid point, for the purpose of the paper having a competent prompt writer would be needed to make a fair comparison.I think the researchers would know how to get the best from their own AI bot, so that&#x27;s a level of competency that should be extended to comparisons, otherwise user competency becomes a source of bias. I do feel you&#x27;re correct in your concerns though, the systems shouldn&#x27;t need experts to use them, nor should they need the user to already know the right answer, which leads me to my next point:When it comes to real world expectations, perhaps instead we need a large group of random people (with no prior experience) working with each bot to complete a set of tasks in order to determine how it truly performs - something that could be enhanced if the answers weren&#x27;t easy to check. reply altruios 11 hours agorootparentprevSo what if we have an AI prompter-assister... we take an input prompt: run it through an AI to transform that prompt into proper AI talk - then that is what&#x27;s prompted to the actual AI... That way the AI will always have the best prompt possible, because the Prompt-helper helps your prompt...&#x2F;s if anyone needs it. reply larperdoodle 11 hours agorootparentIs the &#x2F;s because that&#x27;s literally what they&#x27;re already doing? reply emtel 6 hours agorootparentprevDisagree - a model may have capabilities that it only deploys in certain circumstances. In particular, if you train on the whole internet, you probably learn what both stupid and smart outputs look like. But you probably also learn that the modal output is stupid. So it’s no ding on the model’s capabilities if it defaults to assuming it should behave stupidly. reply PumpkinSpice 5 hours agorootparentWhat you&#x27;re basically saying is \"the model as trained can&#x27;t do well at this task, so let&#x27;s use our own cognitive skills to help it.\"That&#x27;s a problem for comparative benchmarking, right? You&#x27;re no longer testing the model; you&#x27;re testing the model in tandem with the prompt engineer. This raises several big questions:1) How do you know that the engineer&#x27;s knowledge of the \"correct\" answer isn&#x27;t being subtly encoded in the prompt? Essentially the Clever Hans phenomenon.2) If you want this to be a fair game, how do you give precisely the same kind of advantage to whatever you&#x27;re benchmarking the LLM against?3) Last but not least, if you&#x27;re not going to throw in your prompt engineer for free with the product, will your results be reproducible by your customers?To be clear, I don&#x27;t think there&#x27;s some cosmically objective way of doing this. If you&#x27;re using prompts written for humans, you&#x27;re already putting the computer at a disadvantage. But at the very least, you&#x27;re measuring something meaningful: how will the model behave in the real world. reply nomel 9 hours agorootparentprevI would claim that most people are very bad at communicating in a way that can be interpreted, by human or AI, with a single shot. Most of the time some back and forth is required to clear things up. I think it&#x27;s unfair to expect gold from garbage input, since meat brains can&#x27;t do that either, without some back and fourth.Those prompts should be available. It&#x27;s ridiculous that they&#x27;re not. reply pama 4 hours agorootparentprevThe supplement discusses how they presented the task. Notably, they first gave all the training examples and then told the model what the task is and didn&#x27;t ask it to reason or create any context before spitting out the answers. So basically the simplest way to interact with it, but probably not a great way to get solutions for this problem if that was the task at hand.https:&#x2F;&#x2F;static-content.springer.com&#x2F;esm&#x2F;art%3A10.1038%2Fs415... reply vessenes 8 hours agorootparentprevAgreed. And there&#x27;s going to be some significant domain decisions for GPT-4 to consider: Will the made up words be existing single tokens? Will those single tokens be heavily overloaded tokens, e.g. a letter of the alphabet? Will the representation of the circles be, say \"B\" for blue, or something else?Along with this are questions as to whether you&#x27;re going to treat GPT-4 as a zero shot or multi-shot oracle; while they have this idea of &#x27;context free&#x27; challenges in the paper, they, crucially, train their network first.Anyway, I like this paper less the more I think about it. reply randcraw 13 hours agorootparentprevThe article suggested that GPF-4 FAILED between 42 and 86 percent of the time. So its success rate would be 58 to 14 percent, which compared to the novel NN&#x27;s 80 percent, seems significant. reply og_kalu 12 hours agorootparentYes I&#x27;m aware. My point is that1. The level of variance displayed here is very atypical for a language model unless you&#x27;re making significant changes to how the information is presented. This alone is cause for more elaboration.2. With this big a variance already showing, it&#x27;s hard to say for sure that they hit the top end. Maybe it seems strange but most LLM evaluation papers still don&#x27;t actually bother to tie in even some extremely well known&#x2F;basic \"output boosters\" like chain of thought and so on. But at least in these instances, we know how they presented it.a \"this is how we presented the task, this is how it performed\" would have been very nice. reply 8bitsrule 11 hours agoparentprev>I couldn&#x27;t find a lot of information as to size of the network usedIn the original paper,[0] in the section called &#x27;Implementation of MLC&#x27;, there&#x27;s a description of sorts (Greek to me):\"Both the encoder and decoder have 3 layers, 8 attention heads per layer, input and hidden embeddings of size 128, and a feedforward hidden size of 512. Following GPT63, GELU64 activation functions are used instead of ReLU. In total, the architecture has about 1.4 million parameters.\"[0] https:&#x2F;&#x2F;www.nature.com&#x2F;articles&#x2F;s41586-023-06668-3 reply sashank_1509 5 hours agoparentprevHonestly I’m surprised by how low Nature has fallen. Is it even a useful signal of paper quality anymore? NeurIPS and ICLR aren’t great but in general I’ve found their work to be more rigorous than that of Nature despite of the fact that they are shorter conference papers compared to Nature’s journal papers.Right now sadly the only useful signal in Deep Learning research is research group. If OpenAI releases a paper I know it’s something good that works at scale, similarly if Kaiming He, Piotr Dollar and team in Meta AI release a paper, it tends to be really good and SOTA. Google Deepmind maintains high quality, Google brain has been more of a mixed bag. If Berkeley releases a paper, it has 50% chance of directly going to trash, Stanford has a much lower percent (I also disambiguate) based on specific groups. Of course I’m going to be heavily biased and this system is not great, but conferences and journals have managed to become such a useless signal that I find this method to be more accurate. reply avgcorrection 11 hours agoparentprevThat’s seriously it? What an insulting (to the reader) headline by Nature. reply valine 13 hours agoprevFor anyone wondering about the architecture this is a 1.4 million parameter transformer model with both an encoder and decoder. The vocabulary size is comically small, it only understands 8 words.It learns new ideas with very few examples, to the extent you can express new ideas with a vocabulary of eight words. reply rpearl 13 hours agoparentlet&#x27;s see...English speakers tend to have a vocabulary of 30k words or so depending on what exactly you measure.GPT-4 has 1.7 trillion parameters.Of course scaling up is quite unpredictable in what capabilities it gets you, but It&#x27;s not that much of a stretch to imagine that a GPT-4 sized model would have a reasonably sized vocabulary. Certainly worth testing if you have the resources to train such a thing! reply glitchc 13 hours agorootparentIt&#x27;s the mapping of parameters to vocabulary claim embedded in your response that needs validation. 1.7 trillion parameters means what exactly?Let&#x27;s start with working vocabulary. Working vocabulary doesn&#x27;t just mean knowing n words. It means putting n words together in factorially many valid combinations to construct sentences. And 30k btw is an insane working vocabulary. Most people know 1000 words on average in English. All of their sentences are structured from those 1000 words. This is true for most cases, except certain ones like Mandarin or German, where basic words can be used to assemble more complex words.Certainly GPT-4 knows something. Presumably that something can be mapped to a working vocabulary. How large a vocabulary that is requires a testable, reproducible hypothesis supported by experimental proof. Do you have such a hypothesis with proof? Does anyone? Until we do it&#x27;s just a guess. reply throwaway9274 3 hours agorootparent100% of people know the most common 1000 words. The remainder of those who know more words fall into a consistent curve across languages that follows Zipf’s law. This is different than “most people know 1000 words on average.” reply rpearl 10 hours agorootparentprevI don&#x27;t care to pay for access to gpt-4 but one could easily use one of the vocabulary estimation tests, which use some statistics plus knowledge of word appearance frequency, to estimate its vocabulary size. https:&#x2F;&#x2F;mikeinnes.io&#x2F;2022&#x2F;02&#x2F;26&#x2F;vocab is one such test which explains the statistics ideas, and there are many others based on similar principles. reply _a_a_a_ 12 hours agorootparentprev> Most people know 1000 words on average in EnglishMaybe I misunderstand but that sounds so stupid and wrong I don&#x27;t know where to start. Standard vocab estimates are 15K - 30K, averaging about 20K (these from memory)Edit: from wiki https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Vocabulary#Native-language_voc...---As a result, estimates vary from 10,000-17,000 word families[16][19] or 17,000-42,000 dictionary words for young adult native speakers of English.[12][17]A 2016 study shows that 20-year-old English native speakers recognize on average 42,000 lemmas, ranging from 27,100 for the lowest 5% of the population to 51,700 lemmas for the highest 5%. These lemmas come from 6,100 word families in the lowest 5% of the population and 14,900 word families in the highest 5%. 60-year-olds know on average 6,000 lemmas more. [12]According to another, earlier 1995 study junior-high students would be able to recognize the meanings of about 10,000–12,000 words, whereas for college students this number grows up to about 12,000–17,000 and for elderly adults up to about 17,000 or more.[20]--- reply Y_Y 11 hours agorootparentDoes the average include people who don&#x27;t speak English? If about 4% of the world&#x27;s population are native speakers and the number of words known tails off after that I can imagine it could almost be approximately true. And maybe we are counting babies in English majority countries as native speakers but they haven&#x27;t learned all their 20k words yet. Of course GP&#x27;s point is still invalid in that case. reply debo_ 10 hours agorootparentprevI assumed they missed a 0 and meant 10000 words. reply swyx 12 hours agorootparentprev> if you have the resources to train such a thing!estimates i&#x27;ve heard for training gpt4 was $500m all in for what its worth reply Izkata 13 hours agoparentprevMorse code has a vocabulary of 3 words (dot, dash, pause between human words). reply IMTDb 13 hours agorootparentThen English has a vocabulary of 27 words: A -> Z + space reply sterlind 12 hours agorootparentI think a fairer comparison would be Toki Pona, a micro-language with ~120 words. you can express lots of things if you have a great deal of patience, Up-Goer Five style.In logic there&#x27;s also SKI combinator calculus, which is Turing-complete with three symbols, and unlike the Morse or A-Z examples, but like the Toki Pona example, each symbol has a semantic meaning.If you just want to describe ideas in an abstract realm like sequences of colors, like this paper, it&#x27;s not surprising you don&#x27;t need many words. reply nerdponx 12 hours agorootparentprevIf you tokenize using character n-grams, this isn&#x27;t totally wrong. reply Izkata 11 hours agorootparentExactly.There was a post on here a few months ago about training using single characters as tokens instead of words, and it worked really well, being able to create new Shakespeare-like text despite not using human words as tokens. What a (human) word is can be learned by the model instead of encoded in the training set. reply yawnxyz 13 hours agorootparentprevthose are more like tokens, not words reply samfriedman 13 hours agoprevLink to the actual paper: https:&#x2F;&#x2F;www.nature.com&#x2F;articles&#x2F;s41586-023-06668-3 reply drcwpl 14 hours agoprevBy contrast, GPT-4 struggled with the same task, failing, on average, between 42 and 86% of the time, depending on how the researchers presented the task. “It’s not magic, it’s practice,” reply CSMastermind 11 hours agoprevThe link is to a news article about a recent paper not the a link to the research itself.The editorialization of this being a breakthrough was done by the reporter not the authors of the paper.I see people here comparing this to GPT-4 but I can&#x27;t find that section in the actual paper nor in the underlying data. Can someone point me in the right direction? reply pama 5 hours agoparentThe fourth sentence of the discussion points to the relevant work in their supplement. Here is the link to the supplement: https:&#x2F;&#x2F;static-content.springer.com&#x2F;esm&#x2F;art%3A10.1038%2Fs415... reply m3kw9 12 hours agoprevWhen an important word is quoted, don’t take it seriously reply danielmarkbruce 12 hours agoprevThis seems dumb. Sure, an LLM can&#x27;t learn a new word. An LLM isn&#x27;t an entire system. You could make a system (which extensively used an LLM) to do this fairly easily. reply matmulbro 11 hours agoprevcheck out other articles by the same author: https:&#x2F;&#x2F;www.nature.com&#x2F;search?author=Max+Kozlov reply caddemon 7 hours agoparentThis guy is a science journalist, the authors of the source research paper are more relevant if you&#x27;re trying to infer anything about the material from the authors: https:&#x2F;&#x2F;www.nature.com&#x2F;articles&#x2F;s41586-023-06668-3FWIW I think even the original paper is more of a master class in riding an academic bubble than anything of important substance. I&#x27;m just not sure what looking at other articles by this journalist is supposed to convey. reply mistrial9 13 hours agoprevsplendid sales headline - however, human communication is varied and multi-layered. Since there are too many angles to summarize -- suffice it to say that IMHO a healthy skepticism is warranted, along with evidence and test results.link to cited repo: https:&#x2F;&#x2F;github.com&#x2F;brendenlake&#x2F;MLC&#x2F;tree&#x2F;v1.0.0 reply tomohelix 13 hours agoparentI will take this article with a bag of salt but I think we are very close to solving the human communication problem. Not because the machines are perfect but because the human, our benchmarks, are prone to mistakes and so a \"close enough\" machine would pass as a human just fine. reply marysnovirgin 11 hours agorootparentThere is inherently no solution to the human communication problem. The mistake has always been in thinking technology would unite us and improve communication when clearly it&#x27;s doing the opposite. reply Beijinger 13 hours agoparentprevI agree. But \"Nature\" is quite a name. reply matt123456789 13 hours agorootparentAnd desperate to retain their relevance in the face of the onslaught of advancements that open access papers has unleashed. reply jltsiren 6 hours agorootparentThat&#x27;s a category error. You don&#x27;t submit your manuscript to a prestige journal in order to publish it but to take advantage of their PR machinery. The services Nature provides are very good and cost-effective, but you have to meet their standards.As research papers, the papers published in Nature&#x2F;Science&#x2F;etc. are rarely that useful. Because the journals target the general scientifically literate audience, the interesting details are usually hidden in supplementary material. And the supplements are often little more than giant info dumps that nobody has paid sufficient attention to.It would be nice to live in a world where such PR services are unnecessary, but that&#x27;s not the world we are living in. The academia is very competitive, and there is never enough funding and never enough good jobs. reply schleck8 13 hours agorootparentprevSo to retain their relevance you claim they abandon academic standards and sensationalize an openly accessible study that anyone can read and thus dispute the article. Okay. reply caddemon 7 hours agorootparentI don&#x27;t think it is quite that intentional, but just as human economic systems regularly create bubbles there are blind spots in the academic science collective. People desperately want to get in on LLMs right now. reply dotnet00 9 hours agorootparentprevIt isn&#x27;t exactly unheard of for them to do that. They&#x27;ll just wipe their hands of it afterwards if it turns out to be bad science by saying that their goal isn&#x27;t to publish research that&#x27;s guaranteed correct. reply robertlagrant 11 hours agorootparentprevAnyone can read but most press will read and believe the abstract, and write breathless articles on it. replyjmsuth 11 hours agoprevsounds lit reply MattPalmer1086 13 hours agoprev [–] I am no expert in this field, but this seems an important result, even if on a limited model.I don&#x27;t think that anyone was very sure if generalisation was actually happening with current architectures. Happy to be corrected by anyone who knows more. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Researchers have created a neural network that can generalize language akin to humans, surpassing the chatbot ChatGPT in incorporating newly acquired words into existing vocabularies and varying contexts.",
      "This technological advancement could culminate in more organic interactions between humans and machines.",
      "The study indicates that neural networks can accomplish systematic generalization, a crucial component of human cognition, which has previously been a contentious subject in the artificial intelligence field."
    ],
    "commentSummary": [
      "Scientists created a neural network with human-like understanding and production of language, boasting an 85% efficacy in creating color sequences based on instructions.",
      "Critics argue that this success might be a result of prompt engineering, and there are ongoing discussions on testing hurdles, bias, fairness, and reproducibility in language models.",
      "The post explains GPT-4, noting its smaller vocabulary and potential for scaling, and mentions a new language model that can create and comprehend new words, trained on over 8 million English words."
    ],
    "points": 177,
    "commentCount": 56,
    "retryCount": 0,
    "time": 1698262125
  },
  {
    "id": 38014812,
    "title": "Nile: Serverless Postgres for modern SaaS",
    "originLink": "https://www.thenile.dev/blog/introducing-nile",
    "originBody": "Docs About Us Community Blog Templates Pricing Star us on 2023-10-25 ● 25 min read ● Sriram Subramanian Introducing Nile, Serverless Postgres for modern SaaS I am thrilled to announce Nile, a serverless Postgres database designed for modern SaaS applications. Modern SaaS applications are multi-tenant. We’re the first database that virtualizes tenants into the database. This enables seamless tenant isolation, per-tenant backups, and placement on multi-tenant or dedicated infrastructure, anywhere on the planet. You can do all this with the experience of a single Postgres! You don’t have to manage multiple databases, build complex permissions for isolation, or write buggy scripts to read specific tenant data from backups. On top of the tenant model, we provide opt-in user management capabilities, customer-specific vector embeddings, and instant tenant admin dashboards. You can do all of this with very little code. Moreover, Nile's Postgres is built for the cloud, enabling effortless scaling and a true serverless experience. You can sign up for our waitlist today to try it out. Before Nile, I spent six years at Confluent, helping transform the company from primarily on-premise to a successful global SaaS company. Through this journey, I learned the challenges of launching and scaling a SaaS product to thousands of customers and tens of thousands of users. We spent significant time managing and isolating tenants, supporting different tenant deployment models, dealing with long downtimes to restore tenant data from backups, and optimizing per-tenant performance. We also had to build the organization and user management capabilities, store and move data to different parts of the company, track usage, bill individual customers, and handle many other SaaS problems. When we spoke to many other companies from different verticals, the problems were similar. All these problems in building SaaS were around data, but the database had little to offer. We started thinking about what an ideal database for SaaS will look like. What foundational elements would it require? How can we create a fully integrated solution that simplifies the development and scaling of SaaS while also offering the flexibility for developers to integrate with their preferred tools? We picked Postgres as our foundational database. We built tenant virtualization into it, allowing many virtual tenant databases to be placed on physical Postgres databases. We built a single database experience to interact with all these virtual tenant DBs. This was a powerful primitive that provided world-class developer experience and helped solve all the tenant management problems. These virtual tenant DBs are isolated, have their own backups, can be placed on multi-tenant or dedicated infrastructure, and can be deployed to any location worldwide. On top of this basic foundation of tenants, we also built the concept of users and their relationship with the tenants. The authentication and authorization semantics execute on top of this, providing an impregnable level of security for tenants and users. Storing and querying vector embeddings per tenant becomes trivial. They can now be placed closer to the tenant and scale indefinitely when the index size becomes large and resource-consuming. Finally, the database gives out-of-the-box customer admin dashboards to understand and debug issues with tenant and user growth, insights into per-tenant performance, and management controls to perform administrative operations on tenants and users. Finally, the database is built to be serverless and leverage cloud-native solutions. This database, built from first principles, significantly simplifies the development and scaling of SaaS. We will go deeper to understand what SaaS is, what it means to say they are modern, the current challenges in building them, and finally, what choices and tradeoffs we made in building the database for modern SaaS. What makes SaaS modern, and why is it hard to build? SaaS is a pretty overloaded term at this point, and it would be useful to specify how we define it. We define SaaS as any application that’s multi-tenant. A tenant can be a company, an organization, or a workspace in your product that contains a group of users. Here are a few examples of SaaS products and how tenants and users map to them: GitHub helps a group of developers manage and deploy their code. Each Github organization is a tenant, and the developers within those organizations are users. Salesforce or Hubspot helps sales reps manage their leads. Each company is a tenant, and the users are the sales reps. Ring is a home security company that provides alarm services to different households. Each household is a tenant, and people living in a house using their service are users. Toast is a platform to help build software for restaurants. The restaurants are tenants, and the employees of the restaurants are the users. It is clear from these examples that SaaS is a delivery mechanism and will be leveraged by every vertical, including technology, hardware, manufacturing, industrial, legal, etc. Our insight is that 95% of companies fall into this category, and there’s a massive opportunity to simplify the life of developers building these products. We've spent years building and talking to SaaS companies identifying the core principles of modern SaaS. They're tenant-centric, secure, globally deployed and scalable, fast and responsive, and provide AI-native experiences. Secondary values like data-centricity, real-time, collaboration and offline mode, and monetization are increasingly important. Let's examine them in more detail based on our experience. Customer or tenant-centric A SaaS application provides services to multiple tenants or organizations. Users can create new organizations and get invited to existing ones. They can access the organization irrespective of where they are in the world. One organization's data is perfectly isolated from the other. In addition, you want the performance of one tenant not to affect the other tenants. There are many other considerations: Where is the tenant’s data located? What happens when a tenant's data is deleted? How long will you keep data backups for each tenant? How can you restore a specific tenant’s data? How many tenants can you support? What are the compliance needs for each customer, etc? Everything about tenant management is hard. You typically start with a single database and place all the tenants on it. You tackle data isolation between tenants by implementing brittle permission logic at the application level or complex, hard-to-debug, row-level security policies in databases like Postgres. You turn on daily backups but have little idea how to restore data for specific tenants when customers lose data. You end up writing some hacky scripts that are slow and buggy to parse through the backups and extract the tenant data. Once the application has users, you run into your first performance issue. Some tenants are pushing more load, and others have large datasets causing queries to take more resources. This impacts other customers as well. You need help determining which customer is causing the impact and which ones are being impacted. To solve this, you migrate some tenants to dedicated databases, which requires building metadata and sharding logic at the application layer to manage all this. Schema changes, rollouts, monitoring, and developer experience become more complex. This was our story and every other SaaS company's story. Secure at every step Modern SaaS is all about being secure by default. The data that belongs to one tenant cannot be exposed to another tenant under any circumstances. This is commonly referred to as tenant data isolation. Users should only be able to see the data of tenants to whom they have access. Most applications need to provide modern authentication support, such as social logins and enterprise logins. There has to be support for a fine-grained permission model for users within a tenant. The same user can have different permission policies across different tenants. These security needs seem simple but are complex to get right for a multi-tenant application in practice. Most authentication solutions focus on only users and leave developers to think about tenants and the interaction between users and tenants. Organization management is an entire suite of problems that needs deep coordination with the tenant's data in the database. One other critical decision that needs to be made is where the user data resides. Ideally, the primary database should be the source of truth for user data. If not, you must figure out how to sync the data between a third-party service and your primary database. This is a hard problem in distributed systems. Synchronizing user data from a third-party service requires a reliable way to copy it to the primary database, even when failures happen. This cannot be accomplished by stateless event services like webhooks, where you can lose data. You need a reliable replayable event stream to synchronize it. Even with that, you have to deal with eventual consistency in your application. Another option is a two-phase commit between the database and the external service, which is impractical. The cleanest approach is to build auth on top of your source of truth database. Globally available All SaaS companies want to be global from day one. At the same time, customers expect great performance and want their compliance needs to be satisfied. Providing low latency globally is hard because you need more than optimizing the database performance alone. The last mile of receiving the response from the server to the client constitutes a significant part of the latency. For example, the network latency between Sydney, Australia, and New York, USA, is around 200 ms on average. This is probably 10x more than the server-side latency of the database. The only solution is to place the data closer to the tenant. Achieving compliance requirements in different countries is equally hard, and it also needs data to be stored locally in the country where the application is accessed. This, again, requires managing multiple databases distributed across the globe. Most companies lose critical business because they cannot provide this capability. Creating and managing multiple databases across different parts of the globe poses many challenges. This is hard as it creates challenges with schema migrations, is expensive to operate, and requires complex sharding and client-side routing. Developers should be abstracted from these problems and spend their time on the core business logic. AI-native experience With the rise of GPT and other open-source large language models, AI-native applications have gained massive traction. Instead of AI being a separate vertical, AI will become more immersive in interacting with SaaS applications. For example, GitHub Copilot provides a seamless experience for developers to use as a coding assistant. Notion provides an AI assistant that helps to write documents, rephrase existing writeups, and summarize long articles (like this one). Hubspot provides a personal chatbot for salespeople to have conversations about their leads and pipelines. It is obvious from these examples where this is heading. New product designs will have AI built in from the start. The difficulty of building the AI infrastructure for SaaS is that you cannot use the large language models directly. They are trained on public data and will typically provide incorrect results. They need tenant-specific data to give relevant results. In addition, there are compliance and security issues with sharing all the private data of tenants to a large language model. This requires building architectures like RAG (more about this later) that require creating tenant-specific vector embeddings, storing them, and augmenting the LLM prompt with the tenant context. This will help with avoiding the hallucination problem and also keep the data secure. The latency of querying these embeddings is another challenge, and network latency from the user to the database will further exacerbate it. Finally, vector indexes like HNSW take significant resources and need horizontal scaling if the embeddings grow fast. Highly available and scalable Everyone wants their application to be highly available. SaaS applications used to have weekend maintenance schedules to upgrade the database. Some applications still do! This is no longer acceptable for most users. The expectation is to have 99.99 percentile availability. Also, as the application scales, users want things to work as they used to. They don’t want any interruption in service or any performance degradation. Building a fully automated technology to manage tenant health proactively is not trivial. You have a service impact if you cannot do zero downtime upgrades. Similarly, you would have customer impact when it takes too long to restore specific tenant data from backups, or developers are manually trying to add more capacity due to a sudden spike in workload or lack of isolation. In addition to these five principles, modern SaaS also has a few other considerations that are quickly becoming standard. Data-centric SaaS applications can be enhanced by providing valuable data insights to the users through the application. Building these data-centric experiences is still a challenge for front-end engineers. Real-time This falls into two categories: pushing data as they happen to the application and executing complex business workflows as events happen. Building these flows and connecting all these systems require multiple moving parts today. Collaborative and offline mode Applications like Figma and Notion have a collaborative experience built into the product. In addition, you can work offline and sync your data later if you don’t have an internet connection. Techniques like CRDTs needed to solve this are not easy to use. Monetizable There is a big shift towards usage-based billing from just charging for the number of seats, especially in these market conditions. The complexity of collecting usage and billing on it is not easy. Designing a database from first principles for modern SaaS We had a few key criteria that we wanted to take into consideration when we designed the database. We had to pick a good relational database that was highly performant, and extensible with growing popularity. We wanted to consider supporting multiple tenants and how the experience can still be like a single database. The ability to place tenants anywhere on the planet while not losing any of the benefits of a single database in one location was critical. On top of the tenant model, we wanted to design a foundational user model to help support all the user management capabilities. We also had to think about how we will enable vector embedding per tenant and how to support scaling them. Finally, the ability to scale instantaneously and reduce the cost of storage was key factors. Postgres We needed to pick a database we would build our tooling around, and the obvious choice was Postgres. Postgres is a world-class database that is winning in the OLTP space. This trend will continue, and making Postgres easy for building SaaS is the best way for us to have the maximum impact. In my opinion, one of the biggest reasons for Postgres's success is its wide suite of features and extension flexibility. This is a great foundation to build the right tooling around it, making it world-class for SaaS. A solution with Postgres should provide a fully integrated experience while preserving the complete flexibility and extensibility of Postgres. It should also work well with Postgres’s vast tooling ecosystem. Built-in tenant virtualization The most foundational element in SaaS is a tenant. It makes a lot of sense to build this core concept into the database. Imagine having a lot of virtual tenant databases that can be co-located on one physical Postgres (multi-tenant) for better cost, and some of them can be placed on a dedicated database for better isolation. The virtual tenant DBs can be located anywhere on the planet for low latency or compliance. The client can route to the right tenant seamlessly without routing logic in the application. Isolating tenants into their own virtual DBs is great, but you will also want to be able to share data across tenants where it makes sense. Backups should be available for each tenant, and it should be possible to restore them instantaneously. Schema changes should be applied seamlessly across all the tenant DBs, and it should also be possible to do staged rollouts for different tenant tiers. While supporting all this, all the standard SQL capabilities should work across the tenants for admin operations. All the standard Postgres tooling should work. You want the experience of a single Postgres! This sounds like magic, and we can make this magic a reality. The experience would be something as follows: Creating a new virtual tenant DB is as simple as a standard insert into the tenant's table. By default, the tenant will get created on a multi-tenant Postgres in the default region. You should be able to specify any location in the world or the infrastructure type if you want a dedicated Postgres for a tenant (more on this in the next section). -- create a record for the first customer insert into tenants (name) VALUES ('customer1'); Creating a new table for each tenant should be like standard table creation, and the database should ensure all the virtual tenant DBs get the schema changes applied to them. Let us call them tenant-aware tables. -- creating an employee table that is tenant aware create table employees ( tenant_id uuid, id integer, name text, age integer, address text, start_date timestamp, title text, CONSTRAINT FK_tenants FOREIGN KEY(tenant_id) REFERENCES tenants(id), CONSTRAINT PK_employee PRIMARY KEY(tenant_id,id)); With the table in place, you can add rows for a specific tenant. Let us say tenant “customer 1” has a few employees that must be added to the system. -- adding employees for customer 1 insert into employees (tenant_id, id, name, age, address, start_date, title) values ('018ac98e-b37a-731b-b03a-6617e8fd5266',1345,'Jason',30,'Sunnyvale,California','2016-12-22 19:10:25-07','software engineer'), ('018ac98e-b37a-731b-b03a-6617e8fd5266',2423,'Minnie',24,'Seattle,Washingtom','2018-11-11 12:09:22-06','sales engineer'), ('018ac98e-b37a-731b-b03a-6617e8fd5266',4532,'Shiva',32,'Fremont, California','2019-09-05 04:03:12-05','product manager'); Now, let us assume a second tenant, “customer 2” needs to be added to the system, and a few employees are added to this new tenant. This would again create another virtual tenant DB. The inserts will route to the right virtual tenant DB, but the experience will be like simply inserting into the employee's table. -- create the second customer insert into tenants (name) VALUES ('customer2'); -- insert employees for the second customer insert into employees (tenant_id, id, name, age, address, start_date, title) values ('018aca35-b8c4-7674-882c-30ae56d7b479',5643,'John',36,'London,UK','2017-12-12 19:10:25-07','senior software engineer'), ('018aca35-b8c4-7674-882c-30ae56d7b479',1532,'Mark',27,'Manchester,UK','2022-10-10 12:09:22-06','support engineer'), ('018aca35-b8c4-7674-882c-30ae56d7b479',8645,'Sam',42,'Liverpool,UK','2015-08-04 04:03:12-05','product manager'); Directing queries to a specific tenant DB and getting full data isolation should be as easy as specifying the tenant ID in the session context . The client library can even abstract this by invoking this for you, depending on what tenant_id is trying to access data. This should all work out of the box without struggling with complex permissions, managing multiple databases, or dealing with error-prone row-level security policies. -- set the session context to a specific tenant -- who needs to be isolated. set nile.tenant_id = '018ac98e-b37a-731b-b03a-6617e8fd5266'; select * from employees tenant_id id name age address start_date title 018ac98e-b37a-731b-b03a-6617e8fd5266 1345 Jason 30 Sunnyvale,California 2016-12-22 19:10:25 software engineer 018ac98e-b37a-731b-b03a-6617e8fd5266 2423 Minnie 24 Seattle,Washington 2018-11-11 12:09:22 sales engineer 018ac98e-b37a-731b-b03a-6617e8fd5266 4532 Shiva 32 Fremont, California 2019-09-05 04:03:12 product manager The best part is you should still be able to query across the tenant DBs like a standard table if you don’t specify any context. select * from employees tenant_id id name age address start_date title 018ac98e-b37a-731b-b03a-6617e8fd5266 1345 Jason 30 Sunnyvale,California 2016-12-22 19:10:25 software engineer 018ac98e-b37a-731b-b03a-6617e8fd5266 2423 Minnie 24 Seattle,Washington 2018-11-11 12:09:22 sales engineer 018ac98e-b37a-731b-b03a-6617e8fd5266 4532 Shiva 32 Fremont, California 2019-09-05 04:03:12 product manager 018aca35-b8c4-7674-882c-30ae56d7b479 5643 John 36 London,UK 2017-12-12 19:10:25 senior software engineer 018aca35-b8c4-7674-882c-30ae56d7b479 1532 Mark 27 Manchester,UK 2022-10-10 12:09:22 support engineer 018aca35-b8c4-7674-882c-30ae56d7b479 8645 Sam 42 Liverpool,UK 2015-08-04 04:03:12 product manager While there’s a need for virtual tenant DBs that isolate data, there’s also a need to share data across tenants. It should be easy to create shared tables that can be accessed by/[across] all tenants and are globally available. All standard queries should work seamlessly both on tenant-aware and shared tables -- list of flights that a corporate travel booking site can use to share across all the tenants. -- employees in different tenants can view these flight data to book tickets create table flights ( id integer PRIMARY KEY, name text, from_location text, to_location text, departure_time TIMESTAMP, arrival_time TIMESTAMP ); Global and flexible tenant placement When building a modern SaaS application, the critical factors that need to be considered are latency, performance isolation, compliance, and cost. The capability of a database to place tenants has a significant impact on achieving this balance. Placement can be of two types: Regional placement You want to place individual tenants (customers) in different regions worldwide for compliance or latency reasons. You should be able to create the tenant database in any available location without worrying about the number of databases or the operational complexity. insert into tenants (name, region) values ('customer 1', 'aws-us-east1'); insert into tenants (name, region) values ('customer 2', 'aws-eu-west1'); Infrastructure placement You will want to place tenants in a multi-tenant or dedicated physical database. The decision for this will depend on the customer's needs, cost, and level of isolation needed. Typically, you would start to place all your customers in a multi-tenant database and then have the need to place some tenants on dedicated physical databases. insert into tenants (name, region, deployment_mode) values ('customer 2', 'aws-us-east1', 'dedicated'); The client should be able to route to the right tenant without any work from the user. Also, while providing all the placement flexibility, the magic lies in providing the ability to manage all these tenants in different locations and placements like a single Postgres instance. Here are a couple of examples where this will be useful: Make schema changes once, and the database should apply the change across all the virtual tenant DBs -- the bookings table where each row represents a single booking -- for a specific employee within a customer/tenant create table bookings ( tenant_id uuid, booking_id integer, employee_id text, flight_id integer, total_price float, PRIMARY KEY(tenant_id,booking_id)); Query across tenants for insights like a single database -- Calculates the total no of candidates per tenant that have -- applied for a job for a recruiting product. Can be used to define -- active tenants select t1.id as customer_id,t1.name as customer_name, count(c1.id) as no_of_candidates from candidates c1 right join tenants t1 on c1.tenant_id=t1.id group by t1.id,t1.name; First-class support for users The first basic primitive of a database built for SaaS is tenants. The second is users. Managing users in the context of tenants is complex, and having built-in support will make application development significantly faster. In addition, it will help to store user data in the database with strong consistency and correctness. Authentication should provide a suite of tools that makes it easy to drop in a form to get end-to-end authentication supported for tenants and users in minutes. This should support the entire lifecycle of tenant or organization management, including inviting users to an organization, deleting an organization that soft deletes the tenants in the underlying database, and providing overrides for each tenant to configure custom authentications. For permissions, basic enforcement of what data users get access to should be easier than it is today. When a user belongs to a specific tenant, access should automatically be restricted to other tenants. You don’t need application logic or complex SQL policies to enforce and maintain this. In addition, permissions should have a flexible language to help define fine-grained column-level resource permissions. The best part is that no instrumentations are required in code, which is often buggy due to the different paths that need to be secured. Instead, permission at source is the strongest security guarantee you can get. While the database should provide a fantastic solution out of the box, it should also be flexible for users to bring their own auth. This includes building your own authentication or integrating another third-party auth with the database. Great developer platforms can provide flexibility and let developers have finer control over how they want to build out their applications. Domain and tenant-aware AI-native architecture Every SaaS application will be an AI-native application like every software application was a SaaS-native application when SaaS happened. SaaS revolutionized how software was delivered. AI will revolutionize how software is experienced. AI for SaaS needs to be specific to the domain and tenant. For example, A corporate wiki (e.g., Confluence, Notion) where the employees can perform a semantic search on their company data A chatbot for a CRM (e.g., Salesforce, Hubspot) that sales reps can use to ask questions about past and future customer deals and can have a back-and-forth conversation An autopilot for developers in their code repository (Github, Gitlab) to improve productivity. The autopilot should run on the company's code as well, apart from learning from public repositories. A powerful architecture to achieve this is Retrieval augmented generation(RAG). The idea is to prevent large language models from hallucinating by augmenting the prompt with relevant context. This is usually done by converting the tenant's data set and the query to a common format called embeddings. The prompt issued by the user belonging to a specific tenant will be augmented with more context from that tenant's embeddings. This helps LLMs to be more contextual and also more secure. A database for SaaS should have native support for storing vector embeddings per tenant. It should also help store the metadata relevant to each tenant and the embeddings. Given Postgres is our choice, the pgvector extension combined with tenant virtualization would be powerful. create table wiki_documents(tenant_id uuid, id integer, embedding vector(3)); insert into wiki_documents(tenant_id, id, embedding) values ('018ade1a-7843-7e60-9686-714bab650998', 1, '[1,2,3]'); select embedding'[3,1,2]' as distance from wiki_documents; You get the following benefits with such a system: Embeddings and metadata computed and stored per tenant Embeddings and metadata are stored near the customer to speed up the first-byte response to a query HNSW and IVFLAT index support from pg_vector Unlimited scaling of embeddings since tenants can be distributed and sharded. HNSW is a pretty resource-intensive Purpose-built SDKs that integrate with LLM hosts such as OpenAI and Huggingface and vector embeddings. Serverless and cloud-native Serverless is how developers will adopt databases in the next decade. Before anyone jumps to say, “There is no such thing as serverless. There are only other people's servers”, the intent of using serverless is to define the experience developers get. It does not mean that the database is implemented without any servers! A database for SaaS should allow developers to focus on their queries, use cases, and core application logic. Developers don’t have to worry about managing capacity, the server configurations, or paying for capacity they don’t use. This gets even more complex if you want to manage multiple databases for each tenant. A database should let you have any number of virtual tenant databases but give you all the goodness of serverless. It should enforce price limits and ensure developers don’t get a sticker shock. The goal of serverless is to care about developers, which is exactly what it should do. The second thing is that the database needs to be built for the cloud. This means leveraging the native cloud infrastructure to build a highly scalable and elastic system. It makes sense to decouple storage and compute and push storage to cloud storage like S3. This helps to keep the compute stateless and makes it easier to scale them quickly. You still want to shard the tenants across databases and regions to provide placement flexibility (regional and infrastructure placement) and scale the storage as needed. Tenant-level insights and administration A huge part of building and running a SaaS application is to understand the growth and performance of each tenant and optimize it. This has been traditionally hard for SaaS. Most want a simple way to look up their active customers, users, and product usage to understand better how the different queries are performing for each customer. The database should have native support for this. Given it understands tenant boundaries, users within those tenants, and all the queries executed in that context, it would be trivial to show relevant insights to the developers. Developers should be able to understand the growth of the product, how the query performs for each tenant, and past trends. All the performance metrics, usage metrics, and even logs can be understood for each tenant. Postgres tools such as pg_stats, EXPLAIN, and ANALYZE should work and provide insights by tenant. World-class developer experience Databases still need to be made easier to use. While Postgres does a great job, there is still a lot of friction in the end-to-end developer journey to build SaaS applications with a cloud-native database. Developers should be able to test locally with the DB for a rapid feedback loop on their laptop, create test databases to apply schema changes, and then migrate to production. This whole experience should be integrated well with a change management system like GitHub. Lastly, ensuring a thriving developer community around the database is key to helping each other and learning quickly. And some more There are many more things I chose not to talk about now. Things like propagating real-time changes per tenant to the front end, supporting analytics to build data-centric applications, and leveraging usage data per tenant for monetization are all critical topics in building SaaS. The tenant virtualization is the basic building block. Many SaaS tooling and integrations can be built on this foundation to make it easy to build and scale the product. We would love to hear your feedback and thoughts about this on our GitHub discussion forum or Discord community. Nile - a company to accelerate modern SaaS Nile is a company that was started to make the database that I explained a reality. The mission of Nile is to enable developers to accelerate the next billion modern SaaS applications. What we will build at Nile will help accomplish this and truly change the future of SaaS. Nile will deliver on this promise. If you are building SaaS, we would love to talk to you. If you are an amazing engineer, we would love to have you join us in this mission. You can try out Nile by signing up for our waitlist today. We are onboarding new users every day. You can get started with one of our quickstarts. We also have templates and demos that will make it easy to get started. We would love to have you try out Nile, give us feedback, and help us build something truly world-class. If you need help, you can reach us on our GitHub discussion forum or our Discord community. Follow us on Twitter or Linkedin to get regular updates. We are building something truly wonderful and are excited about this journey! Talk to Us Email address How can we help? Send Message Postgres built for modern SaaS Join the waitlist Thanks for joining! We'll be contacting you shortly. or Contact Us Copyright © 2023 Nile Documentation Quick Start Blog About Pricing Contact Sales FAQ All Systems Operational ↗",
    "commentLink": "https://news.ycombinator.com/item?id=38014812",
    "commentBody": "Nile: Serverless Postgres for modern SaaSHacker NewspastloginNile: Serverless Postgres for modern SaaS (thenile.dev) 165 points by yarapavan 17 hours ago| hidepastfavorite112 comments hobofan 13 hours agoI&#x27;ve been interested to see what Nile will be since the Twitter pre-announcement, and: uff.The tenant capabilities are nice to have, but even when building a tenant-focused SaaS not really a big draw. The examples shown even come down to \"you can achieve 80% of this by just adding a tenant column everywhere\". When comparing this to e.g. Supabase, their autogenerated REST&#x2F;GraphQL APIs solve a lot more significant pain points, especially when starting out. reply infra_dev 12 hours agoparentSorry to hear that. We understand each one will have a different set of problems. From our experience and talking to others, it is usually not as simple as adding a tenant_id column. You typically care about security from day one and want to be really careful how you isolate customers. You would also want to add user and organization management easily to the product. We have made these steps really easy without having to spend time writing complex permission logic and potentially buggy code. We also are able to provide query insights by tenant since the database understands tenant boundaries. There are also other things that I have mentioned in the blog. Having said that, if our users want autogenerated APIs, we would be more than happy to invest in it. We did have plans for it but in our conversations most did not bring it up. Hopefully, we can convert you to love Nile as we grow. reply hobofan 11 hours agorootparent> You would also want to add user and organization management easily to the product.That&#x27;s usually something that I&#x27;d outsource as much as possible to Auth0 (yikes, considering the last days), as building out the UIs and state handling for all user auth and management flows is a huge chore. I think recently Clerk has set a new standard on how easy that can be. I&#x27;d be surprised if a database product could compete in a meaningful way in that area.I&#x27;m looking forward to see what Nile evolves to! (IIRC Supabase also didn&#x27;t look that enticing when it first appeared on the map). In general I&#x27;m really happy to see databases as such an active space of innovation again. reply mattashii 11 hours agoprevI wonder how this compares to e.g. Citus with some triggers and RLS on top.As this does regional accesses of shared and modifiable data, does Nile implement or guarantee snapshot consistency for cross-shard queries? Citus doesn&#x27;t have this yet, iirc.From the docs, I assume Nile does something like the following:- \"smart partitioning\" of tables on tenant_id when tenant_id is detected on table creation. These partitions are either region-local when the tenant is located in that region, or foreign tables. (Alternatively, non-local tenant data is replicated with e.g. logical replication&#x2F;LR, or triggers)- global tables are replicated across all regions, again presumably with LR- RLS on the smart partitioned tables, which applies the tenant filter when nile.tenant_id is set.Do you have any docs where I can read up on this in more detail?All in all this looks like a real neat project. Congrats on launching. reply endigma 15 hours agoprev\"Grow for years\" only really works if your SaaS also exists in years. I can&#x27;t imagine deciding to run a production DB with a custom RLS thing going on without being able to directly port that off-provider in a worst case scenario. Supabase sort of gets around this by being open source, but even then depending on their custom setup gives me a little anxiety. Not sure about other managed&#x2F;\"serverless\" Postgres. reply kiwicopple 14 hours agoparentIt’s worth mentioning that portability is one of our core Principles at Supabase too:https:&#x2F;&#x2F;supabase.com&#x2F;docs&#x2F;guides&#x2F;getting-started&#x2F;architectur...This is why we don’t run a fork of Postgres, and we lean heavily into extensions rather than customizations. As the docs mention: this forces us compete on experience.(Speaking here to your point about supabase, not to detract from Nile, which looks very cool) reply endigma 14 hours agorootparentI use Supabase at work for this reason, just not sure I&#x27;m _completely_ prepared to pick up and move to a non-Supabase PG if I really had to, which is a little unsettling for long term reliability. This is probably a me problem, you guys are doing great work on avoiding lock-in. reply kiwicopple 13 hours agorootparentI recommend complimenting the supabase tooling with “external” tooling - pgadmin, direct Postgres libs, etc. Even if you don’t migrate (which we hope you never do) you’ll definitely become more seasoned Postgres developer and you should find that we’re not doing anything too “magical”. Everything you learn with supabase should be transferable reply infra_dev 13 hours agorootparentprevHey kiwicopple, big virtual hi. I am a fan of your work. reply kiwicopple 13 hours agorootparentcongrats on the launch! reply infra_dev 15 hours agoparentprevNile CEO here. Nile will promise to make the experience of moving out of Nile really easy. This is one our core product principles. We want users to stay for the value we provide.Nile user permissions are optional. You can decide to use any third-party provider for it. We are in the design phase for permissions at this point. We would love to get your feedback to understand more about your concerns https:&#x2F;&#x2F;github.com&#x2F;orgs&#x2F;niledatabase&#x2F;discussions&#x2F;159 reply infra_dev 14 hours agorootparentI do also want to mention that we don&#x27;t fork Postgres. We have built tooling around Postgres using extensions and gateway layers on top of it. reply endigma 13 hours agorootparentThis doesn&#x27;t necessarily mean that any user could pick up and switch to a different PG instance, as such a young provider maybe look at having some docs for migrating off-platform as a sort of assurance. Maintaining those docs might also help you prevent adding or changing things that would introduce lock-in, it should be a consideration for every feature or API change. reply infra_dev 13 hours agorootparentAgree. We will prioritize how to migrate from Nile. At the Postgres level we don&#x27;t want any lock-ins. We would have APIs that simply SaaS workflows that users may choose to use. reply endigma 13 hours agorootparentprevThat&#x27;s good to hear, the last thing we need in software is more lock-in. reply saisrirampur 14 hours agoprevVery cool. This is Sai, ex-Citus and currently PeerDB. You are promising many features incl. region aware tenant placement, tenant level metrics, easy tenant isolation etc. which would really help multi-tenant SaaS customers. Back during my days at Citus, we spent many cycles to a build a database for SaaS. We built some (not all) the features you mentioned and saw customers really finding value.Congrats on the launch. I would love to try out Nile in the future! reply infra_dev 14 hours agoparentThanks sai. Great to hear from you! I have been following PeerDB and you folks are doing great work. reply jeroen79 16 hours agoprevWhat makes this serverless?, adding an extra \"tenant\" layer does not affect it being run on one or more servers. reply infra_dev 16 hours agoparentNile CEO here. Nile abstracts away compute machines and provides an experience where you can easily scale up or down based on the load you push.Specifically, Nile lets you do the following - Create a database and start querying it. Nile takes care of adding capacity to tenants as workload increases. - Pay for what you use. You will only pay for what you use. We have plans for pricing where you can pay based on usage per tenant. This will ensure your business value is aligned with the cost of your database. For example, a customer on your free tier may not be an active user and you would not pay for them in Nile. - We have built multitenancy into Postgres and a gateway layer that routes. This helps us to scale to zero with instant availability when you want to scale back up.- You can create even a million tenants if you have that many customers. - We have built connection pooling into Nile. This helps to provide limitless connections as you grow reply makoz 10 hours agorootparentDisclaimer work at AWS.I&#x27;m still trying to understand the scaling story better. When we say serverless it mentions automatically scaling when it detects some sense of resource pressure. If I have a \"hot tenant-database\", does that mean this shard will be scaled automatically without impact to existing queries? Or would there be some \"blip\". I suppose it&#x27;s unavoidable in edge cases but curious about the regular ones as well.It&#x27;s an incredibly cool CX you have here with the automated query routing&#x2F;tenancy story though, looking forward to what happens in this space. reply orliesaurus 15 hours agorootparentprevI thought Cassandra DB was a version of this, am I wrong? reply ranguna 2 hours agorootparentCassandrs is nosql, so I&#x27;m not sure how it can be a version of a serverless postgres provider. reply WendyTheWillow 15 hours agoparentprevI learned this probably later than I should have, but \"serverless\" now has two meanings.The first meaning I was familiar with was the idea that there was no long-running process operating a service. This was like a lambda, executing upon a trigger and then stopping.The second meaning I learned about more recently was the idea of \"serverless\" being an abstraction layer, where you don&#x27;t think about what server the service is deployed on (specifically, you get to stop caring about the resources allocated to that server), even though it is deployed as a continuous, long-running process. reply fidrelity 15 hours agorootparentSerious follow-up question: So the difference between &#x27;managed&#x27; and &#x27;serverless&#x27; databases is that for the former I know some level of infrastructure (CPU, RAM, size, etc.) whereas for the latter it&#x27;s completely hidden and priced in?I was also only aware of your first definition of serverless. reply gwen-shapira 15 hours agorootparentServerless isn&#x27;t just hidden and priced in - it is supposed to scale automatically with your use.AWS Lambda lets you think about \"invocations\" and not CPU and you trust that the CPU will show up when needed. At Nile we hope to let you focus on \"queries per sec\" and even \"queries per second per tenant\" while we scale the infrastructure as needed for you.Incidentally, our product has a dashboard that shows you exactly these metrics :) reply fidrelity 13 hours agorootparentBut in reality those limits don&#x27;t disappear, they just get buried deeper, hidden in the docs somewhere.AWS Lambda has a default concurrency limit of 1k and each function has a configurable memory limit.Sure, those limits allow for a lot more elasticity and flexible pricing but the limitations haven&#x27;t disappeared.Also, there are now some &#x27;serverless&#x27; hosting providers that do fixed monthly pricing (fermyon.com&#x2F;pricing). Isn&#x27;t this taking the best part of serverless ad absurdum or is there something I&#x27;m missing?Lastly, I hope I don&#x27;t sound argumentative. I work for a company that has the described problem of multi-tenant SaaS and I love Postgres, so I am fully supportive of your mission! reply mason55 15 hours agorootparentprevYes. If you look at, for example, Amazon&#x27;s offerings, this is how they use the terms. reply joshstrange 13 hours agoprevThe tenants concept is really cool and something I&#x27;m fighting with right now. I actually went single-tenant from day 1 (not exactly on purpose) and it&#x27;s a been a pain to find a DB solution that will work well for me.I absolutely love PlanetScale but having 1 database per client means paying for 1 plan per client. I&#x27;m B2B so I have way fewer \"clients\" but my load is incredibly spiky for each client (75% of the time they have near-0 usage, 20% of the time they have a tiny amount of usage, and the 5% they use a bunch). As it stands right now their heavy load never overlaps so I&#x27;ve been mulling over a move to an RDS cluster where I can run multiple databases on the same hardware.I&#x27;m not super interested in migrating to Postgres (though I think my app would move relatively easily, I don&#x27;t use anything super MySQL-specific, it&#x27;s just what I know) but I&#x27;ll be watching this project as it moves forward. I&#x27;d really like to not manage my own DB, it&#x27;s not where I&#x27;m strong and I&#x27;d rather focus on other things. reply infra_dev 13 hours agoparentSorry to hear your problems. We would be a great fit for your use case. We are serverless and support spiky workloads. You can map your clients to tenants in Nile. Let us know if anything changes on your side in the future. I would love to connect. reply mdaniel 15 hours agoprev> You can sign up for our waitlist today to try it out.I guess this gets a pass since it&#x27;s not a \"Show HN\" but that junk drives me crazy reply infra_dev 15 hours agoparentNile CEO here. I agree, and I am with you. I can vouch that this is not done with any malicious intent. We were not ready for HN yet but here we are. Our goal was to work with initial users to really polish the product before we open it up to everyone. We understand this would discourage some to not join and we hope to get them back once we are available for general availability. reply yencabulator 13 hours agoparentprevEven worse is the Github link to a practically empty repository. reply gwen-shapira 17 hours agoprevNile co-founder here :)Nice surprise to see our launch here. Happy to answer any questions... reply candiddevmike 17 hours agoparentAfter reading the landing page, I have no idea what I would use this for or what a tenant means. How do I manage my schema? How do I do migrations? Is this thing running all the time? What&#x27;s the tech stack underneath? reply infra_dev 16 hours agorootparentNile CEO here. Thanks for the feedback. Let me try to explain it a bit.Modern SaaS applications are multi-tenant. We’re the first database that virtualizes tenants into the database. A tenant is primarily a company, an organization, or a workspace in your product that contains a group of users. This enables seamless tenant isolation, per-tenant backups, and placement on multi-tenant or dedicated infrastructure, anywhere on the planet. You can do all this with the experience of a single Postgres! You don’t have to manage multiple databases, build complex permissions for isolation, or write buggy scripts to read specific tenant data from backups. On top of the tenant model, we provide opt-in user management capabilities, customer-specific vector embeddings, and instant tenant admin dashboards.You manage schemas like how you manage with standard Postgres. Your favorite tooling should work. When you make the schema change, Nile pushes the schema to all the tenants. For the user, it is like interfacing with a single Postgres instance.We have built a Rust based layer internally to manage tenants, route them, shard them if needed and have multiple tenants talk to each other. Happy to chat more. My email is ram@thenile.dev reply hathawsh 16 hours agorootparentCan some tenants stick to an older version of the schema while other tenants use a newer schema?Also, how is Nile different from creating a database (or several databases) for each tenant within a single Postgres cluster? reply gwen-shapira 14 hours agorootparentWe don&#x27;t have per-tenant schema right now, but we have started designing multi-version experience and it doesn&#x27;t seem too far from here.Nile is different from DB per tenant in a single PG cluster in that it is much lower overhead per tenant. Since we offer a service, it will translate to lower cost.The DB-per-tenant gets painful after the first few 100 tenants, but some SaaS have thousands of tenants, each with very low activity. Our model makes inactive tenants nearly free.In addition, we also provide the \"unified view\", which lets you query all your tenants as if they were in the same DB. So you can connect as an admin and \"select * from my_table\" will give you the results for all tenants. Can be pretty handy. reply hathawsh 14 hours agorootparentThanks. Good answers.What are you thinking will happen when a SaaS grows like Salesforce, with a very large number of tenants, where some of the tenants have very large databases? What will Nile do when the database just can&#x27;t fit in a single Postgres cluster?Edit: Never mind, I see from your web site that moving tenants between databases is one of the main things you try to address. reply drdaeman 16 hours agorootparentprev> Modern SaaS applications are multi-tenant.This is true in a sense “most modern SaaS apps have at least two unrelated users or user groups” (forgive me please if I’m wrong here, but that’s how I loosely understand “multi-tenant”), but it’s not exactly clear why this is important.I strongly suspect that the majority of modern SaaSes don’t do any database-level tenant isolation or per-tenant backups. The smaller the company the less it’s likely. Row-level security is a very rare sight to behold, even in regulated areas (certifications like HIPAA compliance don’t really require this). The best they do if they’re really global (I’m sure most are only global in “we accept users from anywhere”, but not so much under the hood - even though cloudy sales pitches love to paint a different picture, most SaaSes I’ve seen were one or two-region deployments) is try to move&#x2F;shard data closer to the the user’s region.I think one concrete example (as simple as possible) would help a lot. reply maweaver 15 hours agorootparentI think it makes more sense if you think of it in terms of \"B2B\" SaaS applications. Think selling a subscription to a medium-sized company, all in one geographical location, where data is shared between all users of that organization, and very carefully not shared outside of that group. For a more concrete example, think Salesforce.I&#x27;m not sure that I would generalize that to all modern SaaS applications though. reply infra_dev 14 hours agorootparentprevNile CEO here. Here are a few use cases that can help you. We believe SaaS is 95% of new companies today and it is very broadly applicable. Happy to chat further if interested1. GitHub helps a group of developers manage and deploy their code. Each Github organization is a tenant, and the developers within those organizations are users. 2. Salesforce or Hubspot helps sales reps manage their leads. Each company is a tenant, and the users are the sales reps. 3. Ring is a home security company that provides alarm services to different households. Each household is a tenant, and people living in a house using their service are users. 4. Toast is a platform to help build software for restaurants. The restaurants are tenants, and the employees of the restaurants are the users. reply yencabulator 13 hours agorootparent> 1. GitHub helps a group of developers manage and deploy their code. Each Github organization is a tenant, and the developers within those organizations are users.Nope, Github users exist outside of organizations in a global namespace, and can be invited to be members of multiple organizations. reply infra_dev 12 hours agorootparentYes, that is correct. In Nile, users are shared tables. They can belong to multiple tenants. In the case of the Github example, the organization is a tenant and users will be a shared table. Nile provides this out of the box. Will fix the usecase example to be more clear. replygwen-shapira 16 hours agorootparentprevIt is a Postgres, so schema and migrations work exactly as they would elsewhere.Tenants are your customers. It is normal for SaaS to have either a schema per tenant or one schema and tenant_id column in most tables. Nile provides you with both experiences at the same time. reply jadbox 16 hours agoparentprevAt first pass, I&#x27;m impressed with the multi region&#x2F;tenant built-in support. I take it that changing a region is as changing the table row key. I wonder though about this strategy strictly place user&#x27;s data as an entry into the data store... what if my users travel a lot between regions? Is the best strategy that upon user login to update their region in all their related tables? reply infra_dev 16 hours agorootparentNile CEO here. Nile provides tenant virtualization. Each tenant has a group of users within them. Typically, you would choose one location for a tenant. This will be based on your customer location. This would mostly stay the same. The users in a company could travel, but the choice of region is usually decided by where the company is located. Yes, you would be able to change the location of a tenant and the data will be moved to a new region but this usually happens if there is a major decision about location in a company. reply jadbox 16 hours agorootparent> This would mostly stay the same. The users in a company could travel, but the choice of region is usually decided by where the company is located.For most of my apps, I have very little idea on their region aside from their login IP origin, and we get a high level of multi-region travels (like conference organizers). I&#x27;d encourage you to transform the notion of a tenant transfers from a &#x27;major decision&#x27; to &#x27;assume users will&#x2F;should switch to closest tenant login&#x27;. It looks like your platform already allows this move-tenant-on-login approach, but I&#x27;d love to see more docs and more tests around that use-case. reply infra_dev 15 hours agorootparentCould you send me a note on ram@thenile.dev. Would love to understand your use case better. reply barnabask 15 hours agorootparentprevHow interesting. Does that mean the same is true for deployment_mode? As in, assuming &#x27;customer 2&#x27; was originally made &#x27;dedicated&#x27;, is this how we&#x27;d move them back to shared deployment mode? update tenants set deployment_mode = &#x27;shared&#x27; where name = &#x27;customer 2&#x27;;Does that mean some downtime or broken connections for that tenant while data is shuffled around? reply gwen-shapira 15 hours agorootparentOur goal is to make it transparent.The architecture includes proxy layer that handles routing and maintains the connections, so we believe broken connections are avoidable. reply gwen-shapira 16 hours agorootparentprevgreat point!If they travel a lot, you may want the data in one location (although it still depends, moving data is often faster than flying to a different region).Tenant placement is especially great if their location has data residency requirements. We discovered that companies with many EU customers need this. reply rkuodys 16 hours agoparentprevCool product if it works as promised with one caveat - I have saas app on django. I would happily migrate it from current setup to something that promises Tenant separation out of the box. But I&#x27;m not dropping the framework anytime soon. How will that work together? reply gwen-shapira 16 hours agorootparentOoh, yes! I need to get a Django and other Python examples going.With Flask it is fairly straightforward - you add the tenant configuration to the DB connection when you pick it up to serve a request. The Java and NodeJS examples do something similar if you need to see the idea. reply infra_dev 16 hours agorootparentprevNile CEO here. We work out of the box with Django. We are working on providing examples and tutorials for Django soon.We definitely want to play well with the ecosystem. reply pbowyer 2 hours agorootparentBe great to have an example for Symfony (PHP) and Doctrine ORM too. reply flashgordon 16 hours agorootparentprevGolang demos&#x2F;samples with Gorm&#x2F;Xorm please (pretty please)! reply gwen-shapira 16 hours agorootparentNoted :) I was checking out Xorm last night. It looks awesome! reply k4rli 15 hours agoparentprevI have no need for the product currently but website&#x27;s really nice with the black-white color schema; I rarely see a website that actually feels as nice. Can&#x27;t check currently on phone but this is probably nextjs underneath, right? reply gwen-shapira 14 hours agorootparentIndeed! How did you guess? reply brosciencecode 16 hours agoprevThis looks like an interesting take on serverless Postgres! Is this type of multi tenant separation enough for the kinds of users who care about it? I’d imagine a lot of the concerns around multi-tenant would be related to potential application layer bugs that can co-mingle data. reply manfromnowhere 16 hours agoparentData isolation, recovery, backups are a big problem in the world of SaaS, especially at huge scale. Companies end up hiring a dedicated infra team to handle such issues. reply theturtletalks 15 hours agorootparentMakes sense, but if you&#x27;re doing multi-tenancy, why not deploy a postgres database for each user so co-mingling is not even possible? That would make on-prem deployments easier to migrate to as well. reply randlet 15 hours agorootparent> why not deploy a postgres database for each user so co-mingling is not even possibleThis is the approach we took and I think it helps with IT review docs. reply infra_dev 14 hours agorootparentNile lets you do this without incurring the operational complexity of managing multiple databases. We let you place the virtual tenant DB either on one multitenant Postgres DB or a dedicated Postgres. So, you can actually create a dedicated one for each of your tenant in Nile but interact with them like a single Postgres instance. We take care of schema updates across them, client-side routing and metadata management reply randlet 14 hours agorootparent> We let you place the virtual tenant DB either on one multitenant Postgres DB or a dedicated Postgres.Sounds promising, but by \"a dedicated Postgres.\" do you mean a different server or just a different db on the same server? I&#x27;m trying to get at how the cost would change between the two solutions. Right now we can run N databases on the same Postgres server for roughly the same cost as running a single multitenant db. Switching to \"server per customer\" seems like it would be cost prohibitive. reply infra_dev 13 hours agorootparentWe are going to support a database in the same server initially but could also provide dedicated server in the future. The nice thing about Nile&#x27;s design is that we can provide different placements for different cost profiles with the developer experience of a single Postgres instance. reply randlet 11 hours agorootparentNice! Thanks for the response. replygolondon 15 hours agoprevJust for the tradition, I would like to leave a comment: \"I don&#x27;t see how this will work. There is nothing here you can&#x27;t do with Postgres schemas\" reply gwen-shapira 15 hours agoparentTechnically true, since we did all that with Postgres :) reply jxi 16 hours agoprevHow does this differ from Neon? reply infra_dev 16 hours agoparentNile CEO here. We do offer serverless Postgres but that is where the similarity ends.We’re the first database that virtualizes tenants into the database. This enables seamless tenant isolation, per-tenant backups, and placement on multi-tenant or dedicated infrastructure anywhere on the planet. You can do all this with the experience of a single Postgres.Here are some examples that can help you to understand the type of use cases. Most applications are multi-tenant and this is what we help with.1. GitHub helps a group of developers manage and deploy their code. Each Github organization is a tenant, and the developers within those organizations are users. 2. Salesforce or Hubspot helps sales reps manage their leads. Each company is a tenant, and the users are the sales reps. 3. Ring is a home security company that provides alarm services to different households. Each household is a tenant, and people living in a house using their service are users. 4. Toast is a platform to help build software for restaurants. The restaurants are tenants, and the employees of the restaurants are the users.Happy to chat more. My email is ram@thenile.dev reply kjfdslakj 15 hours agorootparentDon&#x27;t take this the wrong way, because I think serverless postgres is a major achievement. But would you say multitenant means use Nile, and for everything else, use neon? reply infra_dev 13 hours agorootparentIf you are building a static website (usually your website) or building a social networking product like Facebook, I would not recommend Nile. We recommend Nile for any usecase where you are serving multiple groups of users. In our experience, 95% of applications in the market today seem to fall into this category. reply niklearnstodev 16 hours agoprevHaving never worked on a multi-tenant SaaS app, is this how multi-tenancy is typically implemented (a per-tenant-database)? Is there a certain scale at which this becomes the ideal pattern? If so, has anyone made the shift from a single-database approach to a per-tenant-database approach? reply infra_dev 15 hours agoparentNile CEO here. There are many approaches to doing multitenancy. - You can create one physical DB per tenant - You can place multiple tenants on the same DBBoth approaches have pros and cons. This is exactly what Nile is solving. We want users to not worry about all the operational complexity of picking a choice. You can choose any approach in Nile.In Nile, the tenant DB is a virtual concept. You can choose to place it on a multitenant DB along with all the other tenants or choose to place it on a dedicated DB. Nile provides a single experience irrespective of your choice and takes care of all the operational complexity. We also go one step further and also let you place a tenant in any location worldwide but still have one Postgres experience.You can read more about it here https:&#x2F;&#x2F;www.thenile.dev&#x2F;docs&#x2F;tenant-management https:&#x2F;&#x2F;www.thenile.dev&#x2F;docs&#x2F;tenant-placementWould love the feedback reply manfromnowhere 15 hours agoparentprevNotion does something similar, sharding postgres grouped by their tenants. It takes a huge effort and preparation to get it right, both at the application and infra level. Link: https:&#x2F;&#x2F;www.notion.so&#x2F;blog&#x2F;sharding-postgres-at-notion reply gwen-shapira 15 hours agorootparentExactly that! Notion, Figma, Loom, Slack, Discord, Sentry have all been an inspiration toward the problem we are trying to solve. reply sb8244 15 hours agoparentprevI&#x27;d say it&#x27;s probably not the typical implementation. Mainly because it&#x27;s a pain to implement and manage.I guess that&#x27;s why this was created though. It&#x27;s definitely an intriguing tool.I did shift in past from single database to sharded via citus. The actual migration was smooth, but 6+ months of work went into ensuring compatibility.There&#x27;s ways to nearly guarantee compatibility without actually using a sharded approach, like enforcing all tables have a uniform shard key. reply niklearnstodev 15 hours agorootparentGood point, this product does make this approach far more palatable.Curious if the sharding strategy that you were shifting to was company-based, as is implemented in this case? reply sb8244 15 hours agorootparentYup! I lean towards a tenant ID approach. I ALWAYS use a library that enforces these tenant checks on queries. Ruby (https:&#x2F;&#x2F;github.com&#x2F;citusdata&#x2F;activerecord-multi-tenant) and Elixir (I wrote https:&#x2F;&#x2F;github.com&#x2F;sb8244&#x2F;ecto_tenancy_enforcer) are the ones I have experience with. reply randlet 15 hours agoparentprev> is this how multi-tenancy is typically implemented (a per-tenant-database)?There&#x27;s a few different approaches and deciding which to use can be tough. When I was adapting a formerly single tenant Django application to a multi-tenant solution, I went for a \"db-per-customer\" (with many databases on a single db server) for a few main reasons:1) Allows you to backup and restore databases on a per customer basis.2) Helps with IT reviews if you can say \"your data exists in its own DB and is not co-mingled with other customers data\"3) Implementation seemed like it was going to be simpler, especially for adapting an existing single tenant application to a multi-tenant one.4) Makes it easy to migrate existing single tenant-db&#x27;s to the multi-tenant app.The main drawback for us I would say is that it makes managing database migrations&#x2F;schema changes a bit more challenging since you now need to update N db&#x27;s every time there&#x27;s a schema change. This was not super difficult though.Overall I am very happy we decided to go with a multi-db multi-tenancy solution. reply e1g 15 hours agorootparentSame setup for us, as this is the only option for B2B&#x2F;enterprise products you have contractual obligations to delete all tenant data at the end of the term.Additional benefits: easy to support customer-managed encryption keys and can give their BI people direct access. reply notjoemama 15 hours agoparentprevYeah, worked in projects with both of those methodologies. Combining tenants in one database is good for cross tenant aggregation but causes people to reach for...> brittle permission logic at the application level or complex, hard-to-debug, row-level security policies in databases like PostgresSeparating them into separate databases has its own problems with connection pooling, resource management, and query speed. It&#x27;s also a pain when you have to combine the data. Then you go down the rabbit hole of ETL and SaaS products with a \"scratch\" interface that promises to speed things up through (yet another) customer DSL and new naming convention for everything you already know.A better option is separating tenants by schema. Think about how you switch between schemas in Postgres. Queries look something like this:> set search_path to public, tenantA; > select * from somewhere as smw inner join elsewhere lsw on smw.id = lsw.somewhere_id;The somewhere table is in the public schema, elsewhere is in the tenantA schema.In Rails, there are a couple gems that come to mind for multi-tenancy. acts_as_tenant works exactly like this, by swapping the tenant schema in ActiveRecord (the Rails ORM layer). The ros-apartment gem is another (formerly just &#x27;apartment&#x27;). I ran across another gem called &#x27;roomer&#x27; too but it is outdated. It works the same way though. You could even roll your own if you insert the logic at the right layer of whatever stack you&#x27;re using.Set the tenant at the request level and the ORM auto switches the schema for you. Match a subdomain to the tenant and away you go. You got a SaaS application. edit: And, it&#x27;ll pass a security audit because of the separation. And you can query across LOB tenant data in a BI front end if you can live without real-time data and build some materialized views; if Redshift and Snowflake are just too expensive.Using schema separation you get the best of both worlds; smaller data in tenant specific tables with the ability to cross tenant query because they&#x27;re in the same database. And yes, I&#x27;m well aware foreign servers are a thing in Postgres but with sufficiently large data you have to spend more time tuning them for fetch size and indexes to get decent performance. Forget the fact that sometimes you have to implement dynamic SQL using SQL which is a nightmare of repetitious quotation marks with any complex data structure. Foreign servers amplify the escaped quotes. My stomach turns remembering having to write that code...Is there a npm package for something like this? React&#x2F;node is not my daily driver. reply gwen-shapira 14 hours agorootparenthey :) I also like Rails acts_as_tenant. We searched far and wide for something similar for JS ecosystem and so far, didn&#x27;t find anything.We build our JS SDK by wrapping Knex (nice query builder, not quite an ORM) and injecting our logic to the connection process. You could do the same.The issue is that there are at least 5 popular JS ORMs, so we don&#x27;t get the same solve-it-once that we get in the Rails ecosystem. reply api 15 hours agoparentprevSometimes it is. Often it&#x27;s done in the database itself, but then you have to be very careful you never have a query that returns data that belongs to someone else. reply KRAKRISMOTT 15 hours agoprevWhat&#x27;s the cold start time like? Neon&#x27;s performance is horrible. reply mj4e 12 hours agoparentHave you tried Neon recently? There were some big improvments rolled out in the late summer - https:&#x2F;&#x2F;neon.tech&#x2F;blog&#x2F;cold-starts-just-got-hot reply tristan957 13 hours agoparentprevWhat cold start times have you experienced? I work at Neon, so I&#x27;m more than happy to pass along your experience if you want to share it with me. You can email me at tristan at neon.tech. Or you can reply here. reply infra_dev 15 hours agoparentprevNile CEO here. You can place tenants on multitenant DB or a dedicated Postgres DB. Placing the tenants on multitenant DB is the default. This has no cold start time since the instance&#x2F;container is shared. If you choose to place a tenant on a dedicated tenant DB, you would have cold time of a few seconds. We are building this as we speak and will have more numbers to share soon. However, if you have chosen to place a tenant on a dedicated DB, these typically would be critical customers who are actively using the DB and may never want the instance to go down. We are exploring provisioned compute tokens for this purpose. reply pier25 14 hours agoprevDoes this support listen&#x2F;notify, PG extensions, etc? reply infra_dev 14 hours agoparentWe do plan to support a bunch of extensions soon. We do support pg_vector at this point. Would love to know if you have any favorite ones. Also, could you share the use case for listen&#x2F;notify? We currently do not support it but have plans for something that gives you the same functionality. reply pier25 11 hours agorootparentAs far as extensions I think postgis should be pretty much a default in all PG installations these days.I use listen&#x2F;notify and triggers as some sort of pubsub. reply bob1029 16 hours agoprevWould it be fair to compare this to things like Azure SQL Server Hyperscale architecture? My first impression of the docs indicates this is a similar idea but for Postgres. reply infra_dev 15 hours agoparentAzure SQL Server Hyperscale architecture gives you plenty of scale but does not do anything to help with managing tenants.I will explain what Nile tries to do. Happy to follow up.The most foundational element in SaaS is a tenant. It makes a lot of sense to build this core concept into the database. Imagine having a lot of virtual tenant databases that can be co-located on one physical Postgres (multi-tenant) for better cost, and some of them can be placed on a dedicated database for better isolation. The virtual tenant DBs can be located anywhere on the planet for low latency or compliance. The client can route to the right tenant seamlessly without routing logic in the application.Isolating tenants into their own virtual DBs is great, but you will also want to be able to share data across tenants where it makes sense. Backups should be available for each tenant, and it should be possible to restore them instantaneously. Schema changes should be applied seamlessly across all the tenant DBs, and it should also be possible to do staged rollouts for different tenant tiers. While supporting all this, all the standard SQL capabilities should work across the tenants for admin operations. All the standard Postgres tooling should work. You want the experience of a single Postgres.This is what Nile tries to achieve. A model that gives you fine-grained control over your tenants. You create, scale, locate, pay all by tenants. reply beoberha 15 hours agoparentprevThey don’t seem to get into their architecture under the hood. The novel aspect seems to be that they have tenants as a first class member of the database reply rsweeney21 14 hours agoprevIs there a mechanism for replicating shared&#x2F;system data across tenants? Can I deploy into a specific AWS or GCP region? reply infra_dev 14 hours agoparentCurrently, we support only AWS but do want to support other cloud providers. Technically, you can even have one DB that spans across cloud providers with your tenants, but we have not yet seen many use cases for multi-cloud.W.r.t replicating data across tenants, could you give an example use case for it? reply rsweeney21 13 hours agorootparentLet&#x27;s say I&#x27;m building a CRM and I want to have an \"industry\" or \"cities\" table that is the same across all tenants. I want a copy of cities in each tenant for referential integrity, but I also need to update it periodically across all tenants. reply infra_dev 13 hours agorootparentGreat question. Nile supports shared tables for this purpose. Shared tables are regular tables that can be shared across all the tenants in another table. We have example use cases and how this works in Nile here https:&#x2F;&#x2F;www.thenile.dev&#x2F;docs&#x2F;tenant-sharing. Let me know if this works for you. reply rsweeney21 12 hours agorootparentThat sounds like exactly what I was looking for. Impressive! replyjroseattle 16 hours agoprevHow would I incorporate Nile into a disaster recovery or failover plan? reply flashgordon 16 hours agoprevThis is brilliant. Founders are top notch. They truly understand control plane development needed for true regional services. Cant wait to see more of this! reply manfromnowhere 16 hours agoprevHow does the vector embedding work? Do you store the embeddings per tenant and let the application search for it? reply infra_dev 16 hours agoparentNile CEO here. Yes, you can store embeddings per tenant and search for it. You can read more about vector embeddings and how we support it here https:&#x2F;&#x2F;www.thenile.dev&#x2F;docs&#x2F;ai-embeddings reply sgammon 16 hours agoprevLove Nile!! We worked with their team on a project last year. I absolutely cannot say enough about how great they are.If you are building multi tenant saas you should totally look at them!! reply kjfdslakj 16 hours agoprevAnyone use this and and the incumbent neon.tech? reply swyx 14 hours agoparentneon and supabase are both the up and comers in the postgres world i think. the real incumbents are the AWS RDSes of the world and their azure and gcp equivalents. reply jmtucu 15 hours agoprevDoes it work with Drizzle ORM? reply gwen-shapira 15 hours agoparentWe don&#x27;t have an official example yet, but I expect it will work. So far every JS framework that uses https:&#x2F;&#x2F;node-postgres.com works great and so no reason to think Drizzle wouldn&#x27;t. reply iFire 16 hours agoprev [–] Code is not released.LICENSEApache-2.0https:&#x2F;&#x2F;github.com&#x2F;niledatabase&#x2F;niledatabase&#x2F;blob&#x2F;main&#x2F;LICEN...Edited:This is the docs repo. reply infra_dev 16 hours agoparentNile CEO here. Yes, this is docs, examples and our website right now. Our background is in open source for the last 15 years. We helped build Apache Kafka and grow the community to a very successful one. We believe open source should be done well and hope to consider it once we have the bandwidth to provide DIY ways to run Nile. reply benpacker 16 hours agoparentprev [–] This is the docs repo replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Nile, a serverless Postgres database, is designed for SaaS applications, seeking to simplify development and scaling by providing tenant isolation, per-tenant backups, and a serverless experience.",
      "It features an emphasis on virtual tenant databases for data isolation across different customers and includes functionalities like routing queries to correct tenant databases and sharing data between tenants.",
      "Nile is AI-native and provides first-class support for user management within the context of tenants, with in-built authentication and permissions management. It offers resources for users and encourages a thriving developer community."
    ],
    "commentSummary": [
      "Nile is a serverless Postgres database tailored for modern SaaS (Software as a Service) applications, offering multi-tenancy, routing capabilities, and tenant virtualization for enhanced scalability.",
      "Nile emphasizes portability and easy migration, providing preventions against vendor lock-in. It allows for meticulous control over tenants and includes shared tables for data replication.",
      "As of now, Nile is only available via documentation and examples, with the potential of a Do-It-Yourself (DIY) option from the company in the future."
    ],
    "points": 165,
    "commentCount": 112,
    "retryCount": 0,
    "time": 1698252355
  },
  {
    "id": 38013955,
    "title": "SpaceX Starship Super Heavy Project at the Boca Chica Launch Site",
    "originLink": "https://www.faa.gov/space/stakeholder_engagement/spacex_starship",
    "originBody": "Access Denied You don't have permission to access \"http://www.faa.gov/space/stakeholder_engagement/spacex_starship\" on this server. Reference #18.beb42d17.1698315494.4f800d91",
    "commentLink": "https://news.ycombinator.com/item?id=38013955",
    "commentBody": "SpaceX Starship Super Heavy Project at the Boca Chica Launch SiteHacker NewspastloginSpaceX Starship Super Heavy Project at the Boca Chica Launch Site (faa.gov) 167 points by peter_d_sherman 18 hours ago| hidepastfavorite522 comments perihelions 17 hours agoStarship is awesome. It&#x27;s the most capable and sophisticated rocket ever built. It&#x27;s a major asset to the US military and its future capability. It has very significant launch safety issues in its current state. FAA enforcement is generally reasonable; they&#x27;re professional and competent.I don&#x27;t know why this topic polarizes people to such an extreme degree. reply jiggawatts 9 hours agoparent> I don&#x27;t know why this topic polarizes people to such an extreme degree.Because some people are so rabidly anti-Elon that they would rather nail the feet of the human race to the ground than allow that \"bad man\" to succeed at taking us to the stars.There were several people here on HN screeching that a few lumps of concrete strewn on a beach is an ecological disaster of unfathomable proportions.Don&#x27;t forget about the astronomers complaining about the global internet being provided by Starlink affecting their precious telescopes, while ignoring the minor detail that Starship will be able to launch a JWST-sized telescope weekly if they want to get above the atmosphere.We can&#x27;t have the future because it slightly inconveniences the present and ruffles the feathers of developers fired from Twitter. reply akira2501 1 hour agorootparent> would rather nail the feet of the human race to the ground than allow that \"bad man\" to succeed at taking us to the stars.This type of false equivalence and extreme hyperbole is why it polarizes people. The preferred terms of the conversation are so insane as to invite that specific outcome.> affecting their precious telescopesYou also seem to feel entitled to adopt the position of a rank bully. Where does this entitlement come from? While reflecting on that, you might find a more charitable and honest answer as to the sources of polarization on this topic.> We can&#x27;t have the future because it slightly inconveniences the present and ruffles the feathers of developers fired from Twitter.We&#x27;ll have the future with or without Space X. This type of angry hype and blind argumentation simply underscore the above points. reply somenameforme 51 minutes agorootparentMeaningful progress in space exploration and rocketry, prior to SpaceX, was negligible. There was no real motivation to try to lower prices, let alone meaningfully advance technologies, for aerospace companies headed by MBAs and motivated exclusively by profit, all with a defacto monopoly in launches. And there&#x27;s every reason to think that without SpaceX we would still be on that trajectory.As for the future... SpaceX has certainly inspired a large number of companies looking to try to emulate it success, but none have really managed to achieve anything comparable to increasingly dated SpaceX tech at this point, let alone where SpaceX is taking us with technologies like the Starship. So with this I think there&#x27;s also a reasonable fear that without SpaceX we&#x27;d relapse back into the past since 1972, in terms of space progress - which is to say near zero.One really cannot overstate the impact that SpaceX has had on space in the past, is continuing to have on space in the present, and will almost certainly continue to have in the future. That people want SpaceX to fail, and imperil all of this, just because they don&#x27;t like somebody they don&#x27;t even know, is such a terrible reflection on the state and motivations of society today. reply hef19898 46 minutes agorootparentSpace exploration, sending vehicles to asteroids and meteors, Mars...., did just fine without SpaceX. Maybe SpaceX made the launches for those a tad cheaper, but launch costs are far from the most important cost factor for those missions.Which leaves rockertry. Reusable rockets are quite an achievement, sure. So far the real world impact is limited to satellite internet, which is not available globally yet.Starship still has to be launched successfully to count as rocketry advancement. reply tw04 9 hours agorootparentprev> We can&#x27;t have the future because it slightly inconveniences the present and ruffles the feathers of developers fired from Twitter.Or because he constantly stomps on experienced engineers with stupid ideas and puts the whole thing at risk. Literally EVERYONE said the cement base was a stupid idea and yet Elon had to trump his own experts.Every time he forces his idiotic ideas on his engineers he puts the future of the whole business at risk. At least he’s been so distracted by the Twitter debacle the adults have been able to make decisions without having to cater to his ego and make him think the idea was his. reply kcplate 7 hours agorootparentI can literally watch SpaceX fire rockets into space 3-4x a month from my backyard.Name one other company, person, or even a country that can and is willing to do that. There are none. As long as SpaceX can and no one else can, the future of SpaceX is on a pretty sound footing in my opinion. reply ben_w 42 minutes agorootparentI&#x27;m all in favour of SpaceX having an engine-rich development cycle that gets things done faster and cheaper than anyone else, this doesn&#x27;t mean Musk is doing everything right.I&#x27;m sad about the interference that Starlink causes to ground based astronomy, this doesn&#x27;t mean Musk is ignoring those issues.And I value government agencies making sure that business interests are balanced against democratic will of the people, that doesn&#x27;t mean they&#x27;re funded at the right level for a rapidly growing industry. reply lancewiggs 5 hours agorootparentprevRocketlab is doing this at about half the rate. reply kortilla 5 hours agorootparentNo it’s not, it’s not even making 1 per month. reply nickik 4 hours agorootparentprevNot even close, and doing it with a tiny 100kg rocket isn&#x27;t even remotely the same thing anyway. reply m4rtink 1 hour agorootparentNot to mention it does not even have a reusable booster (yet) and unfortunately there seem to be still some reliability issues as well. reply soperj 6 hours agorootparentprev> Or because he constantly stomps on experienced engineers with stupid ideas and puts the whole thing at risk. Literally EVERYONE said the cement base was a stupid idea and yet Elon had to trump his own experts.Wouldn&#x27;t that be called working from first principles? Proving it doesn&#x27;t work can be quicker in the long run than over-designing something based on what you think won&#x27;t work. reply hef19898 43 minutes agorootparentThat is why I hate people working from first principle so much: The intentionally ignore decades and centuries of knowledge and experience in fields they don&#x27;t understand and refuse to accept the fact the resulting failure is their fault. They are very, very quick to claim success so everytime they get lucky and their hairebrained ideas work (mostly only once). reply tigershark 5 hours agorootparentprevYou don’t need to work from first principles to understand that the most powerful (by far) rocket built would obliterate whatever concrete you use without an appropriate water deluge system and&#x2F;or flame trench. reply ben_bai 1 hour agorootparentAnd now they have to repair the launchsite, which they already did. And add water deluge, which they already did.The upside was they got lots of data to improve the next rocket, which they already did. It&#x27;s ready to go again, just waiting for FAA approval. reply kortilla 5 hours agorootparentprev> Literally EVERYONE said the cement base was a stupid idea and yet Elon had to trump his own experts.Even Elon said this. It was a gamble, it didn’t pay off. reply hef19898 42 minutes agorootparentAnd those gambles make Elon a bad engineer, if one at all. reply d-z-m 7 hours agorootparentprev> Literally EVERYONE said the cement base was a stupid idea and yet Elon had to trump his own experts.Do you have more information on this? My quick googling turned up nothing. reply almost_usual 7 hours agorootparentThis submission was flagged on HN but it was pointed out.> In addition to the siting and sizing of the pad, SpaceX does not have a flame trench, nor do they have a water deluge system used to suppress heat and sound energy from any launches, as the Army Corps of Engineering permitting required to add these civil engineering systems is itself a multi-year process.> No large rocket complex on the planet: not in Russia, nor China, and certainly not in the US, exists that doesn’t contain one or both of these energy suppression systems.https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=35590279https:&#x2F;&#x2F;blog.esghound.com&#x2F;p&#x2F;spacexs-texas-rocket-is-going-to reply Animats 6 hours agorootparentBoca Chica now has a better launch pad with a flame deflector and a water deluge system.[1] They really needed that. The first version just fired the entire output of the booster at a flat concrete slab, which destroyed the pad, sending chunks of concrete into the ocean and around the area.[1] https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=LYRJn3uvw3M reply skellington 5 hours agorootparentprevSpaceX said it was more a question of timing. That the water system would take too long and they were hoping to test before it was fit. The first test involved a subset of all the engines so they hoped the concrete would survive. reply brandonagr2 6 hours agorootparentprevYou sound like you don&#x27;t know anything about what actually happened or the SpaceX engineering process in general.SpaceX knew that the concrete wasn&#x27;t the final solution, it was always temporary, they had already started building the steel water cooled plate before the first test flight. Based on the data they had available from the series of static fire tests leading up to the test they thought the concrete would ablate and survive one test flight before they took the downtime to replace it. Do you have any evidence to support your assertion that Elon overruled all the SpaceX engineers on the timing of when to install the steel water cooled plate or are you Literally making things up?Learning more by moving quickly and taking calculated risks is clearly the better approach, as evidenced by the current dominance of the Falcon 9 and SN 25 and booster 9 sitting on a repaired OLM and being scheduled to make another orbital attempt in less than 2 weeks. reply kasdi 2 hours agorootparent> Do you have any evidence to support your assertion that Elon overruled all the SpaceX engineers on the timing of when to install the steel water cooled plate or are you Literally making things up?Unfortunately, #LiterallyMakingThingsUp seems to be a trend these days. reply fomine3 4 hours agorootparentprev> Learning more by moving quickly and taking calculated risks is clearly the better approach,I think most people agree that it&#x27;s better for SpaceX business, but some don&#x27;t agree that it&#x27;s worthwhile for our society with what happens if failed. It&#x27;s like Tesla&#x27;s \"FSD Beta\" situation. reply renewiltord 5 hours agorootparentprevBizarre that the most accurate take here is greyed out. Absolutely correct. reply skellington 5 hours agorootparentprevYou&#x27;re only being downvoted because of your accuracy. reply nickik 4 hours agorootparentprevYes and he has often overruled his engineers and was right. Taking calculated risk to shorten development is reasonable. Even if you don&#x27;t get it always right.> Literally EVERYONE said the cement base was a stupid ideaThey expected it to break but be ok for one launch. Its a reasonable risk to launch sooner.> Every time he forces his idiotic ideas on his engineers he puts the future of the whole business at risk.And yet the he has lead the business for 20+ years and the company has been getting more and more and more successful. I guess that just happens by magic.> At least he’s been so distracted by the Twitter debacle the adults have been able to make decisionsWhen SpaceX does good its because Musk wasn&#x27;t there, when it does bad its because of Musk. Classic. reply wnkrshm 2 hours agorootparentI wonder why Musk is always thrown into the ring with SpaceX, when its entire operation is mostly done by Gwynne Shotwell. reply zpeti 1 hour agorootparentBecause Elon is the product lead (and founder and owner), Shotwell does the business development.Product is way more interesting in this case than BD, considering it&#x27;s the most badass rockets ever made. But feel free to praise Shotwell too, that&#x27;s great too. reply hef19898 41 minutes agorootparentYou really think Elon is anymore than Product Lead &#x2F; Chief Engineer in title? reply madaxe_again 3 hours agorootparentprevThag make round rock. He call “wheel”. Thag idiot. No need round rock wheel thing in cave.Sometimes you do something against conventional wisdom, and people call you a genius. Sometimes it doesn’t pay off.I am assuming that you are employed, rather than an employer. reply Lewton 2 hours agorootparentprevDo you have to put \"bad man\" in quotes? It&#x27;s possible to respect his achievements without lionizing the personHe&#x27;s legit terrible as a person, someone who spends a significant amount of his time dedicated to trolling is not someone we should look up to reply okr 2 hours agorootparentA person trolling is a person with dark humor. I like persons with dark humor. These persons tend to be warm and humane as well. Dark humor comes from experiencing life kicking you in the guts early enough, so that you can start to joke about it. It&#x27;s all a joke, but make the best out of it. reply Gasp0de 46 minutes agorootparentHe&#x27;s a narcissist who also happens to be a right wing extremist though. And even if it was all a joke, through his position he has a huge influence on politics and a lot of people and it would be extremely irresponsible to make such jokes.However, no matter how much I dislike the person I do appreciate the achievements at PayPal, Tesla and SpaceX in which he took part. reply hnbad 50 minutes agorootparentprevThe difference between dark humor and trolling is that trolling punches down. I still enjoy some dark humor but my taste for trolling has massively decreased since I grew out of being an angsty self-hating teenage boy who thought misanthropy made me smarter.Yeah, no, trolls don&#x27;t tend to be warm and humane. Trolling is the opposite of that actually. And it usually stems from cowardice because sincerity makes you vulnerable and that takes courage. reply tibbydudeza 2 hours agorootparentprevHe acts out his irrational fears and amplifying it because of his wealth and social media.But he gets a special pass from his little cult for being homophobic and having racist overtones. reply ethanbond 7 hours agorootparentprevIs launch capacity the thing that holds back more space-based telescopes, and are those telescopes going to have the same availability to researchers as terrestrial ones?If either answer is no, then the brag about capacity isn’t really relevant. reply lmm 5 hours agorootparent> Is launch capacity the thing that holds back more space-based telescopesEverything holds back more space-based telescopes - launch capacity, manufacturing capacity, research ideas. But the cheaper launching becomes, the more funding can be devoted to other parts (although something like Amdahl&#x27;s law will apply), and may even trigger a virtuous cycle where cheaper launches mean you can get away with more standardised, less hardened hardware, which in is then lighter and can be launched more easily, and...> are those telescopes going to have the same availability to researchers as terrestrial ones?No, of course not, space telescopes are massively oversubscribed and difficult for even superstar researchers to get time on. That&#x27;s exactly why we want to launch more of them. reply ethanbond 5 hours agorootparentRight so basically “we’ll maybe have more space telescopes someday” is not actually relevant to “you are effectively destroying terrestrial telescopes today.” reply radu_floricica 4 hours agorootparentYou managed to get exactly the opposite conclusion from what the parent said. This exchange should be on the wikipedia page for \"confirmation bias\". Funny af, honestly.Just for fun: what exactly could the parent have said to change your mind? Because if the answer is \"nothing\", then you&#x27;re a rock. reply soperj 5 hours agorootparentprevWhen you can design space telescopes to be heavier, and they don&#x27;t cost as much to launch, then you can design them cheaper. If one fails then you can more easily replace it. Initial designs of the James Webb began in 1996 and it didn&#x27;t launch until 2021 and cost $10 billion. If they could use more off the shelf parts and didn&#x27;t have so many design constraints it would have been quicker and cheaper. reply ethanbond 5 hours agorootparentNone of which is relevant to astronomers who depend on terrestrial telescopes to do their work today, so it’s not really a meaningful response to their complaints. reply nickik 4 hours agorootparentI&#x27;m so sick of people acting like Starlink is the end of terrestrial telescopes. Fucking insane. Actually inform yourself. A very low number of terrestrial telescope sometimes lose a slight amount of information. Terrestrial astronomy is fine and will continue to be fine. reply fastball 7 hours agorootparentprevAbsolutely launch capacity is holding back more space-based telescopes. More telescopes means more availability to researchers. reply ethanbond 6 hours agorootparentSure, in the same way that Ferrari doubling its production means more people can get their kids to school conveniently. reply jbm 6 hours agorootparentIsn&#x27;t Starship the cheap option for orbital launch? reply ben_w 35 minutes agorootparentIt&#x27;s a steam-liner in an age of sailing galleons, hopefully it will make an orbital ring (analogous to budget airlines) affordable. reply ethanbond 5 hours agorootparentprevBut the whole point is if you ruin thousands of terrestrial telescopes used (successfully) by thousands of researchers, and in exchange you get a promise of one day maybe having tons of orbital telescopes, you aren’t really addressing the concern. reply zpeti 1 hour agorootparentCome on, you are arguing in such bad faith its ridiculous. Everyone knows space based telescopes are orders of magnitude better, and will be better for research than thousands of earth based telescopes.Even the researches, unless very selfish, should know that ideally you want many more very powerful space based telescopes if you actually want to do research and not just marvel at the stars from your patio.We obviously want larger launch capacity in the long run. It&#x27;s not even a question. Falcon 9 is already the most successful rocket ever on almost all stats of usefulness, why shouldn&#x27;t we have at least SOME faith that spacex will be able to build starship and use it? reply theodric 1 hour agorootparentprevIn this case, Starship is really more akin to a bus than a sports car reply fastball 5 hours agorootparentprevI don&#x27;t think I understand the analogy. reply ethanbond 5 hours agorootparentAdding capacity at the tippy top of the market, while destroying capacity at the much larger middle&#x2F;bottom of the market, is very unlikely to be net positive. reply fastball 4 hours agorootparentGotcha, a couple points:- Starlink interferes with terrestrial telescopy much less than the baseline issues such as weather, atmosphere, etc.- SpaceX has already done great work in ameliorating these issues anyway with better non-reflective coatings and design.- Telescopes in space are orders of magnitude more useful than terrestrial ones, so it would not be a surprising net positive at all.- Even if the previous point weren&#x27;t true, telescopes are not really equivalent to taking kids to school. One is a necessity, the other is a nice to have. The truth is that most of the low-hanging astronomical fruit that can be gleaned from the \"middle&#x2F;bottom of the market\" has already been picked anyway. Almost all new&#x2F;significant astronomical discoveries&#x2F;research are happening with space-based telescopes for exactly this reason. People aren&#x27;t unraveling the secrets of the universe with a telescope in their backyard anymore.- This entire situation has really nothing to do with Starship being a good thing. You can argue that Starlink is a net negative (for all the above reasons this seems hard to justify in practice), but that argument is orthogonal to whether or not Starship is good. This isn&#x27;t really your fault because the parent comment is the one that initially conflated the two, but I felt this point should be made. replypeyton 7 hours agorootparentprevYou could probably do a swarm type of telescope. I thought the limiting factor with JWST was expertise. reply nesyt 5 hours agorootparentprevRadio telescopes often are much larger than JWST and&#x2F;or are interferometric arrays, which in either case remain impractical to deploy to orbit. reply shiroiuma 16 minutes agorootparentThey should be building those things on the far side of the Moon instead. Radio telescopes suffer from interference from terrestrial radio sources, which is why they locate them in the middle of nowhere, West Virginia, but even that doesn&#x27;t fully isolate them. Putting them on the far side of the Moon would (at least for a while) completely eliminate problems with terrestrial interference, plus give humanity a good reason to back to the Moon and build some serious infrastructure there, and perhaps also distract us from fighting with each other so much. It would also give many engineers something much more important and useful to work on than ad-ware. reply bandyaboot 8 hours agorootparentprevPolarization is characterized by people being driven to opposite extremes. That fact that you explain it exclusively in reference to just one of the extremes tells me you occupy the other. reply davidmurdoch 7 hours agorootparentNon-polarization is a thing. So is circular. reply mensetmanusman 7 hours agorootparentprevStaying put is also polarizing. reply ordu 2 hours agorootparentprev>> I don&#x27;t know why this topic polarizes people to such an extreme degree.> Because some people are so rabidly anti-ElonYou know, polarization takes at least two poles. If some people are rabidly anti-Elon, so some people are rabidly pro-Elon.> Don&#x27;t forget about the astronomers complaining about the global internet being provided by StarlinkThey do not complain about the global internet. They have nothing against the global internet per se. They complain about satellites. There are no fundamental physical laws stating that the global internet comes with littering the sky with thousands of bright satellites. They can be less bright at least, or probably one can use some military expertise on making flying objects undetectable by any means. Then come costs&#x2F;benefits analysis and the question becomes too difficult for an armchair experts to grasp. So they instead prefer to construct a strawman they feel comfortable to fight.When you allow yourself to use such a rhetoric devices, you shouldn&#x27;t be surprised when the other side becomes polarized. They reciprocate and then you feel the right or even an obligation to throw some more shit into your discussion, and then you have no chance for a meaningful discussion. reply lm28469 1 hour agorootparentprev> than allow that \"bad man\" to succeed at taking us to the starslmao, we managed to fuck up our very own perfect planet in 200 years of industrial revolution and the plan is to go transform a dead rock into earthElon or others I&#x27;ll still find it stupid, this isn&#x27;t minecraft> We can&#x27;t have the future because it slightly inconveniences the presentIt&#x27;s more like the present is (more than) slightly inconveniencing our future, and ego maniacs like Musk are a big part of the problem reply tibbydudeza 2 hours agorootparentprevWell safety comes first - this let&#x27;s try it in production and see if it works for software - so a portion of youtube barfs - nobody harmed except missing their favourite cat vidoes.The same with the FDA - we don&#x27;t want a repeat of Thalidomide babies do we ???. reply pstuart 9 hours agorootparentprevThere&#x27;s another duality of thought: I want SpaceX and Tesla to succeed. Regardless of my feelings about him, I acknowledge that Elon was instrumental in sparking the shift to EVs. Also, that having a dictator with a vision can allow companies to do audacious things that would normally die in committees (like reusable rockets, etc...)That said, I have nothing but contempt for the man and am petty enough to have schadenfreude in any of his personal comeuppance. reply dcormier 7 hours agorootparentI have enjoyed watching a new launch provider emerge, EVs become a real thing, and him being forced to buy Twitter. reply pj_mukh 6 hours agorootparentprevI think this is only complicated because people aren’t able to hold competing thoughts in their heads.There was a man who was massively effective in getting multiple once-in—a-generation revolutionary companies of the ground by sheer grind and lots of luck (yes..both). We should thank that man of yore.But that man is now a convenient stooge for the right wing and a pointless edgelord whiling away his money on pointless projects.Both of these can be true. It’s okay.Here’s to hoping Tesla, SpaceX and all his other world changing companies succeed inspite of him and let him cement his complicated legacy.Go Starship Super Heavy!!PS: Shoutout to Gwynne Shotwell for being a massively effective administrator for this incredible rocketship of a company. reply baq 4 hours agorootparent> Shoutout to Gwynne ShotwellShe’s the low key (on this forum anyway) hero of human space flight in this decade. Absolute unit. reply Me1000 16 hours agoparentprevI&#x27;m a SpaceX fan and I&#x27;ve been excited to watch Starship&#x27;s progress over the years, but this comment is a little premature. It might one day be the most capable rocket ever built, but it&#x27;s not there yet. Starship has yet to reach orbit, the Raptor engines have a long ways to go before they become as reliable as the Merlin, and the recovery of the booster or ship are still a ways out too. There are still a lot of technical and regulatory hurdles Starship needs to cross. reply rtkwe 7 hours agorootparentThere&#x27;s also that the whole plan of Starship colonizing Mars is wildly impractical and all the numbers Musk throws out don&#x27;t work; the second you try to start fitting the supposed 100 passengers in to Starship for example there&#x27;s just not room even if you halve the NASA recommended space per person. Once you account for keeping them alive once they get there it makes the slave trade ships look luxurious. SpaceX is doing really neat stuff just dragged down by Elon&#x27;s overhyping sales pitches. reply baq 4 hours agorootparentYeah. Sending 3 is reasonable and would advance Mars science by 100x (10x the first day with a shovel) but dude rants about cities. Nice to have a vision, I guess? But maybe let’s try with 3 first. reply pjc50 1 hour agorootparentThe first human landing on Mars destroys a large section of Mars science forever, because then we can no longer be sure if life traces we find there are indigenous or not. reply ramraj07 51 minutes agorootparentSlight nuance. We can most definitely tell if a life source you find there is from mars or not - assuming it has the same dna backbone, sequence comparison can tell exactly when life diverged into the two planets (as it likely did if mars ever had life).The real danger is that life forms hitchhiking the first humans can totally overwhelm any existing life and completely condemn it. reply cnlevy 2 hours agorootparentprevUntil now, rockets have been produced \"by hand\", one by one. And you get handcrafted prices for rockets. To lower pricing, and revolutionize space travel, you need a production line of rockets. What will you do with 100s of rockets of this factory ?Also, you need a vison to advance things. Millions of electric cars ? 10 years ago it would have been a joke reply mschuster91 1 hour agorootparent> Millions of electric cars ? 10 years ago it would have been a jokeViable electric cars were a thing even way back in the late 19th century [1]. The problem was that burning oil was cheaper (as the users had to pay none of the externalities for decades), and so it lost out for a good while despite being more efficient (i.e. energy contained in the fuel vs distance driven) on paper.On top of that came the massive, decades-long lobbying efforts of the fossil fuel industry to get rid of public transit.[1] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;History_of_the_electric_vehicl... reply hnbad 45 minutes agorootparentprev> Millions of electric cars?Electric cars are nice and all but if you want to credit Elon Musk with contributing to the switch from gas to EV, you also have to credit him with killing high-speed rail with spitballing about the vaporware that is building underground vacuum tunnels to shuttle cars around, aka the Hyperloop (before it became a closed-loop underground taxi service with no regard for fire safety). reply mjevans 4 hours agorootparentprevSend a pile of good robots and tools there first.Build a lab. Run it with things that we hope are good enough, but don&#x27;t value enough to get home (back to earth) safely.If we&#x27;re really smart we can even use the whole thing to bootstrap a useful environment to get to and a far easier environment to get back from. reply generalizations 7 hours agorootparentprevFar as weight goes, wouldn&#x27;t 1-2.5 tons of payload capacity per person be enough? And as far as volume is concerned, I&#x27;m pretty sure there&#x27;s lots of ways to increase that dramatically while you&#x27;re in space (e.g. inflatable habs). All you really have to do is figure out how to keep them comfortable until the starship is outside the atmosphere and whatever larger spaces have been constructed&#x2F;inflated. reply usrusr 3 hours agorootparentFor an Apollo-grade flag selfie and back? I&#x27;d say 1-2.5 tons are plenty. Anything more than that, certainly not. reply lmm 5 hours agorootparentprev> Far as weight goes, wouldn&#x27;t 1-2.5 tons of payload capacity per person be enough?IIRC you need 6 tonnes of food and oxygen just to keep them alive for the transit. reply namibj 2 hours agorootparentSolar-powered electrochemical synthesis of small energy source molecules like glucose or acetate might reduce that substantially. If you supply 80% of the energy demand that way, you&#x27;d easily half the \"proper food\" mass that you need to ship. reply lmm 1 hour agorootparent> Solar-powered electrochemical synthesis of small energy source molecules like glucose or acetate might reduce that substantially.Has that ever been done for human consumption before? Relying on a novel technology in a setup where, if it breaks, everyone on board dies, seems rather dubious. reply brandonagr2 6 hours agorootparentprevJust imagine only sending 20 people instead of a theoretical 100 people in a single starship out of an armada of starships to mars. Would it even be worth the trip if we landed only 20 people per ship? That would make actually landing on mars such a failure reply imtringued 4 hours agorootparentThe problem is that you won&#x27;t get to send twenty people either... reply trollerator23 12 hours agorootparentprevAyep. Well said. It could be but it isn&#x27;t yet. However SpaceX does have a good track record in that regard. reply Me1000 11 hours agorootparentSpaceX is an impressive accomplishment by any measure, no one should try to take that away. The Falcon 9 brought some much needed innovation to the industry and I&#x27;d argue established an accessible commercial industry in space. And while I&#x27;m quite optimistic that Starship will eventually be a success, I think it&#x27;s healthy for people to take a step back and remember that Dragon was delayed for years (yes, so was Starliner but it&#x27;s not relevant here), Falcon Heavy was delayed for years, and Starship is also delayed by years (and despite the other person&#x27;s comment to my original, it&#x27;s not the fault of the FAA). Falcon Heavy never actually achieved reuse&#x2F;landing for the core stage, and has since abandoned even attempting it. I believe it was Shotwell herself who said Falcon Heavy was a mistake. reply simonh 3 hours agorootparent> Falcon Heavy never actually achieved reuse&#x2F;landing for the core stage, and has since abandoned even attempting it.That’s a weird thing to list as a criticism, the centre core ends up going way higher and faster than a normal booster, they know recovering it is a stretch. One did landed successfully, but was lost on the way to shore due to rough seas. On most flights they expend the core to get additional performance, doing so doubles GTO delivery capacity.As for ‘delayed for years’ that’s relative to knowingly highly aggressive target timelines. Compared to space industry standards they were still completed at break neck speeds.Both these criticisms are just attempts to use skewed optics to turn what are actually some of SpaceX’s bigest successes into apparent failures. SpaceX shoots and hits much higher than anyone else. The fact that they aim even higher than that is no sign of failure. reply bisby 6 hours agorootparentprevI internally tend to contribute SpaceX&#x27;s success to Shotwell. Sure, Elon challenges the status quo of space companies and prompts \"radical new ideas\", but I think she is the force that makes it an actually viable company that isn&#x27;t just a billionaire dumping money down the drain. reply nickik 3 hours agorootparentIf you don&#x27;t like Musk, just ignore him, pick the next person in the hierarchy and assign the success to that person. SpaceX was successful before Shotwell was president.Shotwell is great, but so are lots of other people that work for SpaceX. reply Capricorn2481 1 hour agorootparentHow about it&#x27;s the cumulative effort of talented people working at the company? reply kmmlng 42 minutes agorootparentAbsolutely, the organization as a whole is succesful, but the exact same people in a different organization might not quite be as succesful. There is something in the DNA of the organization that is just working and that is an effect of how it was set up. reply foobarian 8 hours agorootparentprevAt least with Starship we have seen the booster land so there is the existence proof. It just needs to not catch fire afterwards :-) reply cchance 8 hours agorootparentprevPretty sure to do any of those things or improve on any of them they need to be allowed to actually launch the frigging rocket reply hersko 14 hours agorootparentprev> Starship has yet to reach orbitYeah, well they&#x27;re trying but the FAA isn&#x27;t letting them launch. It&#x27;s possible the one they want to launch will make orbit, or maybe it will be the next one etc.. The point is it will never achieve anything if it keeps getting delayed by the FAA. reply deprecative 13 hours agorootparent> The point is it will never achieve anything if it keeps getting delayed by the FAA.If Elon didn&#x27;t want things to be delayed so bad by the FAA maybe he shouldn&#x27;t have launched on 4&#x2F;20 for the lulz without adequate launch site infrastructure for such a launch.The FAA shouldn&#x27;t let them launch until SpaceX has proven they&#x27;ve done the work and have done their best to mitigate these issues going forward - both the actual consequences and the decision processes that led to them. From what I remember the FAA basically rubber stamped SpaceX&#x27;s incident report (or whatever it was called) that the Internet reported as being from the FAA itself. reply cchance 8 hours agorootparentYes exactly, sure... if we ignore the fact that the launch on 4&#x2F;17 was scrubbed and the 4&#x2F;20 date just happened to be the next window and he made a joke about it.As for the not adequate launch site infrastructure that had 0 to do with the date, they built the pad long before launch, expecting the fondag to handle the heat&#x2F;pressure and it didn&#x27;t work, they didn&#x27;t suddenly build a pad throw it together and say we&#x27;re launching cause 4&#x2F;20 because LOL. reply ajmurmann 13 hours agorootparentprev> If Elon didn&#x27;t want things to be delayed so bad by the FAA maybe he shouldn&#x27;t have launched on 4&#x2F;20 for the lulz [..]It&#x27;s incredible that we live in a world where a statement like this has at least some veracity. reply machdiamonds 10 hours agorootparentThis isn&#x27;t true, the original launch was set for 4&#x2F;17 but was delayed due to an issue: https:&#x2F;&#x2F;www.reuters.com&#x2F;business&#x2F;aerospace-defense&#x2F;elon-musk... reply tigershark 4 hours agorootparentPretty much everyone following the first orbital attempt closely for months could tell that the 3 days delay was just bullshit to appease Musk.I was following starship from the time when was still called ITS or BFR. reply brandonagr2 6 hours agorootparentprev> until SpaceX has proven they&#x27;ve done the work and have done their best to mitigate these issues going forwardI have great news for you, they have already done that!https:&#x2F;&#x2F;twitter.com&#x2F;elonmusk&#x2F;status&#x2F;1700789411279966339 https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=cltnwVMcYgw reply elteto 17 hours agoparentprevBecause people hate Musk (understandably so) and since, apparently, we can&#x27;t hold nuanced opinions anymore, then they must also hate whatever the man has produced.By the way, I absolutely despise the man and his antics, but I don&#x27;t want to live in a world where SpaceX fails, just to spite him. reply cchance 8 hours agorootparentSame i didn&#x27;t mind him before he went completely nutters, but i can love SpaceX, Tesla and the companies without loving him, it seems other people have decided everyone at tesla and spacex are evil because an idiot owns the company. reply oezi 3 hours agorootparentI don&#x27;t know. At some point you have to draw a line. For me Elon has said enough problematic things that it is out of the question to buy a Tesla. reply avmich 17 hours agorootparentprevI&#x27;m thinking about rebranding SpaceX with Gwynne Shotwell persona - I think she at least spends greater fraction of her time on SpaceX matters than Elon these days. reply darknavi 17 hours agorootparentI normally say Gwynne Shotwell is underappreciated but I am really glad people here mention her. She is definitely the \"rock\" that holds the leadership team together it seems. reply machdiamonds 10 hours agorootparentprevPersonally, I like it when the technical people are seen as the face of the company:https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;SpaceXLounge&#x2F;comments&#x2F;k1e0ta&#x2F;eviden... reply cryptoegorophy 13 hours agorootparentprevWhy people hate him? Seems like a lot of “media” hates him and that’s what causes people to hate this guy, not the guy itself but the media. He does have some questionable behaviour for a CEO, but I highly prefer that kind of ceo that talks what he thinks rather than the one that reads from the brochure to make shareholders happy. Positives are far far more outweigh the negatives in this case. reply wolverine876 13 hours agorootparentIf you want to discuss it, let&#x27;s have a genuine discussion. You know many more and better reasons why people dislike Musk. reply stevenally 5 hours agorootparentprevPeople hate him because he&#x27;s a d*ck. reply imtringued 3 hours agorootparentprevYou&#x27;re talking about the guy suggesting an air cushion inside a vacuum tube. Meanwhile all he built is \"Teslas in tunnels\" without even demonstrating \"full self driving\" in this limited environment. reply cchance 8 hours agorootparentprevHe is a trans-phobic (because his daughter came out as LGBTQ and basically told him to screw off because he didn&#x27;t accept her), he&#x27;s an antisemitic (see recent X posts and shares), believes in science, but suddenly is anti-vaccinations for no reason, and honestly just seems to be posting things to make the right wing happy lately. reply AYBABTME 7 hours agorootparentNot drinking _all_ of the trans-culture koolaid doesn&#x27;t make someone trans-phobic.I think he&#x27;s posting a lot of crap, and probably doesn&#x27;t have much of a filter and is impulsive at times. Clearly he&#x27;s got some mental problems that lead him to say and retweet stuff on a whim that he probably doesn&#x27;t actually believe. I think we can all understand these imperfections.At the end of the day, he&#x27;s an incredible human being, flaws and all. No one&#x27;s perfect, and he&#x27;s cocky and pushy and rude and stuff. But he&#x27;ll be in history books, and mostly for having done a whole lot of good for humanity, while pissing off a lot of humans. reply davkan 6 hours agorootparentYou’re being overly charitable suggesting he doesn’t believe the things he posts. He has a clear ideological bent and the garbage he posts, antisemitism included, is right in line with it. reply kortilla 5 hours agorootparentYou can tell by the way he posts all of the pro-Hamas memes. reply tpmx 24 minutes agorootparentWhere? Didn&#x27;t find anything when looking for that. replyelteto 12 hours agorootparentprevOff the top of my head:- He has turned into a pro-Putin, right wing troll, regularly spewing out falsehoods on Twitter&#x2F;X.- How he has (mis?)managed Twitter so far.- All the lying and broken promises regarding FSD and other shenanigans with Tesla stock (the “taking it private” debacle, the bitcoin pump and dump, etc).- All the COVID conspiracy idiocy and non-sense.I’m sure there’s plenty more I’m forgetting. reply foobarian 8 hours agorootparent> - How he has (mis?)managed Twitter so far.I get a kick out of Elon&#x2F;Twitter schadenfreude as much as the next person, but I also have to consider that maybe the \"growth at all costs\" Wall Street mentality has permeated our society and psyches so thoroughly that it triggers a strong kneejerk reaction to anyone going against that grain. Here is a leader who is finally saying, to hell with the investors and the board and kowtowing to the advertisers, I will make the changes I feel are right, and we are rejecting it because it&#x27;s \"mismanagement.\" Where mismanagement is defined as not playing along with the public market incentives.I&#x27;m sure it&#x27;s a swing too far in the apologist direction, but you gotta wonder... reply macintux 7 hours agorootparentprevHe lost me at “pedo guy”. reply avmich 12 hours agorootparentprevRight, but does it all outweight the benefits he brought?.. reply Me1000 10 hours agorootparentYour comment is addressed directly by the great-grandparent comment in that1) It lacks all nuance because your question implies that if a person provides benefits to [whomever] and it&#x27;s greater than their antics&#x2F;demons, then you should like them. And that&#x27;s simply not how the world works. And2) The comment even said they wouldn&#x27;t want to live in a world without SpaceX despite his antics.People are complicated and so too are the views individuals hold about other people. It&#x27;s not a spectrum where people eventually just dismiss extremely concerning things because someone made something cool. reply avmich 9 hours agorootparent> It&#x27;s not a spectrum where people eventually just dismiss extremely concerning things because someone made something cool.That&#x27;s the matter of the question. Elon Musk has some significant achievements which shouldn&#x27;t be dismissed just because he behaves less than perfect somewhere else. reply Me1000 9 hours agorootparentI understand you&#x27;re trying to frame the question like that, but as has been pointed out now TWICE, and I will for a third time, it&#x27;s a flawed question because you haven&#x27;t left any room for nuance. OP literally said they want SpaceX to exist and that they don&#x27;t like Musk. It&#x27;s a nuanced thought out opinion and your question doesn&#x27;t allow for that. Specifically because your premise is flawed, that by not liking a man you&#x27;re somehow dismissing his achievements. That&#x27;s obviously and clearly not the case here at all. reply avmich 8 hours agorootparent> I understand you&#x27;re trying to frame the question like thatYou don&#x27;t seem to understand me at all. elteto listed a few things, which can be agreed with, and yet which aren&#x27;t enough to explain cryptoegorophy&#x27;s question \"Why people hate him\". I&#x27;m reminding that there&#x27;s another side of things - people in this discussion generally quite aware of that, and only some focus on a one-sided picture. You don&#x27;t need to repeat that the question is flawed - you just have to correctly understand the question. That is, it&#x27;s a reminder of another side, which is necessary for cryptoegorophy&#x27;s question. It&#x27;s true that it&#x27;s a complex question, but you don&#x27;t understand me if you think I don&#x27;t leave the room for nuance. Or, in other words, you can just dislike a man - but to explain why people in general have a correlated opinion, you have to look at the whole perspective. reply elteto 9 hours agorootparentprevThank you, that’s exactly my point. I couldn’t have said it better myself. replykortilla 5 hours agorootparentprev> He has turned into a pro-Putin, right wing troll, regularly spewing out falsehoods on Twitter&#x2F;X.Why does Starlink work in Ukraine? reply nickik 3 hours agorootparentprev> - He has turned into a pro-Putin, right wing troll, regularly spewing out falsehoods on Twitter&#x2F;X.This one is just baffling. He is literally the most important private person helping Ukraine right now.He like once suggested that total victory maybe wasn&#x27;t a viable goal and that at some point in time some compromise peace might have t be made. Something lots of political scientists have also predicted would happen. reply fallingknife 6 hours agorootparentprev- He has turned into a pro-Putin, right wing troll,Have seen this claimed many times but nothing to back it- How he has (mis?)managed Twitter so far.Mismanaging a company is hardly unusual, nor a reason to hate someone unless you are a shareholder or employee- All the lying and broken promises regarding FSD and other shenanigans with Tesla stock (the “taking it private” debacle, the bitcoin pump and dump, etc).Tesla shares are up massively, so this is not a reason to hate him, even if you are a shareholder. It is a reason to hate him if you are a short seller, I guess. He has Tweeted about crypto, but there is no evidence he participated in any pump and dump- All the COVID conspiracy idiocy and non-sense.Can you cite anything for this? I assume it is just more of the same media hysteria about him being some kiind of right wing fascist with no actual backing. reply mcpackieh 13 hours agorootparentprevGo on reddit and ask them. They&#x27;ll tell you that Elon Musk aligned himself with republicans aka &#x27;literally nazis&#x27;. This outweighs anything positive he could possibly ever do. Any cred he once earned for himself by trying to popularize electric cars? Completely gone, he&#x27;s a republican so he hates the environment. Building rockets is perceived to be little more than a cynical cover story for his real plan to ruin wetlands and murder ocelots. reply lstodd 13 hours agorootparentSo this.On the ocelot question - he will cynically tickle them to death instead.This is about as reasonable discussion as can be had on the topic of Musk. Which is sad. reply mcpackieh 10 hours agorootparentThe ocelot concern is a transparent farce. reply HappyDaoDude 9 hours agorootparentprevMy initial issues with Musk was that he tended to push ideas and time frames WAY beyond what was reasonable.Tesla &#x2F; Space X are already amazing in almost ever respect, it doesn&#x27;t need all the silly hype machine on top of it. Yes, it is neat to think about Mars bases eventually but that should be a stretch goal not pushed as \"It is 4 years away!\".Starship is an incredible achievement already and I suspect it will come together quicker than we anticipate (less than a decade, probably in the next 2-3 years) but Musk had always promoted time lines and ambitions that were silly. Like point to point public rocket travel by 2030. The thing cannot land yet and they are already thinking 50 steps ahead with a stated date. That doesn&#x27;t detract from Space X&#x27;s achievements but it does cast a shadow over them as a whole. reply jwells89 7 hours agorootparentThat over-ambitiousness is a big factor in attracting (and to some degree, keeping) talent I&#x27;d bet. It&#x27;s one of SpaceX&#x27;s key differentiators compared to incumbents where the overarching attitude seems to be, \"well, we&#x27;ll get back to the moon at some point in the future, maybe, if we&#x27;re lucky\". That&#x27;s not to knock the brilliant people working for those companies but it&#x27;s gotta be harder to be excited when it feels like the corporate gears are perpetually gummed up with cold tar. reply fnordpiglet 7 hours agorootparentprevHype = funding reply imtringued 3 hours agorootparentprev>Starship is an incredible achievement already and I suspect it will come together quicker than we anticipate (less than a decade, probably in the next 2-3 years)You do know that the next Artemis mission is in 2024? According to your timeline it would be delayed more than the much hated space launch system which actually went to the moon reply fallingknife 6 hours agorootparentprevWho cares? If he builds the most advanced rocket in the world, nobody will remember he was late. Late is not a meaningful criticism when building things that have never been done before. reply senectus1 8 hours agorootparentprevIf you replace the words Elon Musk with \"some guy\" and talk about spaceX rather than some guy... it helps a heap reply sneak 14 hours agorootparentprevI’m of the belief that the reason he has so suddenly become hated in the last few years (because it’s really unjustified, if you look purely at his works) is a direct result of engineering by those who would suffer if he continued his ascent without public opinion against him. None of the public narrative about him (especially the Twitter stuff) or the reasons people generally mock him make much sense, or are very relevant to 99% of the things he is actually spending time and resources on. It’s 100% manufactured.Starship and access to orbit, as well as Starlink (which cheap access to orbit enabled) are indeed insanely powerful geopolitical tools. Many of the existing geopolitical engineers would hate to see him not be firmly subordinate to themselves.I wouldn’t be surprised if the FAA’s decision is being used as a bargaining chip here. You don’t get to do things like this in the USA unless you play ball 100% with the existing people who control access to orbit.Nobody is richer or more powerful than the people who presently control the satellite-based weapons and surveillance systems that the US operates. Nobody will be able to be in a position to replace or supplant them without some sort of negotiation with them.Imagine it: with a working Starship, Musk could replace GPS, Keyhole, and whatever the rods-from-god system is codenamed, in a matter of months (or perhaps weeks, if the payload design work is already underway), for anyone on the Earth who he thinks would benefit his goals. A lot of the leverage that exists against him (and can presently be used to constrain him) would be gone, never to return. It’s already fairly obvious that the geopolitical status quo on Earth is not very important to him. reply rout39574 14 hours agorootparentI think the recent wave of vitriol is mostly associated with his decision to destroy Twitter in the process of attempting to make it a safe space for racists. That and his seeming to align himself with our strategic adversaries on the world stage.The latter is possibly dismissable as \"Well, that&#x27;s just your opinion, man...\" but he gives muscle to his opinion by making business decisions with strategic policy implications (e.g. turn off Ukraine starlink service at strategig moments..)The twitter vandalism is very clearly \"his works\". reply saturn8601 37 minutes agorootparentThe automotive and space industry has been screaming from the hills about him for years now. Tesla and SpaceX are marvels of what you can do if you have billions to burn and the freedom to do so. The CEO of Ford or any other OEM couldn&#x27;t spend the kind of dough and make the mistakes that Musk has made. Twitter brought his antics to the forefront in techie circles so software people who didn&#x27;t listen to said people from other industries finally got the message. reply cryptoegorophy 13 hours agorootparentprevGenuinely curious what is a Twitter vandalism? I’ve used Twitter for about 10years and for me it hasn’t changed, I still have the same logical timeline with people that I follow and their tweets. What is it that changed that I can’t figure out? reply dmix 10 hours agorootparentThe only noticeable thing that&#x27;s changed is the old blue check mark brigade isn&#x27;t dominating what gets preference in the algorithm and subsequently what most often goes viral. This group strongly having been in one ideological group has made those in the same group notice they are no longer given automatic popularity points and they don&#x27;t like it.Social media has always been cancer, some people just want it more preferenced to their sort of cancer by a centralized system.But otherwise I see little evidence it&#x27;s actually stopped anyone from using it other than people giving heartfelt anecdotes on HN and lots of talk about Mastodon that unsurprisingly died off quick. reply rtkwe 7 hours agorootparentInstead the new blue check buyers are pushed to the top of replies with either mid responses or ads to their latest crypto pump and dump. reply imtringued 3 hours agorootparentprevMy followers on twitter are 100% bots with a bio that advertises other people&#x27;s accounts. reply bluescrn 9 hours agorootparentprevShutting down Twitter would be doing the world a huge favour. He&#x27;s halfway there. reply jryle70 8 hours agorootparentprev> turn off Ukraine starlink service at strategig momentsThis makes absolutely no sense, yet people keep repeating itTWZ: Do you trust Elon Musk?KB: (Laughs) In what sense?TWZ: There was the discussion over Walter Isaacson’s book excerpt and whether Musk shut off Starlink to prevent a Ukrainian attack on Sevastopol last year, or whether as he claimed he denied a request to provide it.KB: Look, [Starlink] is a private property of a private person. Yes we really very widely use his products and services. The whole of the line of contact talks to each other to some extent using his products and services. The only thing I can say here is that without those services and products it would be a catastrophe. But it is true that he did turn off his products and services over Crimea before. But there&#x27;s another side to that truth. Everybody&#x27;s been aware of that.TWZ: So he did turn it off?KB: This specific case everybody&#x27;s referring to, there was a shutdown of the coverage over Crimea, but it wasn&#x27;t at that specific moment. That shutdown was for a month. There might have been some specific cases I&#x27;m not aware of. But I&#x27;m totally sure that throughout the whole first period of the war, there was no coverage at all.TWZ: But did he ever put it on and then shut it off?KB: There have been no problems since it&#x27;s been turned on over Crimea.https:&#x2F;&#x2F;www.thedrive.com&#x2F;the-war-zone&#x2F;exclusive-interview-wi... reply sneak 13 hours agorootparentprev> or are very relevant to 99% of the things he is actually spending time and resources onTwitter is irrelevant; he is doing product (read: design for manufacture) design on electric cars, battery systems, rockets, internet access satellites, brain computer interfaces, solar, humanoid autonomous robots, and tunnel boring machines, in approximately that order.Twitter is like 20th on the list, but it’s a great target for narrative-based outrage (“the bullied one gets rich and buys the playground” etc). Also note that if you truly believe in freedom for one-to-many publishing of all legal speech (as I do) then an increase in racist publishing is naturally going to be a consequence of that. Freedom of expression for all is far more important than censoring racists (which doesn’t stop them from being racist or stop the spread of racism anyway). reply feoren 13 hours agorootparent> the bullied one gets rich and buys the playgroundWhat version of Elon Musk are you thinking of here? Read literally anything he says and it&#x27;s immediately clear that he&#x27;s always been the bully. He wasn&#x27;t some underdog who was bullied and pulled himself up by his bootstraps to prove everyone wrong, he&#x27;s the son of an apartheid emerald mine owner who made some good business bets and has now figured out how to scale up his bullying to a national scale. The already-rich bully bought the playground so that nobody could stop him from bullying everyone even more.> Also note that if you truly believe in freedom for one-to-many publishing of all legal speech (as I do) then an increase in racist publishing is naturally going to be a consequence of thatAh, the old \"I&#x27;m free to publish racism but you&#x27;re not free to call me out when I do so\". These free-speech \"absolutists\" always abandon their morals as soon as they get the opportunity to censor someone who is making fun of them for being a douchebag. It&#x27;s always about wanting a spout-racism-free card, never about the inalienable rights of mankind. reply snovv_crash 12 hours agorootparentPlease fact check the emerald mine thing. From what I understand it is wildly overblown, his estranged dad had a couple shares, that&#x27;s all. The fact that it has gathered so much steam fits perfectly into a Manufactured Consent style narrative.And FYI, if your 401k has some index fund exposure you&#x27;re probably the partial owner of some cobalt mines in Congo that have questionable labor practices. reply avmich 12 hours agorootparentprevI remember works of Musk before 2002. And I don&#x27;t see where it is> but you&#x27;re not free to call me out when I do soin the GP post, literally or in meaning. So... I think you&#x27;re at least exaggerating too much, at least in some places.However I do see your point. reply feoren 12 hours agorootparentElon Musk uses his power to censor people who make fun of him or that he otherwise disagrees with. One of his claims of why he bought Twitter was to restore free-speech on the platform, which really turned out to be allowing hate speech and alt-right propaganda while censoring opposing views. My claim is that everyone who claims to be a free-speech absolutist is secretly the exact same: they want free speech for themselves, to spout whatever hate-speech they are tired of having to contain, but will happily censor anyone else who opposes them or makes fun of them. It&#x27;s been demonstrated hundreds of times over and I&#x27;ve never seen a counterexample.People who actually value personal freedoms understand that there are always tradeoffs: you cannot simultaneously have freedom-to-bully and freedom-from-bullying. It&#x27;s a difficult problem. People who claim it&#x27;s simple are not actually interested in solving it. The people who say that freedom-to-bully is infinitely more important than freedom-from-bullying (as all \"free speech absolutists\" are inherently claiming) are, quite obviously, bullies that want to get away with bullying. reply avmich 11 hours agorootparentI mostly agree. The only thing which I&#x27;d learn more about is> I&#x27;ve never seen a counterexamplePerhaps that Voltaire&#x27;s \"I disapprove of what you say, but I will defend to the death your right to say it\" was made too much in jest and didn&#x27;t really correspond to some real events, before or after. Or people like Vaclav Havel, who got to the power from the power&#x27;s opponents, didn&#x27;t have opportunity to refrain from silencing a political adversary. I don&#x27;t know. reply fallingknife 6 hours agorootparentprev> Elon Musk uses his power to censor people who make fun of himWhich is petty and stupid. But AFAIK he has not censored political content he disagrees with, so I much prefer it to the previous regime. replyzpeti 13 hours agorootparentprev> decision to destroy Twitter in the process of attempting to make it a safe space for racistsCan you back that up, with actual data, and not the politically motivated articles from democrat aligned media?The only specific cases of this I’ve seen was an actual bot network saying the n word a lot when Elon took over, which was obviously a coordinated attack.Other than that, where is this racist hell hole that twitter has become apparently? Where is the proof? reply katbyte 1 hour agorootparenthttps:&#x2F;&#x2F;www.washingtonpost.com&#x2F;technology&#x2F;2023&#x2F;03&#x2F;30&#x2F;elon-mu...https:&#x2F;&#x2F;www.latimes.com&#x2F;business&#x2F;technology&#x2F;story&#x2F;2023-04-27...https:&#x2F;&#x2F;finance.yahoo.com&#x2F;amphtml&#x2F;news&#x2F;group-flagged-100-rac... reply ajmurmann 12 hours agorootparentprevI used to be pretty much a Elon fanboy. I don&#x27;t hate him now, but feel mixed and largely neutral about him. What did that for me is that his communication on Twitter seemed to ignore the fact that having a very large audience brings responsibility. It&#x27;s different if I mention to some buddies in the pub over beers that I read some research about vaccines that made me wonder if I should get the vaccine than if I tweet the same thing to an audience of many million people. I am just making this vaccine example up in this case because I am too lazy to go back through his history, but he has said a lot of things with wide-reaching implications without doing proper research and due diligence required when communicating to that many people, many of whom see him as a role model. This does very real harm and makes me question his maturity. reply snovv_crash 12 hours agorootparentSame boat. I think he&#x27;s been in a place where nobody has said \"no\" to him in such a long time that he&#x27;s just lost touch a bit with reality. Also, I really don&#x27;t think it&#x27;s fair to make opinions of him unless you also make opinions of the other billionaire&#x27;s based on what they actually think, not just their PR firm. You&#x27;re not going to get _any_ off-the-cuff remarks from Bezos, for example. reply ajmurmann 11 hours agorootparent> Also, I really don&#x27;t think it&#x27;s fair to make opinions of him unless you also make opinions of the other billionaire&#x27;s based on what they actually think, not just their PR firm. You&#x27;re not going to get _any_ off-the-cuff remarks from Bezos, for example.That&#x27;s my point though. I am not judging the content of his opinions. I am concerned about the fact that he is voicing them with little care. Everybody has some weird opinions and half-baked ideas. It&#x27;s very different to have these thoughts in your head vs sharing them with friends and family or to to voice them to 160 million followers. He can think in private whatever he wants and I wouldn&#x27;t care or judge him unless it starts to impact other people. I think lots of weird shit, but it just makes my wife roll her eyes. Nobody is gonna die from it. replysschueller 3 hours agoparentprev\"I don&#x27;t know why this topic polarizes people to such an extreme degree. \"Because people like Elon and Gwynne have knowingly lied or purposefully mislead the public regarding Space X.An example is the Point to Point travel, this is not every going to happen. Anyone with a bit of knowledge about rocketry etc. knows this has a zero percent chance of happening alone because of the noise it would case. In their presentation they had Zürich as a destination, Zürich is so small that you would blow out every window in the entire city. Launching starship in Zürich will never ever happen. reply cnlevy 2 hours agorootparentNot from Zurich, but from an ocean platform 20km from the coast of every big coastal city. High speed trains (350km&#x2F;h) will go direct to the airport from every city less than 500km away. I agree landlocked Zurich will have a hard time to get a spaceport.Have a look at https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Kansai_International_Airport reply m4rtink 52 minutes agorootparentBodensee will do:https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Lake_Constance reply ethagknight 8 hours agoparentprevThe various replies in this thread witness that there is a purely irrational response to Elon&#x27;s \"harsh but mildly conservative\" leanings that people can&#x27;t seem to be mature enough to acknowledge that he has ramped up several major international corporations in a wildly entrepreneurial manner, yet these fools are focused on \"yes well technically he had subsidies and a ruby mine\" as if there&#x27;s some cheat code he used that no one else like Boeing or Ford had access to. reply lm28469 1 hour agorootparent> people can&#x27;t seem to be mature enough to acknowledge that he has ramped up several major international corporations in a wildly entrepreneurial mannerOr you know, people acknowledge both but his dumbassery overshadows his genius by a long stretch. Bezos, Zuck &co at least have the decency to shut the fuck up when they should, which is 99.9% of the time on 99.9% of topics. That&#x27;s all he would have to do to be more appreciated reply redundantly 8 hours agorootparentprevMildly?reply elil17 16 hours agoparentprevI don&#x27;t think it&#x27;s accurate to call it the most capable rocket ever built given that it hasn&#x27;t been capable of getting into orbit thus far. reply eagerpace 15 hours agorootparentNo other rocket even in the planning stage comes close to Starship. No other rocket organization builds rockets the way SpaceX does. There just isn&#x27;t a comparison to what they&#x27;re doing that justifies criticism that they&#x27;re unsuccessful or doing it wrong. It&#x27;s a different process.I&#x27;m not saying that Musk is perfect, or that you&#x27;re doing this, but people like to fault this wildly ambitious projects for what they haven&#x27;t achieved. But when they do work they have an outsized impact on the status quo. When Starship succeeds (and I believe it&#x27;s just a matter of time whereas Tesla FSD is still an \"if\") it will revolutionize space travel in ways that seem sci-fi today.State-of-the-art today is building machines that cost billions of dollars and throw them away after using them one time! reply whycome 15 hours agorootparent> No other rocket even in the planning stage comes close to Starship.Both my rockets and Starship have reached space the same number of times. reply BHSPitMonkey 1 hour agorootparent> Both my rockets and Starship have reached space the same number of times.Wouldn&#x27;t it be more apples-to-apples to compare \"all your rockets\" to \"all of SpaceX&#x27;s rockets\", or \"all your superheavy-class rockets\" to \"all of SpaceX&#x27;s superheavy-class rockets\"? reply verdverm 15 hours agorootparentprevOne fabricator has a track record and additionally tested their latest rocket more than zero timesAlso, Starship is beyond the planning stage reply tsimionescu 15 hours agorootparentprevYou are making two assumptions. One explicitly, that Starship will work in anything resembling its current design and promised operational paramters. This is by no means as guaranteed as you make it out to be (it&#x27;s very much an if, not a when). The promises of rapid reusability are very much up in the air, and the whole many-engine design is also not proven in the slightest yet.Secondly, you&#x27;re assuming that reusable rockets are better than one-time use ones. While this may be true for certain kinds of missions, it is not at all clear for many others.Reusable rockets fundamentally will have lower payload for the same thrust, for the simple reason that they need fuel for the return stage. They will also need to be made from sturdier materials to survive reentry, which again limits their capacity. reply avmich 13 hours agorootparentI disagree with both.> One explicitly, that Starship will work in anything resembling its current design and promised operational paramters.We have a test flight behind us, which showed many tens of seconds of the stack flight. That&#x27;s a big achievement validating the rocket architecture and general parameters. Frankly I&#x27;d assume we crossed equator in rocket development here, we&#x27;re in completion stage more than developing.> This is by no means as guaranteed as you make it out to be (it&#x27;s very much an if, not a when).You know, there are no physical laws which prevent Starship from working. SpaceX shows economics on their side. At this point it&#x27;s not guaranteed that Starship will fly - because it&#x27;s hard to predict the future - but it&#x27;s a pretty safe bet that Starship can be made to fly.> The promises of rapid reusability are very much up in the air, and the whole many-engine design is also not proven in the slightest yet.There are many successful many-engine rockets. Soyuz has 5 engines but 32 nozzles firing at launch. Falcon Heavy has 27 separate engines. Saturn-I had 8, Falcon 9, Black Arrow 8 - the last one just 4-5 times less engines than Super Heavy. To say it&#x27;s not proven in the slightest is bending the reality a bit too much.> Secondly, you&#x27;re assuming that reusable rockets are better than one-time use ones. While this may be true for certain kinds of missions, it is not at all clear for many others.It&#x27;s important however what those cases are. By now we have a good history of Falcon-9 launches, where for a number of years we have a substantial reduction of cost to orbit for a wide variety of payloads. So maybe - maybe - there are many other kinds of missions where reusability is a disadvantage, but those kinds are clearly in substantial minority.> Reusable rockets fundamentally will have lower payload for the same thrust, for the simple reason that they need fuel for the return stage. They will also need to be made from sturdier materials to survive reentry, which again limits their capacity.That&#x27;s technically true, but arguing this is a bit like arguing that a car made for a single travel would be lighter and cheaper that the one made for repeated use. True, but quite irrelevant for most practical cases. reply tsimionescu 3 hours agorootparent> We have a test flight behind us, which showed many tens of seconds of the stack flight.As became apparent in the post mortems, the rocket lost its chosen flight path the moment it left the pad, probably due to the engine failures. It flew of course, but it was a failed launch from T+3 or so. The safety systems also failed to self-destruct the rocket on command - they thankfully did enough damage for the atmosphere to take care of the rest.Basically the launch only proved that the parts hold together and the engines produce enough lift. The engines themselves are still far too prone to failure (apparently this was using an older generation, so maybe that part is already fixed).> There are many successful many-engine rockets. Soyuz has 5 engines but 32 nozzles firing at launch. Falcon Heavy has 27 separate engines. Saturn-I had 8, Falcon 9, Black Arrow 8 - the last one just 4-5 times less engines than Super Heavy. To say it&#x27;s not proven in the slightest is bending the reality a bit too much.You&#x27;re right, I was exaggerating a bit. Still, my layman&#x27;s understanding is that there is a fundamental difference between Falcon Heavy&#x27;s multi booster design with 9 engines per booster, and Super Heavy&#x27;s 33 engine design on a single booster. Maybe I&#x27;m wrong on this.> So maybe - maybe - there are many other kinds of missions where reusability is a disadvantage, but those kinds are clearly in substantial minority.As I understand it, the disadvantages start once you want to put large payloads beyond orbit. Starship&#x27;s main goal is to put a payload on the moon (this is what the NASA funding is for) and for this purpose it is much worse than a traditional single use rocket: instead of a simple trip to the moon, the design is to launch to orbit, then do an additional 6 or so launches to refuel it while in orbit, and only then will it have enough power to fly to the moon.SpaceX is banking on the launch being so cheap with their hopes of rapid reusability that they can do 7+ launches of Starship for less than the cost of a more traditional mission. Falcon 9 definitely is not that cheap compared to other rockets, but perhaps Starship will indeed be. reply eagerpace 14 hours agorootparentprevThe first is a fair, but I&#x27;m not assuming that it has to work exactly as claimed. It&#x27;s so far ahead of current tech that if it even marginally succeeds the stated objectives it will transform the industry.The second, I disagree, reusable is definitely better in every way. I&#x27;m sure there are edge cases where it needs to be proven or a particular mission, but no other machines are as costly and disposable.Rocket designs haven&#x27;t evolved much over the last 50 years. Competitors all claim to want reusability but none of the major players are pursuing it seriously. Engine design and manufacturing is hilariously obsolete. NASA has become a jobs program instead of a innovator. I&#x27;m just happy to see a radical new approach to design, manufacturing and testing. reply ge96 11 hours agorootparentprevRIP SLSYeah SpaceX is goat. Between starlink, self landing rockets and this, oh man. reply psunavy03 8 hours agoparentprevBecause Elon doesn&#x27;t realize his childish douchebaggery has that much of an impact on how some people view what are otherwise his very legitimate accomplishments as a businessman.Twitter&#x2F;X most certainly not among those accomplishments. reply tsimionescu 15 hours agoparentprevMaybe wait until it actually flies more than a few seconds without going off the rails before declaring it the greatest rocket ever built?Right now they haven&#x27;t even proven that the many engine design is actually workable, rhier engines failed at a spectacular rate in the single full test launch that they conducted (maybe because of the ill-conceived launch site, maybe for other reasons). reply thereddaikon 15 hours agorootparentEh, people were happy to call the N1 the most powerful rocket ever for years even though it mostly qualified as a bomb and not a rocket. Starship&#x27;s paper capabilities are indeed impressive. If they manage to make it work then great. reply avmich 13 hours agorootparentAnother example would be Spruce Goose - which still has its name in the list of the largest aircrafts.So, no, Starship already has a place in history. reply avmich 13 hours agorootparentprev> Right now they haven&#x27;t even proven that the many engine design is actually workableThey don&#x27;t need to prove it to people who accept as the only proof the demonstration of the fact. Remember you can have proofs in different ways, and professionals are fully aware of this. reply verandaguy 5 hours agoparentprev>I don&#x27;t know why this topic polarizes people to such an extreme degree.A number of reasons, actually.- Because the entire idea of \"the Earth is fucked, so let&#x27;s go set up camp on Mars\" is a train of thought that&#x27;s only applicable to the ultra-rich, and in the current economic environment that&#x27;s (pretty understandably) an unpopular idea.- Because after Starship&#x27;s failed attempt at landing and highly-destructive launch earlier this year, people who care about the nearby wildlife refuge at Boca Chica are understandably not thrilled about continued ops there.- Because the man behind SpaceX -- whose past achievements are admittedly impressive, at least in the spaceflight industry -- is increasingly associated with deceptive marketing, poor design choices, and incompetent product management, and when a corporation like SpaceX relies on significant funding from taxpayers that&#x27;s a troubling combination.- Personally, for me, coming from startups, \"move fast and break things\" scales terribly in terms of (for lack of a better word) social responsibility, and with the company&#x27;s stated ambitions, I don&#x27;t see this ending well.SpaceX does a lot of cool shit, but let&#x27;s not pretend like they&#x27;re advancing the state of human existence here. They&#x27;re a commercial entity, even if not publicly traded, but with Musk at the helm that feels like the tradeoff between being purely profit-driven vs having later-years Howard Hughes behind the wheel.Anyway, it&#x27;s pretty disingenuous to call Starship in particular \"the most capable and sophisticated rocket ever built.\" So far it&#x27;s capable of doing a significantly suborbital hop and failing to land. You could argue that it&#x27;s failed at the one thing a spacefaring vessel should, by definition, not fail at.I do trust in the FAA&#x27;s judgement here, but I hope they work closely with Fish & Wildlife. The effects of climate change are increasingly endangering wildlife in the Gulf of Mexico, and having chunks of concrete the size of a living room flying into the water isn&#x27;t helping. reply jupp0r 5 hours agorootparentI&#x27;m no fan of Elon Musk. Yet if you downplay the significance of cutting the cost of bringing mass to orbit by a factor of 1000, you really haven&#x27;t thought through the implications of this enough. The whole \"billionaires are going to leave earth behind\" thing is as much of a dumb conspiracy theory as much of the stuff Elon is tweeting lately, by the way. reply justapassenger 13 hours agoparentprevIt&#x27;s like saying in 1990 that Apple Newton is amazing product. reply chasd00 17 hours agoparentprevIirc they’re waiting on the fish and wildlife service now and not the FAA. FWS is even more slow. reply dylan604 16 hours agorootparentIt&#x27;s not like they could put out a public notice for all of the fish and wildlife to attend a planning & zoning meeting for their comment on the situation. Determining the effect of human endeavors on said fish & wildlife is a little more complicated that going door to door and informing them of their plans. reply golemotron 8 hours agoparentprevThe US is so polarized that all it takes is for an opinion to form on either the Left or the Right.The other side will form the opposite opinion to signal that it is different. reply cedws 15 hours agoparentprevFalcon is impressive. Dragon is impressive. Starship is a flying tin can. reply avmich 13 hours agorootparentI&#x27;m amazed at how swiftly opinions like this change with the appearance of new facts. reply CommieBobDole 18 hours agoprevI think many of the issues that SpaceX has had with the Starship&#x2F;Super Heavy project are due to the poor suitability of the launch&#x2F;build site. The launch site itself is tiny and directly adjacent to protected wetlands, the only access between the build and launch sites is via a two-lane public road which is the only access to the also-adjacent state park beach, etc.There were other sites under consideration, and I&#x27;m sure they had their reasons for passing on them, but it&#x27;s hard to see offhand how they could be worse than Boca Chica. reply mordymoop 18 hours agoparentMy family owns some land in south Texas and my subjective sense from dealing with that reality and talking to people in the area is that you can’t throw a rock without hitting a protected wetland. In practice, the ubiquity of environmentally delicate tracts of land seems to be used by the state to restrict or permit industrial activities arbitrarily, likely based on political favoritism. If you think this is hyperbole, I suggest you look into the details of the various solar power projects in Texas. reply yellow_lead 15 hours agorootparentHeard an anecdote from an architect in south Texas: if you have land there, and it rains enough, your land can become a protected wetland. Now you can&#x27;t build on it. reply sho_hn 15 hours agorootparentTo be fair, there&#x27;s also a good case for preventing people from building on land to protect ecosystems. We may not need that many rockets, and it&#x27;s certainly not the only priority for society.Our tech circles tend to paint a very one-sided picture of the rules just putting roadblocks in front of us, but there&#x27;s a lot of good examples both of what unregulated progress can do to natural resources, and of preservation efforts making a real difference.If I was a professional environmentalist&#x2F;preservationist, I&#x27;d be very frustrated with the total lack of empathy by the tech community and their efforts (often cutting-edge science!) getting described as backwards or in the way of progress almost constantly ... reply kortilla 5 hours agorootparent> I was a professional environmentalist&#x2F;preservationist, I&#x27;d be very frustrated with the total lack of empathy by the tech community and their efforts (often cutting-edge science!) getting described as backwards or in the way of progress almost constantly ...Please list out all of the other wetlands being destroyed by space exploration. Then list them as a percentage of global wetlands or list out what would be endangered by this one location being used as a launch site. reply shafyy 14 hours agorootparentprevExactly. Keeping wetlands intact is very important for climate change, because draining them releases a shit ton of greenhouse gases. Of course, it&#x27;s also important for biodiversity. reply kortilla 5 hours agorootparentNobody is draining wetlands at starbase. reply shafyy 18 minutes agorootparentAnd the only reason for that is because they&#x27;re protected lands. reply lefstathiou 14 hours agorootparentprevIf you were an environmentalist &#x2F; preservationist, how would you determine where the line is between what’s an appropriate level of resistance versus inappropriate (or what’s fair for spacex vs unfair for the environment)? reply lodovic 6 hours agorootparent(offtopic: this is how I would ask GPT4) reply vkou 12 hours agorootparentprevI would draw the line at being able to maintain a steady-state ecosystem in perpetuity.We, uh, have yet to meet that line in most of the world. Pretty much anyone draining an aquifer, or having to import more soil nutrients than are produced by their land year-over-year, is doing something that&#x27;s unsustainable. reply starbase 10 hours agorootparent> maintain a steady-state ecosystem in perpetuityImpossible. It&#x27;s not how the universe works. reply schiffern 9 hours agorootparent> Impossible. It&#x27;s not how the universe works.The degree to which we normalize unsustainable industrial activities is impressive.We&#x27;re not talking about the heat death of the universe here. Industrial society (especially industrial agriculture) is counting down toward auto-destruct sequence on a time scale of decades, not billions of years. Look at trendlines for soil erosion, aquifer depletion, cadmium soil buildup, land salinification, etc.It&#x27;s oddly one-sided how people always ask if sustainable agriculture can replace industrial agriculture. By the very definition of the word \"unsustainable,\" industrial agriculture cannot replace industrial agriculture.The impact of rockets is a tiny speck by comparison. In this case rockets will effectively preempt the slow encroach from land privatization lobbying and housing development, which would be far (far!) more destructive to the wetlands than the occasional rocket detonation or ten...Anyone who loves preserving wilderness should love rocket launch sites, as shown by the history of Cape Canaveral vs surrounding land. reply starbase 8 hours agorootparentWhoa. You believe that soil and aquifer issues will lead to society&#x27;s destruction in a matter of decades? What evidence supports that belief? reply schiffern 8 hours agorootparent> You believeNot just me, this is the mainstream business-as-usual expectation. Collapse of breadbasket regions tends to be a Very Bad Thing.What did you think \"unsustainable\" meant anyway?https:&#x2F;&#x2F;www.scientificamerican.com&#x2F;article&#x2F;only-60-years-of-...https:&#x2F;&#x2F;theconversation.com&#x2F;farmers-are-depleting-the-ogalla...https:&#x2F;&#x2F;www.science.org&#x2F;doi&#x2F;10.1126&#x2F;sciadv.adh2458> will lead to society&#x27;s destructionTechnically by \"self-destruct\" I mean that the agriculture system destroys itself, by somehow undermining its own mechanisms of support. How much of &#x27;society&#x27; gets pulled down with it? That&#x27;s up to us to decide. reply starbase 7 hours agorootparentAre you aware that less than 6% of US farmland is irrigated, and only half of irrigated farmland (3% of total) uses groundwater?97% of our farmland uses no groundwater. None.If US lost 3% of its agricultural output tomorrow, we&#x27;d still be growing more food than we can possibly eat; still be filling our cars with a mix of gasoline and corn liquor as we do today.Perhaps I should have asked this question instead: Is there any evidence that would cause you to change your belief that society is on the brink of collapse, or is that belief unfalsifiable like religious faith? reply altfredd 5 hours agorootparentWhat about total amount of viable farmland? How much of that amount do those 6% constitute?How much of farmland is situated close to cities (main cause of aquifer deterioration)? Would that farmland still have enough water after aquifers are caput? reply starbase 5 hours agorootparentMy takeaway was that 97% of US farmland would be unaffected by aquifer collapse. The 3% that would be affected (and that&#x27;s assuming every aquifer in the country goes dry, which is not at risk of happening) those farms might become completely nonviable, or they might be able to shift to less water intensive crops and methods. In either case, aquifer collapse is not a significant threat to our food supply.Nonetheless, it is prudent to preserve those water sources.re: farms near cities, I think it varies a lot by region. Growing thirsty crops near LA is going to be a lot harder than near Houston. reply mschuster91 1 hour agorootparentprevSoil erosion and other forms of degradation is bound to affect billions of people until 2050 [1].Groundwater degradation is just as bad of an issue - in the US [2], in Europe [3] and APAC regions [4]. The sole exception is Africa, but if they follow the same pathway as everyone else in exploiting and managing it, it&#x27;s not going to be sufficient [5].[1] https:&#x2F;&#x2F;lordslibrary.parliament.uk&#x2F;research-briefings&#x2F;lln-20... (full report: https:&#x2F;&#x2F;researchbriefings.files.parliament.uk&#x2F;documents&#x2F;LLN-...)[2] https:&#x2F;&#x2F;www.nytimes.com&#x2F;interactive&#x2F;2023&#x2F;08&#x2F;28&#x2F;climate&#x2F;groun...[3] https:&#x2F;&#x2F;www.nationalgeographic.co.uk&#x2F;environment-and-conserv...[4] https:&#x2F;&#x2F;www.asiapathways-adbi.org&#x2F;2022&#x2F;11&#x2F;the-invisible-wate...[5] https:&#x2F;&#x2F;phys.org&#x2F;news&#x2F;2023-03-africa-aquifers-scarcity.html replyeastof 14 hours agorootparentprevI am an environmentalist. The line is that SpaceX is operating a fundamentally unsustainable business. The appropriate level of resistance is that which prevents them from conducting any launches at all. Launching rockets is quite literally the last possible thing we need to achieve a sustainable and equitable future for our planet.Before you call my opinion fringe&#x2F;extreme, go ahead and speak to some low-income folks at your local dive bar. You&#x27;ll most likely find that 90+% of them are vehemently opposed to space missions in general, and especially SpaceX given the absurdity of traveling to Mars when we have so many low-hanging problems to fix here on Earth. reply maxdo 13 hours agorootparentIt&#x27;s such a bold statement. Building a colony on Mars, in such a harsh environment, is not possible without extreme sustainability. The entire colony&#x27;s existence will rely on being sustainable.You don&#x27;t have free air; you need to find a way to reuse it, or you&#x27;ll die.You can&#x27;t simply source water from a river; if you don&#x27;t find a way to reuse the same water multiple times, you&#x27;ll die.You can&#x27;t just eat vegetables and rely on cows that graze on open land; if you don&#x27;t figure out a way to produce food without using vast expanses of land, you&#x27;ll perish.You can&#x27;t just build a house from a few sticks from the nearest forest or rely on minimal heating from drilled gas or oil. If you don&#x27;t find a way to protect against radiation and heat your home efficiently, you&#x27;ll die.You can&#x27;t rely solely on oil for energy; if you can&#x27;t move between structures, sooner or later, you&#x27;ll die.Mars represents a global rethinking of our entire way of living, pivoting to a sustainability-only approach.In many cases, the sustainable approach is also cheaper. After all, reusing resources tends to be more economical. Consider solar energy as an example. It&#x27;s booming not just because of its environmental benefits, but because it&#x27;s cost-effective.And why are we building solar panels? Because NASA needed it before for space exploration.So when I hear, \"Let&#x27;s not focus on space; let&#x27;s fix Earth,\" I can&#x27;t help but think of a Luddite who&#x27;s inadvertently advocating for our planet to remain in its current, unsustainable state. reply AtlasBarfed 10 hours agorootparentPolitics is the art of the possible.\"Lets fix Earth\". The issue is the small wee number (what, almost 8 billion) of humans on the Earth and getting them to cooperate. So far, notsomuch, and the beloved economic structure to every Hacker News, capitalism, does not have practical structures to accomodate conservation, environmentalism, restraint, or valuation of nature.Capitalism essentially is a structure that maximizes resource use. The entire ruling elite was determined by the winners of capitalism, and their psychology is not of rational restraint, respect of the world, respect of others, or even respect for their children.Capitalism has a side game of converging to maximal sociopathy for the individual (greed is good, selfish is good per microeconomics, that is the definition of a rational consumer) while not overly crashing the whole system, except maybe after the next quarter&#x27;s earnings report.Capitalism and the \"economics intelligentsia\" have no workable theory for transitioning our current economic structure to a different one. The notion of an \"externality\" (note that the verbiage directly places concerns of environmentalism and long term survival as a phenomenon outside&#x2F;external to the functioning of economics) has only existed in a widespread fashion in the last decades, and really only begrudgingly to address the impending reality of global warming. Thus, there is no real development of economic (and certainly no practical political ones) to transition to some restrained model.The current economic plan: let it get so bad that the actual supply&#x2F;demand curves of markets are \"disrupted\" enough. This probably means war, famine, displacement of billions, loss of arable and livable land, etc.The fact the elite have increased their wealth share shows that since the rise of widespread science on sustainability, the power structure has doubled down on sociopathy, selfishness, denialism, and procrastination.This is not good. The only positive trend is the miraculous fact that EV drivetrains and solar&#x2F;wind turned out to be cheaper than ICE&#x2F;fossil fuels once sufficient infrastructure and research had been performed.But nothing, absolutely nothing, stops habitat destruction, soil erosion, squandering of water resources, pollution, and mass extinctions.Happy days! reply thaumaturgy 13 hours agorootparentprevI would also call myself an environmentalist, yet statements like this are the major reason I&#x27;ve been reluctant to identify as such loudly or often. Misguided environmentalists have for a long time been steadfastly opposed to nuclear energy for example, and I have not.The on-the-ground reality is that concern for and protection of the natural environment are relatively recent practices and must be balanced against the continued technological and sociological progress of humanity. Otherwise, the answer is easily that the best thing for \"the environment\" is the complete extinction of humans. While some people may want to give that a serious treatment, I&#x27;ve always wondered why those people don&#x27;t volunteer to go first.Likewise, poorer societies produce less pollution than wealthier ones, so environmentalists willing to forego any kind of human progress in favor of protecting the environment should at least consider migrating altogether to countries without telecommunications infrastructure.We don&#x27;t yet know what all of the benefits and costs will arise from a lower barrier to space exploration. But, humans exist all over this planet right now because exploration is part of our nature. Rejecting space exploration out of hand is to reject our very nature -- a curious argument, from a naturalist. reply justinclift 12 hours agorootparent> The on-the-ground reality is that concern for and protection of the natural environment are relatively recent practices ...What do you call \"relatively recent\"? reply colonCapitalDee 13 hours agorootparentprevGPS has generated over $1.4 trillion in value in the US alone since it was opened up to the public in the 80&#x27;s [1]. Millions of people use satellite TV and radio. Commercial imaging satellites are used for mapping, weather forecasting, wildfire detection, and scientific research. SpaceX&#x27;s own Starlink system has revolutionized satellite internet for regions too remote or underdeveloped to be served by traditional internet providers. And who knows what we&#x27;ll be doing in 50 years! Imagine if we are able to use rockets for point-to-point travel on Earth, or we figure out how to mine asteroids, or if the economics of space-based manufacturing work out.Also, abusing environmental regulation to set space policy is just straight up a bad idea. It&#x27;s fine if you think we shouldn&#x27;t be investing in space, but don&#x27;t try and force that belief on the rest of us in an undemocratic manner. It&#x27;s very NIMBY-esque[1] https:&#x2F;&#x2F;www.space.commerce.gov&#x2F;doc-study-on-economic-benefit... reply AtlasBarfed 10 hours agorootparentNIMBYism has no answer for the department of defense.SpaceX and the super heavy payloads are a massive massive massive strategic advantage for the defense department. Imagine:You want a functionally operational combined arms battalion deployed within two hours to the middle of Siberia? And then regularly supplied? Forget about having expensive foreign bases. You can deploy boots on the ground forces within hours.Starship is a cheap platform for 100-150 tons of ... whatever ... deployed ... whereever ... whenever. To say nothing of orbital battle platforms or other stuff, simply the rapid deployment alone makes SpaceX absolutely critical to US \"defense\".I can imagine the US DoD taking renewed interest in those midwestern remote ICBM sites as ready launch sites for rapid deployment forces. That&#x27;s right, launch from Kansas, land whereever in hours. Australia? Africa? Antarctica? Sure.Imagine fighting a conventional war and local general thinks they have a US affiliated fighting force pinned down. Suddenly, a combined arms battalion appears right behind his lines. The mobility Starship would provide the US military at very palatable costs is a battlefield revolution. reply deadbeeves 3 hours agorootparentNah, that&#x27;s never going to happen. Rockets are inherently dangerous. Loading tons of people onto one is gambling with a 1 in 20 chance (possibly higher) that all of them die. Even if nothing goes wrong with the rocket per se, how do you land it somewhere where you don&#x27;t already have infrastructure, or worse still, in a hot zone? On the best days landing a rocket is a delicate and error-prone procedure, can you imagine if there&#x27;s someone actively trying to stop you?>Suddenly, a combined arms battalion appears right behind his lines.That \"suddenly\" is pretty funny. Can you imagine trying to sneak up on someone from aboard the loudest vehicle in the world as you&#x27;re trying to gently guide it to the ground to avoid exploding? If the enemy has SAMs or artillery, your rocket and everyone in it is toast. Even if you successfully land, you better hope you&#x27;ve used all your fuel before the enemy has a chance to start shooting small arms. Even if a mostly empty rocket can&#x27;t explode, it can still easily be engulfed in flames. reply mcpackieh 6 hours agorootparentprevI don&#x27;t buy it, for several reasons. In no particular order:1) 100-150 tons is the estimated payload to LEO, not back down to the ground. For Starship to land (on Earth) it will need to be mostly if not entirely empty.2) Even if Starship could get that much payload down to the ground, how do you unload vehicles from an upright Starship? A built in crane maybe, but it sounds like a recipe for disaster.3) Once you land a Starship somewhere remote, how do you get it back? It can&#x27;t fly back (from Earth). It&#x27;s too big to realistically airlift unless maybe you have a very large runway nearby for something like a supped up Super Guppy &#x2F; Airbus Beluga. Do you plan on just leaving this cutting edge hardware in Siberia?4) Missile defense systems could easily shoot down a Starship landing near enemy territory.5) Why is this needed? Wars tend to have weeks of warning, at least for those who need to plan them. This is plenty of time for military planners to get their assets prepared to be deployed from nearby military bases or navy ships, both of which America has in spades around the world. American military logistics are already so excellent, there doesn&#x27;t seem to be much margin for improvement. reply feoren 13 hours agorootparentprevYou don&#x27;t think satellites have been a godsend for environmental conservation?Would banning space development in the U.S. help us actually fix any of those low-hanging problems?> go ahead and speak to some low-income folks at your local dive bar.Are low-income folks at a local dive bar particularly knowledgeable about the subtle tradeoffs involved in effective government regulation? reply robertlagrant 11 hours agorootparent> Are low-income folks at a local dive bar particularly knowledgeable about the subtle tradeoffs involved in effective government regulation?If they were, they&#x27;d be high income. Or be about to be. reply TheCraiggers 13 hours agorootparentprev> Before you call my opinion fringe&#x2F;extreme, go ahead and speak to some low-income folks at your local dive bar.Sorry, I don&#x27;t mean to be gatekeepery here, but \"low income folk at my local bar\" is the last demographic I would seek the opinion of on anything scientific or of broader scope than car maintenance.Anecdotally, my experience is that many of these people love conspiracy theories, and applying \"common sense\" t",
    "originSummary": [],
    "commentSummary": [
      "The outline covers a wide range of issues regarding Elon Musk and SpaceX, touching upon debates around launch safety, environmental impact, ambitious claims, and SpaceX's Starship rocket.",
      "The convergence of space telescopes and Starlink satellites is discussed, along with varying opinions on Musk's management style and controversial use of Twitter.",
      "In-depth discussions and debates focus on the impact of SpaceX's activities on protected wetlands, the sustainability and necessity of space missions, and the potential use of Starship for military purposes."
    ],
    "points": 163,
    "commentCount": 522,
    "retryCount": 0,
    "time": 1698248357
  }
]
