[
  {
    "title": "Essential Elements for a Robust PR Strategy in B2B Tech Sector: Forbes Analysis",
    "originLink": "https://www.forbes.com/sites/forbesagencycouncil/2023/11/07/what-b2b-tech-companies-need-to-create-a-successful-pr-strategy/",
    "originBody": "FORBESLEADERSHIP What B2B Tech Companies Need To Create A Successful PR Strategy Heather Kelly Forbes Councils Member Forbes Agency Council COUNCIL POST| Membership (Fee-Based) Nov 7, 2023,07:45am EST CEO of Next PR, an award-winning, full-service public relations firm with offices across the U.S. GETTY You likely know that building credibility and demonstrating industry expertise are key ingredients in growing your tech brand. You also probably know that B2B buyers rely heavily on third-party sources when making purchasing decisions. But how can you establish that third-party credibility and highlight your industry knowledge in front of your target audience? Enter public relations. Beyond positive media coverage of your product or service, a holistic PR approach for your B2B brand can support lead generation, sales growth, and even attract funding or merger and acquisition opportunities. Here are the elements of a successful PR strategy to grow your tech brand: Thought Leadership Offer your executives or subject matter experts as media interview sources or contributing writers to help build your brand's credibility and market clout. Speaking engagements at industry events are also a powerful tool for positioning your experts as influencers and authorities in front of your target audience. This strategy can directly drive lead generation, especially when reporters or contributed pieces link to your company's website. MORE FOR YOU Refurbed Raises $57 Million For Its Renovated Tech Marketplace OpenAI ChatGPT Opens The Door For You To Make Money By Easily Devising Income-Producing GPTs Based On What You Know Or What Others Want To Know Chinese Smartphone Makers Aim To Beat Apple And Samsung In Generative AI Industry Awards Winning industry awards helps you flex your expertise and innovative products to the masses. Research relevant awards for both your product and your team members, and then get going on compelling submissions. Show rather than tell in these applications—include strong examples and data to highlight what makes your product or team the best in the industry. Why? There are two main reasons: 1. Customers care about award-winning products. When prospects see your product earning industry accolades, it helps them feel confident in buying from you and knowing they chose the best solution, putting you ahead of your competitors. 2. Winning awards can drive team morale, which is key for business growth. Team members want to feel proud of their company, and winning awards—especially personal or team-focused ones—can exemplify this. Plus, who doesn't want to be rewarded for their work? Social Media Strategies LinkedIn is a valuable social platform for B2B brands, connecting you with your target audience and allowing you to create relationships with key stakeholders and prospective customers. In my experience, the posts where I share something personal and tie it to our team's work get the most engagement. People love it when a leader's personality shines through; it helps you cultivate that connection with your audience. Plus, social media is a great place to share all of the other awesome things you're doing, like winning awards, speaking at events and being interviewed by the media. Analyst Relations Online influencers wield tremendous power in driving audience behavior. While they might not be on TikTok, analysts at firms like Gartner and Forrester are the influencers who affect B2B buyer behavior. Many have a following that extends beyond work at their firm into their own personal LinkedIn channels. Arranging briefings and maintaining ongoing relationships with these B2B influencers can drive sales and pique investor interest. One way to do this is to coordinate Analyst Days, where you bring together analysts for a demonstration and Q&A. We've found that this is an effective and efficient strategy that pays off substantially for our clients' long-term coverage and credibility. Event Support Whether your company is attending an industry event or user conference, having someone on-site to handle PR for you can ensure a smooth experience and get you in front of the right reporters and analysts. With so many people to meet and greet, it can be difficult to carve out time for media and analyst relations yourself. Bringing a team to coordinate PR and event logistics affords you more time to make and nurture industry connections. Brand Building There’s much more to getting media attention for your company or product launch than issuing a press release over the wire. Your company should stay relevant even when you don’t have news to share. Follow reporters in your space and offer expert commentary on the topics they cover to position your experts as reliable sources, drive inbound interview requests and keep you involved in the conversation. Take advantage of \"downtime\" to schedule background calls with reporters. This is a great way to maintain momentum so when you do have news, you aren't starting from scratch and can leverage your established relationships to get in front of your target audience. Funding And Exit Strategies Strategies for both raising and announcing funding are key. With many venture capital firms overcapitalized and increased competition, it takes a lot of media awareness and momentum to catch their attention and validate your company as a potential investment. Once you secure funding, gaining media coverage that highlights why your funding matters for the industry will help cut through the news clutter. Develop a media outreach strategy and build media lists of relevant reporters who cover financial news. If you're aiming for an IPO or to be acquired, connect your executives with high-profile reporters to position them as leaders in the space, helping drive shareholder or buyer interest and boost your valuation. For B2B tech companies, a strong PR strategy is crucial. Keep these essential elements in mind to help boost your company's credibility and give you an edge over your competitors. Forbes Agency Council is an invitation-only community for executives in successful public relations, media strategy, creative and advertising agencies. Do I qualify? Follow me on Twitter or LinkedIn. Check out my website. Heather Kelly CEO of Next PR, an award-winning, full-service public relations firm with offices across the U.S. Read Heather Kelly's full executive profile here. Editorial Standards Print Reprints & Permissions",
    "originSummary": [
      "B2B tech companies require a strong PR strategy for building credibility and demonstrating industry expertise, according to a Forbes article.",
      "Key components of a potent PR plan include demonstrating thought leadership with media interviews and contributing to written works, winning industry awards, leveraging LinkedIn for networking, cultivating relationships with influential industry analysts, and maintaining a constant media presence.",
      "The PR strategy should also include adequate support during events and have detailed plans for raising and announcing funding."
    ],
    "commentBody": "",
    "commentSummary": [
      "B2B tech companies require a strong PR strategy to develop credibility and establish industry expertise, according to a Forbes article.",
      "A successful PR plan can include elements such as demonstrating thought leadership through media interviews and written contributions, securing industry awards, utilizing LinkedIn for networking, and maintaining relations with influential industry figures.",
      "It's beneficial for these tech companies to constantly stay in media spotlight and to have strategies in place for both raising funds and making successful funding announcements."
    ],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1699362772538
  },
  {
    "title": "UK's Competition and Markets Authority to Gain New Powers to Regulate Big Tech Companies",
    "originLink": "https://www.aol.com/uk-antitrust-regulator-big-tech-115316758.html",
    "originBody": "UK antitrust regulator to take on Big Tech with new legal power November 7, 2023 at 6:53 AM LONDON (Reuters) - Britain's antitrust regulator will gain legal powers to tailor rules for big tech companies, such as Meta, Alphabet and Amazon, to ensure they treat businesses and consumers fairly, according to the King's Speech setting out the government's priorities. The Competition and Markets Authority (CMA) set up a dedicated Digital Markets Unit more than two years ago, armed with the expertise to examine rapidly evolving markets like social media. The proposed \"Digital Markets, Competition and Consumers\" law, whose powers were originally intended to come into force in 2022, will give the unit the \"teeth\" to underpin its remit. Advertisement A small group of big tech companies with designated status will have to comply with the rules, the government said. They could be fined up to 10% of global turnover for breaches under the proposed bill announced on Tuesday. (Reporting by Paul Sandle, Editing by Kylie MacLellan)",
    "originSummary": [
      "The UK's Competition and Markets Authority (CMA) is set to acquire new legal powers to enforce rules on major tech companies like Meta, Alphabet, and Amazon through a proposed law known as \"Digital Markets, Competition and Consumers\".",
      "The Digital Markets Unit of the CMA could impose fines on companies up to 10% of their global revenue for violations under these new rules.",
      "The intended goal of this law is to ensure fair treatment of businesses and consumers in the digital market."
    ],
    "commentBody": "",
    "commentSummary": [
      "The UK's Competition and Markets Authority (CMA) is slated to acquire new legal powers under a proposed law \"Digital Markets, Competition and Consumers.\"",
      "The powers will enable the CMA's Digital Markets Unit to establish rules for large tech companies such as Meta, Alphabet, and Amazon.",
      "In the case of violations, the companies could be subjected to penalties up to 10% of their global turnover. The law is designed to ensure fair business practices and consumer protection."
    ],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1699362772538
  },
  {
    "title": "Startups Fill in the Trust and Safety Gap Left by Big Tech, But Experts Caution Risks",
    "originLink": "https://www.wired.com/story/trust-and-safety-startups-big-tech/",
    "originBody": "VITTORIA ELLIOTT BUSINESSNOV 6, 2023 2:29 PM Big Tech Ditched Trust and Safety. Now Startups Are Selling It Back As a Service The burgeoning trust and safety industry promises to help tech companies navigate scrutiny and regulation. But these services bring problems of their own. PHOTO-ILLUSTRATION: ANJALI NAIR; GETTY IMAGES Massive layoffs across the tech sector have hit trust and safety teams hard over the past year. But with wars raging in Ukraine and the Middle East and more than 50 elections taking place in the next 12 months, experts worry that a nascent industry of startups created to keep people safe online won’t be able to cope. The cuts made headlines a year ago, when X (then Twitter) fired 3,700 people—including hundreds in trust and safety roles. Since then, Meta, Alphabet, and Amazon have made similar cuts. The layoffs at X inspired other platforms to do the same, argues Sabhanaz Rashid Diya, founding director at tech policy think tank the Tech Global Institute and a former member of Meta’s policy team. “In many ways, Twitter got away with it,” she says. “That’s given the other companies the confidence to say, ‘You know what? It’s OK. You can survive and not face a terrible consequence.’” Still, the cost of these cuts is arguably already evident in the way major platforms have scrambled to respond to the war between Israel and Hamas. And the shift away from in-house trust and safety teams has created an opening for consultancies and startups to offer something new: trust and safety as a service. These companies, many of them founded and staffed by people with Big Tech pedigrees, let platforms “buy rather than build” trust and safety services, says Talha Baig, a former Meta engineer whose startup, Sero AI, recently received backing from accelerator Y Combinator. “There is a lot more labor out on the marketplace, and there’s also a lot more customers willing to buy that labor.” But experts warn that outsourcing trust and safety also means outsourcing responsibilities to teams with no power to change the way platforms actually work. Sahar Massachi, a former member of Meta’s civic integrity team and cofounder and executive director of the Integrity Institute think tank, worries that by outsourcing key functions, platforms may be undermining their ability to improve products. Trust and safety issues can sometimes be more about product design than active moderation—should a user be able to reshare content? How much weight should different metrics be given within a recommendation algorithm? “The vendors could be great, but they won’t be able to have insight into that because of the ways that companies work,” Massachi says. MOST POPULAR BUSINESS Where the Hell Is X CEO Linda Yaccarino? VITTORIA ELLIOTT GEAR Here’s Everything You Can Do With Copilot, the Generative AI Assistant on Windows 11 DAVID NIELD GEAR 30 Essential Home Repair Tools You Should Have MATT JANCER SCIENCE The JWST Has Spotted Giant Black Holes All Over the Early Universe CHARLIE WOOD The same is true of the AI systems that companies use to help flag potentially dangerous or abusive content. Platforms often use huge troves of data to build internal tools that help them streamline that process, says Louis-Victor de Franssu, cofounder of trust and safety platform Tremau. But many of these companies have to rely on commercially available models to build their systems—which could introduce new problems. “There are companies that say they sell AI, but in reality what they do is they bundle together different models,” says Franssu. This means a company might be combining a bunch of different machine learning models—say, one that detects the age of a user and another that detects nudity to flag potential child sexual abuse material—into a service they offer clients. And while this can make services cheaper, it also means that any issue in a model an outsourcer uses will be replicated across its clients, says Gabe Nicholas, a research fellow at the Center for Democracy and Technology. “From a free speech perspective, that means if there’s an error on one platform, you can’t bring your speech somewhere else–if there’s an error, that error will proliferate everywhere.” This problem can be compounded if several outsourcers are using the same foundational models. By outsourcing critical functions to third parties, platforms could also make it harder for people to understand where moderation decisions are being made, or for civil society—the think tanks and nonprofits that closely watch major platforms—to know where to place accountability for failures. Science Your weekly roundup of the best stories on health care, the climate crisis, genetic engineering, robotics, space, and more. Delivered on Wednesdays. Your email SUBMIT By signing up you agree to our User Agreement (including the class action waiver and arbitration provisions), our Privacy Policy & Cookie Statement and to receive marketing and account-related emails from WIRED. You can unsubscribe at any time. This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply. “[Many watching] talk as if these big platforms are the ones making the decisions. That’s where so many people in academia, civil society, and the government point their criticism to,” says Nicholas,. “The idea that we may be pointing this to the wrong place is a scary thought.” Historically, large firms like Telus, Teleperformance, and Accenture would be contracted to manage a key part of outsourced trust and safety work: content moderation. This often looked like call centers, with large numbers of low-paid staffers manually parsing through posts to decide whether they violate a platform’s policies against things like hate speech, spam, and nudity. New trust and safety startups are leaning more toward automation and artificial intelligence, often specializing in certain types of content or topic areas—like terrorism or child sexual abuse—or focusing on a particular medium, like text versus video. Others are building tools that allow a client to run various trust and safety processes through a single interface. MOST POPULAR BUSINESS Where the Hell Is X CEO Linda Yaccarino? VITTORIA ELLIOTT GEAR Here’s Everything You Can Do With Copilot, the Generative AI Assistant on Windows 11 DAVID NIELD GEAR 30 Essential Home Repair Tools You Should Have MATT JANCER SCIENCE The JWST Has Spotted Giant Black Holes All Over the Early Universe CHARLIE WOOD Big Tech companies have tended to see trust and safety as a cost center, says Baig—something they have to do to keep regulators and civil society groups at bay, but without much monetary value. But that soon may change. The European Union’s Digital Services Act and the UK’s Online Safety Act, for instance, have created new obligations for tech companies big and small to monitor what happens on their platforms, and these pieces of legislation allow governments to levy huge fines. “Companies don’t change the way in which they moderate content on their platform to gain 5, 10, 30 percent efficiency,” says Tremau’s Franssu. “What will motivate them is if they’re scared of getting fined, especially fines as big as 6 percent of global annual revenue, or criminal liability, as we may see in the UK.” New regulations in the UK and Europe will also come to bear on smaller platforms, particularly around the kinds of content and services children can access. Startups may prefer to buy trust and safety as a service, rather than building their own teams and systems, says Sara Ittelson, a partner at the venture fund Accel, which has invested in the trust and safety tool Cinder. “It used to be that companies thought that trust and safety issues were only surfacing for platforms of a particular size,” she says. “But in reality, you’re going to get them pretty early on.” And people, she argues, ultimately don’t want to use platforms they don’t feel safe on or that are full of junk content. The explosion of interest in generative AI has only increased the pressure on companies to address trust and safety issues earlier in their life cycles. Generative AI tools can now be used to manufacture and share child sexual abuse material and nonconsensual pornography, both of which would violate most platforms’ guidelines. “There’s much greater awareness as to how these tools can be exploited,” Ittelson says. This has raised questions for companies about how they are going to make sure their platforms aren’t overrun with generative AI content, or how they’re going to ensure their tools aren’t abused. “Gen AI is making it 10 times worse,” says Dror Nahumi, a partner at Norwest Venture Partners, which has invested in trust and safety startup ActiveFence. “If I’m a bad actor and I was creating an article a week, now I could create 10 different posts in the same week without making any extra effort.” MOST POPULAR BUSINESS Where the Hell Is X CEO Linda Yaccarino? VITTORIA ELLIOTT GEAR Here’s Everything You Can Do With Copilot, the Generative AI Assistant on Windows 11 DAVID NIELD GEAR 30 Essential Home Repair Tools You Should Have MATT JANCER SCIENCE The JWST Has Spotted Giant Black Holes All Over the Early Universe CHARLIE WOOD While investors that spoke to WIRED were hesitant to guess at the potential size of the trust and safety as a service industry, ActiveFence, which was founded in 2017 and is amongst the oldest players in field, raised $100 million in 2021 and was valued at about half a billion dollars in 2021. And its cofounder, Noam Schwartz, says that valuation has risen. While it’s still nascent, the industry is clearly growing. “This is exactly the way the cybersecurity industry was 20 years ago,” says Schwartz. A 2020 report from the venture capital firm Paladin Capital found that the industry had already raised over $1 billion in funding, and a 2023 report from the UK Department for Science Innovation, and Technology estimated that “Safety Tech,” which includes everything from content moderation to scam detection, was on track to hit £1 billion ($1.22 billion) in revenue by the mid-2020’s. Though Nahumi says the Big Tech layoffs may indicate that there is, momentarily, less appetite to spend on trust and safety in general, “in the long term, we see that as a good thing for the companies in the space because it means that [tech companies] will have to rely more and more on services from companies that specialize in the space, and not something built in-house.”",
    "originSummary": [
      "Tech giants like Meta, Alphabet, Amazon, and Twitter have downsized their trust and safety teams, leading to a surge in startups offering these services back to the companies.",
      "These startups are relying heavily on automation with AI and machine learning to detect dangerous content. However, experts warn that this could lead to errors spreading across all client platforms due to outsourcing.",
      "Despite these concerns, possible regulatory fines and the effects of generative AI are pressuring companies to enhance online safety more efficiently, making these startup solutions increasingly attractive."
    ],
    "commentBody": "",
    "commentSummary": [
      "In the wake of big tech companies like Meta, Alphabet, Amazon, and Twitter downsizing their trust and safety teams, there's a growing sector of tech startups offering these services back to them.",
      "However, concerns have been raised about potential problems such as the inability for these outsourced teams to alter company operations and the possibility of errors arising from the use of AI and machine learning for dangerous content detection.",
      "Critics argue that outsourcing complicates pinpointing where moderation decisions are made, while generative AI and potential regulatory fines are intensifying the pressure on companies to improve online safety promptly and effectively."
    ],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1699362772538
  },
  {
    "title": "Rising Demand for AI Professionals Outpaces Supply in China Amid Tech Firms' Race for Large Language Models",
    "originLink": "https://www.scmp.com/tech/tech-trends/article/3240656/chinas-ai-talent-pool-limited-amid-surging-job-demand-triggered-chatgpt-race-report-finds",
    "originBody": "Artificial intelligence + FOLLOW Get more with myNEWS A personalised news feed of stories that matter to you Learn more The surging demand for jobs in artificial intelligence is largely driven by increased competition among China's Big Tech companies. Image: Shutterstock TechTech Trends China’s AI talent pool limited amid surging job demand triggered by ChatGPT race, report finds The surging job demand is largely driven by increasing competition among China Big Tech to launch their large language models and applications Algorithm and natural language processing engineers are most sought after, accounting for 46 per cent and 11 per cent of demand, respectively Ben Jiang in Beijing + FOLLOW Published: 7:00pm, 7 Nov, 2023 Why you can trust SCMP For every five new jobs in artificial intelligence (AI) in China, there are only two qualified workers in the labour market, a sign of the serious shortage of talent in the hot sector, according to a newly published report. The surging demand is largely driven by increasing competition among Chinese Big Tech firms, including TikTok parent ByteDance, e-commerce powerhouse Alibaba Group Holding, video gaming giant Tencent Holdings and telecommunications equipment maker Huawei Technologies, to launch their large language models (LLMs) and AI applications, according to a report by Maimai, a career-focused social network service. ByteDance had the largest demand among its peers, with the most openings for AI jobseekers over the last three years. China’s career hopefuls find slim prospects in diminished job market From January through August, the top five Chinese tech firms with the most AI jobs were ByteDance, food delivery giant Meituan, lifestyle social media platform Xiaohongshu, Alibaba and Huawei. Baidu and Tencent, which have both invested heavily in their generative AI services, came in sixth and seventh respectively. Alibaba owns the South China Morning Post. A raft of AI chatbots developed by Chinese tech giants have received government approval for public roll-out. The companies are now racing to infuse their products with AI, as well as the business operations of potential customers, to enhance productivity. The demand has also pushed average monthly salaries for AI talent to 46,518 yuan (US$6,388), a more than 6 per cent increase from last year. The figure dwarfs the average monthly salary of 18,976 yuan for white collar workers in Beijing, according to information from Chinese headhunting service Liepin. Algorithm and natural language processing engineers are the most sought-after talent, accounting for 46 per cent and 11 per cent of AI job demand, respectively, while computer-vision engineers, algorithm researchers, autonomous-driving-system engineers and data-mining engineers fill out the remainder. Sign up for our Newsletters Find out more The role of ChatGPT researcher accounted for 1.23 per cent of all available AI talent, highlighting efforts by Chinese tech firms to learn from OpenAI’s groundbreaking conversational bot ChatGPT that was launched almost a year ago, triggering a global AI arms race. The Maimai report found that of all AI posts, corporate employers were willing to shell out the most for ChatGPT researchers, who earn as much as 66,000 yuan per month. A huge AI logo is displayed at the Smart China Expo, August 27, 2019. Photo: Shutterstock Images Beijing, where almost half of the country’s AI models are developed, accounted for 36 per cent of new AI job openings from January to August, followed by financial hub Shanghai, southern tech hub Shenzhen, eastern Hangzhou, and Guangzhou, the capital of southern Guangdong province. The top five cities generated almost 80 per cent of the country’s need for AI jobs, a sign of the concentration of the industry in top-tier Chinese cities. The AI sector has become a rare bright spot in an otherwise downcast Chinese job market, separate research by Liepin noted earlier this year. Fresh graduates with degrees related to LLMs are in short supply in a market where the youth jobless rate has hit record highs, according to Liepin’s 2023 employment report for Chinese university graduates. Post",
    "originSummary": [
      "There is a high demand for jobs in AI (Artificial Intelligence) in China that exceeds the current supply of qualified personnel; the ratio is five available jobs to every two suitable candidates, according to a Maimai report.",
      "Major Chinese tech firms including ByteDance, Alibaba, Tencent, and Huawei are driving this demand as they compete to develop large language models and AI applications, with ByteDance showing the highest requirement of AI professionals in recent years.",
      "Jobs like algorithm engineering and natural language processing make up a significant portion of the AI job demand at 46% and 11% respectively, while the average pay for AI jobs has increased by over 6%, further increasing the industry's attractiveness."
    ],
    "commentBody": "",
    "commentSummary": [
      "The demand for AI jobs in China is exceeding the supply of qualified workers, creating five new jobs for every two suitable candidates, as per a report by Maimai.",
      "The fierce competition among ByteDance, Alibaba, Tencent, and Huawei to develop AI applications and large language models fuels this high demand, with ByteDance leading in AI job posts.",
      "The most in-demand roles are algorithm and natural language processing engineers, comprising 46% and 11% of job demand, while AI professionals have seen their average salary rise by over 6%."
    ],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1699362772538
  },
  {
    "title": "Baidu Shifts from Nvidia to Huawei for AI Chips Amid US Pressure",
    "originLink": "https://www.reuters.com/technology/baidu-placed-ai-chip-order-huawei-shift-away-nvidia-sources-2023-11-07/",
    "originBody": "Technology Exclusive: Baidu placed AI chip order from Huawei in shift away from Nvidia Reuters November 7, 20239:14 AM UTCUpdated 4 hours ago Baidu sign is seen at the World Artificial Intelligence Conference (WAIC) in Shanghai, China July 6, 2023. REUTERS/Aly Song/File Photo Acquire Licensing Rights BEIJING/SHANGHAI, Nov 7 (Reuters) - Baidu (9888.HK) ordered artificial intelligence chips from Huawei (HWT.UL) this year, two people familiar with the matter said, adding to signs that U.S. pressure is prompting Chinese acceptance of the firm's products as an alternative to Nvidia's. One of the people said Baidu, one of China's leading AI firms, which operates the Ernie large language model (LLM), placed the order in August, ahead of widely anticipated new rules by the U.S. government that in October tightened restrictions on exports of chips and chip tools to China, including those of U.S. chip giant Nvidia (NVDA.O). Advertisement · Scroll to continue Baidu ordered 1,600 of Huawei Technologies' 910B Ascend AI chips - which the Chinese firm developed as an alternative to Nvidia's A100 chip - for 200 servers, the source said, adding that by October, Huawei had delivered more 60% of the order, or about 1,000 chips, to Baidu. The second person said that the order's total value was approximately 450 million yuan ($61.83 million) and that Huawei was to deliver all of the chips by the end of this year. Both people declined to be named because the details of the deal were confidential. Advertisement · Scroll to continue Although the order is tiny relative to the thousands of chips top Chinese tech firms have historically ordered from Nvidia, the sources said it was significant, as it showed how some firms could shift away from the U.S. company. Baidu, alongside Chinese peers such as Tencent (0700.HK) and Alibaba (9988.HK), is known to be a long-time client of Nvidia. Baidu was not previously known to be a AI chip customer of Huawei. Advertisement · Scroll to continue Although Huawei's Ascend chips are still seen as far inferior to Nvidia's in terms of performance, the first source said they were the most sophisticated domestic option available in China. \"They were ordering 910B chips to prepare for a future where they may no longer be able to purchase from Nvidia,\" the first source said. Baidu and Huawei did not respond to requests for comment. Nvidia declined to comment. Huawei's website says it has since 2020 collaborated with Baidu to make its AI platform compatible with Huawei hardware. In August, the two companies said they would deepen compatibility between Baidu’s Ernie AI model and Huawei’s Ascend chips. Baidu has developed its own line of Kunlun AI chips, which the company says supports large-scale AI computing, but the company has mainly relied on Nvidia's A100 chip to train its LLM. After the U.S. last year imposed rules stopping Nvidia from selling its A100 and H100 chips to China, the company issued new A800 and H800 chips as alternatives for Chinese customers, including Baidu. Nvidia is no longer able to sell those chips to China because of the October rules. HUAWEI OPPORTUNITY Analysts predicted last month that the U.S. curbs would create an opening for Huawei to expand in its $7 billion home market. The company has been the subject of U.S. export controls since 2019. The order adds to signs of technological advances for Huawei, as Beijing pours investment into its domestic semiconductor industry to help it catch up with overseas peers and urges state-owned firms to replace foreign technology with domestic alternatives. Huawei drew substantial global attention in August when it unexpectedly unveiled a new smartphone that analysts said uses internally developed processors featuring advanced semiconductor technology, highlighting the company's progress in chip development despite sanctions. In September, Reuters reported that Huawei's in-house chip design unit, HiSilicon, had commenced shipments of newly developed Chinese-made processors for surveillance cameras to clients in 2023 in another comeback sign. ($1 = 7.2782 Chinese yuan renminbi) Reporting by Yelin Mo, Zhang Yan and Brenda Goh; Additional reporting by Josh Ye in Hong Kong; Editing by Gerry Doyle Our Standards: The Thomson Reuters Trust Principles. Acquire Licensing Rights , opens new tab Read Next Technology category Intel shelves planned chip operation expansion in Vietnam - source Intel has shelved a planned investment in Vietnam that could have nearly doubled the U.S. chipmaker's operation there, one person briefed on the plans said, in a blow to the country's growing ambitions in the chips industry. Technology category How Huawei plans to rival Nvidia in the AI chip business U.S. curbs on the sales of advanced artificial chips by Nvidia to China are creating an opening for Huawei to win market share, with sources saying it won a sizeable AI chip order from Chinese tech giant Baidu this year. Technology category Exclusive: Meta bars political advertisers from using generative AI ads tools Facebook owner Meta is barring political campaigns and advertisers in other regulated industries from using its new generative AI advertising products, a company spokesperson said on Monday, denying access to tools that lawmakers have warned could turbo-charge the spread of election misinformation. Technology category Nintendo hikes profit forecast as Switch battles on Nintendo on Tuesday raised its operating profit forecast for the financial year ending March by 11% to 500 billion yen ($3.32 billion) as heavy-hitting franchises continued to attract gamers to its aging Switch console. Technology category Musk's Starlink wins bid to roll out Mexico's rural satellite internet -documents Starlink, the satellite internet service of billionaire Elon Musk's rocket manufacturer SpaceX, has won a tender from Mexico's state energy firm to provide services through December 2026, according to documents seen by Reuters on Monday.",
    "originSummary": [
      "Baidu, a Chinese internet giant, has switched from Nvidia to Huawei for artificial intelligence (AI) chips amid increased US pressure and export restrictions on chips to China.",
      "This significant shift suggests that Baidu is preparing for a future where access to Nvidia might be limited, given Baidu's long-term customer relationship with Nvidia.",
      "Despite being generally considered less superior than Nvidia's, Huawei's Ascend chips are seen as the most advanced domestic option in China, indicating a larger shift towards Huawei's products."
    ],
    "commentBody": "",
    "commentSummary": [
      "Baidu, the Chinese internet giant, ordered artificial intelligence (AI) chips from Huawei, marking a shift away from Nvidia amid escalating US export restrictions.",
      "Baidu's decision, interpreted as readiness for a future without access to Nvidia, indicates a significant paradigm shift as Baidu has been a long-standing Nvidia customer.",
      "Huawei's Ascend chips, though generally considered inferior to Nvidia's, are recognized as the top domestic choice in China, suggesting a wider acceptance of Huawei's products within the country. However, no comments have been provided by Baidu, Huawei, or Nvidia about this incident."
    ],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1699362772538
  },
  {
    "title": "Big Tech Companies Including Meta, Google, Microsoft, Face Lawsuits over Alleged Copyright Infringements in AI Training",
    "originLink": "https://nymag.com/intelligencer/2023/11/how-big-tech-companies-really-think-about-ai.html",
    "originBody": "SCREEN TIME NOV. 6, 2023 How Big Tech Companies Really Think About AI By John Herrman Photo-Illustration: Intelligencer; Photo: David Paul Morris/Bloomberg via Getty Images If you’re a big generative AI company, that means you’re currently in the process of getting sued, vigorously and by multiple parties at once. Multiple groups of authors, one with the Authors Guild, have filed suit against OpenAI and Meta for training their models on copyrighted material. Alphabet has been accused in a class action of “mass theft” and of scraping “everything ever created and shared on the internet by hundreds of millions of Americans.” Visual artists have filed suit against Midjourney and Stability AI; Stability AI is also the defendant in a lawsuit filed by Getty Images, which claims the company’s model was trained, without permission, on millions of its photos. Anthropic is being sued by record labels over lyrics. Microsoft is getting sued by anonymous software developers over a coding tool in GitHub. These lawsuits vary in scope and seriousness and collectively touch on not just copyright but, from various legal and ethical angles, questions of privacy and consent. They’re sort of all over the place, but with good reason: This is new territory, and it’s not yet clear how existing laws and legal precedents relate to technologies that, to the plaintiffs and lots of other people, seem like they might be built on a foundation of theft and for something like copying. A lot of their claims will likely be dismissed, and some of these suits have already been pared down. Mauricio Uribe, a partner at law firm Knobbe Martens, describes this early round of suits filed against OpenAI, Google, and Microsoft as akin to “seeing the undercard of the prize fight” — the type of suit that will eventually help settle what are still emerging as the core legal questions about generative AI, like whether training models on millions of pieces of copyrighted material is protected, as companies like OpenAI claim, by fair use. The courts can have fun with questions like that. In the meantime, we can have fun learning something else. Tech companies have responded to most of these lawsuits with filings of their own — mostly motions to dismiss — that contain not just legal arguments but full-throated defenses, on behalf of their clients, of generative AI as a project and as an industry. For the most part, Uribe says, these are “completely extraneous to legal questions.” But they’re also kind of wild, revealing how these companies talk about AI when threatened or when there’s money on the line. Take Google, whose lawyers set up a motion to dismiss like this: Generative artificial intelligence (“AI”) holds perhaps unprecedented promise to advance the human condition. It is already beginning to revolutionize the way we use technology, serving as a companion that can help research, summarize, and synthesize information; brainstorm ideas; write original creative or factual text and software code; and create images, videos, and music. It will open doors to new insights and forms of expression, as well as better, personalized help and advice in areas such as education, health care, government services, and business productivity. The plaintiff’s “383-paragraph anti-AI polemic,” Google’s lawyers say, “would take a sledgehammer not just to Google’s services but to the very idea of generative AI,” i.e., that thing that we’ve just been told will advance the human condition. “To realize the promise of this technology,” they say, “generative AI models must learn a great deal,” and like “a human mind” they require “a great deal of training” to do so, concluding that “using publicly available information to learn is not stealing.” Google routinely makes pretty bold public claims about AI. In a September letter, CEO Sundar Pichai said it would be “the biggest technological shift we see in our lifetimes.” But the company tends to make these claims in the passive voice, with lots of caveats about safety, caution, and its “collaborative” openness to regulation, with an obligatory nod to not getting things wrong and minimizing harm. In legal filings, instead, we get an unqualified argument: AI is important, maybe the most important thing in the world; Google must be allowed to do what it’s doing to help AI realize its potential. Stability AI, in its response to a lawsuit by visual artists, takes a similar approach and suggests that it is at the forefront of an industry that is “rapidly expanding the boundaries of human creativity and capability.” Who would want to get in the way of something like that? OpenAI’s lawyers open a motion to dismiss with a litany of other people’s words. “While the technology is still in its early days, some commentators believe that in the future, it may help to remedy ‘some of the world’s worst inequities,’ from unequal access to health care, to global educational disparities, and beyond,” the lawyers write. (The aforementioned “commentator” is Bill Gates.) “Others suggest that ChatGPT, in particular, ‘Heralds an Intellectual Revolution,’ representing an innovation whose significance may ultimately prove comparable to ‘the invention of printing.’” (These “others” are Henry Kissinger and Eric Schmidt.) Microsoft’s lawyers begin by mounting an argument that using AI is part of “GitHub and Microsoft’s ongoing dedication and commitment to the profound human project” of open-source software. Meta’s lawyers are a bit less dramatic, but they’re also up to something interesting. In their motion to dismiss a copyright case, they describe LLaMa, the company’s large language model, in humanizing terms. “Just as a child learns language (words, grammar, syntax, sentence structure) by hearing everyday speech, bedtime stories, songs on the radio, and so on,” the lawyers write, “LLaMA ‘learned’ language by being exposed — through ‘training’ — to ‘massive amounts of text from various sources,’ such as code, webpages, and books, in 20 languages.” This is, again, not legally relevant to the lawsuit. But, in addition to being sort of funny — I’m not sure that “just as” really carries us from a child’s “bedtime stories” to “massive amounts of text” in “20 languages” — this frames the debate over AI in a specific and perhaps useful way, casting models as innocent, curious, independent beings that simply want to learn, and positioning their creators as mere helpers in an intuitive, inevitable process of apprehension — as parents who want the best for their young … entities? Not as software and advertising companies fighting over what they’re allowed to do in service of creating and monetizing new software. You wouldn’t sue a child for humming a song, would you? Would you? None of this tells us much about the legal questions at hand, and judges will know to ignore it. These setups are followed mostly by aggressive legal argumentation calling into question every single premise of the plaintiffs’ claims, which is what the tech companies’ lawyers were hired to do: Of course training AI is fair use! Of course its outputs are transformative! Who are you to even take issue, here? Etc. What these arguments do provide is a glimpse into the future of how AI companies will talk about themselves. Leaders at Google, Microsoft, Meta, and especially OpenAI have enjoyed, over the last couple of years, the benefit of speaking theoretically. Most people in the world don’t have much, if any, direct experience with state-of-the-art AI tools; those that do have encountered them mostly in the context of demonstration, or as small features in software they already use. Figures like Sam Altman and Sundar Pichai have been relatively free to pontificate about what AI is and what it can do; they’re quite comfortable conceding potential harms or talking about responsibility and stewardship in the present and future tenses. They go out of their way to sound not just optimistic but cautious, generous, and humble about the future of AI and their parts in it. They do this because it’s good marketing. But they also do this because it’s easy. They’re not answering for specific, urgent grievances, but rather posing and responding to questions about how they plan to prevent the apocalypse. They’re not responding to public outcry. They’re not dealing with criticism — or even regulations — that cause them much worry, yet. But they will. And when they do, they’ll probably sound more like they already do in court, in addressing alleged past harms — copyright violation, theft, indiscriminate scraping — in addition to concerns about materially specific future harms: self-important, indignant, and shrill. They’ll have to defend what they’re doing, not just what they say they want to do, to regulators and eventually to a collective plaintiff, i.e., the public. And they might sound a little bit ridiculous. MORE SCREEN TIME What Happens When Ads Generate Themselves? Spotify Is Eating the Entire Music Business Is X (Formerly Twitter) Worth $1? SEE ALL SIGN UP FOR THE INTELLIGENCER NEWSLETTER Daily news about the politics, business, and technology shaping our world. Email TAGS: SCREEN TIME ARTIFICIAL INTELLIGENCE META GOOGLE MORE LEAVE A COMMENT",
    "originSummary": [
      "Numerous tech giants such as OpenAI, Google, Microsoft, and Meta are facing lawsuits for allegedly using copyrighted materials to train their AI models without consent.",
      "These lawsuits raise unresolved ethical and legal questions around copyright, privacy, and consent in the context of AI training.",
      "The defendants make a case that the use of public data for generative AI training, akin to human learning, doesn't constitute theft. The outcome of these cases might establish legal precedents for AI training and development."
    ],
    "commentBody": "",
    "commentSummary": [
      "Big tech firms like OpenAI, Google, Microsoft, and Meta are facing lawsuits accusing them of using copyrighted content to train their Artificial Intelligence (AI) models without consent.",
      "These lawsuits pose still unclear ethical and legal dilemmas related to copyright, privacy, and consent in the realm of AI.",
      "The defendants maintain that generative AI requires substantial training, akin to human cognition, and that utilizing publicly accessible data is not an act of theft. These cases could influence future legal frameworks for AI training and development."
    ],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1699362772538
  },
  {
    "title": "Enterprise Software Stocks Underperform Amid Corporate America's Reduced Software Spending",
    "originLink": "https://www.theinformation.com/articles/behind-enterprise-software-stocks-lackluster-year",
    "originBody": "The Briefing markets enterprise Behind Enterprise Software Stocks' Lackluster Year By Akash Pasricha akash@theinformation.c­om Profile and archive → Follow Akash on TwitterNov. 6, 2023 5:00 PM PST The good news from tech’s earnings season, so far, is that the ad market appears to have recovered a lot from the worst of the downturn. But that’s likely not true for enterprise software. While we haven’t yet heard earnings updates from most enterprise software firms, some of those who have reported suggest that business remains weak, thanks to a software spending pullback by corporate America. It’s no wonder that the enterprise software sector has been a tech disappointment this year. One proxy for software as a service stocks—the Bessemer Venture Partners Cloud Index, which tracks 71 software firms—is up just 15% this year, much less than the Nasdaq 100 Technology Sector Index, a broader basket of 38 tech firms, which is up 40% (see chart).",
    "originSummary": [
      "Enterprise software stocks have underperformed this year due to decreased business activity and a reduction in software spending by corporations.",
      "The Bessemer Venture Partners Cloud Index, which monitors 71 software companies, has seen a modest increase of only 15%, markedly below the 40% surge of the Nasdaq 100 Technology Sector Index.",
      "Despite a recovery in the tech ad market, this improvement is not reflected in the enterprise software sector."
    ],
    "commentBody": "",
    "commentSummary": [
      "The performance of enterprise software stocks has been unimpressive this year due to weakened business and reduced software expenditure by corporations.",
      "The Bessemer Venture Partners Cloud Index, tracking 71 software companies, only witnessed a 15% increase, which is significantly less than the 40% surge in the Nasdaq 100 Technology Sector Index.",
      "Even though the tech ad market shows signs of recovery from previous downturns, this upswing does not reflect in the enterprise software sector."
    ],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1699362772538
  },
  {
    "title": "Israeli Tech PR Experts Unite to Combat Misinformation Amid Crisis",
    "originLink": "https://www.calcalistech.com/ctechnews/article/r1scluwmp",
    "originBody": "24/7 Buzz Startups VC AI Innovation Opinions Events Promising Startups 2022 BiblioTech Boarding Pass Startup: Confidential Appointments CTalk Tech Gateways 2022 VC Survey @Finance Ctech Testimonials DataTech Projects AboutNewsletterContact usRSSFacebookTwitter ACCESSIBILITY by Homepage Projects 20 Minute Leaders 20 Minute Leaders HOME 24/7 buzz STARTUPS VC AI Innovation OPINIONS EVENTS ABOUT NEWSLETTERSEARCHCONTACT US ACCESSIBILITY Recently Read The shameful antisemitism of “Elite Institutions” From the U.S. Army to Marriage in Israel: the Legal Status of DNA Testing Kits The top travel-tech trends set to revolutionize tourism in 2023 Recommended videos The 50 most promising Israeli startups - 2023 Israeli Cybersecurity startups to watch out for in 2023 Photo: Noam Dor Startup Nation United Tech PR community fills the vacuum Rachel Glaser tells of how her fellow PR professionals united to ensure journalists had what they needed to tell our story as accurately as possible Michael Matias, Yaffa Abadi 10:43, 07.11.23 TAGS: Startup Nation United PR Israel-Gaza Conflict We all remember the panic and confusion that marked the days following October 7th, from scrambling to gather equipment and supplies for the IDF to finding shelter and safety for families in the Southern communities. No one was ready for the chaos. But another aspect of disorganization during the crisis was on the PR front. With thousands of journalists flocking to Israel from the moment the war began, there was not yet an organized team, resources, contacts, or footage to ensure the story of what was happening in Israel would be told as authentically and accurately as possible. This is where communications professional Rachel Glaser and a group of professional tech PR experts came into the picture. We spoke to Rachel about how she and her professional PR ecosystem rallied together to address this significant gap and establish an organized and coordinated effort to support journalists covering the atrocities of October 7th and onwards. The PR tech space is usually a highly competitive one. With competing tech companies and sometimes crowded spaces, many PR professionals, in-house and external, are fighting for coverage for their company and their executives. But like a microcosm of Israeli society, the PR community united with a singular mission. In Rachel's words, “We all just had this shared goal and this shared purpose of portraying Israel fairly and accurately in the media.” 2 View gallery Rachel Glaser United (Photo: Noam Dor) Rachel tells us of a Whatsapp group, Comms Cabal, where most PR professionals covering Israeli tech belong, one that is there to plan meet-ups and share occasional tips. But one month ago, this became the online headquarters for this team of PR warriors, a place where journalists could get whatever they needed before any official system was put into place. This encompassed tasks like sorting through the overwhelming number of videos and images, and meticulously labeling and organizing them into folders. The goal was to ensure journalists had access to correct and authentic B-roll footage to support their stories. Moreover, the group facilitated connections between journalists and families of hostages who could share their harrowing personal experiences with the world. They also took on crisis control duties by reaching out to news outlets with inaccurate and damaging headlines to correct the narrative, and so much more. The significance of their efforts is no secret. We have all seen the tendency for the media to spin an incorrect narrative, so having these PR professionals, ones with connections to every major outlet and with the know-how of sharing narratives, proved to be a valuable asset for our country. When discussing their actions and the unity they achieved from day one, Rachel offers a broader perspective: “I think, our little comms cabal group is just one very small indication of the unity among the people of Israel in every way. From real estate agents finding people housing to people cooking in Citizen's Kitchen preparing something like 5,000 meals for people in the South, to endless donations. People just stepped in where needed, worked together and took care of everything.” With their shared goal of telling our stories accurately and enabling personal stories of victims to come through to the forefront, these Comms professionals have stepped forward to lend their time and expertise and play this unique and significant role in these dark times. 2 View gallery Michael Matias and Yaffa Abadi (Photo: Omer HaCohen/Hagar Bader) About: Yaffa Abadi and Michael Matias co-produce Startup Nation United, a series showcasing how Israelis have united for a common vision and sharing stories of individuals in the tech industry who have rallied for social and tech initiatives during the ongoing war. Yaffa Abadi is the founder and CEO of Abadi Brands, a boutique consultancy specializing in personal branding and thought leadership for investors. With a background in private intelligence, leading F2 Venture Capital's communications, and experience in the CEO's office at monday.com, her ghostwritten work has been featured in publications such as Forbes, Business Insider, Bloomberg, Entrepreneur.com, Yahoo, and more. Michael Matias, Forbes 30 Under 30, is the CEO of Clarity, a startup that preserves trust in digital media by fighting deepfakes. Their enterprise security solution authenticates digital media and protects from social engineering and phishing. Previously he was an officer at 8200, studied AI and Computer Science at Stanford University, and serves on the boards of Tech2Peace and Make-A-Wish Israel. Michael is an active angel investor in the AI and Cyber domain, was a Venture Fellow at Innovation Endeavors and a Venture Partner at Secret Chord and J-Ventures. TAGS Startup Nation United PR Israel-Gaza Conflict Rss Contact Us Newsletter Facebook Twitter About CTechTerms of UsePrivacy Policy Developed by UI & UX by Basch_Interactive",
    "originSummary": [
      "A team of professional tech PR experts including Rachel Glaser, came together during the crisis of October 7th in Israel to facilitate accurate media representation.",
      "The group, known as 'Comms Cabal', utilized Whatsapp to connect journalists with families affected by the crisis, correct misinformation in news outlets, and support the narrative.",
      "Their collaborative effort is recognized as part of the 'Startup Nation United' series, which illuminates the unity and durability of Israel's tech sector during continuous conflict."
    ],
    "commentBody": "",
    "commentSummary": [
      "Amid a crisis following October 7th, Rachel Glaser and a coalition of Israeli tech PR professionals took action, organizing an approach to ensure the accurate representation of events in the media.",
      "Through a Whatsapp group called 'Comms Cabal', these PR experts sorted a multitude of images and videos, provided authentic information to journalists, liaised between journalists and affected families, and corrected misinformation in the news.",
      "Despite the competitive nature of the tech PR space, this collaborative effort, featured in the 'Startup Nation United' series, demonstrates the unity and resilience of Israel's tech industry during challenging times."
    ],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1699362772538
  }
]
