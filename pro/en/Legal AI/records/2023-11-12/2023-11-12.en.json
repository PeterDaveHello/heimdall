[
  {
    "title": "Deepfakes: The Dark Side of AI Calls for Stringent Laws",
    "originLink": "https://www.daijiworld.com/index.php/news/newsDisplay?newsID=1139290",
    "originBody": "Home News Obituary Recipes Charity Special ಕನ್ನಡ Live TV RADIO Advertise Matrimonial Properties Jobs Classifieds Red Chillies Music Ask Dr Greetings Astrology Tribute Of Love Latest Microsoft may bring its AI Copilot to 1 bn Windows 10 users: Report Sun, Nov 12 Muhurat trading & Diwali week to begin on an auspicious note Sun, Nov 12 Investors to focus on inflation data in the week ahead Sun, Nov 12 Almost half of Asia-Pacific companies exploring GenAI use cases Sun, Nov 12 Investors to focus on inflation data in the week ahead Sun, Nov 12 Deepfakes reveal dark side of AI, call for stringent laws Sun, Nov 12 May your celebrations be filled with warmth, prosperity: Apple CEO on Diwali Sun, Nov 12 BusinessDeepfakes reveal dark side of AI, call for stringent laws Sun, Nov 12 2023 12:07:06 PM New Delhi, Nov 12 (IANS): Deepfakes, which first emerged on the scene in 2019 with fake videos of Meta CEO Mark Zuckerberg and former US House Speaker Nancy Pelosi, are the 21st century’s alternative to Photoshopping --- creating images and videos of celebrities via a form of artificial intelligence (AI) called deep learning. If you have seen former US President Barack Obama calling Donald Trump a “complete dipshit”, or Zuckerberg having “total control of billions of people’s stolen data” -- and more recently a deepfake video of actor Rashmika Mandana that went viral on social media – you probably know what deepfake is. According to experts, the prevalence of deepfakes, which are compelling and AI-generated videos or audio recordings, has witnessed a notable increase in recent times. According to Sonit Jain, CEO of GajShield Infotech, this surge can be attributed to the growing accessibility of deep fake technology and its application in various domains. “Deepfakes have found utility in entertainment, political manipulation, and even fraudulent activities. Data protection and privacy laws should be strengthened to limit the collection and use of personal data for deepfake creation without explicit consent,” Jain told IANS. Deepfakes can be used in phishing attacks, convincing employees to take actions that compromise security. Abhishek Malhotra, Managing Partner at TMT Law Practice, said that technological advancement comes with a dark side, and unfortunately, this time, the impact is rather nasty. “Similar experiences were faced by actor Anil Kapoor, and he rightly approached the court of law for resolution. As would be logical in such situations, the court upheld the personal rights of the actor and recognised his right to prevent the abuse and misuse of his reputation and goodwill,” Malhotra said. In September, the Delhi High Court issued an interim order protecting the personality rights of Kapoor and restraining various entities from misusing his image, name, voice, or other elements of his persona for financial gain without his consent. Kapoor sought protection of his personality rights, aiming to prevent various entities, including unidentified individuals, from violating his personality rights by using his name, acronym 'AK,' nicknames like 'Lakhan,' 'Mr. India,' 'Majnu Bhai,' and the phrase 'Jhakaas,' as well as his voice and images, for commercial gain without his permission. “This judgment can be taken as an indication of what regulations in this space can look like. Freedom of speech and expression can never be exercised at the cost of the reputation of others, nor by encroaching into the personal lives of people,” Malhotra told IANS. Further, since efforts are already underway to crack down on fake news, it can be expected that similar treatment is afforded to AI deepfakes and memes, etc, said experts. According to them, the Mandana case underscores the need for a legal and regulatory framework to address deepfakes in the country, emphasizing the importance of preserving personality rights and curbing the misuse of AI tools to portray public figures in fictional scenarios. This emerging scenario may lead to the development of specific laws and regulations governing AI-generated content and memes, potentially impacting online speech and creative expression. It also raises questions about freedom of expression, especially in the context of memes, as it addresses the legal status of AI-generated content in comparison to human-created content. Deepfake technology poses a significant threat to the privacy and individual rights of public figures. As seen in the case of Mandanna, it can be used to create convincing fake videos that can potentially harm a person's reputation or even incite legal action. Deepfake technology can be weaponized to create deceptive content that poses a threat to national security. It can be used to manipulate public sentiment, create forged videos of politicians or leaders, and potentially incite chaos or conflicts, according to experts. Last week, Union Minister of State for Electronics and IT, Rajeev Chandrasekhar, said that those who find themselves impacted by AI-generated deepfakes should file first information reports (FIRs) at the nearest police stations and avail the remedies provided under the Information Technology (IT) Rules, 2021 and the Indian Penal Code (IPC). It is a legal obligation for online platforms to prevent the spread of misinformation by any user under the Information Technology (IT) Rules, 2021. \"They are further mandated to remove such content within 36 hours upon receiving a report from either a user or government authority. Failure to comply with this requirement invokes Rule 7, which empowers aggrieved individuals to take platforms to court under the provisions of the Indian Penal Code (IPC),\" the minister said. To address such risks, organisations should invest in cybersecurity measures, employee training, and awareness programmes while implementing monitoring and incident response plans to mitigate the potential security breaches caused by deepfakes, experts advised. Top Stories Mangaluru: Much-awaited wave pool inaugurated at Manasa Water Park 1 day ago 1 Leave a Comment Your Email address will not be published. Title: Deepfakes reveal dark side of AI, call for stringent laws You have 2000 characters left. Disclaimer: Please write your correct name and email address. Kindly do not post any personal, abusive, defamatory, infringing, obscene, indecent, discriminatory or unlawful or similar comments. Daijiworld.com will not be responsible for any defamatory message posted under this article. Please note that sending false messages to insult, defame, intimidate, mislead or deceive people or to intentionally cause public disorder is punishable under law. It is obligatory on Daijiworld to provide the IP address and other details of senders of such comments, to the authority concerned upon request. Hence, sending offensive comments using daijiworld will be purely at your own risk, and in no way will Daijiworld.com be held responsible. You might also like Popular Most Commented No place in Gaza is safe, situation in hospitals catastrophic: UNRWA Sun, Nov 12 Popular Israeli web series 'Fauda' star killed in Gaza: IDF Sun, Nov 12 Hostages and Missing Families Forum to sue top Hamas leaders in ICJ for Oct 7 attacks Sun, Nov 12 Tesla Model 3, Y leads US EV market in 1st nine months of 2023: Report Sun, Nov 12 Huge installation in Tel Aviv calls for death penalty for Hamas Sun, Nov 12 Iranian President slams US for supporting Israeli offensive against Gaza Sun, Nov 12 Gaza's main hospital out of service as fuel runs out: Palestinian official Sun, Nov 12 IDF to help evacuate babies from Al-Shifa hospital Sun, Nov 12 Egypt's Rafah land crossing from Gaza to reopen from today Sun, Nov 12 Sudan's warring parties trade blame over destroying major bridge in capital Sun, Nov 12 With BSY's son Vijayendra on top, K'taka BJP to take on a stronger Cong Sun, Nov 12 Beltangady: Destructive lone tusker spotted roaming at Charmady Sun, Nov 12 Kundapur: Bike-car collision claims life of youth after a month Sun, Nov 12 6 Mangaluru: Sub registrar's office biometric fraud – Police in pursuit of prime suspect Sun, Nov 12 3 Beltangady: Picnic tour in ambulance – Driver, passengers fined, vehicle impounded Sun, Nov 12 9 Man murders woman, her three children; mother-in-law critically hurt in attack Sun, Nov 12 38 Udupi: Daijiworld impact – Street lights installed on Udupi-Manipal national highway Sun, Nov 12 9 Sullia: Herd of seven elephants found near highway Sun, Nov 12 8 UPSC success story – India's first visually impaired woman IFS officer Sun, Nov 12 2 Mangaluru: Bus, truck collide near Ambedkar Circle at Jyoti - 4 including driver injured Sun, Nov 12 12 Corporate Office Daijiworld Residency, Airport Road, Bondel Post, Mangalore - 575 008 Karnataka India Telephone : +91-824-2982023. General Enquiry: office@daijiworld.com, News & Info : news@daijiworld.com Franchise Office Kishoo Enterprises, 3rd Floor, Mandavi Trade Centre, Kadiyali, Udupi – 576 102 Telephone : 0091-820-4295571 E-mail : udupi@daijiworld.com Daijiworld Middle East FZE, P.O.Box: 84772, Dubai, UAE Tel: 971-50-6597629 Fax: 971-4-2639207 Email: dubai@daijiworld.com News Obituary Recipes Special Red Chillies Music Copyright © 2001 - 2023. All Rights Reserved. Published by Daijiworld Media Pvt Ltd., Mangalore. Home About Contact Disclamier Privacy Policy Powered by ATC Online LLP",
    "originSummary": [
      "Deepfakes, which are AI-generated videos or audio recordings, have become more common and pose a threat to privacy and individual rights.",
      "Regulations and legal frameworks are necessary to address deepfakes and prevent their misuse for entertainment, political manipulation, and fraudulent activities.",
      "Online platforms have a responsibility to remove deepfake content upon receiving a report to combat the spread of misinformation, and organizations should invest in cybersecurity measures and employee training to mitigate potential security breaches caused by deepfakes."
    ],
    "commentBody": "",
    "commentSummary": [],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1699797351251
  },
  {
    "title": "Protecting Bollywood Celebrities: Tackling the Threat of Deepfake Technology",
    "originLink": "https://www.hindustantimes.com/cities/mumbai-news/how-deep-has-deepfake-struck-bollywood-101699729936623-amp.html",
    "originBody": "Home Latest News Cricket Education India World Cities Entertainment Lifestyle Astrology Editorials Shop Now World Cup 2023 Elections HT Premium HTCity Live Score Videos Photos Trending Web Stories Tech Business Sports Delhi News Mumbai News Bengaluru News Quickreads Daily Digest Following Games World Cup Schedule 2023 World Cup Points Table World Cup Most Runs World Cup Most Wickets News / Cities / Mumbai News / How deep has deepfake struck Bollywood? How deep has deepfake struck Bollywood? ByMeena Iyer Nov 12, 2023 04:51 AM IST Stakeholders in the industry are quietly revisiting their contracts to safeguard themselves from this potential threat. Mumbai: Earlier this week, film star Amitabh Bachchan strongly reacted when actress Rashmika Mandanna became the latest victim of deepfake – a morphed video of Mandanna had surfaced on social media. Bachchan called for an urgent need for legal and regulatory action to tackle the spread of fake content online. The recent Rashmika Mandanna deepfake case has exposed an ugly side of AI. (Getty Images) In September, the Delhi High Court granted film star Anil Kapoor an ex-parte, omnibus injunction restraining 16 entities from using his name, likeness and image by using Artificial Intelligence (AI), face morphing and even GIFs for monetary gain or commercial purpose. We're now on WhatsApp. Click to join. In fact, today many actors are looking to add clauses to their talent contracts, where they want film makers to specify that they will be safeguarded against AI or any such technology that may alter their name and image maliciously. Given the frenzy on the subject, HT spoke to Kapoor who feels, the time to act is now. The recent Rashmika Mandanna deepfake case has exposed an ugly side of AI. It is a clear-cut example of how AI can be misused to distort and morph images to affect the reputation of someone. More than that, it is a lesson for other public figures to actively monitor and take action against such acts. We need laws now to govern the use of AI. Are actors’ contracts being modified in the face of this new threat? Many newer contracts have already started incorporating specific language for AI. There is a greater need these days for actors to ensure that they are taking all measures to prevent use of their attributes by third parties. Amitabh Bachchan and you are seniors from the industry who woke up to the dangers of AI long before others did. Elaborate. In the past few years we’ve seen AI transform and develop at a rapid pace. It started with ChatGPT writing essays and stories and has grown exponentially since then. AI is now being regularly utilised by many creators across the globe. The frenzy surrounding blockchain, crypto and NFTs which came around the same time only underlines how technology has become pervasive in the arts. It was only a matter of time till this technology was going to be used to create audio visual content. Any actor with a fan following – no matter how big – is going to face situations where their name, image, likeness and personal attributes are commercially used without permission. Technology only increases the avenues. Mr Bachchan’s case was the first foray into AI, technology and personality rights in India. Soon after that, Screen Actors’ Guild protests began in the United States on similar lines. Are court cases the way forward? Yes. There is no legal framework for use of AI or AI in films. Personality rights in itself is a new and developing concept in India and this law will evolve with time. Legal action is the most viable option right now. We will have to see how the courts and government take steps to address the issue. Name, image, likeness contracts are big in the West. Even high school celebrity sports guys are being safeguarded against ‘being copied’. Are we late to wake up? The entertainment industry in India is growing rapidly every year, while simultaneously adapting to new technologies. This is bringing to light many issues that weren’t seen before and we are adapting as fast as we can to these changes. Without a doubt there are lessons to be learned from the West on how they have managed to tackle these issues. But it’s better late than never. Imitation is no longer flattering. It’s threatening! Fandom is generally flattering, however now something small can snowball into a larger issue. The potential for mischief, especially with the use of technology and the new avenues it has created, is astounding. Everyone enjoys flattery, but there is definitely a line that should not be crossed. Using another’s image without permission for personal gain, commercial purposes, or to spread ill will is not warranted at all. It can definitely pose a threat. But at the end of the day, the only persons who can act against it are the celebrities themselves. So, it depends on how they view it. Exciting news! Hindustan Times is now on WhatsApp Channels Subscribe today by clicking the link and stay updated with the latest news! Click here! SHARE THIS ARTICLE ON TOPICS Rashmika Mandanna Ai + 1 More OPEN APP",
    "originSummary": [
      "Bollywood industry stakeholders are taking measures to protect themselves from the increasing threat of deepfake technology following the case of actress Rashmika Mandanna being targeted.",
      "Actors are now including clauses in their contracts to safeguard against any technology that could maliciously alter their image or name.",
      "Amitabh Bachchan and Anil Kapoor, who have been outspoken about the dangers of AI, believe that legal action is necessary to address this issue and safeguard the rights of public figures in Bollywood."
    ],
    "commentBody": "",
    "commentSummary": [],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1699797351251
  },
  {
    "title": "DLSA Samba Concludes Successful Legal Services Week with Aid Distribution and Helpline Awareness",
    "originLink": "https://www.jammulinksnews.com/mb/newsdet.aspx?q=334494",
    "originBody": "Home Latest Citizen Reports Jammu Kashmir National Campus Jobs Cinema Plus Food Tenders Obituary Notices Travel Reviews Spiritual Sports News Archive SAMBADLSA Samba concludes Legal Services week activities Jammu Links News 11/11/2023 SAMBA: District Legal Services Authority Samba, under the aegis of JKLSA and under the guidance of Yesh Pal Kotwal, Chairman DLSA Samba, today culminated the Legal Services week activities which commenced on 7th of this Month. The program was inaugurated by Chairman DLSA Samba and thereafter Chairman DLSA Samba distributed Wheel Chairs, Walking Sticks, blankets and motor tricycles among the beneficiaries at ADR centre Samba. The aid was provided by the Department of Social Welfare Samba. Thereafter the Judicial Officers of District Court Complex Samba and Members of Bar Association Samba distributed Ration among the needy people of different villages of District Samba which was organized with the contribution of All the Judicial Officers of District Samba Another activity organized by DLSA Samba was Affixing of stickers on the local Auto Rickshaws displaying the Helpline no of DLSA Samba for the information of entitled Legal Aid Seekers. The legal aid is extended to eligible individuals as is mandated under Sec 12 of The Legal Services Authorities Act, 1987. The entitled persons can approach DLSA Samba for getting Legal Aid Lawyers for their respective cases. The activity was organized by DLSA Samba in collaboration with ARTO Samba and Astro Mahindra and Mahindra Ltd. The series of activities reflected the commitment of the DLSA Samba to provide free and competent services to the people of district Samba. The program witnessed the presence of all the Judicial Officers of District Court Complex, Senior and other Members of Bar Association Samba, ARTO, District Social Welfare Officer and his team along with beneficiaries , representatives from Astro Mahindra and Mahindra, Officers of LADC, Panel Advocates Staff and PLVs of DLSA Samba, Auto rickshaws owners etc. Subscribe to Jammu Links News Video Channel for daily headlines wrap up, interview and other exclusive video features. From The Author",
    "originSummary": [
      "The District Legal Services Authority in Samba, Jammu and Kashmir, has successfully concluded its Legal Services week activities.",
      "The activities included distributing aid to beneficiaries and providing ration to needy villages.",
      "The DLSA Samba also affixed stickers with a helpline number on local auto rickshaws to promote access to free and competent legal services for the people in the district."
    ],
    "commentBody": "",
    "commentSummary": [],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1699797351251
  },
  {
    "title": "AI and the Future of Work: Ensuring Democratic Control and Human Creativity",
    "originLink": "https://www.dollarsandsense.org/archives/2023/1123ovetz.html",
    "originBody": "AI and the Future of Work Workers’ struggles will determine how the latest round of automation will affect labor. By Robert OvetzNovember/December 2023 This article is from Dollars & Sense: Real World Economics, available at http://www.dollarsandsense.org This article is from the November/December 2023 issue. Subscribe Now at a 30% discount. The 149-day-long writers Guild of America (WGA) strike by 11,500 Hollywood screenwriters is one of the most important strikes in decades because it tamed the Hollywood corporate beast. Along with the 160,000 members of SAG-AFTRA, the actors’ union still on strike after nearly three months, the writers’ strike was perhaps the largest strike explicitly directed at the threat of artificial intelligence (AI) to human workers. After decades of disturbing dystopian film plots about humans being wiped out by AI and robots being smarter than us, the very people who wrote and acted in them saw AI coming for their own jobs. While such films once helped us work through our anxieties with this technology, today those who make them are living it. The strikes began only months after the high-profile release of Open AI’s ChatGPT reignited a global conversation about the impact of artificial intelligence on work. Along with other publicly available AI, such as the graphics generator Dall-E owned by the same company, AI now appears poised to do many kinds of work once thought exclusive to humans. These developments are prompting an anxious discussion about the future of labor. AI is already being integrated into a wide range of jobs, including making hamburgers, caring for the sick, writing papers, doing complex math and computer coding, making illustrations, analyzing complex legal documents, and even deciding whom to hire and fire. There is also a growing list of examples of AI replacing human workers entirely. This past spring, the nonprofit National Eating Disorders Association replaced its unionized workers with its “Tessa” chatbot, though the group later removed Tessa after it was found to be giving dangerous advice to clients. Some of the technology does not yet live up to the hype, but will it one day? Whether AI makes human workers obsolete, makes our work easier, or makes it even more exploitative will depend on the balance of power between the capitalist class and the working class. That struggle will not be fought out in the halls of government, where the AI corporations are already engaged in a charm offensive—such as during Senate hearings on AI this past May—in order to forestall a possible ban in favor of regulation. Strong unions and an organized working class can dictate the terms of a new deal that redistributes the fruits of increased productivity or does away with capitalism and work as we know it. Our future is being decided now whether we are ready or not. The WGA and SAG-AFTRA strikes clearly illustrate that although AI is unlikely to replace the entire human labor force, it is already making some kinds of work obsolete and deskilling others. Like all forms of technology before it, from the loom to the personal computer, AI is a terrain of class struggle. How that struggle turns out is yet to be decided. André Gorz’s Two Paths The threat of AI to human labor is hardly a new concern to scholars of work and capitalism. Nearly 40 years ago, French socialist philosopher André Gorz’s book Paths to Paradise foresaw the AI apocalypse and warned of two possible outcomes. In one possible future, productivity-increasing technology like AI would neuter working-class struggle by segmenting the working class into a small number of “elite waged workers” alongside a superfluous “mass of unemployed and precarious casual workers.” Gorz’s other possible future celebrated the abolition of work and the redistribution of wealth. This is a possibility because, Gorz wrote, “in the fully automated factory, the quantity of living labor drops towards zero, and so does purchasing power distributed as wages. Automation abolishes workers: equally, it abolishes potential buyers.” Without buyers and workers, Gorz foresaw a world in which work was abolished and replaced by democratic control over the economy and a society moving us past capitalism. But Gorz wasn’t very optimistic about the socialist possibility. He thought the dystopian future of automated capitalism was more likely. Rising productivity would allow a small group of workers to live in comfort as the great mass of global society suffered as superfluous humans, at best able to hope for occasional, precarious waged work. Without a powerful working class able to force firms to redistribute profits, Gorz was terrified of the use of automation to abolish work. Leaving the decisions to AI corporations will make dystopia increasingly likely, especially as it continues to be used in policing and war, making some of Hollywood’s supposedly futuristic films seem frighteningly realistic. It is more common to think of AI as another more sophisticated form of technology that can adapt and change its actions to solve problems based on new information it can generate itself (see sidebar “Automation vs. AI vs. Regenerative AI”). The Future of Work While it is still far in the future, we have already seen glimpses of the dystopian future foretold in sci-fi films like “Blade Runner,” “Avengers: Age of Ultron,” “Ender’s Game,” and “RoboCop.” Perhaps no film tells this story better than “Elysium,” in which the rich barricade themselves on a space station protected by a wall of armed AI-robot soldiers with their boots on the necks of the destitute horde back on Earth. Humanity as unnecessary, destructive, and superfluous is a common theme in the genre. In “Avengers: Age of Ultron,” Ultron destroys humanity—and the superheroes—instead of saving it as it was designed to do. It is a fulfillment of scientist Stephen Hawking’s 2014 warning that “the development of full artificial intelligence could spell the end of the human race.” Today, such visions of terror are the result of the lack of a coherent strategy to resist AI. In the European Union, the initiative has been seized by the social democratic parties and unions who are attempting to ameliorate and benefit from AI, rather than fight it. Think tanks, social democratic parties, and unions in the United States and European Union view AI as a question of privacy and safety, and have mostly approached it in terms of accountability, equity, inclusion, and transparency. This approach reduces a question of political economy to one of individual rights. Automation vs. AI vs. Regenerative AI In this article the terms “automation,” “AI,” and “generative AI” are used interchangeably. Automation can be any type of technology that replaces human labor by completing pre-programmed tasks with little to no human intervention. AI can be understood as a type of automation that uses available data to complete a task and can adapt its actions based on interpretations of new information and programming. Generative AI uses the existing data to create something new based on its capacity to make decisions, predict outcomes, and solve problems thus creating new data based on its analysis of patterns in the existing data used to program it. In short, AI interprets existing data but regenerative AI can use the data to create new data. AI and the Rationalization of Labor A class analysis of AI sees it as the latest type of technology designed to deskill and replace human labor. There are two simultaneous impacts of AI on both low-skilled and higher-skilled work. While automation uses programmed operations to allow a machine to complete a sequence of tasks, traditional AI uses data fed to it by programmers to make decisions or predictions based on its programming. A more advanced type of AI known as “generative AI” can use new information to autonomously adapt, change its actions, create something new, and even generate its own new data without the direct intervention of programmers. Both types of AI, like all forms of automation, are designed to reduce the dependence of capital on human labor. In general, employers want to use AI to break our work into component tasks, a process referred to as the “rationalization” of labor, in order to determine which ones can be automated. Some types of complex tasks are already being accomplished by AI, leaving behind other tasks that cannot yet be automated to be done by human workers who augment the AI. The debate is still ongoing about whether AI will augment or replace human labor. According to an International Labour Organization (ILO) study, the largest impact of generative AI will be in office work; many clerical and writing tasks will be automated, leaving behind only deskilled office workers to maintain machines running the AI, rather than doing the tasks the AI now accomplishes. The ILO study predicts that fewer high-wage and many low-wage jobs will be created to service the technology, with workers functioning as what Karl Marx and Friedrich Engels famously called “appendages of the machine.” While the ILO estimates a modest 48 million jobs will be automated worldwide, 181 million will be augmented by AI, with the greatest impact on work done by women. Other estimates vary widely about the number of jobs that AI will allow to be fully or partially automated. In 2017, the corporate consulting firm McKinsey estimated that 60% of all jobs are vulnerable to some degree of automation, resulting in 400 to 800 million workers becoming obsolete by 2030. The Organization for Economic Cooperation and Development (OECD) reported that “27% of jobs are in occupations at high-risk of automation,” particularly in very skilled professions such as finance, medicine, and law. Researchers from OpenAI, the same company that invented ChatGPT, warn that about 80% of U.S. workers could see as much as 10% of their work automated. In total, 19% of jobs have at least 50% of what they do at risk of automation. The OpenAI report established the dominant narrative among employers that “routine and repetitive tasks” are the most vulnerable to being automated by AI, but in fact, it is likely to impact more highly skilled types of work as well. The result will be a higher rate of productivity by the workers still left whose work augments the AI. As a result, the consistent rise in productivity will continue to result in stagnant or declining wages as the productivity gains are passed along as higher profits. The ILO study estimates that “in the near future, generative AI systems similar to GPT are more likely to become productivity tools, supporting and speeding up the execution of some tasks within certain occupations.” A 2019 study by Daron Acemoglu of MIT and 11 other researchers found that AI was already making us work harder and produce more for less pay. As AI is introduced into the workplace, it reduces the number of human workers and human work hours, while increasing productivity for those workers who remain. The issue is not whether AI will have an impact on work, but that it is already having one. A survey by the human resources and recruiting contractor Checkr found approximately 85% of workers have already used AI in their jobs. The question is how quickly that impact will intensify and spread. The already-widespread use of algorithms, learning-management systems, and automated software functions such as spell checks, internet searches, and chatbots in our work is an indicator of how rapidly we can expect more AI in the workplace. Traditional AI has already had a large impact on manual labor, including many kinds of service work and manufacturing, for several decades—a trend that will no doubt continue. Now, generative AI has begun to replace more complex types of “cognitive” work. KPMG’s U.K. labor market study (see table) projects that authors, writers, and translators will have 43% of their tasks automated in the next decade. Programmers, software developers, PR and communications workers, and IT support are estimated to have 20% or more of their work tasks affected. Scientists and higher education faculty were the lowest on the list, but still face 6% of their work being automated by AI. A Future Dystopia Whether AI augments, deskills, or makes some kinds of human workers obsolete, it will likely bring the Global North into much closer alignment with the rest of the world, where formal employment is precarious, tedious, and poorly paid. Working for a specific boss, in a single workplace, and with regular pay has long been nonexistent for most of the human population. According to the ILO, in Africa, 85.8% of people have no formal jobs. That number is 68.2% in Asia and the Pacific, 40% in the Americas, and 25.1% in Europe and Central Asia. In the United States, estimates for precarious labor range widely. The U.S. Bureau of Labor Statistics says it comprises 10.1% of the workforce. McKinsey estimates it at 32%. These developments are hardly surprising. In 1867, Marx already imagined the automated factory run by self-learning AI. In Capital Volume I, he wrote that “As soon as a machine executes, without man’s help, all the movements required to elaborate the raw material, and needs only supplementary assistance from the worker, we have an automatic system of machinery, capable of constant improvement in its details.” The focus on AI obscures not only the loss of social control when human labor is rendered obsolete, but why the technology is used in the first place. Just like the National Eating Disorders Association’s misstep with AI or the Hollywood studios’ desire to use AI writers and actors, bosses everywhere attempt to reduce their reliance on workers by augmenting or replacing them with new productivity-increasing technology. They are especially keen to do so when workers attempt to organize and assert their power. Bosses often introduce technology in response to worker organizing, disruptions, and strikes. As Marx explained in Capital Volume I, “It would be possible to write a whole history of the inventions made since 1830 for the sole purpose of providing capital with weapons against working-class revolt.” AI is just the latest technology to play this role. Because high unemployment risks social disorder, capitalists must keep people working to some extent even as they try to reduce their reliance on human labor in order to increase profits and maintain control of their firms. If AI can do the work of many human workers, it threatens to blow up the use of work as social control. The introduction of labor-saving technology to reduce the reliance on human workers while making the fewer workers who keep their jobs work harder is known as the “zerowork paradox.” AI replaces workers, and those who still have jobs work harder until they, too, can be automated. AI will gradually automate parts of work so that capital will need fewer and fewer workers. The robot apocalypse is not that robots will take our jobs, it is that work will no longer keep us under control. Getting rid of human workers without a new means of imposing social control means not only disorder but also brutal totalitarian repression. For Gorz, that meant “what is being preserved is not the capitalist system but capitalism’s system of domination.” This is what makes the totalitarian police states of sci-fi films like “Elysium” and “RoboCop” more realistic, and thus more terrifying. In the bleak dystopian future, the human population itself becomes entirely unneeded. A New Social Contract A more hopeful AI future would promise less work, a better quality of life, and even the abolition of work itself. As we produce more in less time and with less effort, some people believe that the increased fruits of our collective labor could be shared globally to meet all human needs. Visions of what that would look like have been the focus of recent books such as Peter Frase’s 2016 book Four Futures: Life After Capitalism and Aaron Bastani’s 2020 book Fully Automated Luxury Communism: A Manifesto, advocating for humans to exploit the work of robots to fund a life of human leisure. Whichever outcome occurs won’t come to pass without a struggle for power to either control the fruits of the capitalist economy or rupture it to get beyond capitalism. This May, I interviewed Boston College professor Juliet Schor, author of the 1992 book The Overworked American: The Unexpected Decline of Leisure. She said new technology in the workplace has not always led to higher unemployment. Now is not the first time we have faced mass unemployment and destitution because of the potential replacement of human labor with technology. The steam-powered factory, the railroads, and automobiles made many types of agricultural and skilled work obsolete, threw many people into joblessness and precarity, and coincided with a series of depressions with high unemployment between the 1860s and 1930s. Workers responded by organizing unions, striking, and even arming themselves in self-defense against corporate thugs, judicial injunctions, the army, state militias, the National Guard, and police—as I show in my first book, When Workers Shot Back, which was published in 2019. Schor proposes that we advocate for converting rising productivity from AI into shorter hours, and to get rid of the worst kinds of work: “The key is that workers are organized. Get the shorter hours ball rolling now, for the movement for a four-day week. People want this a lot now.” She points to four-day work week trials now under way in the United Kingdom and Ireland, which she has been involved in, and at Samsung in South Korea. The problem, according to Schor, is that we are not democratically making the necessary choices about whether and how we want to grow the economy. Nor are we confronting the ecological and social damage from doing so. This is the paradox of capitalism. We work to survive even though work is a primary source of the threat of ecocide. Schor’s sense of the possibilities is rooted in the knowledge of the outcomes of previous worker struggles. Capitalists responded by introducing new technology to deskill, replace, or discipline insurgent workers by making them work harder and produce more. But it also led to two other different, conflicting outcomes. These struggles raised union density, led to disruptive strike waves, and extracted social democratic reforms. In countries with strong unions and labor parties, these advances were enshrined in both the shortening of the work week and earlier retirements. In countries like the United States, it resulted in the 1938 Fair Labor Standards Act that provided the 40-hour work week for some workers, and in labor union contracts that traded higher wages for even more intensive work. The results of this deal can be seen in historical declines in work hours. According to Our World in Data (see figure), between 1870 to 2017, annual work hours declined about 40% worldwide, from about 3,100 to about 1,800. Work hours declined by more than half in five European countries, the United States, and Australia. However, downward progress stalled in nearly every country since the 1970s. Since the demand for the legal eight-hour workday was enshrined into law for most hourly workers in the Fair Labor Standards Act, our unions have largely ignored the issue of work, who controls it, and how much of it we do. After the 1950 “Treaty of Detroit” between the United Auto Workers and General Motors, it became common for unions to cut deals with the boss to produce more if workers get paid a larger share of the profits our labor produces. That closed the inequality gap for some white male workers, but the effects didn’t last. The boss responded with systemic racism and sexism, privatization, outsourcing, bankruptcy, mergers, and automation—and now AI. A Democratically Controlled Economy The future of AI will be the outcome of the balance of power between workers and capitalists. Rising working-class power that threatens to disrupt the economy is the most likely way to force the question of whether we ban AI or regulate who controls the technology and what it produces. This is the reason why the screenwriters and actors went on strike over AI. The WGA strike resulted in a new contract that empowers the workers to control AI. They now get to decide how AI is used in writing scripts. The contract requires the companies to disclose which materials are produced by AI and a screenwriter cannot be forced to use those materials. When writer’s materials are used to “train” AI, the union can challenge it as a contractual violation. Most media handwringing about AI and the future of work fails to address the fact that it is not only a question about work but more fundamentally about how we organize society. The future will turn on how we decide to govern ourselves and what kind of economic system we want—and organized workers will have the power to decide it. This means both asking hard questions and taking action, both of which we are not yet doing. Will we implement a new social contract that redistributes income and wealth in exchange for fewer hours of work at safer and more fulfilling jobs? Will we rise up and abolish the life-killing capitalist system and democratically seize control of and run the economic system in order to abolish work as a coerced activity for survival? Ultimately, our survival will be determined by our ability to democratically control work and the economy. Too many of us work far too much for far too little. Meanwhile, too many have too little or no work. This is the irrationality of work under capitalism: it really does not determine whether we survive or not. Getting past capitalism would allow us to democratically decide what work is needed and what is not. That process will involve sorting out what work is destructive and what is needed to take care of one another and meet human needs. Abolishing work as a coercive means of control, exploitation, and domination would free the full range of human creativity and expression. This is the only way to avoid both the robot apocalypse and ecocide. The answer to the question about the future of work is that work has no future. Answering the question about the future of work, as well as AI, means answering the question of the future of humanity and the planet. Failure to answer either question will make the AI work apocalypse more certain. We still have a little bit of time to determine whether the metaphorical robots become the new slave drivers of the elites, used to keep the unneeded humans in line. The actors and screenwriters who struck over control of AI have reminded us that our most important weapon against AI is already in our repertoire. We need to use it well. Robert Ovetz teaches at UC Berkeley and San José State University. He is editor of Workers’ Inquiry and Global Class Struggle (Pluto), and the author of When Workers Shot Back (Haymarket) and the new book We the Elites: Why the U.S. Constitution Serves the Few (Pluto). Follow him at @OvetzRobert Sources: Dominic Patten, “SAG-AFTRA Strike Could Hinge On AI; Deep Divisions Remain Between Actors & Studios In Final Hours Of Talks,” Deadline, July 10, 2023 (deadline.com); Mike Elk, “160,000 SAG-AFTRA Members to Strike with 11,000 of the Writers Guild for 1st Time in 60 Years,” Payday Report, July 13, 2023 (paydayreport.com); Chloe Xiang, “Eating Disorder Helpline Fires Staff, Transitions to Chatbot After Unionization,” Vice, May 25, 2023 (vice.com); “NEDA Suspends AI Chatbot for Giving Harmful Eating Disorder Advice,” Psychiatrist.com, June 5, 2023 (psychiatrist.com); Gabriel A. Silva, “The ChatGPT Debate: Are We Intelligent Enough To Understand ‘Intelligence’?,” Forbes, March 14, 2023 (forbes.com); Dominic Patten, “SAG-AFTRA Strike Could Hinge On AI; Deep Divisions Remain Between Actors & Studios In Final Hours Of Talks,” Deadline, July 10, 2023 (deadline.com); ChatGPT (chat.openai.com/auth/login); Cody Godwin, “Burger-Flipping Robot Begins First Shift,” BBC, March 5, 2018 (bbc.com); Zeynep Tufekci, “Failing the Third Machine Age: When Robots Come for Grandma,” Medium, July 22, 2014 (medium.com); Robert Ovetz, “Taylor’s Digital Stopwatch: What the U.S. Labor Movement Can Learn from European Workers Who are Organizing Against ‘Algorithmic Management,’” Dollars & Sense, September/October, 2022 (dollarsandsense.org); Nitin Kumar, “Legal Tech: Artificial Intelligence-Enabled Review,” Forbes, August 23, 2021 (forbes.com); Jacob Zinkula, “AI is Helping Your Company Decide Who to Lay Off,” Business Insider, February 23, 2023 (businessinsider.com); André Gorz, Paths to Paradise: On the Liberation from Work, London: Pluto Press, 1985; Center for AI Safety, “Statement on AI Risk,” n.d. (safe.ai); “Stephen Hawking Warns Artificial Intelligence Could End Mankind,” BBC, December 2, 2014 (bbc.com); Gerard Rinse Oosterwijk, “AI, platforms and (human) workers’ rights,” Social Europe, July 7, 2023 (socialeurope.eu); OECD Employment Outlook: Artificial Intelligence and the Labour Market, 2023 (oecd.org); Sam Altman, “Planning for AGI and Beyond,” OpenAI, February 24, 2023 (openai.com); Cecilia Kang, “OpenAI’s Sam Altman Urges A.I. Regulation in Senate Hearing,” New York Times, May 16, 2023 (nytimes.com); Karl Marx and Friedrich Engels, Manifesto of the Communist Party, London: Pluto Press, 1848[2017] (marxists.org); James Manyika, Susan Lund, Michael Chui, Jacques Bughin, Jonathan Woetzel, Parul Batra, Ryan Ko, and Saurabh Sanghvi, “Jobs Lost, Jobs Gained: What the Future of Work Will Mean for Jobs, Skills, and Wages,” McKinsey Global Institute, November 28, 2017 (mckinsey.com); OECD Employment Outlook: Artificial Intelligence and the Labour Market, 2023 (oecd.org); Dan Milmo, “AI Revolution Puts Skilled Jobs at Highest Risk, OECD Says,” The Guardian, July 11, 2023 (theguardian.com); Tyna Eloundou, Sam Manning, Pamela Mishkin and Daniel Rock, “GPTs are GPTs: An Early Look at the Labor Market Impact Potential of Large Language Models,” arXiv:2303.10130, Cornell University (arxiv.org/abs/2303.10130); Yael Selfin and Dennis Tatarkov,“Generative AI and the UK Labour Market,” KPMG, June 2023 (assets.kpmg.com); Paweł Gmyrek, Janine Berg, David Bescond, “Generative AI and Jobs: A global analysis of potential effects on job quantity and quality,” ILO 2003 (ilo.org); Daron Acemoglu, Gary W. Anderson, David N. Beede, Cathy Buffington, Eric E. Childress, Emin Dinlersoz, Lucia S. Foster, Nathan Goldschlag, John C. Haltiwanger, Zachary Kroff, Pascual Restrepo and Nikolas Zolas, “Automation and the Workforce: A Firm-Level View from the 2019 Annual Business Survey,” National Bureau of Economic Research Working Paper Series (nber.org); Sarah Kessler, “The A.I. Revolution Will Change Work. Nobody Agrees How.,” New York Times, June 10, 2023 (nytimes.com); Sara Korolevich, “Insights from American Workers: A Comprehensive Survey on AI in the Workplace,” checkr.com, May 24, 2023 (checkr.com); Yael Selfin and Dennis Tatarkov,“Generative AI and the UK Labour Market,” KPMG, June 2023 (assets.kpmg.com); Daron Acemoglu, David Autor, Jonathon Hazell and Pascual Restrepo, “AI and Jobs: Evidence from Online Vacancies,” National Bureau of Economic Research Working Paper Series (nber.org); ILO News, “More than 60 Per Cent of the World’s Employed Population are in the Informal Economy,” April 30, 2018 (ilo.org); Steven F. Hipple and Laurel A. Hammond, “Self-employment in the United States,” U.S. Bureau of Labor Statistics, March 2016 (bls.gov); André Dua, Kweilin Ellingrud, Bryan Hancock, Ryan Luby, Anu Madgavkar, and Sarah Pemberton, “Freelance, Side Hustles, and Gigs: Many More Americans have Become Independent Workers,” McKinsey & Company, August 23, 2022 (mckinsey.com); Karl Marx, Capital, Vol. I, NY: Vintage, 1977; Zerowork (zerowork.org/); Sam Altman, “Planning for AGI and Beyond,” OpenAI, February 24, 2023 (openai.com); “Elysium,” 2013 (sonypictures.com); Hannah Arendt, The Origins of Totalitarianism, NY: HBJ, 1951, Robert Ovetz, When Workers Shot Back, Chicago: Haymarket Press, 2019 (haymarketbooks.org); Charlie Giattino, Esteban Ortiz-Ospina and Max Roser, “Working Hours,” Our World in Data, December 2020 (ourworldindata.org); John Maynard Keynes, “Economic Possibilities for our Grandchildren,” in Essays in Persuasion, New York: W. W. Norton & Co., 1963; Justin, “UAW History—The Treaty of Detroit,” July 25, 2020 (uawd.org); Thomas Paine, Agrarian Justice, 1797 (piketty.pse.ens.fr); Kevin Van Meter, “We Should Demand Democratic Workplaces, But What Does That Mean?,” New Politics, December 26, 2022 (newpol.org); Robert Ovetz, “Hollywood Screenwriters Strike Put a Leash on AI,” The Chief, October 17, 2023 (thechiefleader.com). Did you find this article useful? Please consider supporting our work by donating or subscribing. Home Subscribe Archive Back issues Reprints Recent issues 2023 archive 2022 archive 2021 archive 2020 archive 2019 archive 2018 archive 2017 archive 2016 archive 2015 archive 2014 archive 2013 archive 2012 archive 2011 archive 2010 archive 2009 archive 2008 archive 2007 archive 2006 archive 2005 archive 2004 archive 2003 archive 2002 archive 2001 archive 2000 archive 1999 archive 1998 archive 1997 archive 1996 archive D&S books About D&S For instructors Get involved D&S blog Advertise Donate Dollars & Sense P.O. Box 209, Portsmouth, NH 03802 Phone: (617) 447-2177 Fax: (617) 447-2179 Email us. © 2023 Economic Affairs Bureau, Inc.",
    "originSummary": [
      "The article explores the impact of AI on the future of work and raises concerns about the potential replacement of human workers by AI.",
      "It discusses the need for democratic control over AI and work to avoid negative consequences and ensure a system that allows for human creativity and expression.",
      "The article also delves into the potential automation of office tasks and its effects on employment and wages."
    ],
    "commentBody": "",
    "commentSummary": [],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1699797351251
  },
  {
    "title": "Google in talks to invest 'hundreds of millions' in Israeli AI startup Character.AI",
    "originLink": "https://www.calcalistech.com/ctechnews/article/h1vdzfaqt",
    "originBody": "24/7 Buzz Startups VC AI Innovation Opinions Events Promising Startups 2022 BiblioTech Boarding Pass Startup: Confidential Appointments CTalk Tech Gateways 2022 VC Survey @Finance Ctech Testimonials DataTech Projects AboutNewsletterContact usRSSFacebookTwitter ACCESSIBILITY by Homepage News News HOME 24/7 buzz STARTUPS VC AI Innovation OPINIONS EVENTS ABOUT NEWSLETTERSEARCHCONTACT US ACCESSIBILITY Recently Read From the U.S. Army to Marriage in Israel: the Legal Status of DNA Testing Kits The top travel-tech trends set to revolutionize tourism in 2023 The shameful antisemitism of “Elite Institutions” Recommended videos Palo Alto Networks announces the acquisition of Israeli startup Talon Cyber Security Eleos Health raises $40 million to extend the use of AI for behavioral health Photo: Shutterstock Google in talks to invest ‘hundreds of millions’ into AI startup Character.AI Character.AI's chatbots, with various roles and tones to choose from, have appealed to users ages 18 to 24, who contributed about 60% of its website traffic. Reuters 11:02, 12.11.23 TAGS: AI Google Character.AI Alphabet’s Google is in talks to invest in Character.AI, an artificial intelligence chatbot startup. Character.AI was founded by Noam Shazeer and Daniel De Freitas, two former employees at Google Brain, and the tech giant is expected to invest ‘hundreds of millions of dollars’ as Character.AI seeks to train models to keep up with user demands, two sources briefed on the matter told Reuters. The investment, which could be structured as convertible notes, according to a third source, will deepen the existing partnership Character.AI already has with Google, in which it uses Google's cloud services and Tensor Processing Units (TPUs) to train models. 1 View gallery The Google office (Photo: Shutterstock) Character.AI allows people to chat with virtual versions of celebrities like Billie Eilish or anime characters, while creating their own chatbots and AI assistants. It is free to use, but offers subscription model that charges $9.99 a month for users who want to skip the virtual line to access a chatbot. According to data from Similarweb, Character.AI's chatbots, with various roles and tones to choose from, have appealed to users ages 18 to 24, who contributed about 60% of its website traffic. The demographic is helping the company position itself as the purveyor of more fun personal AI companions, compared to other AI chatbots from OpenAI's ChatGPT and Google's Bard. Related articles: New Waze Feature Provides Early Warning for Accident-Prone Roads Google Withdraws from Web Summit Participation; Israeli VCs Unite in Joint Conference Boycott Google executive: \"Bard is not intended to provide factual answers, just a companion for creative tasks\" The company previously said its website had attracted 100 million monthly visits in the first six months since its launch. The story, broken exclusively by Reuters, comes as the startup is also in talks to raise equity funding from venture capital investors, which could value the company at over $5 billion, sources said. In March, it raised $150 million in a funding round led by Andreessen Horowitz at $1 billion valuation. Google has been investing in AI startups, including $2 billion for model maker Anthropic in the form of convertible notes, on top of its earlier equity investment. Google has previously invested or purchased Israeli companies such as Waze, BreezoMeter, Siemplify, and others. TAGS AI Google Character.AI Rss Contact Us Newsletter Facebook Twitter About CTechTerms of UsePrivacy Policy Developed by UI & UX by Basch_Interactive",
    "originSummary": [
      "Google is considering investing \"hundreds of millions\" of dollars in Character.AI, an AI chatbot startup founded by ex-Google Brain employees.",
      "Character.AI offers users the ability to chat with virtual celebrities and create their own chatbots and AI assistants.",
      "This investment will strengthen the collaboration between Google and Character.AI, as Google already uses their cloud services and Tensor Processing Units (TPUs) for model training. Additionally, Character.AI is in discussions to raise equity funding that could value the company at more than $5 billion."
    ],
    "commentBody": "",
    "commentSummary": [],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1699797351251
  },
  {
    "title": "France to Host Next AI Safety Summit in Europe",
    "originLink": "https://www.foxnews.com/world/france-host-ai-safety-summit-european-nations-jockey-tech-leadership",
    "originBody": "Artificial Intelligence France to host next AI safety summit as European nations jockey for tech leadership France pledged around $530 million toward supporting 'global AI players' By Peter Aitken Fox News Published November 12, 2023 2:00am EST Facebook Twitter Flipboard Comments Print Email close Video AI expert on the danger of artificial intelligence to commerce and potential federal legislation AI expert Marva Bailer tells Fox News Digital how the open availability of artificial intelligence can have negative impacts and talks potential federal legislation to control it. European nations continue to jockey for leadership on artificial intelligence (AI), with Paris announcing it will host the next safety summit shortly after Britain hosted the first one. \"The first edition of the Artificial Intelligence Security Summit, organized by the United Kingdom, provides an opportunity to develop international cooperation in the field of security, a crucial issue for the years to come. It was, therefore, natural for France to host the second edition of this summit,\" French Minister Delegate for the Digital Economy Jean-Noël Barrot said in a press release. The future of AI remains up for grabs, with many nations trying to position themselves at the forefront of the race. Britain most explicitly has made its intentions clear with multiple and escalating pledges of hundreds of millions of dollars dedicated to research and development. Barrot claimed that France is \"a European leader\" in AI development. French Finance Minister Bruno Le Maire noted several important initiatives, including AI ethics, that France has launched, as well as the country’s own €500 million (around $534 million) pledge towards supporting \"global AI players.\" STAR TACKLES AI IN LEGAL SHOWDOWN AGAINST APP THAT USED HER LIKENESS, VOICE IN AD A declaration on artificial intelligence safety was issued during a summit in Bletchley Park, Britain. Under the declaration, 28 countries and the European Union agreed on the need for a new global effort to ensure AI is developed and used in a safe and responsible way. (Rory Arnold/No 10 Downing Street/Handout via Xinhua) \"Artificial intelligence is a tremendous lever for innovation and progress, and we want Europe to take full advantage of it,\" le Maire said in the same press release. \"However, certain developments and uses of AI pose security risks, and international cooperation is the best way of dealing with them.\" The first summit was held in Britain at Bletchley Park – the birthplace of the computing machine, known as the Enigma Machine, as part of Alan Turing’s research and work to decode Germany’s messages during World War II. The summit hosted world leaders and technology experts, including ChatGPT maker OpenAI’s CEO Sam Altman and social media platform X CEO Elon Musk, who launched his own AI model named \"Grok,\" a seeming reference to Robert A. Heinlein’s science fiction novel \"Stranger in a Strange Land.\" WHAT IS ARTIFICIAL INTELLIGENCE (AI)? Britain spearheaded the Bletchley Declaration, which 28 countries including China and the U.S. signed: The agreement aims to provide a standard of safety and cooperation between participants to ensure AI tech does not become dangerous. Bruno Le Maire, France's finance minister, left, and Rishi Sunak, U.K. prime minister, on day two of the AI Safety Summit 2023 at Bletchley Park in Bletchley, U.K., Nov. 2, 2023. (Chris J. Ratcliffe/Bloomberg via Getty Images) Brussels hosted a one-day summit last week that sought to \"find answers to many of the questions around global AI regulatory cooperation\" following the Bletchley summit. \"AI is a global challenge that doesn’t recognize borders,\" Ireland's Minister for Enterprise, Trade and Employment Simon Coveney said during his keynote address at the International AI Summit 2023 organized by Euronews. A HYPED AI-BASED RESTAURANT OPENED TO FANFARE LAST MONTH - NOW IT'S EMPTY \"The EU can’t do it alone,\" he stressed. \"It must build an alliance and it must at least try to reach a global consensus.\" Bruno Le Maire, French minister for economy, finance, industry and digital security, speaks at a press conference during the U.K. Artificial Intelligence Safety Summit at Bletchley Park, in central England, Nov. 2, 2023. (Justin Tallis/AFP via Getty Images) Experts noted that the discussion and struggle for AI dominance rests currently in a split between the West and China, which has wanted \"a seat at the AI table… for years,\" according to Rebecca Arcesati, a lead analyst at the Mercator Institute for China Studies. Matt Sheehan from the Carnegie Endowment for International Peace theorized that \"cooperation on AI is very much going to be shaped by the West's geopolitical relationship with China.\" CLICK HERE TO GET THE FOX NEWS APP France did not specify when the summit would occur, but leaders agreed to a follow-up summit during sideline discussions in Bletchley Park. Le Maire’s office stressed that they will remain in line with the overall European Union strategy for the governance of AI. Peter Aitken is a Fox News Digital reporter with a focus on national and global news.",
    "originSummary": [
      "France will host the next AI safety summit, aiming to address security risks and promote global cooperation in AI development.",
      "European nations are competing for leadership in AI, with France committing $530 million to support global players.",
      "The summit will align with the European Union's strategy for governing AI and comes after Britain hosted the first summit."
    ],
    "commentBody": "",
    "commentSummary": [],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1699797351251
  },
  {
    "title": "White House Heightens Concerns about AI Following \"Mission: Impossible\" Movie",
    "originLink": "https://moderndiplomacy.eu/2023/11/11/white-house-says-mission-impossible-increased-joe-bidens-concerns-about-ai/",
    "originBody": "Sign in Welcome! Log into your account your username your password Forgot your password? Get help Privacy Policy Password recovery Recover your password your email A password will be e-mailed to you. HomeNewsTech NewsWhite House says ‘Mission: Impossible’ increased Joe Biden’s concerns about AI Tech News White House says ‘Mission: Impossible’ increased Joe Biden’s concerns about AI President Joe Biden’s concerns over artificial intelligence intensified after watching “Mission: Impossible – Dead Reckoning Part One\". By Newsroom November 11, 2023 photo:unsplash Biden signed a sweeping executive order regulating the development of artificial intelligence, saying he wants to prevent AI from making social media “more addictive” or from abetting fraud. Biden noted that he’s seen a “deep fake” video of himself, using a term for the increasingly prevalent and convincing doctored videos. His concerns sharpened after he watched Tom Cruise’s latest action-packed thriller, according to White House deputy chief of staff Bruce Reed. “If [Biden] hadn’t already been concerned about what could go wrong with AI before that movie, he saw plenty more to worry about,” Reed said. Reed said he watched the film with Biden at Camp David, following its release in July earlier this year. President Joe Biden’s concerns over artificial intelligence intensified after watching “Mission: Impossible – Dead Reckoning Part One,” according to the White House. These AI features are known to be a concern for Biden, who Reed said has been “profoundly curious about the technology” of AI. Biden had witnessed AI technology create “fake AI images of himself [and] of his dog”, and had seen it perform “the incredible and terrifying technology of voice cloning,” Reed added. “[AI] can take three seconds of your voice and turn it into an entire fake conversation.” The complex, rapidly evolving field of artificial intelligence raises legal, national security and civil rights concerns that can’t be ignored, notes Bloomberg. Governments don’t have a great track record of keeping up with emerging technology. But the complex, rapidly evolving field of artificial intelligence raises legal, national security and civil rights concerns that can’t be ignored. Some US cities and states have already passed legislation limiting use of AI in areas such as police investigations and hiring, and the European Union has proposed a sweeping law that would put guardrails on the technology. While the US Congress works on legislation, President Joe Biden is directing government agencies to vet future AI products for potential national or economic security risks. Why does AI need regulating? Already at work in products as diverse as toothbrushes and drones, systems based on AI have the potential to revolutionize industries from health care to logistics. But replacing human judgment with machine learning carries risks. Even if the ultimate worry — fast-learning AI systems going rogue and trying to destroy humanity — remains in the realm of fiction, there already are concerns that bots doing the work of people can spread misinformation, amplify bias, corrupt the integrity of tests and violate people’s privacy. Reliance on facial recognition technology, which uses AI, has already led to people being falsely accused of crimes. A fake AI photo of an explosion near the Pentagon spread on social media, briefly pushing US stocks lower. Google, Microsoft, IBM and OpenAI have encouraged lawmakers to implement federal oversight of AI, which they say is necessary to guarantee safety. What’s been done in the US? Biden’s executive order on AI sets standards on security and privacy protections and builds on voluntary commitments adopted by more than a dozen companies. Members of Congress have shown intense interest in passing laws on AI, which would be more enforceable than the White House effort, but an overriding strategy has yet to emerge. Among more narrowly targeted bills proposed so far, one would prohibit the US government from using an automated system to launch a nuclear weapon without human input; another would require that AI-generated images in political ads be clearly labeled. At least 25 US states considered AI-related legislation in 2023, and 15 passed laws or resolutions, according to the National Conference of State Legislatures. Proposed legislation sought to limit use of AI in employment and insurance decisions, health care, ballot-counting and facial recognition in public settings, among other objectives. What’s the EU working on? Building on laws addressing privacy and hate speech, the EU is working out the specifics of an AI Act, to take effect in stages by 2026. It’s the first attempt by a Western government to oversee how developers handle risks and deploy their models. It would ban categories of AI seen as most potentially exploitative or manipulative of the public, such as any system that enables the kind of social scoring used in China, where citizens earn credit based on surveillance of their behavior. Other AI applications deemed of high (but not unacceptable) risk, such as programs used to analyze and rank job candidates, would be subject to rules on disclosure, record-keeping and human oversight. Another focus is on transparency: People would need to be informed when interacting with an AI system, and any AI-generated or manipulated content would need to be flagged. What do the companies say? Leading technology companies including Amazon.com, Alphabet, International Business Machines and Salesforce pledged to follow the Biden administration’s voluntary transparency and security standards, including putting new AI products through internal and external tests before their release. In September, Congress summoned tech tycoons including Elon Musk and Bill Gates to advise on its efforts to create a regulatory regime, concludes Bloomberg. The majority of U.S. adults don’t believe the benefits of artificial intelligence outweigh the risks, according to a new Mitre-Harris Poll. By the numbers: 54% of the 2,063 adults in a Mitre-Harris Poll survey in July said they were more concerned about the risks of AI than they were excited about the potential benefits. At the same time, 39% of adults said they believed today’s AI technologies are safe and secure — down 9 points from the previous survey in November 2022. Why it matters: AI operators and the tech industry are eyeing new regulations and policy changes to secure their models and mitigate the security and privacy risks associated with them. The new survey data is some of the first to highlight the growing support for these regulatory efforts. Respondents were more concerned about AI being used in malicious cyberattacks (80%) and identity theft schemes (78%) than they were about it being used to cause “harm to disadvantaged populations” (66%) or replacing their jobs (52%). Roughly three-fourths of respondents were also concerned about AI technologies being used to harvest and sell their personal data. Yes, but: Not all demographics feel the same wariness about AI technologies. 57% of Gen Z respondents and 62% of millennials said they were more excited about the potential benefits of AI than they were worried about the risks. And men were typically more excited than concerned about AI technologies (51%) than women (40%). TAGSArtificial IntelligenceSecurityUSA FacebookTwitterWhatsAppLinkedinReddItTelegram Previous article AfDB, leaders commit to catalyse investment in cities as engines of the continent’s economic growth Next article Afreximbank announces $1-billion African Film Fund Newsroom RELATED ARTICLES Tech News Mind the gap: travel apps need human help to bridge digital divide Tech News What are the Factors for Buying a Filter for Your Furnace? Tech News How to Get More Followers on Instagram? LATEST ARTICLES Palestine’s Right to Self Determination or Israel’s Right to Self Defense? November 12, 2023 Why is getting Tesla increasingly difficult for Indonesia? November 12, 2023 Pioneering Sustainable Travel Solutions in Developing Countries, Part 1 November 12, 2023 Netanyahu’s Peace and War November 12, 2023 Of Palestine and the Baltic States’ Human Rights – New Tensions in European Society November 12, 2023 Load more",
    "originSummary": [
      "President Joe Biden has expressed concerns about the potential negative impacts of artificial intelligence (AI) after watching the movie \"Mission: Impossible – Dead Reckoning Part One\".",
      "The White House is taking steps to regulate AI by setting standards for security and privacy protections.",
      "The European Union is also working on legislation to oversee the use of AI, and technology companies have pledged to follow transparency and security standards.",
      "A recent survey indicates that a majority of US adults are more concerned about the risks of AI than excited about its potential benefits."
    ],
    "commentBody": "",
    "commentSummary": [],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1699797351251
  },
  {
    "title": "For the young brides of India, social media becomes a trap",
    "originLink": "https://www.voanews.com/a/for-the-social-media-child-brides-of-india-the-road-to-justice-is-long/7350963.html",
    "originBody": "Accessibility links Skip to main content Skip to main Navigation Skip to Search Next Close Previous Next Print Options: Images Multimedia Embedded Content Comments Cancel Print Link has been copied to clipboard Home United States U.S. News All About America Silicon Valley & Technology Immigration World Africa The Americas East Asia Europe Middle East South & Central Asia Ukraine Press Freedom COVID-19 Pandemic China Iran Broadcast Programs Follow Us Languages Search Search Previous Next Breaking News South & Central Asia For the ‘Social Media Child Brides’ of India, the Road to Justice Is Long November 11, 2023 10:23 AM Sarah Aziz Prodeepa, a child marriage and trafficking survivor, in her East Midnapore neighborhood. Like many other economically challenged survivors, she has received no legal aid from authorities. (Sarah Aziz/VOA) Share Print East Midnapore, West Bengal, India — It was a rainy August evening in a remote village of the West Bengal state in India when a WhatsApp message from an anonymous number appeared on 16-year-old Prodeepa’s smartphone screen. Her name and those of her family members have been changed to ensure anonymity. \"I saw his profile photo and found him really handsome. We began talking, and I immediately fell for him,\" the high school student from the East Midnapore district told VOA. Three weeks later, the boy asked Prodeepa to come with him to visit his hospitalized mother in a city about an hour away. Prodeepa told her mother that she was going to a shop in the village. \"We thought she would be back in a few minutes,\" said Bidisha, her mother. \"But Prodeepa did not return, and the next day I received a call from an unknown number.\" The voice on the other end, which Bidisha did not recognize, said, \"Mother, I am fine. I got married.\" Gone without a trace The fifth National Family Health Survey report says that almost half the girls in India’s rural West Bengal state get married before they turn 18. According to Jibananda Das, chairperson of the East Midnapore Child Welfare Committee, or CWC, social media is the greatest breeding ground for traffickers who are looking for child brides. \"It is especially difficult for us as government authorities to trace child marriage victims, because the majority of these marriages are unregistered. Most such girls are therefore merely reported as kidnapped or missing,\" he told VOA. ‘Dyed hair and Coca-Cola' With her husband unemployed, Bidisha, the sole earning member of the family, earns about $26 a month by making cigars. \"All I wanted for my daughter and son were lives marginally better than my own. Now I feel like all my dreams have shattered,\" she said. According to the National Family Health Survey, about half the girls in West Bengal, India, are married off before they turn 18. (Sarah Aziz/VOA) New Delhi-based anti-trafficking activist Pallabi Ghosh said that underage girls from West Bengal are especially vulnerable to being trafficked and married off because of the extreme poverty and deep-rooted culture of \"sheltering\" children in the state. \"The oldest daughter of a poor Bengali family, despite being a child herself, is forced to be the primary caregiver of all her younger siblings,” she said. \"Deprived of the attention and love of parents who are out working all day to make ends meet, many girls look for love elsewhere — usually on their phones,\" the founder and director of the Impact and Dialogue Foundation, a nongovernmental organization that works to prevent human trafficking and rehabilitate survivors, told VOA. \"I handled the trafficking case of a rural girl who met a boy online and was enamored because he had dyed hair and bought her a cold drink. These girls’ exposure to the outside world is so limited that they end up trusting strangers at the tip of a hat,\" Ghosh said. No money, no justice According to a copy of the First Information Report, or FIR, filed by Prodeepa’s family three days after she disappeared, the family looked all over the village several times before finally reporting her missing. Manoj Kumar Sharma, head of an anti-human trafficking unit under the border security forces in east India, told VOA that economically challenged families in India are often afraid of even filing an FIR when their girls go missing. \"As national police forces, we take upon several complicated trafficking and child marriage cases, which the local police do not,” Sharma said. “It is not that they do not have the power or resources; they lack the enthusiasm and will, which is something that must be cultivated.\" VOA reached out to three police officials in East Midnapore district, including the sub-inspector who oversaw Prodeepa’s FIR proceedings. All of them refused to comment. Sitting in a dingy bedroom with copies of the FIR and other legal documents regarding her case sprawled across the bed, Prodeepa said softly, \"I share everything with my mother, but I did not tell her about the boy. That was my greatest mistake.\" The boy, who came to pick up Prodeepa on a motorcycle, refused to take off his helmet with a face shield. \"We rode for a distance before I realized we were headed in the wrong direction,” she said. “I asked him what was going on, but he brushed it off.\" The \"boy\" was, in fact, a 26-year-old man. He looked nothing like the WhatsApp photo. Prodeepa was sexually abused, coerced into marriage and held against her will by the man and his family for a week. Prodeepa, a child marriage survivor, flips through some of the illustrations she made while at a government-approved rehabilitation center. (Sarah Aziz/VOA) Madhab, Bidisha’s older brother, said that the family delayed reporting Prodeepa as missing because they were afraid of rumors. \"People in villages talk. We had to wait until we were sure that she hadn’t married him voluntarily,\" he said. ‘She said I was a bad girl’ For Prodeepa and her family, there is little hope for justice any time soon. The perpetrator, who comes from a well-off family, was never arrested. Prodeepa was promised legal aid by a nongovernmental organization, but it later backed out. The CWC’s Das told VOA that all the rehabilitation centers for child survivors of sexual abuse in East Midnapore, like the one where Prodeepa was kept for a month after her rescue, are NGO-operated. While at the CWC-approved center, Prodeepa’s family was allowed to visit for only 15 minutes at a time. As someone with no formal education like most rural women in India, Bidisha had no knowledge of the official procedure and said that no authority took the time to explain it to her. \"A one-way trip to the center would cost me a week’s worth of income,” she said. “I often wondered why my daughter was being detained away from me like a criminal. Shouldn’t it have been that man who abused her?\" Her eyes brimming with tears, she asked a final question: \"It’s like we are invisible to everyone. Is it because we are poor?\" Leafing through the pencil illustrations she made while at the rehabilitation center, Prodeepa said that one of the officials at the institution said she was responsible for her own abuse. \"She said I was a bad girl,\" Prodeepa said. \"But I never believed her. This is not my punishment to bear, but that of the criminal who wronged me.\" Related Girls Avoid Internet Due to Abuse and Bias, Report Warns In India, Human Traffickers Target Tribal Women and Girls Nearly 10K Women, Girls Go Missing in Kashmir, Sparking Alarm Indian Police Nab Over 2,000 Men for Illegal Child Marriages More South and Central Asia Stories Indians Set World Record Celebrating Diwali as Worries About Air Pollution Rise Myanmar Fighter Jet Crashes; Rebels Claim Responsibility For the ‘Social Media Child Brides’ of India, the Road to Justice Is Long Pakistan Extends Stay of 1.4 Million Registered Afghan Refugees Indian Capital Gets Breather as Rain Brings Respite from Smog The Day in Photos November 10, 2023 Recommended 52 Documentary Back to top Follow Us United States US News Immigration All About America Silicon Valley & Technology World Africa The Americas East Asia Pacific Europe Middle East South & Central Asia Sections VOA Programs Special projects Day in Photos Press Freedom Refugees VOA News on Iran VOA News on China Arts & Culture Economy & Business Health Extremism Watch Student Union VOA Connect 52 Documentary Videos More From VOA VOAAfrica.com Programs VOA Learning English Polygraph.info Editorials Satellite schedule About this site Terms of Use & Privacy Notice About VOA Get VOA+ VOA Around the World Contact VOA Media Relations Usage Requests VOA Pronunciation Guide XS SM MD LG",
    "originSummary": [
      "The article examines the problem of child marriage and trafficking in India, with a particular focus on the story of Prodeepa, a 16-year-old girl who was deceived into a marriage through social media.",
      "It emphasizes the challenges faced by underage girls from economically disadvantaged backgrounds and the struggles they encounter in their pursuit of justice.",
      "The article calls attention to the inadequate resources and support available for victims of child marriage and advocates for stronger measures to combat this issue."
    ],
    "commentBody": "",
    "commentSummary": [],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1699797351251
  },
  {
    "title": "The Week in Audio: Exploring Girl Bands, Dating Experiments, and Deepfakes in the Law",
    "originLink": "https://www.theguardian.com/tv-and-radio/2023/nov/11/where-its-at-a-short-history-of-girl-bands-radio-1-review-28-dates-later-grace-campbell-law-in-action-deepfakes-and-the-law-joshua-rozenberg",
    "originBody": "Tionne ‘T-Boz’ Watkins, Lisa ‘Left Eye’ Lopes and Rozonda ‘Chilli’ Thomas of TLC. FilmMagic, Inc Miranda Sawyer on podcasts and radio Radio Review The week in audio: Where It’s At: A Short History of Girl Bands; 28 Dates Later; Law in Action: Deepfakes and the Law – review The Spice Girls, All Saints, TLC and co are fondly remembered; Grace Campbell dates 28 people she’d normally reject; and Joshua Rozenberg tests out the law against AI Miranda Sawyer @msmirandasawyer Sat 11 Nov 2023 12.00 EST Where It’s At: A Short History of Girl Bands (Radio 1)BBC Sounds 28 Dates LateriHeartPodcasts Law in Action: Deepfakes and the Law (Radio 4)BBC Sounds Radio 1’s A Short History of Girl Bands is an easy, lively listen, with presenter Mollie King skimming deftly across the top of a neat script and some great interviews. It’s set in recent years (no Ronettes or Supremes), and journalists contextualise with insight, whether US journalist Julianne Escobedo Shepherd or British writer Michael Cragg. Cragg, who wrote the brilliant Reach for the Stars, about 90s chart acts, gives good context throughout, covering the Spice Girls, All Saints, Mis-Teeq, Cleopatra. Remember them? You do, once you hear the tracks. This is a Radio 1 documentary, as opposed to Radio 4, so nothing is dwelt on for long. Interviews are trimmed into short, snappy clips; topics are dealt with in a couple of minutes. Actually, it’s refreshing not to have a point banged in hard (I’ve been listening to a lot of news podcasts, and the nail-it-high pomposity is getting worse), and though the underlying argument that all-female bands are never taken as seriously as all-male ones is made throughout, the individual nuances of each episode keeps this series fresh. We cover fashion, history, money and sex and move between the UK and the US, the Spice Girls and Destiny’s Child. And, be still my beating heart, the second episode focuses on TLC and features interviews with T-Boz and Chilli. Where Spice Girls alluded to safe sex, TLC made things obvious by making safe sex a fashion statement (they pinned condoms to their clothes, and released Waterfalls, about drugs and the Aids crisis). Music is used beautifully, popping in and out across the show. This gives a naturally upbeat feel, even when the topics aren’t so cheerful. TLC went bankrupt a year after releasing the huge-selling LP CrazySexyCool because of their rubbish record deal: “We were all dolled up and we had all these Grammys, so it looked a certain way… but the real deal is we didn’t have any money,” says Chilli. A seemingly light series that is careful to make its point. Grace Campbell is a youngish writer and standup comic who, until now, had not crossed my radar. She’s lively and confident, with an almost-posh north London drawl, and her new podcast series has a neat, though not original, concept. 28 Dates Later sees her go on dates with 28 people she would usually reject. Dating apps are boring her, she says in her intro: she’s worked through them so often that there’s nobody interesting left. So why not try the usually left-swiped? She’s joined on her quest for new dating fun by Ros, a good friend who’s been happily settled in a relationship for many years. Ros has never used a dating app, and is content to live vicariously through Grace. The scene-setting chat between the two is nice; we know where we’re going and why. What we might call the meat of the show is a little disappointing, though. Grace’s first date is with a man the series calls the Sugar Daddy. He’s in his 40s and rich, and we hear snippets of his and Grace’s conversation throughout the show, interspersed with Ros and Grace’s analysis. The Sugar Daddy insists he lives off a trust fund, and spends every day doing what he enjoys, which is going to the gym, then going on a date, usually at a casino. He says he used to have three women, all of whom were his “girlfriends” and whom he took gambling every night. He also says he went out with 1,000 women in three years: a new one every evening. Grace is good at keeping the conversation going, but she’s oddly naive. At one point she wonders if the Sugar Daddy wanted sex in return for paying for his three girlfriends to gamble their nights away. Well, duhhh, is all I’m saying to that one. Also, a trust fund man with a working-class accent is unusual, to say the least, but she doesn’t ask him about that. The Sugar Daddy is clearly lying about much of his so-called life and, though Grace considers this, she doesn’t delve deeply enough for us to find out anything worthwhile. It would have been more fun if she’d gone gonzo and taken the Sugar Daddy up on his offer of a proper night out. Too much chat, not enough action, is what I’m saying – which possibly says more about me than this gently entertaining podcast. Law in Action is a nice example of what Radio 4 gets right and wrong, all in one show. Presenter Joshua Rozenberg is warm and exceptionally experienced, but not much jolts him out of his comfort zone. Last week’s main feature, Deepfakes and the Law, on some of the legal implications of AI, was interesting – essentially, existing laws can be used to prosecute anyone who uses AI to replicate someone’s voice or image – but was let down by some odd production decisions. The complicated teeing up of a feature where Rozenberg had to guess if a voice was AI or real made the actual guessing a bit of a letdown. Radio 4 has so many of these established shows just ticking over, week by week by week: competent, long-running series that look at life and news through the lens of law, or media, or money. They’re all OK, though a little old fashioned. And I sometimes wonder if their specialist approaches can tell us anything important about today’s fast-moving, vast-scale world. It can feel like they’re trying to understand how a whole human works by only examining her big toe. Or a whole fake human, by only examining her voice. Explore more on these topics Radio Miranda Sawyer on podcasts and radio Radio 1 Radio 4 BBC Podcasts Spice Girls All Saints reviews Reuse this content",
    "originSummary": [
      "The article discusses various podcasts and radio shows such as \"Where It's At: A Short History of Girl Bands,\" \"28 Dates Later,\" and \"Law in Action: Deepfakes and the Law.\"",
      "\"Where It's At\" provides an engaging and educational look at the history of girl bands like TLC and the Spice Girls.",
      "\"28 Dates Later\" follows Grace Campbell on her dates with people she would typically reject, but it is criticized for its lack of depth.",
      "\"Law in Action\" dives into the legal implications of deepfakes and AI, but its production choices are deemed odd."
    ],
    "commentBody": "",
    "commentSummary": [],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1699797351251
  }
]
