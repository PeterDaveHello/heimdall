[
  {
    "title": "AI Speeds Up Orangetheory's Legal Team by 80% in Reviewing User Agreements",
    "originLink": "https://fortune.com/2023/11/14/orangetheory-ai-artificial-intelligence-automation-legal-attorneys-contracts/",
    "originBody": "LEADERSHIP ·A.I. How AI helped Orangetheory’s legal team complete a 6-month project in half the time: ‘It’s straightforward math to see the cost savings’ BYTREY WILLIAMS Orangetheory's legal department used AI to review more than 1,000 user agreements. Of all the corporate functions that are ripe for AI disruption, legal teams are at the top. According to a 2021 study from global consulting firm KPMG, companies hire about six lawyers per $1 billion in revenue, and much of their work, writing contracts and laboring over reviews, is still manual. In June 2022, the legal team at the popular fitness studio franchise Orangetheory had a major undertaking on its hands: The streamlining and standardization of the roughly 1,000 different user agreements across its 1,500 U.S. franchises. Devising how to review, consolidate, digitize, and ensure the varying contracts all use the same language fell to Charlene Barone, director of legal operations and strategy. “We like to keep consistency across the franchises, but some states require very specific language,” Barone says. Some states require certain language in termination clauses or when it comes to indemnification, and some even specify fonts and formatting. Previously, Orangetheory’s yearly contract reviews had been a manual process, taking roughly two-and-a-half hours per contract to read, update, and change the language, Barone says. This project would require reviewing more than 1,000 contracts, identifying redundancies, and consolidating them to just 200. Barone is the sole legal operations specialist at Orangetheory. Her role is essentially that of a project manager for the five-person legal department. By her estimation, it would take them six months to review and redline the 1,000-plus contract templates—or about 3.5 months if they worked 24/7 and ignored all other duties. “We didn’t have a good strategy to get this solved,” Barone says. She reached out to Ironclad, a contract management software company with an AI tool that allows legal teams to create and tag contracts. More than 60% of Ironclad’s 1,700 clients use its AI tools, including L’Oréal, OpenAI, and the Houston Texans. Using the AI software allowed OrangeTheory to review each contract in just 30 minutes, an 80% drop in time. The human element came in directing the AI on identifying redundancies in agreements, what language Orangetheory needed in its legal templates, and checking the AI’s results. The project, which she expected to take six months, wrapped up in just under three, despite the learning curve required to use a new software system and learn how best to input prompts. Barone says the team is now moving to digitize its 200 user agreement contracts much sooner than anticipated. “There’s real value in saving time when it comes to legal operations. We’re talking about saving several hundred hours of our legal team’s work,” Barone says. Orangetheory declined to provide a specific dollar amount, but Barone says, “Consider how much you pay your attorneys per hour—it’s straightforward math to see the cost savings.” Automating the contract standardization process also means the company can focus more heavily on customers’ needs, which Barone says only spells more revenue. “It’s not just about saving costs; it’s about making our service even better and potentially boosting revenue through increased customer retention and referrals,” she says. For many CEOs, legal is the last place they want to spend money on headcount, so small teams are often burdened with many tasks and few resources, says Ironclad CEO Jason Boehmig. He expects to see legal departments use AI before other parts of the business. Ironclad processes roughly 1 billion contracts annually through its platform, Boehmig says. Not all are using AI, but the technology gives legal departments a repository of past contracts to inform future ones. “We’re at this perfect storm moment where AI and legal teams are truly on the forefront of innovation,” he says. “You’ve got this set of tools that are really good at reading and writing structured things, which contracts are, then you’ve got legal teams whose primary job is to do contracts, yet they aren’t getting new headcount.” AI doesn’t spell the end of corporate legal departments, Boehmig cautions. It’s a good assistant, but relying on AI for all contract needs or legal advice would be a disaster. “Orangetheory is a good example of our preferred way of working, which is that we need a human running things, and we’re going to make that human 10x more effective, as opposed to just replacing a human,” Boehmig says. “We’re going to see this battle play out…but we’re definitely on the side of there should be a human directing things.” Subscribe to CHRO Daily, our newsletter focusing on helping HR executive navigate the changing needs of the workplace. Sign up for free. The Latest 0 minutes ago ASIA - ELON MUSK Elon Musk cryptically wished a ‘speedy recovery’ by Narendra Modi official after Tesla CEO misses key meeting over India factory BYCHRISTIAAN HETZNER 0 minutes ago LEADERSHIP - A.I. How AI helped Orangetheory’s legal team complete a 6-month project in half the time: ‘It’s straightforward math to see the cost savings’ BYTREY WILLIAMS 0 minutes ago LIFESTYLE - LUXURY Prices of high-end Rolex and Patek Philippe watches hit a new 2-year low as luxury slump spreads beyond LVMH and Gucci BYPRARTHANA PRAKASH 0 minutes ago NEWSLETTERS - TERM SHEET The new realities of venture capital, in 3 charts BYJESSICA MATHEWS 0 minutes ago NEWSLETTERS - THE MODERN BOARD CEOs serving as board chairs are controversial but a new study shows they could be great during a crisis BYLILA MACLELLAN 0 minutes ago RETAIL - BEAUTY Avon survived on door-to-door sales for 137 years. Now, it’s opening its first U.K. stores because its customers have given up being at home BYRYAN HOGG",
    "originSummary": [
      "Orangetheory's legal team employed AI to expedite and standardize the review of over 1,000 user agreements, completing the task in half the time it would have taken manually.",
      "The AI software facilitated the examination of each contract within a mere 30 minutes, resulting in an impressive 80% reduction in time, saving the legal team a substantial number of hours and costs.",
      "By utilizing AI, the legal team can dedicate more attention to customer requirements and potentially enhance revenue; however, AI is perceived as an assistant rather than a substitute for humans in legal departments."
    ],
    "commentBody": "",
    "commentSummary": [],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1699969108033
  },
  {
    "title": "Challenges Faced in the Legal Industry's Adoption of AI",
    "originLink": "https://www.pymnts.com/news/artificial-intelligence/2023/use-of-ai-in-the-legal-industry-faces-challenges/",
    "originBody": "WATCH NOWSUBSCRIBE Search PYMNTS TV Today B2B Retail Fintech Digital Transformation Crypto EMEA Tracker® Reports PYMNTS® Data Markets More Topics Artifical Intelligence Connected Car Buy Now Pay Later Banking Cloud Cross-Border Payments Gig-Economy Grocery & Pharmacy Healthcare Payments Insurtech Small & Medium Businesses Social Platforms Subscription Commerce Travel TechREG® Real-Time Payments Restaurants More Topics Featured SEE ALSO: Editor’s Picks Opinion CE100 Index Working Capital & Liquidity Competition Policy International A PYMNTS Company Stay Current Subscribe Become a Partner Use of AI in the Legal Industry Faces Challenges By PYMNTSNovember 14, 2023The legal industry’s widespread adoption of generative artificial intelligence (AI) will necessarily involve recalibrating workforce roles and skills and reckoning with varying degrees of readiness and trust among professionals within and across industries. Coupled with the challenges of this reboot are the thorny issues surrounding security, privacy and ethics. Additionally, the belief that generative AI will revolutionize efficiency for so much legal work is tempered somewhat by the majority of legal professionals who have reservations about the industry’s current preparedness for this AI-driven future. Compounding the challenges of actionably preparing the industry is the current lack of industrywide consensus about the merits of generative AI. While the evangelists are deeply optimistic that generative AI will have positive impacts on the profession, they currently represent only about half of professionals. As the industry wrestles with these as-yet unresolved issues, the road to widespread adoption of AI in the legal industry remains neither straightforward nor universally agreed upon. Shifting gears: Changes in the legal industry’s workforce for an AI-enabled future Many legal players nonetheless are restructuring their practices to accommodate the use of generative AI and, in doing so, are changing work dynamics and skill requirements. This has led to concerns that roles traditionally performed by humans are at risk. More than two-thirds of law professionals recently mused that roles responsible for much of the life cycle of knowledge management and research in the industry could be replaced by generative AI. However, these same respondents also voiced skepticism about the technology’s ability to perform high-level legal work such as facilitating corporate restructuring or navigating international trade disputes. The potential challenges to traditional roles, however, simultaneously present counterbalancing opportunities: the rising demand for both specialized AI skills and industry-specific technologies. Law firms are increasingly seeking AI experts, and the competition for LawTech talent has intensified. For instance, some firms are planning to expand their teams of lawyers and developers who work with AI. In fact, Allen & Overy recently introduced a chatbot to assist attorneys in drafting contracts and client memos — and its rivals are following suit. The shakeup that generative AI is bringing to the legal industry is affecting not only the workplace but also its precursor — legal education. Universities across multiple continents have established initiatives or courses to equip students and professionals with the skills to interact with AI in their practices. The trust gap: A legal industry polarized about its AI readiness Thus far, the use of generative AI in the legal industry has been characterized by a patchwork of readiness and trust, as evidenced by a range of conflicting opinions among legal professionals and firms. On the one hand, the legal industry exhibits cautious optimism about generative AI: More than 6 in 10 law firms and corporate legal departments believe the technology will deliver significant business advantages. On the other, 72% of legal professionals are doubtful that the industry is adequately prepared for the looming AI revolution, and, as noted earlier, only 1 in 5 believe the advantages of using AI surpass the disadvantages. For example, the University of Liverpool offers a module that provides “hands-on experience” with legal tech tools, while the University of Technology, Sydney, has introduced specialized courses that cover topics ranging from governance and regulatory risks of AI use in legal matters to possible failure points of AI. In the United States, the University of Arizona Law School is spearheading a multi-institution initiative to prepare law libraries across the country for the strategic implementation of AI into their operations. As generative AI marches more deeply into legal territory, the discrepancy between roles at risk and those that require more nuanced human judgment will likely widen. This will necessitate a more systemic shift in legal education and clerking that focuses much less on rote skills and much more on strategy, ethics and other human-centric capabilities. Consequently, the legal firms most likely to pull ahead in this transition may not necessarily be the ones that adopt AI the fastest but those that adapt most holistically to this emerging ecosystem. Partly shaping this cautious outlook are concerns about the trustworthiness and reliability of generative AI in a legal context. More than half of legal professionals are uncertain about the technology’s reliability, and nearly 2 in 5 do not trust it. Consumers of legal services are not entirely won over either, with 55% of clients and potential clients expressing serious concerns about the use of AI within the legal profession. In the near term, disparities in perceptions about trust and readiness may create a segmented legal services market in which AI adoption varies significantly depending on the size of the firm and the specific legal tasks involved. As the industry becomes more accustomed to what AI can and cannot do, these disparities are likely to converge toward a more uniform framework of AI adoption. Ethical roadblocks: Security and privacy concerns surround AI usage in the practice law Although generative AI promises to unleash unprecedented efficiency gains for the legal sector, it also raises complex questions about security, privacy and ethics that cannot be ignored. The industry’s initial outlook toward these aspects has been one of both caution and concern. Many in the legal industry are wary of using generative AI, particularly consumer-facing AI technologies such as ChatGPT. More than 60% of legal professionals do not currently use the technology in their practice, citing security and privacy concerns. Their reluctance stems primarily from unresolved questions of how AI technologies handle privacy and ensure client confidentiality — a view disproportionately held by firms’ partners and managing partners. In response to these concerns, some law firms have already adopted internal measures, including warnings and outright bans against unauthorized use of generative AI in their legal work. The industry’s cautious stance toward the adoption of generative AI technologies is in large measure a manifestation of ethical and operational concerns pertaining to the use of the current iterations of this tech. If generative AI technologies become more robust and sophisticated, will the legal industry’s caution evolve into acceptance? Or will ethical and security concerns be amplified, creating even stronger barriers to adoption? Regulation and guidelines will be instrumental in answering these questions. Recommended Retail Subscribers Like to Stick With What’s Familiar Fed and CFPB Raise Dollar Thresholds for Applicability of Regulations Digital Identity as the New Currency Hackers Claim ICBC Paid to End Ransomware Attack See More In: AI-ID, artificial intelligence, ChatGPT, generative AI, Generative AI Tracker, Law, Legal Industry, News, PYMNTS Intelligence, PYMNTS News, Tracker Series Trending News Use of AI in the Legal Industry Faces Challenges Amazon Extends Social Shopping Efforts With Snapchat Deal NCR Voyix President Says Digital Invoices and ‘Clear’ Messaging Pave Way for Real-Time B2B Payments The Big Story Only a Third of eCommerce Merchants Know if Fraud Caused a Failed Payment Featured News NCR Voyix President Says Digital Invoices and ‘Clear’ Messaging Pave Way for Real-Time B2B Payments Data-Rich Insights Will Power B2B Payments Innovation and Embedded Finance B2B Payments Need ‘Foundational Infrastructure Layer’ as Faster Account-to-Account Beckons Over a Quarter of Consumers Cite Free Cancellation as Key Factor in Choosing Beauty Subscriptions No Shame in the Game: Why Consumers Are Proudly Flaunting Dupes Connatix CFO: Collaboration and Trust Are Redefining B2B Payments Innovation Push-to-Debit Paves Road to Better B2B Payments for Trucking and Logistics Subscribe PYMNTS Today Artificial Intelligence Cryptocurrency B2B Retail TechREG® Digital Transformation SUBSCRIBE Partner with PYMNTS We’re always on the lookout for opportunities to partner with innovators and disruptors. Learn More",
    "originSummary": [
      "The legal industry is facing challenges in adopting generative AI due to concerns about job roles, trust, readiness, security, privacy, and ethics.",
      "Some legal professionals believe generative AI can revolutionize efficiency, while others are skeptical and believe the industry is not prepared for this AI-driven future.",
      "The use of generative AI is leading to changes in workforce roles and skill requirements, with law firms seeking AI experts and introducing AI tools."
    ],
    "commentBody": "",
    "commentSummary": [],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1699969108033
  },
  {
    "title": "Harnessing the Power of AI to Combat Cyber Threats: A Comprehensive Approach",
    "originLink": "https://news.bloomberglaw.com/us-law-week/using-ai-in-cyber-incident-response-demands-a-total-safety-check",
    "originBody": "Baker Donelson’s Matthew White and Justin Daniels assess the new threats that may emerge when companies adopt AI in the workplace, and how they can stay ahead on cybersecurity efforts. Cybersecurity incident response is a developing area that’s increasingly using artificial intelligence-based technology. AI and cyber threats are converging in a unique way—as AI generates a host of new and sophisticated cyber threats, it’s being deployed in software and service offerings that could make cybersecurity incident response more efficient and effective. Companies should realize the AI-driven evolution of cyber threats and consider deploying AI-based tools to fortify their cybersecurity programs. New Threats Cyber criminals or threat actors use AI to launch targeted and effective cyberattacks, often using low-cost AI tools that are upending the cyber threat landscape. Threat actors use AI to create malware and other viruses quickly, making these threats available to almost anyone interested in becoming a hacker—regardless of technological background or programming skills. Threat actors also are using generative AI to create effective phishing, smishing, and vishing messages that lack the poor grammar, improper tone, or misspellings that have been hallmarks of these types of attacks. The translative power of these tools makes it easier to create content in multiple languages, increasing the geographic scope of threats. AI is enabling threat actors to generate more effective deepfakes—phony images, audio clips, or videos of events and individuals. Deepfakes mimic images, voices, and even videos of individuals to perpetrate identify theft, social engineering, and other frauds. AI-based technologies are making it more difficult to discern what’s real while making cyberattacks quicker, easier, more widespread, and even broader in scope. Enhancing Security Our reliance on computer-based technologies, coupled with the rise of new AI-generated cyber threats, creates new risks for companies and makes cybersecurity preparedness essential. The arms race for offensive and defensive superiority in cyber warfare is always evolving. The power of AI is creating a host of new tools and services to combat cyber fraud that is entering the marketplace and becoming increasingly cost-efficient. Some of their capabilities include: Automating threat detection activities without human intervention, increasing effectiveness and efficiency of threat mitigation and detection Detecting and identifying vulnerable patterns and potential failures within company networks and monitoring them in real time Analyzing patterns, content, anomalies, and links in emails before they enter a user’s inbox to prevent phishing attacks, and analyzing audio and video content to quickly identify potentially fraudulent content Using advanced learning techniques to quickly investigate large volumes of potentially malicious data Analyzing historical data to identify the root cause of an incident Streamlining incident response by automating communications to appropriate team members, categorizing and triaging incidents based on their potential to harm an organization, and simplifying the process of documenting incidents. Perfect off the shelf solutions for incident response don’t exist, and organizations must spend the necessary time and effort to properly implement and calibrate the appropriate technologies into their environments. To optimize the effectiveness of the AI-based solutions, these tools must be “trained” on the right data within an environment and that their settings, rules, configurations, and any assumptions are properly constituted for that environment. Security Tools Since many providers are entering the market for AI-based cybersecurity and incident response solutions, companies must ensure they’re using the right tool from the right vendor by asking: What AI tools does the vendor use to analyze or modify your data? Were the vendor’s AI tools developed in conjunction with experienced incident response professionals? Within any solutions, to what extent are results generated by AI versus traditional analysis methods? What are the sources of data that the vendor used to train and develop any AI tools, and how extensive were those datasets? Does the provision of data to a vendor (and for this purpose) comply with applicable privacy laws and/or confidentiality obligations? What restrictions are imposed on the vendor’s ability to use (or further use) any data provided? Can the company’s confidential information, sensitive information, or trade secrets be prevented from entering the vendor’s AI tools? If not, what measures does the vendor have in place to protect this information? How are ownership rights protected in any AI-generated output that includes or is based upon the company’s data? How are answers generated by the AI tool verified to ensure accuracy and completeness? Does the company’s technical team understand how the AI tool works, including what objectives it does or doesn’t meet, what training or calibration is required, and what ability exists to oversee the implementation of the tool? Both the threats created by sophisticated AI applications and the cutting-edge AI-based tools developed to fight these and other cyber-related threats more efficiently will continue to grow. Companies should evaluate implementing AI-based security tools into their cybersecurity and incident response programs to supplement and advance cyber prevention and preparedness planning. As part of this process, companies should understand the vendor and the tools they acquire to ensure efficient, effective, and compliant implementation. It’s time for companies to take advantage of the power of AI to prepare themselves for the next generation of cyber threats. This article does not necessarily reflect the opinion of Bloomberg Industry Group, Inc., the publisher of Bloomberg Law and Bloomberg Tax, or its owners. Author Information Matthew White is co-chair of Baker Donelson’s financial services cybersecurity and data privacy team. Justin Daniels is a shareholder at Baker Donelson, providing corporate advice to growth-oriented and middle-market domestic and international technology businesses. Write for Us: Author Guidelines Continue Reading Learn About Bloomberg Law AI-powered legal analytics, workflow tools and premium legal & business news. Learn more Already a subscriber? Log in to keep reading or access research tools. Log In",
    "originSummary": [
      "AI is being used by cybercriminals to execute advanced and targeted cyberattacks.",
      "AI is also being utilized in cybersecurity incident response to enhance protection.",
      "The article recommends that companies acknowledge and address the AI-driven evolution of cyber threats, and suggests implementing AI-based tools to strengthen cybersecurity programs."
    ],
    "commentBody": "",
    "commentSummary": [],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1699969108033
  },
  {
    "title": "Guidance on Integrating AI into Business Operations While Complying with Laws and Guidelines",
    "originLink": "https://www.globallegalpost.com/news/is-ai-really-here-yet-have-we-missed-the-boat-are-we-struggling-to-keep-up-988785763",
    "originBody": "LAW OVER BORDERS COMPARATIVE GUIDES Artificial Intelligence This first edition, written by leading AI legal specialists, provides answers and insight on how to integrate Artificial Intelligence into business operations, whilst working within the relevant law and guidelines in key jurisdictions around the world....1yr This first edition, written by leading AI legal specialists, provides answers and insight on how to ...",
    "originSummary": [
      "The Law over Borders Comparative Guides on Artificial Intelligence is a comprehensive resource written by AI legal specialists.",
      "It provides guidance on integrating AI technology into business operations.",
      "The guide also emphasizes the importance of complying with laws and guidelines across different jurisdictions globally."
    ],
    "commentBody": "",
    "commentSummary": [],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1699969108033
  },
  {
    "title": "Optimizing AI in the Legal Department: Three Effective Testing Methods",
    "originLink": "https://www.wolterskluwer.com/en/expert-insights/three-ways-to-test-your-ais-effectiveness",
    "originBody": "LegalNovember 13, 2023 Three ways to test your AI’s effectiveness This article by Jitendra Gupta, Director, Ops Decision Science at Wolters Kluwer ELM Solutions, was originally published in Legal Dive. It’s no secret that artificial intelligence has swiftly woven itself into everyday life. ChatGPT gained one million users in a mere five days, fast food chains are using AI to take drive-thru orders, and Reddit co-founder Alexis Ohanian called the coming AI revolution “bigger than the smartphone.” While the buzz around AI has grown tremendously in recent months, AI-enabled solutions have been around far longer — including many that target corporate legal departments. A lot has already been written about how companies can build, mature, and benefit from artificial intelligence. But once a corporate legal department has implemented AI — a process that includes getting buy-in from the top and building trust from below — its work isn’t done. Instead, legal teams need to be able to ensure the AI they’ve implemented is effective. With that in mind, let’s dive into three ways to test your AI’s effectiveness. 1. Gamify adoption Because artificial intelligence improves with more input, incentivizing adoption is key to creating effective AI. Gamify the task to spur employees to squeeze the most out of a new tool. By placing AI in a competitive context, people’s competitive spirit will come out, and adoption is likely to be embraced with far more enthusiasm. For example, a legal team could test the effectiveness of its AI by giving a large set of invoices to a team with access to the tool — and a comparable set of invoices to a team without it. At first, many users may aim to beat the AI. But as time goes on, it’s likely that more people will want to be on the review team that is being supported by the technology. By gamifying the experience, in-house teams can create buzz around the tool, get people excited about trying it, and ultimately spur both buy-in and adoption. 2. Run AI behind the scenes Despite your best efforts, though, skepticism around AI-enabled software is likely to persist. This is particularly the case considering AI is not deterministic but probabilistic. When experts are used to software with a very black-and-white output, they tend to focus on what AI gets wrong. One way to avoid this problem is to consider running the AI behind the scenes first. For instance, have AI review sets of law firm invoices that human reviewers have already gone over. Gauge the speed and accuracy of the AI-driven process versus the manual process. Chances are good that the AI will be quicker — and might even find billing errors humans did not initially notice. This is an effective approach because it turns the tables: instead of humans checking the work of AI, AI can check the work of humans. Running AI in the background can give proof of the AI’s effectiveness, which can then be shared with the process owner. Thus, when AI is introduced to users, they’ll be able to see its value more quickly and may be more eager to jump on board. 3. Use process mining software Finally, process mining software is extremely valuable in understanding how and to what degree an AI solution improves efficiency. Process mining software is like an X-ray machine into people’s workflows. Process mining software is great for monitoring workflow efficiencies and identifying potential areas for improvement. For example, process mining can be used to ascertain how much time corporate lawyers are spending on core, operational platforms versus other solutions, like Excel. It can also be useful to see how much time it takes for legal teams to perform certain actions — reviewing and signing off on an invoice, for example. If this seems intrusive, just do it on a sample of users. The point is to be able to identify, using clearly defined KPIs, how people’s workflows look both pre- and post-implementation of the AI-enabled solution. Having data to demonstrate how and where the AI solution is improving efficiency can be useful in spurring adoption and thus refining the tool. The bottom line While there’s tremendous buzz around AI, don’t bring in an AI solution for the sake of saying you did so. Instead, be strategic and set expectations appropriately. Because AI is not deterministic, there will be a learning curve. During that time, it’s crucial to check in and assess whether the solution is trending in the direction you hoped. Remember: there are many ways to test a new tool’s effectiveness while also generating user enthusiasm and buy-in. Make it a game, measure KPIs, and, above all, be honest about how things are going. Explore related topics Artificial intelligenceEnterprise softwareExpert insights Solutions Enterprise legal management Market-leading provider of enterprise legal spend and matter management, contract lifecycle management, and legal analytics solutions Learn More How we help Matter management Spend management Contract management Related Insights Article Legal November 06, 2023 Legal Leaders Exchange: Procurement’s contribution to budgeting and spend control In-house and outside counsel have contrasting motivations, but procurement professionals can help. Learn More Article Legal November 01, 2023 Legal Technology Innovation: Navigating Complex Team Dynamics and Resolving Issues Ken Crutchfield, Vice President and General Manager of Legal Markets at Wolters Kluwer Legal & Regulatory U.S., focused his most recent article for Above the Law on navigating complicated dynamics and resolving issues within teams. Learn More Article Legal November 01, 2023 Congratulations, 2023 Legal Innovators! ELM Solutions has announced the 2023 Legal Innovator Award winners! Learn More Article Legal October 27, 2023 Five keys to trusted AI Our Jitendra Gupta writes about the five main components of trustworthy AI. Learn More",
    "originSummary": [
      "Gamifying adoption of AI tools in corporate legal departments can incentivize employees to use the technology through competition.",
      "Running AI behind the scenes to showcase its speed and accuracy compared to manual processes is another effective testing method.",
      "Process mining software can be used to analyze workflow efficiencies and identify areas for improvement when evaluating the effectiveness of AI solutions in legal departments."
    ],
    "commentBody": "",
    "commentSummary": [],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1699969108033
  },
  {
    "title": "Maximizing Efficiency: 7 AI Applications for In-House Legal Workflows",
    "originLink": "https://www.jdsupra.com/legalnews/7-ai-applications-for-in-house-legal-8353200/",
    "originBody": "Menu News & Insights Popular Labor & Employment Finance & Banking Intellectual Property Health & Healthcare Environmental Issues more… Business Insurance Commercial Real Estate Corporate Taxes Immigration Securities more… Personal Residential Real Estate Estate Planning Civil Rights Personal Taxes Bankruptcy more… Jump to: Latest Updates » Trending [7] [Hot Topic] Artificial Intelligence [Hot Topic] Employer Liability Issues [Hot Topic] Environmental, Social & Governance [Ongoing] Read Latest SCOTUS Analysis, All Aspects Stay Informed: Popular Reads on JD Supra Meet JD Supra's Top Authors! Build a Morning News Digest: Easy, Custom Content, Free! Browse All Law News Topics » Find Author By Business Matters Labor & Employment Finance & Banking Intellectual Property Insurance Taxes By Personal Issues Civil Rights Family Matters Personal Injury Wills, Trusts, & Estate Planning Worker’s Compensation By Location California New York Texas Canada United Kingdom Subscribe Custom Email Digests Build a custom email digest by following topics, people, and firms published on JD Supra. Twitter RSS Feeds for Publishers For Reporters My Account Log In November 13, 2023 7 AI Applications for In-House Legal Workflows Onit + Follow Contact LinkedIn Facebook Twitter Send Embed ARTIFICIAL INTELLIGENCE As AI capabilities progress, in-house legal teams have an invaluable opportunity to integrate these advanced technologies into key workflows and processes to drive greater efficiency, insights, and productivity. When thoughtfully implemented, AI can serve as an ally in handling high-volume, repetitive tasks that have traditionally burdened legal professionals’ time. From contract management to legal research and beyond, AI systems powered by strong prompting skills can amplify and augment in-house teams’ efforts, allowing professionals to focus their expertise on the most strategic, high-value aspects of legal work. Here are 7 key AI applications for in-house legal workflows: Contract Analysis and Review: A well-crafted prompt can enable AI to sift through complex contracts meticulously, spotlight duties, identify potential risks, and offer actionable insights. Invoice Auditing: AI can rapidly process high volumes of legal invoices, flagging potentially erroneous charges for auditors to review. This optimizes the invoice validation process. Litigation Support and Preparation: AI assists with tasks like organizing case documents, drafting briefs, and finding supporting precedents to bolster arguments. This reduces repetitive preparation work. Regulatory Monitoring: AI tracks updates across vast regulatory sources and alerts teams to key changes relevant to the business. This enables proactive compliance. IP Management: Consider the herculean task of analyzing vast patent databases. With its efficiency, AI ensures exhaustive patent searches and assists in drafting applications with precision. Discovery: AI expedites eDiscovery by quickly filtering huge document sets down to the most relevant materials, minimizing review time. Legal Research: With thoughtful prompting, AI can rapidly traverse extensive legal databases, identifying pertinent cases, rulings, and regulations. Integrating AI into these critical in-house workflows with meticulous implementation and oversight can profoundly augment legal professionals’ capabilities and enable more strategic, high-value work. AI’s incorporation in legal practice is not just a pursuit of efficiency — it’s about refining the quality of legal services. As we harness AI’s prowess, a principle must be held sacred: AI tools, no matter how advanced, should serve as an extension of your expertise and not a replacement. Send Print Report Latest Posts 7 AI Applications for In-House Legal Workflows 5 Key Factors to Consider When Integrating AI into Your Legal Department [Webinar] Mastering AI For Legal Professionals: A Practical Course in Generative Technologies - October 5th, 2:00 pm - 3:30 pm CT The ROI of Legal Operations: Measuring Success and Demonstrating Value with Legal KPIs How Corporate Legal Teams Benefit From RFP See more » Written by: Onit Contact + Follow more less Published In: Algorithms + Follow Artificial Intelligence + Follow Automation Systems + Follow Business Development + Follow Business Strategies + Follow Client Services + Follow Contract Management + Follow Discovery + Follow In-House Perspective + Follow Innovative Technology + Follow Legal Operations + Follow Legal Project Management + Follow Legal Research + Follow Machine Learning + Follow Professional Practice + Follow Science, Computers & Technology + Follow more less Onit on: \"My best business intelligence, in one easy email…\" Your first step to building a free, personalized, morning email brief covering pertinent authors and topics on JD Supra: Sign Up Log in *By using the service, you signify your acceptance of JD Supra's Privacy Policy. - hide - hide Back to Top Home What Is JD Supra? Subscribe Leverage Your Thought Leadership Privacy Policy Terms & Conditions Contact Team Cookie Preferences Explore 2023 Readers' Choice Awards Copyright © 2023 JD Supra, LLC",
    "originSummary": [
      "In-house legal teams can enhance their productivity and efficiency by integrating artificial intelligence (AI) into their workflows.",
      "AI can assist with various tasks, including contract analysis, invoice auditing, litigation support, regulatory monitoring, IP management, discovery, and legal research.",
      "Legal professionals should view AI as an extension of their expertise rather than a replacement, enabling them to concentrate on strategic and high-value work."
    ],
    "commentBody": "",
    "commentSummary": [],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1699969108033
  },
  {
    "title": "Canadian Silica Maker and Singaporean AI Firm to Go Public in US via SPAC Deals",
    "originLink": "https://www.law360.com/energy/articles/1765939/canadian-silica-maker-singaporean-ai-firm-ink-spac-deals",
    "originBody": "Sign In Try our Advanced Search for more refined results Toggle Dropdown Search Law360 Search News Only Search Cases Only Search PTAB Only Search TTAB Only Advanced Search Sign In Close Law360 Law360 UK Law360 Pulse Law360 Employment Authority Law360 Tax Authority Law360 Insurance Authority Law360 Real Estate Authority Products Lexis® Law360 In-Depth Law360 Podcasts Rankings Regional Powerhouses Law360's MVPs Women in Law Report Law360 400 Diversity Snapshot Practice Groups of the Year Rising Stars Titans of the Plaintiffs Bar Sections Adv. Search & Platform Tools About all sections Browse all sections Banking Bankruptcy Class Action Competition Employment Energy Expert Analysis Insurance Intellectual Property Product Liability Securities Beta Tools Track docs Track attorneys Track judges Site Menu Join the Law360 team Search legal jobs Learn more about Law360 Read testimonials Contact Law360 Sign up for our newsletters Law360 Company Resource Library Site Map Help Intellectual Property Securities Bankruptcy Competition Employment White Collar Legal Industry Access To Justice Law360 UK Pulse || See all sections || TAKE A FREE TRIAL ADVERTISEMENT Don't want ads? Subscribe or login now. ADVERTISEMENT Canadian Silica Maker, Singaporean AI Firm Ink SPAC Deals By Tom Zanki (November 13, 2023, 6:57 PM EST) -- A Canadian silica producer and a Singaporean artificial intelligence business announced plans to go public in the United States on Monday by merging with special-purpose acquisition companies, under the guidance of at least eight law firms combined. . . . Law360 is on it, so you are, too. A Law360 subscription puts you at the center of fast-moving legal issues, trends and developments so you can act with speed and confidence. Over 200 articles are published daily across more than 60 topics, industries, practice areas and jurisdictions. A Law360 subscription includes features such as Daily newsletters Expert analysis Mobile app Advanced search Judge information Real-time alerts 450K+ searchable archived articles And more! Experience Law360 today with a free 7-day trial. Start Free Trial Already a subscriber? Click here to login ADVERTISEMENT ADVERTISEMENT Related Sections Asset Management Capital Markets Energy Environmental Massachusetts Mergers & Acquisitions Private Equity Technology Texas Law Firms DLA Piper Ellenoff Grossman Hunter Taubman Rajah & Tann Reed Smith Skadden Arps White & Case Companies BMO Capital Markets Corp. The 2023 Law360 Prestige Leaders Check out our Prestige Leaders ranking, analysis and interactive graphics to see which firms stand out for their financial performance, attractiveness to attorneys and law students, ability to secure accolades, and positive legal news media representation. Top 10 trending in Energy 1Supreme Court Lays Out Code Of Conduct 2Paul Clement's Big Idea: Overrule Chevron, Ease Polarization 3Biden Admin Wins Reversal On Solar Safeguard Expansion 4Green Groups Lose Bid To Stop ConocoPhillips' Willow Project 5Biden GHG Cost Estimates Face Uncertain Fate In Court 6Exxon Climate Suit Could Fix A Circuit Split, Justices Told 73 Firms Steer Mach Natural's $815M Anadarko Basin Play 8White House Finalizes Agency Cost-Benefit Analysis Guidance 9Senate Votes To Block Relaxed EV 'Buy America' Rules 10Geothermal Spat Should Stay As One Suit, Co-Founder Says ADVERTISEMENT ADVERTISEMENT Hello! I'm Law360's automated support bot. How can I help you today? For example, you can type: I forgot my password I took a free trial but didn't get a verification email How do I sign up for a newsletter? Ask a question! © 2023, Portfolio Media, Inc.AboutContact UsLegal JobsAdvertise with Law360Careers at Law360TermsPrivacy PolicyCookie SettingsAd ChoicesHelpSite MapResource LibraryLaw360 Company × Already have access? Click here to login Get instant access to the one-stop news source for business lawyers Register Now! Start your free 7-day trial To continue reading, fill out the form below to activate a free 7-day trial of Law360. Email (NOTE: Free email domains not supported) First Name Last Name Job Title Password (at least 8 characters required) Confirm Password Get the best of Law360 in your inbox Select at least one primary interest below to receive curated, daily newsletters designed by senior editors so you can quickly scan the latest news and analysis in your area of practice. Asset Management Capital Markets Energy Environmental Massachusetts Mergers & Acquisitions Show all interests Law360 may contact you in your professional capacity with information about our other products, services and events that we believe may be of interest. You’ll be able to update your communication preferences via the unsubscribe link provided within our communications. We take your privacy seriously. Please see our Privacy Policy. Start Free Trial × Sign up for our Energy newsletter You must correct or enter the following before you can sign up: Please provide a professional email: Select more newsletters to receive for free Law360 takes your privacy seriously. Please see our Privacy Policy. No Thanks Sign up now Thank You!",
    "originSummary": [
      "A Canadian silica producer and a Singaporean AI business are planning to go public in the US through mergers with special-purpose acquisition companies (SPACs).",
      "The deals will be facilitated by at least eight law firms."
    ],
    "commentBody": "",
    "commentSummary": [],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1699969108033
  },
  {
    "title": "Weak global response to military use of AI undermines progress in regulation",
    "originLink": "https://www.c4isrnet.com/opinion/2023/11/13/we-need-hard-laws-on-military-use-of-ai-and-soon/",
    "originBody": "Artificial intelligence’s destructive potential has resulted in a flurry of recent governance activity. Mere days before the U.K. hosted its AI Safety Summit from Nov. 1-2, the Biden administration announced the executive order on “Safe, Secure, and Trustworthy Artificial Intelligence.” Though the summit in the U.K. set out to focus on catastrophic risks of AI, the U.S. efforts have focused on more concrete issues such as its military uses. While at the summit, U.S. Vice President Kamala Harris announced several new initiatives that comprised the executive order, such as the new AI Safety Institute. But crucially, Harris also announced that 31 nations had joined the Political Declaration on Responsible Military Use of Artificial Intelligence and Autonomy. The declaration was first announced at the Summit on Responsible Artificial Intelligence in the Military Domain held in February in the Netherlands. The update on the declaration signals U.S. commitment to this effort and brings attention to the signatory list that includes U.S. allies such as Canada, Australia and France. Notably missing, though, are Russia and China. The likelihood of either state joining a U.S.-led effort in the current geopolitical climate is exceedingly low. Russia was not welcome at either summit and is unlikely — with its ongoing invasion of Ukraine — to be brought into these discussions. Even if it was invited, Russia would not likely sign even voluntary documents, as it does not wish to see any regulation, binding or nonbinding, on emerging technologies. China did attend the summits and sign onto two non-legally binding instruments: the “REAIM 2023 Call to Action”; and the “Bletchley Declaration” agreed to at the U.K. summit. While important for further dialogue, this obscures a greater obstacle that China poses on AI regulation generally — and specifically on military applications of AI. While China is unlikely to be as obstructionist as Russia has been in multilateral discussions on autonomous weapons, it is clear it will only agree to nonbinding instruments and those that are on its terms. This means that it is unlikely to join the U.S. Political Declaration on Responsible Military Use of AI and Autonomy due to its strategic interests in relation to the technology and the broader geopolitical competition with the U.S. This was evident when it came to the recent vote on the first-ever resolution on autonomous weapons at the First Committee of the General Assembly, which generally notes that states recognize the urgency to address growing autonomy in weapon systems and to hold more talks. While 164 voted to approve the resolution, China abstained. China’s abstention highlights that it will try to shape any outcome, including delaying efforts, until the terms are favorable to its ambitions to achieve military AI supremacy. Only two states voted against the resolution: Russia and India. Neither vote is surprising given both Russia and India have pushed back against more significant regulatory steps at the U.N. Convention on Certain Conventional Weapons, or CCW. Indeed, that forum has largely stalled due to the treatment of consensus as unanimity as well as resistance by Russia and India. Is the pushback by China, Russia and India insurmountable? Over the years of discussions on autonomous weapons at the CCW, it has become evident that allies talking to allies does not address the challenge of more adversarial states or states that would be adversaries, primarily for the U.S. and its allies. China joining some of these discussions should be welcomed. However, there should be no illusion that the presence of China or its signing of nonbinding measures is indicative of its willingness to commit to hard laws. Now, this may not appear to be an issue, as neither the U.S. nor its allies are too interested in hard laws on military AI. Even the expected “landmark agreement” — reached on the margins of the Asia-Pacific Economic Cooperation summit between the U.S. and China, apparently banning the use of AI in weapons, drones and nuclear command and control — is more than anything going to feature voluntary and aspirational measures. However, voluntary agreements and exchange of information are much easier to do with allies. When crisis scenarios among more adversarial states arise — and they are likely to as more states deploy AI and more autonomous systems in battlespaces — it will be important to have clarity on what is permissible, communication channels open, and clear rules guiding uses of AI and autonomy. It is likely sooner rather than later that states will realize the benefit of some legally binding instruments as well. The political declaration and the first-ever U.N. resolution on autonomous weapons are important steps forward, as is the expected bilateral agreement between the U.S. and China. But more governance, including hard laws and complementary processes on military AI and autonomous weapons, is needed. This will require a degree of skilled diplomacy to engage not just allies but potential adversaries, and to craft legal agreements. Only then will the risks that come with military AI, such as errors and conflict escalation, be truly addressed. Branka Marijan is a senior researcher at Project Ploughshares, specializing in the military and security implications of emerging technologies. She is also a contributor to the Centre for International Governance Innovation think tank. Share: More In Opinion Russian arms industry banks on Dubai defense fair to show viability State-owned Rosoboronexport had announced a new counter-drone weapon to be on display, but the equipment was nowhere to be seen. US Air Force’s Sentinel missile ‘struggling,’ faces rising costs It has been decades since the Air Force last developed a nuclear missile, the secretary says, and surprise issues are cropping up. US seeks to fund Israeli laser as Army considers Iron Beam’s potential The U.S. Army is eyeing Iron Beam as a possible alternative laser to augment its own fire protection capability. White House radio spectrum access plan may benefit internet, drones As much as 2,786 megahertz of spectrum may be repurposed for wireless broadband, drones and satellites.",
    "originSummary": [
      "The U.K. hosted an AI Safety Summit to discuss the potential catastrophic risks of AI, while the U.S. focused more on the military applications of AI.",
      "U.S. Vice President Kamala Harris announced the establishment of the AI Safety Institute and the participation of 31 nations in the Political Declaration on Responsible Military Use of AI and Autonomy.",
      "Russia and China declined to join the declaration, with Russia not receiving an invitation and China only signing nonbinding agreements on its own terms. This resistance from major powers could impede the progress in establishing binding agreements on military AI regulation. It highlights the need for enhanced governance, including enforceable laws and diplomatic engagement to address the risks posed by military AI."
    ],
    "commentBody": "",
    "commentSummary": [],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1699969108033
  }
]
