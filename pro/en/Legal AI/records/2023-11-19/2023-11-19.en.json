[
  {
    "title": "France, Germany, and Italy advocate for self-regulation of foundation models in EU's AI law",
    "originLink": "https://www.euractiv.com/section/artificial-intelligence/news/france-germany-italy-push-for-mandatory-self-regulation-for-foundation-models-in-eus-ai-law/",
    "originBody": "By Luca BertuzziEuractiv.com Est. 4min 12:59 (updated: 13:01) Content-Type: News News Based on facts, either observed and verified directly by the reporter, or reported and verified from knowledgeable sources. [Tada Images/Shutterstock] Euractiv is part of the Trust Project >>> Print Email Facebook Twitter LinkedIn WhatsApp Telegram The three biggest EU countries are pushing for codes of conduct without an initial sanction regime for foundation models rather than prescriptive obligations in the AI rulebook, according to a non-paper seen by Euractiv. The AI Act is a flagship EU legislation to regulate Artificial Intelligence based on its capacity to cause harm. The file is currently at the last phase of the legislative process, where the EU Commission, Council, and Parliament gather in ‘trilogues’ to hash out the law’s final dispositions. The negotiations on the world’s first comprehensive AI law have been disrupted by the rise of ChatGPT, a versatile type of AI system known as General Purpose AI, which is built on OpenAI’s powerful foundation model GPT-4. On 10 November, Euractiv reported that the entire legislation was at risk following mounting opposition from France, which gained support from Germany and Italy in its push against any regulation on foundation models. The EU heavyweights – France, Germany, and Italy – asked the Spanish presidency of the EU Council, which negotiates on behalf of member states, to retreat from the tiered approach on which there seemed to be a consensus at the last political trilogue in mid-October. EU’s AI Act negotiations hit the brakes over foundation models A technical meeting on the EU’s AI regulation broke down on Friday (10 November) after large EU countries asked to retract the proposed approach for foundation models. Unless the deadlock is broken in the coming days, the whole legislation is at risk. In response, European Parliament officials walked out of a meeting to signal that leaving foundation models out of the law was not politically acceptable. In recent weeks, the Spanish presidency attempted to mediate a solution between the EU parliamentarians and the most reluctant European governments. However, the three countries circulated on Sunday (19 November) a non-paper that shows little room for compromise, considering that horizontal rules on foundation models would go against the technology-neutral and risk-based approach of the AI Act that is meant to preserve innovation and safety at the same time. “The inherent risks lie in the application of AI systems rather than in the technology itself. European standards can support this approach following the new legislative framework,” the document said, adding that the signatories are “opposed to a two-tier approach for foundation models”. “When it comes to foundation models, we oppose instoring un-tested norms and suggest to instore to build in the meantime on mandatory self-regulation through codes of conduct,” the non-paper further said, noting that these follow the principles defined at the G7 with the Hiroshima process. EU policymakers enter the last mile for Artificial Intelligence rulebook The world’s first comprehensive AI law is entering what might be its last weeks of intense negotiations. However, EU institutions have still to hash out their approach to the most powerful ‘foundation’ models and the provisions in the law enforcement areas. Instead, the three countries argue that regulating General Purpose AI systems that can be available for specific applications rather than foundation models would be more in line with the risk-based approach. To implement this approach, Paris, Berlin, and Rome propose that foundation model developers would have to define model cards, technical documentation that summarises the information about trained models to a broad audience. “Defining model cards and making them available for each foundation model constitutes the mandatory element of this self-regulation,” the non-paper noted, stressing that these cards will have to include the relevant information on the model capabilities and limits and be based on the best practices within the developers’ community. The examples provided include the number of parameters, intended uses, potential limitations, results of studies on biases, and red-teaming for security assessment. The non-paper proposed that an AI governance body could help develop guidelines and check the application of model cards, providing an easy way to report any infringement to the code of conduct. EU AI Act ‘cannot turn away from foundation models’, Spain’s state secretary says With Europe’s AI rulebook at a delicate stage of negotiations, Carme Artigas, the Spanish Secretary of State for Digitalisation and Artificial Intelligence, spoke to Euractiv about the state of play of the inter-institutional discussions. “Any suspected violation in the interest of transparency should be made public by the authority,” the document continued. The three countries also do not want sanctions to apply at the beginning. According to them, a sanction regime would only be set up following systematic infringements of the codes of conduct and a ‘proper’ analysis and impact assessment of the identified failures. For the three, European standards could also be an important tool to create the adaptive capacity needed to take into account future developments. The approach to foundation models will be at the centre of a discussion of the Telecom Working Party, a technical Council body, on Tuesday (21 November). On the same day, MEPs will hold an internal meeting on the matter, followed by a dinner with the Council presidency and the Commission. “This is a declaration of war,” a parliament official told Euractiv on condition of anonymity. [Edited by Zoran Radosavljevic] Read more with EURACTIV MEPs ask Commission to act after revelations of sensitive EU data sell-off A cross-party coalition of Members of the European Parliament demanded that the European Commission take action following the revelations that sensitive data from European leaders was being sold to the highest bidder. Print Email Facebook Twitter LinkedIn WhatsApp Telegram Topics AI Act Artificial Intelligence artificial intelligence Foundation models France Germany Italy Technology",
    "originSummary": [
      "France, Germany, and Italy, the three largest countries in the EU, are advocating for codes of conduct rather than strict obligations to regulate foundation models in the EU's AI Act.",
      "They argue that focusing on regulating General Purpose AI systems instead of foundation models aligns better with a risk-based approach.",
      "The countries propose that developers should define model cards with relevant information as a mandatory element of self-regulation, and they oppose initial sanctions, suggesting a sanction regime should only be implemented for systematic violations of the codes of conduct.",
      "These disagreements have disrupted negotiations on the AI Act and may jeopardize the entire legislation."
    ],
    "commentBody": "",
    "commentSummary": [],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1700403328211
  },
  {
    "title": "UnitedHealth's AI Denies Claims in Error, Lawsuit Alleges",
    "originLink": "https://www.usatoday.com/story/news/health/2023/11/19/unitedhealth-artificial-intelligence-denies-claims-in-error-lawsuit-says/71579822007/",
    "originBody": "HEALTH UnitedHealth Group Add Topic Is your health insurer using AI to deny you services? Lawsuit says errors harmed elders. Ken Alltucker USA TODAY For years, vital decisions about who got medical care coverage took place in back offices at health insurance companies. Now, some of those life-altering decisions are being made by artificial intelligence programs. At least that's the contention of the two families who sued UnitedHealth Group this week, saying the insurance giant used emerging technology to deny or shorten rehabilitation stays for two elderly men in the months before they died. They say that UnitedHealth's artificial intelligence, or AI, is making \"rigid and unrealistic\" determinations about what it takes for patients to recover from serious illnesses and denying them care in skilled nursing and rehab centers that should be covered under Medicare Advantage plans, according to a federal lawsuit filed in Minnesota by the estates of two elderly Wisconsin patients. The lawsuit, which seeks class-action status, says it is illegal to let AI override doctors' recommendations for these men and patients like them. The families say assessments like that should be done by medical professionals. The families note in the suit that they believe the insurance company is denying care to elderly patients who won't fight back even though evidence shows the AI is doing a lackluster job of assessing people's needs. The company used algorithms to determine coverage plans and override doctors' recommendations despite the AI program's astonishingly high error rate, they say. More than 90% of patient claim denials were overturned through internal appeals or a federal administrative law judge, according to court documents. But in reality, few patients challenged the algorithms' determinations. A tiny percentage of patients − .2% − choose to fight claim denials through the appeals process. The vast majority of people insured by UnitedHealth's Medicare Advantage plans \"will either pay out-of-pocket costs or forgo the remainder of their prescribed post-acute care,\" the lawsuit says. Attorneys representing the families suing the Minnesota-based insurance giant said the high rate of denials is part of the insurance company's strategy. \"They're placing their own profits over the people that they are contracted with and then legally bound to cover,\" said Ryan Clarkson, a California attorney whose law firm has filed several cases against companies using AI. \"It's that simple. It's just greed.\" UnitedHealth told USA TODAY in a statement naviHealth's AI program, which is cited in the lawsuit, isn't used to make coverage determinations. \"The tool is used as a guide to help us inform providers, families and other caregivers about what sort of assistance and care the patient may need both in the facility and after returning home,\" the company said. Coverage decisions are based on the Centers for Medicare & Medicaid Services' criteria and the consumer's insurance plan, the company said. \"This lawsuit has no merit, and we will defend ourselves vigorously,” the company said. Lawsuits of this type are not new. They are part of a growing body of litigation. In July, the Lawson law firm filed a case against CIGNA Healthcare alleging the insurer employed AI to automate claims rejections. The firm also has pursued cases against ChatGPT maker OpenAI and Google. Families pay for expensive care that the insurer denies The plaintiffs in the suit this week are the relatives of two deceased Wisconsin residents, Gene B. Lokken and Dale Henry Tetzloff, who were both insured by UnitedHealth's private Medicare plans. In May 2022, Lokken, 91, fell at home and broke his leg and ankle, requiring a brief hospital stay followed by a month in a rehab facility while he healed. Lokken's doctor then recommended physical therapy so he could regain strength and balance. The Wisconsin man spent less than three weeks in physical therapy before the insurer terminated his coverage and recommended he be discharged and sent to recover at home. A physical therapist described Lokken's condition as \"paralyzed\" and \"weak,\" however his family appeals for continued therapy coverage were rejected, according to the lawsuit. His family opted to continue with treatment despite the denial. Without coverage, the family had to pay $12,000 to $14,000 per month for about a year of therapy at the facility. Lokken died at the facility in July 2023. The other man's family also raised concerns that necessary rehabilitation services had been denied by the AI algorithm. Tetzloff was recovering from a stroke in October 2022, and his doctors recommended the 74-year-old be transferred from a hospital to a rehab facility for at least 100 days. The insurer initially sought to end his coverage after 20 days, but the family appealed. The insurer then extended Tetzloff's stay another 20 days. The man's doctor had recommended additional physical and occupational therapy, but his coverage ended after 40 days. The family spent more than $70,000 on his care during the next 10 months. Tetzloff spent his final months in an assisted living facility, where he died on Oct. 11. 10 appeals to rehab a broken hip The legal action comes after Medicare advocates began raising concerns about the routine use of AI technology to deny or reduce care for older adults on private Medicare plans. In 2022, the Center for Medicare Advocacy examined multiple insurers' use of artificial intelligence programs in rehabilitation and home health settings. The advocacy group's report concluded that AI programs often made coverage decisions that were more restrictive than what Medicare would have allowed and the decisions lacked the level of nuance necessary to evaluate the unique circumstances of each case. \"We saw more care that would have been covered under traditional Medicare denied outright or prematurely terminated,\" said David Lipschutz, associate director and senior policy attorney for the Center for Medicare Advocacy. Lipschutz said some older adults who appeal rejections might win a reprieve only to be shut down again. He cited the example of a Connecticut woman who sought a three-month stay at a rehab center as she recuperated from a hip replacement surgery. She filed and won 10 appeals after an insurer repeatedly attempted to terminate her coverage and limit her stay. Importance of having 'human in the loop' Legal experts who are not involved in these cases said artificial intelligence is becoming a fertile target for people and organizations seeking to rein in or shape the use of emerging technology. Gary Marchant, faculty director at the Center for Law, Science and Innovation at Arizona State University's Sandra Day O'Connor College of Law, said an important consideration for health insurers and others deploying AI programs is making sure that humans are part of the decision-making process. While AI systems can be efficient and complete rudimentary tasks quickly, programs on their own can also make mistakes, Marchant said. \"Sometimes AI systems aren't reasonable and they don't have common sense,\" said Marchant. \"You have to have a human in the loop.\" In cases involving insurance companies using AI to guide claim decisions, Marchant said a key legal factor might be how much a company defers to an algorithm. The UnitedHealth lawsuit states that the company limited workers' \"discretion to deviate\" from the algorithm. Employees who deviated from the AI program's projections faced discipline or termination, the lawsuit said. Marchant said one factor to track in the UnitedHealth cases and similar lawsuits is how closely employees are required to follow an AI model. \"There, clearly, has to be an opportunity for the human decider to override the algorithm,\" Marchant said. \"That's just a huge issue in AI and healthcare.\" He said it's important to consider the consequences of how companies set up their AI systems. Companies should think about how much deference they give to an algorithm, knowing that AI can digest huge amounts of data and be\"incredibly powerful\" as well as \"incredibly accurate,\" he said, and leaders should also keep in mind that AI \"sometimes can just be completely wrong.\" Ken Alltucker is on X, formerly Twitter, at @kalltucker, or can be emailed at alltuck@usatoday.com.",
    "originSummary": [
      "Families are suing UnitedHealth Group, alleging that the use of AI resulted in denial or shortened rehabilitation stays for elderly patients, leading to harm and death.",
      "The lawsuit claims that the AI program made \"rigid and unrealistic\" decisions about patients' recovery, denying them necessary care.",
      "UnitedHealth denies the allegations, stating that the AI tool is only used as a guide and that decisions are ultimately made by providers and caregivers."
    ],
    "commentBody": "",
    "commentSummary": [],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1700403328211
  },
  {
    "title": "Top LLM Text AI Tools Revolutionizing the Legal Field",
    "originLink": "https://medium.com/@eliashaider/top-5-llm-text-ai-tools-in-the-world-free-paid-be8ee0bc7060",
    "originBody": "Top 5 LLM Text AI Tools in The World — (Free & Paid) Elias Haider · Follow 15 min read · 2 hours ago -- In today’s digital age, the demand for efficient and accurate language processing tools is on the rise. When it comes to the legal field, having access to the best large language models (LLMs) can significantly enhance productivity and streamline legal research. Top 5 LLM Text AI Tools in The World With the growing prominence of LLMs, a plethora of AI-powered text tools has emerged, each offering unique features and functionalities. Navigating this diverse landscape can be challenging, making it crucial to identify the most effective and versatile tools. In this article, we will explore the top 5 LLM text AI tools in the world, revolutionizing the way legal professionals analyze and understand complex legal texts. Let’s dive into the world of cutting-edge technology and discover how these tools can revolutionize the legal landscape. What is LLM Text AI Tools LLM text AI tools are software applications that harness the power of large language models to perform a wide range of tasks related to text and language. These tools empower users to generate creative content, translate languages, summarize complex information, and even engage in insightful conversations. Revealing The Core of (LLM) Large Language Model Text AI Tools LLM text AI tools are software applications that harness the power of large language models to perform a wide range of tasks related to text and language. These tools empower users to generate creative content, translate languages, summarize complex information, and even engage in insightful conversations. A Wide Range of Applications The diverse applications of LLM text AI tools span across various industries and fields, including: Content Creation: Generate engaging blog posts, captivating social media content, and compelling marketing materials. Translation: Seamlessly translate documents, emails, and websites into multiple languages, breaking down language barriers. Summarization: Condense lengthy texts into concise summaries, extracting key information and saving valuable time. Chatbots and Virtual Assistants: Power intelligent chatbots and virtual assistants that provide customer support, answer questions, and engage in natural conversations. A Catalyst for Innovation LLM text AI tools serve as a driving force behind innovation, enabling businesses to: Enhance Productivity: Automate routine tasks related to text processing, freeing up employees’ time for more strategic endeavors. Expand Reach: Cater to a global audience by effortlessly translating content and reaching new markets. Personalize Customer Experiences: Create personalized content and recommendations based on individual preferences, fostering stronger customer relationships. Top 5 Free AI Video Generator Without Watermark Online for Faceless Video Discover the top 5 free AI video generator without watermark in online for creating engaging faceless videos without a… eliashaider.medium.com As LLM technology continues to evolve, its impact on the world of text and language is bound to grow exponentially, shaping the way we communicate, learn, and work. LLM text AI tools stand at the forefront of this transformation, empowering individuals and organizations to harness the power of language in ways never before imagined. Importance of LLM Text AI Tools The importance of LLM text AI tools cannot be overstated. In a field where precision and comprehensive analysis are paramount, these tools provide a significant advantage. By leveraging natural language processing and machine learning algorithms, LLM text AI tools can efficiently analyze vast amounts of legal data, statutes, case law, and other legal texts. They can extract key information, identify relevant passages, and generate summaries, saving legal professionals valuable time and effort. Benefits of LLM Text AI Tools: Empowering Efficiency, Creativity, and Innovation In the ever-evolving landscape of technology, Large Language Model (LLM) Text AI Tools have emerged as game-changers, revolutionizing the way we interact with and utilize human language. These sophisticated tools, powered by the remarkable capabilities of LLMs, offer a plethora of benefits that are transforming various industries and aspects of our lives. Photo by Andrea De Santis on Unsplash 1. Enhanced Productivity and Efficiency LLM Text AI Tools empower individuals and businesses to streamline workflows, automate tasks, and enhance productivity. By leveraging their ability to analyze, summarize, and generate text, these tools can significantly reduce manual effort and free up time for more strategic activities. 2. Creative Content Generation LLM Text AI Tools have opened up new frontiers in creative content generation, enabling individuals and businesses to produce high-quality, engaging content with ease. From generating captivating marketing copy to crafting compelling scripts, these tools provide a powerful platform for storytelling and communication. 3. Deeper Insights from Text Data LLM Text AI Tools enable organizations to extract valuable insights from vast amounts of text data, providing a competitive edge in decision-making and strategic planning. By analyzing customer reviews, social media conversations, and market research reports, these tools can uncover hidden patterns and trends that inform effective strategies. 4. Personalized Customer Interactions LLM Text AI Tools are transforming customer interactions, enabling businesses to provide personalized and engaging experiences. Chatbots powered by these tools can converse with customers in natural language, answering questions, resolving issues, and providing product recommendations. 5. Language Translation and Localization LLM Text AI Tools are breaking down language barriers, enabling seamless communication across cultures. These tools can accurately translate documents, websites, and other forms of text, facilitating global collaboration and expanding market reach. The benefits of LLM Text AI Tools extend far beyond these examples, as their potential continues to expand. As these tools become more sophisticated and accessible, they will undoubtedly play an increasingly transformative role in shaping the future of communication, creativity, and innovation. How Can I Use Blockchain in My Business — A Complete Guide If you’ve been asking yourself, “How can I use blockchain in my business?” then you’ve come to the right place… eliashaider.medium.com 1. ChatGPT: Empowering Legal Professionals with Generative Language Models ChatGPT is a remarkable generative language model that has transformed the way legal professionals interact with AI-driven tools. With its advanced natural language processing capabilities, ChatGPT enables legal practitioners to engage in dynamic conversations with the model, obtaining accurate and contextually relevant responses. This sub-heading explores the key features and benefits of ChatGPT, showcasing how it empowers legal professionals in their day-to-day tasks. Photo by ilgmyzin on Unsplash 1. Advanced Language Processing ChatGPT’s advanced language processing capabilities make it a valuable tool for legal professionals seeking assistance in legal research and analysis. By understanding the intricacies of legal texts, ChatGPT can provide insightful responses to legal queries, helping legal practitioners find relevant information swiftly. Its ability to comprehend complex legal concepts and generate coherent responses contributes to its effectiveness in assisting legal professionals in their tasks. 2. Interactive Legal Research One of the notable advantages of ChatGPT is its interactive nature. Legal professionals can engage in dynamic conversations with the model, gaining access to valuable insights and suggestions. ChatGPT can assist in legal research by providing case law references, analyzing legal documents, and offering alternative perspectives on legal issues. This interactive approach allows legal practitioners to refine their research process and explore various angles of legal analysis. 3. Enhanced Legal Drafting ChatGPT’s generative language capabilities make it a valuable tool for legal drafting. By providing prompts and context, legal professionals can leverage ChatGPT to generate draft documents, contracts, or legal opinions. The model’s ability to generate coherent and contextually appropriate responses saves time and effort in the drafting process. Legal practitioners can refine and customize the generated content to align with their specific requirements, streamlining the overall drafting workflow. ChatGPT’s integration of generative language models into the legal domain has opened up new possibilities for legal professionals. With its advanced language processing, interactive research capabilities, and enhanced drafting support, ChatGPT has become a go-to tool for legal practitioners seeking efficient and reliable AI-driven assistance. By leveraging the power of generative language models like ChatGPT, legal professionals can enhance their productivity, accuracy, and overall effectiveness in handling complex legal tasks. 2. Google Bard: Harnessing the Power of the Best Large Language Models Google Bard is a cutting-edge tool that harnesses the power of the best large language models to revolutionize legal research and analysis. With its vast database of legal documents, statutes, and case law, Google Bard provides legal professionals with a comprehensive resource at their fingertips. This sub-heading explores the key features and benefits of Google Bard, showcasing how it empowers legal professionals in their quest for accurate and efficient legal information. Photo by Mojahid Mottakin on Unsplash 1. Vast Legal Database At the core of Google Bard is an extensive legal database that encompasses a wide range of legal texts. This vast collection of legal documents, statutes, and case law serves as a treasure trove of information for legal professionals. By leveraging the best large language models, Google Bard can efficiently search and retrieve relevant legal information, saving legal practitioners valuable time in their research process. This comprehensive legal database ensures that legal professionals have access to the most up-to-date and authoritative legal sources. 2. Advanced Search Capabilities Google Bard’s advanced search capabilities are a game-changer for legal professionals. The tool allows users to perform complex searches using keywords, phrases, or even natural language queries. By utilizing the best large language models, Google Bard can understand the nuances of legal language and deliver precise search results. Its ability to identify relevant passages and provide contextual snippets enables legal professionals to quickly navigate through vast amounts of legal information and pinpoint the most pertinent sections for their research or analysis. 3. AI-Driven Analysis Another notable advantage of Google Bard is its AI-driven analysis capabilities. By leveraging the power of the best large language models, the tool can provide advanced insights and analysis on legal texts. Legal professionals can gain a deeper understanding of complex legal concepts, identify patterns, and uncover connections between different legal documents. Google Bard’s AI-driven analysis empowers legal practitioners to conduct thorough and comprehensive research, ensuring that they have a holistic view of the legal landscape. Google Bard’s integration of the best large language models into its platform has transformed the way legal professionals approach legal research and analysis. With its vast legal database, advanced search capabilities, and AI-driven analysis, Google Bard provides legal practitioners with a powerful tool to navigate the complexities of the legal field. By harnessing the power of the best large language models, Google Bard enhances the efficiency, accuracy, and effectiveness of legal research, empowering legal professionals to make well-informed decisions. Google Bard is Killing ChatGPT Day by Day Believe or Not! Learn why and how Google Bard is killing ChatGPT day by day! check out in details in the article… eliashaider.medium.com 3. Bing Chat: Leveraging the Power of the Best Large Language Models Bing Chat is a versatile tool that leverages the power of the best language models to provide efficient and reliable assistance to legal professionals. With its chat-based interface, Bing Chat offers an interactive experience for legal practitioners seeking answers to legal queries, case law references, or access to legal research materials. This sub-heading explores the key features and benefits of Bing Chat, showcasing how it empowers legal professionals in their day-to-day tasks. Photo by Rubaitul Azad on Unsplash 1. Interactive Conversations One of the standout features of Bing Chat is its interactive nature. Legal professionals can engage in dynamic conversations with the tool, obtaining accurate and contextually relevant responses. By utilizing the best large language models, Bing Chat can understand the intricacies of legal language and provide informative answers to legal queries. This interactive approach allows legal practitioners to have a conversation-like experience while seeking legal information, enhancing their efficiency and productivity. 2. Swift Information Retrieval Bing Chat’s ability to swiftly retrieve legal information makes it a valuable tool for legal professionals. By leveraging the power of the best large language models, Bing Chat can efficiently search through vast amounts of legal data, statutes, case law, and other legal texts. Its advanced search capabilities ensure that legal practitioners can quickly find the information they need, saving them valuable time and effort in their research process. Bing Chat’s swift information retrieval ensures that legal professionals have access to up-to-date and relevant legal resources. 3. Reliable Legal Research Bing Chat’s integration of the best large language models makes it a reliable tool for legal research. Legal professionals can rely on Bing Chat to provide accurate case law references, assist in legal analysis, and offer suggestions for legal drafting. By leveraging the extensive knowledge and language comprehension abilities of the best large language models, Bing Chat ensures that legal practitioners have access to reliable and insightful legal information. This enhances the quality and depth of their research, enabling them to make well-informed decisions. Bing Chat’s utilization of the best language models has transformed the way legal professionals seek legal information and assistance. With its interactive conversations, swift information retrieval, and reliable legal research capabilities, Bing Chat empowers legal practitioners to streamline their research process and enhance their overall productivity. By harnessing the power of the best large language models, Bing Chat provides legal professionals with a valuable tool to navigate the complexities of the legal field. 4. Meta: Unleashing the Potential of Generative Language Models Meta is an innovative tool that unleashes the potential of generative language models to revolutionize legal research and analysis. With its state-of-the-art algorithms, Meta provides legal professionals with a comprehensive platform for legal research and analysis. This sub-heading explores the key features and benefits of Meta, showcasing how it empowers legal professionals in their quest for accurate and efficient legal information. Photo by Dima Solomin on Unsplash 1. Advanced Data Analysis Meta’s advanced data analysis capabilities make it a standout tool for legal professionals. By leveraging generative language models, Meta can sift through vast amounts of legal data, extract relevant information, and generate insightful summaries. Legal practitioners can gain a deeper understanding of complex legal concepts, identify key patterns, and uncover connections between different legal texts. Meta’s advanced data analysis empowers legal professionals to conduct thorough and comprehensive research, ensuring a holistic perspective. 2. Streamlined Document Navigation One of the notable advantages of Meta is its ability to streamline document navigation. Legal professionals can seamlessly navigate through legal documents, statutes, and case law by utilizing Meta’s intuitive interface and powerful search capabilities. The tool’s integration of generative language models allows for precise search results, ensuring that legal practitioners can quickly locate relevant passages and information within legal texts. Meta’s streamlined document navigation saves time and effort, enhancing the overall efficiency of legal research. 3. Enhanced Decision-Making Meta’s integration of generative language models enhances the decision-making process for legal professionals. By providing comprehensive analysis and insights, Meta enables legal practitioners to make well-informed decisions based on a thorough understanding of the legal landscape. Legal professionals can rely on Meta’s generative language capabilities to generate alternative legal arguments, explore different perspectives, and assess potential outcomes. This enhanced decision-making support allows legal practitioners to navigate complex legal scenarios with confidence. Meta’s integration of generative language models into its platform has transformed the way legal professionals approach legal research and analysis. With its advanced data analysis, streamlined document navigation, and enhanced decision-making capabilities, Meta provides legal practitioners with a powerful tool to navigate the complexities of the legal field. By harnessing the power of generative language models, Meta enhances the efficiency, accuracy, and effectiveness of legal research, empowering legal professionals to make well-informed decisions. Top 7 Emerging Technologies to Watch in 2024 Discover the top 7 emerging technologies set to revolutionize the world in 2024. Stay ahead of the curve with these… eliashaider.medium.com 5. Claude: The Epitome of the Best LLM Text AI Tools in the World Claude stands out as one of the best LLM text AI tools in the world, offering unparalleled capabilities to legal professionals. With its advanced natural language processing and machine learning algorithms, Claude has revolutionized the way legal research and analysis is conducted. This sub-heading explores the key features and benefits of Claude, showcasing how it has earned its reputation as one of the best LLM text AI tools in the world. Claude 1. Superior Language Comprehension Claude’s superior language comprehension abilities make it a standout LLM text AI tool. By leveraging the power of advanced machine learning algorithms, Claude can understand the nuances of legal language, including complex legal concepts and terminology. This enables legal professionals to input queries or legal texts into Claude and receive accurate and contextually relevant responses. Claude’s ability to comprehend legal texts at a high level contributes to its effectiveness in assisting legal practitioners in their research and analysis tasks. 2. Efficient Legal Research One of the notable advantages of Claude is its ability to streamline legal research. Legal professionals can input keywords, phrases, or even natural language queries into Claude, and the tool will swiftly retrieve relevant legal information from its vast database. Claude’s advanced algorithms ensure accurate search results, saving legal practitioners valuable time and effort in their research process. By providing efficient access to legal materials, Claude enhances the productivity and effectiveness of legal research. 3. Powerful Legal Analysis Claude’s powerful legal analysis capabilities set it apart as one of the best LLM text AI tools in the world. By leveraging its advanced machine learning algorithms, Claude can analyze legal texts, statutes, and case law to provide insightful analysis and summaries. Legal professionals can rely on Claude to identify key legal principles, evaluate legal arguments, and generate comprehensive legal opinions. Claude’s powerful legal analysis supports legal practitioners in making informed decisions and strengthens their overall legal strategy. Claude has earned its reputation as one of the best LLM text AI tools in the world due to its superior language comprehension, efficient legal research capabilities, and powerful legal analysis features. By leveraging the power of advanced machine learning algorithms, Claude empowers legal professionals to enhance their productivity, accuracy, and overall effectiveness in handling complex legal tasks. With Claude as their tool of choice, legal practitioners can navigate the intricacies of legal research and analysis with confidence. Comparison and Evaluation: Assessing the Best Language Models When it comes to assessing the best language models, a thorough comparison and evaluation process is crucial. This helps in determining the most effective and reliable language models for specific tasks. This sub-heading explores the key aspects to consider during the comparison and evaluation of language models, highlighting the importance of selecting the best models for optimal results. how Large Language Models Work 1. Performance and Accuracy Performance and accuracy are critical factors when comparing and evaluating language models. The best language models should demonstrate high levels of accuracy, ensuring that they can understand and generate language with precision. Models that accurately capture the nuances of human language and provide accurate responses are highly valuable for various applications. Evaluating the performance and accuracy of language models through benchmarking against relevant datasets and tasks helps in identifying the top performers. 2. Language Comprehension and Context Language comprehension and context are crucial aspects to consider during the comparison and evaluation of language models. The best language models should have a deep understanding of language, including the ability to comprehend complex sentence structures, idiomatic expressions, and domain-specific terminology. Evaluating how well a language model can interpret and generate contextually relevant responses is vital to determine its effectiveness in various applications. Models that excel in understanding and generating coherent and contextually appropriate language are usually preferred. 3. Training Data and Generalization The training data utilized by language models and their ability to generalize are essential evaluation factors. The best language models should be trained on diverse and extensive datasets, enabling them to learn a wide range of linguistic patterns and concepts. Models that can generalize well to unseen or out-of-domain data are highly desirable. Evaluating a language model’s ability to generalize beyond its training data helps in assessing its versatility and robustness in real-world applications. Comparison and evaluation play a pivotal role in identifying the best language models for specific tasks. By considering factors such as performance and accuracy, language comprehension and context, and training data and generalization, one can make informed decisions about which models are most suitable. Assessing the strengths and limitations of different language models allows for the selection of the most effective and reliable options, ensuring optimal outcomes in various language processing applications. Top 10 Highly Demand Trendy AI Technology You Should Learn for 2024 Discover the top 10 in-demand and trendy AI technologies revolutionizing industries. Explore the future of artificial… eliashaider.medium.com Conclusion: Embracing the Best LLM Text AI Tools in the World The availability of the best LLM text AI tools in the world has revolutionized the legal profession, empowering legal professionals to enhance their research, analysis, and decision-making processes. These tools, with their advanced natural language processing and machine learning capabilities, have become invaluable assets for legal practitioners. By incorporating the best LLM text AI tools into their workflows, legal professionals can unlock new levels of efficiency, accuracy, and productivity. The best LLM text AI tools in the world offer superior language comprehension, enabling them to understand complex legal concepts, terminologies, and statutes. This comprehension allows for precise and contextually relevant responses, ensuring that legal practitioners receive accurate information and analysis. With these tools, legal professionals can conduct efficient legal research, swiftly retrieving relevant legal information from extensive databases. The speed and accuracy of these tools streamline the research process, saving valuable time and effort for legal practitioners. Moreover, the best LLM text AI tools provide powerful legal analysis capabilities. By analyzing legal texts, statutes, and case law, these tools can generate comprehensive insights and summaries, assisting legal professionals in their decision-making processes. The ability to evaluate legal arguments, identify key legal principles, and generate alternative legal opinions contributes to more informed and well-rounded legal strategies. In embracing the best LLM text AI tools in the world, legal professionals position themselves at the forefront of technological advancements in the legal field. These tools empower legal practitioners to navigate the complexities of legal research and analysis with confidence, enhancing their overall effectiveness and enabling them to deliver exceptional results. By harnessing the power of AI-driven tools, legal professionals can embrace a future where technology and human expertise work hand in hand to redefine the practice of law.",
    "originSummary": [
      "LLM text AI tools in the legal field, such as ChatGPT and Google Bard, revolutionize the legal profession by enhancing productivity and improving research and analysis processes.",
      "AI-powered tools like chatbots and language translation tools are highlighted for improving customer communication and breaking down language barriers.",
      "Bing Chat, Meta, and Claude are discussed as AI tools that empower legal professionals in their research and decision-making processes, providing comprehensive insights and helping make informed decisions."
    ],
    "commentBody": "",
    "commentSummary": [],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1700403328211
  },
  {
    "title": "Artists Demand US Copyright Reforms on AI, Tech Industry Pushes Back",
    "originLink": "https://www.voanews.com/a/artists-push-for-us-copyright-reforms-on-ai-but-tech-industry-says-not-so-fast-/7361182.html",
    "originBody": "Accessibility links Skip to main content Skip to main Navigation Skip to Search Next Close Previous Next Print Options: Images Multimedia Embedded Content Comments Cancel Print Link has been copied to clipboard Home United States U.S. News All About America Silicon Valley & Technology Immigration World Africa The Americas East Asia Europe Middle East South & Central Asia Ukraine Press Freedom COVID-19 Pandemic China Iran Broadcast Programs Follow Us Languages Search Search Previous Next Breaking News Technology Artists Push for US Copyright Reforms on AI, But Tech Industry Says Not So Fast November 18, 2023 8:01 PM Associated Press FILE - Actor and filmmaker Justine Bateman, right, speaks outside Netflix during a Writers Guild rally on July 13, 2023, in Los Angeles. Share Print Country singers, romance novelists, video game artists and voice actors are appealing to the U.S. government for relief — as soon as possible — from the threat that artificial intelligence poses to their livelihoods. \"Please regulate AI. I'm scared,\" wrote a podcaster concerned about his voice being replicated by AI in one of thousands of letters recently submitted to the U.S. Copyright Office. Technology companies, by contrast, are largely happy with the status quo that has enabled them to gobble up published works to make their AI systems better at mimicking what humans do. The nation's top copyright official hasn't yet taken sides. She told The Associated Press she's listening to everyone as her office weighs whether copyright reforms are needed for a new era of generative AI tools that can spit out compelling imagery, music, video and passages of text. \"We've received close to 10,000 comments,\" said Shira Perlmutter, the U.S. register of copyrights, in an interview. \"Every one of them is being read by a human being, not a computer. And I myself am reading a large part of them.\" What's at stake? Perlmutter directs the U.S. Copyright Office, which registered more than 480,000 copyrights last year covering millions of individual works but is increasingly being asked to register works that are AI-generated. So far, copyright claims for fully machine-generated content have been soundly rejected because copyright laws are designed to protect works of human authorship. But, Perlmutter asks, as humans feed content into AI systems and give instructions to influence what comes out, \"is there a point at which there's enough human involvement in controlling the expressive elements of the output that the human can be considered to have contributed authorship?\" That's one question the Copyright Office has put to the public. A bigger one — the question that's fielded thousands of comments from creative professions — is what to do about copyrighted human works that are being pulled from the internet and other sources and ingested to train AI systems, often without permission or compensation. More than 9,700 comments were sent to the Copyright Office, part of the Library of Congress, before an initial comment period closed in late October. Another round of comments is due by December 6. After that, Perlmutter's office will work to advise Congress and others on whether reforms are needed. What are artists saying? Addressing the \"Ladies and Gentlemen of the US Copyright Office,\" the Family Ties actor and filmmaker Justine Bateman said she was disturbed that AI models were \"ingesting 100 years of film\" and TV in a way that could destroy the structure of the film business and replace large portions of its labor pipeline. It \"appears to many of us to be the largest copyright violation in the history of the United States,\" Bateman wrote. \"I sincerely hope you can stop this practice of thievery.\" Airing some of the same AI concerns that fueled this year's Hollywood strikes, television showrunner Lilla Zuckerman (Poker Face) said her industry should declare war on what is \"nothing more than a plagiarism machine\" before Hollywood is \"coopted by greedy and craven companies who want to take human talent out of entertainment.\" The music industry is also threatened, said Nashville-based country songwriter Marc Beeson, who's written tunes for Carrie Underwood and Garth Brooks. Beeson said AI has potential to do good but \"in some ways, it's like a gun — in the wrong hands, with no parameters in place for its use, it could do irreparable damage to one of the last true American art forms.\" While most commenters were individuals, their concerns were echoed by big music publishers — Universal Music Group called the way AI is trained \"ravenous and poorly controlled\" — as well as author groups and news organizations including The New York Times and The Associated Press. Is it fair use? What leading tech companies like Google, Microsoft and ChatGPT-maker OpenAI are telling the Copyright Office is that their training of AI models fits into the \"fair use\" doctrine that allows for limited uses of copyrighted materials such as for teaching, research or transforming the copyrighted work into something different. \"The American AI industry is built in part on the understanding that the Copyright Act does not proscribe the use of copyrighted material to train Generative AI models,\" says a letter from Meta Platforms, the parent company of Facebook, Instagram and WhatsApp. The purpose of AI training is to identify patterns \"across a broad body of content,\" not to \"extract or reproduce\" individual works, it added. So far, courts have largely sided with tech companies in interpreting how copyright laws should treat AI systems. In a defeat for visual artists, a federal judge in San Francisco last month dismissed much of the first big lawsuit against AI image-generators, though allowed some of the case to proceed. Most tech companies cite as precedent Google's success in beating back legal challenges to its online book library. The U.S. Supreme Court in 2016 let stand lower court rulings that rejected authors' claim that Google's digitizing of millions of books and showing snippets of them to the public amounted to copyright infringement. But that's a flawed comparison, argued former law professor and bestselling romance author Heidi Bond, who writes under the pen name Courtney Milan. Bond said she agrees that \"fair use encompasses the right to learn from books,\" but Google Books obtained legitimate copies held by libraries and institutions, whereas many AI developers are scraping works of writing through \"outright piracy.\" Perlmutter said this is what the Copyright Office is trying to help sort out. \"Certainly, this differs in some respects from the Google situation,\" Perlmutter said. \"Whether it differs enough to rule out the fair use defense is the question in hand.\" Related Hollywood Actors Offered Protections Against AI in Labor Deal AI Experts Weigh in on Biden’s Executive Order Biden Cites Moves on Fentanyl, AI and Military Communications After Xi Meeting World Leaders Agree on Artificial Intelligence Risks More Science & Health News Artists Push for US Copyright Reforms on AI, But Tech Industry Says Not So Fast Advertisers Flee Elon Musk's X Amid Concerns of Antisemitism Backlash SpaceX Starship Launch Fails Minutes After Reaching Space US Approves SpaceX for 2nd Launch of Starship Super Heavy Nickel Miners, Environmentalists Learn to Live Together in Michigan The Day in Photos November 17, 2023 Recommended 52 Documentary Back to top Follow Us United States US News Immigration All About America Silicon Valley & Technology World Africa The Americas East Asia Pacific Europe Middle East South & Central Asia Sections VOA Programs Special projects Day in Photos Press Freedom Refugees VOA News on Iran VOA News on China Arts & Culture Economy & Business Health Extremism Watch Student Union VOA Connect 52 Documentary Videos More From VOA VOAAfrica.com Programs VOA Learning English Polygraph.info Editorials Satellite schedule About this site Terms of Use & Privacy Notice About VOA Get VOA+ VOA Around the World Contact VOA Media Relations Usage Requests VOA Pronunciation Guide XS SM MD LG",
    "originSummary": [
      "Artists from various creative industries are calling for government regulation of artificial intelligence (AI) to protect their livelihoods.",
      "Concerns include unauthorized replication of their work by AI systems and the use of copyrighted human works to train AI models.",
      "Technology companies argue that the current status quo allows for AI system improvement through the use of published works."
    ],
    "commentBody": "",
    "commentSummary": [],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1700403328211
  },
  {
    "title": "Disney Asks Microsoft to Stop AI Users from Infringing Trademarks",
    "originLink": "https://www.cartoonbrew.com/law/report-disney-asks-microsoft-to-prevent-ai-users-from-infringing-its-trademarks-235039.html",
    "originBody": "LawTech Report: Disney Asked Microsoft To Prevent AI Users From Infringing Its Trademarks By Amid Amidi11/18/2023 12:02 pmBe the First to Comment! Share Tweet Email 0 Tributes and parodies of Pixar-style characters generated by Microsoft’s Bing AI imaging tool have drawn the attention of The Walt Disney Company’s legal counsel. The concern stems over a recent social media trend in which people prompted images of pets in a “Pixar” style. The issue though wasn’t the artwork itself, but rather Bing’s generation of a trademark-infringing Disney-Pixar logo. The Financial Times reported that Disney requested Microsoft to prevent its users from infringing on trademarks. In response, the tech giant blocked the term “Disney” from its image generator, which is powered by DALL-E 3 technology. After tweaks, Microsoft has restored the prompt. According to the FT report, Microsoft’s AI-generated images are still pumping out a jumbled version of the Disney-Pixar logo, and it remains unclear whether this new version has adequately addressed Disney’s concerns. Microsoft told FT: There is a current level of variability that may return different results from time to time as we continue to refine our safety systems . . . Additionally, artists, celebrities, and organizations can request to limit the creation of images associated with their names and brands. More concerning for Disney is the “Offensive AI Pixar” meme, in which Microsoft Bing users create offensive film ideas in a generic cg style that many people associate with Pixar films. This trend is much more difficult to shut down because it’s a near certainty that Bing Image Creator has already been trained on copyrighted Disney and Pixar artwork. Further complicating the matter, the text and Disney-Pixar logos for this meme are being physically inserted by users after the central image has already been generated. Offensive Disney and Pixar parodies have always lurked in the corners of the internet, but AI tech has made it so anyone can generate such pieces in mere seconds, no skill required. The proliferation of such material will only grow as AI systems engage in widespread theft of intellectual property belonging to others, and no immediate solution is on the horizon for how Disney (or anyone else) can put a stop to the misuse of their trademarks. Share Tweet Email 0 Read More: Artificial intelligence Microsoft Pixar The Walt Disney Company Amid Amidi More Articles Amid Amidi is Cartoon Brew's Publisher and Editor-at-large. MORE IN LAW: Congressman Joaquin Castro Calls For Investigation Into WBD’s Handling Of ‘Coyote Vs. Acme’ NFT-Financed Animated Series ‘Stoner Cats,’ Co-Created By Pixar Vet Ash Brannon, Fined $1M By SEC ‘Rick And Morty’ Creator Justin Roiland Accused Of Sexual Assault, Grooming, Providing Alcohol To Minors In New Report Suspect Admits Starting Fire That Killed 36 People In 2019 Kyoto Animation Arson Attack Sponsored Stories from Cartoon Brew Sponsored by Reallusion Reallusion Pitch & Produce: Creating A 2D Animated Series Pilot With Cartoon Animator 5 By Cartoon Brew Connect1 month ago Sponsored by Praxinos Praxinos Is Looking For Beta Testers For Its Unreal Engine Animation Software, Odyssey By Cartoon Brew Connect5 months ago Sponsored by SCAD Get Ready For SCADFILM’s AnimationFest 2023 By Cartoon Brew Connect2 months ago Latest News from Cartoon Brew Box Office Report A Deep Dive Into The 10 Highest-Grossing Animated Features Of 2023 (So Far) By Jamie Lang2 days ago Series Seth MacFarlane’s ‘Ted’ Spinoff Series Gets Trailer And Release Date By Jamie Lang2 days ago Feature Film ‘Trolls Band Together’ Reviews Roundup: Vibrant And Colorful Animation Are Fun Enough, But The Sequel’s Plot Is Thin By Jamie Lang2 days ago Artist Rights It’s Official, DNEG Vancouver Has Unionized After Labor Board Confirmation (Exclusive) By Jamie Lang2 days ago Feature Film Bob Iger Says Fourth ‘Frozen’ Film Is Already In The Works By Jamie Lang3 days ago Cartoon Brew Pick The Horror And Glory Of Human History Told In Five Minutes In Theo W. Scott’s ‘Cuties’ By Jamie Lang3 days ago Feature Film I Saw ‘Coyote Vs. Acme’ And It’s As Wonderful As Everyone Says It Is By Amid Amidi4 days ago Feature Film ‘Baby Shark’s Big Movie’ Gets New Trailer Ahead Of December 8 Debut By Jamie Lang4 days ago Animators Warner Music Will Use AI To Recreate Édith Piaf’s Voice And Image In New Animated Biopic By Jamie Lang4 days ago Feature Film Congressman Joaquin Castro Calls For Investigation Into WBD’s Handling Of ‘Coyote Vs. Acme’ By Jamie Lang4 days ago Feature Film Hear Zachary Levi’s Take On Rocky In New ‘Dawn Of The Nugget’ Trailer By Jamie Lang4 days ago Feature Film Watch The Trailer For Prime Video’s ‘Merry Little Batman’ By Jamie Lang5 days ago Share Tweet Email 0",
    "originSummary": [
      "Disney has requested that Microsoft take action to prevent users of its Bing AI imaging tool from infringing on its trademarks.",
      "The concern stems from a social media trend where people generated images of pets in a \"Pixar\" style, leading to the creation of a trademark-infringing Disney-Pixar logo by Bing's image generator.",
      "Microsoft has blocked the term \"Disney\" from the image generator, but a modified version of the logo is still being produced. Offensive AI Pixar memes are also causing concern as users create offensive film ideas using copyrighted Disney and Pixar artwork.",
      "The misuse of trademarks through AI technology presents a challenge for Disney and other companies to address."
    ],
    "commentBody": "",
    "commentSummary": [],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1700403328211
  },
  {
    "title": "Federal Prosecutor Seeks Takeover of Rikers Island Amid Ongoing Violence and Rights Violations",
    "originLink": "https://www.nytimes.com/2023/11/18/nyregion/rikers-island-federal-takeover.html",
    "originBody": "ADVERTISEMENT SKIP ADVERTISEMENT Federal Prosecutor Asks Judge to Strip New York of Control Over Rikers Manhattan’s top federal prosecutor joined the Legal Aid Society and other lawyers representing people detained in the jail complex in calling for a takeover. Share full article The administration of Mayor Eric Adams of New York has faced mounting pressure over dangerous and chaotic conditions at Rikers Island. Credit... Ed Jones/Agence France-Presse — Getty Images By Hurubie Meko Nov. 18, 2023 The federal government on Friday formally joined an effort to strip Mayor Eric Adams’s administration of control over Rikers Island, asking a judge to hand oversight of the troubled jail complex to an outside authority. Joining lawyers who represent people detained in New York City jails, Manhattan’s top federal prosecutor, Damian Williams, wrote in a court filing that the appointment of an outside authority, known as a receiver, was the only solution to the persistent violence and chaos at Rikers. Mr. Williams, the U.S. attorney for the Southern District of New York, had previously called for a takeover in July. The day after that statement, the judge who will decide on a takeover, Laura Taylor Swain of Federal District Court, wrote that the Adams administration had failed to “address the dangerous conditions that perpetually plague the jails.” In August, she set a schedule for federal prosecutors and detainees’ lawyers to argue in favor of receivership; Friday’s filings were the first step in that lengthy process. The Department of Justice has sought this kind of remedy in “only a handful of corrections cases and under exceptional circumstances,” Mr. Williams wrote on Friday, adding that the city under two mayors and four correction commissioners had been “unable or unwilling” to make reforms that would reduce violence and “remedy the ongoing violation of the constitutional rights of people in custody.” The parties also asked that Judge Swain hold the city in contempt for violating a 2015 agreement that required it to make sweeping reforms. A spokesman for the city’s Law Department, Nick Paolucci, said on Saturday that the administration had made progress to address longstanding problems at Rikers and that receivership was not the solution to fix the jail system. The filings from Mr. Williams, in addition to those from the Legal Aid Society and a private law firm that represents people detained at Rikers, come as the city faces mounting pressure to show improvements in jail conditions, and weeks after the administration announced that the embattled jails commissioner, Louis A. Molina, would leave his post by mid-November and become the assistant deputy mayor for public safety. Mr. Adams has not named a successor. That receivership is on the table “reflects the enormity of the challenges that persist in the city jails,” said Hernandez D. Stroud, counsel in the Justice Program of the Brennan Center for Justice at New York University School of Law. The city will have a chance to respond to the filings, and then the plaintiffs will have another opportunity to answer, he said, adding that it could be well into next year before Judge Swain makes a determination on the question of receivership. To date, the city has failed to grasp the “urgency and severity” of the crisis it has created, said Mary Lynne Werlwas, director of the Prisoners’ Rights Project at the Legal Aid Society. “A receiver is necessary now because there’s nothing more the court can do to compel the city to operate the jails within constitutional bounds,” she said. Watchdogs and prisoners’ rights advocates have also criticized Mr. Adams’s administration for what they say are attempts to roll back efforts at transparency by past administrations. Under Mr. Molina’s tenure, the Correction Department has limited the public release of potentially damaging information, revoking a jails oversight panel’s unrestricted access to video footage from Rikers Island (it later restored the access) and reversing an earlier policy of notifying the public when deaths occur in custody. As of last month, nine people have died this year in New York City jails. Nineteen died last year. A federal monitor appointed to oversee the jails as part of the 2015 agreement has pointed to episodes that he said showed persistent dysfunction and dangers at the island complex in recent months, many of which he said correction officials had not mentioned to him and in some cases had hidden. The monitor, Steve J. Martin, wrote in a report earlier this month that instead of making incremental progress, the department was demonstrating “sustained and chronic institutional resistance and recalcitrance toward court-ordered reform.” Throughout his recent reports, Mr. Martin has stressed that the conditions in the jails and the risk of harm, for both detainees and correction officers, have not been improving. In May, Mr. Martin described five “serious and disturbing” incidents over a two-week period that he said jail staff and leadership had failed to report, including the deaths of two people in custody. One detainee, Carlton James, was severely injured after being tackled by correction officers on May 11. Mr. James was tackled twice in one day, once while he was “rear-cuffed and in leg shackles,” according to the monitor, and was taken to the hospital, where he underwent multiple surgeries. Mr. Martin said his team was not aware of the severity of his condition until May 24, after an article by The City included a statement from the Correction Department. In a declaration submitted with the filings on Friday, Mr. James said that he was paralyzed from the neck down and remained in the hospital. Share full article ADVERTISEMENT SKIP ADVERTISEMENT",
    "originSummary": [
      "The federal government and lawyers representing detainees are calling for control of Rikers Island to be taken away from Mayor Eric Adams's administration due to dangerous and chaotic conditions.",
      "Manhattan's top federal prosecutor, Damian Williams, has filed a court document stating that appointing an outside authority to oversee the jail complex, known as a receiver, is the only solution to the ongoing violence and constitutional rights violations.",
      "The Department of Justice has rarely sought this remedy in corrections cases, highlighting the seriousness of the situation."
    ],
    "commentBody": "",
    "commentSummary": [],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1700403328211
  },
  {
    "title": "Concerns over Altman's Departure Could Impact AI Governance",
    "originLink": "https://www.forbes.com/sites/michaelperegrine/2023/11/18/sam-altmans-departure-and-board-oversight-of-artificial-intelligence/",
    "originBody": "FORBESLEADERSHIPLEADERSHIP STRATEGY Sam Altman’s ‘Departure’ And Board Oversight Of Artificial Intelligence Michael Peregrine Senior Contributor Nov 18, 2023,12:12pm EST Sam Altman’s “departure” as CEO is a brake-tapper event for board monitoring of AI development. GETTY IMAGES Let’s get this straight. The CEO of one the leading companies behind artificial intelligence-the technology for which trustworthiness is a major concern-is basically fired by his board, essentially for being untrustworthy. Note to file: not a good thing. The backstory: On Friday, November 17 the Board of Directors of OpenAI, the prominent developer of ChatGPT, shocked the technology sector with its termination of CEO Sam Altman, a leading figure in the world of artificial intelligence development and usage. The Board’s announcement was cryptic: “The board of directors of OpenAI, Inc., the 501(c)(3) that acts as the overall governing body for all OpenAI activities, today announced that Sam Altman will depart as CEO and leave the board of directors… Mr. Altman’s departure follows a deliberative review process by the board, which concluded that he was not consistently candid in his communications with the board, hindering its ability to exercise its responsibilities. The board no longer has confidence in his ability to continue leading OpenAI.” No further information was provided by OpenAI, and no hard facts have subsequently arisen in the media. There has been no confirmation of the focus and scope of the internal investigation, its accuracy and fairness, and what his alleged lack of candor may have related to. It’s unfair to Altman, his former company and the importance of the underlying governance issues to speculate on what may have occurred. MORE FOR YOU Dream On! YouTube Testing AI-Powered Music Creation Tool 4 Rules For Unleashing Radical Innovation In The Era Of Generative AI Billionaire Group Including Eric Schmidt Building AI Research Lab In Paris But regardless, it has served to tarnish the reputation of a wunderkind of AI who has also testified to Congress and consulted with world leaders on AI technology. For if the Chat GPT board has lost confidence in such a prominent figure as Mr. Altman, it’s certainly possible that it may affect the confidence with which other boards view their own company’s use of AI. And that could arise in at least three particular areas: First, it could undermine the general confidence which boards have in the future of AI for their own company. Much of the board level discussion to date has focused on the delicate balance between the promise of AI and its potential benefits to the company and its stakeholders on the one hand, and the potentially staggering risks the technology presents, on the other hand. To have one of the most prominent proponents of AI be accused in so many words of being deceitful to his board will resonate beyond the OpenAI situation. Boards are willing to tolerate many CEO idiosyncrasies, but dishonesty is not one of them. To the extent that Mr. Altman’s reputation is damaged in the eyes of corporate directors, it could lead them to be more circumspect of the promises of AI and the projections of its public proponents. Second, it is likely to increase board interest in establishing fulsome and reliable internal reporting mechanisms on AI from the executive leadership team. Recent Delaware case law has underscored the board’s fiduciary obligation to establish effective management-to-board information systems on compliance risks of the organization. To have such an apparently prominent breakdown in board reporting at ChatGPT may prompt boards to “double down” on management reporting-perhaps to executive chagrin and push-back. Third, it may increase board concerns for the orientation of pending federal regulation of AI. Mr. Altman has been a notable participant in public discourse on the promise and risks of AI. In his prominent May 16 testimony before Congress, he proposed a collaboration between industry and government to establish a federal regulatory structure to address AI. This, to mitigate what he chillingly described as the “worst case” of AI risk: “I think if this technology goes wrong, it can go quite wrong…”. Prescient boards are likely to anticipate the impact of Mr. Altman’s diminishment on Congress’ approach, especially as it relates to the treatment of corporate liability. Mr. Altman’s alleged lack of candor with his own board may prompt Congress to be more suspect of corporate responsibility and reliability as it relates to AI. The Wall Street Journal has reported that board concerns may have related to whether the company was fully considering the safety implications of its products rolled out as part of its rapid expansion of commercial offerings. If the Journal report on safety is verified, it will serve to exacerbate the concerns of many boards and cause them to increase their focus on AI safety risks. It might be a game-changer from a board oversight perspective. The promises and risks of AI technology are essentially the same today as they were on November 17, when ChatGPT announced its termination of Mr. Altman. But the perception of those promises and risks may have changed-at least from the perspective of corporate governance. Boards may-at least in the near term-adopt a more cautious and circumspect approach to AI, which may retard its natural development. As unfortunate as that might ultimately be, you can’t blame boards for tapping the breaks a bit given the credibility costs of the Altman controversy. Follow me on LinkedIn. Check out my website. Michael Peregrine I am a partner in the Chicago office of international law firm McDermott Will & Emery and earned my law degree at Northwestern University. I represent corporations (and their officers and ... Read More Editorial Standards Print Reprints & Permissions",
    "originSummary": [],
    "commentBody": "",
    "commentSummary": [],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1700403328211
  },
  {
    "title": "Legal Aid Defense Counsels Urged to Embrace Technology in Cyber Offenses",
    "originLink": "https://www.thehindu.com/news/national/andhra-pradesh/legal-aid-defense-counsels-asked-to-gain-knowledge-of-digital-technology/article67550681.ece",
    "originBody": "India World Opinion Sports e-Paper Menu ICC World Cup Elections Health Editorial SEARCH FREE TRIAL PREMIUMSubscribeLOGINACCOUNT FREE TRIALLOGINACCOUNT PREMIUMSubscribe ICC World Cup Elections Health Editorial SEARCH India World Opinion Sports e-Paper ICC World Cup Elections Health Editorial SEARCH News Business Entertainment Life & Style Society Technology Videos Podcast Cities States Science Show More Chennai Delhi Bengaluru Hyderabad Movies Food Children Data Kochi Books Brandhub Coupons Education To enjoy additional benefits FREE TRIAL PREMIUMSubscribeLOGINACCOUNT ShowcaseSubscribe to NewslettersCrossword+ CONNECT WITH US Home News India Andhra Pradesh Legal aid defense counsels asked to gain knowledge of digital technology Justice B.V.L.N. Chakravarthy of Andhra Pradesh High Court participates in the State-wide orientation programme for Legal Aid Defense Counsels organised APSLSA and NLSA November 19, 2023 06:05 pmUpdated 06:05 pm IST - VIJAYAWADA Rajulapudi Srinivas COMMents SHARE High Court Judge, Justice B.V.L.N. Chakravarthy, has asked the legal aid defense counsels to gain knowledge of digital technology as electronic evidence has become vital in cyber offences. The judge participated in the State-wide orientation programme for Legal Aid Defense Counsels (LADC), organised by the AP State Legal Services Authority (APSLSA) and the National Legal Services Authority (NLSA) here on Sunday. Speaking on the occasion, Justice Chakravarthy said the role of defense counsels was important and asked them to go through the Indian Evidence Act, 1872 and the Information Technology (IT) Act, 2000. “Many advocates do not have expertise in electronic records. But, there is a need to have complete knowledge of digital technology as electronic evidence has become a must in each and every crime,” the judge said. APSLSA Member Secretary M. Babitha, A.P. Judicial Academy Director A. Hari Haranadha Sarma, senior advocates Sunkara Rajendra Prasad, U.S.R. Raju, M. Venkateswara Rao and others spoke on ‘Significance and objectives of LADC Scheme’, ‘Art of Cross Examination’ and ‘Professional Ethics’. COMMents SHARE Related Topics Andhra Pradesh / Vijayawada Top News Today Top News India World Sports Business Sci-Tech Entertainment Life & Style The Hindu About Us Code of Editorial Values News Archive Sitemap Print Subscription Digital Subscription Subscribe to Newsletters Rss Feeds Readers Editor-Terms of Reference Authors & Contributors Contact us Contact Us Social Media Advertise With Us Group News Sites Business Line BL on Campus Sportstar Frontline இந்து தமிழ் திசை The Hindu Centre Young World Club The Hindu ePaper Business Line ePaper Crossword + Free Games Other Products RoofandFloor STEP Images Classifieds - Digital Classifieds - Print Bookstore & Special Publications Popular Sections ICC World Cup 2023 Israel Hamas War Live Updates Israeli–Palestinian conflict 2023 Latest News National News International News Videos Life & Style Food Podcast Showcase Opinion Editorial Columns Comment Cartoon Letters Interview Lead Business Agri-Business Industry Economy Markets Budget Sport Cricket Football Hockey Tennis Athletics Motorsport Races Other Sports Sci-Tech Science Technology Health Agriculture Environment Gadgets Internet States Andhra Pradesh Karnataka Kerala Tamil Nadu Telangana Other States Cities Bengaluru Chennai Coimbatore Delhi Hyderabad Kochi Kolkata Kozhikode Madurai Mangaluru Mumbai Puducherry Thiruvananthapuram Tiruchirapalli Vijayawada Visakhapatnam Trending on thehindu.com Mother, 9-month-old baby girl charred to death after being electrocuted in Hope Farm in Bengaluru ChatGPT-maker OpenAI fires CEO Sam Altman for lack of candor with company Trisha on Mansoor Ali Khan: ‘I am grateful never to have shared screen space with someone as pathetic as him’ Uttarkashi tunnel collapseIAF airlifts 27.5 tonnes of critical equipment for Uttarakhand rescue efforts NMC reduces NEET 2024 syllabus, cuts 9 chapters from chemistry and six from biology Trending on our Group sites How the rupee has held up Index Outlook: Nifty 50, Sensex: Can oscillate in wide range Why did ChatGPT creator OpenAI oust its CEO Sam Altman? How BJP’s yoga misadventure in Maldives paved the way for China to assert its dominance IND vs AUS Live scorecard, World Cup 2023 Final: India sets Australia 241-run target Terms of Use Privacy Policy Copyright© 2023, THG PUBLISHING PVT LTD. or its affiliated companies. All rights reserved. BACK TO TOP Comments Comments have to be in English, and in full sentences. They cannot be abusive or personal. Please abide by our community guidelines for posting your comments. We have migrated to a new commenting platform. If you are already a registered user of The Hindu and logged in, you may continue to engage with our articles. If you do not have an account please register and login to post comments. Users can access their older comments by logging into their accounts on Vuukle.",
    "originSummary": [
      "Justice B.V.L.N. Chakravarthy of the Andhra Pradesh High Court advises legal aid defense counsels to acquire knowledge of digital technology due to the increasing importance of electronic evidence in cyber offenses.",
      "The judge made this statement during a State-wide orientation program for Legal Aid Defense Counsels organized by the AP State Legal Services Authority and the National Legal Services Authority.",
      "He stressed the importance for defense counsels to familiarize themselves with the Indian Evidence Act, 1872 and the Information Technology (IT) Act, 2000."
    ],
    "commentBody": "",
    "commentSummary": [],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1700403328211
  },
  {
    "title": "France, Germany, and Italy Agree on Binding AI Regulations in Europe",
    "originLink": "https://ca.news.yahoo.com/eu-ai-act-germany-france-112117981.html",
    "originBody": "Euronews EU AI Act: Germany, France and Italy reach agreement on the future of AI regulation in Europe Read full article Reuters Sun, November 19, 2023 at 5:21 a.m. CST·3 min read EU AI Act: Germany, France and Italy reach agreement on the future of AI regulation in Europe France, Germany, and Italy have reached an agreement on how artificial intelligence (AI) should be regulated, according to a joint paper seen by Reuters, which is expected to accelerate negotiations at the European level. The three governments support commitments that are voluntary, but binding on small and large AI providers in the European Union that sign up to them. The European Commission, the European Parliament, and the EU Council are negotiating how the bloc should position itself. The EU's AI Act: A guide to understanding the ambitious plans to regulate artificial intelligence In June, the European Parliament presented its AI Act designed to contain the risks of AI applications and avoid discriminatory effects, while harnessing the innovative power of AI. On Friday, MEPs walked out of a meeting with member state representatives after reaching a deadlock over the proposed approach to foundation models, according to Eurativ. France, Germany, and Italy were among the larger member states pushing against regulation, a move which threatened to derail efforts to get the legislation passed in this session of the European Parliament altogether. AI rules should be binding for everyone During the discussions in June, the European Parliament proposed that the code of conduct should initially only be binding for major AI providers, which are primarily from the United States. The three EU governments have said this apparent competitive advantage for smaller European providers could have the drawback of reducing trust in them, resulting in fewer customers. The rules of conduct and transparency should therefore be binding for everyone, they said. Initially, no sanctions should be imposed, according to the paper. If violations of the code of conduct are identified after a certain period of time, however, a system of sanctions could be set up. EU AI Act nearing agreement despite three key roadblocks – co-rapporteur In the future, a European authority would monitor compliance with the standards, the paper said. Story continues Germany's Economy Ministry, which is in charge of the topic together with the Ministry of Digital Affairs, said laws and state control should not regulate AI itself, but rather its application. Digital Affairs Minister Volker Wissing told Reuters he was very pleased an agreement had been reached with France and Germany to limit only the use of AI. \"We need to regulate the applications and not the technology if we want to play in the top AI league worldwide,\" Wissing said. Balance between tech and law objectives State Secretary for Economic Affairs Franziska Brantner told Reuters it was crucial to harness the opportunities and limit the risks. \"We have developed a proposal that can ensure a balance between both objectives in a technological and legal terrain that has not yet been defined,\" Brantner said. As governments around the world seek to capture the economic benefits of AI, Britain in November hosted its first AI safety summit. Can the EU and its allies cooperate with China on AI safety standards? The German government is hosting a digital summit in Jena, in the state of Thuringia, on Monday and Tuesday that will bring together representatives from politics, business, and science. Issues surrounding AI will also be on the agenda when the German and Italian governments hold talks in Berlin on Wednesday. TRENDING 1. Storm that left 1,500 vehicles stranded overnight on Trans-Canada Highway 2. Homeowners who haven't had to bag leaves in decades 'furious' as Toronto cuts service to save $2.3M 3. 'Queen of Canada' Romana Didulo and her followers leave Sask. village school after 2 months 4. Sex assault centre director replaced over letter questioning alleged Hamas rapes 5. Bursts of heavy lake-effect snow likely over Ontario next week",
    "originSummary": [
      "France, Germany, and Italy have reached an agreement on regulating artificial intelligence (AI) in Europe.",
      "The agreement supports voluntary but binding commitments for AI providers in the European Union.",
      "The three governments propose that rules of conduct and transparency should be binding for all, with the possibility of sanctions for violations, and a European authority would monitor compliance with the standards."
    ],
    "commentBody": "",
    "commentSummary": [],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1700403328211
  }
]
