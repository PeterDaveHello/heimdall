[
  {
    "title": "AI Chatbot GPT-4 Outperforms Human Aspiring Lawyers on Legal Ethics Exam",
    "originLink": "https://www.reuters.com/legal/transactional/ai-chatbot-can-pass-national-lawyer-ethics-exam-study-finds-2023-11-16/",
    "originBody": "Transactional Technology Legal Innovation Legal Industry AI chatbot can pass national lawyer ethics exam, study finds By Karen Sloan November 16, 202311:03 AM UTCUpdated 3 hours ago AI (Artificial Intelligence) letters are placed on computer motherboard in this illustration taken June 23, 2023. REUTERS/Dado Ruvic Acquire Licensing Rights Nov 16 (Reuters) - Popular AI chatbot GPT-4 outperforms most aspiring lawyers on the legal ethics exam required by nearly every state in order to practice law, a new study has found. GPT-4 answered 74% of the questions correctly on a simulated Multistate Professional Responsibility Exam (MPRE), compared with an estimated 68% average among human test takers nationwide, according to a report released on Thursday by LegalOn Technologies — which sells AI software that reviews contracts. Advertisement · Scroll to continue “Our study indicates that in the future it may be possible to develop AI to assist lawyers with ethical compliance and operate, where relevant, in alignment with lawyers’ professional responsibilities,” the study reads. It joins a growing body of research examining AI within legal education and attorney licensure. An earlier study found that the previous version of GPT-4 earned passing but not stellar scores on law school final exams. Another more recent study found that GPT-4 can pass the bar exam. Earlier this month, researchers found that access to GPT-4 improved speed on legal writing assignments but didn’t bolster the quality law students’ work. Advertisement · Scroll to continue GPT-4 is a large language model from Microsoft-backed OpenAI that generates human-like text based on user queries. A spokesperson for the National Conference of Bar Examiners, which develops the MPRE, said that it could not assess the LegalOn report's claims that GPT-4 can pass its ethics test. \"The legal profession is always evolving in its use of technology, and will continue to do so,\" said National Conference spokesperson Sophie Martin. She added that \"attorneys have a unique set of skills that AI cannot currently match.\" Advertisement · Scroll to continue Every state besides Wisconsin requires law students to pass the 60-multiple-choice MPRE before they are admitted to practice, in addition to passing the bar exam. Tested subjects include conflicts of interest, lawyer-client relationships and confidentiality. Most people take the MPRE while in law school. GPT-4 performed particularly well on questions about conflicts of interest, with a 91% rate of correct responses. It also answered 88% of questions about the client-lawyer relationship correctly. But its accuracy fell with questions on communications about legal services and safekeeping funds and other property, which it answered correctly a respective 71% and 72% of the time. “This research demonstrates for the first time that top-performing generative AI models can apply black-letter ethical rules as effectively as aspiring lawyers,” the study reads. Read more: AI improves legal writing speed, not quality - study Bar exam score shows AI can keep up with 'human lawyers,' researchers say Get the latest legal news of the day delivered straight to your inbox with The Afternoon Docket. Reporting by Karen Sloan Our Standards: The Thomson Reuters Trust Principles. Acquire Licensing Rights , opens new tab Karen Sloan Thomson Reuters Karen Sloan reports on law firms, law schools, and the business of law. Reach her at karen.sloan@thomsonreuters.com Read Next / Editor's Picks Business category UAW members ratify labor deal with Mack Trucks The United Auto Workers (UAW) union on Wednesday said about 3,900 members representing Volvo Group -owned Mack Trucks ratified a new five-year contract in the U.S., ending a 39-day long strike following the rejection of an earlier deal. Sustainable Finance & Reporting category GM's labor deal with UAW union on verge of ratification General Motors' tentative labor deal with the United Auto Workers (UAW) union closed in on ratification as the votes were counted on Wednesday. Business category US appeals court scraps Sempra's Port Arthur LNG emissions permit A U.S. court has removed an emissions permit for Sempra's Port Arthur LNG export terminal in Texas, but the company said construction of the facility will continue for now. Business category Elon Musk denies report of potential Starlink IPO in 2024 Elon Musk on Wednesday denied a report that his rocket company SpaceX was discussing an initial public offering (IPO) for its satellite internet business, Starlink, as soon as 2024. Markets category Exclusive: ValueAct takes stakes in Recruit and Expedia, says they are poised for strong growth ValueAct Capital Management has bought stakes in job-search site Indeed's parent Recruit Holdings and in online travel services provider Expedia Group and believes both are poised for strong growth. Markets category Boom at last for 'Big Long' in bonds The scale of the debt market reaction to October's U.S. inflation undershoot partly reflects sheer relief in what's now one of the biggest bond market bets of the century so far. Technology category Barclays flags Treasuries central clearing cybersecurity risks after ICBC hack A key reform proposed by the U.S. Securities and Exchange Commission to boost the use of central clearing for U.S. Treasuries could leave the market more exposed to cybersecurity risks, Barclays said, referring to the cyber hack of Industrial and Commercial Bank of China's U.S. broker-dealer last week. Markets category ValueAct builds stake in Disney, adds drama at home of Mickey Mouse -sources ValueAct Capital has built a large stake in Walt Disney and sees room for the media and entertainment giant's stock price to roughly double, people familiar with the investment firm's thinking said on Wednesday. ExplainerExplainer: The numbers behind China's renewable energy boom China and the U.S. have agreed to back a global target to triple global renewable energy capacity by 2030, the two superpowers said in a statement on Wednesday, two weeks before nearly 200 countries meet for the COP28 climate conference. Business category France's top court demands new trial over $2 bln UBS fine France's top court on Wednesday ruled a new trial should be held over a 1.8 billion-euro ($1.95 billion) fine against UBS for promoting illegal banking services and money laundering in the country. Markets category Exclusive: Adobe open to remedy discussions with EU on Figma deal, chief counsel says Photoshop maker Adobe expects to get an EU antitrust warning on its $20 billion bid for cloud-based designer platform Figma and is open to proposing remedies to resolve regulatory concerns, its chief counsel told Reuters on Wednesday. Business category Goodyear CEO to retire in 2024 as tire maker plans to streamline business Goodyear Tire & Rubber Co said on Wednesday longtime CEO Richard Kramer has decided to retire next year and also unveiled initiatives to streamline its business, months after settling with activist investor Elliott. Business category Marsh, Lloyd's, Ukraine launch war risk ship insurance to cut grain costs Insurance broker Marsh , Lloyd's of London (SOLYD.UL) insurers and Ukrainian state banks have launched a programme to cut the cost of claims for damage to ships and crew transporting grain through the Black Sea corridor, Marsh said on Wednesday. Business category Chevron reviewing options for East Texas assets after shale acquisitions Chevron Corp said it is evaluating options for around 70,000 net acres of land in East Texas' Haynesville shale formation after pausing development earlier this year, with sources saying a full sale is one option under consideration. ANALYSISGlencore coal deal shows power of fossil fuels - even on their way out Glencore's deal to buy Teck Resources' steelmaking coal unit shows how cheap fossil fuels can be a lucrative option for companies - for a decade or two at least - even as they are phased out in favour of renewable energy. Business category US denies Repsol's request for Venture Global LNG approvals The U.S. Department of Energy (DOE) on Tuesday rejected for a second time oil major Repsol SA's request to reopen regulators' approval of Venture Global LNG's Calcasieu Pass export plant in Louisiana.",
    "originSummary": [
      "A study has shown that GPT-4, an AI chatbot, outperforms most aspiring lawyers on a legal ethics exam, correctly answering 74% of questions compared to the average of 68% for human test takers.",
      "The results suggest that AI like GPT-4 could potentially help lawyers with ethical compliance in the future.",
      "GPT-4 is a language model developed by OpenAI with support from Microsoft, but the National Conference of Bar Examiners, responsible for the legal ethics exam, cannot currently verify the study's claims."
    ],
    "commentBody": "",
    "commentSummary": [],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1700142340897
  },
  {
    "title": "How AI Language Tools in Legal Profession Can Lead to Trouble",
    "originLink": "https://www.washingtonpost.com/technology/2023/11/16/chatgpt-lawyer-fired-ai/",
    "originBody": "For AILAW. (Washington Post illustration; Shutterstock) Listen 8 min Share Comment Add to your saved stories Save Zachariah Crabill was two years out of law school, burned out and nervous, when his bosses added another case to his workload this May. He toiled for hours writing a motion until he had an idea: Maybe ChatGPT could help? Tech is not your friend. We are. Sign up for The Tech Friend newsletter. Within seconds, the artificial intelligence chatbot had completed the document. Crabill sent it to his boss for review and filed it with the Colorado court. “I was over the moon excited for just the headache that it saved me,” he told The Washington Post. But his relief was short-lived. While surveying the brief, he realized to his horror that the AI chatbot had made up several fake lawsuit citations. Crabill, 29, apologized to the judge, explaining that he’d used an AI chatbot. The judge reported him to a statewide office that handles attorney complaints, Crabill said. In July, he was fired from his Colorado Springs law firm. Looking back, Crabill wouldn’t use ChatGPT, but says it can be hard to resist for an overwhelmed rookie attorney. Advertisement Story continues below advertisement “This is all so new to me,” he said. “I just had no idea what to do and no idea who to turn to.” Business analysts and entrepreneurs have long predicted that the legal profession would be disrupted by automation. As a new generation of AI language tools sweeps the industry, that moment appears to have arrived. Stressed-out lawyers are turning to chatbots to write tedious briefs. Law firms are using AI language tools to sift through thousands of case documents, replacing the work of associates and paralegals. AI legal assistants are helping lawyers analyze documents, memos and contracts in minutes. The AI legal software market could grow from $1.3 billion in 2022 to upward of $8.7 billion by 2030, according to an industry analysis by the market research firm Global Industry Analysts. A report by Goldman Sachs in April estimated that 44 percent of legal jobs could be automated away, more than any other sector except for administrative work. Advertisement Story continues below advertisement But these money-saving tools can come at a cost. Some AI chatbots are prone to fabricating facts, causing lawyers to be fired, fined or have cases thrown out. Legal professionals are racing to create guidelines for the technology’s use, to prevent inaccuracies from bungling major cases. In August, the American Bar Association launched a year-long task force to study the impacts of AI on law practice. “It’s revolutionary,” said John Villasenor, a senior fellow at the Brookings Institution’s center for technological innovation. “But it’s not magic.” AI tools that quickly read and analyze documents allow law firms to offer cheaper services and lighten the workload of attorneys, Villasenor said. But this boon can also be an ethical minefield when it results in high-profile errors. Story continues below advertisement In the spring, Lydia Nicholson, a Los Angeles housing attorney, received a legal brief relating to her client’s eviction case. But something seemed off. The document cited lawsuits that didn’t ring a bell. Nicholson, who uses they/them pronouns, did some digging and realized many were fake. Advertisement They discussed it with colleagues and “people suggested: ‘Oh, that seems like something that AI could have done,’” Nicholson said in an interview. Nicholson filed a motion against the Dennis Block law firm, a prominent eviction firm in California, pointing out the errors. A judge agreed after an independent inquiry and issued the group a $999 penalty. The firm blamed a young, newly hired lawyer at its office for using “online research” to write the motion and said she had resigned shortly after the complaint was made. Several AI experts analyzed the briefing and proclaimed it “likely” generated by AI, according to the media site LAist. Story continues below advertisement The Dennis Block firm did not return a request for comment. Share this article Share It’s not surprising that AI chatbots invent legal citations when asked to write a brief, said Suresh Venkatasubramanian, computer scientist and director of the Center for Technology Responsibility at Brown University. Advertisement “What’s surprising is that they ever produce anything remotely accurate,” he said. “That’s not what they’re built to do.” Rather, chatbots like ChatGPT are designed to make conversation, having been trained on vast amounts of published text to compose plausible-sounding responses to just about any prompt. So when you ask ChatGPT for a legal brief, it knows that legal briefs include citations — but it hasn’t actually read the relevant case law, so it makes up names and dates that seem realistic. Story continues below advertisement Judges are struggling with how to deal with these errors. Some are banning the use of AI in their courtroom. Others are asking lawyers to sign pledges to disclose if they have used AI in their work. The Florida Bar association is weighing a proposal to require attorneys to have a client’s permission to use AI. One point of discussion among judges is whether honor codes requiring attorneys to swear to the accuracy of their work apply to generative AI, said John G. Browning, a former Texas district court judge. Browning, who chairs the state bar of Texas’ taskforce on AI, said his group is weighing a handful of approaches to regulate use, such as requiring attorneys to take professional education courses in technology or considering specific rules for when evidence generated by AI can be included. Advertisement Story continues below advertisement Lucy Thomson, a D.C.-area attorney and cybersecurity engineer who is chairing the American Bar Association’s AI task force, said the goal is to educate lawyers about both the risks and potential benefits of AI. The bar association has not yet taken a formal position on whether AI should be banned from courtrooms, she added, but its members are actively discussing the question. “Many of them think it’s not necessary or appropriate for judges to ban the use of AI,” Thomson said, “because it’s just a tool, just like other legal research tools.” In the meantime, AI is increasingly being used for “e-discovery”— the search for evidence in digital communications, such as emails, chats or online workplace tools. Story continues below advertisement While previous generations of technology allowed people to search for specific keywords and synonyms across documents, today’s AI models have the potential to make more sophisticated inferences, said Irina Matveeva, chief of data science and AI at Reveal, a Chicago-based legal technology company. For instance, generative AI tools might have allowed a lawyer on the Enron case to ask, “Did anyone have concerns about valuation at Enron?” and get a response based on the model’s analysis of the documents. Advertisement Wendell Jisa, Reveal’s CEO, added that he believes AI tools in the coming years will “bring true automation to the practice of law — eliminating the need for that human interaction of the day-to-day attorneys clicking through emails.” Jason Rooks, chief information officer for a Missouri school district, said he began to be overwhelmed during the coronavirus pandemic with requests for electronic records from parents litigating custody battles or organizations suing schools over their covid-19 policies. At one point, he estimates, he was spending close to 40 hours a week just sifting through emails. Story continues below advertisement Instead, he hit on an e-discovery tool called Logikcull, which says it uses AI to help sift through documents and predict which ones are most likely to be relevant to a given case. Rooks could then manually review that smaller subset of documents, which cut the time he spent on each case by more than half. (Reveal acquired Logikcull in August, creating a legal tech company valued at more than $1 billion.) Advertisement But even using AI for legal grunt work such as e-discovery comes with risks, said Venkatasubramanian, the Brown professor: “If they’ve been subpoenaed and they produce some documents and not others because of a ChatGPT error — I’m not a lawyer, but that could be a problem.” Those warnings won’t stop people like Crabill, whose misadventures with ChatGPT were first reported by the Colorado radio station KRDO. After he submitted the error-laden motion, the case was thrown out for unrelated reasons. He says he still believes AI is the future of law. Now, he has his own company and says he’s likely to use AI tools designed specifically for lawyers to aid in his writing and research, instead of ChatGPT. He said he doesn’t want to be left behind. “There’s no point in being a naysayer,” Crabill said, “or being against something that is invariably going to become the way of the future.” Share Comments",
    "originSummary": [
      "The use of AI language tools in the legal profession is increasing, with chatbots and software being used for various tasks such as writing briefs, document analysis, and e-discovery.",
      "However, these tools come with risks, as some chatbots have been found to provide false information, resulting in negative consequences like lawyer dismissals, fines, and case dismissals.",
      "Judges are trying to navigate these errors and are considering actions like banning AI in courtrooms or mandating lawyers to disclose their use of AI. The AI legal software market is projected to experience significant growth in the future."
    ],
    "commentBody": "",
    "commentSummary": [],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1700142340897
  },
  {
    "title": "Generative AI's Impact on the Legal Industry: A Revolution in Operations and Innovation",
    "originLink": "https://news.bloomberglaw.com/us-law-week/generative-ais-rise-in-legal-space-could-be-a-win-for-clients",
    "originBody": "Factor’s Ed Sohn and Six Parsecs’ Jae Um consider how AI will impact different types of legal work and in-house’s relationship with outside counsel. Generative AI developments are coming at a blistering pace, fueling both noise and skepticism. Like many industries, the legal space is curious about the adoption of generative AI and its potential to streamline operations and drive innovation. Large language models merit sustained attention in this environment. They exhibit two attributes of unique relevance to the practice and business of law: They offer impressive proficiencies in language that enable significant redesign for substantive legal work. They also present more intuitive human-machine interactions that dismantle barriers to adoption. The interplay of these two attributes will unlock latent value in the billions. GenAI’s impact will hit across the entire legal supply chain and reshape 80% of the corporate legal wallet, estimated at about $450 billion in the US. The composition of this spend is characterized below, with the associated problems and stakes of each tier. This composition analysis flows from the insight that legal functions are asked to solve a portfolio of problems for the enterprise. A one-size-fits-all approach is unlikely to succeed. Generating insights about value creation and delivery means addressing the controlling problems and risk drivers in each value tranche. Cream and commodity categories noted above merit their own discussions. For now, it’s sufficient to say that they’re each impacted by GenAI in unique and specific ways. Core The core accounts for the lion’s share of spend, which is about $360 billion in total legal budget. Core is also the tranche most susceptible to transformation in the means and economics of service delivery, both internally and externally. Based on the current capabilities and future trajectory of LLMs, we expect over $300 billion of that budget to be reshaped in first- and second-order ways. Core work arises in the normal course of business operations—contracting, product counseling, and mid-complexity commercial litigation are demonstrative examples. This tranche exhibits high variance in scope, legal complexity, and business risk on a per-matter basis, but with a few commonalities. Core work typically requires both legal expertise and business proximity; much of it is high-volume and recurring, but with variations that make it unsuitable for conventional thinking about process standardization or tech enablement. This is complex legal work at scale, where corporations remain most underserved—and the twin pressures of increasing workloads and finite budgets are most acute in the core. Performance gaps manifest as everyday frustration and friction for the business that legal seeks to enable. Even as outside counsel serving this work struggle to deliver quality under increasing price pressure, in-house counsel still experience considerable pain and resource waste. While sophisticated legal functions are likely to pull more core work in-house, this is a strategy historically constrained by productivity and upper limits on headcount. GenAI impact in the core can best be expressed as a progression of a familiar feature of legal teams: staffing leverage. For generations, senior lawyers have extended their finite capacity through supervision of junior lawyers and paraprofessionals. Now, GenAI is becoming a virtual teammate—or an army of virtual teammates—that can read, research, operate, and draft in ways that a legal professional can. Lawyer and GenAI collaboration creates “bionic teams” that allow a leap forward from conventional thinking about the “tech-enabled lawyer.” Bionic teaming represents a sharp departure from previous tech and solution approaches that required high up-front investment of money, time, and effort. In the past, lawyers have experienced legal tech as deterministic process configuration that constrains their judgment rather than enables their work. Now, bionic teams place client needs at the center and human experts in the lead, without the heavy burdens of adoption and training. Legal organizations can now deploy powerful, on-demand GenAI capabilities in nimble ways as core needs arise. For core work, GenAI enables new service model design, making available novel paradigms of human-machine collaboration and new thinking about how to embed legal expertise into the business operations of the enterprise. The reshaping of core spend will expand technology spending, with GenAI offering a pathway to much greater return on investment. Corporates are likely to begin by funneling budget away from traditional outside counsel to fund these investments. The result will be transformative, and not uniform—each legal team will experience these new GenAI co-workers differently. For some teams, GenAI will take on support and intermediary roles around specialists, resulting in rebalancing of in-house headcount away from generalists. In other teams, GenAI will facilitate centralized expertise and knowledge that generalist lawyers can integrate intuitively and apply consistently. Teams with the self-awareness and foresight to envision the contours of their specific destination will navigate the journey with more speed and confidence. GenAI creates a rare opportunity for a comprehensive and varied redesign to the historical means of production for legal work. Broad legal budget impact will be one bellwether indicator of something even more exciting: the emergence of a truly client-centric era, where the general counsel redesigns and orchestrates the future of legal services around the needs of the client. This article does not necessarily reflect the opinion of Bloomberg Industry Group, Inc., the publisher of Bloomberg Law and Bloomberg Tax, or its owners. Author Information Ed Sohn is global head of capabilities at Factor, an integrated law provider that works alongside corporate legal departments and law firms to manage complex transactional legal work. Jae Um is founder and executive director at Six Parsecs, an insights and advisory firm for the legal market providing strategy advice to leading law firms and NewLaw disruptors. Write for Us: Author Guidelines Continue Reading Learn About Bloomberg Law AI-powered legal analytics, workflow tools and premium legal & business news. Learn more Already a subscriber? Log in to keep reading or access research tools. Log In",
    "originSummary": [
      "GenAI (generative artificial intelligence) is set to have a significant impact on the legal industry, bringing advancements and efficiency.",
      "Large language models have the potential to revolutionize legal work and improve human-machine interactions.",
      "It is predicted that GenAI will reshape 80% of the corporate legal wallet, which amounts to approximately $360 billion in the US alone."
    ],
    "commentBody": "",
    "commentSummary": [],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1700142340897
  },
  {
    "title": "Thomson Reuters Unveils Gen AI Tools to Revolutionize Legal Profession",
    "originLink": "https://www.pymnts.com/artificial-intelligence-2/2023/thomson-reuters-introduces-generative-ai-tools-for-legal-professionals/",
    "originBody": "WATCH NOWSUBSCRIBE Search PYMNTS TV Today B2B Retail Fintech Digital Transformation Crypto EMEA Tracker® Reports PYMNTS® Data Markets More Topics Artifical Intelligence Connected Car Buy Now Pay Later Banking Cloud Cross-Border Payments Gig-Economy Grocery & Pharmacy Healthcare Payments Insurtech Small & Medium Businesses Social Platforms Subscription Commerce Travel TechREG® Real-Time Payments Restaurants More Topics Featured SEE ALSO: Editor’s Picks Opinion CE100 Index Working Capital & Liquidity Competition Policy International A PYMNTS Company Stay Current Subscribe Become a Partner Thomson Reuters Introduces Generative AI Tools for Legal Professionals By PYMNTSNovember 15, 2023Thomson Reuters has launched a series of initiatives aimed at transforming the legal profession through the use of generative AI. These initiatives are set to provide legal professionals with powerful tools to enhance their research and workflow, the global content and technology company said in a Wednesday (Nov. 15) press release. One of the key highlights of these initiatives is the introduction of GenAI within the AI-Assisted Research on Westlaw Precision platform. This skill allows legal professionals to quickly find answers to complex research questions, drawing from a comprehensive collection of editorially enhanced content. Thomson Reuters is also building on the AI assistant experience created with CoCounsel, an AI legal assistant. In 2024, they will launch an AI assistant that will serve as the interface across Thomson Reuters products with GenAI capabilities. This integration will provide customers with a seamless experience and the ability to choose the right skills to solve their specific legal problems. With the introduction of AI-Assisted Research and CoCounsel Core, legal professionals will have access to eight GenAI-powered core skills. These skills include AI-Assisted Research on Westlaw Precision, Prepare for a Deposition, Draft Correspondence, Search a Database, Review Documents, Summarize a Document, Extract Contract Data and Contract Policy Compliance. Thomson Reuters also has plans to develop numerous additional GenAI skills to address customer-specific needs. Thomson Reuters’ GenAI tools leverage the capabilities of Thomson Reuters Labs, the company’s 1,600 attorneys and its content, Mike Dahn, head of Westlaw Product Management at Thomson Reuters, said in the release. “Our human oversight, technology expertise and industry-leading content are critical to producing trusted answers with generative AI,” Dahn said. “This tool won’t obviate the need for attorneys, but it will help them do their work better and faster.” PYMNTS Intelligence has found that the natural language capabilities of GenAI offer unprecedented advantages for distilling legal information and synthesizing actionable insights. The technology can dramatically accelerate the completion of legal tasks without diluting quality, according to “The Confluence of Law and AI: An Inevitability Waiting to Happen,” a PYMNTS and AI-ID collaboration. The report also found that GenAI offers the potential to redistribute workloads in ways that can liberate junior associates to conduct more complex, value-added work. Recommended Thomson Reuters Introduces Generative AI Tools for Legal Professionals Nearly 40% of Gig Economy Ad Hoc Transactions Sent via Instant Payments UPS Debuts Tool to Get Supply Chain Elements in Tune AI Can Predict the Weather, What About Financial Forecasts? See More In: AI, artificial intelligence, generative AI, legal, News, PYMNTS News, Thomson Reuters, What's Hot Trending News Middle Market CFOs Say Automated AP/AR Delivers Certainty in Tough Economy Bryzos CEO Says Higher-for-Longer Rates Force Focus on Business Payment Processes Real-Time Credit Decisioning Helps B2B Payments Feel as Seamless as P2P The Big Story Platform Economics: How Instacart Leverages Time Into Profits Featured News Middle Market CFOs Say Automated AP/AR Delivers Certainty in Tough Economy Bryzos CEO Says Higher-for-Longer Rates Force Focus on Business Payment Processes Real-Time Credit Decisioning Helps B2B Payments Feel as Seamless as P2P Payments Innovation Drives Improved Operational Outcomes for Corporates Gen Zs Live With Family to Save Money; Gen Xs as Caregivers Brick-and-Mortar Merchants to Take a Hit as Retail Sales Sputter? Target Says ‘Tis the Season for Financial Stress Subscribe PYMNTS Today Artificial Intelligence Cryptocurrency B2B Retail TechREG® Digital Transformation SUBSCRIBE Partner with PYMNTS We’re always on the lookout for opportunities to partner with innovators and disruptors. Learn More",
    "originSummary": [
      "Thomson Reuters has introduced generative AI tools aimed at transforming the legal profession.",
      "The tools, such as the GenAI skill, will improve legal professionals' research and workflow by providing quick access to answers for complex questions and identifying the appropriate skills to address specific legal issues.",
      "These tools utilize Thomson Reuters Labs, the company's attorneys, and its content to leverage the power of generative AI, allowing for improved distillation of legal information and the redistribution of workloads to allow junior associates to focus on more complex tasks."
    ],
    "commentBody": "",
    "commentSummary": [],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1700142340897
  },
  {
    "title": "Generative AI Shows Promise in Legal Ethics Exam, Outperforming Humans by 6%: Study",
    "originLink": "https://www.businesswire.com/news/home/20231116912443/en/Generative-AI-Passes-the-Legal-Ethics-Exam-in-Study-by-LegalOn-Technologies",
    "originBody": "Generative AI Passes the Legal Ethics Exam in Study by LegalOn Technologies Download Research from LegalOn Technologies indicates that GPT-4 can perform better than the average test taker on the legal ethics exam. (Graphic: Business Wire) Research from LegalOn Technologies indicates that GPT-4 can perform better than the average test taker on the legal ethics exam. (Graphic: Business Wire) Image Full Size Small Preview Thumbnail Image Full Size Small Preview Thumbnail November 16, 2023 06:00 AM Eastern Standard Time SAN FRANCISCO--(BUSINESS WIRE)--In a groundbreaking development, researchers at LegalOn Technologies have demonstrated that both OpenAI’s GPT-4 and Anthropic’s Claude 2 can pass the legal ethics exam, a test nearly all US lawyers are required to pass, alongside the bar exam. This milestone underscores the potential for AI to assist lawyers in legal work and demonstrates the increasingly advanced capabilities of large language models applied to law. “Generative AI applied to legal work continues to surprise and impress. Today it is capable of tasks that, this time last year, seemed years away” Post this Earlier this year, research found that the generative AI model GPT-4 could surpass law students in passing the Uniform Bar Examination. LegalOn’s study extends this discovery, revealing that these models can also navigate complex rules and fact patterns around professional responsibility. Ethics are part of many professional certifications, but their importance in law is highlighted by the standalone ethics exam that lawyers must pass. LegalOn’s research tested several leading generative AI models, including OpenAI's GPT-4, GPT-3.5, Anthropic's Claude 2, and Google's PaLM 2 Bison, on their ability to correctly answer questions modeled for the legal ethics exam, known as the Multistate Professional Responsibility Exam (MPRE). GPT-4 performed best, answering 74% of questions correctly, outperforming the average human test-taker by an estimated 6%. GPT-4 and Claude 2 both score above the approximate passing threshold for the MPRE in every state where it is required, a threshold estimated to range between 56-64% depending on the jurisdiction. “This research advances our understanding of how AI can assist lawyers and helps us assess its current strengths and limitations,” stated Daniel Lewis, US CEO of LegalOn. “We are not suggesting that AI knows right from wrong or that its behavior is guided by moral principles, but these findings do indicate that AI has potential to support ethical decision-making.” The MPRE consists of 60 multiple choice questions covering a broad range of topic areas, such as client confidentiality, conflicts of interest, and malpractice. For its study, LegalOn tested each large language model against 100 simulated exams composed of questions created by Professor Dru Stevenson, who teaches professional responsibility at South Texas College of Law Houston. Each large language model was tested using a “zero shot” approach, which involves no prior training about legal ethics. \"That AI can pass the legal ethics exam marks a turning point not only for legal technology but also for the practice of law,\" said Professor Stevenson. “The responsibility for ethical decisions will always remain firmly with legal professionals, but this study shows the potential for technology to assist the legal community with consistently meeting high ethical standards.” “Generative AI applied to legal work continues to surprise and impress. Today it is capable of tasks that, this time last year, seemed years away,” said co-author Gabor Melli, VP of Artificial Intelligence at LegalOn Technologies. \"This research indicates that it may be possible to develop AI to assist lawyers with ethical compliance and operate, where relevant, in alignment with lawyers’ professional responsibilities.” GPT-4’s performance varied by subject area, and there are opportunities for improvement. It performed particularly well in areas such as conflicts of interest and client relationships, and less well on topics such as the safekeeping of funds. These findings indicate that performance may improve with more domain-specific knowledge and lawyer-led training and validation. This research reaffirms LegalOn’s belief in the importance of integrating expert legal content and knowledge with AI systems to build professional-grade tools. Earlier this year, LegalOn launched AI Revise, the first AI contract editor enhanced by expert legal knowledge, enabling legal teams to make precise, context-aware contract revisions with one click. For a deeper insight into this study and its implications, download a copy of the report here. About LegalOn Technologies LegalOn Technologies is the leading AI contract review software for legal teams, serving innovative lawyers and legal professionals at over 4,000 companies and firms globally. The company is backed by leading investors and has raised over $130M. Companies and firms interested in our technology can find more information and sign up for a demo at LegalOnTech.com. LegalOn’s US headquarters are in San Francisco, and its global headquarters are in Tokyo. Follow LegalOn on LinkedIn to stay up to date on the latest news and developments. Contacts Corey Longhurstinfo@legalontech.com",
    "originSummary": [
      "OpenAI's GPT-4 and Anthropic's Claude 2 have shown the ability to pass the legal ethics exam required for US lawyers, showcasing the potential for AI to assist in legal work.",
      "GPT-4 outperformed the average human test-taker by 6%, answering 74% of questions correctly.",
      "The study suggests that AI has the potential to support ethical decision-making in the legal profession, but GPT-4's performance varied by subject area, indicating the need for more domain-specific knowledge and lawyer-led training."
    ],
    "commentBody": "",
    "commentSummary": [],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1700142340897
  },
  {
    "title": "Thomson Reuters Launches AI Tools for Legal Research on Westlaw Precision",
    "originLink": "https://www.foxbusiness.com/technology/thomson-reuters-launches-generative-ai-tools-legal-research",
    "originBody": "Artificial intelligence Published November 15, 2023 7:58pm EST Thomson Reuters launches generative AI tools for legal research Thomson Reuters' AI legal research tools take questions in natural language, synthesize answers Facebook Twitter Comments Print Email By Eric Revell FOXBusiness close video We will see massive innovation in artificial intelligence: C3.ai CEO Tom Siebel provides insight on the powerful technology on \"The Claman Countdown.\" Thomson Reuters announced the launch of new generative artificial intelligence (AI) initiatives on Wednesday, including the incorporation of GenAI into the company’s legal research platform to help professionals with complex research. The new functionality, known as AI-Assisted Research on Westlaw Precision, allows users to pose complicated legal research questions in natural language and provides synthesized answers by citing Thomson Reuters’ Westlaw database that draws on 150 years of legal analysis and content along with links to other sources with regard to the relevant legal authority at issue. \"AI-Assisted Research on Westlaw Precision helps lawyers quickly and efficiently find answers – from the simple to the most complex questions,\" David Wong, chief product officer for Thomson Reuters, and Mike Dahn, head of Westlaw Product Management at Thomson Reuters, told FOX Business. \"In the past, this research could take hours of poring through documents, cases, statutes etc., now with this technology, they can find the answers in minutes. And it’s using the most trusted legal content on the market in Westlaw Precision. This frees them up to focus on more high-value, strategic work,\" they added. LAWYERS WHO USED CHATGPT INCLUDED FAKE LEGAL RESEARCH FABRICATED BY AI CHATBOT Thomson Reuters announced a new AI-powered legal research tool that lets users pose questions in natural language. (Pascal Le Segretain / File / Getty Images) To prevent the generative AI tool from \"hallucinating\" by making up case names or citations, Thomson Reuters’ AI-Assisted Research uses retrieval augmented generation (RAG) to keep the large language models that underpin the platform focused solely on the language of the content in the Westlaw archive. \"When asked a question, the AI reads through Westlaw content, finding the most relevant answers to some of the hardest questions, writes a synthesized answer to that question, and then cites the materials it pulls from in order to give confidence in the data,\" Wong and Dahn explained. Ticker Security Last Change Change % TRI THOMSON REUTERS CORP. 133.43 -0.41 -0.30% Thomson Reuters is also planning upgrades to a GenAI assistant called CoCounsel, which has already launched and is available to customers but will get new skill sets over the next year as it’s integrated further into the company’s content and products. WHAT IS ARTIFICIAL INTELLIGENCE (AI)? Thomson Reuters is planning to add new AI-powered skills to its research tool and CoCounsel assistant. (iStock / iStock) Between AI-Assisted Research and CoCounsel, the company says attorneys and legal professionals using the platform not only get the benefit of AI-powered legal research but can also leverage it to draft, review and summarize legal documents. They can also use the tools to monitor contract compliance with contracts and extract relevant data from contracts for further examination. The newly launched AI tools and those that the company plans to roll out going forward are developed using the Thomson Reuters Generative AI platform, which Wong and Dahn said helps the company quickly expand its AI product offerings by building on reusable components. GET FOX BUSINESS ON THE GO BY CLICKING HERE \"It is a cloud native technology platform that uses an API-first development approach and incorporates Thomson Reuters UX and Design systems,\" they explained. \"It enables Thomson Reuters to quickly and easily launch new generative AI skills by leveraging reusable components as the building blocks for future products. The Thomson Reuters Generative AI platform provides a safe, privacy-compliant, and reliable platform for generative AI development.\" U.S. Stock Market Quotes Advertisement Advertisement Advertisement Advertisement",
    "originSummary": [
      "Thomson Reuters has introduced AI tools for legal research on its Westlaw Precision platform.",
      "The AI-Assisted Research feature can understand complex legal questions in natural language and provide synthesized answers using the company's Westlaw database.",
      "The tools aim to save lawyers time by quickly finding answers to legal questions and can also be used for various tasks such as drafting legal documents and monitoring contract compliance."
    ],
    "commentBody": "",
    "commentSummary": [],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1700142340897
  },
  {
    "title": "Navigating the Role of AI in the Legal Tech Industry: Ethical Considerations and Strategies for Improvement",
    "originLink": "https://www.jw.com/news/frb-ai-legal-tech/",
    "originBody": "Navigating the AI Landscape and Revolutionizing Legal Tech November 15, 2023Podcast: Future-Ready Business Share this article: The release of ChatGPT in late 2022 thrust AI into the forefront of public conversations, shifting attitudes from initial skepticism to the current widespread fascination. In this episode of FRB, we engage in a conversation with the CMO of HyperDraft, Inc., Ashley Carlisle, as she provides a comprehensive exploration of predictive analytics, the role of AI in this domain, ethical considerations related to AI usage, the importance of diversity in AI development, and strategies for improving tech literacy. Featured This Episode Our Hosts: Art Cavazos Partner, San Antonio Twitter: @FinanceLawyer Follow on LinkedIn » Courtney White Research Attorney, Dallas & Houston Instagram: @courthousecouture Follow on LinkedIn » Episode Guest: Ashley Carlisle HyperDraft, Chief Marketing Officer Follow on LinkedIn »Episode Transcription Art Cavazos: Hi, I’m Art Cavazos, a corporate and finance lawyer with Jackson Walker. And this is Future-Ready Business. I’m joined today by my co-host, Courtney [White]. And we’re going to be talking about AI and automation with our very special guest, Ashley Carlisle. And Ashley, we’d like to let our guests introduce themselves. And that way the audience can tie voice to name and get to hear a little bit about you. You want to go first? Ashley Carlisle: Sure, thanks for having me. I appreciate your time. My name is Ashley Carlisle. I am the CMO at HyperDraft. And I am a former Goodwin and Kirkland corporate attorney myself, so I understand the pain and excited to connect with you all. If you haven’t heard of HyperDraft we help organizations scale legal work with our AI powered document and workflow automation solutions. Basically, we make legacy processes simpler by digitizing them so that legal can be less tedious and less annoying. And we work mainly with Fortune 500, and public tech, healthcare, financial, and private equity clients across the US. Art Cavazos: Fantastic. And thank you very much for that. And Courtney, you of course are a returning guests on FRB and part of the FRB team. But for those who haven’t heard the previous episodes, can you tell us a little bit about yourself as well? Courtney White: Sure. My name is Courtney, and I’m a research attorney in our Houston office. I also host the Jackson Walker Fast Takes podcast and outside of work I’m also a blogger on TikTok, Instagram at the account Courthouse Couture. Art Cavazos: Great, thank you. And as always, before we jump in, I’d like to remind our listeners that the opinions expressed today do not necessarily reflect the views of Jackson Walker, its clients or any of their respective affiliates. This podcast is for informational and entertainment purposes only, and does not constitute legal advice. So today, Ashley, obviously you told us a little bit about your background. And so we’re here to talk mainly about AI Artificial Intelligence, which has become such a huge topic this year. And like, you know, as I know, last year, was not at the forefront of everybody’s, you know, what they were talking about? I think back to like March 2022, and headlines were being made because Elon Musk and 1000 other tech aficionados, were signing this open letter calling for a six month pause on AI development. And of course, you know, that didn’t happen. I think everybody who signed that letter probably continued working on AI. And then it was really like late 2022 when ChatGPT was released. And then by early 2023, that’s been all anybody can talk about. 2023 will probably be remembered as, you know, the year of AI. But you’ve been doing this for a long time, right? You didn’t just start when this became the hot trending topic on whatever Elon Musk is calling his social media sites these days. So can you tell us a little bit about, kind of really just building more on your background, how did you get interested in AI? And how did you get to this point? Ashley Carlisle: Yeah, I think you’re right, that 2023 is going to be known as the year of AI and history, we’ll see whether that’s a like exciting thing or a boring thing. So yes, HyperDraft has been around since the end of 2017, beginning of 2018. And it was interesting how you phrased the question, because I was kind of nodding along internally, because it’s kind of representative of our company’s journey with AI. So when we started off, our company was called HyperDraft AI, and in 2018, and 2019, when we’d go to legal departments, or law firms, and even mentioned our name, like the mention of AI would just make them bored, or like skeptical one of the two. And so eventually, we got a lot of feedback from them. And advisors to be like, Oh, take AI out of your company name. Like no one really wants to know how the sausage is made. No one cares that you guys have your own proprietary AI, like they just want to know the output and the use cases. So we did that. And we’ve been HyperDraft since 2019. And so it’s really funny. And this last year, like you said, of like the ChatGPT, post ChatGPT And the last year to see how people have just completely turned to 180. I think it is slowly dying down. But I also think it shows an underlying phenomenon with especially the legal industry, but the world generally of our generation grew up with technology, and we just assume that things are possible that maybe other generations didn’t. So you know, you see ChatGPT and instead of wondering like, Oh, how can ChatGPT help me do like these basic things? You see it and immediately your imagination is like how can it help me fly? How can it help me do these crazy things? You go from zero to 100 very quickly, though I think that’s kind of been the year of ChatGPT echo chambering that we’ve lifted as people seeing this very basic thing and using it as a jumping point to jump to like, let their imagination run wild. And I think hopefully 2024 will be a year where that’s kind of reined in. And people are using it more and becoming more familiar, and really asking more foundational questions that can help us all increase our tech literacy with AI and actually to kind of allow it to move us meaningfully forward, especially in the legal industry. Courtney White: I think what I’m most interested in is AI’s ability to streamline legal work. Lawyers get paid by the hour. So it is no mystery, that that can get expensive, especially in large scale transactions, litigation, and the like. So what I really would like to kind of discuss is how can AI be harnessed in areas of transactional work. So for instance, contracts, M&A transactions, real estate transactions, and those are all areas where there is a lot of detailed work, if you are handling the work, the work can get very voluminous. And law firms obviously want to get as most, the largest amount of work that they possibly can. But you want to be efficient in handling that work. And also be mindful of the client’s objectives of keeping the bill as manageable as possible. So I’d love to know your thoughts on how AI can be harnessed in those areas in a way that is also respectful of client information and privacy concerns that many have with AI. Ashley Carlisle: Yes, well, there’s like seven things in there. But I’m excited. So if I’ve missed one of them, hold me accountable and bring me back for that part of the question. The first thing you started off was the premise that, you know, we talked about a lot in legal tech, which is the billable hour has been the elephant in the room for legal tech for 30 years, the tools that we have made better have foundationally been around for 30 years. And the main reason why they haven’t had like prolific adoption is the billable hour and people’s misconceptions of how they give value to their clients. I think post pandemic, a lot of things have shifted, people know that technology can be an instrumental part of business and legal work now and are kind of pushing from the in house side onto their legal providers for like innovative ways to do things, I think people are more cost conscious than ever. And I also think that with people getting excited about ChatGPT, and using more technology, people are getting these new ideas on how they can bring more value to their practice with creativity and leveraging these tools and a different way. So to be frank, the billable hour is still a problem with adoption in the law firm setting. But that is why you will see so many in house legal departments really kind of being the leaders and adoption and many ways in our space. And it’s been very interesting to see the success stories on that end. And I think some of us are thinking and we’re kind of seeing it firsthand that that’s kind of been kind of an example situation where the law firms are scratching their heads thinking, Oh, well, if our clients can do these internal projects so much more efficiently, how can I redo how I’m doing my work, whether that be with flat fees, or alternative billing structures to use my team and this technology more effectively. That’s kind of that point that you mentioned at the beginning with the billable hour and how you commoditize the value of attorney work. One thing that I’ve realized leaving big law and now being in this legal tech bubble, is when I was a debt finance attorney, I really only thought of my time in hours. And now that I’m on the other side, I realized that a lot of in house counsel doesn’t really care about the bill as long as you’re giving them the value they want. And at the end of the day, there are still a lot of teams that are kind of not thinking of the bigger picture. Courtney White: So Ashley, I am sure you are familiar with the way legal departments work having a legal background yourself. And I’d love to just start out with exploring how AI is being used for contract analysis and management. Ashley Carlisle: Sure. So contract analysis has been around for a while. And the tools keep getting better and better. I know when I was at big law firms we used EagleEye Contract Companion. There’s tools like that there’s also tools that dive into identifying what’s market, creating issues, lists from contracts. And then also, contracts analysis tools are often used on the back end after contracts are executed for reporting to see where trends lie within certain deal type structures and for teams to kind of assess how the goal is doing and whether that’s working for the big picture of the business. I would say that I do hear complaints sometimes about contracts analysis tools because of the fact that it requires a very large amount of data to produce the answers that people are looking for. And another thing which kind of ties back to some general AI concepts that I think people are talking about more so in this last year is it’s really hard to create models. And it’s really hard to sculpt data. Because typically when you’re doing that you’re looking for the average answer. And as most of us know, having gone to law school and being very hard working, lawyers aren’t looking for the average answer. Lawyers are looking for the best answer. And so using these tools is often not something people should completely be reliant on, it should be a guidepost, or kind of a double checking mechanism, or something that kind of makes sure that you’re not missing something along the way. But that’s a common complaint that I hear is just that they expect these tools are going to be able to replicate what’s in their brain. And I guess from a job security perspective, it’s good that they can’t necessarily do that. But it’s also important to know why that is. And that really is just kind of how data modelling and these AI models work within an analytics framework. In regards to contract management, contract management is also known as Contract Lifecycle Management, or CLM, which if you’re in house, I apologize for all of the people out there who have spam you with emails about CLM solutions, or all the events you’ve been invited to or what have you. Obviously, that has been a huge adoption, push for the legal industry in the past few years. And if you’re unfamiliar with what that is, that basically is just automating a contract process. So basically digitizing how you draft, manage, store, and then review contracts. And the idea is to put a whole organization connectively together with technology, so that an in house department, for example, you could see how finances using your documents, how sales is using your documents, a connectivity tissue kind of a technological way that typically isn’t there and standard organizations just because as they grow, that becomes increasingly harder. Our CEO actually wrote a chapter that’s kind of an intro to what contract management is, and a new book called The Legal Tech Handbook. So I’m not going to bore you, unfortunately, I could go on for about two hours as to what CLM is and how it’s being used and legal departments. But if people are interested, that book is available on Amazon. But generally people are using it just to kind of speed up deal cycles. And to make sure that legal is not the bottleneck. Because often problems with legal or not legal doing a poor job, it’s the underlying people and processes that they have to interact with. And so kind of by standardizing process and using contract management, you can kind of as a team, solve these issues, and then automate friction out of the process. Courtney White: And in that same vein, which I think you already touched on some of it, I would love to know if AI could even be used in very technical transactional deals like M&A deals, complex real estate transactions, areas where you have large amounts of data. And you want to pare down the information and give your client a product that’s very useful to them. But you also want to protect client important information and proprietary information to your client. Could AI be used in those instances as well? Ashley Carlisle: Sure, people have used AI tools and diligence processes. And they’ve also used them to kind of see what’s market and certain things, as I said, the market example sometimes falls flat just because you need so much data to do that. And in order for you to get that data securely. That would take a long time, many law firms are trying and with time, maybe they’ll develop their own process to do that. And then in regards to the diligence, I think the main thing that lawyers really want, which I understand as a first year associate, I quickly realized I was not going to be an M&A lawyer, because diligence is awful, at least to me, finance, diligence is a lot less. And so I went I went that route, is that even though these tools can help you identify what type of agreements are in a corpus of documents, certain provisions, red flags, synthesize them into tables, which is helpful. We still as attorneys have a duty to our clients a duty of competence to know what’s in those documents, we still have to read them. And so obviously, that’s something that all of us attorneys know. But that is something that you often see articles written about of like, will robot lawyers replace us? Well, technically, as it stands, we still have to read the documents. So no, and you’re gonna be happy that we still have to read the documents, because lord knows something will come out a few months later, and you’re like, help me this is happening. And if we just depended on the tools, it would take a lot longer and a crisis management situation to figure that out. So short answer is yes, they’re being used. But I would say that people overestimate the replication of complex legal minds in the transactional context, especially on the diligence side, the tools are being used and document automation and workflow automation commonly and we do have many clients in house and law firms that are using them. Because, you know, you can only cut an MSA so many ways or at SBA so many ways or a credit agreement so many ways. But at the end of the day, people have to review and make sure that the bespoke provisions to that client have to be detailed for them. So really, it’s just kind of jumping ahead 10 steps as opposed to replacing the entirety of a lawyer’s workflow. Art Cavazos: So when you mentioned jumping ahead 10 steps, that makes me think of another use for AI, which is in predictive analytics. Can you tell us a little bit about what Predictive analytics is? And what AI does? What role AI can play in that, or maybe is playing in that? Ashley Carlisle: Sure, this is something that’s, you know, I think all of us in legal tech are very excited about because we’re kind of at the beginning of hopefully a predictive analytic, or analysis age, but kind of baseline. It’s using advanced analytics, machine learning statistical models to analyze large volumes of data and have more proactive and predictive information for legal, which, if that was too long winded for you, basically, it could be that lawyers can be more of a preventative practice as opposed to a crisis management practice, because we’d know ahead of time, is this motion worth it based on the judge the court the type of case. I’ve gone through the corpus of data. And now I have this prediction that maybe it is good for my client or not, should I settle? How much will it cost for my team to do a series of transactions for this real estate company is my pricing, you know, something they’re going to go for? It really could allow the practice of law to operate more like a traditional business than an insular legal institution, which we have for maybe centuries at this point. But like I said, we’re kind of at the beginning of predictive analytics, there are some companies, Lex Machina is one of them that has partnered with some law firms. And they are trying to build this stuff out. And I think everyone, including myself, is very excited to see how this could kind of transform our industry. And maybe our clients might come to us before there’s like a big explosion, which would be super exciting, be a long term business partner with them, perhaps. But one thing I will say is that in this case, right now, it’s being used more to litigation framework, and hopefully with time that will be expanded into a transactional as well. But data is also key there. Art Cavazos: And what types of matters could be predicted? Like what types of you know, you used the word explosion, what type of events are being identified? Ashley Carlisle: So I think mainly, it’s a risk assessment risk management tool. So whether it be on the litigation side, if there are certain infractions that are going to lead to litigation, if it’s worth settling, things like that. And then more on the regulatory side, I guess it would be more of a monitoring of kind of violations, maybe privacy, labor, what have you, and kind of how the organization can structure, the teams that are handling those are outside counsel. And the best way for them. One thing that I forgot to mention, which I think is very different from the rest of the legal Tech game right now, is that law firms have really been the ones to mold this space and will in the future, which is the opposite of the other categories. Because the other categories, there’s people like us who are building it, and we have a lot of in house clients, we have some law firms, but mainly in house clients that are leading the charge. But in this case, it’s really been law firms that have put a ton of money into kind of trying to build these on their own. And maybe each law firm someday will have their own predictive analytics software that your teams would be using at the beginning of each matter, to determine who was on your team, what the course of action will be. So perhaps kind of staffing and how we assess deals and matters going forward might be different. Courtney White: I’d like to talk a little bit about AI ethics. This is a very interesting topic, a lot of people have a lot of opinions on the future of AI because of this ethical component. And so the first question just really is if you could just dive into some of the ethical considerations that people have in the use of AI and business, and potentially the bias that could potentially happen, or is happening already with the usage of AI, the role of an errors with human oversight. Just love to have you know that or just start that discussion? Ashley Carlisle: Yeah, I think this is going to continue to develop, especially in the coming years, we kind of know the big picture right now, which I’ll kind of go over briefly. But there’s gonna be more things that pop out of the woodwork because at the end of the day, AI is still a blackbox. I ask our engineers all the time, many of whom have been working with AI and models since 2008, some 2003. If they know exactly how it’s going to act at a certain time, especially with these large LLM stock, the ones we make but kind of the larger ones. And the reality is no, there’s going to be a ton of companies that pop up in the next few years that kind of dive into that black box and figure out what other ethical things us as lawyers should be considering. But today, I would say cognitive bias is huge. And the crazy thing about bias with AI is technically we could eliminate it but no one’s figured out how to yet. So that’s gonna be one of those processes that we can I know it exists, and we need to be vigilant, but there isn’t a solution to fix it today. But the biases come from two places, which is the technology doesn’t create itself, it is developed by a developer. And unconsciously, just like, you know, when you’re drafting a document, you’re gonna have little quirks in there, whether you know it or not the people under you, the people above, you might see kind of your behavior and like the things you’d like to include, don’t like to include, but you’re not aware of it. And so when you have so many developers, hundreds of thousands of developers and testers working with this AI data, it’s just a multiplication of biases that they’re unaware of. And so they can’t self-identify and self-correct. The other thing is, if you have a lack of data, you can create an inadvertent bias. Also, if you include too much data that’s irrelevant, you can create an inadvertent bias, it really goes to, I think, also, this next generation, there’s going to be a lot of people that just aren’t data stackers and data modelers, a lot of Gen Z and Gen Alpha, or whatever is coming next, they’re just going to be organizing stacks of data for us. So we can know exactly what we’re looking at to the extent we can. And then in regards to human oversight, like you mentioned Art, there’s been a lot of weird, you know, I think even the UN signed a letter about AI, which I read, and I don’t even think they really understand what AI is, but they tried. Silicon Valley, there’s been many different groups that have talked about the role of oversight, we all stand in the same bucket of people need to be looking into this. But no one really knows how that’s going to happen, whether that’s going to be regulations on the federal or state level, whether that’s going to be a consortium of tech companies that fund kind of a governance arm, I think there’s going to be a lot, there’s already a lot of smart people trying to figure out how to solve this. And we’re already seeing in the legal tech space, a lot of companies that are kind of popping up. Basically, governance companies willing to help you identify these issues, identify these red flags and put policies in place. And I know a lot of in house teams are kind of looking to them for guidance, and know that it’s going to be an advisory role for many years, not something we can fix today. I think the last thing I skipped over sorry, which is probably the most important is the privacy concerns, especially with these large LLM models, the ChatGPT, the llamas, there’s going to be hundreds more. There’s already I think 10 big ones. Most of these are training data with your inputs. And so most in house departments will advise people and most law firms have policies, whether informally or formally saying, “Please don’t put our information in these models.” I know you want a cover letter or an email draft from ChatGPT. But like what you put in there, you might not realize this proprietary, even client names, things like that, that might like where they’re located might seem like totally chill to you. But like this is all being captured. And the footprint is there. That is a big concern is also the shadow IT phenomenon of you know, as lawyers, we could tell people what to do and how to do it. But are people going to actually follow directions? As we know that doesn’t always happen. So even if we have the most ironclad privacy policies tell people not to use these things on the back end? How are we going to clean up and advertent proprietary information that’s been put into these models and then scraped by other actors, that’s going to be something that all lawyers are going to be figuring out how to clean up in the next like, decade or so. Courtney White: Right. So everybody’s going to have to understand privacy, at least to a functional level, to serve their client. And then the next question I really have is a little bit more specific regarding we have a Diversity Counseling practice here. And we care about it at our law firm. Have you seen any best practices? Do you know of any, in avoiding bias, specifically, with a lack of diversity within this AI space? We already know it exists within the tech space. And so I would assume that it also exists just generally within AI in the creation of AI and these models. And so I just love to know how that is being addressed. Ashley Carlisle: So I think that is one of the many big things that the Silicon Valley letters were was kind of that’s what the impetus for them being concerned about this. And one thing I will say is ChatGPT didn’t follow the standard development protocol for LLMs. Which is why we don’t have the answers to these questions now. So ChatGPT decided to release its consumer interface without testing it fully on the population or a beta group of the population and knowing how to fix these problems. They just decided, Oh, well the world will help us decide what the problems are. And they even have policies which they have been very self-aware at of saying like, we don’t know what’s going to happen. Please don’t depend on this. Please know that we might accidentally have these biases or maybe we didn’t think things through yet, what have you. The problem is now that it’s already out in the world, the people like Microsoft, who already had been developing the same time, they were forced to release their model when ChatGPT did, but really, they were trying to fight the good fight of let’s test this internally, let’s really think about the biases, let’s really do multiple beta testing, let’s think about these issues of diversity and misinformation and, you know, even regionalized point of views in different areas in different cultures and different languages. And unfortunately, because people were so interested in ChatGPT, and their competitors kind of were like, well, I guess we gotta release ours before we’re done with everything. I don’t think there is an answer. And I think there, like I said, there’s going to be a lot of advisory situations and parallel to the adoption of this. And personally, I’m more conservative, hence why I went to law school. So I’m like, Oh, we should test this and kind of know, what problems are going to create before we unleash it into the world. So I wouldn’t have taken the ChatGPT approach. But I think that’s something that people as they’re using this data, and as they’re analyzing the output should realize that, not that it hasn’t been thought of thoughtfully, but it definitely could be full of misinformation, unintentionally, that could be detrimental to, you know, having points of view or information that reflects the world we live in. Because we don’t know what the developer, the background of the developers, we don’t know how many there are, there are so many things. So in a way, we kind of unfortunately became part of their organization and testing and dealing with this technology and real time like they are. Art Cavazos: Yeah, and you bring up a really interesting point about AI safety and regulation on one hand, and folks who aren’t so concerned with that and want to just push things forward as fast as they can. And kind of let the technology and the market sort it all out. But I wanted to ask you, on the question about, you know, you were speaking about inadvertent bias and that, but what about, for example, there’s some AI chatbots out there that have programmed values. I think some of them refer to it as a constitutional AI or something. And essentially, the idea being that, that you were not inadvertently but actually intentionally placing principles or values into the model to affect the outcome in some way. What are your thoughts on that? And will people start using that to kind of create their own intentionally biased, which could be in a lot of different contexts, like a partisan context, or in various other contexts, where you actually do want, and the goal is to produce a chatbot, that is going to give a certain set of predictable answers that align with a certain set of values? Ashley Carlisle: I mean, so is your question, are people going to use it nefariously? Art Cavazos: Well, will that even be considered nefarious? Or will that be just one use case that people are going to start using it, you know, create their “talking points” Chabot? Ashley Carlisle: I mean, they might I think what’s interesting, too, is people, it’s been very interesting to see how people think that technology is fundamentally changed with ChatGPT, when in reality, it’s just a new interface, the technology, we’re already living in our own algorithms, we’re already living on our own sides of the internet. Even your Google, for example, by Google’s results will not be the same as either of yours, which always is shocking to me, my husband and I, at the end of the day, I always talk about what did your algorithm tell you today, and it is completely different from mine, right? So what you’re saying is, it holds true in the fact that we’ve already been living in our own value sets and our own preferences, and the technology world around us has just showed us what we want to see or what they guess we want to see. And I think that’s why there’s just been so much disconnect and polarization and that, like feeds that that’s a whole other conversation. And I think ChatGPT, maybe it’s just an easier way for people to see how it could go wrong, or how you can create bias information for your own uses. But in reality that kind of already exists. And I think if anything, ChatGPT was just kind of lightning in a bottle that made people more interesting and realizing the world we’re living in, for better or worse. I wish I had a happier answer to that one. Art Cavazos: Yeah, no, I agree. I think I think it’s just going to amplify what people are already doing. Just now you can create an AI generated YouTube video to go along with it and have AI generated social media accounts, pushing it out and write AI generated articles and it just an amplification tool. Ashley Carlisle: And I also think like, kind of segwaying it’s going to be potentially a lot of misinformation and an age of misinformation. So, you know, first amendment defamation attorneys, this might be your decade, I don’t know it’s gonna be an interesting time to kind of parse what is fact and as you know, in a court of law, what is fact? How do you determine it? We’re not the most tech savvy, we’re going to have to increase our tech literacy, probably as lawyers to have that duty of competence to make sure we know what is truth and what is not. It’s going to be a very interesting time potentially. But I think it’ll be more incremental than it will be overnight, which doesn’t solve the problem. It’s still things we need to kind of be vigilant of, but it gives me a little bit of solace that like we’re not gonna have to deal with the world potentially all being fueled by misinformation. Tomorrow, it’ll be probably more incremental and more hidden than we realize, it’s just important to keep that in mind, especially as you’re talking to in a legal context to your clients. Having more data points for what they’re saying or what the information they’re giving, you will probably be more important as well. Courtney White: I’d love to know Ashley, if you have any perspective on how law firms can increase their tech literacy. It seems that law is one of those fields that is very slow to change. So I’d love to know your perspective on that, especially since you’ve worked in a law firm. Ashley Carlisle: Yes, so I would say there are a lot of km professionals, knowledge management professionals that are especially at the big law firms. Obviously, the small to mid-sized law firms have a leaner staff. And typically, they don’t have those departments. But what’s really interesting is the small and mid-sized law firms in the last 20 years have been kind of the most innovative and the test case for technology and the legal industry, because it’s easier to adopt with a smaller set of people, obviously, less opinions, less red tape, the big law firms have kind of been watching small and mid-sized law firms and have seen that they’ve had more adoption with document automation, workflow automation, kind of the low hanging fruit as you will, the main bottleneck right now for tech literacy has been this build versus buy phenomenon. As lawyers, we think we can do everything. And to be honest, we probably could. But is it worth our time? Is it worth our money? You know, you give up something to do something. And I think law firms especially now are in this mode of, well, I don’t want to be want to buy it, I could just build it. And it’s been very interesting phenomenon. It used to be they want to do that for doc automation, you know, they would see doc automation solutions and be like, Oh, this doesn’t impress me, I could just build my own and then it never happened. Then it was workflow automation. Now it’s CLM. Now it’s AI. So I think a big part of the problem is the fact that we are independent thinkers, we are people who are very smart. And to our detriment, we tried to do everything. You know, we consult law firms, legal departments, we give presentations on AI, we go through policies, there are many others like us. And I’m really hoping with the ChatGPT age that more law firms will just dedicate the time to being okay with learning from other people and not being scared to ask for information. But I think at the end of the day, that’s kind of in the DNA of the legal industry. And so as vendors, we’ve had to be very creative or meet people where they are, and just hope for incremental improvements with tech literacy. It’s not that it’s not out there because it is. It’s mainly just, unfortunately, our own neurosis that typically is the proper. Courtney White: We’re natural skeptics. Yes, absolutely. Art Cavazos: Speaking of which, there’s a there’s this kind of ongoing debate that I’ve been skeptical of both sides, if that’s possible. There’s an argument and I’ve made this argument in the past myself about AI that it could do the menial tasks, you know, the tasks that no one wants to do, and kind of free up people to do the more creative work, more strategic work. You were saying earlier that robot lawyers won’t be replacing us anytime soon, you know, you’re still going to need humans to do certain types of work. But also, we’ve seen a lot of these, like DALL·E and other models that can reproduce art work, you know, ChatGPT, and others can do lots of the written word, whether that’s like copywriting or story-writing, you name it. And those are all very creative areas. And those seem to be some of the first places that are being hit, so to speak, by AI and, you know, potentially being replaced by AI. And you saw it with the Hollywood strikes and everything, the reactions that that there have been. So what are your thoughts on that kind of debate about what is AI’s role? And what are people’s role in jobs going forward and kind of this line that sometimes gets drawn between creative or strategic work versus the more menial tasks? Ashley Carlisle: It’s been an interesting conversation that’s continued to evolve, and the thing that I’ve noticed is it totally depends on the personality of the specific lawyer I’m talking to in regards to how they define that creative strategic work right. So I come from a transactional background, I myself naturally before really having this ongoing conversation was like, okay, that would be, you know, I’m gonna have like the most innovative covenants I’m going to be fighting, like for the deals that note, like the points that no one’s getting on every deal, like, I guess that’s what my extra time would allow me to do, right? But in reality, if you ask clients of yours, they don’t really care about that; they would love if you actually would talk with them on the phone a couple times a week. They would love if you were a more active counselor to their business. But I think the problem is, especially on the transactional side, we are so used to kind of being Scriveners of our documents. And that is important, but we forget that we are such a trusted adviser. And I really think that we are going to become more business counselors and talk with our clients a lot more as we start using this technology. And I think for some lawyers, that’s really exciting to them. And I think for some, it’s terrifying because they don’t want to talk, you know. A big thing, as you know, in law school people have to typically pick between this is a generalization, but transaction or litigation, and oftentimes you find them more gregarious people, maybe the drama kids, the people in like law review or whatever those productions will go litigation, and then the more quiet people will go transactional or tax, or what have you, it could be that everyone’s just talking to their client, always everyone’s doing more presentations. I think it really could be a new generation of, and probably a more casual situation for our profession of, we’re probably not going to be wearing suits and be in our ivory tower and instructing people the rules; we’re probably going to be more in the weeds, maybe with like jeans on at their office a couple times a week, being a quasi-member of their team. And I think, for some people, that’s really exciting. Some it’s not, I get it, but at the end of the day, I really think that’s where AI is going to push us into is being more of a conversational role. And I think at the end, it’s going to help because, as you guys see, it annoys me. So I’m sure it annoys, hopefully, everybody. People don’t realize what lawyers do. People think it’s really easy. They oversimplify it because there’s an asymmetry of information. They only deal with us when they’re upset; when they’re upset, they’re not going to be able to remember, like, all the clarifications and basically parenthesis things of our job; they’re only going to remember the emotional parts of it. So they don’t really know or have an accurate view of their experience with us are remember, like all the different things we did for them. As people try to replicate what lawyers do with tech, they’re going to be increasingly disappointed; they’re going to realize that they’re still going to need us; it’s going to give us new business in different ways that we haven’t even realized yet. People just have no idea what we do. So they think it’s so easy. But time and time again, even now we’re getting calls from people being like, Oh, I thought I could replace this. But this is awful. It’s like, yeah, you can’t replace us. I’m sorry. Like we are neurotic, law school was awful. We took the bar; we work way too hard in our profession. No machine can do that. And then also, we’re like looking at all these different issues at one time; you can’t train that type of intent and complex intent into these models. Maybe like an another century, but no time soon is our brand going to be replicated; it’s going to be very average answers. So maybe, for like basic wills, if you don’t have a complicated family structure, maybe ChatGPT would be useful as a starting point in that context. But the majority of law is nuanced. And so it’s really, I think people, like you said, they get skeptical, they get scared of the technology, and maybe how it will change the industry. Because I think it will, but I don’t think it’s going to change in the way that people are thinking it’s going to change. Art Cavazos: So we as a group of lawyers can all agree that lawyers cannot be replaced. And that’s how law is made. Right? I think we just made a law. Courtney White: I think and this is probably just because I love social media. I’d love to know your thoughts on how we can kind of harness AI to beef up our social media presence as lawyers, a lot of lawyers are already using social media to innovatively talk about legal issues, I’d love to know how AI could potentially play a role in that. Ashley Carlisle: So, and I’m, I’m a skeptic on this one. I don’t know if you guys have used these Large Language Models to create content, you know, more marketing content or social media content or what have you. Courtney White: No, but I’ve seen it. Ashley Carlisle: Yep, it’s to me, it’s pretty awful. It’s pretty average, right? With time, it’ll slightly get better, hopefully, unless the model is, the problem with these models too, as the inputs being put in. So the more people that go for the average, awful content, it’ll be the status quo. So I think in some ways, when I talk to friends of mine who want to get more into the personal branding side of things, which I think will be more important, like I said, as the soft skills of law become more important, we will be having to do more of that. And I think we should have for a long time. I think lawyers have this idea that we’re the best kept secret and that people should know how talented we are. And we get upset when people don’t realize it and we forget that we haven’t told the world like, Oh yeah, I do this and this and this and I’m awesome. So I think it’s finally the time that people are going to just tell what they do and how awesome they are, and I’m excited for that. But I think AI is gonna be good in the point of if you’re scared and don’t know where to start. It’ll push you forward, give you an outline, give you ideas, show you resources, be an easier kind of form of Google that’s less intimidating, a better interface. But I really don’t know how much more it’s going to change other than that. Also, maybe if you need graphics, or photos, there are better starting points, like you said, I mean, when I started this job, I had no idea what Sigma, Canva any of these things are that I now use on a daily basis. So perhaps things like that. But at the end of the day, content, contracts, legal documents, the status quo will be loud. But those that rise above the pack, those that do it on their own, will be of even more value than they are today. Because it’s gotta be obvious who’s putting in the work. Art Cavazos: Well, thank you, Ashley. And thank you, everyone, for joining us on this episode of Future-Ready Business. We really did touch on a lot of things today regarding AI. Our producer Greg suggested we talk about some other things, I don’t think we did that. But hopefully he’ll forgive us and post this episode anyway. Ashley, I hope you’ll join us again soon. And I hope you enjoyed it and had a good time. Are you on social media? Where can folks find you on the internet? I’m kind of not. So that’s why I ask. Ashley Carlisle: Yes. Well, thank you so much for having me. And I know we covered a lot of topics. And there’s so much more to cover here. So happy to come back. And to the extent people have any questions about anything that we kind of touched on today, you can feel free to email me my email is ashley@hyperdraft.ai. You can find HyperDraft at our website, hyperdraft.ai. We are currently an invite only platform so you can sign up for updates. And we will let you know kind of what’s going on. And if you have any questions about how we’re helping clients with document or workflow automation, we’d be happy to chat about that. And if you want to follow along, we have some fun events coming up this year. We’re active on all socials at @HyperDraftInc, especially on LinkedIn. And like Courtney said, if you’re not on LinkedIn already, you should be. Only 20% of legal professionals are on there. And it’s a shame. I know when I was in big law, sorry, I’m going to soapbox this. When I was in big law, I didn’t, will go on there. I was really scared to kind of not have a voice. But I was just like, I’m busy. I don’t want to do this. But I think it would have been better just for my professional development. And to figure out what my business development niche was, if I did it incrementally with time as opposed to like as a fifth year six year associate freaking out like, Oh my God, who are my clients going to be? What’s my point of view? Like, how am I going to do this? So I would think of it as more of like, a course that you do for yourself on personal branding as you go along. But yeah, find us on LinkedIn at HyperDraft Inc. Art Cavazos: Thank you. And Courtney, unlike me, you kind of are a big deal online. Where can folks find you on the internet? Courtney White: People can find me on my social media channels @CourthouseCouture. Art Cavazos: Fantastic. And if you liked the show, please rate and review us wherever you listen to your favorite podcasts and share FRB with your friends and colleagues. You can find us, I exaggerated, we do have a @FutureReadyBusiness [account] on Instagram and Threads. And I do have a Twitter account, but I’m still calling it Twitter. So I don’t know if like I’m gonna get kicked off at some point. Courtney White: It’s “X”. Art Cavazos: Yeah, but exactly, so until I get kicked off the platform for continuing to call it “Twitter”, I’m @FinanceLawyer. As mentioned at the top of the show, the opinions expressed today do not necessarily reflect the views of Jackson Walker, its clients, or any of their respective affiliates. This podcast is for informational and entertainment purposes only and does not constitute legal advice. We hope you enjoyed it. Thank you for listening. Courtney White: Thank you. Visit JW.com/future-ready-business-podcast for more episodes. Follow Jackson Walker LLP on LinkedIn, Twitter, Facebook, and Instagram. This podcast is made available by Jackson Walker for informational purposes only, does not constitute legal advice, and is not a substitute for legal advice from qualified counsel. Your use of this podcast does not create an attorney-client relationship between you and Jackson Walker. The facts and results of each case will vary, and no particular result can be guaranteed. In This Story Arturo Cavazos, Jr. Partner, San Antonio Courtney J. White Research Attorney, Dallas Tags Corporate & Securities Technology Artificial Intelligence Houston San Antonio Dallas Recent Navigating the AI Landscape and Revolutionizing Legal Tech Jackson Walker Alumni NewsletterFall 2023 Alumni Spotlight: Randy Bowman Veterans Roderick Faulk and Brian Pettis on Lessons Learned from the US Air Force Benefits Planning for Year End and 2024 Jackson Walker Debuts San Antonio Office’s New Space at 1900 Broadway in the Pearl District Jackson Walker Represents Harmony Housing in Sale of 121 Affordable-Housing Projects Earth, Wind, and Solar: What Are Renewable Energy Rights? More News",
    "originSummary": [
      "AI and predictive analytics play a significant role in the legal tech industry, particularly in streamlining legal work in transactional areas.",
      "It is crucial to understand the limitations of AI and the responsibility of lawyers to read and comprehend legal documents.",
      "While AI is not replacing lawyers, it is streamlining certain processes. Privacy concerns, biases, and the need for human oversight and regulation remain challenges."
    ],
    "commentBody": "",
    "commentSummary": [],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1700142340897
  },
  {
    "title": "AI-Assisted Research: Speeding Up Legal Research with AI on Thomson Reuters' Westlaw Precision",
    "originLink": "https://legal.thomsonreuters.com/blog/legal-research-meets-generative-ai/",
    "originBody": "Artificial Intelligence Introducing AI-Assisted Research: Legal research meets generative AI November 15, 2023 · 5 minute read Share Facebook Twitter Linkedin Email November 15, 2023 · 5 minute read Share Facebook Twitter Linkedin Email Westlaw Precision users are now able to experience state-of-the-art generative artificial intelligence (AI) in legal research. AI-Assisted Research on Westlaw Precision is the first generative AI offering from Thomson Reuters and will help legal professionals find the answers they need faster and with high confidence. “We’ve used AI to serve up editor-created answers for over a decade,” said Erik Lindberg, Senior Director of Westlaw Product Management at Thomson Reuters. “What’s different now is that we’re generating a new response just for your question, rather than retrieving prewritten responses. AI-Assisted Research can generate answers in real-time, reflecting current law across jurisdictions. Researchers can get answers to a far broader array of questions than what we could anticipate with human power alone.” AI-Assisted Research uses a large language model (LLM) that analyzes trusted content on Westlaw to generate answers. The content analyzed includes cases, statutes, and regulations. The LLM also relies heavily on the editorial enhancements the Westlaw attorney-editors add to these primary law sources, which include the West Key Number System, headnotes, and KeyCite. “Our attorney editors have spent nearly 150 years preparing us for generative AI,” Lindberg said. “Because of how they have structured our content and added human interpretation to it – really since the first volume of the National Reporter System – we can quickly and reliably generate an answer to nuanced legal questions supported by authoritative search results.” Running an AI-assisted search The AI-Assisted Research tab will be the default homepage tab for Westlaw Precision users, though you can easily toggle to the Precision Research or other content tabs if you prefer. Once you enter your question and hit “Submit”, the LLM goes to work, along with the retrieval augmented generation (RAG) engine that allows users to understand how the response was generated. First, the tool looks for applicable primary law. The underlying content that is searched is extremely important. Many LLMs use training data as of a certain point in time, and their responses won’t reflect anything that happened after that time. But the law continues to evolve, and because the LLM is relying on Westlaw’s primary law, AI-Assisted Research is constantly taking in and learning from the latest and most relevant law. Once it has selected the relevant documents, it generates a response to your question. “This is incredibly powerful when you’re starting your research,” Lindberg said. “Westlaw is able to tell you what the law is even if that requires information from multiple authorities.” Importantly, the response also includes footnotes so you can see the legal passages that informed the response.Sign up for insights, updates, and all things AI @ Thomson Reuters. More about AI @ Thomson Reuters Validating the response Legal researchers can read through the linked documents to validate the response. This is a tremendous time saver for people who are used to reading through multiple documents and synthesizing an answer themselves. This is not to say that users should rely on the response from Westlaw without double-checking – it’s still incredibly important to read the documents to ensure they do indeed support your position. “Open AI tools like ChatGPT pull from all sorts of sources and often serve up ‘hallucinations’ – responses that sound plausible but are completely false,” Lindberg said. “We avoid that by relying on the trusted content within Westlaw and building in checks and balances that ensure our answers are grounded in good law.” “Westlaw is very different than some of the freely available tools, like ChatGPT,” Lindberg said. ”Those tools are looking to create a chat-like experience that can be great for creative writing. But with legal research, you need accuracy, reliability, and responses that are fully grounded in trusted primary law.” Customers who have tested the new capability agree that AI-Assisted Research provides an important jumpstart in their legal research, especially in areas they aren’t familiar with. They still verify the results, but they spend less time and are less frustrated doing it. “The ability to type a question, get an answer, and have all the supporting resources right underneath that answer so you can ensure it is supported by case law within Westlaw is very important. And I think it’s proven to be a very effective and accurate way to get answers to complex legal questions,” said Andrew Bedigian, Counsel, Larson LLP. Users won’t have to learn much to take advantage of the time savings of AI-Assisted Research. Lindberg does have one tip: you may benefit from adding more detail to your prompt. “Historically our users are quite succinct in their natural language queries – they ask a broad question and sift through the results,” he said. “Now, you can pose a question like you would to a colleague and get a new plain-language response addressing your specific question. You don’t have to learn how to engineer prompts, we’ve done that heavy lifting for you, but you may want to give Westlaw a bit more to work with in your queries.” His other big piece of advice? “No tool can do all of your research for you. No matter what you’re using to understand the law, be sure you’re checking the sources the results come from and using it as a starting point for your research. The real wisdom still comes from the legal professional, not the research system.” ________________________________________________________________________ Learn how you can get a jumpstart on your research with faster answers to legal questions thanks to AI-Assisted Research, now available on Westlaw Precision”. Facebook Twitter Linkedin Email Artificial Intelligence Legal Topics Technology",
    "originSummary": [
      "Thomson Reuters has introduced AI-Assisted Research on its Westlaw Precision platform, leveraging generative artificial intelligence (AI) to aid legal professionals in finding legal answers faster and with more confidence.",
      "The AI system analyzes trusted content on Westlaw, such as cases, statutes, and regulations, to generate real-time answers based on current law across multiple jurisdictions, complete with footnotes for validation.",
      "The feature offers a significant time-saving advantage for legal researchers, particularly in unfamiliar areas of the law, but Thomson Reuters stresses the need to verify the results and cross-check supporting resources for accuracy in legal research."
    ],
    "commentBody": "",
    "commentSummary": [],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1700142340897
  }
]
