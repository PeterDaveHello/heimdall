[
  {
    "title": "Texas Veterans Legal Aid Week to Provide Free Civil Legal Services to Qualified Veterans",
    "originLink": "https://cbsaustin.com/news/local/texas-veterans-legal-aid-week-offers-free-civil-legal-services-to-qualified-veterans-statewide",
    "originBody": "NEWS WEATHER WE ARE AUSTIN SPORTS GAME CENTER WATCH 70 NEWS Local Nation & World Entertainment Offbeat Marshals' Most Wanted Connect to Congress Armstrong Army Strong Inside Your World beyond the podium Spotlight on America Full Measure with Sharyl Attkisson Traffic Crisis in the Classroom ProAdvice Paxton Trial WEATHER Weather Home Radar Maps Cams Weather Alert Days Hurricane Center Allergens Weather Blog Weather App WE ARE AUSTIN We Are Austin Home Road Trippin' My Hometown Sinclair Cares Partner Spotlight SPORTS Sports Home High School College Professional TICKETS GAME CENTER Game Center Home Sudoku Memory Tiles Crossword Tricky Trivia Secret Letter Grand Cipher Flip Wordido Baseball Bash Dart Attack Hit the Spot Hoops Galore Indoor Hoops Galore Outdoor Classic Ten-Pin Bowling Puck Luck Volley CHIME IN STATION Station Home Contact People Careers EEO Terms Copyright Privacy Mobile Apps Contests Schedule Commercial Production Newsletter Sign Up NextGen TV Community Partner Program LAWMAKERS LEGAL Terms & Conditions Copyright Notices EEO Public File Report FCC Info FCC Applications Public File Assistance Contact News Team Careers Contests Privacy Policy Cookie Policy Cookie Preferences ACCESSIBILITY Texas Veterans Legal Aid Week offers free civil legal services to qualified veterans statewide by Allison Miller Mon, November 6th 2023, 1:27 PM UTC Courtesy: CBS Austin File ... Austin, TX — Texas veterans are invited to participate in Texas Veterans Legal Aid Week (TVLAW), a statewide effort in honor of Veterans Day coordinated by the Texas Access to Justice Foundation and legal aid programs across the state. During the week of Nov. 4-11, 2023, legal aid programs, local bar associations, law schools and pro bono private lawyers will provide civil legal services for qualified Texas veterans in various locations throughout the state. The Texas Access to Justice Foundation provided grant funding this year to 13 nonprofit organizations that provide civil legal services to veterans. Last year, legal aid organizations provided legal services to more than 6,300 Texas veterans. A list of in-person and virtual clinics and events throughout the state can be found here. Assistance and referrals are also provided through a statewide hotline for veterans at Texas Legal Services Center, 1-800-622-2520, option 2 or online at https://texaslawhelp.org/ through the live chat feature. Outside of Texas Veterans Legal Aid Week, veterans can receive legal aid assistance year-round at legal aid clinics, both in-person and virtual, across the state. EVENTS: In-person events: Central Texas: American GI Forum Veteran Ask-A-Lawyer Friday, Nov. 3, 10 a.m. – 1 p.m. American GI Forum San Antonio, TX 782054 Contact for more information: 956-718-4618 Veterans Legal Clinic Tuesday, Nov. 7, 10 a.m. - 5 p.m. Good Samaritan Veterans Outreach & Transition Center 202 Connelly St. San Antonio, TX 78203 Contact for more information: 210-764-9119 Veterans Ask at Audie Murphy Wednesday, Nov. 8, 9 a.m. – 12 p.m. VA Audie Murphy 7400 Merton Minter 3rd Floor, Room D302 San Antonio, TX 78229 Contact for more information: 833-329-8752 Military Family Law Matters Information Session Wednesday, Nov. 8, 10 a.m. – 2 p.m. Operation Phantom Support 401 N. 8th St. Killeen, TX 76541 Contact for more information: 713-652-0077 Legal Advice Clinic for Veterans Thursday, Nov. 9, 2 - 5 p.m. Heart of Texas Veterans One Stop 2010 La Salle Ave. Waco, TX 76706 Contact for more information: 254-710-4244 Veterans’ Legal Advice Clinic Friday, Nov. 10, 1 - 4 p.m. St. Philip’s College Good Samaritan Veterans Outreach and Transition Center 202 Connelly St. San Antonio, TX 78203 Contact for more information: 210-678-8100 VA Outpatient Center Monday, Nov. 13, 1:30 - 4 p.m. 7901 Metropolis Dr. Austin, TX 78744 Contact for more information: 512-472-0279 Register online at https://www.austinbar.org/?pg=events. Veterans Ask-A-Lawyer Kerrville Monday, Nov. 13, 10 a.m. - 12 p.m. Kerrville VA Medical Center 3600 Memorial Blvd., 5th floor, Room 522 Kerrville, TX 78028 Contact for more information: 210-212-3740 Register online at https://www.trla.org/get-helpveterans. Virtual events: Vet Week Online Various events Nov. 6 - 10 Register online at https://www.facebook.com/LoneStarLegalAid/. Austin LRS Legal Line Monday, Nov. 7, 5:30 - 7:30 p.m. Contact for more information: 512-472-8303 Lone Star Legal Aid Veteran Outreach Event Wednesday, Nov. 8, 1:30 - 3:30 p.m. Contact for more information: 713-652-0077 Dallas Bar Association Legal Line Wednesday, Nov. 8, 4 - 8 p.m. Register online here. Veterans Virtual Legal Clinic (Midland) Thursday, Nov. 9, 9:30 - 11:30 a.m. Contact for more information: 432-332-1207 Free Veterans Virtual Legal Clinic Thursday, Nov. 9, 9:30 - 11:30 a.m. Contact for more information: 432-332-1207 Veterans Telephone Counsel & Advice Clinic Thursday, Nov. 9, 10 a.m - 2 p.m. Contact for more information: 800-354-1889 extension 1529 Kerr County Family Law Clinic Thursday, Nov. 9, 1 - 4 p.m. Contact for more information: 830-257-4446 Hardin County Family Law Clinic Friday, Nov. 10, 9 a.m. - 12 p.m. Contact for more information: 409-246-2826 Veterans Virtual Legal Clinic (Ector County) Friday, Nov. 10, 9:30 - 11:30 a.m. Contact for more information: (432) 332-1207 Denton County Veterans Legal Clinic Monday, Nov. 13, 5 - 7 p.m. Contact for more information: 940-383-1406 Veterans’ Virtual Legal Advice Clinic San Antonio Legal Services Association Wednesday, Nov. 15, 1:00pm-4:00pm Contact for more information: 210-764-9119 Register online at https://www.sa-lsa.org/veterans/. Texas Access to Justice Foundation BE THE FIRST TO COMMENT The Texas Access to Justice Foundation, created by the Supreme Court of Texas in 1984, is the primary state-based funding source for the provision of civil legal aid in Texas. The organization is committed to the vision that all Texans will have equal access to justice, regardless of their income. The Foundation administers a variety of funding sources, which are earmarked to assist nonprofit organizations in providing legal aid to approximately 100,000 Texas families each year. For more information, please visit: www.teajf.org TRENDING Slots player at Excalibur Las Vegas hits $12.2 million jackpot Beloved French bulldog stolen in broad daylight from Great Hills family home Search underway for mother who abandoned injured infant at Texas hospital, police say One person dead, child injured in early morning crash near COTA Pflugerville Fire Department responded to neighborhood house fire STAY CONNECTED Like Us Follow Us NEWSLETTER SIGN UP /SIGN-UP © 2023 Sinclair, Inc. TermsEEOFCCFCCPrivacy PolicyCookie PolicyCookie Preferences NEWS IN PHOTOS: \"Local\" Beloved French bulldog stolen in broad daylight from Great Hills family home Austin Israeli-American Council hosts March for Israel at Texas State Capitol Rethink35 protests upcoming expansion of I-35 in East Austin One person dead, child injured in early morning crash near COTA Loading ...",
    "originSummary": [
      "The Texas Veterans Legal Aid Week (TVLAW) announces a statewide initiative offering free civil legal assistance to qualified veterans from November 4-11, 2023.",
      "The initiative, spearheaded by The Texas Access to Justice Foundation and numerous legal aid programs, involves collaboration among local bar associations, law schools, and pro bono private lawyers.",
      "The foundation has extended grant funding to 13 nonprofit organizations providing civil legal services to veterans. Information on participating clinics and other relevant details can be found on their website."
    ],
    "commentBody": "",
    "commentSummary": [
      "Texas Veterans Legal Aid Week (TVLAW) is inviting veterans to take part in a state-level initiative to provide free civil legal services from November 4-11, 2023, for eligible veterans.",
      "The initiative, organized by The Texas Access to Justice Foundation in cooperation with numerous legal aid programs, law schools, local bar associations, and pro bono private attorneys, aims to help veterans with civil legal issues.",
      "The foundation has offered grant financing to 13 nonprofit organizations catering the civil legal needs of veterans this year. The list of participating clinics and additional information can be found on their website."
    ],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1699284891961
  },
  {
    "title": "UK's Advancements in Lawtech: AI Tools Aid Lawyers and Contribute to Economic Growth",
    "originLink": "https://thenextweb.com/news/uk-leading-generative-ai-lawtech",
    "originBody": "In times gone by, lawyers would spend hours poring over documents and huge amounts of time and energy on research. But for many of today’s law firms, those days are coming to an end. The landscape is being revolutionised, thanks to exciting new technology and automation. Artificial intelligence tools can now help shoulder the burden of the kind of work that drains lawyers’ time — from reviewing documents and due diligence checks, to drafting legal documents and carrying out legal research. In 2021, Oxford University estimated that around half of all solicitors in England and Wales were using at least one form of AI-assisted lawtech (specialised solutions for the legal sector). And generative AI has the potential to make even greater strides in our legal sector. With the advent of increasingly advanced programmes — like ChatGPT and other large language models — we can see just how much power they have to understand and generate meaningful responses to complex questions. It gives us a tantalising glimpse into the future. Just think of the potential this could offer to law firms when it comes to improving access to legal services — reducing the time and costs from previously labour-intensive work. Lawtech UK The <3 of EU tech The latest rumblings from the EU tech scene, a story from our wise ol' founder Boris, and some questionable AI art. It's free, every week, in your inbox. Sign up now! Each new advancement brings the possibility of faster, smarter, more effective working, freeing up lawyers’ time to focus on the things that really require their expertise. Above all, it’s a real opportunity to make legal services more accessible for the public as they navigate a world of legal rights. That’s a win for law firms, but most of all, it’s a win for those needing their services. So, now we are in a new and exciting phase of experimentation and exploration. It’s a huge area of interest for the Government, and for me as Justice Minister, as we do even more to improve access to legal services for people in this country. In the past decade the UK has quickly become a world-leader in lawtech and we want to help our innovators to continue to grow. In 2019, we set up LawtechUK as an industry-led programme to support the growth of the lawtech industry in the UK. Now in its second phase, and headed up by CodeBase and Legal Geek, it has been a huge success. Backed by £6 million of funding from 2019 up to 2025, it is a cause close to my heart — one I’m incredibly proud of. We’re also helping our lawtechs promote and sell their products in international markets. The Ministry of Justice’s GREAT Legal Services campaign and Department for Business and Trade have helped UK lawtech make business connections across the world — including high-potential markets like Singapore, Australia, and the US. The GREAT campaign promotes a variety of UK legal services, and in the last financial year helped to generate more than £6 million in projected business wins for UK lawyers, and over 60 business leads. Lawtech startups leading the way The sector is going from strength to strength with each new development. Take Harvey AI, which is using natural language processing, machine learning, and data analytics to automate and enhance various aspects of legal work, such as contract analysis, litigation, and regulatory compliance. Genie AI has created a tool for drafting contracts, drawing on extensive data to suggest clauses. And Summize offers legal contract lifecycle management and generates internal summaries of contracts to assist lawyers. RobinAI has created a machine learning model using data from over 4 million legal documents, enabling users to draft and negotiate contacts as much as 80% faster while saving people up to 75% of their legal fees. And Legl has integrate a generative AI layer to enhance client due diligence, reducing complexity, and speeding up the collection of information to reduce the amount of data to be assessed by professionals. The benefits extend far beyond more efficient legal services. A report from the Solicitors Regulation Authority estimated that AI could add as much as £630 billion to the economy by 2035. And it could create upwards of 14 million new jobs by 2027, as more firms bring in tech specialists and upskill teams — so collaboration and support for businesses really is key. Isambard-AI It’s why we’re investing in a world-leading AI Research Resource in Bristol, backed by a £900 million fund, to turbocharge scientific discovery and keep the UK at the forefront of AI development. The Isambard-AI cluster will be one of the most powerful supercomputers in Europe, helping industry experts and researchers harness the game-changing potential of AI. But amid all this growth and innovation, we have to consider risk if we’re to fully capitalise on the benefits of generative AI. We need appropriate regulation that allows innovation while protecting users. We also need transparency in the systems we create, because if we can’t understand how a decision has been made, how can we explain it or trust it in our services? And we need reliable data to draw from and to avoid the risk of bias and discrimination, so that users feel safe to manage information in line with GDPR and data privacy regulation. Supporting startups in navigating regulation The Government is fully behind this work, identifying AI as one of five critical technologies essential for making the UK a global science and technology superpower. Just last month, LawtechUK brought together lawyers, technologists, regulators, and other experts to explore what generative AI means for the legal sector and how it can benefit consumers of legal services. They are now leading on work to understand how this technology is being used across the country, mapping out areas of work to improve collaboration and truly grasp its potential. And LawtechUK’s Regulatory Response Unit is bringing together regulators into a single, fast response forum to support startups navigating the regulatory landscape. And that’s not all. The new Office for Artificial Intelligence is developing a pro-innovation regulatory framework to address risk without stifling growth. This will be underpinned by five principles which guide and inform the responsible development and use of AI. Ethically future-proofing legal services Ultimately all innovation carries risk, and Generative AI raises many ethical, social, and practical concerns. But it’s a risk we’re determined to manage. That’s why our Frontier AI Taskforce is helping evaluate the risks of AI, and the UK hosted a global AI Safety Summit last week. What we can’t risk is our world class legal services sector getting left behind as others surge forward on the rising tide of AI. By gripping the issues, and encouraging safe adoption — we can future-proof our legal services without compromising on ethics, accuracy, and quality. And as a long-standing legal services world leader, there’s no place we’d rather be than leading the charge on this exciting new lawtech. Also tagged with UK AI STARTUPS Published November 6, 2023 - 3:05 pm UTC Back to top STORY BY Mike Freer Popular articles 1 New erotic roleplaying chatbots promise to indulge your sexual fantasies 2 UK plan to lead in generative AI ‘unrealistic,’ say Cambridge researchers 3 New AI tool could make future vaccines ‘variant-proof,’ researchers say 4 3D-printed stem cells could help treat brain injuries 5 New technique makes AI hallucinations wake up and face reality",
    "originSummary": [
      "Lawyers in England and Wales are increasingly utilizing AI tools for tasks such as document reviews, due diligence checks, and drafting legal documents, improving accessibility and speed of services.",
      "In 2021, Oxford University estimated approximately half of all attorneys in these regions took advantage of AI-enhanced lawtech, supported by initiatives like Lawtech UK, established in 2019 with a £6 million fund.",
      "Though AI could potentially contribute £630 billion to the UK economy by 2035 and create 14 million jobs by 2027, the government acknowledges the necessity for a regulatory framework to ensure innovation without compromising user protection and data privacy."
    ],
    "commentBody": "",
    "commentSummary": [
      "Lawyers in England and Wales are extensively using artificial intelligence (AI) tools for tasks like document reviews, due diligence checks, and drafting of legal documents. As of 2021, around half of all solicitors in these regions used AI-assisted law technology.",
      "Lawtech UK, a body established in 2019 to support the growth of the lawtech industry, has a £6 million fund. AI is projected to contribute £630 billion to the UK economy by 2035 and create 14 million new jobs by 2027.",
      "While AI use increases in the legal sector and benefits the economy, the government acknowledges the importance of a regulatory framework that balances innovation and user protection as well as data privacy."
    ],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1699284891961
  },
  {
    "title": "The Legal Landscape of AI: Big Tech Face Lawsuits Over Copyrighted Material Usage in AI Training",
    "originLink": "https://nymag.com/intelligencer/2023/11/how-big-tech-companies-really-think-about-ai.html",
    "originBody": "SCREEN TIME 9:30 A.M. How Big Tech Companies Really Think About AI By John Herrman Photo-Illustration: Intelligencer; Photo: David Paul Morris/Bloomberg via Getty Images If you’re a big generative AI company, that means you’re currently in the process of getting sued, vigorously and by multiple parties at once. Multiple groups of authors, one with the Authors Guild, have filed suit against OpenAI and Meta for training their models on copyrighted material. Alphabet has been accused in a class action of “mass theft” and of scraping “everything ever created and shared on the internet by hundreds of millions of Americans.” Visual artists have filed suit against Midjourney and Stability AI; Stability AI is also the defendant in a lawsuit filed by Getty Images, which claims the company’s model was trained, without permission, on millions of its photos. Anthropic is being sued by record labels over lyrics. Microsoft is getting sued by anonymous software developers over a coding tool in GitHub. These lawsuits vary in scope and seriousness and collectively touch on not just copyright but, from various legal and ethical angles, questions of privacy and consent. They’re sort of all over the place, but with good reason: This is new territory, and it’s not yet clear how existing laws and legal precedents relate to technologies that, to the plaintiffs and lots of other people, seem like they might be built on a foundation of theft and for something like copying. A lot of their claims will likely be dismissed, and some of these suits have already been pared down. Mauricio Uribe, a partner at law firm Knobbe Martens, describes this early round of suits filed against OpenAI, Google, and Microsoft as akin to “seeing the undercard of the prize fight” — the type of suit that will eventually help settle what are still emerging as the core legal questions about generative AI, like whether training models on millions of pieces of copyrighted material is protected, as companies like OpenAI claim, by fair use. The courts can have fun with questions like that. In the meantime, we can have fun learning something else. Tech companies have responded to most of these lawsuits with filings of their own — mostly motions to dismiss — that contain not just legal arguments but full-throated defenses, on behalf of their clients, of generative AI as a project and as an industry. For the most part, Uribe says, these are “completely extraneous to legal questions.” But they’re also kind of wild, revealing how these companies talk about AI when threatened or when there’s money on the line. Take Google, whose lawyers set up a motion to dismiss like this: Generative artificial intelligence (“AI”) holds perhaps unprecedented promise to advance the human condition. It is already beginning to revolutionize the way we use technology, serving as a companion that can help research, summarize, and synthesize information; brainstorm ideas; write original creative or factual text and software code; and create images, videos, and music. It will open doors to new insights and forms of expression, as well as better, personalized help and advice in areas such as education, health care, government services, and business productivity. The plaintiff’s “383-paragraph anti-AI polemic,” Google’s lawyers say, “would take a sledgehammer not just to Google’s services but to the very idea of generative AI,” i.e., that thing that we’ve just been told will advance the human condition. “To realize the promise of this technology,” they say, “generative AI models must learn a great deal,” and like “a human mind” they require “a great deal of training” to do so, concluding that “using publicly available information to learn is not stealing.” Google routinely makes pretty bold public claims about AI. In a September letter, CEO Sundar Pichai said it would be “the biggest technological shift we see in our lifetimes.” But the company tends to make these claims in the passive voice, with lots of caveats about safety, caution, and its “collaborative” openness to regulation, with an obligatory nod to not getting things wrong and minimizing harm. In legal filings, instead, we get an unqualified argument: AI is important, maybe the most important thing in the world; Google must be allowed to do what it’s doing to help AI realize its potential. Stability AI, in its response to a lawsuit by visual artists, takes a similar approach and suggests that it is at the forefront of an industry that is “rapidly expanding the boundaries of human creativity and capability.” Who would want to get in the way of something like that? OpenAI’s lawyers open a motion to dismiss with a litany of other people’s words. “While the technology is still in its early days, some commentators believe that in the future, it may help to remedy ‘some of the world’s worst inequities,’ from unequal access to health care, to global educational disparities, and beyond,” the lawyers write. (The aforementioned “commentator” is Bill Gates.) “Others suggest that ChatGPT, in particular, ‘Heralds an Intellectual Revolution,’ representing an innovation whose significance may ultimately prove comparable to ‘the invention of printing.’” (These “others” are Henry Kissinger and Eric Schmidt.) Microsoft’s lawyers begin by mounting an argument that using AI is part of “GitHub and Microsoft’s ongoing dedication and commitment to the profound human project” of open-source software. Meta’s lawyers are a bit less dramatic, but they’re also up to something interesting. In their motion to dismiss a copyright case, they describe LLaMa, the company’s large language model, in humanizing terms. “Just as a child learns language (words, grammar, syntax, sentence structure) by hearing everyday speech, bedtime stories, songs on the radio, and so on,” the lawyers write, “LLaMA ‘learned’ language by being exposed — through ‘training’ — to ‘massive amounts of text from various sources,’ such as code, webpages, and books, in 20 languages.” This is, again, not legally relevant to the lawsuit. But, in addition to being sort of funny — I’m not sure that “just as” really carries us from a child’s “bedtime stories” to “massive amounts of text” in “20 languages” — this frames the debate over AI in a specific and perhaps useful way, casting models as innocent, curious, independent beings that simply want to learn, and positioning their creators as mere helpers in an intuitive, inevitable process of apprehension — as parents who want the best for their young … entities? Not as software and advertising companies fighting over what they’re allowed to do in service of creating and monetizing new software. You wouldn’t sue a child for humming a song, would you? Would you? None of this tells us much about the legal questions at hand, and judges will know to ignore it. These setups are followed mostly by aggressive legal argumentation calling into question every single premise of the plaintiffs’ claims, which is what the tech companies’ lawyers were hired to do: Of course training AI is fair use! Of course its outputs are transformative! Who are you to even take issue, here? Etc. What these arguments do provide is a glimpse into the future of how AI companies will talk about themselves. Leaders at Google, Microsoft, Meta, and especially OpenAI have enjoyed, over the last couple of years, the benefit of speaking theoretically. Most people in the world don’t have much, if any, direct experience with state-of-the-art AI tools; those that do have encountered them mostly in the context of demonstration, or as small features in software they already use. Figures like Sam Altman and Sundar Pichai have been relatively free to pontificate about what AI is and what it can do; they’re quite comfortable conceding potential harms or talking about responsibility and stewardship in the present and future tenses. They go out of their way to sound not just optimistic but cautious, generous, and humble about the future of AI and their parts in it. They do this because it’s good marketing. But they also do this because it’s easy. They’re not answering for specific, urgent grievances, but rather posing and responding to questions about how they plan to prevent the apocalypse. They’re not responding to public outcry. They’re not dealing with criticism — or even regulations — that cause them much worry, yet. But they will. And when they do, they’ll probably sound more like they already do in court, in addressing alleged past harms — copyright violation, theft, indiscriminate scraping — in addition to concerns about materially specific future harms: self-important, indignant, and shrill. They’ll have to defend what they’re doing, not just what they say they want to do, to regulators and eventually to a collective plaintiff, i.e., the public. And they might sound a little bit ridiculous. MORE SCREEN TIME What Happens When Ads Generate Themselves? Spotify Is Eating the Entire Music Business Is X (Formerly Twitter) Worth $1? SEE ALL SIGN UP FOR THE INTELLIGENCER NEWSLETTER Daily news about the politics, business, and technology shaping our world. Email TAGS: SCREEN TIME ARTIFICIAL INTELLIGENCE META GOOGLE MORE LEAVE A COMMENT",
    "originSummary": [
      "Big tech firms including OpenAI, Meta, Alphabet, and Microsoft are facing legal challenges for allegedly training their AI models on copyrighted content without consent.",
      "The lawsuits have highlighted concerns about copyright, privacy, and consent, suggesting that these companies' technologies could be built upon unauthorized usage.",
      "The implicated tech companies have defended by asserting AI's potential to improve human life, arguing their actions fall under fair use. These lawsuits are predicted to impact future legal rulings concerning generative AI and copyright."
    ],
    "commentBody": "",
    "commentSummary": [
      "Major tech companies including OpenAI, Meta, Alphabet, and Microsoft are facing lawsuits for allegedly training their AI models on copyrighted content without consent.",
      "These lawsuits highlight issues of copyright, privacy, and consent, with plaintiffs implying that the technologic foundations of these companies may rely on unauthorized duplication or theft.",
      "In defense, these tech companies contend in court that AI has the potential to better human condition, hence their actions should be seen as fair use. These lawsuits could impact the future legal framework for generative AI and copyright issues."
    ],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1699284891961
  },
  {
    "title": "New Measures to Limit Employer's Use of AI in California: Impact on Recruitment and Performance Evaluation",
    "originLink": "https://www.sandiegouniontribune.com/business/story/2023-11-06/ai-law-and-the-workplace-also-why-cas-measure-on-caste-discrimination-was-vetoed",
    "originBody": "(The San Diego Union-Tribune ) In the coming year, Californians may see state legislators and regulators develop binding measures that limit how employers may use AI BY DAN EATON NOV. 6, 2023 4 AM PT Facebook Twitter Show more sharing options Any Law at Work column offers only a snapshot of the state of the law of the topic addressed when the column runs. The very title of the column implies the constant motion of the law of the workplace. Today’s column addresses legal developments in issues addressed in columns earlier this year. Artificial intelligence On Sept. 21 the U.S. Equal Employment Opportunity Commission (EEOC) adopted its 2024-2028 strategic enforcement plan. As in the draft of the plan on which this column previously focused, the EEOC explicitly recognizes employers’ increasing use of artificial intelligence, or AI, especially in targeting job advertisements, recruiting applicants, and deciding whom to hire. ADVERTISEMENT To combat “technology-related employment discrimination,” the EEOC says it will “focus on employment decisions, practices, or policies in which covered entities’ use of technology contributes to discrimination based on a protected characteristic. These may include, for example, the use of software that incorporates algorithmic decision-making or machine learning, including artificial intelligence; use of automated recruitment, selection, or production and performance management tools; or other existing or emerging technological tools used in employment decisions.” On Oct. 30 President Joe Biden issued a wide-ranging executive order addressing the development and use of AI as it affects everything from commerce to employment to national security. The president’s statement of eight principles that will guide policy development says in part that AI should not be deployed in the workplace “in ways that undermine rights, worsen job quality, encourage undue worker surveillance, lessen market competition, introduce new health and safety risks, or cause harmful labor-force disruptions.” The president’s order gives the secretary of labor 180 days to work with other agencies and other stakeholders to “develop and publish principles and best practices for employers that could be used to mitigate AI’s potential harms to employees’ well-being and maximize its potential benefits.” Best practices do not have the force of law, but may influence how courts apply existing law to novel factual scenarios involving AI and may shape later federal or state AI-related regulation and legislation. The president ordered workplace AI best practices to address, at minimum, specific steps employers should consider taking to address: How AI may displace jobs and create career opportunities, and its use in evaluating applicants and workers; The implications of AI in employer compliance with rules related to labor standards, protected worker activity such as whistleblowing and union organizing, compensation, and workplace health and safety; and The implications of the use of AI to collect and use data about workers. The order directs the Department of Labor and other federal agencies to consider turning these best practices once developed into guidelines for the programs under their jurisdiction. The order also directs the secretary of labor to issue guidance to employers that use AI to “monitor or augment” employee work in how to use AI without violating federal law requiring employees to be compensated for all hours worked. In the coming year, Californians may see state legislators and regulators develop binding measures that limit how employers may use AI. Such measures may draw on the work Gov. Gavin Newsom has directed all state agencies to undertake in his Sept. 6 executive order to study the development, use and risks of generative AI within state government. Caste discrimination measure vetoed In May, the column focused on SB 403, then pending in the state legislature, which would have outlawed caste discrimination under the California Fair Employment & Housing Act. In that column, I wrote “It is hard to see what a separate claim of caste discrimination in employment will add to a claim of race discrimination or even national origin discrimination asserted by those not of South Asian descent.” On Oct. 7, Newsom vetoed the measure. In his veto message, Newsom wrote: “California already prohibits discrimination based on sex, race, color, religion, ancestry, national origin, disability, gender identity, sexual orientation, and other characteristics, and state law specifies that these civil rights protections shall be liberally construed. Because discrimination based on caste is already prohibited under these existing categories, this bill is unnecessary.” The measure’s sponsor, state Sen. Aisha Wahab, responded to the veto by saying “I’ll continue to fight to balance power and support vulnerable Californians.” It is unclear whether this means if Wahab, a Democrat, will reintroduce the measure. Until then, the courts may determine whether caste discrimination is indeed prohibited by existing law, illuminating the law at work. Dan Eaton is a partner with the San Diego law firm of Seltzer Caplan McMahon Vitek where his practice focuses on defending and advising employers. He also is an instructor at the San Diego State University Fowler College of Business where he teaches classes in business ethics and employment law. He may be reached at eaton@scmv.com.",
    "originSummary": [
      "In the next year, Californians may see measures restricting the use of AI in workplaces, following adoption of a strategic enforcement plan by the US Equal Employment Opportunity Commission and an executive order by President Joe Biden.",
      "These initiatives aim to counter potential misuse and discrimination in AI applications, such as in recruitment and performance evaluation. While they don't hold legal power, they could shape how courts interpret laws in situations involving AI.",
      "The executive order requests the creation of best practices focusing on AI's potential effects on jobs, adherence to labor standards, and employee data collection. Once established, these practices could evolve into guidelines for federal agencies' programs."
    ],
    "commentBody": "",
    "commentSummary": [
      "The US Equal Employment Opportunity Commission and President Joe Biden are taking measures to control possible abuses and discrimination arising from AI use in workplaces, especially within recruitment and performance evaluation processes.",
      "While these measures do not have the legislative force, they could reshape court's interpretation of existing rules in situations involving AI.",
      "The executive order orders the development of specific best practices regarding AI’s potential effect on jobs, labor standards compliance, and data collection on employees which, once established, could form guidelines for federal agency programs."
    ],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1699284891961
  },
  {
    "title": "Biden's Executive Order Aims to Ensure Safe and Trustworthy AI, Balancing Innovation with Regulation",
    "originLink": "https://www.law360.com/technology/articles/1740242/white-house-ai-order-balances-innovation-and-regulation",
    "originBody": "Toggle Dropdown Sign In INTELLECTUAL PROPERTY SECURITIES BANKRUPTCY COMPETITION EMPLOYMENT WHITE COLLAR LEGAL INDUSTRY ACCESS TO JUSTICE LAW360 UK PULSE || SEE ALL SECTIONS || TAKE A FREE TRIAL ADVERTISEMENT Don't want ads? Subscribe or login now. Expert Analysis White House AI Order Balances Innovation And Regulation By Kristen Logan and Martin Zoltick (November 6, 2023, 8:37 AM EST) -- On Oct. 30, President Joe Biden issued an executive order on safe, secure and trustworthy artificial intelligence. [1]. . . Law360 is on it, so you are, too. A Law360 subscription puts you at the center of fast-moving legal issues, trends and developments so you can act with speed and confidence. Over 200 articles are published daily across more than 60 topics, industries, practice areas and jurisdictions. A Law360 subscription includes features such as Daily newsletters Expert analysis Mobile app Advanced search Judge information Real-time alerts 450K+ searchable archived articles And more! Experience Law360 today with a free 7-day trial. Start Free Trial Already a subscriber? Click here to login ADVERTISEMENT Related Sections Aerospace & Defense Compliance Consumer Protection Cybersecurity & Privacy Health Intellectual Property Public Policy Technology Transportation Law Firms Rothwell Figg Companies Amazon.com Inc. Google LLC Meta Platforms Inc. Government Agencies Federal Trade Commission National Institute of Standards and Technology U.S. Copyright Office U.S. Patent and Trademark Office ADVERTISEMENT Ask a question! © 2023, Portfolio Media, Inc.AboutContact UsLegal JobsAdvertise with Law360Careers at Law360TermsPrivacy PolicyCookie SettingsAd ChoicesHelpSite MapResource LibraryLaw360 Company × Already have access? Click here to login Start your free 7-day trial To continue reading, fill out the form below to activate a free 7-day trial of Law360. Email (NOTE: Free email domains not supported) First Name Last Name Job Title Password (at least 8 characters required) Confirm Password Get the best of Law360 in your inbox Select at least one primary interest below to receive curated, daily newsletters designed by senior editors so you can quickly scan the latest news and analysis in your area of practice. Aerospace & Defense Compliance Consumer Protection Cybersecurity & Privacy Health Intellectual Property Show all interests Law360 may contact you in your professional capacity with information about our other products, services and events that we believe may be of interest. You’ll be able to update your communication preferences via the unsubscribe link provided within our communications. We take your privacy seriously. Please see our Privacy Policy. Start Free Trial",
    "originSummary": [
      "On October 30, President Joe Biden issues an executive order focusing on the safety, security, and trustworthiness of artificial intelligence (AI), aiming to strike a balance between innovation and regulation.",
      "Law360 is providing an analysis of this order, giving daily insights on legal issues, trends and developments related to this domain.",
      "This executive order emphasizes the importance of AI regulation and innovation, indicating the current administration's stance towards technology and its potential societal impacts."
    ],
    "commentBody": "",
    "commentSummary": [
      "On October 30, President Joe Biden issued an executive order focusing on the safe, secure, and trustworthy implementation of artificial intelligence, aimed at maintaining a balance between innovation and regulation.",
      "The analysis of this executive order is being provided by Law360, a platform that provides daily updates on legal issues, trends, and developments.",
      "This executive order highlights the growing importance and attention given to ensuring the safety and trustworthiness of AI technologies by the government."
    ],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1699284891961
  },
  {
    "title": "Texas Veterans to Receive Free Legal Aid on Veterans Day Courtesy of Nonprofits",
    "originLink": "https://cw39.com/news/texas/texas-veterans-receive-free-legal-aid-this-week/",
    "originBody": "SHARE HOUSTON (KIAH)– Texas veterans will receive legal aid this week in honor of Veterans day this weekend thanks to the Texas Access to Justice Foundation and legal aid programs. Throughout November 11, legal aid programs will be available for free. The Texas Access to Justice Foundation provided grant funding to 13 nonprofit organizations this year. Last year, legal aid organizations provided legal services to over 6,300 Texas veterans. If you’re a veteran in need of legal services , you can find a list of in-person and virtual clinics and events throughout Texas here. Legal aid assistance is still offered year-round at legal aid clinics across the state. Here is the list of events for the rest of this week: Tuesday, Nov. 7, 8 a.m. – 4 p.m. DeBakey Medical Center – Veterans Administration Hospital MOST READ: 2 people found dead in car outside Greenspoint apartments, HPD says Room 6C-105 2002 Holcombe Blvd. Houston, TX 77030 Contact for more information: 713-652-0077 MOST READ: Several people hurt by gunfire at pasture party for Prairie View A&M homecoming Walkup Clinic at Combined Arms Beacon Law Legal and Lone Star Legal Aid Wednesday, Nov. 8, 9 a.m. – 12 p.m. Combined Arms MOST READ: Fatal auto-pedestrian crash shuts down part of eastbound 610 Loop in Houston 2929 McKinney St. Houston, TX 77003 Contact for more information: 832-983-1139 Red, White and You Job Fair MOST READ: Several people hurt by gunfire at pasture party for Prairie View A&M homecoming Thursday, Nov. 9, 9 a.m. – 2 p.m. Workforce Solutions 4424 North Fwy Houston, TX 77022 MOST READ: Remarkable Woman Contact for more information: 713-243-6692 Suggest a Correction Copyright 2023 Nexstar Media Inc. All rights reserved. This material may not be published, broadcast, rewritten, or redistributed. CCPA Notice SPONSORED CONTENT Privacy Policy This Serum Went Viral and Sold Out On Amazon (In 2 Days) BrunchesNCrunches California Pharmacies Hate When Seniors Discover These $20 Hearing Aids $20 Hearing AidsSearch Ads Learn More Learn More About Early Signs & Symptoms Of Multiple Myeloma SearchFavoritesSearch Ads Options That Might Help Against Diabetes Yahoo! Search McAfee License Renewal Notice McAfee.com Click Here I Feng Shui'd My Bedroom With The Bed, By Thuma Thuma Learn More California Find The Cost of Full Mouth Dental Implants In 2023 Full Mouth Dental Implants What if WW1 had split the U.S. into many tiny states? Game simulates alternative history Historical Strategy Game Play Now Odd Trick That Gets Rid Of Dust (You'll Wish You Tried It Sooner) Clarifion Read More What if WW1 had never happened? Game simulates historical scenarios Historical Strategy Game Play Now Game shows alternate WW2 endings Grand Historic Strategy Simulation Play Now Method Discovered By Accident Relieves Ringing Ears (Watch Now) Experts In HealthRinging Ears Learn More ✕ READ NEXT > 2 people found dead in car outside Greenspoint apartments, HPD says READ NEXT > Next story ✕ ✕ READ NEXT > 2 people found dead in car outside Greenspoint apartments, HPD says Next story in 5 Cancel READ NEXT > Next story in 5 Cancel",
    "originSummary": [
      "The Texas Access to Justice Foundation and legal aid programs will provide free legal aid to Texas veterans on November 11, to commemorate Veterans Day.",
      "The foundation has provided grants to 13 nonprofit organizations geared towards this initiative in the current year.",
      "These organizations, which helped over 6,300 veterans last year, will continue their services throughout the year at various legal aid clinics across Texas."
    ],
    "commentBody": "",
    "commentSummary": [
      "On Veterans Day, November 11, Texas veterans will receive free legal assistance, made possible by the Texas Access to Justice Foundation and various legal aid programs.",
      "The Texas Access to Justice Foundation has given grants to 13 nonprofit organizations this year to bolster this initiative.",
      "During the last year, more than 6,300 Texas veterans benefited from these services, which will be sustained all year-round at legal aid clinics state-wide."
    ],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1699284891961
  },
  {
    "title": "EU Regulations to Address AI's Impact on Copyright Laws Amid Artists' Concerns",
    "originLink": "https://english.elpais.com/culture/2023-11-06/artificial-intelligence-clashes-with-copyright-is-it-stealing-thousands-of-protected-creations.html",
    "originBody": "ARTIFICIAL INTELLIGENCE Artificial intelligence clashes with copyright: Is it stealing thousands of protected creations? More and more artists have denounced that this technology is absorbing their works — without authorization — to learn how to imitate them. Meanwhile, the EU is preparing new regulations surrounding AI, as the U.N. held its first conference on the matter A protest organized by the Screen Writers’ Guild in Hollywood, in mid-October. MARIO TAMA (GETTY IMAGES/AFP) TOMMASO KOCHCAIO RUVENAL Madrid - NOV 06, 2023 - 16:11 CET The human brain never stops thinking, even during the most mundane moments of life. But every once in a while, in someone’s head, a special light bulb clicks on. Years ago, as an example, the mind of George R. R. Martin conceived a story of dragons, ice and betrayal, capable of enchanting millions of readers. This was an idea, a work of art, a talent… culture, essentially. And culture is considered to be so important for a society that it’s vehemently protected with copyright law, so that the creators of this culture are properly credited and compensated. These regulations are also meant to protect — in theory — other individuals from stealing or copying said cultural material. But in practice today, intellectual property faces a colossal threat that legislators of the past couldn’t have imagined: artificial intelligence (AI). Several artists have complained — either via public statements or through the courts — about the massive theft of their work, so that machines can be trained to imitate creators. Actor Stephen Fry recently shared his indignant astonishment at a documentary that used his voice, with phrases that he had never recorded. Scarlett Johansson has taken legal action against an application that used her image and name for an advertisement, without even asking for her permission. It turns out that the future –—with all its opportunities and dark clouds — is already here. One of the pillars of the strikes organized by the Writers Guild and the Screen Actors Guild has been the issue of AI. Meanwhile, two weeks ago, UNESCO held its first conference on the impact of AI in the world of cinema. Similarly, the EU is preparing a series of regulations that are scheduled to come into force between 2024 and 2025, which are intended to make this technology fairer, including in the creative field. A question increasingly hovers over workshops, studios and parliaments: is AI robbing artists of their work? Scarlett Johansson before a screening of 'Avengers: Infinity War,' in 2018. GETTY (FILMMAGIC) History, in some way, is repeating itself. In the past, the appearance of the internet drew tens of millions of viewers around the planet, while also offering a world of opportunities to the arts. But, at the same time, the number one public enemy of the last decades emerged as a result: piracy. This isn’t just about culture. The dangers to the privacy, stability, or even health of citizens is of such concern that President Joe Biden recently resorted to a law from the era of the Korean War (1950-1953) to force technology companies to notify the American government about any advancement that poses a “serious risk to national security.” The dilemmas affect everything from the running of the White House to the day-to-day life of any household. The concerns and complaints in the field of copyright don’t stop multiplying. “[This widespread occurrence] cannot be described as theft. Generative AI systems draw on pre-existing texts and images to learn to produce their own. If [the materials are] protected by intellectual property rights, their use may require authorization. What the authors are denouncing is that they didn’t give permission [to the AI systems],” explains José María Méndez, a lawyer at Baker McKenzie who’s an expert in the sector. He insists, however, on distinguishing each incident on a case-by-case basis. David Fuentes Lahoz — a lawyer specializing in intellectual property at Bird & Bird — seconds this. ”The correct thing would be to talk about a potential infringement of intellectual property rights.” This results in an economic benefit only for the companies that own these programs, while the artists don’t even get the crumbs. Both experts also mention another possible risk: that the works generated in such a manner actually represent plagiarism. Roundtable during the first UNESCO conference on the impact of AI in cinema, in Paris, on October 19, 2023. EDGAR SAPIÑA (EFE) Iban García del Blanco — a socialist member of the European Parliament for Spain, who is involved in the preparation of the EU regulations on AI — has spoken about the evasion of the law when it comes to AI. While he acknowledges that this is a matter of interpretation, he has pointed out that the European copyright directive — approved in 2019 — does permit data mining and the use of licensed content without authorization, but only for scientific research and development. García del Blanco has denounced the fact that generative AI often tries to hide under this umbrella term. “We’re facing the exploitation of rights of owners, [via the] use of a standard that wasn’t designed for [this purpose].” He has suggested that the European Commission issue an official clarification on the matter, or even modify the article in question. At the same time, future EU regulations want to register generative AI systems and require maximum transparency regarding what data they use, how much they use and how they use it. This is key so that creators can claim their piece of the pie — including the one that big tech firms have already eaten. Brussels is also considering an explicit notice that accompanies any work not created by humans, to distinguish them and avoid deepfakes (modifications made by AI based on videos or real images). Keanu Reeves has thrown credibility to this initiative: the actor is already signing contracts in which he vetoes being subject to digital touch-ups. There’s also another front in this battle — perhaps the most devilish one. Once trained, the machines are ready to generate their own cultural offerings. And, therefore, they compete with the same artists whose work they have been swallowing up. First they steal the creations… then, they steal the audience. “They could have used millions of works [that are already available] in the public domain, but they choose to work with the current ones. It’s evident that [these tech companies] want to compete in the market,” García del Blanco sums up. That’s exactly why the Screen Writers’ Guild got the studios to commit to limiting the role of this technology in the writing of movies. The current actors’ strike is also putting forward the proposal to limit the use of AI in the filming of movies. Companies that want to generate culture through AI may also find themselves facing a specific problem, according to lawyer Fuentes Lahoz: “To speak of copyright, [a creation] must be the result of at least one person. If said [creation] came substantially or exclusively from an artificial intelligence system, copyright protection could hardly be recognized. Hence, the spread of [certain creations] that lack authorial protection could occur.” “Let’s think about a company that decides to invest millions of [dollars] into a system that creates songs. These [productions] could be free of copyright and, therefore, the company wouldn’t have the right to object to the unauthorized use of said music.” An exhibition at the Center for Contemporary Culture of Barcelona (CCCB), led by the Barcelona Supercomputing Center. It’s about the history, creative possibilities and ethical and legislative challenges of AI. GIANLUCA BATTISTA “There’s something that’s glaringly absent from texts generated by AI: the soul that is born from desires, hope, pain, violence. The machine has none of that… [All you can do] is teach it to simulate [those things],” explains writer Lorenzo Silva. He — along with many other storytellers — aren’t so concerned about competing with works created by AI, which they consider to be “empty.” Rather, they take issue with the use of their books to train these systems. The novelist Javier Sierra adds: “Perhaps it is easier to copy novels from a genre that follows a structure — such as detective stories or romances — but, in general, books written by AI will cause discomfort in their readers, due to the feeling that they’re always reading the same thing.” Identity theft, professional replacement and precariousness are all fears that have shaken up the cultural sector. Just look at the number of promotional campaigns that already save on commissioning an illustrator, as the machines draw for free. A movement among photographers is encouraging all professionals to make explicit in each image that they prohibit its use for AI. More and more groups — from the plastic arts to the publishing industry — are loudly demanding compensation and justice. Obviously, the arts always draw on past influences. For instance, every author recommends reading a lot before facing the blank page. And there’s no filmmaker or musician who hasn’t watched and listened to something before recording. Isn’t AI then a disciple like any other? “These are machines that imitate a certain style through mass reproduction. They can replicate it [in just] a few moments. The future writer who intends to be inspired by George R. R. Martin will at least have had to have [purchased] and read his books,” answers García del Blanco. “At a legal level, a book or a movie isn’t protected in the same way as other assets, because we consider them to be different [from other products]. We find it acceptable that an author draws on the works of his predecessors to generate his own, because this is the only way in which human creativity can develop. The absence of the human element is what leads us to a different reasoning with AI. [However, this doesn’t stop some parties from] advocating for the protection of works generated by AI through intellectual property rights,” explains attorney José María Méndez. Does pirating also feed AI? Generative AI — which has been developing for about seven or eight years now — is fed with all the information available on the web. Through the algorithm used to analyze the codes of websites in search of information, it collects everything: from the images that an illustrator uploads, to products available in the public domain. “[These systems] have fed on data that was available on the internet: they haven’t stolen it or hacked any computer,” explains Jordi Torres, a researcher at the Barcelona Supercomputing Center. But does this also include data posted illegally? “I couldn’t say if each image or text that is added to these massive databases is reviewed, or if the use [that a company] wants to apply to it complies with the licensing terms of each product,” admits Enzo Ferrante, who holds a doctorate in Computer Science from Paris-Saclay University. Precisely in his legal complaint, George R.R. Martin claims that ChatGPT obtained his A Song of Ice and Fire literary saga from illegal online libraries. EL PAÍS tried unsuccessfully to communicate with the developers of ChatGPT, OpenAI, and Stability to ask about the origins of the information that they feed their large language models (LLMs). Not everything, however, is bad news. AI also offers a universe of possibilities to the entire planet, creators included. García del Blanco himself is aware of this. “Some cartoonists told me that they’ve stopped wasting time drawing repetitive cartoon backgrounds to be able to concentrate on the creative parts that stimulate them the most and are considered essential. The same [mechanism] can be applied in the audiovisual sector or the music sector.” “In the history of humanity, whenever a new tool has emerged, it has never been dismissed,” Torres emphasizes. However, he advocates for its democratization through legislation that everyone can participate in drafting. “Let it not just be a few people who do it for us. We have to get closer [to the process], we have to learn from it and not leave it in the hands of a few politicians or engineers,” he affirms. García del Blanco agrees. “AI is coming to give us a hand. But controls must be established.” It’s all about carefully considering how to regulate and which regulations to ultimately impose. Luckily, human beings never stop thinking. Sign up for our weekly newsletter to get more English-language news coverage from EL PAÍS USA Edition More information Scarlett Johansson takes legal action against AI app that used her image EL PAÍSMADRID Robin Williams’ daughter Zelda slams AI for recreating her father’s voice EL PAÍSMADRID ARCHIVED IN ChatGPT OpenAI Adheres to More information If you are interested in licensing this content, please contact ventacontenidos@prisamedia.com NEWSLETTER Sign up to EL PAÍS In English Edition bulletin MOST VIEWED ‘A 12-year-old is not ready’: Why thousands of parents are teaming up to delay their children’s first cell phone use Sheena Josselyn, neuroscientist: ‘Eliminating a memory is fairly simple, once you have the right tools’ A researcher who publishes a study every two days reveals the darker side of science A decade since ‘Sapiens’: Scientific knowledge or populism? After the Hamas war, what then?: The fate of Gaza sparks global concern",
    "originSummary": [
      "Prominent artists like Scarlett Johansson and Stephen Fry are protesting against the unauthorized use of AI to simulate their work, raising significant concerns over the potential exploitation of artists' rights.",
      "The European Union (EU) is drafting a set of AI regulations, projected to be in place by 2024 or 2025, aiming to make AI technology more equitable, particularly within the creative industry.",
      "With the rise of AI-created works that mimic human artists, questions are being raised about their copyright protections. Intellectual property specialists argue that a work must involve at least one human creator to be eligible for such protection."
    ],
    "commentBody": "",
    "commentSummary": [
      "Artists, including Scarlett Johansson and Stephen Fry, are raising concerns about AI being used without their consent to mimic their artwork.",
      "The European Union is preparing to enact AI regulations between 2024 and 2025, aimed at ensuring fairness particularly in the creative sector.",
      "Amid concerns about AI infringing artists' rights, the Screen Writers’ Guild and Screen Actors Guild are seeking limitations on the use of AI, while legal experts are debating whether AI-generated works should have copyright protection."
    ],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1699284891961
  },
  {
    "title": "US Representatives Advocate for National Data Privacy Standards Amid Rising AI Advancements",
    "originLink": "https://news.bloomberglaw.com/us-law-week/ais-rise-flags-need-for-federal-privacy-and-security-protection",
    "originBody": "The explosion of artificial intelligence and its potential impact on US policy and the economy require Congress to pass a national data privacy and security standard, say Reps. Cathy McMorris Rodgers (R-Wash.) and Jay Obernolte (R-Calif.). Artificial intelligence is here to stay. This technology is both exciting and disruptive, offering advancements that could empower people, expand worker productivity, and grow the US economy. We need to ensure America leads in developing standards and deploying this emerging technology. A critical first step toward achieving AI leadership is passing a national data privacy standard. Unlocking the potential of AI could radically improve every sector of our economy. In the energy industry, AI tools have the potential to deliver affordable, reliable energy to Americans faster and more efficiently. It also can reduce risks to our electric grid—by improving wildfire prediction modeling—and help reduce carbon and other emissions. Video: Can Laws Keep Up With AI’s Fast Pace? In telecommunications, AI technology will enhance the performance of next-generation communications networks and improve internet speeds. In the health sector, AI is already helping to improve diagnostics that will save millions of lives. Data powers all of these new tools. The more information companies can feed into their machine learning systems, the smarter those systems can become. Yet a lack of transparency into AI systems and the data used to train them raises serious concerns about how they operate and where they might potentially be abused. Used nefariously, AI could enable cybercriminals to develop potent threats to our critical infrastructure, or create deepfake AI content to scam people out of their money or personal information—in addition to other harmful and illegal activities. AI could expand the power of companies and governments to surveil, track, and build profiles on US consumers and online users. These profiles could then be used to manipulate human behavior in ways that are difficult to resist or even detect. AI tools also might be exploited by geopolitical adversaries to spy on Americans and influence national opinion. Guarding against these risks while still enabling America to reap the benefits of AI will be one of the key challenges of our time. Achieving this balance will require a deliberate approach to AI. A national data privacy standard must be the first step. Establishing comprehensive protections on the collection, processing, transfer, and storage of our data should be foundational to AI regulation in Congress. Read more: Data Protection Leaders Differ on Powers of New US Privacy Law Last year, the Energy and Commerce Committee worked in bipartisan fashion to advance comprehensive data privacy and security legislation, which passed out of the committee with near unanimous support. We’re building on that momentum this Congress. We continue to work toward legislation that would implement the most robust privacy protections to date in the US, putting people back in control of their data. Our efforts include a series of hearings currently underway to discuss how AI tools can strengthen US competitiveness across every sector of the economy. Conversations also address how sensible data privacy and security safeguards are a foundational step to unlock the potential of this new technology. This effort will inform our work to strike an appropriate balance that gives businesses flexibility to remain agile as they develop these cutting-edge technologies, while ensuring responsible use of AI. Our national privacy standard would restrict how companies collect, store, and sell sensitive information; regulate the use of profiles on people to track, predict, and manipulate behavior for profit; and prevent data practices that harm children by making it illegal to track information for and target advertising to youth. Many people already widely distrust how big tech companies collect and share user data, and a majority of Americans want more control over how their data is used. Many agree the government should do more to address how companies handle data privacy issues, in a substantial shift from a decade ago. AI’s promise is an explosion of productivity and the realization of long-held goals such as affordable energy, better health care, and an improved standard of living. As companies begin integrating AI features and tools into their business practices, it’s vital that Congress act to put people back in control of the online information that can be used to feed machine learning. The best way to achieve this is through a national data privacy and security standard. By setting clear rules of the road that promote innovation, strengthen protections for people’s data privacy and security, and ensure companies are assessing the safety of their algorithms as AI is deployed, the US will continue to lead on this revolutionary technology. This article does not necessarily reflect the opinion of Bloomberg Industry Group, Inc., the publisher of Bloomberg Law and Bloomberg Tax, or its owners. Author Information Rep. Cathy McMorris Rodgers (R-Wash.) represents Washington’s fifth congressional district. She is chair of the House Energy and Commerce Committee and leads the committee’s AI and data privacy efforts. Rep. Jay Obernolte (R-Calif.) represents California’s 23rd congressional district. He co-chairs the Congressional Artificial Intelligence Caucus and spent 30 years running his own video game development company. Write for Us: Author Guidelines Continue Reading Learn About Bloomberg Law AI-powered legal analytics, workflow tools and premium legal & business news. Learn more Already a subscriber? Log in to keep reading or access research tools. Log In",
    "originSummary": [
      "Congress representatives Cathy McMorris Rodgers and Jay Obernolte advocated for a national data privacy and security standard given the swift progress in artificial intelligence (AI) technologies.",
      "They referenced the dual nature of AI - its potential for economic growth and enhancing living standards, but also its role in substantial cybersecurity dangers and expanded surveillance capabilities.",
      "They stressed the importance of comprehensive data protections in the context of AI regulation, echoing public sentiment where a majority of Americans wish for greater control over their data applications."
    ],
    "commentBody": "",
    "commentSummary": [
      "Reps. Cathy McMorris Rodgers and Jay Obernolte propose that Congress adopt a national standard for data privacy and security, especially important with the fast-paced developments in artificial intelligence (AI).",
      "Despite AI's promise for economic growth and enhanced living standards, the technology also brings about risks including powerful cybersecurity threats and increasing surveillance capabilities.",
      "In response to these risks and seizing AI's potential benefits, the representatives argue for comprehensive regulations on data practices, a sentiment shared by many Americans who desire greater control over their data usage."
    ],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1699284891961
  },
  {
    "title": "Indian Legal Market Trends: Foreign Firms, AI Use Rise, New Laws Take Effect, and Young Lawyers Drive Change",
    "originLink": "https://law.asia/new-legal-market-trends/",
    "originBody": "Home Intelligence report Glimpses of the Road Ahead Intelligence report Glimpses of the Road Ahead 6 November 2023 Our annual ‘State of the Legal Market’ survey finds that AI, specialist firms, discerning clients and the paired trends of fragmentation and consolidation are preoccupying the legal community. Katherine Abraham reports B ig changes are afoot in the Indian legal landscape with the arrival of foreign firms and the integration of artificial intelligence (AI) technology. Old-fashioned lawyers who once struggled over basic computer technologies must now come to terms with AI for their firms, and there are fresh challenges as law firms pursue premium clients in an increasingly competitive environment. On top of this, India’s legal system is progressing through a substantial overhaul. There is a legislative bill for a new principal law on criminal offences, Bharatiya Nyaya Sanhita. It has not just been Sanskritised in name, it has chosen a new course. The bill includes – but is not restricted to – repealing sedition, a new penal code against mob lynching, death for rape of minors, and first-time community service as a punishment for petty offences. Another key legislative proposal is to replace the Code of Criminal Procedure with the Bharatiya Nagarik Suraksha Sanhita. Its bill proposes 533 sections in which 160 sections have been changed from the old code. Nine new sections have been added, while another nine have been repealed. Behind the scenes, lawyers say they are expecting technology to freshen their business activities. There’s an optimism that AI applications could enhance reach and usage to help existing legal services through e-discovery, contract management and legal analytics. Against this backdrop, India Business Law Journal surveyed law firms across the country for differing thoughts, ideas and challenges from a who’s who of the legal market. Our annual survey on the state of the legal market has been done in conjunction with the release of the India Business Law Directory, which can be read in the pages that follow. This year’s survey received responses from 70 Indian law firms of various scales and specialties. Bigger is better? The legal market in 2022-23 witnessed a trend of law firm fragmentation alongside instances of practice consolidation. For clients, escalating numbers of mid-sized firms are bringing reduced costs; for traditional law businesses, it means increasing competition. Notable recent mentions include the merger of Atlas Law Partners with Luthra and Luthra Law Offices. Atlas co-founder Harry Chawla became managing partner after the merger, bringing his team to form a robust combined entity with the Luthras. Similarly, Saraf and Partners absorbed boutique real estate firm SRGR Law Offices; Akshat Pande’s Alpha Partners merged with Kolkata-based Fox & Mandal; and Prashant Mara’s BTG Legal merged with Advaya Legal to form BTG Advaya. Further, Siddharth Raja, former co-founder of Samvad Partners, has merged his legal practice with Mumbai-based first-generation law firm Vertices Partners. Foreign firms It seems the arrival of foreign firms is occupying many minds in 2023. “The most significant development has been giving access to Indian markets to foreign law firms by the Bar Council of India,” says Nitu Agarwal, founder and partner at Mumbai’s YNSS Law Offices. “The big law firms may see a high attrition rate in the short term as the foreign law firms may have deeper pockets to pay a higher salary to acquire talent.” Kritika Krishnamurthy, founding partner at AK and Partners in New Delhi, says: “Foreign law firms are now joining hands with Indian law firms to create hybrid entities that are capable of legal advisory internationally from one point.” But Krishnamurthy says this is still going to mean stiff competition within the Indian market. “This has really brought the reality home for Indian law firms, especially mid-sized and small-sized firms, that survival can become an issue if services are not up to international standards,” she says. “These law firms could also be in direct competition with the top-tier law firms who were [previously] the point of contact to facilitate such advisory.” The hiring and retention of the best legal talent is a huge challenge, according to Reena Khair, senior partner at Kochhar & Co in New Delhi. “The most significant development has been the substantial increase in the demand for legal services in India. This trend is visible both in respect of litigation and non-litigation work.” However, Zulfiquar Memon, founder and managing partner at MZM Legal in Mumbai, draws back a little from the views of his counterparts. “I feel this is a highly anticipated space and many international players are eyeing the opportunity,” he says. “I am not sure if it is a significant development, but the news around international law firms getting clearance on their footprints in India gathered some traction for a while. I think there was some excitement related to this information. However, when we carefully examined the development, it was hardly anything relevant.” In addition to foreign firms and AI, Gunita Pahwa, joint managing partner at S&A Law Offices in Gurugram, identifies alternative dispute resolution as a disruptor to traditional law business. “Mediation and arbitration are becoming more popular, particularly in commercial disputes,” she says. Smaller and trendier AK’s Krishnamurthy sees market signals that bigger may no longer be universally considered better. “The next big trend, which perhaps not many people are noticing, is the number of mid-sized and small-sized firms that are now present in the market,” she says. “They are all headed by partners from tier-one firms promising the same level of expertise at lower prices. “Niche law firms, smaller in size, but where clients have access to equity partners for direct meetings and advisory, are being favoured by many foreign investors over a big setup where you deal with a principal associate or a salaried partner.” There is evidence to back Krishnamurthy. Earlier this year, former Juris Corp partner Neeraj Dubey established his own firm, The Valid Points Law Offices, with big, nationwide plans. Similarly, Priyanka Chaudhari, former Netflix India director and counsel, launched her own independent practice this year. After 18 years, Jayashree Dasgupta departed from Dhir & Dhir to establish an independent litigation chamber in South Delhi. Nishita Malik, a partner at Sumanto Basu and Associates in New Delhi, likewise identifies this as a trend. “There seems to be a shift from previously family/single person-controlled big law firms to smaller more dynamic firms having various highly skilled personnel at the helm,” she says. “The shift to a more egalitarian culture, where younger lawyers are set to lead and have the means and opportunity to advise on big transactions, is the development the legal services market in India is seeing now.” Society of Indian Law Firms president Lalit Bhasin, the managing partner of Bhasin & Co in New Delhi, speaks of a turning tide in corporate business. “Law firms’ engagement with the company has seen a marked decline as companies rely more on their in-house legal teams, and only in extraordinary matters or in the field of litigation are law firms involved,” he says. Akshaya Bhansali, a partner at Mindspright Legal in Mumbai, says India’s growth is reaching new heights with “a strengthening partnership between corporate and law firms in India”. “Earlier this relationship was focused on providing legal solutions to the problems which the companies used to face; now the companies … first approach law firms to make legally sustainable plans,” she says. S&A’s Pahwa suggests the relationship between companies and law firms has “evolved for the better” in a climate of increasing “transparency and appreciation of legal recourse”. “Prioritisation of pre-dispute stage strategies, advisory and risk assessment has improved,” she says. “The importance of regular communication and legal case reporting to companies and client management is better appreciated by law firms and companies.” Zia Mody, co-founder and managing partner of AZB & Partners in Mumbai, observes general counsel are much more active in setting the terms of relationships between their companies and law firms. “The companies are very clear as to, in their mind, which law firm has the domain in which practice area,” she says. MZM’s Memon agrees business is flowing towards responsive, agile law practices. “Clients who are small and medium companies who have regular businesses … lately have been preferring small boutique firms for their specialised legal assistance – for example IPR, employment, compliance, internal investigations and fraud,” he says. “Many clients have actually stopped engaging with their firms and prefer smaller boutique practices run by erstwhile senior partners of large law firms, which turns out to be cost effective and easy to navigate.” TREND-SPOTTING Pravin Anand, managing partner of Anand and Anand, pinpoints key developments The most significant developments in the legal services market in India during the past year are below: Pravin Anand Managing partner Anand and Anand Technology integration. Law firms, legal professionals and courts have adopted legal tech tools for research, document management, case management and client communications. This trend is expected to continue, enhancing efficiency and facilitate public/client service. The Mediation Bill, 2023. The bill requires people to try to settle civil or commercial disputes through mediation before going to court. The bill promotes mediation, enforces mediated settlement agreements at the will of the parties, provides a body for registering mediators, encourages community mediation and makes online mediation acceptable. Emergence of alternative legal service providers. Besides traditional law firms, alternative legal service providers have gained ground. These include legal process outsourcing companies and legal tech startups that offer cost-effective solutions for tasks such as document review, contract management and legal research. Regulatory changes. The introduction of the Advocates (Amendment) Bill, 2023, is aimed at the elimination of touts by empowering the courts to publish lists of speculated individuals acting as middlemen between clients and their legal representatives. Virtual courts and e-filing. The pandemic accelerated the adoption of virtual court proceedings and e-filing systems in India. This digital transformation has continued to assist the courts, legal representatives and clients, making legal processes more accessible and efficient. Legal education. Legal education and training programmes in India are evolving to meet the demands of the modern legal services market. Many institutions have offered specialised courses in areas like intellectual property, international law and cyber law. Foreign firms. The Bar Council of India allowed foreign law firms to practise in India. However, it restricted their scope of operations to non-litigation areas such as advice regarding foreign and international law. The said provision safeguards the interests of the Indian clients as well as the legal practitioners. Specialised practice areas. Law firms have been increasingly specialising in niche practice areas such as intellectual property, technology law, environmental law, and arbitration. Clients have been seeking specialised expertise for complex legal issues. Ethical and professional standards. There has been a growing emphasis on ethical and professional standards in the legal profession. Initiatives have been taken to promote transparency, accountability and adherence to high ethical standards among legal practitioners. AI: Asset or liability? The pandemic has highlighted the importance of collaboration within law firms. Work-from-home lawyers can’t simply walk up to their colleagues’ desks, and law teams require efficient and effective tools to digitally collaborate in real-time. The introduction and inclusion of AI in moderate amounts has been a key development. “The most significant development in legal services in India, I feel, is the use of AI in the legal field to make the legal system better,” says Mindspright’s Bhansali. “Technology has an important role … and, with young decision makers, India can improvise its judicial system.” S&A’s Pahwa believes an AI-supported legal system “will have a better reach and utilisation” as humans test the newfound limits of machines and India’s Digital Personal Data Protection Act kicks in. “In addition, online dispute resolution platforms, legal-tech startups, legal digital media and legal publishing platforms have also evolved and transformed,” she says. “It is a transformative phase driven by technology and new developments, which I believe will enhance the efficiency, accessibility and effectiveness of legal services.” A vast majority of participants seem inclined towards the inclusion and adoption of AI for legal ease. “With the adoption of AI, instead of spending hours on data collection, the time saved could be used for roles that require greater intellectual engagement,” says Rashi Suri, managing partner at Upscale Legal in New Delhi. But, it seems one must tread carefully. “Technology backed by AI needs to be adopted with abundant precaution,” says Suri. “AI-backed machines function only on the basis of information fed to them and they also need to be taught how to process that information.” Better legislation, less interference With general elections due in April 2024, the Indian government has been working quickly to pass legislation. This has stirred both the bar and bench. “Many laws and policies have led to ambiguities causing uncertainty,” says Sumanto’s Malik. “It would be preferable for the overhauling of various legislation to be done from a more holistic approach with inputs from the relevant industry/sector players.” “India is on the cusp of a major leap forward,” says Gautam Khurana, managing partner at India Law Offices in New Delhi. “Our general elections scheduled for 2024 would be the most important factor that would influence the Indian market.” Upscale’s Suri says that instead of only introducing laws and legislation, the government should first reduce regulatory complexity. “The government should consolidate the laws and agencies … thereby reducing regulatory complexity, encouraging formalisation of the workforce and enhancing flexibility for employers,” she says. Hitesh Soni, founder of Hitesh Soni & Associates in Mumbai, has a similar opinion. “The government ought to make efforts towards the establishment of a unique window that will be staffed by experts who are able to contribute to the enhancement of corporate governance,” he says. YNSS’ Agarwal elaborates. “The government needs to consider having a single window clearance for registrations, licences and clearances required for incorporating and operating a company in India,” she says. “The regulatory regime in this aspect needs streamlining to a large extent.” SILF’s Bhasin plumbs for clarity and consistency in subordinate legislation. “Rules and regulations keep on changing every year,” he says. “This should be avoided, and a clear-cut provision should be made that there would be no change for the next five years.” Macro challenges India has been on the front foot with proposing new legislation, but legal industry experts believe policymaking is far from policy implementation. “While the government brings in industry-friendly policies and a non-adversarial tax regime, it is the implementation which is really bad at ground level,” says Ashok Dhingra, senior partner at Ashok Dhingra Associates in Gurugram. “Corruption is one of the major challenges, which is not abating.” Adding to this, there are “inconsistencies” in the regulatory framework. “There are instances of incoherence in the regulatory framework where one agency is not in sync with the laws and framework of another agency, which may be in control of the same industry,” says Upscale’s Suri. “This needs immediate attention to make India a friendly investment destination.” Then there are the problems that are familiar to countries around the world. “Among India’s many macro challenges, moderate demand and high inflation are the most concerning,” says S&A’s Pahwa. “In April 2023, the Asian Development Bank projected growth in India’s GDP to 6.4% in fiscal year 2023 … and rising to 6.7% in FY2024.” AZB’s Mody offers a basket of contributory factors including “the geopolitical uncertainty generally, the state of the US economy and its infection effect on India”. Other issues highlighted by lawyers include unemployment, disparity in the legal education system and the legal market, and students who fail to meet industry standards. “The World Bank’s Ease of Doing Business index ranks countries based on how well they protect property rights and regulate businesses,” says Pravin Anand, managing partner at Delhi’s Anand and Anand. “India’s ranking in the Index was 63rd for 2022, which is a significant improvement from being ranked 77th in 2019.” Anand has a list of ideas for the Indian government, including: “reduced transaction costs, faster project implementation, enhanced predictability, encouragement of real estate development [which can] boost economic growth and create jobs, fostering land market efficiency, and attracting foreign investment apart from supporting small and medium-sized enterprises, reduction in corruption, and modernising and digitising land records as part of property acquisition reforms”. Geopolitics Ashok Dhingra says he has not seen a decrease in any practice area, but Zia Mody notes “general market conditions in India and globally” have affected capital markets practice, while data protection and privacy has newfound enthusiasm from “new legislation high awareness”. Suri brands India as a new “global capability centre”. “Given India’s large technical talent pool, many global corporations have established their captive centres in India in the past decade or so,” she says. Khurana says Indian businesses face risk from a high dependency on imports and rapid changes in geopolitical circumstances. “India’s supply lines are still dependent and need protection over the next three to five years, till the transition can take place successfully,” he says. On the flip side, he says “the new cycle of investment has brought a rush to launch new products and manufacturing. This seems to be triggering M&A transactions.” TAGS Advaya Legal AK and Partners Akshat Pande Akshaya Bhansali Alpha Partners Anand and Anand Artificial intelligence Ashok Dhingra Ashok Dhingra Associates Atlas Law Partners AZB & Partners Bharatiya Nyaya Sanhita Bhasin & Co BTG Legal Code of Criminal Procedure Digital Personal Data Protection Act Fox Mandal Gautam Khurana Gunita Pahwa Harry Chawla Hitesh Soni Hitesh Soni & Associates India Law Offices Jayashree Dasgupta Kochhar & Co Kritika Krishnamurthy Lalit Bhasin Luthra and Luthra Law Offices Mindspright Legal MZM Legal Neeraj Dubey Nishita Malik Nitu Agarwal Prashant Mara Pravin Anand Priyanka Chaudhari Rashi Suri Reena Khair S&A Law Offices Samvad Partners Saraf and Partners SRGR Law Offices Sumanto Basu and Associates Sumanto's Malik The Advocates (Amendment) Billl The Mediation Bill Vertices Partners YNSS Law Offices Zia Mody Zulfiquar Memon Previous article AZB advises Larsen & Toubro on USD1.2 billion share buyback RELATED ARTICLES Alpha Partners merges with Fox & Mandal Alpha Rajan & Partners opens Dubai office to widen MENA reach Alpha inducts food, retail head MOST POPULAR MCA proposal to reinstate CIRP: A critique By Misha, Aishwarya Satija and Kritika Poddar, Shardul Amarchand Mangaldas & Co 6 November 2023 Treating crypto as property in Hong Kong insolvency regime By Tang Chong, Helmsman 18 September 2023 Key features and benefits of a BVI professional fund By Elizabeth Kenny and Wendy Au, Loeb Smith Attorneys 5 September 2023 Likelihood of confusion under India’s trademark law for ‘hush’ products By Prachi Agarwal and Aditi Srivastasa, Anand and Anand in New Delhi 24 August 2023 MARKET PULSE CLA joins hands with JSA to bolster services in India’s south 30 October 2023 Cyril Shroff, Vijayendra Pratap Singh take up new SIAC roles 30 October 2023 Madhavan Srivatsan brings corporate team to Emerald Law 24 October 2023 CORRESPONDENTS Defendants’ rights better balanced in interim injunctions By Manisha Singh and Omesh Puri, LexOrbis 24 October 2023 Insolvency and Bankruptcy Code prevails over Electricity Act By Mani Gupta and Aman Choudhary, Sarthak Advocates & Solicitors 24 October 2023 Spread the news of media investment growth By Rohit Jain and Nitish Mawkin, Singhania & Co 17 October 2023 FEATURES Final frontier, first opportunities Chandrayaan-3 mission puts spotlight on public-private collaboration in space sector 29 September 2023 Growing pains in startup crib A look at the key factors that have spelled trouble for India’s prized startup sector 4 October 2023 Tapping innate strengths How management professionals can strengthen support functions at law firms 2 November 2023 PRACTITIONER’S PERSPECTIVES Zero tolerance on inaction by intermediaries regarding content harmful to children By Pravin Anand, Vaishali Mittal and Siddhant Chamola, Anand and Anand 16 May 2023 Managing founder disputes in startups By Nitu Agarwal, YNSS Law Offices 2 May 2023 Navigating global privacy laws: Best practices By Sreenidhi Srinivasan and Mayank Takawane, Ikigai Law 3 April 2023 VANTAGE POINT Tapping innate strengths How management professionals can strengthen support functions at law firms 2 November 2023 JOBS Legal Counsel APAC, Brand Protection (5+ PQE) – 17077/VTA 7 October 2023 Corporate Lawyer 6 October 2023",
    "originSummary": [
      "The Indian legal market is evolving with foreign law firms entering, a rise in the use of AI, and the adoption of laws like the Bharatiya Nyaya Sanhita addressing modern offences.",
      "Shifts spotted within the market include increased competition from mid-sized firms, mergers between larger firms, and a leaning towards smaller practices led by younger lawyers.",
      "Notable challenges are moderate demand, high inflation, and disparities in legal education, even as the government works to reduce regulatory complexity. Risk areas include high import dependence and rapid geopolitical changes."
    ],
    "commentBody": "",
    "commentSummary": [
      "The Indian legal market is undergoing significant transformation, with the entry of foreign law firms, rising competition from mid-sized firms, consolidation via mergers, increasing use of AI, and the shift towards dynamic practices led by young lawyers.",
      "The Bharatiya Nyaya Sanhita law addressing issues like sedition, mob lynching and instituting community service for minor offences is a noteworthy legal change, alongside efforts to reduce regulatory complexity and increased focus on data protection.",
      "Despite these changes, challenges persist, such as moderate demand, high inflation, disparities in legal education, risks from high import dependence and rapid geopolitical changes, and vulnerabilities in supply lines that need protection."
    ],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1699284891961
  },
  {
    "title": "Worldwide Progress Towards AI-Specific Legislation: From The EU AI Act to the Hiroshima AI Process",
    "originLink": "https://www.helpnetsecurity.com/2023/11/06/sarah-pearce-hunton-andrews-kurth-ai-legislation/",
    "originBody": "Mirko Zorz, Director of Content, Help Net Security November 6, 2023 Share Exploring the global shift towards AI-specific legislation In this Help Net Security interview, Sarah Pearce, Partner at Hunton Andrews Kurth, offers insights into the evolving landscape of AI legislation and its global impact. Pearce explores key principles, public participation, the future of AI laws in a world of rapid technological advancements, and how to balance fostering innovation and ensuring effective regulation. We’re observing a global shift towards AI-specific legislation. Can you provide an overview of the major developments? Indeed, various governments worldwide are looking to legislate the field somehow. Recently, G7 leaders have agreed on the International Guiding Principles on Artificial Intelligence (AI) and a voluntary Code of Conduct for AI developers under the Hiroshima AI Process. The Hiroshima AI Process was established at the G7 Summit in May 2023 to promote guardrails for advanced AI systems on a global level. This is evidence of a shift – and on a global scale. In terms of legislation, the EU AI Act is by far the most advanced. Importantly, the AI Act will be an EU regulation (like the GDPR), meaning it will be directly applicable in all EU Member States, and Member States do not have to enact local law to make the AI Act effective. The AI Act aims to establish a legal framework for developing and deploying AI systems in the EU. EU lawmakers are yet to agree on the text of the legislation fully, it is unlikely the Act will be agreed before December 2023. The fourth meeting was held recently, and certain areas are still not agreed upon, including the existence and form of exemptions to “high risk” classification of an AI system; the right of authorities or employers to use AI-powered emotional recognition technology whereby facial expressions of anger, sadness, happiness and boredom, as well as other biometric data, is monitored to spot tired drivers or workers; and whether the use of real-time facial recognition cameras on streets and public spaces should be a right for member states. In the UK, while there is currently no legislation directly regulating the use of AI, the UK government has, this year, issued a white paper, “A pro-innovation approach to AI regulation”. The pro-innovation approach means the UK government does not propose directly regulating AI use at this stage. Instead, it proposes a principle-based approach based on six core principles that regulators must apply with flexibility to implement and enforce in ways that best meet the use of AI in their sectors. Regulators, such as Ofcom, the Competition and Markets Authority, the Information Commissioner’s Office, the Financial Conduct Authority, and the Medicine and Healthcare Products Regulatory Agency, will be asked to interpret and implement the principles. Much like the G7 International Guiding Principles agreed today, the UK government’s principles bear resemblances to those set out by the OECD some time ago, including safety and security, appropriate transparency and explainability, fairness, accountability and governance, and contestability and redress. The timeline for implementing these principles is unclear, but, according to the government consultation, progress will be made within the next 6 to 12 months. The upcoming AI Summit (another indication of a shift in global attention on AI) may help speed up that process. Finally, we have also just seen the White House unveiling its own plan for AI in the form of an Executive Order. Based on your expertise, what key principles should legislators consider when framing AI regulations to ensure they are effective, fair, and foster innovation? From a privacy perspective, legislators need to consider the core data protection principles contained in the GDPR. However, this is not without challenge, and significant tensions exist between the protection of personal data and the mass use of personal data that is inevitable in any AI technology, to name just one. Generally speaking, the principles outlined by the OECD, reflected in the G7’s code of conduct and the UK government’s proposal, encompass a good selection of considerations on which to base any legislation/regulation in this field. How important is it for the public to be involved in discussions and decisions around AI legislation? And how can we ensure their voice is heard and considered in the regulatory process? It is vital that the public – but moreover, all stakeholders – be involved in discussions around AI. The technology companies developing AI, for example, are likely the best placed to understand the technology fully and can help guide any such discussion. Those organizations deploying the technology must also be closely involved, as they have a particular viewpoint to offer. Governments also need to be a part of the discussion. The position of various nations can offer value and help steer the decision-making of all those governments represented in this context. Finally, let’s not forget the general public, the individuals whose data will likely be processed by the technology. All play valuable yet different roles and will come with different viewpoints that should be aired and considered. Many companies view regulation as hindering innovation, especially in tech. What factors contribute to this perception, and is there any merit to these concerns? Legislation or any form of regulation is often seen as restrictive: by its very nature, it comprises a set of rules that govern. That is often interpreted as “restrictive” and hinders development, innovation, and technological advancement in this context. That is a generalist, simplistic, and somewhat dismissive view. While such concerns are true of certain legislation, it need not be the case for all. Much depends on the form that legislation takes. It will be interesting to see, for example, how the framework proposed by the UK government of a principle-based approach will play out in practice. In theory, such an approach appears not restrictive and is intended to allow for flexibility and promote innovation. How do you see AI legislation evolving in the next 5-10 years, especially considering the rapid advancements in AI capabilities? I think we will see more legislators worldwide looking to develop some form of legislation or regulatory framework. Ideally, there would be alignment amongst the big global players and the G7 announcement today is a step in the right direction. It will be interesting to see how the upcoming summit in the UK also helps nudge that supra-national development. I hope the geo-political environment doesn’t push governments into taking action too quickly and independently, without coordination. Let’s also hope that whatever form legislation takes, whether locally or globally, it will be sufficiently agile to withstand the rapid technological advancements. More about artificial intelligence cybersecurity data EU framework GDPR government Hunton Andrews Kurth legislation opinion privacy regulation UK USA Share",
    "originSummary": [
      "Global governments are moving towards AI-specific laws, with the G7 recently establishing an International Guiding Principles on AI and a voluntary Code of Conduct through the Hiroshima AI Process.",
      "The EU AI Act is the most progressive to date, intending to set a legal framework for AI development and usage across all EU Member States.",
      "Despite no direct regulation currently in place in the UK, the government promotes a pro-innovation stance to AI regulation, founded on six key principles to be flexibly applied by regulators. The White House also recently announced their AI plan."
    ],
    "commentBody": "",
    "commentSummary": [
      "Governments globally are moving towards AI-specific legislation, with the G7 leaders recently establishing International Guiding Principles on AI and a voluntary Code of Conduct under the Hiroshima AI Process.",
      "The most advanced of these, the EU AI Act, looks to form a legal framework for the development and usage of AI systems across all EU Member States.",
      "In the UK, no legislation directly regulates AI, but the government employs a pro-innovation approach featuring six guiding principles, reflecting the rising necessity for legislation that balances support for innovation with effective regulation of technology."
    ],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1699284891961
  }
]
