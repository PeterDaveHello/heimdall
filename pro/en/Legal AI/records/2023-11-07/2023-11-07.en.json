[
  {
    "title": "Leading Law Firms Recruit AI Specialists to Boost Operations and Streamline Processes",
    "originLink": "https://news.bloomberglaw.com/business-and-practice/big-laws-ai-jobs-lay-foundation-for-techs-wider-use-at-firms",
    "originBody": "Analysts, data gurus sought to develop generative AI systems Salaries on the low side; flexibility needed, recruiter says Generative AI is coming to Big Law’s back office, judging by job listings posted over the last few months from Latham & Watkins, Linklaters, and several other leading firms. At least nine US and UK firms are actively seeking more than two dozen software developers, analysts, programmers, and data engineers to build out their AI capabilities, according to postings found on law firm and job aggregator websites. Since the unveiling of the telephone, a Big Law axiom is that lawyers and their firms are wary of technology and slow to adopt it, despite occasional public rhetoric to the contrary. The new job ads—posted on LinkedIn, Indeed.com, and elsewhere by well-established firms—show firms are feeling the competitive heat to incorporate the technology into their operations. Video: Can Laws Keep Up With AI’s Fast Pace? Within a few years, “I can’t imagine that every top 100 firm won’t have a few positions that involve the transformative power of generative AI,” said Davis Wright Tremaine partner Vidhya Prabhakaran, a member of the firm’s AI steering committee. “There are so many potential uses for it. We’re just trying to unlock it.” Firms are focusing on practical applications, from using AI to help lawyers do research and draft briefs to streamlining marketing and business development functions. “The team has a new player,” said Ralph Baxter, a former chairman of Orrick, Herrington & Sutcliffe who advises firms and legal tech companies. “And it’s not a human being.” Fuzzy Job Descriptions Some of the back-office IT jobs that ask for AI experience are vague—by design. OpenAI’s ChatGPT and similar technologies are evolving rapidly. Their ultimate uses in the legal industry, and the levels of disruption they may cause, are still not clear. Linklaters, a nearly 200-year-old London firm, is looking to hire an AI analyst. The role is to support the firm’s AI program, which “has several workstreams in various stages of development,” according to the job listing. Allen & Overy, Goodwin Procter, Bryan Cave Leighton Paisner, Husch Blackwell, and Simpson Thacher & Bartlett are also among the firms hiring for non-lawyer AI positions. Each stress the importance of AI experience—one requires previous work on “cutting edge” AI issues—in their job listings. Allen & Overy has hired seven developers, data scientists, and others to its innovation team since February, said David Wakeling, head of the firm’s markets innovation group. A&O, which is set to combine with Shearman & Sterling to create a massive new firm, is also seeking to fill four additional positions. “We realized this was incredibly disruptive tech early,” said Wakeling, whose firm in February announced that it is integrating “Harvey,” an AI platform that’s been enhanced for legal work. “Law is words, and we have a new way of mastering words.” Goodwin Procter hasn’t launched its own AI platform, said Rachel Dooley, the firm’s chief innovation officer. The firm’s focus is on assisting clients with their own crash courses in how to gain the most from the technology. That means avoiding pitfalls like “hallucinations\"—during which programs spit out falsehoods or nonsensical “facts” with seeming confidence—that still can be found in programs like GPT-4, Google’s Bard, and Microsoft’s Bing. Dooley said her team has led four video round-table discussions at the firm, which are now held monthly. The first talk attracted about 600 people. “People are hungry to learn about it,” she said. The firm is planning to hire for several more positions also focused on AI, including data scientists, Dooley said. Goodwin’s new research analyst “will play a critical role in the adoption and education of the use GenAI in legal and business research,” according to the job listing. The job pays between about $85,000 and $143,000 a year, depending on experience and location. The pay is in line with the other firms’ back office AI jobs. An opening at Wall Street’s Simpson Thacher for a data scientist position is at the top of the salary range, paying between $145,000-$165,000. The salaries firms have listed for their AI-focused back office positions may be on the low side, said John Mann, managing director of the executive search firm Alex & Red. Firms will need to be “flexible and responsive” to candidates who negotiate for higher salaries. Fifteen of the 26 jobs listed, including Dentons’, are listed as “hybrid” positions that require an in-office presence but also allow some work from home. The other posts do not specify whether the staffer will need to work from the office full-time. Firms are “still building out market intelligence from a salary standpoint,” said Jenny Schwope, a senior executive search associate with the law firm consultancy Calibrate. Davis Wright Tremaine may be looking to hire between three and seven new AI-focused back office jobs at the firm in the coming year, in part because it’s becoming a “client imperative,” said Prabhakaran. The firm laid off 21 staff employees in February, joining others that trimmed headcount in response to slowing demand across the legal industry. Davis Wright Tremaine has launched its own version of ChatGPT, according to Prabhakaran. Its generative AI platform is not being used for legal work and doesn’t have access to client data, he said. Instead, it’s being used for business development and administrative tasks. Other firms hiring for new AI workers are doing so in part to promote the use of their own proprietary new AI tools. Dentons in August unveiled “fleetAI,” a chatbot based on GPT-4, which enables the firm’s lawyers in UK, Ireland, and Middle East offices to conduct legal research and generate legal content. The firm is planning to release fleetAI to its offices worldwide, and has at two other chatbots in the works, including one that will focus on legal services. Job responsibilities for Dentons’ new legal AI adoption manager in London will include developing working relationships with legal teams to encourage “the widespread use of our AI tools.” A Replacement for People? Some law firm leaders have said that like any broad-based tech disruption, it’s likely AI will cause workers to be replaced over the next several years. Others AI will spur more new jobs than it destroys. The tools are likely to improve employees’ jobs rather than threaten them, according to Dooley, the Goodwin innovation chief. “I don’t think it’s a replacement tool,” she said. “It’s an elevation tool.” Continue Reading To contact the reporter on this story: Sam Skolnik in Washington at sskolnik@bloomberglaw.com To contact the editor responsible for this story: Sei Chong at schong@bloombergindustry.com Learn About Bloomberg Law AI-powered legal analytics, workflow tools and premium legal & business news. Learn more Already a subscriber? Log in to keep reading or access research tools. Log In",
    "originSummary": [
      "Top law firms Latham & Watkins and Linklaters are hiring AI specialists, indicating a move within the legal sector to incorporate technological advancements for efficiency in operations.",
      "The recruited AI expertise will support lawyers in tasks like research, drafting briefs, and improving marketing and business development processes. Despite vague job descriptions, AI experience is emphasized as important.",
      "The salaries for these AI-centric roles might be below average, but they commonly offer the advantage of remote work flexibility. AI in this sector is being viewed more as a tool for elevation rather than a job threat."
    ],
    "commentBody": "",
    "commentSummary": [
      "Top law firms like Latham & Watkins and Linklaters are hiring AI specialists, signifying a surge in technology adoption in the legal sector for operational enhancement.",
      "The focus is on securing AI expertise to assist lawyers in research, drafting briefs, and enhancing marketing and business development processes, underscoring an upward trend of generative AI in law practices.",
      "While AI-based roles might offer below-average salaries, remote work flexibility is usually available, emphasizing the view of AI as an \"elevation tool\" rather than a job threat in the legal sector."
    ],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1699375517823
  },
  {
    "title": "AI Firm Luminance Develops Autopilot, First AI System to Independently Negotiate Contracts",
    "originLink": "https://www.cnbc.com/2023/11/07/ai-negotiates-legal-contract-without-humans-involved-for-first-time.html",
    "originBody": "SKIP NAVIGATION MARKETS BUSINESS INVESTING TECH POLITICS CNBC TV INVESTING CLUB PRO MAKE IT SELECT USA INTL WATCH LIVE Search quotes, news & videos WATCHLIST SIGN IN TECH An AI just negotiated a contract for the first time ever — and no human was involved PUBLISHED TUE, NOV 7 20234:30 AM ESTUPDATED 5 HOURS AGO Ryan Browne @RYAN_BROWNE_ KEY POINTS In a world first, artificial intelligence demonstrated the ability to negotiate a contract autonomously with another artificial intelligence without any human involvement. At Luminance's London headquarters, the company demonstrated its AI, called Autopilot, negotiating a non-disclosure agreement in a matter of minutes. It marks the first time an AI has ever negotiated a contract with another AI, with no human involved. The only layer that still requires a human is the signing of the agreement. MathisworksDigitalvision VectorsGetty Images In a world first, artificial intelligence demonstrated the ability to negotiate a contract autonomously with another artificial intelligence without any human involvement. British AI firm Luminance developed an AI system based on its own proprietary large language model (LLM) to automatically analyze and make changes to contracts. LLMs are a type of AI algorithm that can achieve general-purpose language processing and generation. Jaeger Glucina, chief of staff and managing director of Luminance, said the company's new AI aimed to eliminate much of the paperwork that lawyers typically need to complete on a day-to-day basis. In Glucina's own words, Autopilot \"handles the day-to-day negotiations, freeing up lawyers to use their creativity where it counts, and not be bogged down in this type of work.\" \"This is just AI negotiating with AI, right from opening a contract in Word all the way through to negotiating terms and then sending it to DocuSign,\" she told CNBC in an interview. \"This is all now handled by the AI, that's not only legally trained, which we've talked about being very important, but also understands your business.\" Luminance's Autopilot feature is much more advanced than Lumi, Luminance's ChatGPT-like chatbot. That tool, which Luminance says is designed to act more like a legal \"co-pilot,\" lets lawyers query and review parts of a contract to identify any red flags and clauses that may be problematic. With Autopilot, the software can operate independently of a human being — though humans are still able to review every step of the process, and the software keeps a log of all the changes made by the AI. CNBC took a look at the tech in action in a demonstration at Luminance's London offices. It's super quick. Clauses were analyzed, changes were made, and the contract was finalized in a matter of minutes. Legal 'autopilot' There are two lawyers on either side of the agreement: Luminance's general counsel and general counsel for one of Luminance's clients — research firm ProSapient. Two monitors on either side of the room show photos of the lawyers involved — but the forces driving the contract analysis, scrutinizing its contents and making recommendations are entirely AI. In the demonstration, the AI negotiators go back and forth on a non-disclosure agreement, or NDA, that one party wants the other to sign. NDAs are a bugbear in the legal profession, not least because they impose strict confidentiality limits and require lengthy scrutiny, Glucina said. \"Commercial teams are often waiting on legal teams to get their NDAs done in order to move things to the next stage,\" Glucina told CNBC. \"So it can hold up revenue, it can hold up new business partnerships, and just general business dealings. So, by getting rid of that, it's going to have a huge effect on all parts of the business.\" Legal teams are spending around 80% of their time reviewing and negotiating routine documents, according to Glucina. Luminance's software starts by highlighting contentious clauses in red. Those clauses are then changed to something more suitable, and the AI keeps a log of changes made throughout the course of its progress on the side. The AI takes into account companies' preferences on how they normally negotiate contracts. For example, the NDA suggests a six-year term for the contract. But that's against Luminance's policy. The AI acknowledges this, then automatically redrafts it to insert a three-year term for the agreement instead. Glucina said that it makes more sense to use a tool like Luminance Autopilot rather than something like OpenAI's software as it is tailored specifically to the legal industry, whereas tools like ChatGPT and Dall-E and Anthropic's Claude are more general-purpose platforms. That was echoed by Peel Hunt, the U.K. investment bank, in a note to clients last week. \"We believe companies will leverage domain-specific and/or private datasets (eg data curated during the course of business) to turn general-purpose large language models (LLMs) into domain-specific ones,\" a team of analysts at the firm said in the note. \"These should deliver superior performance to the more general-purpose LLMs like OpenAI, Anthropic, Cohere, etc.\" Luminance didn't disclose how much it costs to buy its software. The company sells annual subscription plans allowing unlimited users to access its products, and its clients include the likes of Koch Industries and Hitachi Vantara, as well as consultancies and law firms. What is Luminance? Founded in 2016 by mathematicians from the University of Cambridge, Luminance provides legal document analysis software intended to help lawyers become more efficient. The company uses an AI and machine-learning-based platform to process large, complex and fragmented data sets of legal documentation, enabling managers to easily assign tasks and track the progress of an entire legal team. It is backed by Invoke Capital — a venture capital fund set up by U.K. tech entrepreneur Mike Lynch — Talis Capital, and Future Fifty. Lynch, a controversial figure who co-founded enterprise software firm Autonomy, faces extradition from the U.K. to the U.S. over charges of fraud. He stepped down from the board of Luminance in 2022, though he remains a prominent backer. Subscribe to CNBC PRO Licensing & Reprints CNBC Councils Select Personal Finance CNBC on Peacock Join the CNBC Panel Supply Chain Values Select Shopping Closed Captioning Digital Products News Releases Internships Corrections About CNBC Ad Choices Site Map Podcasts Careers Help Contact News Tips Got a confidential news tip? We want to hear from you. GET IN TOUCH Advertise With Us PLEASE CONTACT US CNBC Newsletters Sign up for free newsletters and get more CNBC delivered to your inbox SIGN UP NOW Get this delivered to your inbox, and more info about our products and services. Privacy Policy| CA NoticeTerms of Service © 2023 CNBC LLC. All Rights Reserved. A Division of NBCUniversal Data is a real-time snapshot *Data is delayed at least 15 minutes. Global Business and Financial News, Stock Quotes, and Market Data and Analysis. Market Data Terms of Use and Disclaimers Data also provided by",
    "originSummary": [
      "British AI company Luminance has created an AI system, Autopilot, that can negotiate contracts with another AI system, marking a significant milestone as this was done without human intervention.",
      "This technology uses a proprietary large language model (LLM) to analyse and amend contracts with the aim to streamline the legal paperwork process.",
      "Despite this automation, humans are still required for the final step of signing the agreement, but the company believes this technology could expedite business transactions by automating review and negotiation of routine documents."
    ],
    "commentBody": "",
    "commentSummary": [
      "Luminance, a British AI company, has created an AI system named Autopilot, achieving a first by successfully negotiating a contract with another AI system without human intervention.",
      "Autopilot uses a proprietary Large Language Model (LLM) to automate the analysis and modification of contracts, potentially eliminating much of the paperwork in the legal process.",
      "Humans still play a key role in finalizing the process by signing the agreements, but the company believes this technology could greatly accelerate business transactions through the automation of routine document review and negotiation."
    ],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1699375517823
  },
  {
    "title": "Attorney Enrico Schaefer Shifts Focus to AI Law at Traverse Legal",
    "originLink": "https://mitechnews.com/mitechtv/traverse-legal-focuses-on-artificial-intelligence-law/",
    "originBody": "Traverse Legal Focuses On Artificial Intelligence Law TRAVERSE CITY – Technology attorney Enrico Schaefer always zeros in on the top tech legal issues and now for Traverse Legal it is Artificial Intelligence law. He joins Matt and Mike on MITech TV to talk about legal issues with AI that everyone should know before they embrace this evolutionary technology. You also can check out more information at www.TraverseLegal.Com. By Mike Brennan|2023-11-07T10:32:04-05:00November 7th, 2023|Artificial Intelligence, mitechtv| Share This Story, Choose Your Platform! FacebookTwitterRedditLinkedInTumblrPinterestVk About the Author: Mike Brennan Founder of Michigan News Network, and serves as CEO, as well as Editor & Publisher of MITECHNEWS.COM. Brennan has worked since 1980 as a technology writer at newspapers in New York, NY, San Jose, CA., Seattle, WA., Memphis, TN., Detroit, MI., and London, England. He co-founded and served as managing editor of Pacific Rim News Service (SEATTLE), which developed a network of more than 100 freelance journalists in 17 Asia-Pacific countries. Related Posts AI Makes Human-To-Robot Communication More Seamless AI Makes Human-To-Robot Communication More Seamless November 7th, 2023 ChatGPT Detector Catches AI-Generated Papers With Unprecedented Accuracy ChatGPT Detector Catches AI-Generated Papers With Unprecedented Accuracy November 7th, 2023 Michigan Cyber Patriot Program Seeks Donations, Mentors To Stay Operational Michigan Cyber Patriot Program Seeks Donations, Mentors To Stay Operational November 5th, 2023 Motor City ISSA Meeting: Navigating The Security Challenges Of AI Motor City ISSA Meeting: Navigating The Security Challenges Of AI November 2nd, 2023 Buy Michigan Now Holiday Gift Guide Now Available Buy Michigan Now Holiday Gift Guide Now Available November 1st, 2023 MCWT Update: Luminescence Gala Nov. 11 MGM Grand Detroit MCWT Update: Luminescence Gala Nov. 11 MGM Grand Detroit October 31st, 2023",
    "originSummary": [
      "Technology attorney Enrico Schaefer is now concentrating on artificial intelligence (AI) law at Traverse Legal.",
      "During a conversation on MITech TV, Schaefer pointed out key legal considerations relating to AI technology.",
      "Additional information about AI law can be accessed on the Traverse Legal website."
    ],
    "commentBody": "",
    "commentSummary": [
      "Tech attorney Enrico Schaefer is now focusing on artificial intelligence (AI) law at Traverse Legal.",
      "Schaefer has highlighted crucial legal aspects related to AI technology in a discussion on MITech TV.",
      "Additional information on AI law can be accessed on Traverse Legal's website."
    ],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1699375517823
  },
  {
    "title": "Scarlett Johansson Sues AI App for Unauthorized Use of Her Digital Likeness and Voice in Promotion",
    "originLink": "https://www.pcgamer.com/scarlett-johansson-launches-legal-action-in-a-case-of-ai-imitating-life-imitating-art/",
    "originBody": "News Scarlett Johansson launches legal action in a case of AI imitating life imitating art By Rich Stanton published 7 November 2023 \"I think you shouldn’t miss it.\" COMMENTS (Image credit: Robyn Beck via Getty Images) Hollywood star Scarlett Johansson has launched legal action against an AI app that used her name and an AI likeness in an online advert, needless to say without permission. This is particularly ironic given that one of Johansson's most memorable roles was in the excellent 2013 film Her, where she voices an AI virtual assistant called Samantha that protagonist Theodore falls in love with. First reported by Variety, the 22-second ad has now unsurprisingly disappeared. It was for an image-generating app called Lisa AI: 90s Yearbook & Avatar, and per Variety began with a (genuine) clip of Johansson behind-the-scenes while playing Black Widow. \"What’s up guys,\" says Johansson, \"It’s Scarlett and I want you to come with me…\" before the ad transitions into AI-generated photos closely resembling the actor and an AI Johansson voice starts promoting the app, ending with the line \"I think you shouldn’t miss it\". The ad did have some small print saying \"Images produced by Lisa AI. It has nothing to do with this person.\" That doesn't seem like any sort of mitigation really, though Lisa AI's developer Convert Software is hardly alone in doing this. AI-based celebrity fakes are getting ever-more widespread on social media and even mega A-listers like Tom Hanks have fallen victim to such shenanigans: Hanks was recently forced to deny endorsing a dental plan that used an AI version of him in its marketing, though is yet to sue. \"I could be hit by a bus tomorrow, and that’s it, but performances can go on and on and on and on,\" said Hanks of the technology. \"And outside of the understanding that it’s been done with AI or deepfake, there’ll be nothing to tell you that it’s not me and me alone. And it’s going to have some degree of lifelike quality. That’s certainly an artistic challenge, but it’s also a legal one.\" I've contacted Convert Software to ask for comment on the lawsuit, and will update with any response. One thing to note is that this doesn't seem to be some huge firm but is possibly a one-person operation: the social media accounts are largely unused, and among the app notes and reviews the company tends to talk in the first-person singular. Lisa AI itself is built on existing software like ChatGPT, though it does come with various subscription plans. Whether the lawsuit actually goes anywhere is another matter: most of these things are settled quickly, especially when the infringement is so blatant, without the need for court. However the rise in such incidents means someone is going to push it eventually and try to set a precedent: Johansson's reps have confirmed she has nothing to do with the app, and her attorney Kevin Yorn told Variety: \"We do not take these things lightly. Per our usual course of action in these circumstances, we will deal with it with all legal remedies that we will have.\" PC Gamer Newsletter Sign up to get the best content of the week, and great gaming deals, as picked by the editors. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors By submitting your information you agree to the Terms & Conditions and Privacy Policy and are aged 16 or over. Rich Stanton Rich is a games journalist with 15 years' experience, beginning his career on Edge magazine before working for a wide range of outlets, including Ars Technica, Eurogamer, GamesRadar+, Gamespot, the Guardian, IGN, the New Statesman, Polygon, and Vice. He was the editor of Kotaku UK, the UK arm of Kotaku, for three years before joining PC Gamer. He is the author of a Brief History of Video Games, a full history of the medium, which the Midwest Book Review described as \"[a] must-read for serious minded game historians and curious video game connoisseurs alike.\" MORE NEWS Canon challenges ASML dominance with new chipmaking tech that could lead to cheaper chips Wordle today: Hint and answer #871 for Tuesday, November 7 LATEST A tech analysis of Cities: Skylines 2 proves it's rendering WAY too many polygons, making Cyberpunk 2077 look like Minecraft in comparison SEE MORE LATEST ► See comments MOST POPULAR Bored Ape owners suffer eye and skin injuries from UV lighting at a weekend NFT festival: 'Had so much pain and my whole skin is burned' By Andy ChalkNovember 06, 2023 Halloween's over but you can still scare yourself witless with this VR recreation of Amnesia By Rick LaneNovember 06, 2023 Starfield community patchers are frustrated by the game's lack of mod support: 'A lot of stuff is really broken compared to the other games' By Rick LaneNovember 06, 2023 When it comes to OLED burn-in what you do with your monitor matters more than whether it's an LG or Samsung panel By Jeremy LairdNovember 06, 2023 AMD prioritising multi-thread over single-thread performance for next-gen Zen 5 CPUs according to new rumours By Jeremy LairdNovember 06, 2023 Currently unobtainable Baldur's Gate 3 achievement teases a hardcore permadeath mode that I will never be brave enough to play By Fraser BrownNovember 06, 2023 Alienware built a gigantic 16-foot mechanical keyboard and mouse then convinced a DOTA 2 esports team to actually use it By Andy EdserNovember 06, 2023 EverQuest 2's former creative director has a bleak vision of gaming's future By Rick LaneNovember 06, 2023 Elon Musk's newest scheme is an AI chatbot that is 'based and loves sarcasm' By Rich StantonNovember 06, 2023 I was expecting prices to rise before Black Friday. I was not expecting to see an RTX 4070 gaming laptop drop below $1,000 By Dave JamesNovember 06, 2023 Turns out you can speedrun Duolingo, and someone did an entire course in 24 hours By Mollie TaylorNovember 06, 2023 LOAD COMMENTS",
    "originSummary": [
      "Scarlett Johansson is taking legal action against the AI app Lisa AI: 90s Yearbook & Avatar for using an AI-generated likeness of her and her name in an online ad without her consent.",
      "The ad features an AI-generated image of Johansson with a voice imitation promoting the app. Despite a small print disclaimer, Johansson's team believes it was an insufficient mitigation.",
      "This incident is not unique and reflects a broader issue in the industry: Tom Hanks recently had to refute a third-party endorsement using his AI-generated likeness in a dental plan advertisement."
    ],
    "commentBody": "",
    "commentSummary": [
      "Scarlett Johansson has initiated legal proceedings against an AI application named Lisa AI: 90s Yearbook & Avatar, for unauthorized use of her name and digital representation in an online advertisement.",
      "The advert features an AI-created version of Johansson, including a voice mimic, promoting the app, albeit with a small print disclaimer stating no affiliation with the celebrity.",
      "This incident isn't unique as celebrities' images being used without consent for marketing purposes have emerged before, noting the recent case of Tom Hanks refuting his endorsement of an AI-created version in a dental plan's marketing."
    ],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1699375517823
  },
  {
    "title": "Structuring AI Governance: EU Council Suggests Supervisory Framework for Foundational AI Models",
    "originLink": "https://www.euractiv.com/section/artificial-intelligence/news/governance-of-foundation-models-in-eus-ai-law-starts-to-take-shape/",
    "originBody": "By Luca BertuzziEuractiv.com Est. 5min 15:35 Content-Type: News News Based on facts, either observed and verified directly by the reporter, or reported and verified from knowledgeable sources. [Alexandros Michailidis/Shutterstock] Euractiv is part of the Trust Project >>> Print Email Facebook Twitter LinkedIn WhatsApp Telegram The Spanish presidency of the EU Council of Ministers has proposed a governance architecture for supervising the obligations on foundation models and high-impact foundation models that includes the establishment of a scientific panel. Specific obligations on foundation models like OpenAI’s GPT-4, which supports ChatGPT, the world’s most famous chatbot, are being discussed in the context of the AI Act. This legislative proposal aims to regulate Artificial Intelligence following a risk-based approach. The AI law is at the last phase of the legislative process, in so-called trilogues between the EU Council, Parliament and Commission. Thus, the presidency’s proposed approach on governance, put forward on Sunday (5 November), might be highly influential in the ongoing discussions. Spanish presidency pitches obligations for foundation models in EU’s AI law The Spanish presidency of the EU Council of Ministers has drafted a series of obligations for foundation models and General Purpose AI as part of the negotiations on the AI Act. Foundation model supervision The text indicates that the European Commission would have exclusive powers to supervise the obligations on foundation models, including the ‘high-impact’ ones subject to a tighter regime. The EU executive could investigate and enforce these provisions, either on its own initiative or following a complaint from an AI provider with a contract with the foundation model provider or from a newly established scientific panel. The Commission is to define via implementing acts the procedures for monitoring the application of the obligations for foundation model providers, including the role of the AI Office, the appointment of the scientific panel and the modalities for conducting audits. The EU executive will have the power to conduct audits on foundation models “taking into utmost account the opinion of the scientific panel” to assess the provider’s compliance with the AI Act or to investigate safety risks following a qualified report from the scientific panel. The Commission could either carry out the audits itself or delegate them to independent auditors or vetted red-teamers. The auditors could request access to the model through an Application Programming Interface (API). For high-impact foundation models, the Spanish presidency proposed adversarial evaluations by red teams. For the presidency, the red teams could come from the provider. However, if the political decision is to make them external, the Spaniards have drafted an article empowering the Commission to award the status of ‘vetted red-teamer’. EU policymakers enter the last mile for Artificial Intelligence rulebook The world’s first comprehensive AI law is entering what might be its last weeks of intense negotiations. However, EU institutions have still to hash out their approach to the most powerful ‘foundation’ models and the provisions in the law enforcement areas. These vetted testers must show particular expertise, independence from the foundation model providers, and be diligent, accurate and objective in their work. The Commission is to establish a register of vetted red-teamers and define the selection procedure via delegated acts. The draft text empowers the EU executive, following a dialogue with foundation model providers, to request them to implement measures to comply with the AI law’s requirements and risk mitigation measures when serious concerns of risks are found via the audits. The EU executive will be able to request the documentation the foundation models will have to develop as part of their obligations, for instance, on the capacities and limitations of their model. This documentation might be requested and made available by a downstream economic operator who built an AI application on the foundation model. If the documentation raises concerns about potential risks, the Commission could request further information, initiate a dialogue with the provider and mandate corrective measures. Madrid also proposed a sanction regime for foundation model providers that infringes obligations under the AI Act or fails to comply with requests for documentation, audits or corrective measures. No percentage of the total worldwide turnover has been set yet. Governance framework The Spanish presidency proposed the creation of a ‘governance framework’ for foundation models, including ‘high-impact’ ones, including the AI Office and a scientific panel that will support the Commission’s activities. The activities envisaged are regularly consulting with the scientific community, civil society organisations and developers on the state of managing risks of AI models and promoting international cooperation with its peers. AI Act: EU countries headed to tiered approach on foundation models amid broader compromise The EU approach to powerful AI models is taking shape as European countries discuss possible concessions in the upcoming negotiations on the world’s first comprehensive Artificial Intelligence (AI) rulebook. Scientific panel The scientific panel tasks include contributing to the development of methodologies for evaluating the capabilities of foundation models, advising on the designation and the emergence of high-impact foundation models, and monitoring possible material safety risks related to foundation models. The members of the panel should be selected according to recognised scientific or technical expertise in AI, should act objectively and disclose any potential conflict of interest. They might also apply to be vetted red-teamers. Risky uncompliant systems The presidency proposed a revised procedure to deal with non-compliant AI systems that pose a significant risk at the EU level. In exceptional circumstances where the good function of the internal market might be at stake, the Commission might carry out an emergency evaluation and impose corrective measures, including withdrawal from the market. [Edited by Nathalie Weatherald] Read more with EURACTIV Spanish presidency pitches obligations for foundation models in EU’s AI law The Spanish presidency of the EU Council of Ministers has drafted a series of obligations for foundation models and General Purpose AI as part of the negotiations on the AI Act. Print Email Facebook Twitter LinkedIn WhatsApp Telegram Topics AI Act AI Office artificial intelligence Artificial Intelligence ChatGPT Foundation models high-impact foundation model Technology",
    "originSummary": [
      "The Spanish presidency of the EU Council of Ministers has proposed a governance structure for supervising foundational and high-impact AI models, which is part of ongoing regulatory discussions under the proposed AI Act.",
      "The proposed governance framework includes the establishment of a scientific panel. The European Commission would supervise the obligations on foundational AI models and could conduct audits or delegate them to independent auditors.",
      "The scientific panel, in collaboration with the AI Office, would contribute to the development of evaluation methodologies and assess potential safety risks. There was also a proposal for a sanction regime for model providers who fail to comply with obligations under the AI Act."
    ],
    "commentBody": "",
    "commentSummary": [
      "The Spanish presidency of the EU Council of Ministers proposed a governance structure for supervising foundational and high-impact AI models as part of discussions about the pending AI Act.",
      "The suggested framework involves establishing a scientific panel, allowing the European Commission to supervise obligations on foundational models, and delegating audits to independent auditors. This panel, in collaboration with the AI Office, would assist with creating evaluation methodologies and assessing safety risks.",
      "There is a proposed sanction regime for AI model providers that do not comply with obligations stipulated in the AI Act."
    ],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1699375517823
  },
  {
    "title": "OpenAI Introduces Copyright Shield to Support Customers Against Copyright Lawsuits",
    "originLink": "https://www.businessinsider.com/openai-legal-fees-chatgpt-customers-copyright-suits-sam-altman-2023-11",
    "originBody": "In a statement posted to the company's website, OpenAI clarified that the policy was called a Copyright Shield. picture alliance Redeem now OpenAI plans to offer assistance to customers that are facing copyright lawsuits. Sam Altman announced the policy during a keynote speech at OpenAI's first developer day conference. The move is likely aimed at reducing consumer anxiety around unresolved copyright claims. Advertisement Advertisement OpenAI CEO Sam Altman said the company would protect customers that were facing copyright lawsuits. Altman said during a keynote speech at OpenAI's first developer day conference the company would \"defend our customers\" by paying \"the costs incurred if you face legal claims around copyright infringement.\" In a statement posted to the company's website, OpenAI clarified the policy was called a \"Copyright Shield\" and available to ChatGPT Enterprise users, as well as its developer platform. \"OpenAI is committed to protecting our customers with built-in copyright safeguards in our systems,\" the statement said. Advertisement Advertisement The move is likely aimed at reducing consumer anxiety sparked by unresolved copyright claims against generative AI systems. OpenAI is already battling several lawsuits over claims the company used unauthorized copyrighted material in ChatGPT's training data. This includes one suit from a group of authors that numbers \"Game of Thrones\" writer George R.R. Martin among them. AI image generators have faced similar legal troubles from artists and stock image library Getty Images. The US Copyright Office has been scrambling to deal with the new challenge posed by AI-generated content for some time. Recently, the office has been mulling new rules for the models and the work they produce. Insider's Kali Hays previously reported that Google, Microsoft, and OpenAI were calling for users of generative AI tools to be held responsible for the results produced. Advertisement Advertisement \"In evaluating claims of infringement relating to outputs, the analysis starts with the user,\" OpenAI wrote in comments to the US Copyright Office, which were made accessible to the public last week. \"After all, there is no output without a prompt from a user, and the nature of the output is directly influenced by what was asked for.\" Google, which owns ChatGPT rival Bard, told the US Copyright Office: \"Any resulting liability should attach to the user.\" Sign up for notifications from Insider! Stay up to date with what you want to know. Subscribe to push notifications Read next Watch: What is ChatGPT, and should we be afraid of AI chatbots? ChatGPT OpenAI Google More... Advertisement",
    "originSummary": [
      "OpenAI has introduced a new policy termed \"Copyright Shield,\" announced by CEO Sam Altman, directed towards assisting customers entangled in copyright lawsuits.",
      "This policy is accessible to ChatGPT Enterprise users and developers and aims to alleviate consumer worries over unresolved copyright allegations against generative AI systems.",
      "OpenAI, presently engaged in multiple lawsuits over unauthorized usage of copyrighted content in ChatGPT's training data, continues to assert that users of such generative AI tools should shoulder the responsibility for the produced results."
    ],
    "commentBody": "",
    "commentSummary": [
      "OpenAI has launched a new program called Copyright Shield, in an attempt to support customers dealing with copyright lawsuits.",
      "The policy, announced by OpenAI CEO Sam Altman at their first developer conference, is available to ChatGPT Enterprise users and its developer platform.",
      "The initiative is aiming to alleviate consumer concerns in relation to unresolved copyright claims against generative AI systems, addressing their ongoing legal issues over alleged unauthorized use of copyrighted material in ChatGPT's training data."
    ],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1699375517823
  },
  {
    "title": "OpenAI Pledges Legal Support for Enterprise Users Facing Copyright Lawsuits with its Copyright Shield Initiative",
    "originLink": "https://cointelegraph.com/news/open-ai-cover-legal-costs-chatgpt-users-copyright-lawsuit",
    "originBody": "JESSE COGHLAN 15 HOURS AGO OpenAI promises to fund legal costs for ChatGPT users sued over copyright OpenAI joins Google, Microsoft and others in legally backing their users if they face legal action over copyright infringement. 5778 Total views 39 Total shares Listen to article 0:00 NEWS Join us on social networks OpenAI said it would cover the legal costs for business-tier ChatGPT users who find themselves in hot water over copyright infringement. OpenAI is calling its pledge Copyright Shield, which only covers users of its business-tier ChatGPT Enterprise and its developer platform. OpenAI isn’t covering users of the free and Plus ChatGPT versions. On Nov. 6, at the company’s first developer conference, DevDay, OpenAI CEO Sam Altman said, “We will step in and defend our customers and pay the costs incurred if you face legal claims around copyright infringement, and this applies both to ChatGPT Enterprise and the API.” Altman at OpenAI’s DevDay introduces the legal protection offer Copyright Shield. Source: YouTube OpenAI joins tech firms Microsoft, Amazon and Google in offering to legally back users accused of copyright infringement. Adobe and Shutterstock — stock image providers with generative AI offerings — also made the same promise. OpenAI’s DevDay also saw the firm announce that users can soon create custom ChatGPT models with the option to sell them on an upcoming app store, along with a new and updated AI model dubbed ChatGPT-4 Turbo. Related: AI chatbots are illegally ripping off copyrighted news, says media group OpenAI is facing a litany of suits alleging it used copyrighted material to train its AI models. Comedian and author Sarah Silverman, along with two others, sued OpenAI in July, claiming ChatGPT’s training data includes their copyrighted work accessed from illegal online libraries. OpenAI was hit with at least two further suits in September. A class action alleged OpenAI and Microsoft had used stolen private information to train models, while the Author’s Guild sued OpenAI, alleging “systematic theft” of copyrighted material. Magazine: ‘AI has killed the industry’ — EasyTranslate boss on adapting to change #AI #Copyrights #ChatGPT #OpenAI Add reaction READ MORE How blockchain, AI can help research into extending human life Scammers play a long game using bogus, AI-backed 'law firm' Meta chief AI scientist says AI won’t threaten humans",
    "originSummary": [
      "OpenAI is promising to undertake legal expenses for enterprise-tier users of ChatGPT facing copyright infringement lawsuits, under its initiative called the \"Copyright Shield.\"",
      "The \"Copyright Shield\" supports users of ChatGPT Enterprise and the developer platform but excludes users of the free and Plus versions.",
      "This move mirrors those by tech companies like Microsoft, Amazon, and Google, amid OpenAI facing allegations of using copyrighted materials to train its AI models."
    ],
    "commentBody": "",
    "commentSummary": [
      "OpenAI has committed to covering the legal expenses for business-tier users of ChatGPT who encounter copyright infringement lawsuits through an initiative known as Copyright Shield.",
      "The program applies to users of ChatGPT Enterprise and its developer platform but excludes users of the free and Plus versions, as announced by CEO Sam Altman at their first developer conference, DevDay.",
      "OpenAI's move is in line with those of other technology companies such as Microsoft, Amazon, and Google, who extend legal support to users facing accusations of copyright infringement. This initiative comes amidst ongoing lawsuits accusing OpenAI of using copyrighted materials to train its AI models."
    ],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1699375517823
  },
  {
    "title": "Mitigating Legal and Compliance Risks in Intelligent Use of AI by Companies",
    "originLink": "https://www.morganlewis.com/pubs/2023/11/is-your-company-using-artificial-intelligence-intelligently",
    "originBody": "Skip to content Skip to main navigation Skip to footer English Japanese Our Practice Our People Our Approach Our Thinking Our Firm Careers Locations Our Culture Subscribe Our Practice Our People Our Approach Our Thinking Our Firm Careers Choose Language Home > Our Thinking > Publications > Is Your Company Using Artificial Intelligence Intelligently?, The Legal Intelligencer Publications SUBSCRIBE Outside Publication Is Your Company Using Artificial Intelligence Intelligently?, The Legal Intelligencer November 06, 2023 In the latest installment of The Legal Intelligencer’s ongoing series on ediscovery and information governance, partner Jennifer Mott Williams and associate Bansri McCarthy delve into the world of artificial intelligence in an article discussing how organizations can mitigate legal and compliance risks while maintaining an evolving approach to an equally evolving technology. Read the full-text Legal Intelligencer article >> Authors Jennifer Mott Williams Partner Houston Bansri Mehta McCarthy Associate New York RELATED RESOURCES Sectors Technology Artificial Intelligence, Machine Learning & Automation Services eData Regions North America Contact Us Terms of Use Privacy Policy Cookie Policy Client Access Sitemap Copyright © 2023 Morgan, Lewis & Bockius LLP. All rights reserved.",
    "originSummary": [
      "Jennifer Mott Williams and Bansri McCarthy, in an article for The Legal Intelligencer, discuss the regulatory and legal risks related to the use of artificial intelligence (AI).",
      "They propose ways for companies to adapt and limit these risks while effectively utilizing AI.",
      "The authors emphasize the importance of organizations being mindful about prudently using this rapidly transforming technology."
    ],
    "commentBody": "",
    "commentSummary": [
      "This article by Jennifer Mott Williams and Bansri McCarthy in The Legal Intelligencer delves into the legal and compliance risks that accompany the use of artificial intelligence (AI).",
      "They provide suggestions on how companies can adapt and mitigate these risks while employing AI.",
      "The authors also address how organizations can intelligently incorporate this rapidly progressing technology."
    ],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1699375517823
  }
]
