[
  {
    "title": "Crafting Effective Prompts: A Guide to Mastering Legal AI with the 3Ps Framework",
    "originLink": "https://www.jdsupra.com/legalnews/mastering-the-art-of-legal-ai-prompting-4605039/",
    "originBody": "Menu News & Insights Popular Labor & Employment Finance & Banking Intellectual Property Health & Healthcare Environmental Issues more… Business Insurance Commercial Real Estate Corporate Taxes Immigration Securities more… Personal Residential Real Estate Estate Planning Civil Rights Personal Taxes Bankruptcy more… Jump to: Latest Updates » Trending [7] [Hot Topic] Artificial Intelligence [Hot Topic] Employer Liability Issues [Hot Topic] Environmental, Social & Governance [Ongoing] Read Latest SCOTUS Analysis, All Aspects Stay Informed: Popular Reads on JD Supra Meet JD Supra's Top Authors! Build a Morning News Digest: Easy, Custom Content, Free! Browse All Law News Topics » Find Author By Business Matters Labor & Employment Finance & Banking Intellectual Property Insurance Taxes By Personal Issues Civil Rights Family Matters Personal Injury Wills, Trusts, & Estate Planning Worker’s Compensation By Location California New York Texas Canada United Kingdom Subscribe Custom Email Digests Build a custom email digest by following topics, people, and firms published on JD Supra. Twitter RSS Feeds for Publishers For Reporters My Account Log In November 14, 2023 Mastering the Art of Legal AI Prompting: The 3Ps Framework Onit + Follow Contact LinkedIn Facebook Twitter Send Embed ARTIFICIAL INTELLIGENCE Well-crafted prompts are key to accurate, useful AI outputs. A prompt is your input to the LLM to guide its outputs. Essentially, it’s a question or statement the LLM is asked to respond to or build upon. Prompts can range from a single word to a whole paragraph, depending on what the user is trying to achieve. LLMs use the information in the prompt as a basis for generating their response, so the quality and clarity of the prompt can significantly influence the answer. Careful prompt design is key in instructing the LLM to produce the desired output. Vague prompts lead to confusion, but clear, detailed prompts elicit outstanding results. Framing prompts using the AI’s language gets the desired responses. THE FIRST STEP: BEGIN WITH BASICS AND PROGRESS GRADUALLY When integrating AI into legal tasks, start with straightforward, manageable prompts. For instance, initially use AI to summarize legal documents or provide legal principles overviews. This practical approach allows you to familiarize yourself with AI’s functionalities and limitations while developing proficiency in crafting effective prompts. It’s common to encounter challenges as you navigate this learning process. Rather than aiming for immediate perfection, view each challenge as an opportunity for constructive learning. These early experiences, even the difficult ones, lay the foundation for future success with AI. Remember that success with AI is collaborative. Adjust your approach accordingly if a prompt doesn’t yield the expected results. Refine prompts, analyze responses, and iterate as needed. This hands-on practice is key to mastering prompting and interpretation. As your skills develop, gradually introduce more complexity into prompts. Consistency in practicing core skills leads from proficiency in basics to efficiently handling advanced AI interactions. With a solid foundation, you’ll be well-equipped to fully harness AI’s potential for elevating legal work. THE 3PS PROMPTING FRAMEWORK The 3Ps approach provides a structured way to guide AI systems through effective prompting. It consists of: PROMPT: This is the core instruction provided to the AI detailing exactly what you want it to do. A properly engineered prompt includes clarity, specificity, examples, constraints, and ample context to guide the system. The prompt is where you ask the AI for what you need, whether it’s a legal summary, analysis, document draft, or other output. An effective prompt maximizes accuracy. Combining thoughtful priming, persona setting, and a meticulously crafted prompt allows prompting at an expert level to get the most out of legal AI systems. PRIMING: Priming involves setting the stage and establishing the necessary context for the AI. Imagine you need to brief a junior lawyer on a case’s background before they can work on it; explaining the goals, facts, and history allows them to dive in effectively. Similarly, priming an AI lays the groundwork for success. Examples of priming include summarizing documents the AI needs to read for context, explaining the business objectives, client needs, or legal issues involved, or providing any required definitions or domain knowledge. PERSONA: You can specify a persona if you want the AI to adopt a specific perspective. This puts the AI in a certain mindset, similar to how lawyers think differently depending on their role, like prosecution vs. defense attorneys. Persona examples include patent lawyer (frames responses from a patent law point of view), plaintiff’s attorney (approaches issues from a plaintiff-favoring stance), and criminal prosecutor (considers implications in building a case against the accused). ANATOMY OF A STRONG PROMPT Now that we’ve covered the basics let’s dive into the anatomy of what makes an effective, robust prompt. What core attributes define a truly “strong” prompt? Effective prompts contain: Clarity – Unambiguous, precise phrasing Specifics – Exact definitions of needed information Context Richness – Sufficient background information for depth and insight Good Structure – Clear formatting that aids comprehension Readability – Use simple, concise language. Examples – To illustrate desired outputs Constraints – Outline boundaries and limitations (output length or formatting, timeframe, geography, etc.). Accuracy – Avoiding errors that cause misleading results Large language models are trained on extensive written text, making structural details like complete sentences and line breaks important for accurate responses. Constraints and examples guide the AI by setting expectations and a pathway to follow. Every element of a prompt influences the AI’s response. Vague prompts confuse the AI, while focused, tight phrasing elicits spot-on responses. Constraints like length limits limit the scope. Examples guide better outputs. Each detail shapes the final result. Craft prompts carefully, considering how each component impacts the AI’s understanding. KEY TECHNICAL SETTINGS When using AI systems, there are specific settings you can adjust that impact how the AI responds. Knowing these key technical settings as a beginner will help you get better results. Creativity Setting: This controls how consistent or varied the AI’s responses will be. A high creativity setting makes the responses more random and diverse. But it also increases the chance of incorrect or nonsensical outputs. A low creativity setting makes the AI’s answers more predictable and fact-based. But the responses might be too basic. Response Length Setting: This controls the approximate length of the AI’s responses. Longer responses allow the AI to provide more detailed explanations. But it limits how much background context you can provide in your prompt. Shorter response settings enable you to give more context upfront in your prompt. But, the AI’s answers may lack depth. Using moderate creativity settings and medium response lengths is a good starting point. As you get more experience, you can refine these settings per use case. The key is balancing detail, consistency, and context to get optimal results. Send Print Report Latest Posts Mastering the Art of Legal AI Prompting: The 3Ps Framework 7 AI Applications for In-House Legal Workflows 5 Key Factors to Consider When Integrating AI into Your Legal Department [Webinar] Mastering AI For Legal Professionals: A Practical Course in Generative Technologies - October 5th, 2:00 pm - 3:30 pm CT The ROI of Legal Operations: Measuring Success and Demonstrating Value with Legal KPIs See more » Written by: Onit Contact + Follow more less Published In: Algorithms + Follow Artificial Intelligence + Follow Automation Systems + Follow Innovative Technology + Follow Legal Project Management + Follow Machine Learning + Follow Professional Practice + Follow Science, Computers & Technology + Follow more less Onit on: \"My best business intelligence, in one easy email…\" Your first step to building a free, personalized, morning email brief covering pertinent authors and topics on JD Supra: Sign Up Log in *By using the service, you signify your acceptance of JD Supra's Privacy Policy. - hide - hide Back to Top Home What Is JD Supra? Subscribe Leverage Your Thought Leadership Privacy Policy Terms & Conditions Contact Team Cookie Preferences Explore 2023 Readers' Choice Awards Copyright © 2023 JD Supra, LLC",
    "originSummary": [
      "Crafting effective prompts is crucial when using AI in legal tasks, and starting with simple prompts and increasing complexity can help develop proficiency.",
      "The 3Ps framework (prompt, priming, and persona) is a structured approach to guide AI systems in legal tasks.",
      "Strong prompts have key attributes, and adjusting technical settings can impact the AI's responses."
    ],
    "commentBody": "",
    "commentSummary": [],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1700054524288
  },
  {
    "title": "Law.com: The Ultimate Platform for Legal Professionals",
    "originLink": "https://www.law.com/2023/11/15/will-ai-finally-disrupt-legal-billing-the-morning-minute/",
    "originBody": "Law.com",
    "originSummary": [
      "Law.com is a newly launched website that provides legal professionals with access to legal news, analysis, and resources all in one place.",
      "The platform aims to offer a convenient and comprehensive source of information for legal professionals to stay informed about the latest trends and developments in the legal industry."
    ],
    "commentBody": "",
    "commentSummary": [],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1700054524288
  },
  {
    "title": "Updated Risk Management Frameworks Crucial for Procuring AI Tools, Warns Law Firm",
    "originLink": "https://news.bloomberglaw.com/us-law-week/companies-should-ask-these-risk-questions-when-procuring-ai-tools",
    "originBody": "Parker Poe’s Sarah Hutchins, Debbie Edney, and Robert Botkin emphasize the importance of updating risk-management frameworks to reflect evolving best practices in AI procurement. As businesses increasingly consider artificial intelligence tools to augment, supplement, or replace a variety of functions, it’s crucial to update risk-management frameworks to reflect best procurement practices. Failing to do so can lead companies to adopt what seems like an AI panacea, but is actually a Pandora’s box of regulatory enforcement and litigation risks. Businesses should look to the World Economic Forum’s guidelines for adopting AI responsibly and consider the following questions when procuring AI tools. Do I Understand the Data? AI tools can seem complicated, but they’re only as robust as the data they’re trained on. Businesses should seek assurances from their AI vendors on collecting, using, and disclosing data used to train the model. Vendors should demonstrate they secured all the consent necessary when collecting data from consumers under applicable law. Businesses also should vet the AI tool’s data usage and training methods when onboarding it. And vendors should detail their governance programs, audits, and other mechanisms that ensure the tool’s usability, reliability, and potential for bias, inaccuracies, and unfairness. When inputting company data, businesses need to understand how the vendor will use that data for training purposes, and should think through the possible use cases for internal data that may or may not be uploaded. Finally, a company should understand the tool’s accessibility to company data, and ask whether the data could be collected and reviewed in litigation, if necessary. Have I Considered Regulatory Scrutiny? The Department of Justice, Federal Trade Commission, and other regulators are focused on whether technology companies and their tools create anti-competitive environments or put consumers at a disadvantage. Given the powerful insights AI tools can provide, regulators are concerned with the harm they may have on consumers. An AI tool could be used in marketing and pricing strategies to accurately predict a specific consumer’s spending capacity, for example. The business could then ensure every widget is sold at the highest price that each individual consumer is willing to pay. Regulators have also focused on how bias and inaccuracies in AI output disadvantage certain categories of consumers. AI tools can expand opportunity for anti-competitive market collaboration. Take an element of antitrust law that has long been settled: Companies can’t collude to set future prices but can share historical prices. If an AI tool combs through a massive volume of competitors’ historical price data, “the distinctions between past and current or aggregated versus disaggregated data may be eroded,” Principal Deputy Assistant Attorney General Doha Mekki warned this year. “Where competitors adopt the same pricing algorithms, our concern is only heightened.” By thinking how the data sources could cross a line concerning competitive information, businesses can proactively navigate evolving regulatory risks. Have I Mitigated Security Risks? Cyberattacks on AI vendors have \" potential to impact the integrity of the AI model’s decisions and predictions,” World Economic Forum’s guidelines say. Data duplicated into an AI tool is vulnerable to access by a bad actor, and companies should exercise caution when inputting personally identifiable information. Depending how the tools are integrated, they could create a new back door to company systems. This is particularly true for AI tools that “crawl” through systems looking for places to create efficiencies and where AI tools can make certain fetch or “get” requests for data. It is essential to understanding the vendor’s cybersecurity defenses, including what proactive steps it takes to detect attacks and how its incident response plan would minimize the effects of a breach. Did I Include Best Practices in the Contract? Businesses should ensure they have appropriate clauses in contracts with AI vendors to address usage of provided data, data retention and destruction, intellectual property rights, security breaches, and other standard contractual clauses. Special security measures should be in place for certain categories of data, such as limiting or encrypting data based on personal information that implicates data privacy regulations. Additionally, World Economic Forum guidelines suggest including a compliance statement in master service agreements, such as the Responsible Artificial Intelligence Institute certification, which aligns with current AI regulations and principles. The guidelines also suggest businesses develop their own key performance indicators. Businesses should further consider whether policies providing guidance to employees on proper use are warranted. AI is rapidly changing how the world does business. To maximize the promise of AI while minimizing its risks, companies should be diligent in the proactive assessment of AI tools and protect themselves through each contract. This article does not necessarily reflect the opinion of Bloomberg Industry Group, Inc., the publisher of Bloomberg Law and Bloomberg Tax, or its owners. Author Information Sarah Hutchins is partner at Parker Poe and leads the firm’s cybersecurity and data privacy team. Debbie Edney is counsel at Parker Poe and has experience representing corporate, financial, and individual clients in all aspects of complex commercial litigation. Robert Botkin is an associate at Parker Poe and helps clients navigate data privacy and security issues across industries. Write for Us: Author Guidelines Continue Reading Learn About Bloomberg Law AI-powered legal analytics, workflow tools and premium legal & business news. Learn more Already a subscriber? Log in to keep reading or access research tools. Log In",
    "originSummary": [
      "Parker Poe law firm highlights the need for updating risk-management frameworks when acquiring AI tools to avoid regulatory enforcement and litigation risks.",
      "Businesses should ask important questions when procuring AI tools, such as understanding the data used for training, considering regulatory and anti-competitive scrutiny, and mitigating security risks.",
      "Contracts with AI vendors should include best practices to protect companies and maximize the benefits of AI while minimizing risks."
    ],
    "commentBody": "",
    "commentSummary": [],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1700054524288
  },
  {
    "title": "The Tech Industry's Concerns about Copyright Laws and Artificial Intelligence",
    "originLink": "https://newrepublic.com/article/176932/silicon-valley-ai-copyright-law",
    "originBody": "Matt Ford/ November 15, 2023 Disruptions The Tech Industry’s A.I. Dreams Might Be Headed for a Rude Awakening Silicon Valley thought that the copyright issues over their shiny new tech was a settled matter. They thought wrong. Steve Jennings/Getty Images Andreessen Horowitz co-founder Marc Andreessen speaks at a conference. In the latest Mission: Impossible film, Tom Cruise’s character must defeat his most daunting threat yet: a renegade artificial intelligence program that became sentient and quietly seized control of the world’s financial, political, and military systems. His only way to stop it is a two-piece physical key that he must insert into a computer in a sunken Russian submarine somewhere in the ocean depths. It’s a good action movie, but there’s a glaring plot hole in it. Cruise goes through all these extensive fight sequences—fights on moving trains, chases through narrow alleys, motorcycle jumps from cliffs—to find the key and stop the A.I. program. It’s a lot of time and effort. Why didn’t he just file a copyright lawsuit against it instead? According to Silicon Valley, those legal battles could endanger its attempts to develop sophisticated A.I. programs of their own. That, at least, is what Silicon Valley is telling the U.S. Copyright Office. That agency is currently conducting a policy review to consider how federal copyright laws apply to A.I.-generated works. Andreessen Horowitz, which ranks as the most influential venture-capital fund in the tech industry, used this as an opportunity to set off alarm bells. “The bottom line is this: imposing the cost of actual or potential copyright liability on the creators of AI models will either kill or significantly hamper their development,” Andreessen Horowitz warned. It claimed that generative A.I. programs represent a “new computing paradigm” that could be as transformative as the microchip, and that applying existing copyright laws to it would threaten America’s place “as the leader in global AI development.” Generative A.I. programs have become the new next big thing over the last few years. Programs like ChatGPT, which “answers” questions that you pose to it, and DALL-E, which “creates” images based on user inputs, have broken through into public consciousness. And yet the looming questions over copyright violations threaten to bring it to a grinding halt. A.I.’s problem with copyright law starts with its programming. Despite the branding, generative A.I. programs are not really “artificial intelligence.” They are not sentient. They cannot imagine or dream or fall in love. They cannot generate an umprompted idea or “create” anything in the traditional sense. What they are is an (often impressive) simulacrum of genuine intelligence. The programs achieve this by ingesting, for lack of a better word, large amounts of raw material. Early versions of ChatGPT were seeded with a wide variety of information to serve as the raw matter into which the A.I. would shape content, including the entire English-language Wikipedia, substantial libraries of ebooks, and large swaths of Reddit. From this raw material, ChatGPT and similar programs use algorithms to find patterns and then regurgitate them in response to user prompts. So, for example, if you were to ask a generative A.I. program for the names of all 50 U.S. states, the program isn’t reciting that song that we all learned in first grade to remember them. Instead, the program creates an answer by analyzing the database it was “trained” on and then displays it in a conversational tone. There are pitfalls to this approach of generating information. A program is only as good as the material it ingests. And since it does not actually “look” for the answer but instead constructs it based on probabilistic appearances in a limited corpus of text, it can be disastrously wrong. Earlier this year, a lawyer used ChatGPT for research in a personal-injury lawsuit against an airline, only to discover that it gave him a bunch of fake case names and nonexistent court rulings. ChatGPT had created them out of thin air based on the appearance of similar case names and court rulings in its “language learning model,” or LLM. Starting with how the technology actually works, instead of how it appears to work, is essential to understanding the copyright issues involved with generative A.I. programs. These programs, strictly speaking, do not create anything genuinely new or original. They only break down existing works into their constituent parts and stitch them back together again. There is no imagination or inspiration or contemplation or anything else that humans typically associate with knowledge and learning. There is just regurgitation—albeit at a very complicated level—done at computing speeds that the human mind cannot match. Copyright law is designed to protect that human spark of creativity. Conversely, it does not apply when that spark is missing. Federal courts have previously held that copyright protections only extend to humans, most famously by ruling in 2016 that a selfie taken by a monkey with a photographer’s camera was in the public domain. The U.S. Copyright Office has taken a similar approach. Earlier this year, the office partially rescinded a copyright for a comic book after learning the author had used Midjourney, a generative image program, to illustrate it. The agency reasoned that “artificial intelligence” can’t hold a copyright. It only gets worse for the programs from there. Companies that create generative A.I. programs are also facing a wave of lawsuits over the alleged use of unauthorized copyrighted materials to develop them. In September, for example, the Authors’ Guild and a coalition of high-profile authors sued OpenAI, arguing that its use of their works to potentially create derivative ones infringed on their copyrights and threatened their livelihoods. “Unfairly, and perversely, without Plaintiffs’ copyrighted works on which to ‘train’ their LLMs, [OpenAI] would have no commercial product with which to damage—if not usurp—the market for these professional authors’ works,” the authors argued in their complaint. “[OpenAI’s] willful copying thus makes Plaintiffs’ works into engines of their own destruction.” Most A.I. companies—but not all; we’ll come back to that later—have argued that their use of copyrighted material falls under a doctrine known as fair use. That doctrine is a limited exception of sorts to copyright laws. It allows for unauthorized use in a narrow set of circumstances, most often when the use is limited in nature and does not affect the copyright owner’s ability to profit from their own works. Andreessen Horowitz, in its comment to the U.S. Copyright Office earlier this month, argued that “training” generative A.I. programs is fair use. Two of its reasons were grounded in how the programs actually work. According to the firm, the programs do not technically “store” the material they use; they merely “extract facts and statistical patterns across a broad body of examples of content—i.e., information that is not copyrightable.” Additionally, the firm claimed, it is extremely unlikely that a program will generate something that is “substantially similar” to any individual work used to “train” it, which is a test used in copyright law. But the other two reasons the firm provided in defense of its A.I. investments were more revealing. For starters, it noted that “the only practical way generative AI models can exist is if they can be trained on an almost unimaginably massive amount of content, much of which (because of the ease with which copyright protection can be obtained) will be subject to copyright.” Since there is no right to create or use generative A.I. programs, this is not so much an argument as it is a plea for mercy. Applying copyright laws to A.I. would be, in other words, an existential threat to A.I. It would also be an existential threat to the venture-capital firms that have funded A.I. start-ups in recent years, as Andreessen Horowitz itself acknowledged in its fourth and final reason for fair use. “Over the last decade or more, there has been an enormous amount of investment—billions and billions of dollars—in the development of AI technologies, premised on an understanding that, under current copyright law, any copying necessary to extract statistical facts is permitted,” the firm claimed. “A change in this regime will significantly disrupt settled expectations in this area.” “Settled” is a strange choice of phrasing here. While investments in A.I. start-ups have surely been made over the last decade, generative A.I. programs did not become publicly available or widely used until within the last few years. Once they appeared, a variety of plaintiffs took those companies to court to stop them. Multiple record publishers are suing Anthropic over its alleged use of copyrighted song lyrics. Getty Images sued Stability AI earlier this year for using its library to train an image generator. Companies like Google, Microsoft, and Adobe have promised to indemnify companies that face legal threats for using their A.I. products. The actors’ and writers’ unions in Hollywood even went on strike this summer in no small part to halt the studios’ threats to use A.I. to replace them. Silicon Valley has “disrupted” multiple industries over the years by moving fast and breaking things, so to speak. This time, the affected industries are trying to slow down and stop tech start-ups so they don’t get “settled” in the first place. One solution to which I alluded earlier would be to simply pay to use the copyrighted material. Some major tech companies that can afford to do it already do. But Andreessen Horowitz doesn’t want to do that. “A staggering quantity of individual works is required to train AI models,” the firm told the U.S. Copyright Office. “That means that, under any licensing framework that provided for more than negligible payment to individual rights holders, AI developers would be liable for tens or hundreds of billions of dollars a year in royalty payments.” That would create an “impossibly high financial barrier to AI development” for “small businesses or individual innovators.” That would also be bad for Andreessen Horowitz, which probably would not have invested billions of dollars in A.I. start-ups just for them to spend billions of dollars on royalties. It runs counter to the zeitgeist that animates Silicon Valley’s A.I. push. The fundamental goal of A.I. is to reap the benefits of creative or intellectual labor without having to pay a human being—writers, artists, musicians, lawyers, journalists, architects, and so on—to perform it. A.I. developers, in other words, seek to create something from nothing. But that is not how the laws of thermodynamics work. And unless the courts and federal regulators suddenly embrace the tech industry’s novel new theory of fair use, it will not be how the laws of copyright work either. Matt Ford @fordm Matt Ford is a staff writer at The New Republic. Read More: The Soapbox, Politics, Law, Copyright Law, Buenos Aires, Ai, Artificial Intelligence, Chatgpt, Silicon Valley, Big Tech",
    "originSummary": [
      "The tech industry is concerned about the impact of copyright laws on artificial intelligence (AI) programs, particularly generative AI programs that rely on patterns in existing data.",
      "Generative AI programs are facing copyright issues as they do not create truly original works, leading to lawsuits over alleged use of copyrighted material.",
      "Silicon Valley argues that applying copyright laws to AI could pose a significant threat to the industry and venture-capital firms that have invested in AI start-ups, while the debate continues on whether fair use exceptions apply to AI programs."
    ],
    "commentBody": "",
    "commentSummary": [],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1700054524288
  },
  {
    "title": "Class Action Lawsuit Targets UnitedHealth's AI Algorithm for Denying Elderly Care Claims",
    "originLink": "https://www.benzinga.com/news/large-cap/23/11/35798289/legal-action-targets-unitedhealths-alleged-misuse-of-ai-concerns-around-denial-of-elderly-care-cla",
    "originBody": "Get Benzinga Pro DATA & APIS EVENTS MARKETFY PREMARKET BOOST ADVERTISE Contribute SIGN IN Our Services News Markets Ratings Ideas Yield Money Alts Crypto Cannabis RESEARCH My Stocks Tools - – –% - – –% - – –% - – –% - – –% - – –% - – –% Legal Action Targets UnitedHealth's Alleged Misuse of AI, Concerns Around Denial of Elderly Care Claims by Vandana Singh, Benzinga Editor November 15, 2023 8:09 AM1 min read A proposed class action lawsuit filed against UnitedHealth Group Inc UNH claims that the company's use of an artificial intelligence algorithm systematically denies essential extended care for elderly patients. The lawsuit, filed in federal court in Minnesota, was brought by family members of two deceased UnitedHealth beneficiaries who were compelled to pay out of pocket for medically necessary care that the insurer refused to cover. The plaintiffs aim to represent a nationwide class of individuals on Medicare Advantage insurance plans, administered by private health insurers like UnitedHealth but funded by the U.S. Medicare program. The lawsuit specifically focuses on an AI algorithm called nH Predict, developed by NaviHealth Inc., a company acquired by UnitedHealth in 2020, Reuters noted. Allegedly, UnitedHealth relies on nH Predict to assess claims for post-acute care, including stays in skilled nursing facilities and in-home care, resulting in premature and bad-faith discontinuation of healthcare payments. The complaint highlights that when these coverage denials are appealed to federal administrative law judges, approximately 90% of them are overturned, indicating the significant inaccuracy of the algorithm. Ryan Clarkson, founder of the law firm representing the plaintiffs, emphasized that only a fraction of patients appeal these denials, shedding light on the pervasive impact of UnitedHealth's practices. The lawsuit contends that UnitedHealth's utilization of nH Predict violates patient contracts and insurance laws across multiple states by making claim decisions without adequate evaluation. It seeks a court order to halt this practice and financial compensation for affected individuals. Price Action: UNH shares closed at $540.38 on Tuesday. Disclaimer: This content was partially produced with the help of AI tools and was reviewed and published by Benzinga editors. © 2023 Benzinga.com. Benzinga does not provide investment advice. All rights reserved. Posted In: Large CapNewsHealth CareLegalGeneralAI GeneratedBriefs Popular Channels PreMarket Prep Press Releases Analyst Ratings News Options ETFs Tools & Features Real Time Feed Public RSS Feeds Submit News Tips Blog Embeddable Finance Widgets & Tools Benzinga Catalyst Partners & Contributors Affiliate Program Contributor Portal Licensing & Syndication Sponsored Content Advertise With Us Lead Generation & SEO About Benzinga About Us Careers In The News Events Contact Us Terms & Conditions Do Not Sell My Personal Data/Privacy Policy Disclaimer Service Status Sitemap © 2023 BenzingaAll Rights Reserved",
    "originSummary": [
      "A proposed class action lawsuit has been filed against UnitedHealth Group, accusing the company of using an AI algorithm that unjustly denies necessary extended care for elderly patients.",
      "The algorithm, called nH Predict, allegedly leads to premature and bad-faith termination of healthcare payments.",
      "The lawsuit seeks to represent a nationwide class of individuals on Medicare Advantage insurance plans and aims to obtain a court order to stop the practice, as well as financial compensation for those affected."
    ],
    "commentBody": "",
    "commentSummary": [],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1700054524288
  },
  {
    "title": "Regulating AI in Radio: Addressing Opportunities and Legal Challenges",
    "originLink": "https://www.redtech.pro/regulating-ai-opportunities-and-legal-challenges-for-radio/",
    "originBody": "As we continue to navigate the evolving age of artificial intelligence, the media sector is undergoing transformative changes. AI’s capabilities offer a wealth of opportunities for media companies in content creation, curation, production, marketing, sales, distribution and user engagement. However, with these exciting prospects come legal challenges and risk factors, particularly for radio broadcasters. A key concern for rights holders is AI’s reliance on large volumes of training data, often sourced from the internet and protected by copyright. This issue is further complicated when AI developers fail to disclose the sources of data used in their algorithms. This can have significant legal implications for the media sector, which traditionally owns vast libraries of content and data. The “commercial” text and data mining (TDM) exception in EU copyright law provides a loophole, allowing media organizations to opt out and retain control over their content. However, enforcing this rule is a conundrum due to the challenges of detecting and proving the use of copyrighted content for AI training. In response to the legal challenges of copyright enforcement, several publishers and media companies have already entered into negotiations regarding the use of media content in AI training to ensure monetization and legal use of copyrighted content. A need for closer scrutiny The European Commission’s proposed AI law is also an important step towards harmonizing rules on AI, with the European Parliament supporting a transparency requirement in Art. 28 b AI-Act (current draft). This requirement would make it possible to identify the content used to train AI, addressing concerns about the visibility of content and allowing AI developers to demonstrate their commitment to using high-quality content. Whether the ongoing trilogue negotiations will retain these essential transparency requirements remains to be seen. But that’s not enough. Closer scrutiny by European, national and international regulators is essential to remove ambiguities and disputes, ensure media plurality and promote a more balanced AI landscape. What would be the necessary steps to close legal loopholes and ensure value creation for rights holders? The lawmakers should explicitly extend copyright and ancillary copyright protection to the use of AI models and shift the burden of proof to AI providers. Creators and rights holders must be able to opt out from TDM without penalty and should be compensated for the use of their content. Regulatory and enforcement measures have to prevent gatekeepers from discriminating against creative content in favor of AI content, and AI development should not interfere with source material without explicit permission. For radio and audio publishers, the key challenge is how to increase productivity and efficiency with Broadcasters will need to navigate these issues carefully to reap AI’s benefits while ensuring compliance with copyright laws. Recent advances in AI, such as ChatGPT, Bing AI and Bard, demonstrate the potential of AI and its risks, such as mass plagiarism and the spread of disinformation. These concerns are compounded by the concentration of significant AI resources in the hands of a few technology giants. This raises major competition and ethical issues, especially if these AI models are used to develop competing products or promote tacit collusion between companies. In this regard, Europe, with its proposed AI Act, Digital Services Act (DSA) and Digital Markets Act (DMA), is arguably better prepared to address these challenges from an antitrust and broader regulatory perspective. However, the United States needs to make further progress, as its current legislation does not include specific provisions for AI. Navigating the issues The rise of AI is likely to further empower large tech companies, as there are high barriers to entry in the computing, data creation and basic modeling layers of the AI stack. This situation, compounded by the opacity of the system, can lead to anti-competitive leveraging behavior that is difficult to detect and challenge. It is, therefore, crucial that competition law is prepared to deal with these challenges. In conclusion, while the advent of AI offers new methods of content creation and user engagement, it also presents significant legal challenges. Broadcasters will need to navigate these issues carefully to reap AI’s benefits while ensuring compliance with copyright laws. The EU’s efforts toward an AI law will play a key role in this evolving landscape. However, further steps are needed at national and international levels to ensure a fair and balanced approach to AI in the media. The author is deputy legal counsel for VAUNET. This text reflects the personal view of the author and not those of VAUNET. This article was taken from a RedTech special edition, “Radio Futures: AI Is Now Here!” which you can read here. More stories about AI Smart transmitter solutions for a sustainable future Antenne Deutschland and Radio.Cloud launch AI radio station AIB launches AI working group Could AI replace the radio news writer?",
    "originSummary": [
      "The media sector is undergoing significant changes due to the implementation of artificial intelligence (AI), presenting numerous opportunities for media companies in content creation, production, marketing, and user engagement.",
      "However, there are legal challenges and risks associated with AI, particularly for radio broadcasters, including concerns about using copyrighted training data that AI developers may not disclose.",
      "The EU's \"commercial\" text and data mining exception allows media organizations to maintain control over their content, but there are difficulties in enforcing this rule. Publishers and media companies are negotiating the usage of media content in AI training to ensure legal compliance.",
      "The proposed AI law by the European Commission includes transparency requirements to identify the content used for training AI, but further scrutiny by regulators is necessary to address ambiguities, promote media plurality, and establish a balanced AI landscape.",
      "Steps should be taken to close legal loopholes, extend copyright protection to AI models, shift the burden of proof to AI providers, allow content opt-out without penalties, and provide compensation to rights holders.",
      "In the United States, progress is needed in AI legislation to address concerns of empowering large tech companies and potential anti-competitive behavior, necessitating preparedness in competition law.",
      "Broadcasters must navigate legal challenges while taking advantage of AI, with the EU's AI law playing a crucial role, but additional actions are required at national and international levels to ensure a fair approach to AI in the media."
    ],
    "commentBody": "",
    "commentSummary": [],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1700054524288
  },
  {
    "title": "Challenges and Concerns Surrounding the Use of AI in the Legal Industry",
    "originLink": "https://www.pymnts.com/news/artificial-intelligence/2023/use-of-ai-in-the-legal-industry-faces-challenges/",
    "originBody": "WATCH NOWSUBSCRIBE Search PYMNTS TV Today B2B Retail Fintech Digital Transformation Crypto EMEA Tracker® Reports PYMNTS® Data Markets More Topics Artifical Intelligence Connected Car Buy Now Pay Later Banking Cloud Cross-Border Payments Gig-Economy Grocery & Pharmacy Healthcare Payments Insurtech Small & Medium Businesses Social Platforms Subscription Commerce Travel TechREG® Real-Time Payments Restaurants More Topics Featured SEE ALSO: Editor’s Picks Opinion CE100 Index Working Capital & Liquidity Competition Policy International A PYMNTS Company Stay Current Subscribe Become a Partner Use of AI in the Legal Industry Faces Challenges By PYMNTSNovember 14, 2023The legal industry’s widespread adoption of generative artificial intelligence (AI) will necessarily involve recalibrating workforce roles and skills and reckoning with varying degrees of readiness and trust among professionals within and across industries. Coupled with the challenges of this reboot are the thorny issues surrounding security, privacy and ethics. Additionally, the belief that generative AI will revolutionize efficiency for so much legal work is tempered somewhat by the majority of legal professionals who have reservations about the industry’s current preparedness for this AI-driven future. Compounding the challenges of actionably preparing the industry is the current lack of industrywide consensus about the merits of generative AI. While the evangelists are deeply optimistic that generative AI will have positive impacts on the profession, they currently represent only about half of professionals. As the industry wrestles with these as-yet unresolved issues, the road to widespread adoption of AI in the legal industry remains neither straightforward nor universally agreed upon. Shifting gears: Changes in the legal industry’s workforce for an AI-enabled future Many legal players nonetheless are restructuring their practices to accommodate the use of generative AI and, in doing so, are changing work dynamics and skill requirements. This has led to concerns that roles traditionally performed by humans are at risk. More than two-thirds of law professionals recently mused that roles responsible for much of the life cycle of knowledge management and research in the industry could be replaced by generative AI. However, these same respondents also voiced skepticism about the technology’s ability to perform high-level legal work such as facilitating corporate restructuring or navigating international trade disputes. The potential challenges to traditional roles, however, simultaneously present counterbalancing opportunities: the rising demand for both specialized AI skills and industry-specific technologies. Law firms are increasingly seeking AI experts, and the competition for LawTech talent has intensified. For instance, some firms are planning to expand their teams of lawyers and developers who work with AI. In fact, Allen & Overy recently introduced a chatbot to assist attorneys in drafting contracts and client memos — and its rivals are following suit. The shakeup that generative AI is bringing to the legal industry is affecting not only the workplace but also its precursor — legal education. Universities across multiple continents have established initiatives or courses to equip students and professionals with the skills to interact with AI in their practices. The trust gap: A legal industry polarized about its AI readiness Thus far, the use of generative AI in the legal industry has been characterized by a patchwork of readiness and trust, as evidenced by a range of conflicting opinions among legal professionals and firms. On the one hand, the legal industry exhibits cautious optimism about generative AI: More than 6 in 10 law firms and corporate legal departments believe the technology will deliver significant business advantages. On the other, 72% of legal professionals are doubtful that the industry is adequately prepared for the looming AI revolution, and, as noted earlier, only 1 in 5 believe the advantages of using AI surpass the disadvantages. For example, the University of Liverpool offers a module that provides “hands-on experience” with legal tech tools, while the University of Technology, Sydney, has introduced specialized courses that cover topics ranging from governance and regulatory risks of AI use in legal matters to possible failure points of AI. In the United States, the University of Arizona Law School is spearheading a multi-institution initiative to prepare law libraries across the country for the strategic implementation of AI into their operations. As generative AI marches more deeply into legal territory, the discrepancy between roles at risk and those that require more nuanced human judgment will likely widen. This will necessitate a more systemic shift in legal education and clerking that focuses much less on rote skills and much more on strategy, ethics and other human-centric capabilities. Consequently, the legal firms most likely to pull ahead in this transition may not necessarily be the ones that adopt AI the fastest but those that adapt most holistically to this emerging ecosystem. Partly shaping this cautious outlook are concerns about the trustworthiness and reliability of generative AI in a legal context. More than half of legal professionals are uncertain about the technology’s reliability, and nearly 2 in 5 do not trust it. Consumers of legal services are not entirely won over either, with 55% of clients and potential clients expressing serious concerns about the use of AI within the legal profession. In the near term, disparities in perceptions about trust and readiness may create a segmented legal services market in which AI adoption varies significantly depending on the size of the firm and the specific legal tasks involved. As the industry becomes more accustomed to what AI can and cannot do, these disparities are likely to converge toward a more uniform framework of AI adoption. Ethical roadblocks: Security and privacy concerns surround AI usage in the practice law Although generative AI promises to unleash unprecedented efficiency gains for the legal sector, it also raises complex questions about security, privacy and ethics that cannot be ignored. The industry’s initial outlook toward these aspects has been one of both caution and concern. Many in the legal industry are wary of using generative AI, particularly consumer-facing AI technologies such as ChatGPT. More than 60% of legal professionals do not currently use the technology in their practice, citing security and privacy concerns. Their reluctance stems primarily from unresolved questions of how AI technologies handle privacy and ensure client confidentiality — a view disproportionately held by firms’ partners and managing partners. In response to these concerns, some law firms have already adopted internal measures, including warnings and outright bans against unauthorized use of generative AI in their legal work. The industry’s cautious stance toward the adoption of generative AI technologies is in large measure a manifestation of ethical and operational concerns pertaining to the use of the current iterations of this tech. If generative AI technologies become more robust and sophisticated, will the legal industry’s caution evolve into acceptance? Or will ethical and security concerns be amplified, creating even stronger barriers to adoption? Regulation and guidelines will be instrumental in answering these questions. Recommended Retail Subscribers Like to Stick With What’s Familiar Fed and CFPB Raise Dollar Thresholds for Applicability of Regulations Digital Identity as the New Currency Hackers Claim ICBC Paid to End Ransomware Attack See More In: AI-ID, artificial intelligence, ChatGPT, generative AI, Generative AI Tracker, Law, Legal Industry, News, PYMNTS Intelligence, PYMNTS News, Tracker Series Trending News Innovators Find ‘White Space’ in Making Business Payments Secure and Certain Fashion Wholesaler Marketplace JOOR Says Digital Payments Now in Style Knowing When Payments Will Arrive as Important as Getting Paid, Says Flock Freight CFO The Big Story Ad Hoc Payments Represent One in Every Four Vendor Payables Featured News Innovators Find ‘White Space’ in Making Business Payments Secure and Certain Fashion Wholesaler Marketplace JOOR Says Digital Payments Now in Style Knowing When Payments Will Arrive as Important as Getting Paid, Says Flock Freight CFO Forty Percent of Millennials Use Mobile Wallets to Pay Bills the Day They’re Due Biometric Authentication Tailor-Made for a Digital-First World The Challenge of Establishing Trust in the Age of Anonymous Commerce Inflation May Be Slowing, but Tell That to Consumers Living Paycheck to Paycheck Subscribe PYMNTS Today Artificial Intelligence Cryptocurrency B2B Retail TechREG® Digital Transformation SUBSCRIBE Partner with PYMNTS We’re always on the lookout for opportunities to partner with innovators and disruptors. Learn More",
    "originSummary": [
      "The legal industry is encountering various obstacles in adopting generative AI, including the need for workforce restructuring and addressing concerns related to trust, security, privacy, ethics, and the lack of industrywide consensus.",
      "While some legal professionals are adapting their practices for AI integration, there is skepticism regarding its capability to handle complex legal tasks.",
      "The mismatch between at-risk roles and those requiring human judgment necessitates changes in legal education. Concerns about AI reliability and potential ethical implications such as security, privacy, and client confidentiality need to be addressed through regulations and guidelines."
    ],
    "commentBody": "",
    "commentSummary": [],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1700054524288
  },
  {
    "title": "Lawsuit alleges UnitedHealth improperly denies elderly extended care using AI",
    "originLink": "https://www.reuters.com/legal/lawsuit-claims-unitedhealth-ai-wrongfully-denies-elderly-extended-care-2023-11-14/",
    "originBody": "Litigation Technology Litigation Corporate Structure Health Insurance Lawsuit claims UnitedHealth AI wrongfully denies elderly extended care By Brendan Pierson November 14, 20239:43 PM UTCUpdated 15 hours ago The corporate logo of the UnitedHealth Group appears on the side of one of their office buildings in Santa Ana, California, U.S., April 13, 2020. REUTERS/Mike Blake/File Photo Acquire Licensing Rights Companies UnitedHealth Group Inc Follow Nov 14 (Reuters) - UnitedHealth Group Inc (UNH.N) uses an artificial intelligence algorithm that systematically denies elderly patients' claims for extended care such as nursing facility stays, according to a proposed class action lawsuit filed on Tuesday. Family members of two now-deceased UnitedHealth beneficiaries sued the insurer in federal court in Minnesota, saying they were forced to pay out of pocket for care that doctors said was medically necessary. Advertisement · Scroll to continue They are seeking to represent a nationwide class of people on Medicare Advantage insurance plans, which are funded by the U.S. Medicare program for seniors and some people with disabilities and administered by private health insurers like UnitedHealth. Ryan Clarkson, founder of the law firm representing the plaintiffs, said in an interview the class could include tens of thousands of people, and that claims for damages could reach billions of dollars. Advertisement · Scroll to continue UnitedHealth did not immediately respond to a request for comment. The Minnetonka, Minnesota-based company is the largest U.S. health insurance provider through its UnitedHealthcare Inc subsidiary. The lawsuit centers on an AI algorithm known as nH Predict developed by NaviHealth Inc, a company acquired by UnitedHealth in 2020. It claims that UnitedHealth relies on nH Predict to evaluate claims for so-called post-acute care, which includes stays in skilled nursing facilities and in-home care. Advertisement · Scroll to continue UnitedHealth uses the algorithm to \"prematurely and in bad faith discontinue payment for healthcare services,\" the complaint said. \"This is an example of how AI is being utilized not to help people but to line the pockets of corporations and their shareholders,\" Clarkson said. When these coverage denials are appealed to federal administrative law judges, about 90% are reversed, the complaint said, demonstrating the \"blatant inaccuracy\" of the algorithm. Only a tiny fraction of patients appeal the denials at all, Clarkson said. The lawsuit said UnitedHealth's use of nH Predict violates contracts with patients and the insurance laws of numerous states by deciding claims without properly evaluating them. It seeks a court order stopping the practice and awarding money damages. Reporting By Brendan Pierson in New York, Editing by Alexia Garamfalvi and Richard Chang Our Standards: The Thomson Reuters Trust Principles. Acquire Licensing Rights , opens new tab Brendan Pierson Thomson Reuters Brendan Pierson reports on product liability litigation and on all areas of health care law. He can be reached at brendan.pierson@thomsonreuters.com. Read Next / Editor's Picks Business category Hollywood strikes sap economy as industry readies for revamp While Hollywood celebrates the end of strikes by writers and actors, the multibillion-dollar economic toll on everyone from crew members to caterers will take months to tally. ANALYSISUS drive to make green jet fuel with ethanol stalled by CO2 pipeline foes The U.S. drive to develop sustainable aviation fuel (SAF) using ethanol could be slowed because of growing opposition to proposed pipelines that would curb greenhouse gas emissions from ethanol plants by capturing carbon dioxide and carrying it away to other states for storage. Sustainable Finance & Reporting category Workers United calls for walkouts at hundreds of Starbucks stores on Red Cup day The Workers United union said on Monday that thousands of employees at hundreds of Starbucks stores will walk out on the coffee chain's key Red Cup day promotional event this week, citing staffing and scheduling issues. World at Work category Stellantis offering buyouts to about half its US salaried employees Chrysler-parent Stellantis said Monday it is offering 6,400 U.S. salaried employees voluntary buyouts as it works to cut costs amid the transition to electric vehicles and agreeing to a new United Auto Workers contract. World category A century later, US Army overturns convictions of 110 Black soldiers The U.S. Army on Monday set aside the court-martial convictions from a century ago of 110 African American soldiers, including 19 who were executed, saying they were denied fair trials in a landmark acknowledgement of official racism in America. World at Work category Ford production workers at Kentucky, Louisville vote against new labor deal Production workers at Ford's Louisville assembly and Kentucky truck plants have voted against the tentative labor agreement, while skilled trades workers voted in favor, the local chapter of the United Auto Workers (UAW) said on Monday. World category Company insolvencies jump in England and Wales in October Business insolvencies in England and Wales rose 18% in annual terms during October, official data showed on Tuesday, in a further sign of the tough economic environment facing many firms. Business category UAW president to vow aggressive auto plant organizing in Senate testimony UAW President Shawn Fain will tell a Senate Committee the union plans to aggressively organize non-union U.S. auto plants after winning new contracts with the Detroit Three automakers. Business category US needs more pipeline capacity for reliable gas supply -trade group The U.S. needs more natural gas pipeline capacity to maintain reliable gas supply during extreme cold weather, a trade group representing pipeline companies said on Monday in support of regulators who last week urged sought new rules to prevent a repetition of last winter's power outages. Access to Justice category Study finds racial disparities in whether US judges impose prison Black and Hispanic defendants in federal court are less likely than white ones to be sentenced to probation rather than prison, a difference that largely accounts for the racial disparities in the punishments judges impose, according to a new study. Legal Industry category US law firm Buchanan to absorb 22-lawyer intellectual property firm U.S. law firm Buchanan Ingersoll & Rooney said on Tuesday it will combine with intellectual property law firm RatnerPrestia. People Moves category Law firm Cooley adds NY prosecutor who led public corruption unit Silicon Valley-founded law firm Cooley on Tuesday said it has hired Rebekah Donaleski, who spent nearly a decade in the Manhattan U.S. Attorney's Office and led its public corruption unit for three years. Government category Houston moves to toss some claims in lawsuit over minority contracting The city of Houston, Texas, has asked a federal judge to trim a lawsuit claiming that its program setting aside certain public contracts for minority-owned businesses violates the U.S. Constitution. Legal Ethics category British lawyer found guilty of 'tipping off' client about fraud probe A British lawyer was found guilty on Tuesday of \"tipping off\" his client about a money laundering investigation by Britain's fraud watchdog, which was part of a wider probe into allegations of corruption against Kazakh miner ENRC. Attorney Analysis category The new generation of legal leaders: Millennials make their mark on workplace culture Kirk Coleman of Major, Lindsey & Africa discusses surveys and research reflecting issues raised by millennials about the workplace, career plans, and law firm and company engagement. Legal Industry category Seven arrested over collapsed law firm Axiom Ince, UK officials say Britain's Serious Fraud Office arrested seven people on Tuesday in connection with the collapse of UK law firm Axiom Ince, the fraud watchdog said, as part of a probe into about 65 million pounds ($80.7 million) of missing client money.",
    "originSummary": [
      "UnitedHealth Group Inc is being sued in a proposed class-action lawsuit for allegedly using an artificial intelligence algorithm to deny elderly patients' claims for extended care.",
      "The algorithm, called nH Predict, is accused of prematurely and in bad faith discontinuing payment for healthcare services.",
      "The plaintiffs, representing Medicare Advantage insurance plan holders, are seeking court orders to halt this practice and seek monetary compensation, while UnitedHealth has not responded to the lawsuit."
    ],
    "commentBody": "",
    "commentSummary": [],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1700054524288
  },
  {
    "title": "Balancing Innovation and Oversight: The Importance of Ethical Considerations in AI Law Enforcement",
    "originLink": "https://www.progressivebritain.org/ai-ethics-in-law-enforcement-navigating-innovation-and-oversight/",
    "originBody": "Blog AI Ethics in Law Enforcement: Navigating Innovation and Oversight 15/11/2023By Tom McNeil",
    "originSummary": [
      "The blog emphasizes the significance of ethical considerations when utilizing artificial intelligence in law enforcement.",
      "It delves into the challenges of finding a balance between innovation and oversight in this area.",
      "Tom McNeil, the author of the blog, offers insights on how to effectively navigate these ethical challenges."
    ],
    "commentBody": "",
    "commentSummary": [],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1700054524288
  }
]
