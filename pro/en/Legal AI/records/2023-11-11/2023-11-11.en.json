[
  {
    "title": "Legal Aid to Offer Free Walk-in Legal Clinic for Low-Income Residents in Jennings County, Indiana",
    "originLink": "https://www.therepublic.com/2023/11/11/legal-aid-to-have-free-clinic-in-jennings-county/",
    "originBody": "Local News Legal Aid to have free clinic in Jennings County By Staff Reports - November 11, 2023 JENNINGS COUNTY — Legal Aid will have a free Legal Aid Walk In Clinic for Jennings County community members on Tuesday, Nov. 21 at the Jennings County Public Library in North Vernon. The clinic will be from 3 to 5 p.m. and is for low-income residents. The Legal Aid Clinic and Pro Bono Program utilizes local volunteer attorneys, offering free legal consultations to low-income individuals to those who might not otherwise be able to afford the counsel of an attorney. Individuals coming to the Legal Aid Clinic can expect to receive a 10-minute consultation to answer general and eviction questions, offer legal information, or to receive other limited pro se assistance or advice, in person, on a first-come, first-served basis. There is no need to register in advance. The general advice clinic for items such as adoptions, advance directives, family law, guardianships, protective orders, simple wills and small estates, is from 3 to 5 p.m. The eviction clinic is from 4 to 5 p.m. covering negotiations with a landlord, legal defenses to an eviction damage hearings and eviction records. No criminal law questions will be answered. For more information, visit legalaidpbi.org/services. Previous articleJennings historian wins state genealogy award Next articleNonprofits making progress in tackling homelessness among veterans, but challenges remain Staff Reports",
    "originSummary": [
      "Legal Aid will be hosting a free walk-in clinic in Jennings County, Indiana for low-income residents.",
      "The clinic will provide 10-minute consultations on general legal issues, eviction questions, and limited pro se assistance.",
      "The clinic will cover various legal topics such as family law, wills and estates, and negotiations with landlords, but will not address criminal law questions."
    ],
    "commentBody": "",
    "commentSummary": [],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1699709226785
  },
  {
    "title": "Chicago Legal Aid Clinic Assists Venezuelan Migrants with TPS and Work Authorization Applications",
    "originLink": "https://abc7chicago.com/chicago-migrants-venezeulan-legal-aid-clinic-free/14041768/",
    "originBody": "CHICAGO (WLS) -- It takes about 30 pages of government forms for a migrant to apply for Temporary Protected Status and work authorization. The federal status is only being offered to Venezuelans who arrived before August 1. \"Anyone who has ever done immigration knows it's a really, really deep process with a lot of forms in English and it requires a lot of nuanced information,\" said immigration attorney Nubia Willman. RELATED: Pilot program launching in Chicago to help migrants get work permits Willman and others volunteered their time Friday to help migrants in Ald. Bill Conway's 34th Ward navigate the process. Conway hosted his second legal aid clinic at no cost to taxpayers. \"We have about 30 volunteers who are lawyers, law students and translators that help people go through the very complicated forms,\" he said. READ MORE: Residents march against Brighton Park migrant camp plans Jesus Perdoma-Torres is grateful for the help. He, his partner and their two sons have been living at a downtown shelter for the past few weeks. Through a translator, he said he doesn't want to depend on the government to support himself and his family. He said he wants to work to provide for his children. But it won't happen overnight. \"The immigration processing times take quite a few months. It is a long process because they have to ensure that the person is eligible the person has to get biometrics,\" said Willman. Work authorization could take up to 16 months, but the Biden administration is trying to expedite the process. \"30 days is our goal, in some places it is happening, we can prove it is happening,\" said Illinois Senator Dick Durbin. Durbin stopped by the legal aid clinic. He hopes lawmakers can pass a budget soon that includes more humanitarian assistance for the migrants. For the thousands of migrants who arrived in Chicago after August 1 and do not qualify for TPS or work authorization, Sen. Durbin does not know if President Biden will extend his order to include them.",
    "originSummary": [
      "A legal aid clinic in Chicago is assisting Venezuelan migrants in applying for Temporary Protected Status and work authorization.",
      "The process can be lengthy, taking several months for approval, with work authorization potentially taking up to 16 months.",
      "The Biden administration aims to expedite the process, with a goal of achieving approval within 30 days."
    ],
    "commentBody": "",
    "commentSummary": [],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1699709226785
  },
  {
    "title": "5 Factors to Consider When Integrating AI in Your Legal Department",
    "originLink": "https://www.jdsupra.com/legalnews/5-key-factors-to-consider-when-1903540/",
    "originBody": "Menu News & Insights Popular Labor & Employment Finance & Banking Intellectual Property Health & Healthcare Environmental Issues more… Business Insurance Commercial Real Estate Corporate Taxes Immigration Securities more… Personal Residential Real Estate Estate Planning Civil Rights Personal Taxes Bankruptcy more… Jump to: Latest Updates » Trending [7] [Hot Topic] Artificial Intelligence [Hot Topic] Employer Liability Issues [Hot Topic] Environmental, Social & Governance [Ongoing] Read Latest SCOTUS Analysis, All Aspects Stay Informed: Popular Reads on JD Supra Meet JD Supra's Top Authors! Build a Morning News Digest: Easy, Custom Content, Free! Browse All Law News Topics » Find Author By Business Matters Labor & Employment Finance & Banking Intellectual Property Insurance Taxes By Personal Issues Civil Rights Family Matters Personal Injury Wills, Trusts, & Estate Planning Worker’s Compensation By Location California New York Texas Canada United Kingdom Subscribe Custom Email Digests Build a custom email digest by following topics, people, and firms published on JD Supra. Twitter RSS Feeds for Publishers For Reporters My Account Log In November 10, 2023 5 Key Factors to Consider When Integrating AI into Your Legal Department Onit + Follow Contact LinkedIn Facebook Twitter Send Embed Integrating advanced legal AI tools like LLMs catalyzes a significant shift for in-house legal teams. These models are evolving from mere tools to invaluable partners, extending in-house professionals’ capabilities. Adopting legal AI software is a strategic decision for in-house teams that can transform service delivery, enhance productivity, and provide data-driven insights. Here’s a closer look at five key factors to think about when integrating AI: 1. COST CONSIDERATIONS Immediate Efficiency Gains: AI automation of repetitive tasks like contract reviews can yield direct time savings, reducing manual hours spent. Optimize Spend: The cost savings allow for investments in training, advanced AI tools, and other high-value initiatives rather than repetitive manual work. 2. WORKFLOW EVOLUTION Reskilling: With AI excelling in routine tasks, in-house team members can take on more complex responsibilities, upskilling into higher-value work. Ongoing Learning: As AI evolves, so must in-house professionals’ skills. Regular AI training ensures everyone stays updated on the latest developments. 3. DATA-DRIVEN INSIGHTS Instant Analysis: AI for legal documents can provide real-time insights from data that previously required extensive manual analysis. This empowers faster, informed decisions. Proactive Risk Monitoring: AI analysis of contracts and documents can proactively detect risks, allowing preventative mitigation. 4. CHANGE MANAGEMENT Addressing Hesitancy: Hosting regular workshops provides a venue for hesitant team members to gain familiarity with AI systems in a collaborative setting. This can ease adoption. User Feedback: Encourage continuous user feedback on AI tools. On-the-ground insights allow refinements tailored to team needs. 5. INTEGRATION WITH OTHER TECHNOLOGIES Legal Tech AI Synergy with Blockchain: AI can help validate blockchain data beyond smart contracts, offering a more robust solution for secure transactions or records. Collaborative Platforms: AI can seamlessly integrate with collaborative tools and platforms used by legal firms, ensuring a cohesive workflow. Whether it’s document collaboration or scheduling client meetings, AI can bring efficiency to these tasks. Adaptive Systems: The beauty of modern AI is its adaptability. By connecting it with tools like CRMs or document management systems, it can learn and adapt based on historical data and user interactions. Integrating AI is an ongoing journey requiring strategic planning, skills development, and a willingness to evolve. The payoff makes this effort invaluable for in-house productivity and insights. With thoughtful change management, AI transitions from an external tool to an intrinsic capability. Involvement and feedback from professionals is the key to ensuring the tech aligns with team needs. With meticulous implementation, AI becomes a seamless ally rather than a disruptive presence, propelling teams to new heights. Send Print Report Latest Posts 5 Key Factors to Consider When Integrating AI into Your Legal Department [Webinar] Mastering AI For Legal Professionals: A Practical Course in Generative Technologies - October 5th, 2:00 pm - 3:30 pm CT The ROI of Legal Operations: Measuring Success and Demonstrating Value with Legal KPIs How Corporate Legal Teams Benefit From RFP Key Performance Indicators (KPIs) That All Legal Departments Should Consider See more » Written by: Onit Contact + Follow more less Published In: Algorithms + Follow Artificial Intelligence + Follow Automation Systems + Follow Blockchain + Follow Business Development + Follow Business Strategies + Follow Client Services + Follow In-House Perspective + Follow Innovative Technology + Follow Legal Operations + Follow Legal Project Management + Follow Machine Learning + Follow Professional Practice + Follow Science, Computers & Technology + Follow more less Onit on: \"My best business intelligence, in one easy email…\" Your first step to building a free, personalized, morning email brief covering pertinent authors and topics on JD Supra: Sign Up Log in *By using the service, you signify your acceptance of JD Supra's Privacy Policy. - hide - hide Back to Top Home What Is JD Supra? Subscribe Leverage Your Thought Leadership Privacy Policy Terms & Conditions Contact Team Cookie Preferences Explore 2023 Readers' Choice Awards Copyright © 2023 JD Supra, LLC",
    "originSummary": [
      "The article highlights important factors to consider when incorporating AI into a legal department, including cost considerations, workflow evolution, data-driven insights, change management, and integration with other technologies.",
      "The adoption of AI software in legal departments can bring benefits such as efficiency gains, reskilling opportunities, real-time insights, and improved collaboration.",
      "The author emphasizes the importance of careful implementation and involving professionals to ensure successful integration of AI."
    ],
    "commentBody": "",
    "commentSummary": [],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1699709226785
  },
  {
    "title": "Addressing Challenges and Regulations for AI Adoption in Government Agencies",
    "originLink": "https://www.thomsonreuters.com/en-us/posts/government/ai-training-government-agencies/",
    "originBody": "Agency Operations AI training for state and local government agencies Allyson Brunette Workplace Consultant 10 Nov 2023 · 5 minute read Share Facebook Twitter Linkedin Email Allyson Brunette Workplace Consultant 10 Nov 2023 · 5 minute read Share Facebook Twitter Linkedin Email Government agencies need to train their employees on the latest innovative technology, especially Generative AI, so that agencies can continue delivering needed services to citizens The fast-paced development of generative artificial intelligence (Gen AI) technology and its increasing presence in everyday work routines poses a challenge for government agencies. Without a proactive approach to embrace this technology, there’s a potential for employees to adopt and utilize it without any guidance from agency leaders. A report from Harvard University’s Law Center points out that Gen AI has the capacity to democratize expertise widely, transitioning us away from a world where law and government services are only understood by subject matter experts. The key question then becomes how government agencies can effectively utilize AI to benefit the public while simultaneously protecting the public’s best interests. Understanding which tools are in use At the state, county, and municipal levels, an imperative first step involves identifying the Gen AI tools and systems currently in use. For example, Connecticut state legislation enacted in the summer of 2023 mandates that all generative AI and automated decision-making tools be inventoried by the end of this year. Further, state agency AI policies and an AI Bill of Rights will follow in the state in 2024. Further, municipalities including San Jose, Calif. and Seattle have implemented regulations to ensure responsible use of algorithmic tools. In San Jose, an algorithmic tool must receive approval from the city’s digital privacy office; while in Seattle, it needs to be approved by the purchasing division. San Jose goes a step further by maintaining a public-facing algorithm register, which provides clear explanations of approved AI tools and their use cases in simple language. Establishing shared values and stressing accountability around AI use Government agencies face a delicate balance between regulating innovation and fostering progress in the delivery of government services. The State of Maine, for example, drew a hard line with its decision to establish a six-month pause on all Gen AI use by state agencies earlier this year. A possibly less punitive approach to Gen AI adoption involves establishing a set of common core values to guide the use of this innovative technology. Pennsylvania Gov. Josh Shapiro issued an executive order this fall, emphasizing 10 fundamental values that should govern the application of this evolving technology in state operations. Broadly, these values seek to ensure that Gen AI use empowers employees, furthers agency mission and equity, but also protects privacy and security. Municipalities and counties which are implementing AI use policies and guidelines are placing a strong emphasis on holding employees accountable for the accuracy of the content they produce, whether with or without the assistance of Gen AI. As Chief Information Officer Santiago Garces noted in reference to the City of Boston’s interim guidelines for use of Gen AI, “technology enables our work, it does not excuse our judgment nor our accountability.” In addition, employees using Gen AI technology in cities like Boston, Seattle, Tempe, Ariz., and San Jose are required by their respective policies to fact-check the accuracy of generated content and disclose the use of AI in content creation. Santa Cruz County, Calif. has a policy reminding staff to treat AI prompts as though they were visible to the public online and subject to public record requests. And the City of Boston’s policy stresses the significance of protecting resident and customer privacy by never sharing sensitive or personally identifiable information in prompts. Expanding access to justice and providing mechanisms for safe innovation A topic that has sparked debate in recent years is the use of Gen AI tools for legal interpretation. In a 2022 publication from the Yale University Journal of Law and Technology, the potential benefits and risks of these tools are outlined. The publication highlights the shortage of civil legal aid attorneys and the limitations of pro bono work, and it envisions how non-lawyers can greatly reduce the cost and increase accessibility of legal services. Risks to moving too quickly in this direction include the danger of inherent bias from existing digital records on which AI tools rely, as well as the fact that the ability of Gen AI to recognize patterns does not necessarily apply to the nuanced judgment needed to inform legal advice. Another publication, Vanderbilt University’s Journal of Entertainment and Technology Law issued earlier this year, suggests that fields of law with more stability, like trust law, may be better initial candidates for early AI application. One major finding in this report is that Gen AI use can shift the legal industry away from hourly billing towards flat-fee service provision as document automation is streamlined. This is in alignment with the Thomson Reuters Future of Professionals report findings, which indicates that less credentialed employees can now complete work with AI assistance that previously required credentialed employees at higher hourly rates. The State of Utah made history this year by becoming the first to launch a legal services innovation sandbox, called the Office of Legal Services Innovation, which oversees non-traditional legal businesses and legal service providers with the aim of ensuring that consumers have access to innovative, affordable, and competitive legal services. The agency actively supports emerging tools and platforms that offer unique and creative approaches of providing legal services, particularly to historically underserved communities. To prevent harm, entities within the sandbox are audited monthly to measure utilization and any potential harm. Of course, a major barrier to collaboration between legal service experts and technologists in advancing AI for legal services is the American Bar Association’s restrictions on non-attorneys owning or investing in law firms. While this restriction is intended to safeguard the independent judgment of attorneys, it adversely hampers innovation and collaboration between the legal and technology sectors. Innovation and experimentation should, of course, be deployed first in areas where the risk of harm is less. For example, Santa Cruz County’s AI usage policy explicitly advises employees against using AI tools in critical decisions related to hiring or other sensitive matters where bias could play a negative role. Facebook Twitter Linkedin Email Agency Operations AI & Future Technologies Career advancement & training Cloud Technology Future of Professionals Generative AI Government Government Agencies Talent Development",
    "originSummary": [
      "Government agencies are facing challenges in adopting and utilizing generative artificial intelligence (Gen AI) technology.",
      "Agencies need to identify Gen AI tools in use and establish regulations for responsible usage to protect the public's best interests.",
      "Expanding access to justice through Gen AI tools for legal interpretation is a topic of debate, with potential benefits and risks outlined."
    ],
    "commentBody": "",
    "commentSummary": [],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1699709226785
  },
  {
    "title": "W&M Professor Margaret Hu advocates for legal governance over AI in U.S. Senate testimony",
    "originLink": "https://news.wm.edu/2023/11/10/wm-professor-margaret-hu-serves-as-expert-witness-on-ai-before-u-s-senate-committee/",
    "originBody": "Margaret Hu, the Taylor Reveley Research Professor, professor of law and director of the Digital Democracy Lab at William & Mary Law School, testified before the U.S. Senate Committee on Homeland Security and Governmental Affairs on Nov. 8. The hearing addressed “The Philosophy of AI: Learning from History, Shaping Our Future.” Posing the question, “What does the future of AI governance look like?” the hearing explored the philosophical, ethical and historical aspects of the future of regulating AI, specifically focusing on the possibilities and challenges of legal solutions and AI technologies. “The reason we must consider the philosophy of AI is because we are at a critical juncture in history,” said Hu. “We are faced with a decision: either the law governs AI or AI governs the law.” In addition to her work at W&M Law School, Hu is also a faculty research affiliate with Data Science and W&M’s Global Research Institute. Data and democracy are two of the four core initiatives of the university’s Vision 2026 strategic plan. Hu (center) was joined by Shannon Vallor (right), professor of ethics and philosophy at the University of Edinburgh, and Daron Acemoglu (left), professor of economics at MIT. (W&M Law School photo) In opening remarks, Committee Chairman Gary Peters (D-MI) explained that regulatory oversight of AI and emerging technologies is necessary because technological disruptions reflect “moments in history” that have “affected our politics, influenced our culture and changed the fabric of our society.” Joining Hu in offering expert testimony were Shannon Vallor, professor of ethics and philosophy at the University of Edinburgh, and Daron Acemoglu, professor of economics at MIT. Acemoglu discussed the need to shape a future of AI where the technologies worked to support the worker, the citizen and democratic governments. He explained that the asymmetric privatization of AI research and development skewed the technology in the direction of serving corporate profit rather than benefiting the user of the technology. Vallor pointed out that “AI is a mirror,” reflecting back historical biases and discrimination that have persisted over generations. As a result, she stated that the technology also reflected a point of view and should not be viewed as objective or neutral. In her testimony, Hu shared that regulating AI systems effectively means that policymakers and lawmakers should not view AI oversight in purely literal terms. She explained that AI systems are not simply literal technical components of technologies. Instead, because AI is infused with philosophies such as epistemology and ontology, it should be seen as reflecting philosophical aims and ambitions. Generative AI and machine learning, algorithmic and other AI systems “digest collective narratives” and can reflect “existing hierarchies,” Hu explained. AI systems can adopt results “based on preexisting historical, philosophical, political and socioeconomic structures.” Acknowledging this at the outset allows for visualization of what is at stake and how AI may perpetuate inequities and antidemocratic values. Hu testifies before the U.S. Senate Committee on Homeland Security and Governmental Affairs. (W&M Law School photo) In the past few years, billions of dollars have been invested in private AI companies, fueling the urgency for a dialogue on rights-based AI governance. Hu’s opening statement encouraged the senators to consider placing the philosophy of AI side-by-side with the philosophy of the Constitution to ask if they are consistent with one another. Hu relied upon her expertise as a constitutional law scholar and teacher to describe the need to investigate how we understand the philosophical underpinnings of Constitutional Law as a method to enshrine rights and constrain power. AI must be viewed in much the same way, Hu explained. Both the Constitution and AI are highly philosophical; putting them side-by-side allows for an understanding of how they might be in tension with each other on a philosophical level. The humanities and philosophies that have underscored our “analogue democracy” must serve as our guide in a “digital democracy,” Hu said. Viewing AI too literally as only a technology runs the risk of not fully grasping its impact as a potential challenge facing society. Hu’s testimony invited the question of whether AI will be applied in a way that is consistent with constitutional philosophy, or will it alter it, erode it or mediate it. AI is not only a knowledge structure, but a power and market structure, Hu pointed out during her testimony. With AI already being deployed for governance purposes, Hu noted that we are at a crossroads where we must grapple with whether and to what extent constitutional rights and core governance functions were meant to be mediated through commercial enterprises and AI technologies in this way. As the capacities of AI evolve, several risks will grow exponentially and more rapidly than can be anticipated. Hu said that when a philosophy like a constitutional democracy can speak to a philosophy of AI, it is easier to comprehend how AI as a governing philosophy might attempt to rival or compete with the governing philosophy of a democracy. History demonstrates that the law can be bent and contorted, especially when structures of power evolve into an ideology. At the end of her testimony, Hu made the case that the foundational principles of a constitutional democracy provide a touchstone for analysis. “I return to my opening question of whether the law will govern AI or AI will govern the law,” Hu said. “To preserve and reinforce a constitutional democracy, there is only one answer to this question. The law must govern AI.” To watch the hearing, please visit the Homeland Security and Governmental Affairs page. Editor’s note: Democracy is one of four cornerstone initiatives in W&M’s Vision 2026 strategic plan. Visit the Vision 2026 website to learn more. David Morrill, W&M Law School Tags: data, democracy, Law School, research Subscribe to W&M Weekly share by email share on Facebook share on X share on LinkedIn share by email share on Facebook share on X share on LinkedIn",
    "originSummary": [
      "Professor Margaret Hu testified before the U.S. Senate Committee on Homeland Security and Governmental Affairs on the future of AI governance.",
      "Hu argued that the law should govern AI, rather than AI governing the law, due to its potential to perpetuate inequities and antidemocratic values.",
      "She emphasized the need to investigate the philosophical underpinnings of AI and its impact on constitutional rights and core governance functions, concluding that the law must govern AI to preserve a constitutional democracy."
    ],
    "commentBody": "",
    "commentSummary": [],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1699709226785
  },
  {
    "title": "Combatting AI Disinformation: Ian Bremmer & Maria Ressa Emphasize the Need for Legal Regulations",
    "originLink": "https://www.gzeromedia.com/global-stage/digital-governance/stop-ai-disinformation-with-laws-lawyers-ian-bremmer-maria-ressa",
    "originBody": "Stop AI disinformation with laws & lawyers: Ian Bremmer & Maria Ressa November 10, 2023 GZERO Staff How do you keep guardrails on AI? “In the United States, historically, we don't respond with censorship. We respond with lawyers,” said Ian Bremmer, President and Founder of the Eurasia Group & GZERO Media, speaking in a GZERO Global Stage discussion live from the 2023 Paris Peace Forum. Setting up basic legal structures around artificial intelligence is the first step toward building an infrastructure of accountability that can keep the technology from doing at least as much harm as good. The European Union has an early lead in setting up systems, but Rappler CEO Maria Ressa said, “the EU is winning the race of the turtles” as the entire globe lags far behind the pace of technological advancement. Without legal structures and a healthy free press and civic society in place, democracies will struggle to remain resilient to the threats of AI-generated disinformation. The livestream was part of the Global Stage series, produced by GZERO in partnership with Microsoft. These discussions convene heads of state, business leaders, technology experts from around the world for critical debate about the geopolitical and technology trends shaping our world. How are emerging technologies helping to shape democracy? › Podcast: Artificial intelligence new rules: Ian Bremmer and Mustafa Suleyman explain the AI power paradox › The AI power paradox: Rules for AI's power › AI and data regulation in 2023 play a key role in democracy › Ian Bremmer: How AI may destroy democracy › Paris Peace Forum Director General Justin Vaïsse: Finding common ground - GZERO Media › At the Paris Peace Forum, grassroots activists highlight urgent issues - GZERO Media › global stageparis peace forumartificial intelligenceaimaria ressaian bremmerai lawsai disinformationcensorshipian bremmer ai",
    "originSummary": [
      "Ian Bremmer and Maria Ressa emphasize the significance of establishing legal frameworks and regulations to address the issue of AI-generated disinformation.",
      "They point out that holding individuals and organizations accountable, as well as having a robust free press, is crucial in safeguarding democracies from the dangers of AI.",
      "The European Union is leading the way in this regard, but there is a lack of progress on a global scale. These discussions occurred at the 2023 Paris Peace Forum as part of the Global Stage series coordinated by GZERO and Microsoft."
    ],
    "commentBody": "",
    "commentSummary": [],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1699709226785
  }
]
