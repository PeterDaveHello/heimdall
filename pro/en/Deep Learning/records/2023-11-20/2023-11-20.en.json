[
  {
    "title": "The Role of Gas Analysis in Semiconductor Manufacturing",
    "originLink": "https://www.azom.com/news.aspx?newsID=62182",
    "originBody": "Semiconductors: Importance, Manufacture and How Gas Analysis Factors In Geoff Downing, Mark Mattison In this interview, AZoM talks to Geoff Downing and Mark Mattison from Thermo Fisher Scientific and Entegris, respectively, about semiconductors and their importance, manufacture and how gas analysis factors into these processes.",
    "originSummary": [
      "The interview highlights the significance of semiconductors and their manufacturing process.",
      "Geoff Downing from Thermo Fisher Scientific and Mark Mattison from Entegris share their insights on the role of gas analysis in semiconductor manufacturing.",
      "The discussion provides valuable information on the importance of accurate gas analysis in ensuring quality and efficiency in semiconductor production."
    ],
    "commentBody": "",
    "commentSummary": [],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1700490483544
  },
  {
    "title": "New Study Uses AI to Improve Colorectal Cancer Detection",
    "originLink": "https://www.azorobotics.com/News.aspx?newsID=14480",
    "originBody": "1 Groundbreaking Study Aims to Improve Detection of Colorectal Cancer Using AI Technology",
    "originSummary": [
      "A new study is exploring the use of artificial intelligence (AI) technology to enhance the detection of colorectal cancer.",
      "The aim is to improve early diagnosis and increase survival rates for individuals with colorectal cancer.",
      "AI algorithms will be developed to analyze medical images and identify potential cancerous growths with higher accuracy and efficiency."
    ],
    "commentBody": "",
    "commentSummary": [],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1700490483544
  },
  {
    "title": "The Power of Explainability: How AI Startups Gain a Competitive Edge",
    "originLink": "https://insidebigdata.com/2023/11/20/the-future-of-ai-startups-explainability-is-your-competitive-edge/",
    "originBody": "Your Source for AI, Data Science, Deep Learning & Machine Learning Strategies Subscribe AI Deep Learning Data Science Machine Learning Channels » White Papers Special Reports Resources » Subscribe Search Search: The Future of AI Startups: Explainability Is Your Competitive Edge November 20, 2023 by Contributor Leave a Comment tweet share share share email Generative AI applications extend from physiotherapists using text-to-video tools demonstrating patient recovery exercises to coding Q&As that decrease network language complexity. These pre-trained ML solutions, which previously required highly skilled teams to train, close the gap between tech giants and digital novices—but that’s if they understand the fine print. ML-focused startups are expected to make a significant 21% net contribution to the US GDP by 2030, underscoring their profound impact on economic growth. However, businesses only have to look as far as AI’s role in COVID-19 to know that unexplainable algorithms can lead to automated discriminations, misaligned intentions, and incomplete datasets. Explainability, known as ‘the black box,’ has always been a problem in deep learning models due to their complicated structures that are inherently uninterpretable to human users. And the latest waves of generative AI are much larger and more complex, completing tasks they were not designed to do. Therefore, as almost every budding entrepreneur prioritizing speed and productivity will look to integrate pre-trained ML into their business model, explainability will become a priority to ensure success. Encouraging the engineer’s role to adapt and understand the algorithms in place. With that in mind, let’s explore the future of AI startups. Explainability Will Be a Topic in Every Round Table When generative AI suggests a product or action for the user, providing an explanation amplifies its utility and impact on customers’ choices, enhancing their engagement and decision-making. Explainable AI (XAI) is the system that unravels decision logic, unveils process pros and cons, and offers a glimpse into the system’s future behavior. As AI revolutionizes industries such as marketing—tailoring experiences, suggesting content, and automating interactions—industry professionals must master AI explainability. Balancing prediction precision with clear explanations is key to fostering reliable, business-aligned, and fair AI systems. For this reason, startups will increasingly find themselves simulating potential questions and validating responses on the back end. Local Interpretable Model-agnostic Explanations (LIME) is a method used to explain the predictions of machine learning models by approximating their behavior with simpler, interpretable tools. Startups need to know why ML models provide the answers they do to have confidence in them. They need explainability coverage. While information is available in big research groups like Meta, startups using smaller open-source models will increasingly focus on assessing the level of support. The Role of the Applied AI Engineer Will Become Mainstream If you create a drug and don’t do enough tests, the consequences are fatal. The same applies to software; startups building ML into their applications must regularly audit everything from penetration testing to vulnerability assessments. If they don’t do their homework, their product won’t reach the market. And without understanding the correct software and regional regulations, for example, they could be looking at a security breach or hefty fines. Startups will need to have a team with skills to apply these models. Applied AI engineers may not know how to build ML models from scratch, but they must know how to validate and test them for bias—front engineering teams will get bigger. They will need to know what the models are for, their functionality, and how to create a good user experience. This will increasingly involve plugging models together, such as one that communicates with the customer automatically and another that solves bias to test the functionality. On the usage side, the applied AI engineer will restrict language models. Say a US finance company is calculating consumers’ credit scores; they may choose to confine demographics such as the neighborhood because that can trigger race discrimination. Prompt engineering will help teams test and validate these, but the applied AI engineer will need deep industry knowledge to ask the right questions. The future: AGI and beyond Imagine one AI that can do anything, like a superhuman, reading and speaking—everything a human can do, but better. The mission of artificial general intelligence (AGI) is to form a world where businesses and consumers have access to help with almost any cognitive task, amplifying human ingenuity and creativity. This is what OpenAI is trying to create. With a tight feedback loop of rapid learning and careful iteration, companies will be able to experience and assess the true potential of AI. We are at the point where one model doesn’t know how to do everything, but does one thing really well, and we are connecting these models. A chatbot that reads and translates, coupled with another that reads and speaks, allows businesses to decipher text with one model and use the other to share audio in the desired language. Policymakers and institutions must pay close attention to understand what’s happening, the benefits and downsides of these systems on the economy, and put regulations in place. The more explainable the AI, the easier it will be to gain regulatory support. Many ML models exist, and to avoid exceedingly costly and time-consuming endeavors, startups will find ways to apply existing models and increase their in-house ability to validate and adapt them for their unique business. Future applications and startups will be prod­ucts of col­lab­o­ra­tion between AI specialists and industry experts. About the Author Lucas Bonatto is Director of Engineering for AI and ML at Semantix AI. With a deep passion for machine learning, he has contributed his expertise to renowned tech companies, developing the first generation of large-scale machine learning platforms. Additionally, Lucas is behind Marvin AI, one of the first open-source ML Ops platform and Elemeno, a comprehensive solution for Artificial Intelligence development with fully-managed and highly scalable infrastructure.Semantix AI is a prominent leader in Artificial Intelligence and Analytics solutions. They offer innovative and disruptive services, including one-stop-shop Generative AI platform for quickly implementing AI-native apps within businesses. Their expertise extends to multi-cloud infrastructure, advanced business performance, and industry data governance solutions. Sign up for the free insideBIGDATA newsletter. Join us on Twitter: https://twitter.com/InsideBigData1 Join us on LinkedIn: https://www.linkedin.com/company/insidebigdata/ Join us on Facebook: https://www.facebook.com/insideBIGDATANOW tweet share share share email Filed Under: AI Deep Learning, Data Science, Google News Feed, Machine Learning, Main Feature, News / Analysis, Opinion, Uncategorized Tagged With: AI, artificial intelligence Sponsored Guest Articles Kickstart Your Business to the Next Level with AI Inferencing The need to accelerate AI initiatives is real and widespread across all industries. The ability to integrate and deploy AI inferencing with pre-trained models can reduce development time with scalable secure solutions that would revolutionize how easily you can capture, store, analyze, and use data to be more competitive. White Papers From complexity to clarity: Harnessing the power of AI/ML and risk-informed strategies to streamline clinical data management In today’s fast-paced world, driven by demands for speed and efficiency, the field of clinical development has undergone a remarkable transformation. The way trials are being conducted has changed significantly with decentralized clinical trials (DCT) becoming mainstream and the collection of clinical data from wearables and other remote-monitoring devices becoming common practice. While these advances […] Download More White Papers Join Us On Social Media Speak Your Mind Name * Email * Website Notify me of follow-up comments by email. Notify me of new posts by email. Related Posts Featured From Featured RSS Feed At SC23: Lenovo’s Advancements in Liquid Cooling, Storage, Digital Twins and HPC-AI Software [SPONSORED GUEST INTERIVEW] We spoke at the Lenovo booth with Andreas Thomasch, Director of HPC and AI, European Markets, in this sponsored interview about recent developments across critical HPC-AI challenge areas: Water Cooling: Lenovo was an.... The post At SC23: Lenovo’s Advancements in Liquid Cooling, Storage, Digital Twins and HPC-AI Software appeared first on High-Performance […] More News from insideHPC At SC23: Lenovo’s Advancements in Liquid Cooling, Storage, Digital Twins and HPC-AI Software Advanced Clustering Launches Log File Analyzer LogVisor AI New Commodity Supercomputing Clusters Deployed at NNSA Labs Claim TOP500 Spots LLNL-led SCREAM Team Clinches Inaugural Gordon Bell Prize for Climate Modeling At SC23: AMD’s Brent Gorda Talks TOP500-GREEN500 and the ‘Imminent’ MI300 GPU DE-CIX and CR8DL Announce Enhanced Data Capabilities Partnership for HPC Accelerating AI Inference for High-throughput Experiments About insideBIGDATA Contact Advertise with insideBIGDATA Visit Our Other Site – insideHPC Terms of Service & Copyright Privacy Policy Copyright © 2023",
    "originSummary": [
      "Explainability in AI models is crucial for startups as it can improve customer engagement and decision-making.",
      "Applied AI engineers play a vital role in testing and validating models to ensure they are free from bias and comply with regulations.",
      "Policymakers need to regulate AI systems, especially as the potential of artificial general intelligence (AGI) becomes more apparent."
    ],
    "commentBody": "",
    "commentSummary": [],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1700490483544
  },
  {
    "title": "Earth AI: Accelerating Mineral Discovery for Net Zero Goals",
    "originLink": "https://diginomica.com/how-earth-ai-accelerating-mineral-discovery-and-helping-enterprise-net-zero-goals",
    "originBody": "How Earth AI is accelerating mineral discovery and helping enterprise Net Zero goals Read later By George Lawton November 20, 2023 Audio mode toggler Dyslexia mode Summary: Earth AI pioneers a more efficient experimental process for discovering minerals required for Net Zero goals. Their promising results highlight the importance of combining data science, domain expertise, and systematic thinking to solve new problems relevant to all enterprises. Share this article via Facebook Share this article via Linkedin Share this article via Reddit Share this article via Twitter Share this article via Buffer Share this article via Flipboard One uncomfortable reality about the shift to a Net Zero economy is that it will also require the discovery and mining of a lot of raw materials for the new infrastructure. Engines will be replaced by electric motors, generators with solar and wind, pipes with wires and transformers, and gas tanks with batteries. Building these will require discovering millions of tons of new minerals, many of which are inconveniently located owing to geopolitical issues or nearby communities. Earth AI has announced some preliminary success in finding this buried treasure in new, previously unexplored areas. The mining industry calls these greenfields, in contrast to brownfield exploration adjacent to existing mines. The company recently discovered a rich deposit of molybdenum in Australia with twice the concentration of the largest existing mines. Perhaps more impressively, its new approach achieved a success ratio of one in eight for greenfield discovery compared to the industry average of one in 200. Their results are even slightly better than traditional exploration techniques in brownfield exploration, with an average of one in 20. This is a big deal since each one of those surveying holes costs a lot to dig. Earth AI has also pioneered a more systematic approach to digging these holes using modular components that help keep the costs down for each hole. Cheaper and faster holes also speed the loop on the experimental process to build a better AI model. Earth AI CEO and founder Roman Teslyuk says: Large mining companies have utilized AI to improve mining profits and prolong the life of mining operations. Start-ups like Plotlogic, MineSense, GoldSpot and Stratum AI have been at the forefront of this innovation. These start-ups have been successful at near-mine brownfield exploration and have a swath of large mining clients to whom they sell their services. What’s different about Earth AI is that we never tried to compete in a crowded data-rich mine data re-analysis. Instead, we have focused on finding new greenfield mineral deposits away from existing mines. It is much more challenging, but the reward is much, much larger. Training an AI geologist Looking for greenfield mining opportunities is a much more challenging problem. Brownfields are a well-studied and data-rich environment, while greenfields are data-poor. The standard and preferred solution is to collect new data, which is very costly and time-consuming. The Earth AI team hypothesized they could replace the need for more data with a better approach for interpreting and labeling existing data. They trained their system on 400 million geological cases known from exploration archives. But this was no simple task. Teslyuk explains: It is hard to focus the deep learning model on the right geological aspects at such a scale. We taught our AI to learn geology. Our AI acts like a geoscientist, studying each case, distilling the knowledge, and developing predictions. But this happens on a much bigger scale, generating consistent and dependable predictions. The actual process consists of three phases: Targeting: The models are trained on the 400 million geological cases across Australia to identify areas of mineralization and highlight locations with a high probability of finding a mineral system. Teams go into the field to sample and review the targets. Hypothesis: The geologists study the mineral system on the ground. At this stage, a sister technology helps the geologists better understand the geological setting and aid in forming hypotheses. Drilling: The team tests its hypothesis by drilling down to 600-meter depth and proving or disproving the presence of mineralization. Each drill hole provides invaluable knowledge of the mineral system that is then fed back into the system and used to form new hypotheses. Data quality is key Earth AI recruited a rare mix of geology and deep learning experts. More importantly, it also adopted a research culture. Iterative experimentation helped distill important key components for a geological deep learning system to improve predictions. The company has been conducting research for six years and spent more than six hundred days in the field testing the predictions and gaining feedback for system improvement. Teslyuk observes: The key challenge is researching the ways to focus the model on the right kinds of knowledge that need to be learned. The difficulty is that there is no rule book. Progress is only achieved by generating ideas, running experiments, observing and testing the model performance, and adjusting the system to make things work. We learned that we need to have a constant field presence to obtain real-world feedback. The quality of data from each geological case is essential, but quality monitoring is a huge issue when working on a continental scale using hundreds of millions of data points. So, Earth AI built a half-automated expert-driven data review system that dramatically speeds up data quality review. For example, domain-specific software focuses on finding and remembering data errors and inconsistencies and fixing them at scale. Teslyuk says: AI companies usually do not attempt such tasks, but we see this as a key ingredient of our success. A systematic approach to drilling Another factor was to consider drilling as an essential part of the data collection process rather than outsource it to existing contractors, as is common industry practice. This helped to optimize more steps in the process and streamline field operations. The firm re-designed drilling hardware to make it modular, self-sufficient, and environmentally friendlier. This included integrating a waste-treatment system to reduce ground disturbance and environmental impact. They also streamlined logistics to carry more stock that was better organized for transport and subsequent analysis. The result is relocation between sites can be done within days, compared to industry norms of weeks. Teslyuk surmises: The industry is known for its slow pace. To scale and speed up discoveries, you need to optimize and scale the hardware. Legacy systems are simply incompatible with predictable high-performing operations. We had to spend a lot of effort redesigning the hardware to streamline it with the specifics of the drilling operation. My take As enterprises rush to add AI to their services and products, it's tempting to get caught up in the buzzy new AI models and services rushing to market. A much better approach is to focus on lowering the cost of creating and interpreting experiments, as Earth AI has done. In the long run, this will likely lead to better results as people figure out where these new tools improve accuracy and where they hallucinate. This requires a cultural reframing from trying to create things faster to learning how to learn faster. As Earth AI’s experience has suggested, it took a lot of work to figure out how to automate the process of interpreting and structuring existing data and then confirm or negate each hypothesis more cost-effectively. This kind of shift will be required to succeed in solving the various problems necessary to build out Net Zero infrastructure. Image credit - Pixabay Get your weekly enterprise AI digest Complete the form below to receive the top enterprise AI stories from diginomica, every week. First Name* Last Name* Email* Submit Read more on: Machine intelligence and AI Ethics Sustainability Audio",
    "originSummary": [
      "Earth AI is leveraging data science and domain expertise to speed up mineral discovery for enterprise Net Zero goals.",
      "The company has achieved impressive outcomes in identifying new greenfield mineral deposits, surpassing the industry average success rate.",
      "Their methodology includes training AI models with existing data and employing a systematic and modular drilling approach, while also emphasizing cost reduction for conducting and analyzing experiments, which aligns with the transition towards a Net Zero economy."
    ],
    "commentBody": "",
    "commentSummary": [],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1700490483544
  },
  {
    "title": "Smaller Data Subsets Can Generate Comparable Results in Deep Learning Models: University of Toronto Study",
    "originLink": "https://www.marktechpost.com/2023/11/19/researchers-from-the-university-of-toronto-unveil-a-surprising-redundancy-in-large-materials-datasets-and-the-power-of-informative-data-for-enhanced-machine-learning-performance/",
    "originBody": "Researchers from the University of Toronto Unveil a Surprising Redundancy in Large Materials Datasets and the Power of Informative Data for Enhanced Machine Learning Performance By Rachit Ranjan - November 19, 2023 Reddit Vote Flip Share Tweet 0 Shares With the advent of AI, its use is being felt in all spheres of our lives. AI is finding its application in all walks of life. But AI needs data for the training. AI’s effectiveness relies heavily on data availability for training purposes. Conventionally, achieving accuracy in training AI models has been linked to the availability of substantial amounts of data. Addressing this challenge in this field involves navigating an extensive potential search space. For example, The Open Catalyst Project, uses more than 200 million data points related to potential catalyst materials. The computation resources required for analysis and model development on such datasets are a big problem. Open Catalyst datasets used 16,000 GPU days for analyzing and developing models. Such training budgets are only available to some researchers, often limiting model development to smaller datasets or a portion of the available data. Consequently, model development is frequently restricted to smaller datasets or a fraction of the available data. 🔥 Free AI Webinar: Using OpenAI for Automated HR / Recruiter Resume Scans & AssessmentsI [Nov 21, 10 am PST] A study by University of Toronto Engineering researchers, published in Nature Communications, suggests that the belief that deep learning models require a lot of training data may not be always true. The researchers said that we need to find a way to identify smaller datasets that can be used to train models on. Dr. Kangming Li, a postdoctoral scholar at Hattrick-Simpers, used an example of a model that forecasts students’ final scores and emphasized that it performs best on the dataset of Canadian students on which it is trained, but it might not be able to predict grades for students from of other countries. ↗ Recommended Read: LLMWare Launches RAG-Specialized 7B Parameter LLMs: Production-Grade Fine-Tuned Models for Enterprise Workflows Involving Complex Business Documents One possible solution is finding subsets of data inside incredibly huge datasets to address the issues raised. These subsets should contain all the diversity and information in the original dataset but be easier to handle during processing. Li developed methods for locating high-quality subsets of information from materials datasets that have already been made public, such as JARVIS, The Materials Project, and Open Quantum Materials. The goal was to gain more insight into how dataset properties affect the models they train. To create his computer program, he used the original dataset and a much smaller subset with 95% fewer data points. The model trained on 5% of the data performed comparably to the model trained on the entire dataset when predicting the properties of materials within the dataset’s domain. According to this, machine learning training can safely exclude up to 95% of the data with little to no effect on the accuracy of in-distribution predictions. The overrepresented material is the main subject of the redundant data. According to Li, the study’s conclusions provide a way to gauge how redundant a dataset is. If adding more data doesn’t improve model performance, it is redundant and doesn’t provide the models with any new information to learn. The study supports a growing body of knowledge among experts in AI across multiple domains: models trained on relatively small datasets can perform well, provided the data quality is high. In conclusion, the significance of information richness is stressed more than the volume of data alone. The quality of the information should be prioritized over gathering enormous volumes of data. Check out the Paper. All credit for this research goes to the researchers of this project. Also, don’t forget to join our 33k+ ML SubReddit, 41k+ Facebook Community, Discord Channel, and Email Newsletter, where we share the latest AI research news, cool AI projects, and more. If you like our work, you will love our newsletter.. Rachit Ranjan + posts Rachit Ranjan is a consulting intern at MarktechPost . He is currently pursuing his B.Tech from Indian Institute of Technology(IIT) Patna . He is actively shaping his career in the field of Artificial Intelligence and Data Science and is passionate and dedicated for exploring these fields. Reddit Vote Flip Share Tweet 0 Shares 🔥 Join The AI Startup Newsletter To Learn About Latest AI Startups Previous articleMicrosoft Unveils Azure Custom Chips: Revolutionizing Cloud Computing and AI Capabilities Next articleA New AI Research Releases SWIM-IR: A Large-Scale Synthetic Multilingual Retrieval Dataset with 28 Million Training Pairs over 33 Languages",
    "originSummary": [
      "Deep learning models can achieve similar performance when trained on smaller subsets of data, contrary to the belief that they require large amounts of training data.",
      "Researchers from the University of Toronto developed methods to identify high-quality subsets of data from large materials datasets.",
      "Training models on as little as 5% of the data can produce comparable results to models trained on the entire dataset, emphasizing the significance of data quality rather than data volume in machine learning training."
    ],
    "commentBody": "",
    "commentSummary": [],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1700490483544
  },
  {
    "title": "Canada's AI leadership: reaping rewards and managing risks",
    "originLink": "https://thelogic.co/news/special-report/canada-helped-lay-the-foundations-for-todays-ai-boom-can-it-reap-the-rewards/",
    "originBody": "Illustration by Sébastien Thibault for The Logic Special Report Canada helped lay the foundations for today’s AI boom. Can it reap the rewards? By Murad Hemmadi Nov 20, 20236:45 AM EST The artificial intelligence boom presents Canada with unique opportunities and risks as we seek to benefit from a technology that could reshape how we live. In this special series, Canada’s AI Advantage, The Logic examines how Canadian companies, investors, institutions and workers can gain from the country’s early lead in AI, even as Canada’s pioneers in the field become the world’s most powerful voices of caution. On a trip to California a few years ago, Ruslan Salakhutdinov made time to hang out with some old school chums. A decade earlier, the group had shared a lab at the University of Toronto—and a massive achievement. Enter your email to read this article for free By entering your e-mail you consent to receiving commercial electronic messages from The Logic Inc. containing news, updates, offers or promotions about The Logic Inc.’s products and services. You can withdraw your consent at anytime. Please refer to our privacy policy or contact us for more details. Already a subscriber? Log in here",
    "originSummary": [
      "Canada has emerged as a key player in the AI boom, offering both opportunities and risks for companies, investors, institutions, and workers.",
      "The early lead in AI technology puts Canadian entities in a favorable position to benefit from this growing field.",
      "The article highlights a trip by Ruslan Salakhutdinov, a prominent figure in the AI community, who achieved a significant milestone while collaborating with friends at the University of Toronto."
    ],
    "commentBody": "",
    "commentSummary": [],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1700490483544
  },
  {
    "title": "AI Tool Beats Humans in Crab Gender Identification",
    "originLink": "https://www.miragenews.com/ai-powered-tool-revolutionizes-crab-gender-1127323/",
    "originBody": "Mirage News Mirage News Mirage News Science 20 Nov 2023 10:34 pm AEDT Date Time Share AI-Powered Tool Revolutionizes Crab Gender Identification Tokyo University of Science When winter comes to Japan, fishermen in the northern regions set out to capture one of the most anticipated seasonal delicacies: the horsehair crab. Known locally as \"kegani\" and bearing the scientific name Erimacrus isenbeckii, this species of crustacean is highly sought after throughout the country. To protect the horsehair crab population from overfishing, the Japanese and prefectural governments have implemented various restrictions on their capture. For example, in Hokkaido, where kegani is abundant, capturing females for consumption is strictly prohibited. To comply with these laws, experienced fishermen have learned how to tell apart males from females through visual inspection. While it is relatively straightforward to distinguish them by looking at the underside (abdomen) of the crabs, doing so by looking at their shell side is much more challenging. Unfortunately, when captured crabs settle on board a ship, they almost always do so with their shell side pointing up, and picking them up and flipping them individually to determine their sex is time-consuming. Could this be yet another task artificial intelligence (AI) may excel at? In a recent study, a research team from Japan, including Professor Shin-ichi Satake from Tokyo University of Science (TUS), Japan, sought to answer this question using deep learning. Their latest paper, published in the renowned journal Scientific Reports, is co-authored by Associate Professor Yoshitaka Ueki and Professor Ken Takeuchi from TUS and Assistant Professor Kenji Toyota and Professor Tsuyoshi Ohira from Kanagawa University. The researchers implemented three deep convolutional neural networks based on three well-established image classification algorithms: AlexNet, VGG-16, and ResNet-50. To train and test these models, they used 120 images of horsehair crabs captured in Hokkaido; half of them were males, and the other half were females. A notable advantage of these models is that they are \"explainable AI.\" Simply put, it means given an image of a crab, it is possible to see what specific regions of the image were relevant for the algorithm to make its classification decision. This can reveal subtle differences between the males and females that could be useful for manual classification. The test results were quite promising in terms of accuracy and performance metrics, as Prof. Satake highlights: \"Even though gender classification was virtually impossible by human visual inspection on the shell side, the proposed deep learning models enabled male and female classification with high precision, achieving an F-1 measure of approximately 95% and similarly high accuracy values.\" This means that the AI approach vastly outperformed humans and provided consistent, reliable classification. Interestingly, when observing the heatmaps, which represented the regions the models focused on for classification, the team found significant differences between the sexes. For one, the heatmap was enhanced near the genitalia shape on the abdomen side. When classifying males, the algorithms focused on the lower part of the carapace. In contrast, when classifying females, the algorithms focused on the upper portion of the carapace. This could provide useful information not only for the development of future AI sex classification models for crabs but also shed light on how experienced fishermen can tell apart males from females apart even when looking at their shell side. Considering that being captured can be a great source of stress for crabs, being able to quickly tell females apart without flipping them before release could help prevent health or reproductive problems for these crabs. Thus, deep learning could potentially be an important tool for enhancing conservation and farming efforts. \"The fact that deep learning can discriminate male and female crabs is an important finding not only for the conservation of these important marine resources but also for the development of efficient aquaculture techniques,\" remarks Prof. Satake. Notably, implementing AI classification techniques directly on ships could reduce the amount of manual work and make crab fishing more cost-effective. Moreover, the proposed models could be retrained and repurposed for the gender classification of other species of crabs, such as the blue crab or the Dungeness crab. Overall, this study showcases how AI can be leveraged in creative ways to not only make people's work more efficient but also have a direct positive effect on conservation, responsible fishing, and sustainability of crab aquaculture. *** Reference DOI: https://doi.org/10.1038/s41598-023-46606-x About The Tokyo University of Science Tokyo University of Science (TUS) is a well-known and respected university, and the largest science-specialized private research university in Japan, with four campuses in central Tokyo and its suburbs and in Hokkaido. Established in 1881, the university has continually contributed to Japan's development in science through inculcating the love for science in researchers, technicians, and educators. With a mission of \"Creating science and technology for the harmonious development of nature, human beings, and society,\" TUS has undertaken a wide range of research from basic to applied science. TUS has embraced a multidisciplinary approach to research and undertaken intensive study in some of today's most vital fields. TUS is a meritocracy where the best in science is recognized and nurtured. It is the only private university in Japan that has produced a Nobel Prize winner and the only private university in Asia to produce Nobel Prize winners within the natural sciences field. Website: https://www.tus.ac.jp/en/mediarelations/ About Professor Shin-ichi Satake from Tokyo University of Science Dr. Shin-ichi Satake obtained a PhD degree in Mechano-Informatics Engineering from The University of Tokyo in 1995. He currently serves as a Full Professor of the Department of Applied Electronics at the Faculty of Advanced Engineering of Tokyo University of Science. His research interests focus mainly on simulation engineering and thermal engineering, particularly computational thermal fluid dynamics. He has published over 120 peer-reviewed papers on these topics. About Associate Professor Yoshitaka Ueki from Tokyo University of Science Dr. Yoshitaka Ueki obtained a PhD degree in Engineering from Kyoto University in 2012. He currently serves as an Associate Professor of the Department of Applied Electronics at the Faculty of Advanced Engineering of Tokyo University of Science. His research interests focus on data processing, machine learning, and acoustic engineering. /Public Release. This material from the originating organization/author(s) might be of the point-in-time nature, and edited for clarity, style and length. Mirage.News does not take institutional positions or sides, and all views, positions, and conclusions expressed herein are solely those of the author(s).View in full here. Why? Well, unlike many news organisations, we have no sponsors, no corporate or ideological interests. We don't put up a paywall – we believe in free access to information of public interest. Media ownership in Australia is one of the most concentrated in the world (Learn more). Since the trend of consolidation is and has historically been upward, fewer and fewer individuals or organizations control increasing shares of the mass media in our country. According to independent assessment, about 98% of the media sector is held by three conglomerates. This tendency is not only totally unacceptable, but also to a degree frightening). Learn more here We endeavour to provide the community with real-time access to true unfiltered news firsthand from primary sources. It is a bumpy road with all sorties of difficulties. We can only achieve this goal together. Our website is open to any citizen journalists and organizations who want to contribute, publish high-quality insights or send media releases to improve public access to impartial information. You and we have the right to know, learn, read, hear what and how we deem appropriate. Your support is greatly appreciated. All donations are kept completely private and confidential. Thank you in advance! Tags: Asia , Japan , Toyota , AI , Japanese , Tokyo , artificial intelligence , conservation , sustainability , Kyoto University , Kyoto , University of Tokyo , machine learning , Scientific Reports , deep learning , neural networks",
    "originSummary": [
      "Researchers from Tokyo University of Science have created an AI tool to identify the gender of horsehair crabs.",
      "The tool utilizes deep learning and image classification algorithms to distinguish between male and female crabs by analyzing their shell side.",
      "The AI tool surpasses human accuracy in classifying crabs and could have implications in conservation, aquaculture, and responsible fishing practices."
    ],
    "commentBody": "",
    "commentSummary": ["The requested information is missing.", "-"],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1700490483544
  },
  {
    "title": "Exploring the Top Open-Source AI Frameworks for Innovation and Collaboration",
    "originLink": "https://www.analyticsinsight.net/five-open-source-ai-frameworks-you-should-know-about/",
    "originBody": "Facebook 0 Twitter 0 LinkedIn 0 Email 0 Artificial IntelligenceLatest News Five Open-Source AI Frameworks You Should Know About Parvin Mohmad November 20, 2023 2 mins read Here are the top 5 open-source AI frameworks you should be aware of In the dynamic field of artificial intelligence (AI), open-source frameworks have become pivotal in accelerating innovation and fostering collaboration among developers, researchers, and organizations. These frameworks provide a foundation for building and deploying cutting-edge AI applications. In this article, we’ll delve into five open-source AI frameworks that are making waves in the industry and shaping the future of AI development. 1. TensorFlow: Developed by Google, TensorFlow is a widely used open-source AI framework that has become synonymous with deep learning. It offers a comprehensive ecosystem of tools, libraries, and community resources, making it suitable for a range of applications, from image and speech recognition to natural language processing. TensorFlow’s flexibility and scalability have contributed to its popularity among both beginners and seasoned AI practitioners. 2. PyTorch: PyTorch, maintained by Facebook’s AI Research lab (FAIR), has gained significant traction for its dynamic computational graph, which allows for more intuitive model building and debugging. Its user-friendly interface makes it an excellent choice for researchers and developers alike. PyTorch has become a go-to framework for projects involving natural language processing, computer vision, and reinforcement learning. 3. Keras: While Keras is often used as a high-level neural networks API, it is worth mentioning as it now comes integrated with TensorFlow as its official high-level API. Keras abstracts complex neural network architectures into simple, modular building blocks, enabling rapid experimentation and prototyping. Its seamless integration with TensorFlow makes it a powerful tool for both beginners and experts in the AI community. 4. Apache MXNet: Apache MXNet is an open-source deep-learning framework backed by the Apache Software Foundation. Known for its efficiency and scalability, MXNet is particularly adept at handling sparse data and distributed computing. Its versatility makes it suitable for a range of applications, including computer vision, speech recognition, and recommendation systems. MXNet’s dynamic graph computation capabilities contribute to its appeal in research and production environments. 5. Scikit-learn: While not exclusively a deep learning framework, Scikit-learn is a powerful open-source machine learning library for classical machine learning algorithms. It provides simple and efficient tools for data analysis and modeling, making it a valuable asset for researchers and practitioners. Scikit-learn is widely used for tasks such as classification, regression, clustering, and dimensionality reduction. Disclaimer: Any financial and crypto market information given on Analytics Insight are sponsored articles, written for informational purpose only and is not an investment advice. The readers are further advised that Crypto products and NFTs are unregulated and can be highly risky. There may be no regulatory recourse for any loss from such transactions. Conduct your own research by contacting financial experts before making any investment decisions. The decision to read hereinafter is purely a matter of choice and shall be construed as an express undertaking/guarantee in favour of Analytics Insight of being absolved from any/ all potential legal action, or enforceable claims. We do not represent nor own any cryptocurrency, any complaints, abuse or concerns with regards to the information provided shall be immediately informed here. Facebook 0 Twitter 0 LinkedIn 0 Email 0 AI AI frameworks Keras Pytorch TensorFlow 5 Views 0 Like",
    "originSummary": [
      "TensorFlow, PyTorch, Keras, Apache MXNet, and Scikit-learn are open-source AI frameworks that are driving innovation and collaboration in the field of artificial intelligence.",
      "Each framework has its own unique features and capabilities, making them suitable for different applications in AI development.",
      "These frameworks enable developers to leverage pre-built AI models, design and train their own models, and deploy AI solutions across various industries."
    ],
    "commentBody": "",
    "commentSummary": [],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1700490483544
  },
  {
    "title": "Enhancing Language Models with Retrieval Augmented Generation to Tackle Misinformation",
    "originLink": "https://www.infoworld.com/article/3711100/reining-in-the-bs-in-ai.html",
    "originBody": "Home Artificial Intelligence Generative AI Reining in the BS in AI Large language models trained on questionable stuff online will produce more of the same. Retrieval augmented generation is one way to get closer to truth. By Matt Asay Contributor, InfoWorldNov 19, 2023 6:00 pm PST alberto clemares exposito / Shutterstock Even people not in tech seemed to have heard of Sam Altman’s ouster from OpenAI on Friday. I was with two friends the next day (one works in construction and the other in marketing) and both were talking about it. Generative AI (genAI) seems to have finally gone mainstream. What it hasn’t done, however, is escape the gravitational pull of BS, as Alan Blackwell has stressed. No, I don’t mean that AI is vacuous, long on hype, and short on substance. AI is already delivering for many enterprises across a host of industries. Even genAI, a small subset of the overall AI market, is a game-changer for software development and beyond. And yet Blackwell is correct: “AI literally produces bullshit.” It makes up stuff that sounds good based on training data. Even so, if we can “box it in,” as MIT professor of AI Rodney Brooks describes, genAI has potential to make a big difference in our lives. [ Read next: What can ChatGPT and LLMs really do for your business? ] ‘ChatGPT is a bullshit generator’ Truth is not fundamental to how large language models function. LLMs are “deep learning algorithms that can recognize, summarize, translate, predict, and generate content using very large data sets.” Note that “truth” and “knowledge” have no place in that definition. LLMs aren’t designed to tell you the truth. As detailed in an OpenAI forum, “Large language models are probabilistic in nature and operate by generating likely outputs based on patterns they have observed in the training data. In the case of mathematical and physical problems, there may be only one correct answer, and the likelihood of generating that answer may be very low.” That’s a nice way of saying you might not want to rely on ChatGPT to do basic multiplication problems for you, but it could be great at crafting an answer on the history of algebra. In fact, channeling Geoff Hinton, Blackwell says, “One of the greatest risks is not that chatbots will become super intelligent, but that they will generate text that is super persuasive without being intelligent.” It’s like “fake news” on steroids. As Blackwell says, “We’ve automated bullshit.” This isn’t surprising, given the primary sources for the LLMs underlying ChatGPT and other GenAI systems are Twitter, Facebook, Reddit, and “other huge archives of bullshit.” However, “there is no algorithm in ChatGPT to check which parts are true,” such that the “output is literally bullshit,” says Blackwell. What to do? ‘You have to box things in carefully’ The key to getting some semblance of useful knowledge out of LLMs, according to Brooks, is “boxing in.” He says, “You have to box [LLMs] in carefully so that the craziness doesn’t come out, and the making stuff up doesn’t come out.” But how does one “box an LLM in?” One critical way is through retrieval augmented generation (RAG). I love how Zachary Proser characterizes it: “RAG is like holding up a cue card containing the critical points for your LLM to see.” It’s a way to augment an LLM with proprietary data, giving the LLM more context and knowledge to improve its responses. RAG depends on vectors, which are a foundational element used in a variety of AI use cases. A vector embedding is just a long list of numbers that describe features of the data object, like a song, an image, a video, or a poem, stored in a vector database. They’re used to capture the semantic meaning of objects in relation to other objects. Similar objects are grouped together in the vector space. The closer two objects, the more similar they are. (For example, “rugby” and “football” will be closer to each other than “football” and “basketball”). You can then query for related entities that are similar based on their characteristics, without relying on synonyms or keyword matching. As Proser concludes, “Since the LLM now has access to the most pertinent and grounding facts from your vector database, it can provide an accurate answer for your user. RAG reduces the likelihood of hallucination.” Suddenly, your LLM is much more likely to give you a true response, not merely a response that sounds true. This is the sort of “boxing in” that can make LLMs actually useful and not hype. Otherwise, it’s just automated bullshit. Next read this: The best open source software of 2023 Do programming certifications still matter? Cloud computing is no longer a slam dunk What is generative AI? Artificial intelligence that creates Coding with AI: Tips and best practices from developers Why Wasm is the future of cloud computing Related: Generative AI Emerging Technology Technology Industry Matt Asay runs developer relations at MongoDB. The views expressed herein are Matt’s and do not reflect those of his employer. Follow Copyright © 2023 IDG Communications, Inc.",
    "originSummary": [
      "Large language models (LLMs) in generative AI can produce misleading or false information due to their probabilistic nature and lack of truth verification mechanisms.",
      "Using retrieval augmented generation (RAG) techniques, LLMs can be enhanced with proprietary data to provide more accurate and reliable responses.",
      "RAG relies on vector embeddings to capture semantic meaning and improve the LLM's understanding, making them genuinely useful tools instead of just generators of automated content."
    ],
    "commentBody": "",
    "commentSummary": [],
    "downloadMethod": "",
    "retryCount": 0,
    "time": 1700490483544
  }
]
