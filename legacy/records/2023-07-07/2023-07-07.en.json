[
  {
    "id": 36609641,
    "timestamp": 1688606241,
    "title": "Tell HN: Nearly all of Evernote's remaining staff has been laid off",
    "url": "",
    "hn_url": "http://news.ycombinator.com/item?id=36609641",
    "content": "",
    "summary": "- Evernote, a popular note-taking app, has laid off a significant portion of its staff.\n- The company has been facing financial difficulties and has been struggling to compete with other note-taking apps.\n- This news is important because it suggests that Evernote may be in trouble and users of the app may need to consider alternative options.",
    "hn_title": "Tell HN: Nearly all of Evernote\u2019s remaining staff has been laid off",
    "original_title": "Tell HN: Nearly all of Evernote\u2019s remaining staff has been laid off",
    "score": 926,
    "hn_content": "- Evernote has laid off a significant portion of its remaining staff after being taken over by acquirer Bending Spoons.\n- The company has also increased subscription prices and claimed that the new revenue will be used to fund new features, sparking skepticism about how this will be possible with limited staff.\n- Users are advised that if they are still using Evernote, now might be a good time to stop.\n- Evernote's struggle to convert free users to paying users is highlighted, with the early decision to offer a free version making it difficult to transition to a paid model.\n- The lesson here is that companies should focus on offering something valuable or something cheap, rather than providing something not valuable and expensive.\n- The shift to charging for low-value features and locking in notes led many users to switch to free or lower-cost alternatives.\n- Many VC-funded startups have faced similar problems when trying to monetize their products.\n- There is criticism of VC-funded startups becoming bloated with employees and struggling to generate profit.\n- Users express frustration with the proprietary file format used by Evernote and emphasize the importance of data portability.\n- Obsidian is highlighted as an alternative that offers a more portable and user-friendly experience.\n- Users cite the importance of simplicity, reliability, ubiquity, and speed in a note-taking app, factors that Evernote failed to prioritize.\n- OneNote is offered as an example of a note-taking app that has successfully competed with Evernote.\n- VCs are criticized for not always delivering the best possible product and for wasting human energy and resources on proprietary solutions that may not stand the test of time.\n- The challenges of pricing and competition in the notes app market are discussed, with the difficulty of converting free users to paid customers being a significant hurdle.\n- Users express their preference for note-taking apps that prioritize speed, simplicity, and portability.\n- The reliability and flexibility of plaintext-based note-taking apps are praised.\n- Evernote is criticized for its poor user experience, sluggish performance, and lack of responsiveness on certain platforms.\n- Users discuss their frustration with the transition to Electron, which resulted in a slow experience and missing core features.\n- Users highlight the importance of long-term product support and express their preference for companies that don't sacrifice their core product for growth.\n- The risks of proprietary file formats and the advantages of using established players and open-source distributed solutions are discussed.\n- Users express their support for Obsidian and its commitment to providing a long-term data access solution.\n- Users highlight the value of ease of use, simplicity, reliability, and ubiquity in a note-taking app.\n- Google Keep, Apple Notes, and other alternatives are mentioned as being good enough for most users' needs.\n- Users express their concerns about the data portability and long-term support of SaaS applications and their preference for established players or open-source solutions.\n- The trend of walled gardens and the negative consequences for users is discussed, with concerns about acquiring and losing data and the potential for companies to ruin their product for profit.\n- Users share their experiences being laid off and the financial security it has provided.\n- The discussion shifts to the value proposition of delivery apps like GrubHub and DoorDash and whether their services are worth the high prices they charge.\n- The backend software of delivery apps is highlighted for its real-time resource scheduling capabilities, optimizing time and fuel consumption.\n- Users express their preference for established players with a history of long-term product support and their satisfaction with the simplicity and speed of products like Fastmail.\n- Users discuss the value and challenges of VC funding and the incentives it provides for companies to grow rapidly and take risks.\n- The potential for founders and early investors to take money out of a company along the way is mentioned, making it less likely that they walk away financially worse off.\n- The risks and downsides of VC-funded startups for both the users and the developers are discussed.\n- The importance of trusting SaaS startups and the need for open-source distributed solutions are highlighted.\n- Users express their concerns and frustration with service shutdowns, loss of important data, and the waste of human energy and resources on proprietary solutions.\n- There is a discussion about the benefits and drawbacks of VC funding for founders and the misalignment of incentives between founders and VCs.\n- Some users highlight the issues with VC funding models and suggest alternative approaches to building sustainable businesses.\n- The discussion shifts to the importance of reliability, simplicity, and speed in a storage app.\n- The benefits of using a storage app that is compatible with multiple devices and operating systems are discussed.\n- The challenges of using SaaS apps with data portability and the risks of relying on proprietary solutions are highlighted.\n- Users share their experiences using Evernote, the frustrations they encountered, and their reasons for switching to alternative note-taking apps.- The article discusses the possibility of a new law that may require companies to remove certain content or change the way they handle content.\n- Some users argue against the implementation of retrospective laws and believe they should be prohibited.\n- The discussion includes examples like Coca-Cola and the legality of their products when they were first introduced.\n- Users mention concerns about cold-storage backups and how they may be affected by data removal requirements.\n- Some users express skepticism about the feasibility of a legally binding guarantee for maintaining user data for 100 years.\n- The conversation shifts towards alternatives to Evernote, with users suggesting various note-taking and organization tools like Trilium Notes, Joplin, and Obsidian.\n- Users discuss the advantages and disadvantages of different note-taking apps, including features like collaborative editing, formatting options, and syncing capabilities.\n- Some users share their transition to plain text and the benefits they see in using simple, open formats for long-term data storage.\n- The discussion touches on the difficulties of canceling subscriptions and the dark patterns employed by some companies.\n- Users mention virtual credit cards as a way to manage subscriptions and protect against unwanted charges.\n- Some users share their experiences with canceling subscriptions and potential difficulties they faced.\n- There is a debate about the ease of canceling Amazon Prime, with some users sharing positive experiences and others expressing frustration.\n- Users suggest contacting credit card providers to freeze payments as an alternative to canceling subscriptions.\n- The possibility of filing chargebacks and changing credit card numbers is discussed as potential means to avoid unwanted charges.\n- Some users express concerns about the feasibility of chargebacks and potential consequences, such as losing access to accounts or data.\n- The discussion highlights issues with cancellation processes and the need for improved customer experiences.",
    "hn_summary": "- Evernote has laid off a significant portion of its remaining staff after being taken over by Bending Spoons, raising concerns about the company's ability to fund new features.\n- Users express frustration with Evernote's struggle to convert free users to paying customers and highlight the importance of simplicity, reliability, and portability in a note-taking app.\n- Alternative note-taking apps like Obsidian and OneNote are mentioned as successful competitors to Evernote, and users discuss the risks and downsides of VC-funded startups."
  },
  {
    "id": 36621120,
    "timestamp": 1688670195,
    "title": "GPT-4 API General Availability",
    "url": "https://openai.com/blog/gpt-4-api-general-availability",
    "hn_url": "http://news.ycombinator.com/item?id=36621120",
    "content": "Site NavigationResearchProductDevelopersSafetyCompanySearchNavigation quick linksLog inSign upGPT-4 API general availability and deprecation of older models in the Completions APIGPT-3.5 Turbo, DALL\u00b7E and Whisper APIs are also generally available, and we are releasing a deprecation plan for older models of the Completions API, which will retire at the beginning of 2024.Illustration: Ruby ChenJuly 6, 2023AuthorsOpenAIProduct, AnnouncementsStarting today, all paying API customers have access to GPT-4. In March, we introduced the ChatGPT API, and earlier this month we released our first updates to the chat-based models. We envision a future where chat-based models can support any use case. Today we\u2019re announcing a deprecation plan for older models of the Completions API, and recommend that users adopt the Chat Completions API.GPT-4 API general availabilityGPT-4 is our most capable model. Millions of developers have requested access to the GPT-4 API since March, and the range of innovative products leveraging GPT-4 is growing every day. Today all existing API developers with a history of successful payments can access the GPT-4 API with 8K context. We plan to open up access to new developers by the end of this month, and then start raising rate-limits after that depending on compute availability.Based on the stability and readiness of these models for production-scale use, we are also making the GPT-3.5 Turbo, DALL\u00b7E and Whisper APIs generally available. We are working on safely enabling fine-tuning for GPT-4 and GPT-3.5 Turbo and expect this feature to be available later this year.Moving from text completions to chat completionsWe introduced the Chat Completions API in March, and it now accounts for 97% of our API GPT usage. The initial Completions API was introduced in June 2020 to provide a freeform text prompt for interacting with our language models. We\u2019ve since learned that we can often provide better results with a more structured prompt interface. The chat-based paradigm has proven to be powerful, handling the vast majority of previous use cases and new conversational needs, while providing higher flexibility and specificity. In particular, the Chat Completions API\u2019s structured interface (e.g., system messages, function calling) and multi-turn conversation capabilities enable developers to build conversational experiences and a broad range of completion tasks. It also helps lower the risk of prompt injection attacks, since user-provided content can be structurally separated from instructions.Text summarizationSystemSummarize this message in max 10 words.UserJupiter is the fifth planet from the Sun and the largest in the Solar System. It is a gas giant with a mass one-thousandth that of the Sun, but two-and-a-half times that of all the other planets in the Solar System combined. Jupiter is one of the brightest objects visible to the naked eye in the night sky, and has been known to ancient civilizations since before recorded history. It is named after the Roman god Jupiter. When viewed from Earth, Jupiter can be bright enough for its reflected light to cast visible shadows, and is on average the third-brightest natural object in the night sky after the Moon and Venus.AssistantJupiter: Largest planet, visible to the naked eye at night.Code completionSystemComplete the following code.Userdef fibonacci(num):Assistantif num == 0:  return 0elif num == 1:  return 1else:  fib = [0, 1]  for i in range(2, num + 1):     fib.append(fib[i-1] + fib[i-2])  return fib[num]Few-shot learningSystemYou translate corporate jargon into plain English.UserNew synergies will help drive top-line growth.AssistantWorking well together will make more money.UserLet\u2019s circle back when we have more bandwidth to touch base on opportunities for increased leverage.AssistantWhen we\u2019re less busy, let\u2019s talk about how to do better.UserThis late pivot means we don\u2019t have time to boil the ocean for the client deliverable.AssistantBecause of this sudden change, we don\u2019t have enough time to complete the entire project for the client.We plan to continue investing most of our platform efforts in this direction, as we believe it will offer an increasingly capable and easy-to-use experience for developers. We\u2019re working on closing the last few remaining gaps of the Chat Completions API quickly, such as log probabilities for completion tokens and increased steerability to reduce the \u201cchattiness\u201d of responses.Deprecation of older models in the Completions APIAs part of our increased investment in the Chat Completions API and our efforts to optimize our compute capacity, in 6 months we will be retiring some of our older models using the Completions API. While this API will remain accessible, we will label it as \u201clegacy\u201d in our developer documentation starting today. We plan for future model and product improvements to focus on the Chat Completions API, and do not have plans to publicly release new models using the Completions API.Starting January 4, 2024, older completion models will no longer be available, and will be replaced with the following models:Older model New modelada ada-002babbage babbage-002curie curie-002davinci davinci-002davinci-instruct-beta gpt-3.5-turbo-instructcurie-instruct-betatext-ada-001text-babbage-001text-curie-001text-davinci-001text-davinci-002text-davinci-003Applications using the stable model names for base GPT-3 models (ada, babbage, curie, davinci) will automatically be upgraded to the new models listed above on January 4, 2024. The new models will also be accessible in the coming weeks for early testing by specifying the following model names in API calls: ada-002, babbage-002, curie-002, davinci-002.Developers using other older completion models (such as text-davinci-003) will need to manually upgrade their integration by January 4, 2024 by specifying gpt-3.5-turbo-instruct in the \u201cmodel\u201d parameter of their API requests. gpt-3.5-turbo-instruct is an InstructGPT-style model, trained similarly to text-davinci-003. This new model is a drop-in replacement in the Completions API and will be available in the coming weeks for early testing.Developers wishing to continue using their fine-tuned models beyond January 4, 2024 will need to fine-tune replacements atop the new base GPT-3 models (ada-002, babbage-002, curie-002, davinci-002), or newer models (gpt-3.5-turbo, gpt-4). Once this feature is available later this year, we will give priority access to GPT-3.5 Turbo and GPT-4 fine-tuning to users who previously fine-tuned older models. We acknowledge that migrating off of models that are fine-tuned on your own data is challenging. We will be providing support to users who previously fine-tuned models to make this transition as smooth as possible.In the coming weeks, we will reach out to developers who have recently used these older models, and will provide more information once the new completion models are ready for early testing.Deprecation of older embeddings modelsUsers of older embeddings models (e.g., text-search-davinci-doc-001) will need to migrate to text-embedding-ada-002 by January 4, 2024. We released text-embedding-ada-002 in December 2022, and have found it more capable and cost effective than previous models. Today text-embedding-ada-002 accounts for 99.9% of all embedding API usage.We recognize this is a significant change for developers using those older models. Winding down these models is not a decision we are making lightly. We will cover the financial cost of users re-embedding content with these new models. We will be in touch with impacted users over the coming days.Older model New modelcode-search-ada-code-001 text-embedding-ada-002code-search-ada-text-001code-search-babbage-code-001code-search-babbage-text-001text-search-ada-doc-001text-search-ada-query-001text-search-babbage-doc-001text-search-babbage-query-001text-search-curie-doc-001text-search-curie-query-001text-search-davinci-doc-001text-search-davinci-query-001text-similarity-ada-001text-similarity-babbage-001text-similarity-curie-001text-similarity-davinci-001Deprecation of the Edits APIUsers of the Edits API and its associated models (e.g., text-davinci-edit-001 or code-davinci-edit-001) will need to migrate to GPT-3.5 Turbo by January 4, 2024. The Edits API beta was an early exploratory API, meant to enable developers to return an edited version of the prompt based on instructions. We took the feedback from the Edits API into account when developing gpt-3.5-turbo and the Chat Completions API, which can now be used for the same purpose:SystemApply the change requested by the user to the code.Userdef fibonacci(num):  if num <= 1:    return num  else:    return fibonacci(num-1) + fibonacci(num-2)print(fibonacci(10))UserRename the function to fib.Assistantdef fib(num):  if num <= 1:    return num  else:    return fib(num-1) + fib(num-2)print(fib(10))AuthorsOpenAIView all articlesRelated researchView all researchImproving mathematical reasoning with process supervisionMay 31, 2023May 31, 2023Language models can explain neurons in language modelsMay 9, 2023May 9, 2023GPTs are GPTs: An early look at the labor market impact potential of large language modelsMar 17, 2023March 17, 2023GPT-4Mar 14, 2023March 14, 2023ResearchOverviewIndexProductOverviewChatGPTGPT-4DALL\u00b7E 2Customer storiesSafety standardsPricingSafetyOverviewCompanyAboutBlogCareersCharterSecurityOpenAI \u00a9 2015\u200a\u2013\u200a2023Terms & policiesPrivacy policyBrand guidelinesTwitterYouTubeGitHubSoundCloudLinkedInBack to top",
    "summary": "- OpenAI has announced the general availability of the GPT-4 API, their most capable model, to all paying API customers. This highly requested API provides developers with access to innovative products leveraging GPT-4.\n- OpenAI has also introduced the Chat Completions API, which has proven to be powerful and flexible for a broad range of completion tasks. It accounts for 97% of API usage and offers better results with a structured prompt interface.\n- Older models in the Completions API will be deprecated and replaced with new models starting on January 4, 2024. Developers using these older models will need to upgrade their integration to ensure continued access to the API.",
    "hn_title": "GPT-4 API General Availability",
    "original_title": "GPT-4 API General Availability",
    "score": 691,
    "hn_content": "- OpenAI has released the GPT-4 API, which is now available for all paid users.\n- ChatGPT models like gpt-3.5-turbo and text-davinci-003 are still available but will eventually be deprecated in favor of the GPT-4 API.\n- GPT-3.5-turbo-instruct is a new model that offers more powerful and structured instruction-based interactions.\n- The GPT-4 API offers improved performance and capabilities over previous versions.\n- OpenAI will provide support for users transitioning from older fine-tuned models to the new base GPT-3 models.\n- The move to deprecate certain models may be driven by factors like hardware constraints.\n- Developers are exploring open-source alternatives to mitigate the impact of the model deprecations.\n- The cost and capabilities of different models should be considered when choosing the right one for your use case.- Developers are praising the quality jump from GPT3.5 to GPT4 in various domains, including legal AI and medical writing.\n- The quality and performance of GPT4 can vary depending on the communication style, but it is generally considered superior to GPT3.5.\n- GPT4 shows improvement in code completion and assistance, making it more useful for software engineers.\n- GPT3.5-turbo-0613 fixed some issues with GPT3.5 and is considered reliable for certain tasks.\n- GPT4 is faster and more efficient when used interactively, while GPT3.5-turbo is better for programmatic access.\n- The limited availability of GPT4 APIs has caused frustration among users who want access to the latest models.\n- OpenAI's Whisper, a transformer-based speech recognition model, is being used for audio input in the ChatGPT iOS app.\n- Whipter can provide high-quality training data from audio/video sources.\n- Apple's transformer-based speech recognition in iOS 17 may compete with Whisper, offering real-time transcription.\n- There is a possibility that Apple is training a large transformer model in their datacenter and applying it as an RNN on devices.\n- Whisper can be self-hosted, allowing users to have more control and flexibility.\n- The main concern with Whisper is the requirement to say the entire text at once, which may be challenging for longer batches of text.",
    "hn_summary": "- OpenAI has released the GPT-4 API, which is now available for all paid users.\n- ChatGPT models like gpt-3.5-turbo and text-davinci-003 will eventually be deprecated in favor of the GPT-4 API.\n- GPT-4 offers improved performance and capabilities over previous versions, with developers praising its quality jump in various domains."
  },
  {
    "id": 36614114,
    "timestamp": 1688641885,
    "title": "Godot 4.1",
    "url": "https://godotengine.org/article/godot-4-1-is-here/",
    "hn_url": "http://news.ycombinator.com/item?id=36614114",
    "content": "Godot 4.1 is here, smoother, more reliable, and with plenty of new featuresBy:Godot contributors6 July 2023ReleaseAfter four months of work, we are excited to bring you Godot 4.1! It\u2019s an update that follows our pledge to improve upon Godot 4.0 with frequent incremental releases \u2014 with a focus on stability, performance, and polish.As always, a new release comes with a bunch of welcome new features, like the improved AI navigation avoidance and the ability to detach code editors and put them on other displays.Still, we took great care to prioritize the bugs you have encountered in 4.0. This update fixes over 900 issues that users have reported from using Godot 4 or while helping contributors test 4.1 with pre-release builds. The engine should feel more reliable overall. We will continue improving stability, performance, and workflows with every upcoming feature release of Godot 4.For most games and apps made with 4.0 it should be relatively safe to migrate to 4.1. We are preparing a migration guide that outlines everything you need to pay attention to when migrating your project. Some incompatibilities are expected for C# and GDExtension users specifically, however we are working on making sure to avoid that in future releases. Don\u2019t forget to always make backups when moving versions, even minor. Better yet, prefer using a version control system, such as Git, and commit a version of your project before the migration.If you wish to get straight into the action, you can download Godot 4.1 now. Or stick around and read more about the most notable changes of this release. You can also watch this great highlights video by GDQuest:Giving backAs a community effort, Godot relies on individual contributors to improve. In recent years, user and company donations allowed us to also hire a number of core contributors to work full-time on the engine and bring you these fast-paced releases.Our monthly expenses remain higher than monthly donations, and we still depend on large one-time company donations to fund development. Currently, we need a lot more monthly donations to keep up the pace with Godot 4 updates, not to mention the need to hire more maintainers to review every contribution.Besides financial support, you can also give back by: writing detailed bug reports, contributing to the code base, writing documentation, writing guides (for the docs or on your own website), and supporting others on the various community platforms by answering questions and providing helpful tips.Last but not least, making games with Godot and crediting the engine goes a long way to help make it more popular and convince more people to contribute and improve Godot for everyone. Remember, we are all in this together and Godot requires community support in every area to thrive.HighlightsThis release was made possible thanks to submissions from over 300 contributors! We warmly thank you all for your work and dedication, including those who helped us test the engine before the release and submit bug reports.For an exhaustive list of all the bug fixes and improvements, head on over to our interactive changelog.Without further ado, here\u2019s a breakdown of the main changes and new features.PerformanceGodot games are built as a tree of nodes, which are the engine\u2019s base building block for game entities. Adding and removing nodes are operations the engine needs to do extremely often, so they need to be as fast as possible.In 4.1, we changed the algorithm to use a fast hashmap to make adding and removing child nodes several times faster. Uncommon node operations are slightly slower as a result, and the memory footprint of the base Node class is 10% higher, but this is a small and necessary trade-off for a big benefit to all Godot users, especially to more complex projects with a lot of node manipulation.This version also introduces experimental multithreading for your scenes, a feature kickstarted by Juan Linietsky. New node properties give you full control over how nodes get processed, sequentially or in parallel.As mentioned, the feature is currently marked experimental as it needs extensive testing to find edge cases. We do not recommend using it in production yet. But it sets the foundation for making the most of modern hardware, with simple controls.Also on the multithreading front, Pedro J. Est\u00e9banez worked hard on fixing a large amount of multi-threaded loading issues and limitations.On the rendering side, the Vulkan renderer got a pipeline cache. While Godot already cached shaders to reduce shader compilation stutter, compiling pipelines still lead to some stuttering and slower load times. While the pipeline compilation stuttering issue is far from solved, this represents a step in the right direction and should also lead to a slight decrease in load times when using one of the RenderingDevice-based rendering backends. This cache can be toggled off in the project settings and is on by default in Godot 4.1.This improvement doesn\u2019t address all possible causes of stalls, but it\u2019s a first step in the right direction by Alexander Streng. We\u2019ll keep working on it in upcoming releases.More work will follow on the performance front throughout the year.CoreWhen importing models into Godot, there was often the problem that they ended up facing backward.Juan Linietsky, Tokage, and Aaron Franke worked on a number of ways to address this issue. One of the implemented changes swaps the front and back camera directions in the editor. Also, the look_at() function now has an argument to use the model space as the reference for looking forward instead of the camera\u2019s minus Z axis. These changes also help fix a long-standing bug with path following.This update also brings frame delta smoothing to Godot 4, by lawnjelly. This can significantly improve the fluidity of motion and give smoother gameplay. This option is enabled by default, though please note that it only works when VSync is also enabled.ScriptingGDScriptUntil now, in GDScript, you needed to use a resource or an autoload to share data between multiple instances of the same script.Thanks to George Marques, you can now create and use static variables instead. Static variables store data on the class instead of each instance, so they\u2019re shared between every instance of the class.To make a variable static, add the static keyword in front of a variable defined at the top of your script.A great feature of GDScript added in Godot 4 is the automatic generation of documentation pages for your named classes.This version includes a rework of the system by ocean that now treats enumerations as types, making the generated documentation more precise. You can also now use inline docstrings instead of having to always place them above a variable or a function\u2019s definition.var my_variable = 10 ## This is an inline docstringC#/.NETThe focus in this release was on bringing feature parity between C# and GDScript.When using GDScript, you can define a new node type to use in the editor by adding a global class name to your script.Starting from Godot 4.1, this is also possible in C# by adding the [GlobalClass] attribute to your file, thanks to Raul Santos and Will Nations. You can also use the [Icon] attribute to give your global class a unique icon.Note that as of this release projects made with C# still cannot be exported to mobile and web platforms. We are working on providing the support as soon as possible, but the resolution of this limitation will likely depend on the release of .NET 8 at the end of 2023. This means that the work on enabling mobile and web platforms can only truly start later this year.GDExtensionGodot comes with a unique technology to use low-level languages like C++ as a game scripting language, without having to recompile the engine.While the technology is still in beta for this release, GDExtension is now even closer to GDScript and C# in terms of scripting capabilities. You can now implement new visual shader nodes and create editor plugins with GDExtension.The team also implemented a backward compatibility system to help ensure that code written for Godot 4.1 keeps working even if the API changes in future releases. However, a significant compatibility breakage was necessary to do in 4.1 to fix critical issues in GDExtension, so existing Godot 4.0 extensions will need to be ported and recompiled for 4.1.Finally, a lot of work was done on the architecture once again to make the GDExtension API extensible in the future.All the above resulted from the teamwork of David Snopek, Juan Linietsky, RedworkDE, Yuri Rubinsky, and Yuri Sizov.EditorGodot 4 has support for multiple windows which we use for the project and editor settings and various pop-ups. Starting with this version, you can now also detach docs into floating windows and detach script editors, including the shader editor, and place them on a separate monitor.In addition to that, the editor will now keep track of your window layout so that when you close and reopen the editor, you should often find yourself exactly where you left off.You can thank trollodel, Hendrik Brucker, and Tomasz Chabora for this.Godot 4.0 introduced the option to define and export typed arrays, and to export individual nodes to the inspector, but it was not possible to combine the two. From Godot 4.1 onwards, you can export arrays of nodes to the inspector, which is great to link game objects together.This work was done by Tomasz and Timoth\u00e9 BonhoureThe project manager now allows you to assign tags to individual projects and filter projects by tags. It makes it much easier to search through dozens, if not hundreds of Godot projects.RenderingParticle turbulence got reworked in this version based on artists\u2019 feedback to offer greater creative control. Turbulence is used extensively to create these rich sprawling effects seen in many modern games. Big thanks to KdotJPG and Raffaele Picca for this contribution.Using the new 3D noise textures you can control the density of volumetric fog easily, and make it thinner in certain areas. NoiseTexture3D can also be used to create particle attractor vector fields, which is useful to simulate wind that affects particles. Lasuch and Clay John implemented this feature.While there are still many planned improvements to Godot\u2019s renderers, most will be present in future releases. The rendering team (and all rendering contributors) prioritized bug fixing and stability over new features. Notably, the 3D GLES3 renderer is not yet complete, but will see substantial work over the coming months.NavigationGodot 4.0 introduced real-time avoidance for AI navigation, but it was limited to a single plane.This release includes completely rewritten avoidance algorithms by smix8 to give you much better behaviors and greater control. Avoidance can now happen in 2D or 3D, allowing flying agents to move over those walking on the ground.On top of that, you can now use layers to control which agents avoid which and assign priorities to have some agents push others away.Check out the updated documentation to learn more about how the improved navigation works.Platform supportWe are as committed as ever to have Godot games on all popular platforms, and 4.1 still offers the same capabilities as did Godot 4.0. You can export to all desktop platforms with both standard and .NET version of the engine, and you can export to mobile and web if you don\u2019t use C# in your projects.As of 4.1 web exports still have some limitations due to poor vendor support of certain modern features. Browsers with bad WebGL 2 support, such as Chrome on macOS, unfortunately suffer from issues which we cannot address without a fix from Google or a significant amount of effort put into supporting a dedicated WebGL 1 / GLES2 renderer.We are also aware of the complexity setting up web games on hosting platforms which don\u2019t let you set the required CORS headers for SharedArrayBuffer support. This mostly depends on Safari implementing the coep:credentialless header support, while Chromium-based browsers and Firefox already work fine (especially if you publish on itch.io). There is a possible workaround that we are investigating.Known issuesWith every release we acknowledge that there are going to be problems which we couldn\u2019t resolve in time. Some of these problems have been identified and fixes are being worked on as we speak, while others remain unknown until someone runs into the issue. You can follow our bug tracker to learn if the problem that you\u2019re experiencing has been reported. We appreciate new reports and confirmations of existing reports, as that helps us prioritize fixing specific issues.Here are notable issues that have already been identified that you might experience in Godot 4.1:The newly added API for defining custom configuration properties for export presets does not persist user configurations. Configuration options get reset and lost on editor restarts. The fix is going to be available in 4.1.1 (see GH-79025).On to the next release!We already started work on Godot 4.2, which will come out in four months. We are dedicated to keeping up the pace and sticking to this reliable release cycle, so you never have to wait long for the next batch of improvements and new features.Until then, enjoy Godot 4.1!",
    "summary": "- Godot 4.1 is a new update that brings smoother performance, improved AI navigation avoidance, and the ability to detach code editors.\n- Over 900 bugs from the previous version have been fixed, making the engine more reliable overall.\n- The update also introduces experimental multithreading for scenes, allowing for better utilization of modern hardware.",
    "hn_title": "Godot 4.1",
    "original_title": "Godot 4.1",
    "score": 489,
    "hn_content": "Hacker News new | past | comments | ask | show | jobs | submit loginGodot 4.1 (godotengine.org)489 points by freeCandy 22 hours ago | hide | past | favorite | 145 commentssen 22 hours ago | next [\u2013]I recently switched almost entirely from Unity to Godot 4.0 (not a career game dev, I just make small/indie/itch.io type stuff) and I've been absolutely loving it. It's such a breath of fresh air. It's light, fast, easy to learn, and can do 90% of what you need as a solo/indie type developer.The only thing stopping me from swapping over entirely and giving up Unity for good is the bug that means games take forever to load on itch.io if the user has MacOS (long enough that they think it's broken and close the tab). A majority of the games I make are educational and/or targeted at kids who are using iPads or MacBooks, and being able to link them to itch.io is a LOT easier than teaching them (and convincing the device owner) to install the game locally.They say they're working on it (quoted below), but until then I'm pretty much stuck using Unity for a few projects still. If/when they fix this, I think Godot could really take off for the itch.io/gamejam/etc type crowd.> As of 4.1 web exports still have some limitations due to poor vendor support of certain modern features. Browsers with bad WebGL 2 support, such as Chrome on macOS, unfortunately suffer from issues which we cannot address without a fix from Google or a significant amount of effort put into supporting a dedicated WebGL 1 / GLES2 renderer.> We are also aware of the complexity setting up web games on hosting platforms which don\u2019t let you set the required CORS headers for SharedArrayBuffer support. This mostly depends on Safari implementing the coep:credentialless header support, while Chromium-based browsers and Firefox already work fine (especially if you publish on itch.io). There is a possible workaround that we are investigating.replyHanClinto 20 hours ago | parent | next [\u2013]I'm in a similar boat, and eventually realized that Godot 3.5.2 is still the LTS version and still exports just great for the web -- this is the example that convinced me it was time to switch: https://yet-another-lucas.github.io/plumbing-adventure/After I realized this, I decided to switch from Godot 4.0 C# to Godot 3.5.2 with GDScript and I've been happy ever since. I've even got it set up with a CI/CD pipeline to automatically build-and-deploy to Github Pages whenever I commit to master -- these CI/CD pipelines are pretty sweet.https://www.reddit.com/r/godot/comments/q25riu/hosting_on_gi...replycven714 19 hours ago | root | parent | next [\u2013]> https://yet-another-lucas.github.io/plumbing-adventure/Nice, I made a version of that game myself following the tutorials of https://www.youtube.com/@uheartbeastThis was a while ago, he recently put out a ton of new tutorials for Godot 4, good stuff for quickly getting your hands dirty. You're beyond that point I'm sure, just throwing them out here for anyone else looking for nice intro content.replyHanClinto 18 hours ago | root | parent | next [\u2013]Thank you for the link! I didn't make the linked example -- my work is MUCH simpler than that. :D This was what someone else built and packaged and convinced me that this performance is finally rivaling the Flash experience that I've been missing for so long.replysli 15 hours ago | root | parent | prev | next [\u2013]I would say Heartbeast's courses are overall much better than your typical tutorial content, primarily because they are structured and built like courses rather than tutorials. I paid for a couple of his courses a while back after doing one of his free ones and do not regret it, they were excellent.replyschemescape 17 hours ago | root | parent | prev | next [\u2013]How long should that game take to load?It took a good 20 - 30 seconds for me.replyhenryfjordan 17 hours ago | root | parent | next [\u2013]loaded very quickly for me, 1-2s maybe on a macbook pro on 13.2.1replyeieio 14 hours ago | parent | prev | next [\u2013]I've built 5 small browser-based game-jammy games (e.g. nothing that took me more than ~2 weeks) in Godot 3.5 this year[1] and have largely enjoyed the experience - I'll echo other folks and say that you might just be happy using Godot 3.5 until Godot 4 has functional web exports.Godot 4 _does_ come with some language improvements that I'm excited about, particularly around better typing support and fewer places where you need magic strings (e.g. you can refer to signals by name!) - I suppose if that's a big sticking point for you (totally reasonable!) then waiting might just be better.I will say that at times I've been frustrated by the Godot 4 team's perspective that the MacOS breakage is a Chrome bug and not a regression in Godot[2]. It's really a question of semantics and prioritization more than anything but it's hard for me to not see the behavior as a regression when a feature that I rely on in Godot 3 is broken in Godot 4.That said I'm very grateful for all the work that's gone into Godot 4 (and prior versions) and I'm very excited for the day that I get to use it![1] They're all over at https://eieio.games/ if you're curious![2] https://github.com/godotengine/godot/issues/70691replyflohofwoe 18 hours ago | parent | prev | next [\u2013]> Browsers with bad WebGL 2 support, such as Chrome on macOS.This caught my eye. I haven't run into any WebGL2 problems so far on Chrome/macOS, would be interesting to know what specifically those problems are (however I'm also staying away from some WebGL2/GLES3 features which are known to cause trouble not just on WebGL2, mostly uniform buffers and generally some buffer update patterns that work well on native, but not on WebGL (such as 'buffer orphaning').replyhoten 18 hours ago | root | parent | next [\u2013]Also curious what this refers to. Anyone find a crbug?replyomoikane 15 hours ago | root | parent | next [\u2013]Probably this one: https://crbug.com/1324296Linked from here: https://github.com/godotengine/godot/issues/70691replyhoten 14 hours ago | root | parent | next [\u2013]> Our team's goal is to ship ANGLE's Metal backend imminently. Blocking on that shipment so that hopefully we don't have to diagnose this more deeply.Fantastic news for the Godot folks.replymentos 22 hours ago | parent | prev | next [\u2013]Any opinion on the state of VR on Godot? I\u2019m using UE4 which I have 9 year\u2019s experience in and not the biggest fan of Unity but would be curious to try out Godot.replynurple 18 hours ago | root | parent | next [\u2013]It\u2019s a dream compared to UE. I tried on and off over a couple years to power through building some toy VR apps in UE and was never really able to make much progress past their prefab maps. It\u2019s just so freaking complex that, IME, the fun of the process gets crushed under the weight of making zero forward progress.As I started a NixOS immersion program a few months back I was looking for a new platform that I could do 100% of my dev on Linux. Ran into godot searching vids on YouTube and was really impressed with the workflows so I installed godot and steam (home.packages = [ pkgs.unstable.godot_4 pkgs.steam ]). With openXR support built into godot 4, it automatically picked up the shared lib that stream dropped and in under an hour was walking around using my index and Vive in a VR env and could also build a package for my son\u2019s quest.Within a month on-the-side I had built a tabletopesque tank battle game with a custom ray-based suspension over high poly terrain, particle effects, ballistic artillery, and a unique controller input scheme based on the tilt of the controllers (left for body rotation, right for turret). The physics engine is great, rocking the body on fire was simple as an inverse impulse of the shell spawn vector, and the body properly rolls under both lateral and longitudinal axis by virtue of the damped shocks.All that to say, I think the biggest difference is that with godot 90% of my effort, code, and time was spent writing implementation code for my game while on UE it was spent writing integration code.You obviously miss out on hot topic things like nanite et al, but I learned a long time ago that fidelity has no correlation with an engaging game. The other con will likely be around performance, it\u2019s passable at 90hz, but if you want to start hitting framerates like 144hz, the critical code will probably need to drop to C++ using GDExtention.I\u2019ve also noticed that, with the popularity gaining in gltf, that it was rather trivial to find quality assets with native support.I\u2019d recommend watching some vids on creating VR apps, and another great resource, if you want to grok the interface code, is godot\u2019s xr-tools project: https://github.com/GodotVR/godot-xr-tools/tree/master/addons...replyprox 13 hours ago | root | parent | next [\u2013]Your experience also confirms what I feel Godot is particularly suited for : playtesting and pre-production of parts of your game.You could quickly bang together all kinds of parts to see if your idea works, and then incorporate those in other engines if you so wish.replyFireInsight 21 hours ago | root | parent | prev | next [\u2013]I just very recently started working on a VR game in Godot and the setup was very easy. They also have a project where common parts such as teleporting are implemented, which I didn't try yet, but which seems cool.replysen 21 hours ago | root | parent | prev | next [\u2013]I don't do VR, but I've seen some videos on YT showing people do VR stuff in Godot so it \"works\", but I'm not sure how well.replyg4zj 20 hours ago | parent | prev | next [\u2013]I'm a macOS user who makes games using Godot and publishes them on itch.io, and I haven't experienced this issue. Can you link to an example where this occurs, and provide some information on how the build was exported?replygmjosack 19 hours ago | root | parent | next [\u2013]This is definitely a known issue that I've personally experienced but is even listed as a warning on the docs[1].> Godot 4's HTML5 exports currently cannot run on macOS and iOS due to upstream bugs with SharedArrayBuffer and WebGL 2.0. We recommend using macOS and iOS native export functionality instead, as it will also result in better performance.> Godot 3's HTML5 exports are more compatible with various browsers in general, especially when using the GLES2 rendering backend (which only requires WebGL 1.0).Web exports are essentially unusable for Mac users. It's the biggest complaint I get from my games using Godot 4.x.[1] https://docs.godotengine.org/en/stable/tutorials/export/expo...replyHanClinto 20 hours ago | root | parent | prev | next [\u2013]You're probably using 3.5.x? The majority of web export issues only happen on 4.X.replyg4zj 19 hours ago | root | parent | next [\u2013]I have both installed and am migrating a game between them now. I don't believe I've actually exported the 4.x version for using the HTML5 profile just yet, so I'll have to give that a go.replyHanClinto 19 hours ago | root | parent | next [\u2013]It'd be worth your time before you get too deep. The two issues that I ran into:* CORS issues -- deploying on some sites (esp. gitlab and github pages) runs into issues because of shared buffer requests.* Assuming you get past the CORS issues, there is still extremely slow load on OSX Chrome -- the app eventually loads, but holy smokes it takes forever.Both of those nearly made me give up on Godot, but I'm very happy to stay with 3.5.x until those get resolved.replyg4zj 19 hours ago | root | parent | next [\u2013]Thanks for the information. I am mostly migrating the game to get a first-hand idea of some of the changes I'm most likely to run into while developing the next one.I, too, am happy to stay with 3.5.x. It works pretty well for my purposes, though hopefully 4.x will be a viable option for me soon.replyDarkNova6 21 hours ago | parent | prev | next [\u2013]As somebody contemplating building a 2D strategy game, how good is the C# support?This was a killer feature for Unity over Unreal. If Godot has similarly good integration, it looks like a better choice.replyTillE 19 hours ago | root | parent | next [\u2013]It's worth noting that Godot 4 is using actual .NET instead of Mono, so you get all the tooling support that implies, including seamless debugging with Visual Studio, etc. Unity has been promising that transition for years, but I'm pretty sure they're still using some customized version of Mono.So you can write a game with .NET 7 and everything is great. There's a little bit of extra overhead when making calls into the Godot engine, so you still may want to use bits of C++ for performance where it matters, but otherwise there are only a few rough edges left.replygabereiser 14 hours ago | root | parent | next [\u2013]Unity wants to transpile it to C++ code. IL2CPP where they take the IL code of your C# and translate it into C++ for speed. So yeah, not only are they NOT using dotnet tooling but they are going the opposite direction.replyWinstonSmith84 21 hours ago | root | parent | prev | next [\u2013]It works relatively well, and actually better than in Unity (which use an older C# version), but unfortunately it does not work everywhere. For example, it's not possible to export to the web, which was to me the main show stopper. I needed C# due to some libraries, and I needed that it runs in a browser, so that was game over, no pun intended.Apart from that, I really preferred Godot over Unity. Faster, more consistent, better learning curve, etc.replyDarkNova6 20 hours ago | root | parent | next [\u2013]Thank you, this is really helpful input. It does seem likely Godot will be our engine of choice.replyDoddler 19 hours ago | root | parent | prev | next [\u2013]Are you sure it can't export c# to web? I would have assumed that as true but Godot's documentation does not list that as a limitation, and in fact offers c# code on how to use the JavaScript interop, something that would be pretty meaningless without support.replyWinstonSmith84 19 hours ago | root | parent | next [\u2013]Yes. https://godotengine.org/article/godot-4-1-is-here/> Note that as of this release projects made with C# still cannot be exported to mobile and web platforms. We are working on providing the support as soon as possible, but the resolution of this limitation will likely depend on the release of .NET 8 at the end of 2023. This means that the work on enabling mobile and web platforms can only truly start later this year.replysirwhinesalot 21 hours ago | root | parent | prev | next [\u2013]It's still a bit janky compared to their own GDScript, but C# is supported yes. Because there are two languages though, and C# is the second class citizen, you won't find as many examples on how to do things in C# as in GDScript.replyDarkNova6 20 hours ago | root | parent | next [\u2013]Thanks for the input. Given my background, I think I can figure out the syntax just fine if necessary. I am just sceptical of languages where typing is not strictly static (and I give a hard pass on pure dynamic typing).replyrunevault 18 hours ago | root | parent | next [\u2013]FYI a lot if not all of the core docs actually have tabs on any code samples to switch between c# and gdscript so while tutorials from third parties tend to focus on one or the other, the core docs are a bit better.I've started going through a tutorial on youtube from I think finepointCGI about a horror game in Godot, he is actually doing it twice, once with GDScript and once with c#, so if you want to see someone with some godot experience using c# give it a look.replydoctorpangloss 18 hours ago | parent | prev | next [\u2013]> ...who are using iPads or MacBooks, and being able to link them to itch.io is a LOT easier than...The instant game streaming service I develop targets Unity (see https://appmana.com/watch/virtualtestdrive for an example) and I was considering supporting Godot. But it would probably make more sense to fix web exports.Other than time and money, what obstacles did you face contributing a web export fix for Godot? I am not saying that you should, but I'm sure it crossed your mind.In the game services business, it's my opinion that in order to thrive, you target people who pay. Because Unity costs money, it attracts developers who pay. It's the halo effect. I wonder how the Godot ecosystem attracts developers who pay.replyNezteb 15 hours ago | parent | prev | next [\u2013]Yeah I tried to participate in a Ludum Dare jam shortly after 4.0 came out and was hit with the web export issues.Here are some issues worth tracking: https://github.com/godotengine/godot/issues?q=is:open+is:iss...replyxwowsersx 18 hours ago | parent | prev | next [\u2013]Is anything you've built with Godot publicly available somewhere? If so, can you share?replyjohnday 22 hours ago | prev | next [\u2013]Godot is a super impressive piece of kit. I'm waiting for a reason to start a new game project so that I can get to grips with it more firmly, but what they've been able to do with a relative small team puts Unity to shame. (Even more than Unity puts itself to shame)> This update fixes over 900 issues that users have reported from using Godot 4 or while helping contributors test 4.1 with pre-release builds.Fixing that many issues while further improving performance and stability is itself worthy of commendation. Well done Godot team!replyraincole 22 hours ago | parent | next [\u2013]Fixing 900 issues is definitely impressive, but Godot is probably one of repos with the most open issues on GitHub (5000+ at this moment).Again the number of open issues is not a good indicator of software quality anyway.replyqwery 20 hours ago | root | parent | next [\u2013]Godot's issue tracker is very popular! There have been ~4700 issues created this year, more than half of which have been closed, with ~2000 currently open.Also of note, there's an open proposal[0] 'Automatically close old issues in a way everyone should be happy with' attempting to deal with the significant backlog.[0] https://github.com/godotengine/godot-proposals/issues/3481replybaud147258 21 hours ago | root | parent | prev | next [\u2013]Actually it's 8000+ open issues on Github. It seems the number is capped at 5k in the header of the Github webpage. On the other hand, it's got 34k closed issues, so it's not as if the devs weren't working on thisreplyraincole 21 hours ago | root | parent | next [\u2013]TIL.Github should give them a special badge (Github achievement?) for breaking the 5k limit.replySakos 20 hours ago | root | parent | prev | next [\u2013]I wonder how it ranks compared to other github projects in number of issues opened vs issues closed/resolved, median time to resolve issues, etc.replyretrofuturism 22 hours ago | root | parent | prev | next [\u2013]In this case the number of open issues is a good indicator of usage. Well done Godot!replySpaghettiCthulu 20 hours ago | root | parent | prev | next [\u2013]To be more specific, godot has 8009 open issues at the time of writing.Certainly one of! I'm only aware of flutter/flutter and rust-lang/rust outranking it.replyjokoon 18 hours ago | prev | next [\u2013]I love godot, but:* gdscript is not python, it's lacking several small python things that makes python awesome: list/dict comprehension, .items(), sets, although gdscript is quite enough and still quite a good language for game dev as it does just everything well, especially for natives types etc.* I tried gdnative and I still need to try gdextension, but so far writing C++ for godot seems quite hairy and the programmer must use godot types and \"new()\" everywhere, which is not really easy to deal with, so godot is not really a C++ engine, C++ is only usable if you want to optimize something a bit tedious, which is fine, but important to remember, and it confirms the whole \"use a scripting language 99% of the time, and use C++ only if scripting is not fast enough\"* I would still want to inspect the real potential performance of gdscript compared to other languages, and I don't know if mono/.net is faster. It seems like a very good language especially because it integrate perfectly with how the environment is designed, but I'm still curious if they plan to improve it.* I'm planning to make a multiplayer FPS game, but I don't think godot provides network prediction, and I wish it did.* I'm a bit worried about opengl support in the future, it's not entirely done yet, and I'm afraid it's too difficult to properly implement because new API like vulkan or DX12 are so radically different.Overall godot is the greatest thing that ever happened to open source and game development, game development is one area where open source has trouble making its teeth, and the lightweight design of godot makes it just such a big relief when you compare it to monsters like unreal and unity.replybodge5000 17 hours ago | parent | next [\u2013]> gdscript is not python, it's lacking several small python things that makes python awesome: list/dict comprehension, .items(), sets, although gdscript is quite enough and still quite a good language for game dev as it does just everything well, especially for natives types etc.This is my biggest issue with Godot, although not that GDScript isn't python, its that it isn't a \"real\" language (or I guess general purpose might be a better word). In fact its probably the only thing I miss from Unity.To be fair I'm not sure I'd pick Python myself, as much as I love the language I'd probably pick something with a bit more focus on performance. Go might be a good choice, I dont know.It's not even that GDScript is bad, in fact without comparing it to other languages its pretty great, but you just lose so much when compared to general purpose languages. I know theres bindings, but having done the same with Raylib the support for non-official languages is pretty much non-existent. Its pretty bad for Mono, which is an official bindingreplysli 15 hours ago | root | parent | next [\u2013]The official C# bindings are .NET, not Mono. They were using Mono in older versions, though.replyjackmott42 14 hours ago | root | parent | prev | next [\u2013]There are official bindings to C#, the official docs have C# examples in them, and it can use the latest and greatest .NET versions, not just mono.replybodge5000 11 hours ago | root | parent | next [\u2013]The docs have c# examples, but the community by and large uses gdscript, it's the \"default\" language. Again, it's the same with Raylib, bindings have documentation but it's difficult to find anything using that language outside the docs.replyhoten 18 hours ago | parent | prev | next [\u2013]What does network prediction from a game framework look like? You describe what properties of objects should be interpolated and the engine handles it for you?replyjokoon 12 hours ago | root | parent | next [\u2013]Yes, I guess, properties like projectile/player velocity? Network prediction is a bit tedious to do because it's a lot of fine tuning.It's only useful for latency sensitive games like FPS games or any games that involves simple physics with player versus player situations.replyjackmott42 14 hours ago | parent | prev | next [\u2013]Yes, .NET is faster. Though even AAA games often use slow scripting languages for game logic. Many games, the game logic just isn't a big CPU hog so it doesn't matter.replyCapricorn2481 22 hours ago | prev | next [\u2013]Is there a use care for Godot for cross platform app development instead of something like Electron?replypachorizons 21 hours ago | parent | next [\u2013]Yes, although the first-generation of apps are only just beginning to emerge. Here are a couple of fully-featured projects on Github:Pixel art editor: https://github.com/Orama-Interactive/PixeloramaInfinite canvas drawing tool: https://github.com/mbrlabs/LorienTrello-style kanban board: https://github.com/alfredbaudisch/GodelloNarrative designer for games: https://github.com/mhgolkar/ArrowreplyfreeCandy 21 hours ago | root | parent | next [\u2013]Some more listed here: https://github.com/godotengine/awesome-godot#projectsreplyraincole 21 hours ago | parent | prev | next [\u2013]Material Maker: https://www.materialmaker.orgI tried this when Substance was aquired by Adobe. Surprisingly I found it much easier and enjoyable to use. Substance Designer feels very clumsy.Of course Substance Designer has one unique feature, which is it's integration with Substance Painter. MM has some manual painting capabilities, but it's not a full-fledged painting app.replyq_andrew 7 hours ago | root | parent | next [\u2013]Material Maker is surprisingly alone in the PBR material department for FOSS, I have started thinking about diving into the PRs just to get it up to snuff with Substance. I can hardly pay for Photoshop, Adobe!replyphilipov 21 hours ago | parent | prev | next [\u2013]Is the Godot IDE itself built in Godot?replynkrisc 21 hours ago | root | parent | next [\u2013]It is, and also means extending the editor experience is easy, even using GDScript.replyleetrout 21 hours ago | root | parent | prev | next [\u2013]YepreplyWillAdams 21 hours ago | parent | prev | next [\u2013]Yes.OpenSCAD Graph Editor is done with an earlier version and runs on Mac OS, Windows, and Linux:https://github.com/derkork/openscad-graph-editorreplykeyle 22 hours ago | parent | prev | next [\u2013]Yeah some people use Godot as a GUI frameworkreplygcr 22 hours ago | root | parent | next [\u2013]Expanding on this, Godot has its own 2D widget framework that's fairly straightforward to use, though it doesn't use native widgets.Note that the Godot editor itself is written in the widget framework, so you can get a sense for how well it works just by opening Godot and clicking around.replynumlock86 22 hours ago | root | parent | next [\u2013]The 2D framework, especially for UI, is pretty awesome. But the learning curve on the layout system is quite sprinkled with head scratching and frustration in my opinion.replynightowl_games 21 hours ago | root | parent | next [\u2013]Yeah it's brutal. I've been using Godot professionally for years. I have effectively mastered the layout system but it was annoying to learn. It tries to be like Unity's system but they made a few mistakes with Pivot, Grow Direction and Size Flags imo.I made a tool to position nodes in a way modelled after Cocos2D, with a position, pivot and anchor point.I've made a series of small tools to help me lay stuff out.One really good thing about Godot Ui is the \"StyleBox\" which simply allows coders to make rounded rectangles, which are so frequently used in UI it's nice to not need an artist to make a .pngreplysamstave 18 hours ago | root | parent | next [\u2013]As someone who has never made a game, I really want to make a tower defense game that fixes shortcomings I find in others - where would one complete beginner delve into Godot to accomplish starting to learn the system - there are a number of tuts on YT - one of which is ~11 hours long.Can you make some suggestions to avoid/pre-empt any said headscratchings and frustrations?replynightowl_games 16 hours ago | root | parent | next [\u2013]You are going to scratch your head and be frustrated. Just keep going! Imagine your asking \"I want to make a rock song that is better than the other rock songs. What youtube video can I watch to learn how to play the guitar?\"I usually recommend GDQuest on YouTube. Just start! Keep going! You'll figure it out.replyweinzierl 21 hours ago | parent | prev | next [\u2013]I've heard the Tesla mobile app is made with Godot. Not sure if it is true.replybarnabask 20 hours ago | root | parent | next [\u2013]It was true a year ago: https://news.ycombinator.com/item?id=32358271replyd11z 21 hours ago | prev | next [\u2013]The main contributor/developer behind Godot also released a very handy little tool that is capable of fully decompiling anything made with Godot:https://github.com/bruvzg/gdsdecompreplynightowl_games 21 hours ago | parent | next [\u2013]Cool tool but the main, lead, original developer of Godot is reduz - Juan Linietsky.replykirillbobyrev 15 hours ago | prev | next [\u2013]Godot is just AWESOME, I am very impressed with the progress the team makes and the overall direction of the project.I was always excited about Game Dev (even started learning Computer Science and became a Software Engineer largely because I wanted to make games), dreamed of making my own small games but never really got to it. After I became a full-time Software Engineer, I never really found time or the right tools for making my own small games for fun. I recently discovered Bevy and gave it a try. ECS is a nice concept, but Bevy is more of a library and it's quite hard to make full-featured games using it (just like using SDL/something similar).When I discovered Godot and gave it a try, I was so impressed: it's really nice for beginners, yet performant enough and has amazing community. This is exactly what I wanted to find, so I'm incredibly happy it exists and am very excited about the future development of Godot.One thing I wish was different is choosing a different language as the native and \"official\" one. GDScript is OK and arguably pretty good Python-like language for beginners and rapid prototyping, C# is OK and is probably very nice to have because many people would be happy to switch from Unity, but I personally would be happier with either better C++ support (which I know exists in GDNative interface which was improved in 4.0) or something else.C# is a fine language, but I have a feeling it has so much presence in GameDev just because of Unity. It's way too verbose and the tooling isn't as good (outside of full Visual Studio which I have no desire to use), but maybe \"actual programming\" part of GameDev isn't as important and I should just give in/use GDScript.replysuda50 15 hours ago | parent | next [\u2013]Starting with Godot 4.0, they now support GDExtension which allows you to basically write your own game code in C++ (and other languages), then have the engine import your code: https://docs.godotengine.org/en/stable/tutorials/scripting/g.... There is also a set of Rust bindings that utilize GDExtension too: https://github.com/godot-rust/gdext.They might be worth looking into.replykirillbobyrev 14 hours ago | root | parent | next [\u2013]Yeah, I've seen those and I'm happy Godot moves in this direction, but using these tools would steer me away from the \"default\" and \"primary\" behavior, I'd potentially face more bugs/awkward development setups.It might be worth if I'm serious about Game Development and ready to invest time and effort into customizing the tools, but what I'm looking for is \"out of the box\" experience which will make it easier for me to solve problems that I face (e.g. if I ask questions more people would be able to answer/help), the tutorials/resources I find will be more applicable etc.As others mentioned in this thread, having first-class support for a language isn't the same as providing API for plugins and custom scripts.I wish Godot chose a real existing programming language instead of building their own DSL. Even Lua might have been a decent choice, although I hate the syntax.replybirracerveza 20 hours ago | prev | next [\u2013]Godot may not be able to take on Unreal, but I certainly am cheering for it to take over Unity.Excellent engine, and more and more developers are rightfully recognizing its potential.replyehnto 20 hours ago | parent | next [\u2013]Unity is it's own beast like Unreal but in a different way, Unity as a platform supports mobile monetization in a way other platforms don't and Godot won't be cutting their lunch in that ecosystem any time soon.But I suspect you mean for indie dev, in which case I totally agree. Godot is the lightweight, get out of your way and build shit framework that people want Unity to be. Godot is better at that task by a long shot.replybirracerveza 19 hours ago | root | parent | next [\u2013]It's very telling that Unity is where it is because of monetization.Godot on the other hand is being picked up because it's an excellent engine. Maybe it's not going to kill Unity, but it's certainly going to relegate it to a shovelware low effort money grab engine.replyresoluteteeth 18 hours ago | root | parent | next [\u2013]> It's very telling that Unity is where it is because of monetization.No, it's absolutely not. It may happen to have mobile monetization features built in but it's where it is because it's been the best general game engine for everything other than AAA 3d games, although Godot is catching up.replybirracerveza 3 hours ago | root | parent | next [\u2013]You're right, sorry. I should have said> It's very telling that Unity will keep getting used because of monetization.Once upon a time it was a good engine.Nowadays it's an absolute mess, and it's been that way for a long time now.I am not a game developer, I develop prototypes in my spare time because I have fun tinkering with engines, and with Unity it doesn't take long before it becomes borderline unusable. I don't even want to imagine the struggle devs need to go through to make a full scale game playable, and those struggles prevent them from focusing on making the game actually fun to play. But, thanks to the deeply integrated monetization system, Unity is THE standard if you just want to make a game quickly to shove ads in people's faces every time they die in your simple, yet extremely buggy mobile game with stock assets. Is that a good thing? It depends, but I'd lean towards no.replyTillE 19 hours ago | parent | prev | next [\u2013]It would be insane to even try to compete with Unreal, an engine focused on AAA games that's been around for decades, with a large full-time staff. No open-source project will ever match them, because it's a moving target.Fortunately Unreal Engine is a poor choice for many types of games, and Godot is doing a great job carving out its niche with 2D games and simpler 3D games. There's still a big market for 2D games, and surprisingly there aren't a ton of engines which do a good job supporting them. Godot is easily among the best.replynomel 16 hours ago | root | parent | next [\u2013]> Fortunately Unreal Engine is a poor choice for many types of gamesDo you have some examples? Seeing these 2d games made me question some assumptions I heard [1].[1] https://youtu.be/wreOjWVGkys?t=43replydvtkrlbs 11 hours ago | root | parent | next [\u2013]I mean the problem is 2d game tools isn't getting loves for some time. Paper2d which is the main component of UE for 2d games still haven't updated with UE 5 last time I checked. So it misses a lot of feature parity.replystuckinhell 14 hours ago | parent | prev | next [\u2013]if you can replicate the marketplace, you probably could take on UnityreplySturgeonsLaw 22 hours ago | prev | next [\u2013]Godot is super cool and I have a ton of respect for all the people who put in time to make software like this and Blender et al so damn goodreplyspeedster217 20 hours ago | prev | next [\u2013]Anyone have any tutorials on Godot that they recommend?I've got a small RPG prototype that runs in the console but would love to give it an actual GUI/sprite graphics.replyamitmathew 19 hours ago | parent | next [\u2013]We have a free tutorial for Godot 4 that takes you from the start to a complete game in about two hours. You can find it here: https://quiver.dev/tutorials/create-your-first-godot-4-game/.Disclaimer: I'm the founder of the company that produced this course, but the tutorial is free and the custom assets used in the tutorial are liberally licensed.replydebacle 20 hours ago | parent | prev | next [\u2013]GD Quest is considered the bog standard right now. It's the W3Schools for Godot.As someone who is switching to Godot from Unity however, I think the tutorial ecosystem for Godot is a long ways behind.replygalleywest200 20 hours ago | root | parent | next [\u2013]Most of the tutorials I have seen still exist for Godot 3.X as opposed to 4.X, so it will just take some time is my prediction.replyrisingsubmarine 17 hours ago | parent | prev | next [\u2013]I did one of Heartbeast's courses. Can recommend.He recently put out one for Godot 4 specifically. https://www.youtube.com/watch?v=M8-JVjtJlIQreplyqwery 20 hours ago | parent | prev | next [\u2013]The official docs[0] are definitely the way to go.[0] https://docs.godotengine.org/en/stable/getting_started/intro...replyaglione 19 hours ago | root | parent | next [\u2013]Nathan from GDQuest was hired to write/improve themhttps://godotengine.org/article/we-hired-gdquest-work-manual...I absolutely recommend GDQuest courses, apart from the Godot engine they have a very clean idea about writing software.replycyber_kinetist 19 hours ago | root | parent | prev | next [\u2013]I've done both the official 2D/3D game tutorials in the official documentation, and although the 2D game tutorial wasn't that bad, the 3D tutorial was quite disappointing as a learning experience. It's still not ported to Godot 4, and they use some weird hacky code to achieve some basic gameplay stuff. (And the finished game itself isn't really that interesting...) Even the 2D tutorial leaves something to be desired, since it just dumps heaps of instructions/code at you without explaining you a more general picture first (which wouldn't be a problem for more experienced programmers, but beginners would definitely struggle)That said... it's still the most comprehensively written Godot tutorial to date, so I recommend at least trying out the 2D tutorial.replyjosh_p 19 hours ago | parent | prev | next [\u2013]gamedev.tv has a godot course updated for 4.0. I haven't gone through that one but their other stuff is really good. Just wait for sale. they usually go down to $10-$15 for a course.replykrapp 17 hours ago | parent | prev | next [\u2013]Here is my programming tutorial list on Youtube, it has some Godot tutorials:https://www.youtube.com/playlist?list=PLwYfcDZR0fFcROLjkiyBW...A lot of tutorials you'll find will be for Godot 3 so be sure to search for Godot 4 specifically as a filter. Otherwise be willing to take into account that you'll have to figure out how to make the tutorial code work for your version of Godot (which can be an educational experience in and of itself.)replykoromak 21 hours ago | prev | next [\u2013]I started using Godot for the first time last week! First attempt at game dev. I'm finding it quite friendly to learn.replyireallywantthat 22 hours ago | prev | next [\u2013]Godot is really turning good release by release. I'm very happy for Godot and the team. I'm interested in these features from Godot in future. I hope they implement them in Future Releases.1. FSR22. Excellent Wayland Support3. LLM Integration. It might make NPCs more realisticreplychme 21 hours ago | parent | next [\u2013]> 3. LLM Integration. It might make NPCs more realisticNot sure. That doesn't seems game engine related and more game specific. I think integrating LLM is just some scripting in your game.In terms of AI integration, I would be more interested in AI supported design. Like you describe a map, character or scenario, and the AI will generate something for you, which you then can customize and adapt. But even that is probably best done outside of the core game engine...replyeBombzor 17 hours ago | parent | prev | next [\u2013]Hardware accelerated ray tracing?replyrobertlagrant 21 hours ago | prev | next [\u2013]This is what I've been waiting for! - Samuel Beckett.replyloustak 16 hours ago | prev | next [\u2013]I have shipped two small projects using Godot 3. It's a cool engine but to me it can improve on the following points to be considered a mature engine for a new indie project: * GDscript is cool but lacks features such as better typing and lambdas over generic nodes. * I have encountered many bugs in the Engine more than when I was using GameMaker. * It lacks native mobile monetization.Other than that I'm much more enjoying working with Godot than Unity.replynightowl_games 19 hours ago | prev | next [\u2013]Godots killer feature is the integrated documentation.replysouthwesterly 18 hours ago | parent | next [\u2013]So much yes to this. I like being offline when I work to avoid distractions and this is amazing.replynightowl_games 16 hours ago | root | parent | next [\u2013]The unity documentation drives me nuts.I also compile Godot when I use it so I can read the source and step thru stuff if I ever have a problem.I get paid to use Godot tho, and am a contributor, I'm not the typical user.replygminic 19 hours ago | prev | next [\u2013]\"C#/.NETThe focus in this release was on bringing feature parity between C# and GDScript.When using GDScript, you can define a new node type to use in the editor by adding a global class name to your script.Starting from Godot 4.1, this is also possible in C# by adding the [GlobalClass] attribute to your file, thanks to Raul Santos and Will Nations. You can also use the [Icon] attribute to give your global class a unique icon.Note that as of this release projects made with C# still cannot be exported to mobile and web platforms. We are working on providing the support as soon as possible, but the resolution of this limitation will likely depend on the release of .NET 8 at the end of 2023. This means that the work on enabling mobile and web platforms can only truly start later this year.\"replyhamoid 16 hours ago | prev | next [\u2013]I haven't seen people mentioning using Godot with Kotlin, so I'll leave the link here. At some point it could be nice for Kotlin devs.https://godot-kotl.in/en/stable/replygerardpg 21 hours ago | prev | next [\u2013]Outstanding work, congratulations to the Godot team.replybodge5000 17 hours ago | prev | next [\u2013]Great to see a focus on reliability, I moved back to Godot 3.5 as 4 kept crashing for me so I've been missing out on some of the new features (suprisingly, the one I was most excited about is the improvements to procedural skyboxes, and they certainly lived up to the hype)replyclessg 19 hours ago | prev | next [\u2013]I haven't seen it mentioned yet, so does anybody have experience comparing Phaser with Godot (for 2d games)?replyxwowsersx 18 hours ago | prev | next [\u2013]If anyone here has created something using Godot that is publicly available, would you kindly provide a link to share it here?replygmjosack 18 hours ago | parent | next [\u2013]The 4 games on this page were all made in Godot:https://gareb3ar.itch.io/replyxyzzy3000 19 hours ago | prev | next [\u2013]I like the engine, but the name is essentially one that has no consensus on how it should be pronounced (emphasis on the first syllable, emphasis on the second, or equal emphasis on both).Some background here in the context of the original play from which the name is derived - sorry about the paywall: https://www.nytimes.com/2013/11/12/theater/the-right-way-to-...replyamitmathew 19 hours ago | parent | next [\u2013]It's funny, I met the two co-creators of Godot at GDC this year and they both pronounce it differently. So there may never be a consensus!replyjcmontx 20 hours ago | prev | next [\u2013]First time hearing about this engine. How does it compare to Unity/Unreal? Not a game dev btwreplyLanceH 20 hours ago | parent | next [\u2013]Unreal has everything in 3D game development. On the downside, Unreal has everything in 3D game development. Godot can definitely make 3D games, but if you need Unreal level tooling, there is only one choice. 3D games are definitely possible in Godot.I see the 2D comparison much stronger for Godot. The biggest draws for Unity are if you already know it, you are already excellent with C#, or if you need to deploy to consoles.Godot has everything I've wanted in 2D development (as a serious hobbyist). I can get straight into the source code and modify the engine as needed. I really, really like the composition model of building out nodes, Godot and it leads to excellent code reuse. No licensing issues at all.Asset stores are definitely better for Unreal and Unity.As a hobbyist I'm incredibly happy with Godot. I could definitely see it for 2D PC development. If I had consoles in mind Unity.Anything 3D I would invest my time in Unreal. Godot might be able to handle a current 3D project, but as I move on from that project I would be looking at Unreal with envy.replychii 20 hours ago | parent | prev | next [\u2013]godot is less \"full featured\" than UE. It can compete with unity in terms of features, but i think the ecosystem for unity is much bigger.Godot is much easier to learn and use imho. And being open source means you have access (unlike unity).replybillfruit 17 hours ago | prev | next [\u2013]Is this version having c++ support? Is development using c++ really viable in Godot?Why did they have to invent GDScript? Is there any reason why they could not have chosen a existing language?replysebastianz 16 hours ago | parent | next [\u2013]This is explained in detail in the F.A.Q. here: https://docs.godotengine.org/en/stable/about/faq.html#doc-fa...replykrapp 8 hours ago | prev | next [\u2013]If you're using WorkerThreadPools or HTTPRequests be careful - some change they made to threading broke one of my projects. Nothing else seems to be affected so far.reply29athrowaway 20 hours ago | prev | next [\u2013]There is a Star Fox clone made in Godot, Ex-Zodiac. Cool game.replymanishsharan 20 hours ago | prev | next [\u2013]Could someone advise if this is a suitable platform and language for 10 year olds to learn Game programming ? My kid feels that he has outgrown Scratch and he is looking for a better platform . Will GDscript be easy for him to learn ?replysuda50 19 hours ago | parent | next [\u2013]I haven't used Scratch but I think Godot might be one of the easier engines to get into compared to Unity and Unreal Engine. GDScript (https://gdscript.com/) is a custom language created for Godot and is similar to Python so it will be more complicated than creating games with Scratch since you will be writing out code explicitly rather than dragging blocks together. GDScript is immensely easier to use than C# (Unity) and C++ (Unreal), though.It might be worth looking at GD Quest (https://www.gdquest.com/tutorial/godot/learning-paths/gettin...) to determine if it's something your kid would want to learn and get into. As a developer, I found it very easy to start to get started with Godot versus Unity and Unreal so it might be a fun adventure for your kid to start learning :)replygmjosack 18 hours ago | parent | prev | next [\u2013]I've been doing Godot development with my 9yo and he loves it. If you're looking for something with less emphasis on text based programming Construct and GDevelop are engines I've heard good things about as a continuation from Scratch.replygmjosack 18 hours ago | root | parent | next [\u2013]To add to this I found these tutorials good starting points for a structured lesson with my kids. Would do about 30m-1h a day (mostly up to whenever they get bored). When we started off we'd focus on letting them run the GUI changes and I'd work on the code and explain the concepts to them until they started wanting to do the coding themselves.https://docs.godotengine.org/en/stable/getting_started/first... https://kidscancode.org/godot_recipes/4.x/games/first_2d/ind...After that my son wanted to switch to making his own game so we've been re-implementing boss fights from cuphead and lately he wants to make an idle game.I've also found its fun to just get them to be part of the design process in game jams. It's really great to see the creative ideas that come out of young kids and game making with kids has been super fun and educational.replysylware 21 hours ago | prev | next [\u2013]Until godot devs don't forget the \"-static-libgcc -static-libstdc++\" compile/link options, should be fine, that linking with the oldest set of glibc libs as possible (I saw games carefully using the glibc from debian ubuntu 12.04).I guess godot has proper vulkan->GL fallback.What's now really missing is from sourceware binutils: fine grained control of the versions of the symbols to use while creating binaries. And then, robust game binaries would be much easier to produce: it would let the devs use the latest elf/linux distro and still produce compatible binaries with old elf/linux distros (easy planned obsolescence workaround) avoid the current massive mess (build an old glibc, and reconfigure the toolchain to use it for linking, PAIN).replyelFarto 21 hours ago | parent | next [\u2013]> What's now really missing is from sourceware binutils: fine grained control of the versions of the symbols to use while creating binaries.I did actually prototype an idea for attempting to fix this. The tool would take a list of symbols from a text file and produce a (non-functioning) .so file that ld can link against. The newly created .so file can be injected in via an environment variable (LIBRARY_PATH iirc).Since the list of symbols is just text, it's easily modified to contain only the one's that you want to target.It's not a complicated tool to write, but there are some issues like how to reliably get ld to pick the correct .so file when you're overriding an existing on, LIBRARY_PATH is not 100% reliable. The other issue was if it's nessassary to recreate all the symbol types (like weak, etc..) exactly, I'm not sure exactly what's required for ld.replysylware 20 hours ago | root | parent | next [\u2013]The text file would map simply a symbol to a version, to be overridden in the generated ELF binary (exe or SO).That way, the game devs don't need to build the \"old\" SOs and reconfigure the toolchain to use them, which is unreasonable to ask them (but this is expected from game engine elf/linux devs like unity/unreal/godot/etc) and a MASSIVE PAIN to make work properly (exponentially proportional on the abstraction level of the game/engine build system).While any \"old\" symbol version is not removed...replyubermonkey 19 hours ago | prev | next [\u2013]Man, I've been WAITING for this!(What, nothing? I'll show myself out.)replygardaani 22 hours ago | prev | next [8 more]aero-glide2 19 hours ago | prev | next [\u2013]Sadly GPT hasn't been trained on GODOT 4, so it's been very difficult to develop.replykrapp 17 hours ago | parent | next [\u2013]What if I told you... it's possible to write your own code?replyBaculumMeumEst 21 hours ago | prev [\u2013]i have seen a lot of folks talk about switching to godot due to unity \u201cselling out\u201d. but if godot gets popular enough, money will be waved in the maintainers\u2019 faces, and it will follow the same trajectory.meanwhile, there are alternatives like love2d, which is a more straightforward game engine written in c++ built on popular open source libs like sdl2 with a extended with lua(jit). it\u2019s lightweight enough that you could probably maintain it yourself.replyMacha 21 hours ago | parent | next [\u2013]There are four differences between Godot today and Unity circa 2007 that make this unlikely:1. The Godot trademark is owned by the Software Freedom Conservancy, and not the original authors or their company.2. The founders do have a consulting/support company, W4Games, but it is not Godot Inc, and because of point 1, can never be. Secondly, it is not afforded any special place in the project leadership structure. W4Games employees account for 2 of 9 leadership positions in the Godot project leadership. This is overseen by the SFC who would not permit a company to have too many seats.3. The founder's company also does not have overwhelming control of contributors. Of the top 10 contributors, numbers 1, 2, and 7 are part of W4 Games inc, but all of the top ten have significant contributions.4. It's open source. This is less of a deterrent than the above, since it's MIT licensed so someone could make a closed source fork, but they would have to compete with the community in that case.replythrillgore 8 hours ago | root | parent | next [\u2013]They're working to transition Godot out of the SFC to its own Foundation.replyraincole 20 hours ago | parent | prev | next [\u2013]> but if godot gets popular enough, money will be waved in the maintainers\u2019 faces, and it will follow the same trajectory.Yeah just like when Blender got popular, the developers sold it out and now it's a shitty piece of software.Haha, just kidding. The above never happened and Blender is still getting better every month.replyallan_s 18 hours ago | parent | prev | next [\u2013]with regards to love2d, they are no on the same \"market\" (I have made hobbyist game in both)love2d is really the most minimalist things you can call a game engine, i.e quickly you have to resort to 3rd party library , even for something as simple as 2d collision or the ECS system. If you know perfectly what you are doing it's probably better.Godot is much more battery include so for an experienced programmer it may feel too opinionated.my own experience was that, while I'm a web developer for 10+ years, I'm really new at game development, and love2d was easy at first but soon a pain because I hit a ceiling glass of \"my game has become too complex and I don't know the design pattern of game developement\". At the opposite Godot was a pain at first, especially as a Vim user, i.e why do I have to use this GUI, but once I got used with the tool by following some step by step tutorial, I felt like sky was the limit.replySupermancho 7 hours ago | root | parent | next [\u2013]> love2d is really the most minimalist things you can call a game engineI think DeFold is closer to that.replykrapp 21 hours ago | parent | prev | next [\u2013]Don't get me wrong, I like LuaJIT and SDL2 but Godot is open source. There's no danger of it \"following the same trajectory\" as Unity.replybowsamic 20 hours ago | parent | prev | next [\u2013]Actually the reason that most people don't like Unity is because the goal of the company seems to be to create a million half-baked, fancy-looking ideas rather than creating a solid experience with the core engine. Even today there are still very weird and difficult to circumvent bugs that come up in almost every project, even in trivial ones. Also, the last time I used it all of the old forum threads had been partially corrupted.replyTulliusCicero 19 hours ago | parent | prev [\u2013]> love2dOh god, it uses lua.replyGuidelines | FAQ | Lists | API | Security | Legal | Apply to YC | ContactSearch:",
    "hn_summary": "- Godot 4.1 has been released and includes major bug fixes.\n- Users praise the lightweight, fast, and easy-to-learn nature of Godot 4.0, especially for indie game development.\n- Web exports in Godot 4.1 still have limitations, with issues on certain browsers like Chrome on macOS, but the team is working on resolving them.\n- Some users have experienced slow loading times for web games in Godot 4.0 on macOS Chrome, while others report fast load times.\n- Users recommend GD Quest and Heartbeast tutorials for learning Godot.\n- People mention the suitability of Godot for VR development and cross-platform app development.\n- The popularity of Godot is increasing due to its lightweight design and community support.\n- The GDScript language in Godot is easy to learn and use compared to Unity's C# and Unreal Engine's C++.\n- Users praise the documentation and integrated IDE in Godot.\n- Comparisons are made between Godot and other game engines like Unity and Unreal Engine.\n- Concerns are raised about future monetization and maintainership of Godot, but the open-source nature and ownership structure mitigate these concerns.\n- Love2D is mentioned as an alternative game engine with a simpler design using Lua and SDL2."
  },
  {
    "id": 36624294,
    "timestamp": 1688683457,
    "title": "Air France denied my delay compensation, so I challenged them & won",
    "url": "https://airdisputes.com/air-france-denied-my-delay-compensation-so-i-challenged-them-and-won/",
    "hn_url": "http://news.ycombinator.com/item?id=36624294",
    "content": "Missing a connection can turn a routine trip into a real slog.There\u2019s good news, though. Airlines that operate flights from/within Europe (or from anywhere on an EU carrier) are required by law to get you to your final destination within a specific timeframe. If they don\u2019t, you\u2019re entitled to a good amount of cash thanks to the EU\u2019s passenger protection legislation called EU 261/2004. Outside of the EU; countries like Brazil, Canada, and the UK all have similar laws.Unfortunately, there is nothing stopping an airline from denying a legit claim. They know you wont chase them down in courts, and there\u2019s no automatic oversight.Courtesy of the EU CommissionCourtesy of the EU CommissionPrefaceAirlines are so focused on their bottom line that they will outright lie to passengers, denying totally valid compensation claims. They do this by giving affected passengers incorrect departure/arrival information, or worse, blaming Air Traffic Control, in an attempt to shift focus and avoid payout. (Non-EU-based airlines will straight up ignore EU261/2004 requests!)\u201cIt was an air traffic control delay\u201d is a convincing excuse, but generally not a valid one. Under the law, burden of proof is on the airline.Air France played dirty with me recently\u2014and now you get to read about it! Let this article serve as a tutorial on how to handle an airline dispute on your own. Take note of which proof to keep, which laws mean what, and how to word the emails.The IncidentOriginal schedule (booking e-mail)The first leg of my itinerary was flight AF1225, a quick shot from LIS to CDG on Air France.Everything started normally, with a smooth check-in around 08:00 and a departure time of 09:40 posted on the departures screens. As long as everything went to schedule, I would arrive in Miami at 18:05 (EST).My itinerary allowed for just an hour to disembark the first segment, go through immigration in Paris, then board the international segment. This connection was going to be tight\u2014doable, but tight.Unfortunately, I wouldn\u2019t even make it that far before things went south.Right off the bat, the arrival plane (F-GTAY) from Paris (AF1224) was delayed into Lisbon by about ten minutes, arriving at the gate at 09:00. This gave Air France just 40 minutes to disembark all the passengers, clean, and off/load all the hold luggage.Incoming aircraft F-GTAY (AF1224) on June 1st (FlightAware)The gate agents made an announcement of a short delay due to a \u201clate incoming aircraft,\u201d and put a new departure time up of 09:56. Once the plane was ready, we were quickly boarded and things seemed to be back on track.Then we waited.And waited.At one point, I checked FlightAware, which said the plane had already taken off. We hadn\u2019t even left the gate.(FlightAware)Real-time information from June 1st around 10:15amBy the time the flight left the gate at 10:48, it was clear there was going to be no time to make the connection. This was confirmed by a flight attendant, who told me during the flight to proceed directly to the customer service booth once we arrived at CDG.The flight landed at 13:55, and it wasn\u2019t until about 14:20 that all passengers (including myself) were fully unloaded. It took about ten more minutes to get myself to the customer service booth.(PlaneFlightTracker)(estimated arrival vs actual arrival)Customer ServiceThe AF customer service agents at Charles de Gaulle were helpful enough. I was re-booked on AF686 to Atlanta, and then on DL1399 to Miami. My new ETA: 00:53(+1 day)\u2014roughly 6 hours after my original scheduled landing time, triggering Article 6(1)(c) and Article 7(1)(c) of EU 261/2004.While at the Air France, help desk I asked about my right to compensation, but they would not provide any information. This could be considered a violation of Article 251 (20) of the original treaty:(20) Passengers should be fully informed of their rights in the event of denied boarding and of cancellation or long delay of flights, so that they can effectively exercise their rights.https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=CELEX%3A32004R0261\u201cI don\u2019t know anything about that law,\u201d I was told. \u201cYou\u2019ll have to call.\u201d Instead, I was handed an \u20ac11 voucher for food (which buys nothing at CDG, by the way).The ClaimWithin the next 30 minutes, I had filed a claim through Air France\u2019s online portal. This is a really simple online form that just requires photos of your boarding pass, flight details, bank information, and a short explanation. The entire process from submission to decision should take roughly a week.For the record, the rest of my flights were also delayed, getting me into Miami at 02:15 (+1 day) and making the total delay about eight hours.Within ten days I got a response from Air France: denied.First Denial (for a flight from Israel?)Blaming ATC and weather are common \u201cget-out-of-jail-free cards\u201d airlines use\u2014mostly because it\u2019s initially hard to prove wrong. Most people don\u2019t think an airline would lie to them. I responded to the denial asking for clarification before I escalated.Second DenialEscalationRule of thumb: never trust a company that owes you money to fairly investigate themselves. Once I realized Air France was sticking to the script, I informed them that I will be escalating to the Portuguese Civil Aviation Authority (also known as ANAC).In Europe, each country has a Civil Aviation Authority that is responsible for enforcing EU 261/2004. To escalate a claim, fill out a complaint form and send all the requested documents to the Civil Aviation Authority in the departure country \u2014 in my case Portugal. You may have to write the email in the local language, however many, like ANAC, have an English contact. It can take up to 30 days to receive a response.ConclusionLucky for me, it took just five days for ANAC to come back with a response: OVERRULED!Just to be clear: ANAC requested clarification from Air France, and instead of blaming weather or ATC, AF simply rolled over without challenge. Why? Because the burden of proof falls on the airline and they were presumably lying to me.Instead of reopening my original claim, Air France opened a brand new claim. I was ultimately paid out $658.AftermathAs you can see, Airlines have no trouble hiding the truth from customers. The way to handle it is with confidence and persistance. If you are having trouble with an airline losing your luggage, or making your routine flight a nightmare of rerouting, feel free to reach out to us!Contact Us",
    "summary": "- Airlines operating in Europe are required by law to get passengers to their final destination within a specific timeframe, and passengers are entitled to compensation if this is not met.\n- Air France denied the author's claim for compensation after a delayed flight, but the author challenged this and won their case with the help of the Portuguese Civil Aviation Authority.\n- This post serves as a tutorial on how to handle an airline dispute and provides valuable information on passenger rights and how to navigate the claims process.",
    "hn_title": "Air France denied my delay compensation, so I challenged them and won",
    "original_title": "Air France denied my delay compensation, so I challenged them and won",
    "score": 481,
    "hn_content": "- A passenger challenged Air France for denying their delay compensation and ultimately won\n- Air France initially refused to accept attachments in the claim form and later claimed that the passenger did not include receipts, offering only partial compensation\n- The passenger had to persistently follow up, call customer service, and email receipts to finally receive full payment\n- Other users in the forum share similar experiences with airlines denying compensation claims and the difficulty in navigating the process\n- Some users suggest using third-party services or submitting complaints to regulatory bodies to help resolve disputes\n- This post highlights the challenges passengers face when trying to claim compensation from airlines and the importance of persistence in pursuing their rights.- Airlines with government backing may not have the same incentive to provide good customer service as those in competitive markets.\n- Privatized airlines like JAL, Air Canada, and Air France-KLM have faced criticism for their customer service.\n- European airlines have more competition, leading to a race to the bottom in customer service.\n- European Commission regulations and competitor challenges can limit subsidies and hold airlines accountable.\n- European passengers have more rights and compensation options for flight delays and cancellations compared to passengers in the U.S. \n- Passengers can file complaints with regulatory bodies like ANAC to seek compensation.\n- Airline delays and cancellations can lead to financial losses for passengers, such as costs for hotels, missed events, and lost vacation days.\n- Credit cards with travel insurance coverage, like American Express, can provide additional protection for travelers.\n- It can be time-consuming and challenging for passengers to navigate the process of seeking compensation from airlines.\n- Passengers may need to resort to legal means, such as small claims courts, to enforce their rights and seek compensation.",
    "hn_summary": "- A passenger challenged Air France for denying their delay compensation and ultimately won, highlighting the challenges passengers face when trying to claim compensation from airlines and the importance of persistence in pursuing their rights.\n- Other users in the forum shared similar experiences with airlines denying compensation claims and the difficulty in navigating the process, suggesting the use of third-party services or submitting complaints to regulatory bodies to help resolve disputes.\n- European passengers have more rights and compensation options for flight delays and cancellations compared to passengers in the U.S., and may need to resort to legal means, such as small claims courts, to enforce their rights and seek compensation."
  },
  {
    "id": 36616037,
    "timestamp": 1688652545,
    "title": "France passes bill to allow police remotely activate phone camera, microphone",
    "url": "https://gazettengr.com/france-passes-bill-to-allow-police-remotely-activate-phone-camera-microphone-spy-on-people/",
    "hn_url": "http://news.ycombinator.com/item?id=36616037",
    "content": "Manage Cookie ConsentWe use cookies to enhance our website and our service.AcceptDenyPreferencesFriday, July 7, 2023Menu#ENDSARSPOLITICSANTI-CORRUPTIONRIGHTSECONOMYEDUCATIONHEALTHSPORTNATIONWIDEOPINIONFrance passes bill to allow police remotely activate phone camera, microphone, spy on peopleA bill that would allow police in France to spy on suspects by remotely activating cameras, microphone including GPS of their phones has been passed.TOSIN AJUWON \u2022 JULY 6, 2023French police and people using phoneA bill that would allow police in France to spy on suspects by remotely activating cameras, microphone including GPS of their phones has been passed. The bill allows the geolocation of crime suspects, covering other devices like laptops, cars and connected devices, just as it could be remotely activated to record sound and images of people suspected of terror offences, as well as delinquency and organised crime.Although, the spying provision, which is part of a wider \u201cjustice reform bill\u201d, has been attacked by the left and rights defenders as an authoritarian snoopers\u2019 charter. The provisions \u201craise serious concerns over infringements of fundamental liberties,\u201d stated a French advocacy group promoting digital rights and freedoms, La Quadrature du Net.The group cited the \u201cright to security, right to a private life and to private correspondence\u201d and \u201cthe right to come and go freely,\u201d specifically called the proposal a part of a \u201cslide into heavy-handed security.\u201dBut lawmakers agreed to the bill late Wednesday as Justice Minister Eric Dupond-Moretti insisted the bill would affect only \u201cdozens of cases a year.\u201dDuring the debate on Wednesday, the members of parliament in the camp of President Emmanuel Macron inserted an amendment limiting the use of remote spying to \u201cwhen justified by the nature and seriousness of the crime\u201d and \u201cfor a strictly proportional duration.\u201d They noted that a judge must approve any use of the provision, while the total duration of the surveillance cannot exceed six months.They said sensitive professions, including doctors, journalists, lawyers, judges and MPs, would not be legitimate targets.Last month, the Senate gave the green light to the provision of the justice bill, which would allow law enforcement to secretly activate cameras and microphones on a suspect\u2019s devices. Since 2015, when terrorist attacks rocked France, the country has increased its surveillance powers, and the \u201cKeeper of the Seal\u201d bill has been likened to the infamous US Patriot Act. We have recently deactivated our website's comment provider in favour of other channels of distribution and commentary. We encourage you to join the conversation on our stories via our Facebook, Twitter and other social media pages.More from Peoples GazettePOLITICSKatsina youths pledge to deliver over 2 million votes to Atiku\u201cKatsina State is Atiku\u2019s political base because it is his second home.\u201dNEWS AGENCY OF NIGERIAANTI-CORRUPTIONEFCC says illegal mining threat to Nigeria\u2019s economyThe Economic and Financial Crimes Commission has identified illegal mining and other criminal activities as major threats to Nigeria\u2019s economy.NEWS AGENCY OF NIGERIANATIONWIDEAfter meeting Tinubu, Asari Dokubo to collect one million signatures for FG to begin secession of Igbos from NigeriaAlthough Article 2 of the constitution is against secession, Mr Dokubo argued that it would serve as a cleansing action of the entire country.KUNLE SANNIWORLDGermany, Morocco to strengthen cooperation for conflict resolution\u201cFor us, unilateral steps or provocative steps by the Israeli authorities are not constructive.\u201dNEWS AGENCY OF NIGERIASPORTWorld Cup: Nigerian ambassador tells Super Falcons to make Africa proudThe Super Falcons were urged to go beyond the quarter-finals.NEWS AGENCY OF NIGERIAWORLDThreads: Twitter accuses Meta of stealing trade secrets; threatens lawsuitTwitter owner Elon Musk while reacting to the launch of Threads, said, \u201cCompetition is fine, cheating is not.\u201dADEBOLA AJAYISTATESStudents warned against writing damaging write-ups about Godfrey Okoye University\u201cYou should resist negative communications during the holidays and damaging write ups about one another and the University.\u201dNEWS AGENCY OF NIGERIAxGet every story as it breaksName*Email*     In an era of fake news and overcrowded media marketplace, the journalists at Peoples Gazette aim to provide quality and practical information to help our readers stay ahead and better understand events around them. We focus on being the balanced source of true, stimulating and independent journalism.The Peoples Gazette Ltd, Plot 1095, Umar Shuaibu Avenue, Utako, Abuja.+234 805 888 8330.QUICK LINKSComment PolicyEditorial Code of ConductShare Your TipsAdvert RatesFOLLOW\u00a9 2023 Peoples Gazette\u2122 Limited.\u2715You have blocked Push Notifications. Follow these instructions to enable Push Notifications.\u26a1 by Webpushr",
    "summary": "- A bill has been passed in France that allows the police to remotely activate the cameras, microphones, and GPS of suspects' phones in order to spy on them.\n- The bill also covers other devices like laptops, cars, and connected devices, and can be used to record sound and images of individuals suspected of terror offenses, delinquency, and organized crime.\n- The bill has raised concerns over infringements of fundamental liberties, but lawmakers argue that it will only be used in a limited number of cases, with approval from a judge and strict duration limits.",
    "hn_title": "France passes bill to allow police remotely activate phone camera, microphone",
    "original_title": "France passes bill to allow police remotely activate phone camera, microphone",
    "score": 466,
    "hn_content": "- France has passed a bill that allows police to remotely activate the camera and microphone on a person's phone.\n- The bill covers other devices like laptops, cars, and connected devices as well.\n- There is speculation about whether this capability is already being used or whether it will be mandated in the future.\n- The specific technology or methods used to activate the camera and microphone are not mentioned in the post.\n- It is suggested that this capability could be achieved through malware or via cooperation with device manufacturers.\n- The bill states that the geolocation of crime suspects can also be tracked, extending beyond just phones.\n- The legislation only mentions \"dozens of cases a year\" that would be affected by this capability.\n- The use of this technology raises concerns about privacy and the potential for abuse.\n- The post highlights the importance of strong encryption and security measures to protect against unauthorized access to personal devices.\n- The bill states that certain professions, such as doctors, journalists, lawyers, judges, and MPs, would not be targeted.\n- There is a discussion about the lack of sensitivity attributed to software engineering as a profession in the legislation.- It is expensive to compromise a phone, with the cost ranging from 2-2.5+ million USD, depending on the capabilities and platform.\n- The technology used to compromise a phone is sensitive and can become useless if it gets patched or burnt.\n- The cost of compromising a phone on a per-person basis may not be considered significant when compared to police budgets in major cities.\n- The democratic process may not accurately represent the will of the entire population, as decisions are often made by elected officials.\n- The European Union's push for user-replaceable batteries does not guarantee the mandate for physical toggles and shutters for mic and camera.\n- There is a debate about the potential negative effects of the European Union's actions, such as dismantling end-to-end encryption and full access to texts.\n- The French president's call to block social media sites during riots raises concerns about freedom of speech and government control.\n- The new law in France regarding the compromise of phones does not significantly change the way the state spies on its citizens.\n- There may not be a debate about the balance between individual freedom and national/public security.\n- The historical reference to the French Revolution highlights the contrast between then and now in terms of government control.\n- Continental Western Europe is seen as becoming more authoritarian and corrupt, although this may not be unique to the region.\n- Opinions on civil rights and police violence may differ among liberal intellectuals like Bernard-Henri L\u00e9vy.\n- The balance between order and liberty is a complex and delicate one that can easily be lost.\n- From an opsec standpoint, leaving a phone in airplane mode and turning off location services may not effectively block access.\n- Physical covers for the camera and custom operating systems like LineageOS may help protect privacy, but some vulnerabilities may still exist at the hardware level.\n- The lower-level firmware and software in phones may still have vulnerabilities that can be exploited.\n- The desoldering of microphones or the addition of physical switches may be potential solutions for preventing unauthorized access to audio recording.\n\nThe main takeaway from this post is the discussion surrounding the compromise of phones, the potential invasion of privacy, and the balance between individual freedom and national/public security. It also highlights the concerns about government surveillance and the need for individuals to take steps to protect their privacy.",
    "hn_summary": "- France has passed a bill allowing police to remotely activate cameras and microphones on phones and other devices, raising concerns about privacy and potential abuse.\n- The technology or methods used to activate these features are not specified, but could involve malware or cooperation with device manufacturers.\n- The legislation mentions tracking the geolocation of crime suspects, extends beyond just phones, and exempts certain professions from being targeted."
  },
  {
    "id": 36610595,
    "timestamp": 1688612996,
    "title": "Cloud Backed SQLite",
    "url": "https://sqlite.org/cloudsqlite/doc/trunk/www/index.wiki",
    "hn_url": "http://news.ycombinator.com/item?id=36610595",
    "content": "Cloud Backed SQLiteCloud Backed SQLiteLogin\u2630Timeline Forum FilesPage ContentsOverviewStorage FormatSystem ComponentsBuilding, Deployment and TestingUsageUploading DatabasesAccessing DatabasesSecure ContainersCloud Storage ModulesThe Built-in \"azure\" ModuleThe Built-in \"google\" ModuleDetails and CaveatsConcurrent Access From Multiple ClientsDeleting Unused Block FilesBlock SharingPragma InterfaceVirtual Table InterfaceCommand Line ReferenceDaemon Command Reference1. OverviewThe \"Cloud Backed SQLite\" (CBS) system allows databases to be stored within cloud storage accounts such that they can be read and written by storage clients without first downloading the entire database to the client. This document should be read in concert with the detailed API documentation present in the two main public header files:blockcachevfs.hbcvutil.hDatabases may be accessed concurrently by multiple clients, although ensuring that only a single client is writing to a database at any time is (mostly) left to the application. A \"client\" is a single operating system process system - within a single client process there may be multiple SQLite handles reading and writing a database using the usual SQLite WAL-mode read/write locking to manage concurrent access between themselves. Existing clients do not see changes made by writers automatically, they are obliged to explicitly poll cloud storage to do so.The system currently supports Azure Blob Storage and Google Cloud Storage. It also features an API that may be used to implement support to other cloud storage systems.The software is currently developed on Linux with stock gcc, and on Windows-10 using the MSVC-compatible mingw64 gcc compiler. Other platforms are quite likely to work too, but have not been tested.1.1. Storage FormatSQLite databases are not stored within the blob storage system in the usual format. Instead, each database is divided into one or more fixed-size blocks. The default block-size is 4MB, although this is configurable. Each block is assigned an id between 16 and 32 bytes (128 and 256 bits) in size (all blocks in a single container have the same sized ids). The name of each block file is created by encoding its id in hexadecimal format and adding the extension \".bcv\". For example: 787A5B026DBF882F89748C37AED04CCD.bcvFor containers that use ids smaller than 24 bytes in size, each block id is randomly generated. For manifests that use ids 24 bytes or larger, the first 16 bytes of each id may contain the md5 hash of the block contents, with the remainder of the id made up by pseudo-random values. See the section on block sharing below for further details.Along with the block files is a \"manifest\" file, which contains, amongst other things, a machine-readable description of how the various block files may be assembled into into one or more SQLite databases. The name of the manifest file is always: manifest.bcvThere is also an SQLite database used to store the contents of the \"bcv_kv\" virtual table MAKE THIS LINK SOMEWHERE! named: bcv_kv.bcvAt present, manifest and block files may only be stored in the root directory of a blob storage container, not in any sub-directory. This means that each container contains at most a single manifest file. It may be that this limitation can be removed if desirable. Other files may be stored in a container along with the CBS files, but they must not use the \".bcv\" extension. Files that end with \".bcv\" may be mistaken for surplus block or other files and deleted or overwritten by CBS clients.Note: CBS documentation uses the Azure terminology \"container\" to refer to the cloud storage virtual receptacle in which block files and manifests are stored. In Google Storage documentation the analagous concept is a \"bucket\". Other cloud storage systems may use their own vernacular.1.2. System ComponentsThere are three components to the system:Primitives to:Create blob storage containers and populate them with empty manifest files (manifest files indicating that the container contains no databases).Destroy entire blob storage containers and their contents.Upload databases to cloud storage.Download databases from cloud storage.Create copies of existing databases within cloud storage.Delete databases from cloud storage.List the databases within a cloud storage container.Clean up (remove) unused blocks from cloud storage.Each primitive is available both as an C API that can be called by applications, and as a command-line tool.A daemon process that, while running, provides local SQLite database clients in the same or different OS process with read-only access to databases stored in remote blob storage containers.A VFS module that may be used in two modes, as follows:For read-only access of cloud databases via a running daemon process, orFor read/write access of cloud databases in \"daemonless\" mode.The advantage of using a daemon over daemonless mode is that a single local cache of downloaded database blocks may be shared by multiple processes. In daemonless mode, each process is obliged to maintain its own separate cache.Both the daemon and command line tools are packaged as a single binary executable - \"blockcachevfsd\".2. Building, Deployment and Testingcommand from the root directory of the source tree.Adding Application SupportTo add support for the VFS and various primitives, the following C files from the source code distribution must be built into the application:  bcvutil.c  bcvmodule.c  blockcachevfs.c  simplexml.c  bcvencrypt.cThe following header files from the source code distribution are required:  bcvutil.h  bcvmodule.h  blockcachevfs.h  simplexml.h  bcv_int.h  bcvencrypt.hAs well as SQLite, the application must be linked against libcurl and openssl.The application should not include either \"bcv_int.h\" or \"simplexml.h\" directly. They are required by the build, but are not intended to be used directly. The other three header files are intended to be used by applications, they container declarations for APIs that provide the following functionality:Header file blockcachevfs.h contains APIs required to use the VFS module to access cloud databases via usual SQLite interfaces.Header file bcvutil.h contains APIs required to use the various cloud storage primitives.Header file bcvmodule.h contains APIs required to extend blockcachevfs to access new cloud storage systems (other than Azure Blob Storage and Google Cloud Storage, for which there is built-in support).Building blockcachevfsd:The easiest way to build the \"blockcachevfsd\" executable that contains both the daemon and the command line tools is using the standard: ./configure && makeAlternatively, it may be built from all sources listed above as required for adding blockcachevfs support for an application, along with file \"blockcachevfsd.c\", which contains the main routine.Testing the system:The blockcachevfs system has an automated test suite. Notes describing its use may be found here.3. Usage3.1. Uploading DatabasesThis section illustrates how to upload databases to a blob storage account and begin using them. It assumes that cloud storage module name and authentication details, for example an account name and access key are stored in a file named \"account.txt\" in the current directory. Example account.txt contents for Azure Blob Storage: -module azure -user devstoreaccount1 -auth Eby8vdM02xNOcqFlqUwJPLlmEtlCDXJ1OUzFT50uSRZ6IFsuFq2UVErCz4I6tq/K1SZFPTOtr/KBHBeksoGMGw==The command-line options above can just as easily be specified directly on the command-line. But storing them in a file, and then using the \"-f <file>\" option supported by all commands to treat the contents of the named file as if they were specified directly on the command-line can be less cumbersome.To begin, create a container and an empty manifest to which databases may be uploaded, where $CONTAINER is the container name: $ blockcachevfsd create -f account.txt $CONTAINERIf the named blob storage container already exists, CBS will clobber any manifest file within it with a new, empty, manifest file, effectively deleting any databases in the container.Next, upload one or more databases from the local file system to the blob storage account. In the following, $LOCALDB is an absolute or relative path to an SQLite database file and $DBNAME is the name used to access the database after it has been uploaded. It is an error if there is already a database named $DBNAME in the manifest: $ blockcachevfsd upload -f account.txt -container $CONTAINER $LOCALDB $DBNAME3.2. Accessing DatabasesThis section explains, by way of example code, how to access a blockcachevfs datbase stored in cloud storage using an SQL client. The full program is available here. It should be read together with the API documentation in file blockcachevfs.hThe example code implement a program that accepts four arguments on the command line:A path to an existing directory to use for a blockcachevfs cache directory,The name of a container to attach to the new blockcachevfs VFS the program creates,A path to a database to open using the blockcachevfs VFS, andAn SQL script to evaluate against that database.The program creates a VFS, attaches the container, opens a database handle and then executes the supplied SQL script. The code as presented below omits several uninteresting features for brevity - there is no main() routine for example. But the full version, linked above, contains everything required for a working application.The following block contains the required #include directives and the authentication callback for the example application. All applications require an authentication callback, as there is no other way to provide authentication tokens to system. And there are currently no implementations of cloud storage modules that do not require authentication tokens./*** The code in this file creates and uses a VFS, but it doesn't use any ** cloud storage primitives or implement a new cloud storage module, so ** it only needs to include \"blockcachevfs.h\". And \"sqlite3.h\" of course.*/#include \"blockcachevfs.h\"#include \"sqlite3.h\"/*** This program is hardcoded to access an Azure emulator running on port** 10000 (the default for Azurite) of the localhost. It is also hardcoded** to the demo account - the account built-in to the emulator with the** well-known credentials reproduced below. */ #define CS_STORAGE \"azure?emulator=127.0.0.1:10000\"#define CS_ACCOUNT \"devstoreaccount1\"#define CS_KEY \"Eby8vdM02xNOcqFlqUwJPLlmEtlCDXJ1OUzFT50uSRZ6IFsuFq2UVErCz4I6tq/K1SZFPTOtr/KBHBeksoGMGw==\"/*** Authentication callback. A real application would return a different ** authentication token based on the storage system, account name and ** container name parameters, but since the credentials used by this** application are hard coded, it just returns a copy of constant string** CS_KEY.**** Because the API is defined such that this function must return a buffer** allocated using sqlite3_malloc() or compatible, this implementation** uses sqlite3_mprintf() to make a copy of the authentication token.*/static int csAuthCb( void *pCtx, const char *zStorage, const char *zAccount, const char *zContainer, char **pzAuthToken){ *pzAuthToken = sqlite3_mprintf(\"%s\", CS_KEY); return (*pzAuthToken) ? SQLITE_OK : SQLITE_NOMEM;}The next block contains the start of the cloudsql() function, which does the bulk of the work for this application. It begins by creating the VFS object. Note that, like almost all other blockcachevfs APIs, if an error occurs the sqlite3_bcvfs_create() function returns an error message in a buffer that must be freed by the caller using sqlite3_free().Once the VFS has been created successfully, the application can use the sqlite3_bcvfs_isdaemon() API to see if the VFS has connected to a daemon or is running in daemonless mode.If, when sqlite3_bcvfs_create() is called, there is a daemon process using the specified directory as its cache directory, then the VFS created by the sqlite3_bcvfs_create() call automatically connects to the daemon and provides read-only access. The daemon can be started using the following command line:  blockcachevfsd daemon $DIRECTORYwhere $DIRECTORY above must be the same string as passed to cloudsql() function below via the zDir parameter. If a daemon process was using the directory for its cache directory, but has since exited, the sqlite3_bcvfs_create() call will fail.If there has never been a daemon running in the directory, then the call to sqlite3_bcvfs_create() creates a VFS running in daemonless mode. In this mode it requires exclusive access to the directory. If there is some other daemonless VFS already running in the specified directory, the call to sqlite3_bcvfs_create() fails with SQLITE_BUSY./*** Open a VFS that uses directory zDir as its cache directory. Then attach** container zCont. Next, open an SQLite handle on path zPath using the new ** VFS and execute SQL script zSql.*/static int cloudsql( const char *zDir,        /* Directory to use for blockcachevfs cache */ const char *zCont,       /* Container to attach */ const char *zPath,       /* Path to open */ const char *zSql        /* SQL to execute */){ int rc = SQLITE_OK;       /* Error code */ char *zErr = 0;         /* Error message */ sqlite3_bcvfs *pVfs = 0;    /* VFS handle */ sqlite3 *db = 0;        /* Database handle open on zPath */ /* Create a VFS object. Directory zDir must already exist. If it exists ** and there is a daemon running in that directory, the new VFS connects ** to the daemon for read-only access. Or, if there is no such daemon, ** the new VFS will provide read-write daemonless access. */ rc = sqlite3_bcvfs_create(zDir, \"myvfs\", &pVfs, &zErr); /* Check if this is a daemon VFS or not */ if( rc==SQLITE_OK ){  if( sqlite3_bcvfs_isdaemon(pVfs) ){   printf(\"VFS is using a daemon\\n\");  }else{   printf(\"VFS is in daemonless mode\\n\");  } }Following this, assuming it was create successfully, the code connects the authorization callback to the new VFS. And then \"attaches\" the cloud storage container specified by the user to the VFS.Before the databases in a cloud storage container can be accessed, it must be attached to the VFS. Once it has been attached, SQL clients may access the databases within the container by opening paths of the form \"/$CONTAINER/$DATABASE\" using the blockcachevfs VFS. /* Configure the authorization callback. */ if( rc==SQLITE_OK ){  sqlite3_bcvfs_auth_callback(pVfs, 0, csAuthCb); } /* Attach the container. Specify the SQLITE_BCV_ATTACH_IFNOT flag so that ** it is not an error if the container is already attached.  ** ** There are two reasons the container might already be attached, even ** though the VFS was only just created. Firstly, if this VFS is connected ** to a running daemon process, then some other client may have already ** attached the container to the daemon. Secondly, VFS objects store their ** state in the cache directory so that if they are restarted, all ** containers are automatically reattached. So if this (or some other ** blockcachevfs application) has run before specifying the same  ** cache directory, the container may already be attached. */ if( rc==SQLITE_OK ){  rc = sqlite3_bcvfs_attach(pVfs, CS_STORAGE, CS_ACCOUNT, zCont, 0,    SQLITE_BCV_ATTACH_IFNOT, &zErr  ); }Once the container is attached to the VFS, the database handle is opened and the SQL script executed. Before the script is executed though, sqlite3_bcvfs_register_vtab() is called to make the virtual tables available to the database handle.For the sake of brevity, the code below omits the sqlite3_exec() callback that is part of the full version. /* Open a database handle on a cloud database. */ if( rc==SQLITE_OK ){  rc = sqlite3_open_v2(zPath, &db, SQLITE_OPEN_READWRITE, \"myvfs\");  if( rc!=SQLITE_OK ){   zErr = sqlite3_mprintf(\"%s\", sqlite3_errmsg(db));  } } /* Enable the virtual table interface. */ if( rc==SQLITE_OK ){  rc = sqlite3_bcvfs_register_vtab(db); } /* Execute the provided SQL script. */ if( rc==SQLITE_OK ){  sqlite3_exec(db, zSql, 0, 0, &zErr); }Finally, the cloudsql() function cleans up the two handles it allocated, outputs any error message and returns. sqlite3_close(db); sqlite3_bcvfs_destroy(pVfs); /* Output any error, free any error message and return. */ if( rc!=SQLITE_OK ){  fprintf(stderr, \"Error: (%d) %s\\n\", rc, zErr); } sqlite3_free(zErr); return rc;}3.3. Secure ContainersWhen running in daemon mode, containers may be attached either securely or insecurly. By default, containers are attached to a daemon insecurely. This means that:Any local process that can connect to the daemon's listening socket may read and write the database, and thatEven after the daemon process has stopped, any cached parts of databases in attached containers may be read directly from the cache file.When containers are attached securely, all data stored in the cache file is encrypted using 128-bit AES OFB encryption. Local clients obtain the encryption key from the daemon process by supplying valid cloud storage credentials - a client is granted the encryption key only if it can prove that it already has permission to access the database within cloud storage. Cloud storage credentials are verified only once, when the client first connects, so it is quite possible for a client to remain connected to a daemon process and accessing a database long after its supplied credentials have expired.A container is nominated as secure when it is first attached to a daemon, by specifying the SQLITE_BCV_ATTACH_SECURE flag along with the sqlite3_bcvfs_attach() call.There are two known disadvantages to attaching containers securely:Blocks are stored unencrypted in cloud storage. This means that as well as local clients encrypting and decrypting individual database pages as they are read, each time a block is downloaded the entire block must be encrypted before it can be stored in the cache file. Under some cirumstances this overhead may be significant.If the daemon process crashes or is killed after data is written to a secure container database but before said data has been uploaded to cloud storage, the data is lost.4. Cloud Storage Modules and AuthenticationAll CBS APIs and command-line tools accept a \"module\" specification, which determines the cloud storage system that the system operates on and how it operates. There are two built-in modules, \"azure\", which works with Azure Storage, and \"google\", which works with Google Cloud Storage. There is also an API that may be used to add new cloud storage modules.A module specification consists of the module name optionally followed by one or more URI style key/value parameters. For example: azure azure?sas=1 azure?emulator=127.0.0.1:10000&sas=1There is no default module. It must always be specified explicitly.As well as a module specification, CBS APIs and command-line tools require a user-name and an authentication value - a string containing cloud storage authentication information. Exactly how these are interpreted depends on the module specification. The values expected by the two built-in modules, and how they are used, are described in the following two sections.4.1 The Built-In \"azure\" ModuleThe \"azure\" module is used to interface with Azure Storage. The value provided as a user-name is used as the Azure user name when connecting. The authentication value may either be the corresponding account access-key (shared-key access), or an Azure Shared Access Signature token, depending on the URI style parameters provided along with the module name.One way to generate an SAS token for Azure is to use the \"az\" command line tool. For example, given account $ACCOUNT with access-key $ACCESSKEY, to generate an SAS token that allows read/write access to container $CONTAINER and expires on the 15th of April, 2020: az storage container generate-sas -o tsv    --account-name $ACCOUNT    --account-key $ACCESSKEY    --expiry 2020-04-15    --name $CONTAINER    --permissions dlrwThe daemon process and some command-line commands may also use read-only SAS tokens. To generate a read-only token, the --permissions option in the command above should be passed \"lr\" instead of \"dlrw\".The following URI style parameters may be used to modify the behaviour of the azure module:Option Interpretationemulator If this option is present, it indicates that CBS should connect to an Azure emulator instead of to a real Azure cloud storage account. Both the open source azurite and the legacy emulator are supported. The value of this option should be set to the \"host:portnumber\" address of the port on which the emulated Azure blob service is running. If using either supported emulator on the local machine with default options, this address is \"127.0.0.1:10000\".sas This option must be set to either \"0\" (the default) or \"1\". If it is set to 1, then the module expects the provided authentication value to be an SAS token. Otherwise, it assumes it to be an access-key.customuri This option may only be present if \"sas=1\" is also specified. Similarly, it may only be set to \"0\" (the default), or \"1\". If it is set to 1, then a base URI for the container must be specified in place of the account name parameter. If the specified container name is NULL or a zero-length string, then the base URI is used as is as the URI for the remote container. Otherwise, the specified container name is appended as a directory component to the base URI. For example, if the string value passed as the account name for an \"customuri=1\" module is:https://photos.contoso.comand the container name \"myforms\", then the URI used to access the container manifest is:https://photos.contoso.com/myforms/manifest.bcvAlternatively, the same container can be accessed by specifying a NULL container name and:https://photos.contoso.com/myformsas the custom URI value.For example, to connect to a real Azure account using an SAS token for authentication purposes: azure?sas=1To connect to an Azure blob emulator running on localhost port 10000 (the default) using an access-key for authentication, either of the following may be used: azure?emulator=127.0.0.1:10000 azure?emulator=127.0.0.1:10000&sas=0Or, to connect to a real Azure account using an access-key for authentication: azuremay be used.4.2 The Built-In \"google\" ModuleThe \"google\" module is used to connect CBS to Google Cloud Storage. The user-name parameter should be passed the project-id for the project that owns the storage bucket or buckets to be operated on. In practice, this is only required for CBS's \"create\" primitive, and only then if it needs to create a new cloud storage container (bucket). In all other cases, an empty string may be specified for the CBS user-name parameter.The authorization value parameter must be passed the text of a Google Cloud access token.The google module does not accept any URI style parameters.5. Details and Caveats5.1. Concurrent Access From Multiple ClientsThe system supports any number of concurrent readers using either daemonless or daemon mode. Even though no locks are taken, read transactions are not usually interfered with, even if a new version of the database is pushed by another host while they are ongoing. This is because block files are never modified after they are created; new block files are uploaded for each change. And old block files are not deleted immediately (see below), so ongoing read transactions can usually continue to access them for as long as required.If a database is modified within the cloud storage system, the modifications do not become automatically visible to existing clients. Until the container is \"polled\", clients continue to see the old versions of all databases. A container may be polled either by calling the sqlite3_bcvfs_poll() API:  int sqlite3_bcvfs_poll(sqlite3_bcvfs *pFs, const char *zCont, char **pzErr);or the equivalent PRAGMA interface. To be clear, any changes made are immediately visible to other SQL clients using the same read-write daemonless VFS object, but are not visible to SQL clients using other VFS objects until the container has been polled.Similarly, after changes are made to a cloud storage database via a read-write daemonless VFS object, the new version of the database is not automatically uploaded to cloud storage. In order to upload changes to cloud storage so that they are available to new clients or existing clients after they have polled the container, use the sqlite3_bcvfs_upload() API:  int sqlite3_bcvfs_upload(   sqlite3_bcvfs *pFs,       /* VFS handle */   const char *zCont,       /* Container (alias) to upload databases of */   int (*xBusy)(void*,int),    /* Busy-handler callback */   void *pBusyArg,         /* First argument passed to xBusy */   char **pzErr          /* OUT: Error message */  );or the equivalent PRAGMA interface.At present, it is not possible to upload changes to a database if there have been changes made to *any* database in the container since the most recent poll operation. This is not usually a problem, the container can be polled and then the upload reattempted.However, the poll operation will fail if there have been changes to one or more databases in cloud storage for which there are also local changes yet to be uploaded, or if there are local changes to a database that has been deleted from cloud storage. It is the responsibility of the user to avoid this situation - concurrent modifications being made to the same database at multiple sites - perhaps by using the bcv_kv virtual table.5.2. Deleting Old BlocksOnce they have been uploaded, blocks are never modified within cloud storage. Instead, when a database is modified, new block files are uploaded for the modified regions and the manifest updated to refer to the new list of blocks. This makes managing reader/writer concurrency easier, and facilitates block sharing, but also means that as time passes a large number of unused block files may accumuate within cloud storage.Unused block files may be removed by invoking the sqlite3_bcv_cleanup() interface from bcvutil.h:  int sqlite3_bcv_cleanup(sqlite3_bcv *p, int nSecond);In order to avoid disturbing existing read clients, the second parameter may be used to specify the minimum number of seconds the block must have been unused for to be considered eligible for cleanup.5.3. Block SharingSometimes, a single block may be used by multiple databases within a manifest, saving cloud storage space and bandwidth. This is known as \"block sharing\". Block sharing occurs in two scenarios:If a copy of a database is made using the command line copy primitive, then the copy shares all of its blocks with the original. This takes place regardless of the configured size of block ids for the manifest file.If the configured block-id size for a manifest file is greater than or equal to 24 bytes, then the first 16 bytes of each block id is an md5 hash of the block contents. In this case, before each new block is uploaded, the system checks to see if there already exists a block with the same md5 hash (and hence, we assume, the same content) that can be used in its place.This usually only occurs when a database being uploaded is a copy or slightly modified copy of an existing database, or when an existing database is overwritten with a copy of another database using the SQLite backup API.The block id size used by a manifest file must be configured when the manifest is first created using the command line create command or equivalent API. If block sharing using md5 hash values is required, then the block id size should be set to 24 bytes. Otherwise, it is best left set to the default value of 16 bytes to save space.5.4. Pragma InterfaceBlockcachevfs currently supports three PRAGMA statements - \"PRAGMA bcv_upload\" , \"PRAGMA bcv_poll\" and \"PRAGMA bcv_client\". If further PRAGMA commands are added in the future, the names of the new commands will begin with \"bcv_\".PRAGMA bcv_uploadBlockcachevfs database clients may execute the following PRAGMA statement to force any changes made locally to be uploaded to the cloud storage account: PRAGMA [database].bcv_uploadThe PRAGMA statements does not return until the upload is complete. If successful, an empty string is returned. If an error occurs and the upload cannot be completed, an SQLite error code is returned and the error message set to an English language explanation of the error.Invoking this PRAGMA is different to using the sqlite3_bcvfs_upload() interface in that this command only uploads changes for the current database, whereas sqlite3_bcvfs_upload() uploads all locally modified databases in the container.PRAGMA bcv_pollInvoking \"PRAGMA bcv_poll\": PRAGMA [database].bcv_pollis the equivalent to calling sqlite3_bcvfs_poll() on the container that the database is a part of. If successful, an empty string is returned. Otherwise, an SQLite error code is returned and the error message set to an English language explanation of the error.PRAGMA bcv_clientInvoking \"PRAGMA bcv_client\": PRAGMA [database].bcv_client PRAGMA [database].bcv_client = NAMEThis PRAGMA is used to set or query a cloudsqlite database connection's client name. The configured client name appears in the \"client\" column of the bcv_http_log virtual table for requests associated with the current database connection. It may also appear in log messages. It is not used for any other purpose. The default client name is an empty string.5.5. Virtual Table InterfaceThe virtual table interface consists of three eponymous virtual tables (or two in daemon mode). It is not available automatically, but must be made available to each SQLite connection explicitly by calling the sqlite3_bcvfs_register_vtab() API from blockcachevfs.h:  int sqlite3_bcvfs_register_vtab(sqlite3*);The bcv_container table:The read-only \"bcv_container\" table contains one row for each container attached to the VFS. It has the equivalent of the following schema:  CREATE TABLE bcv_container(   name   TEXT,     -- local name (alias) of container    storage  TEXT,     -- cloud storage system (e.g. \"azure\")   user   TEXT,     -- cloud storage username   container TEXT,     -- container name in cloud storage   ncleanup INTEGER    -- number of blocks eligible for cleanup  )Column \"name\" contains the local alias of the attached container (this may be the same as the remove container name). Columns \"storage\", \"user\" and \"container\" contain the storage module, account and cloud storage container names as specified to sqlite3_bcvfs_attach() when the container was attached.The \"ncleanup\" column usually contains the number of blocks that will be deleted from cloud storage if a cleanup operation (see the sqlite3_bcv_cleanup() API)is run on the container. However, if errors or client crashes have occurred while uploading changes to cloud storage, then there may be extra unused blocks left in the cloud storage container. In this case those blocks will be deleted by the next cleanup operation, but are not included in the value stored in the \"ncleanup\" column of the \"bcv_container\" table.The bcv_container table is available in both daemon and daemonless mode.The bcv_database table:The read-only \"bcv_database\" table contains one row for each database in each attached container. It has the equivalent of the following schema:  CREATE TABLE bcv_database(   container TEXT,     -- local name (alias) of container   database TEXT,     -- name of database   nblock INTEGER,     -- total number of blocks in database   ncache INTEGER,     -- number of blocks in cache   ndirty INTEGER,     -- number of dirty blocks in cache   walfile BOOLEAN,     -- true if transactions in local wal file   state TEXT        -- state of database (see below)  )The \"container\" column contains the local alias of the container (the same value that is stored in the \"name\" column of the bcv_container table). Column \"database\" contains the database name.Columns \"nblock\", \"ncache\" and \"ndirty\" contain the total number of blocks in the database, the number of those blocks that are currently cached locally, and the number of those cached blocks that are dirty and require uploding. It is always true that:  nblock >= ncache >= ndirtyBoolean column \"walfile\" is set to true if there are currently write transactions in a local wal file (blockcachevfs databases are always in wal mode). To determine whether or not there have been local changes to a database, an application might use a query similar to:  SELECT (walfile OR ndirty>0) AS has_local_changes FROM bcv_database WHERE...The \"state\" column usually contains an empty string. There are two exceptions:If the database has been created using sqlite3_bcvfs_copy() but not yet uploaded, then this column contains the text 'copied'.If the database has been deleted using sqlite3_bcvfs_delete() but the delete operation has not yet uploaded, then this column contains the text 'deleted'.The bcv_database table is available in both daemon and daemonless mode.The bcv_http_log table:The \"bcv_http_log\" table contains one row for each HTTP request made by the VFS or connected daemon. It has the equivalent of the following for a schema:   CREATE TABLE bcv_http_log(    id INTEGER,       -- Unique, monotonically increasing id value    start_time TEXT,     -- Time request was made, as iso-8601    end_time TEXT,      -- Time reply received, as iso-8601 (or NULL)    method TEXT,       -- \"PUT\", \"GET\" etc.    client TEXT,       -- Name of client that caused request    logmsg TEXT,       -- Log message associated with request    uri TEXT,        -- URI of request    httpcode INTEGER     -- HTTP response code (e.g. 200)   ) For those requests that can be associated with a single SQLite database handle, the contents of the \"client\" column is the client name as configured using the PRAGMA bcv_client command. For requests associated with a prefetch operation, it contains the string 'prefetch'.To prevent it from consuming an ever-increasing amount of memory, entries are automatically removed from the bcv_http_log on a first-in/first-out according to the values configured for the SQLITE_BCV_HTTPLOG_TIMEOUT and SQLITE_BCV_HTTPLOG_NENTRY parameters. Or, in daemon mode, according to the values passed via the --httplogtimeout and --httplognentry command-line options.Including various overheads, each entry may be assumed to consume 256 bytes of memory or less. So allowing 4096 entries to accumulate in the bcv_http_log table may require up to 1MiB of memory.The bcv_kv table:The schema of the \"bcv_kv\" table is:  CREATE TABLE bcv_kv(   name TEXT PRIMARY KEY,  -- Key value    value          -- Associated payload value  )Unlike the other two eponymous virtual tables described in this section, the bcv_kv table is read-write. Applications may write arbitrary data to the table to be stored in the cloud storage container. The table is empty when the container is first created.The contents of the bcv_kv table is stored as a separate file (an SQLite database) in the cloud container - \"bcv_kv.bcv\".The bcv_kv table implements transaction-like properties. As follows:The first time in a database transaction that the bcv_kv table is read or written, the file is downloaded from cloud storage and cached for the duration of the transaction. All user queries - read and write - are executed against this cached version of the bcv_kv table. This ensures that each transaction sees a consistent version of the table contents.When a read/write transaction is committed, a new version of the bcv_kv table data is uploaded to cloud storage. At this point, if it is found that the file has been modified within cloud storage since it was downloaded at the beginning of the transaction (because some other client wrote to it), the commit fails and the transaction is rolled back. The extended error code in this case is SQLITE_BUSY_SNAPSHOT.Because the entire bcv_kv table is downloaded (and, for write transactions, uploaded) for each transaction, applications should avoid storing large amounts of data within it.The bcv_kv_meta table:The schema of the \"bcv_kv_meta\" table is:  CREATE TABLE bcv_kv_meta(   name TEXT PRIMARY KEY,  -- Header field name   value          -- Header field value  )The bcv_kv_meta table is similar to the bcv_kv table, in that querying it causes cloudsqlite to download the bcv_kv.bcv database file and cache it for the remainder of the transaction. Instead of providing read/write access to the contents of the bcv_kv.bcv database, it provides read-only access to two of the http headers recieved from the cloud storage server when the file was downloaded - \"Date\" and \"Last-Modified\".The bcv_kv_meta table always contains exactly two rows. The first contains the string 'date' in the \"name\" column, and the value of the timestamp from the HTTP \"Date:\" header, in ISO-8601 format, in the \"value\" column. The second row contains 'last-modified' in the \"name\" column, and the ISO-8601 equivalent of the timestamp from the HTTP \"Last-Modified:\" header in \"value\".If, for some reason, the cloud storage server does not provide a \"Date:\" or \"Last-Modified:\" header, or if the contents of that header cannot be parsed, the corresponding \"value\" field in the bcv_kv_meta table is set to NULL.6. Command Line ReferenceThe following options are supported by all or most of the commands enumerated below. All commands accept unique prefixes of any option in place of the full option string.Option Argument-user USER-NAMEThe user or account name to use when accessing cloud storage.-auth ACCESS-KEYThe authentication information to use when accessing cloud storage. The form of this depends on the cloud storage module in use.-container CONTAINER-NAMEThe blob storage container to read from or write to. This option is accepted (and required) by the commands \"upload\", \"delete\", \"list\" and \"download\" only.-file PATHThis option tells the comand to read the local text file at relative or absolute path PATH and treat its contents as whitespace separated command line arguments.-module MODULE-NAMEThe cloud storage module to use to access the remote container. This may be a simple module name (e.g. \"google\") or a module name followed by URI style parameters (e.g. \"azure?emulator=127.0.0.1:10000&sas=1\").-log STRINGThe argument to this option determines when log messages are output to stdout. If the value contains an \"h\" character, a message is output each time an HTTP(S) request is issued or a reply received. If a \"v\" is present in the string, libcurl verbose logging is enabled. All other characters are ignored. The intepretation of the argument to this option is subject to revision at any point. The default value is an empty string (no log messages at all).The following commands are supported: blockcachevfsd copy ?OPTIONS? DATABASE1 DATABASE2Make a copy of database DATABASE1 named DATABASE2. If DATABASE2 exists it is clobbered by the copy. This operation always uses block sharing to avoid uploading any new block files. blockcachevfsd create ?OPTIONS? CONTAINERCreate a new container and add an empty manifest file containing zero databases to it. It is not an error if the container already exists. In this case any existing manifest is clobbered by the new, empty, manifest, effectively deleting any databases currently stored in the container.The following extra options are supported:   -blocksize BlOCK-SIZE   -namebytes BLOCKID-SIZEThe \"-blocksize\" option is used to set the size of each block file stored within cloud storage. The default size is 4MiB. If the argument is an integer value it is interpreted as a size in bytes. If an integer value followed by a 'k' or 'K' character, a size in KiB. Or, if the argument is an integer value followed by an 'm' or 'M' character, a size in MiB. The specified size must be a power of two in bytes. The following switches all serve to set the block-size to 2MiB:   -blocksize 2M   -blocksize 2048k   -blocksize 2097152The \"-namebytes\" option may be passed an integer value between 16 and 32, inclusive, to set the size in bytes of the block ids that will be used by the manifest file. The default value is 16. The block id size has implications for block sharing. blockcachevfsd delete ?OPTIONS? NAMERemove database NAME from the container identified by the -container option. blockcachevfsd destroy ?OPTIONS? CONTAINERDelete an entire blob storage container and its contents.WARNING: Deleting a container from Azure blob storage is (apparently) a lazily executed operation. Even though the container appears to be removed immediately, it still exists in some senses as Azure prevents a new container with the same name from being created for some time. Sometimes this condition persists for up to 24 hours or longer. For this reason, it is better to \"create -clobber\" a container instead of attempting to delete and then recreate it. blockcachevfsd download ?OPTIONS? NAME ?LOCALFILE?Download the named database from the container specified by the -container option to the local file-system. If the LOCALFILE argument is specified, then it is the local file-system path to store the downloaded database at. If no LOCALFILE argument is specified, the downloaded database is stored in the current directory using the same name as is used in cloud storage.The download command supports the following additional option:   -nrequest NThis option sets the number of HTTP(S) requests that are allowed to be outstanding at any one time. The default value is 1. Using a higher value might increase throughput. blockcachevfsd upload ?OPTIONS? DATABASE-FILE ?NAME?Upload the specified local database file to and add it to the manifest in the container identified by the -container option. If the NAME parameter is present then it is used as the name of the uploaded remote database. Otherwise, the remote database takes the same name as the local file, with any directory components removed.The upload command supports the following additional option:   -nrequest NThis option sets the number of HTTP(S) requests that are allowed to be outstanding at any one time. The default value is 1. Using a higher value might increase throughput.The eight commands above mirror the eight APIs made available to database clients (attach and detach by blockcachevfs.h, the others by bcvutil.h). The following commands are also supported, but are considered a convenience only. The command-line options and the output of the following are subject to change at any time: blockcachevfsd files ?OPTIONS? CONTAINERList the files in the specified container, one per line. All files are listed, even those that are not part of blockcachevfs databases. blockcachevfsd list ?OPTIONS? If there is no -container option, list all databases in all containers in the blob storage account. Or, if the -container option is passed, list only the databases in the specified container. blockcachevfsd manifest ?OPTIONS? CONTAINEROutput a human-readable version of the manifest file found in the specified container.7. Daemon Command ReferenceThe daemon process is started as follows: blockcachevfsd daemon ?OPTIONS? DIRECTORY The daemon command supports the following options:Option Argument Default Value-addr IPV4-ADDRESS (default - \"127.0.0.1\")Normally, the daemon listens and accepts connections from client on the localhost address (127.0.0.1). This option allows the daemon to listen for connections on some other local address.-cachesize CACHE-FILE-SIZE (default 1G)Database file blocks downloaded from the blob storage account are cached locally. The cache is allowed to grow up to the size configured by this option, then blocks are expelled on a least-recently-used basis as new blocks are downloaded. The argument to this option must be a positive integer followed by a single \"M\" or \"G\" (or \"m\" or \"g\") character to indicate whether the integer value should be interpreted as a number of MiB or GiB. For example, to use a 1GiB cache, either \"-cachesize 1024M\" or \"-cachesize 1G\" may be specified.-httptimeout SECONDS (default value 600The number of seconds to wait before assuming an HTTPS request made to cloud storage has been lost.-log STRING (default value \"\")The argument to this option determines when log messages are output to stdout by the daemon process. Each character in the argument string turns on different log messages. Characters not listed in the following table are ignored. The interpretation of the argument passed to this option is subject to revision at any time.Character Interpretationm Output a log message each time a message is received from or sent to a connected database client.h Output a log message each time an HTTP(S) request is set or a reply received.e Output a log message when various internal \"events\" occur.v Turn on libcurl CURLOPT_VERBOSE logging.-notimestampsThis option causes the daemon process to omit the high-resolution timestamps from the log messages it outputs.-port PORT-NUMBER (default - first free tcp port >= 22002)The localhost port on which to listen for connections from local database clients.-httplogtimeout SECONDS (default value 3600)The number of seconds after which entries are automatically removed from the bcv_http_log virtual table. A value of less than zero means entries are never removed.-httplognentry INTEGER (default value -1)The maximum number of entries allowed in the bcv_http_log virtual table. Once this limit has been reached old entries are automatically removed to make way for new.-autoexitThis debugging option causes the daemon process to exit cleanly when the number of local database clients drops to zero.-delay MS 0This debugging option causes the daemon process to to pause for the specified number of milliseconds before beginning to listen for incoming connections.-readymessageThis debugging option causes the daemon process to print \"READY\\n\" to stdout when it is ready to accept incoming client connections. This makes it easier to write test scripts that start and stop daemon processes.This page was generated in about 0.004s by Fossil 2.23 [c6115dbf83] 2023-06-23 22:15:34",
    "summary": "- The \"Cloud Backed SQLite\" (CBS) system allows databases to be stored within cloud storage accounts, allowing them to be read and written by storage clients without downloading the entire database.\n- CBS currently supports Azure Blob Storage and Google Cloud Storage, with the potential for adding support for other cloud storage systems.\n- CBS uses fixed-size blocks to store SQLite databases in the cloud, with a manifest file that describes how the blocks assemble into databases. It also provides APIs and command-line tools for uploading, downloading, and managing databases in the cloud.",
    "hn_title": "Cloud Backed SQLite",
    "original_title": "Cloud Backed SQLite",
    "score": 459,
    "hn_content": "Hacker News new | past | comments | ask | show | jobs | submit loginCloud Backed SQLite (sqlite.org)459 points by nalgeon 1 day ago | hide | past | favorite | 143 commentsnoman-land 1 day ago | next [\u2013]I've just been exploring serving large SQLite databases in chunks and querying them with http range requests to prevent downloading the entire database. It's pretty awesome!I found a really interesting library called sql.js-httpvfs[0] that does pretty much all the work. I chunked up my 350Mb sqlite db into 43 x 8Mb pieces with the included script and uploaded them with my static files to GitHub, which gets deployed via GitHub Pages.[1]It's in the very rough early stages but you can check it out here.https://transcript.fishI recommend going into the console and network tab to see it in action. It's impressively quick and I haven't even fine-tuned it at all yet. SQLite rules.[0] https://github.com/phiresky/sql.js-httpvfs[1] https://github.com/noman-land/transcript.fishreplydopamean 1 day ago | parent | next [\u2013]The timing of this is incredible. I was recently given a 120gb SQLite db to work with and I was going to investigate ways to work with it in the morning.replydanielvaughn 20 hours ago | root | parent | next [\u2013]I\u2019m not sure what they offer on this front, but turso is a new edge-based SQLite platform. It might be worth checking out:https://turso.tech/replydopamean 18 hours ago | root | parent | next [\u2013]Thank's! I'll have a look at this as well.replypunnerud 1 day ago | parent | prev | next [\u2013]Like this? Serving Wikipedia as a static SQLite file, using range request: https://news.ycombinator.com/item?id=27016630replynoman-land 13 hours ago | root | parent | next [\u2013]Yes, this is the post I learned about this from and that's the person who wrote the sql.js-httpvfs library I'm using. Extremely cool.replycodethief 17 hours ago | root | parent | prev | next [\u2013]Fantastic, thank you! I came here to find this link. :)replypsanford 18 hours ago | parent | prev | next [\u2013]I often use (my[0]) sqlite http vfs to query databases stored in s3. You can simply make a presigned url and then give that to the vfs and then it all just works.[0]: https://github.com/psanford/sqlite3vfshttpreplypyeri 15 hours ago | parent | prev | next [\u2013]>> querying them with http range requests to prevent downloading the entire database. It's pretty awesome!Querying isn't a problem, you can query as much as you want. But where you'll hit the Sqlite limitation is in scaling for multi user write scenarios. Yes, even Sqlite can handle a few concurrent write requests but once your users start scaling in millions, you'll eventually need a proper RDBMS like mysql or postgres.replynoman-land 15 hours ago | root | parent | next [\u2013]I've been thinking about this a lot. In my particular use-case I can get away with having a totally read-only app.However if I want people to be able to submit corrections to the transcriptions, I need a way to do that. I was thinking of setting up some sort of queue system to make writes non-realtime since, for this app, it's not a big deal.It will be in interesting challenge, for sure.replyvidarh 15 hours ago | root | parent | prev | next [\u2013]sql.js-httpvfs is a read-only solution. The point is to be able to put up pre-baked datasets on any random web server w/range support, or a blob store.replybakkoting 14 hours ago | parent | prev | next [\u2013]I've been using sql.js-httpvfs to get full-text search on a static Github Pages site [1]. (Just make sure you have fts5 enabled on your database.) It works astonishingly well.[1] https://matrixlogs.bakkot.com/WHATWG/search?q=databasereplynoman-land 13 hours ago | root | parent | next [\u2013]This is awesome. Maybe you can help me figure out the best way to search. The transcriptions are one row per word since each word is timestamped. I'm currently just doing client side search in JS for the titles and descriptions but I'll have to do proper SQL search for the body of the transcriptions. What's the best way to search for strings of text if the db is one row per word (~4 million rows)?replyelectroly 12 hours ago | root | parent | next [\u2013]In theory you can add an index on the token text column and then implement full text searching yourself using the index to find the set of documents containing each search term, counting the occurrences per document, and combining the results from all the terms. But FTS5 already does that for you, and it's more efficient than the above.The traditional FTS5 technique as documented [0] should work, same as if this were a local SQLite database. You'll have to duplicate the transcriptions into TEXT form (one row per document) and then use FTS5 to create a virtual table for full text searching. The TEXT form won't actually be accessed for searching, it's just used to build the inverted index.[0] https://www.sqlite.org/fts5.htmlreplybakkoting 13 hours ago | root | parent | prev | next [\u2013]I don't know enough about how FTS works to help, I'm afraid. I don't know if it's possible to search across multiple rows.Were I in your position I'd just create a copy of the DB with the full transcript in each row and run the search against that. If you only have 4 million words, creating an extra copy of the database shouldn't be prohibitively large.replyzX41ZdbW 8 hours ago | parent | prev | next [\u2013]I recommend checking a similar project - storing ClickHouse databases on GitHub pages for serverless analytical queries: https://github.com/ClickHouse/web-tables-demoreplyeterevsky 1 day ago | parent | prev | next [\u2013]I don't know much about SQLite internals, but on the face of it it sounds hacky as hell (pardon if I'm wrong).Wouldn't it be better to make a proper client-server API similar to traditional SQL databases, but on top of SQLite?replyComodoHacker 1 day ago | root | parent | next [\u2013]The point is to use dumb cheap blob storage instead of CPU-consuming server someone has to manage.replyantonvs 20 hours ago | root | parent | prev | next [\u2013]There are many use cases where scaling a traditional centralized SQL database is problematic, that can be addressed by something like this.We have one: we run thousands of VMs at a time, all accessing the same \"database\". Since we already have a good amount of horizontally-scaled compute, having to maintain a separate database cluster, or large vertically-scaled database instance, to match our peak load requirements is problematic in terms of one or more of cost, complexity, and performance. In particular, horizontally-scaled distributed databases tend not to scale up and down efficiently, because of the complexity and time involved in joining the cluster, so the cost benefits of horizontal scaling of compute are lost.An approach like this can fit well in cases like these.replyeterevsky 17 hours ago | root | parent | next [\u2013]I can't see how this could for a readonly database, but how would you resolve collisions on writes and don't make them super slow in the process?replyphamilton 19 hours ago | root | parent | prev | next [\u2013]Databases are really just data structures and algorithms along with some notion of durability.Client/Server databases are just remote data structures. (E.g. Redis is short for \"Remote Dictionary Server\")Sometimes you want your data structures and algorithms to run locally. Could be performance, privacy, cost, or any number of reasons.Local, in-memory data structures hit a few bottlenecks. First, they may not fit in memory. A mechanism for keeping the dataset in larger storage (e.g. disk) and paging in the necessary bits as needed extends the range of datasets one can comfortably work with locally by quite a bit. That's standard SQLite.A second potential bottleneck to local data structures is distribution. We carry computers in our pockets, on our watches, in our cars. Delivering large datasets to each of those locations may be impractical. Cloud based VFS allows the benefits of local data structures on the subset they need without requiring them to fetch the entire dataset. That can be a huge win if there's a specific subset they need.It always depends on the use case, but when the case fits there are a lot of big wins here.replyeterevsky 19 hours ago | root | parent | next [\u2013]One obvious problem that I see with this approach is that it will break if there is any change in the storage format.With client-server architecture, the server code owns the data format, while in this storage-level remote access case, you have to ensure that all of your clients are updated simultaneously. Depending on your architecture it might or might not be feasible.replyvidarh 18 hours ago | root | parent | next [\u2013]For the typical uses for this, you'd tend to serve up a version of Sqlite compiled to wasm or JS to the frontend, so you can be sure it's the same one. Sqlite's storage format is also unusually stable:https://www.sqlite.org/formatchng.htmlreplyzX41ZdbW 8 hours ago | root | parent | prev | next [\u2013]It's better to ensure 100% compatibility with the data format so the new server versions can read the old format without conversions. For example, in ClickHouse, you can install the latest version over a version from 7 years ago, and it will work just fine with the old MergeTree tables.replyelectroly 19 hours ago | root | parent | prev | next [\u2013]The VFS layer in SQLite is begging to be used like this. For a read-only implementation (where you generate the SQLite databases out-of-band and upload them), the code nearly writes itself. It's maybe hacky in the sense of \"I had to write a SQLite module for this\" but it's a very nice fit for SQLite VFS.replynoman-land 15 hours ago | root | parent | next [\u2013]Yes this code was very straightforward to write and this approach lends itself very well to read-only databases of large datasets with no server infrastructure overhead. It's also \"free\" to host for the time being.replyqbasic_forever 20 hours ago | root | parent | prev | next [\u2013]Depends on your needs, if it's just one or even multiple clients reading from the db then range requests of blocks is a great option. Adding a server layer is a huge leap in complexity as you now have code that has to be deployed, managed, secured, etc. vs. just simple blob storage for chunks (s3, etc.).replysitkack 20 hours ago | root | parent | prev | next [\u2013]How so? It\u2019s not like the CPU or the network care.replyeterevsky 19 hours ago | root | parent | next [\u2013]It's difficult to implement correctly if there's more than one client. There is no single source-of-truth to manage any conflicts. Might be ok if the clients have only read-only access.replyanon291 13 hours ago | root | parent | prev | next [\u2013]It's not hacky though. SQLite explicitly supports VFS implementations, and it's in wide use throughout industry. All this does is use emscripten + asyncify to compile to javascript and then implements a vfs that calls into regular javascript calls. SQLite is notoriously well tested, and so if it says that the VFS works a certain way, it probably does.replypama 8 hours ago | parent | prev | next [\u2013]Totally minor but this website does not show anything in lockdown mode on the iPhone.replynoman-land 7 hours ago | root | parent | next [\u2013]Interesting, thanks for the tip! I've never heard of lockdown mode. Unfortunately I don't own an iPhone. Any chance you could post an issue with steps to repro?https://github.com/noman-land/transcript.fish/issuesThank you!replysnowstormsun 1 day ago | parent | prev | next [\u2013]Wow, that's so cool!reply6510 1 day ago | parent | prev | next [\u2013]it badly needs {cursor:pointer} for the things one can click on.replynoman-land 15 hours ago | root | parent | next [\u2013]Yes, indeed! This has been bugging me and I've fixed it. Thank you.reply0xbadcafebee 1 day ago | prev | next [\u2013]This adds more cache consistency issues, concurrency issues, network blocking issues, authn+z issues, daemon process supervision issues, ... for what? To store your SQL data in a remote data store? I would rather my app shell out to gsutil (or curl!) than deal with all of this.Simple hack: mount a tmpfs filesystem and write your sqlite database there. Every 30 seconds, stop writing, make a copy of the old database to a new file, start writing to the new file, fork a process to copy the database to the object store and delete the old database file when it's done. Add a routine during every 30 second check to look for stale files/forked processes.Why use that \"crazy hack\", versus the impeccably programmed Cloud Backed SQLite solution?- Easier to troubleshoot. The components involved are all loosely-coupled, well tested, highly stable, simple operations. Every step has a well known set of operations and failure modes that can be easily established by a relatively unskilled technician.- File contents are kept in memory, where copies are cheap and fast.- No daemon outside of the program to maintain- Simple global locking semantics for the file copy, independent of the application- Thread-safe- No network blocking of the application- Authentication is... well, whatever you want, but your application doesn't have to handle it, an external application can.- It's (mostly) independent of your application, requiring less custom coding, allowing you to focus more on your app and less on the bizarre semantics of directly dealing with writes to a networked block object store.replyCraigJPerry 1 day ago | parent | next [\u2013]>> Every 30 seconds, stop writing, make a copy of the old databaseThat sounds so simple that i almost glossed over it. But then the alarm bells started ringing.If you don\u2019t need to collaborate with other people, this kind of hacking is mostly fine (and even where its not fine, you can always upgrade to using filesystem snapshots to reduce copy burden when that becomes an issue and use the sqlite clone features to reduce global lock contention when you grow into that hurdle etc etc) but if you need to collaborate with others, the hacky approaches always lead to tears. And the tears arrive when you\u2019re busy with something else.replychasil 20 hours ago | root | parent | next [\u2013]If you really need to collaborate with other people, then you likely want something that implements GRANT and REVOKE.replysitkack 20 hours ago | root | parent | next [\u2013]Everything it\u2019s just a URL you already have Grant and revokereplyvasco 1 day ago | parent | prev | next [\u2013]> ... for what?Backups, replication to different regions, access to the data etc become standardized when it's the same as any other cloud bucket. This makes compliance easier and there's no need to roll your own solution. I also never had to troubleshoot sqlite, so I'd trust this will be more robust than what I'll come up with, so I don't get your troubleshooting argument.Not everyone will care about this, but those can just not use it I guess.replybeebmam 1 day ago | parent | prev | next [\u2013]Or just use a database like Postgres. It's a one liner to download and start up a postgres container.replychaxor 1 day ago | root | parent | next [\u2013]Is it really now? I have heavily preferred SQLite to postgres after having nightmares with it many years ago. I preferred SQLite because I often needed a single 1TB file to hand someone to get started on a project with the DB, which seemed far more complex with postgres. There were a ton of steps required to get things set up, just with the installation and authentication alone. I recall needing to make a few users and passwords and specify which tables were allowed for different users, etc. It was far, far too complex for just storing data. Multiple users are extremely uncommon for data analysis, and hiding certain tables isn't really needed most of the time.I know it does have it's use cases, but if you don't need access control and more complexities, postgres (at least then) seems like so much hassle.If it's better now perhaps I may try it, but I can't say I have high hopes.replysupportlocal4h 21 hours ago | root | parent | next [\u2013]If you had to make a few users and passwords and specify which tables were allowed for different users it is only because you chose to design your app this way. You must have felt there was some good reason to divide it up like that.If that was the case, sqlite would have been unsuitable for your needs.In other words, the complexity you describe was not caused by postgres. It was caused by your app design. Postgres was able to accommodate your app in a way that sqlite cannot.Sqlite does have the \"it's all contained in this single file\" characteristic though. So if and when that's an advantage, there is that. Putting postgres in a container doesn't exactly provide the same characteristic.replysauercrowd 1 day ago | root | parent | prev | next [\u2013]Using the docker container is a breeze - add a POSTGRES_PASSWORD env variable and you're all set. I'd be curios how it performs for a TB of data but I would be surprised if it straight out breaks.https://hub.docker.com/_/postgresreplydjbusby 20 hours ago | root | parent | next [\u2013]It works fine, even w/larger data. The data is stored on a bind-mount volume on the host; not in the container.replybshipp 16 hours ago | root | parent | next [\u2013]SQLite can be awesome for huge data sets as I've rarely found anything that can ingest data as rapidly but, as with any database, it requires some specific tweaking to get the most out of it.The biggest headache is the single write limitation, but that's no different than any other database which is merely hidden behind various abstractions. The solution to 90% of complaints against SQLite is to have a dedicated worker thread dealing with all writes by itself.I usually code a pool of workers (i.e. scrapers, analysis threads) to prepare data for inserts and then hand it off for rapid bulk inserts to a single write process. SQLite can be set up for concurrent reads so it's only the writes that require this isolation.replyfauigerzigerk 1 day ago | root | parent | prev | next [\u2013]Is cloud storage authnz is any less convoluted? I realise you're responding only to the \"one liner\" argument, but as soon as you do anything with SQLite that involves the cloud or authnz or secondary processes, you're right back to where you were with client/server database systems in terms of complexity.replyaembleton 23 hours ago | root | parent | prev | next [\u2013]docker run --name some-postgres -e POSTGRES_PASSWORD=mysecretpassword -p5432:5432 -d postgresreplyElectricalUnion 18 hours ago | parent | prev | next [\u2013]> Every 30 seconds, stop writing, make a copy of the old database to a new fileI hope that by \"copy of the old database\" you mean \"Using the SQLite Online Backup API\"[1].  This procedure [copy of sqlite3 database files] works well in many scenarios and is usually very fast. However, this technique has the following shortcomings:  * Any database clients wishing to write to the database file while a backup is being created must wait until the shared lock is relinquished.  * It cannot be used to copy data to or from in-memory databases.  * If a power failure or operating system failure occurs while copying the database file the backup database may be corrupted following system recovery. [1] https://www.sqlite.org/backup.htmlreplygregwebs 23 hours ago | parent | prev | next [\u2013]If I am reading this right the main difference is you are copying the entire db whereas the linked version can copy just the changed blocks. Also in your solution it seems 30 seconds of data loss is expected although that could be avoided by using cloud disk instead of tmpfs and then you could take snapshots as wellreplythrowawaaarrgh 20 hours ago | root | parent | next [\u2013]Oh I see, it has weird independent block file semantics (weird because they aren't reused, unless they are?). That's interesting, although potentially problematic, with the whole \"I'll just keep adding files, unless I remember to cleanup, which could cause problems\" thingIf you can't handle 30 seconds of data loss you should probably be using a real database. I could be wrong but I don't remember this guaranteeing every transaction synchronously committed to remote storage?There's a lot of caveats around block store restrictions, multi client access, etc. It looks a lot more complicated than it's probably worth. I'll grant you in some cases it's probably useful, but I also can't see a case where a regular database wouldn't be more ideal.replyelectroly 11 hours ago | root | parent | next [\u2013]This module DOES guarantee that transactions are synchronously committed to remote storage before completing the transaction. The transaction can be rolled back if uploading to remote storage fails; this is mentioned in the documentation. Ctrl+F \"rolled back\" in the doc. Doing it asychronously would be more complicated and this is a pretty simplistic module.replyp-e-w 1 day ago | prev | next [\u2013]I don't understand what the goal is here. Wherever the cloud is, there is PostgreSQL, and conveniently, PostgreSQL already solves all of the problems that \"Cloud SQLite\" creates, with support for concurrent access, higher performance, richer queries, and lots more.Is this just a toy? What are the upsides in practice of deploying an embedded database to a cloud service?replyelectroly 1 day ago | parent | next [\u2013]Hosting files in S3 is much, much cheaper than running a live instance of PostgreSQL. Incomparably so. We do it specifically to move large, mostly cold, read-only data out of the main RDBMS and into S3 in a way that it can still be queried on-the-fly* without having to be fully downloaded and reconstituted on a server first. Works great and we get to pay S3 prices for storage and nothing for compute. As a kicker, because it's S3 we can access it from any availability zone without paying for cross-AZ data transfer. For the size and coldness of this data, the juice is worth the squeeze. None of the downsides matter for our use case at all.* Using indexes and only touching the pages you need. This is specifically much better than S3 Select, which we considered as an alternative.replyeb0la 22 hours ago | root | parent | next [\u2013]\"Much cheaper\" means is that S3 costs about $23 / TB OTH a db.t4g.small instance with 2 vCPU, 2 GB, and 1 TB is about $260 + cpu credits...replyelectroly 20 hours ago | root | parent | next [\u2013]On the S3 side, you need to factor in Intelligent Tiering. We're not paying S3 Standard prices for this--recall that this is a mix of mostly cold data. It's a 10x difference per GB on average between EBS and our mix of S3 Intelligent Tiering.Add in that your RDS instance needs to be high availability like S3 is (and like our RDBMS is). That means a multi-AZ deployment. Multiply your RDS cost by two, including the cost of storage. That still isn't as good as S3 (double price gets you a passive failover partner in RDS PostgreSQL; S3 is three active-active AZs), but it's the best you can do with RDS. We're north of $500/month now for your example.Add in the cost of backups, because your RDS database's EBS volume doesn't have S3's durability. For durability you need to store a copy of your data in S3 anyway.Add in that you can access S3 without cross-AZ data transfer fees, but your RDS instance has to live in an AZ. $0.02/GB both ways.Add in the personnel cost when your RDS volume runs out of disk space because you weren't monitoring it. S3 never runs out of space and never requires maintenance.$500/month for 1TB of cold data? We were never going to pay that. I won't disclose the size of the data in reality but it's a bunch bigger than 1TB. We host an on-prem database cluster for the majority of things that need a RDBMS, specifically because of how expensive RDS is. Things probably look different for a startup with no data yet, blowing free AWS credits to bootstrap quickly, but we are a mature data-heavy company paying our own AWS bills.As a final summary to this rant, AWS bills are death by a thousand papercuts, and cost optimization is often a matter of removing the papercuts one by one. I'm the guy that looks at Cost Explorer at our company. One $500/month charge doesn't necessarily break the bank but if you take that approach with everything, your AWS bill could crush you.replyantonvs 20 hours ago | root | parent | prev | next [\u2013]And if you need to scale your DB its price goes up, while the cloud storage price remains the same.replyDeathArrow 1 day ago | root | parent | prev | next [\u2013]> Hosting files in S3 is much, much cheaper than running a live instance of PostgreSQL.If your app is running on premises and the DB is on cloud, you can also move the DB on premises so the costs are lower.If your app runs on cloud, too, then you already are paying for the cloud compute so you can just fire up an VM and install Postgres on that.replyelectroly 18 hours ago | root | parent | next [\u2013]Indeed, our RDBMS is on-prem; we'd never actually use RDS. This data's pages were hogging the cache leading to reduced performance for other unrelated tables, and SAN storage isn't particularly cheap or flexible. We wanted to get it out of our on-prem RDBMS. If you're over a hundred billion rows, it's time to think about whether your data belongs there. Maybe it does, maybe it doesn't. This data had an alternative and I took it.> If your app runs on cloud, too, then you already are paying for the cloud compute so you can just fire up an VM and install Postgres on that.This part doesn't make sense. If your app is on the cloud, you're paying for the cloud compute for the app servers. \"Firing up a VM\" for PostgreSQL isn't suddenly free.replyinfamia 18 hours ago | root | parent | prev | next [\u2013]You can absolutely do all of those things, but there is an intrinsic cost for someone to configure, manage, and monitor those things. SQLite will (generally speaking) have far less management overhead because of its relatively limited surface area (e.g., there is no database service).replystavros 1 day ago | root | parent | prev | next [\u2013]If your app is a static JS file, now your DB can also be static.replyqaq 1 day ago | root | parent | prev | next [\u2013]This highly depends on app access patternsreplyelectroly 1 day ago | root | parent | next [\u2013]Absolutely. I\u2019ll go further and say that you must specifically design the database schema knowing that it\u2019s going to be used this way. Your pages need to be packed full with the data you need and nothing you don\u2019t. Spatial locality matters bigtime since \u201cseeks\u201d are so expensive (additional S3 requests), when in a traditional db it matters much less. Wide tables with a lot of columns that might not be used in a query are a bad idea here.Here\u2019s an in-the-weeds tip for anyone attempting the same: your tables should all be WITHOUT ROWID tables. Otherwise SQLite sprays rows all over the place based on its internal rowids, ruining locality when you attempt to read rows that you thought would be consecutive based on the primary key.replywcedmisten 22 hours ago | root | parent | next [\u2013]A few days ago, I tried to use the linked library (sql.js-httpvfs) for a graph network visualization, which went about as well as you'd expect given the poor spatial locality. Do you have any tips for optimizing spatial locality with more complex queries? Can you manually cluster data for some given properties in SQLite?For my project I ended up just exporting the graph edges as JSON, but I'm curious if it would still be possible to make work.replyelectroly 19 hours ago | root | parent | next [\u2013]In a WITHOUT ROWID table, you have control over the order of the rows. Make an id column as your primary key, and set the id appropriately so that rows accessed together will be next to each other in the file. This is how I manually cluster the data.Aside from that, I use an entity-attribute-value model. This ensures that all the tables are narrow. Set your primary key (again, with WITHOUT ROWID) to put all the values for the same attribute next to each other. That way, when you query for a particular attribute, you'll get pages packed full with nothing but that attribute's values in the order of the IDs for the corresponding entities (which you manually clustered).It's worth repeating one more time: you must use WITHOUT ROWID. SQLite tables otherwise don't work the way you'd expect from experience with other DBs; the \"primary\" key is really a secondary key if you don't use WITHOUT ROWID.replywcedmisten 16 hours ago | root | parent | next [\u2013]Thanks for the info! In my case there's not really one primary key that would guarantee good clustering for my query, so I guess there's not much that can be done to optimize here.I'm trying to find all the ancestors of a node in a DAG, so the optimal clustering would vary depending on the node I'm querying forreplyp-e-w 1 day ago | root | parent | prev | next [\u2013]> I\u2019ll go further and say that you must specifically design the database schema knowing that it\u2019s going to be used this way.If it ever turns out, at some point in the future, that you do need features from a standard RDBMS after all, you are going to regret not using Postgres in the first place, because re-engineering all of that is going to be vastly more expensive than what it would have cost to just \"do it right\" from the start.So it seems that Cloud SQLite is basically a hyper-optimization that only makes sense if you are completely, totally, 100% certain beyond any reasonable doubt that you will never need anything more than that.replyelectroly 1 day ago | root | parent | next [\u2013]I can\u2019t reveal too many internal details but this data lived in the RDBMS for years. Its access patterns are well understood. That\u2019s exactly when you start cost optimizing. If this didn\u2019t work out we\u2019d just move back to the old DB schema that we were already using and pay for a bigger server. If we wanted, we could keep the schema as-is and just move it into SQL Server. That would work just fine, too. No re-engineering required.Don\u2019t know how else to say \u201cwe were not born yesterday; we thought of that\u201d politely here. This definitely isn\u2019t something to have your junior devs work on, nor is it appropriate for most DB usage, but that\u2019s different than it not having any use. It\u2019s a relatively straightforward solution to a niche problem.replypid-1 22 hours ago | root | parent | prev | next [\u2013]Why not use parquet files + AWS Athena?replyelectroly 19 hours ago | root | parent | next [\u2013]The ability to use an index to seek directly to a handful of consecutive rows without processing the whole file was very important for our use case. Athena doesn't support indexing like this; it only has partitioning on a single column. It has to scan whole partitions every time. Both S3 Select and Athena are more useful when you want to aggregate massive data sets, but that's not what we're doing. We want to jump in and pull out rows from the middle of big data sets with reasonably low latency, not aggregate the whole thing.replysimlevesque 21 hours ago | root | parent | prev | next [\u2013]To avoid depending on a AWS product.replyBoorishBears 1 day ago | root | parent | prev | next [\u2013]If you mentioned Athena maybe I could see how this follows what the earlier comment says, but as is your usecase doesn't really overlap with why people are building cloud sql productsreplyelectroly 1 day ago | root | parent | next [\u2013]Am I not \u201cpeople\u201d? :)I built a SQLite VFS module just like the one linked here, and this is what I use it for in production. My use case obviously does not preclude other people\u2019s use cases. It\u2019s one of many.GP asked whether this is a toy and what the upsides might be. I answered both questions with an example of my production usage and what we get out of it.replyBoorishBears 1 day ago | root | parent | next [\u2013]A SQLite VFS module isn't a cloud SQL product, my comment refers to companies like fly.io and MotherDuck that are actually selling \"embedded database in the cloud\"It's entirely predicated on developer experience, otherwise there's no reason to specifically reach for an embedded database (in-process doesn't mean anything when the only thing the process is doing is running your DB)replyelectroly 1 day ago | root | parent | next [\u2013]Okay, sure. I\u2019m satisfied that I answered GP\u2019s questions about this VFS module. This HN post is about the VFS module, posted by a notable SQLite extension developer (nalgeon).replybenatkin 1 day ago | parent | prev | next [\u2013]I think letting people build their own system of isolated databases that can easily be started up and shut down for writing or randomly accessed for reading could be one use. It could be used for both performance and security. Offline use could also be improved, possibly by sending binary diffs.replysitkack 20 hours ago | parent | prev | next [\u2013]This is a mechanism not a goal. You make the new goals with the new mechanism.replyBoorishBears 1 day ago | parent | prev | next [\u2013]From my POV this is part of the developer experience push.SQLite running in-process is so convenient to build with that even when people use other DBs they write wrappers to sub it inI guess this is an attempt to let that convenience scale?replyrsync 1 day ago | prev | next [\u2013]I've been (proudly) noting these elegant one-liners for ... 18 years now: pg_dump -U postgres db | ssh user@rsync.net \"dd of=db_dump\" mysqldump -u mysql db | ssh user@rsync.net \"dd of=db_dump\"... but what is the equivalent command for SQLite ?I see that there is a '.dump' command for use within the SQLite console but that wouldn't be suitable for pipelining ... is there not a standalone 'sqlitedump' binary ?replyoefrha 1 day ago | parent | next [\u2013]The .backup command is better than than the .dump command suggested in siblings, as it doesn\u2019t block all writes until it completes. You can then do anything with the backup. (Do keep in mind there\u2019s the .backup never finishing problem on a db with non-stop writes.)replyJNRowe 19 hours ago | root | parent | next [\u2013]The '.backup' command also carries across the metadata too, so you don't lose things like 'application_id'\u00b9.I mention this as I once wasted a bunch of time trying to get a backup created from a '.dump | sqlite3' pipe to work before taking a proper look at the application code, and finally saw that it silently ignored databases without the correct 'application_id' or 'user_version'.\u00b9 https://www.sqlite.org/pragma.html#pragma_application_idreplypolyrand 1 day ago | root | parent | prev | next [\u2013]The .dump command creates a read transaction[0], so it shouldn't block any writes.From the SQLite docs: When a SAVEPOINT is the outer-most savepoint and it is not within a BEGIN...COMMIT then the behavior is the same as BEGIN DEFERRED TRANSACTIONInternally, the .dump command only runs SELECT queries.[0]: https://github.com/sqlite/sqlite/blob/3748b7329f5cdbab0dc486...replyoefrha 1 day ago | root | parent | next [\u2013]A read transaction does block writes, unless you enable WAL mode, which I forgot to mention.replydiarrhea 1 day ago | root | parent | next [\u2013]WAL Mode is the default anyway, I thought.replychasil 20 hours ago | root | parent | next [\u2013]It is not, due to the many restrictions upon it, and warnings in its use.\u201cTo accelerate searching the WAL, SQLite creates a WAL index in shared memory. This improves the performance of read transactions, but the use of shared memory requires that all readers must be on the same machine [and OS instance]. Thus, WAL mode does not work on a network filesystem.\u201d\u201cIt is not possible to change the page size after entering WAL mode.\u201d\u201cIn addition, WAL mode comes with the added complexity of checkpoint operations and additional files to store the WAL and the WAL index.\u201dhttps://www.vldb.org/pvldb/vol15/p3535-gaffney.pdfSQLite does not guarantee ACID consistency with ATTACH DATABASE in WAL mode. \u201cTransactions involving multiple attached databases are atomic, assuming that the main database is not \":memory:\" and the journal_mode is not WAL. If the main database is \":memory:\" or if the journal_mode is WAL, then transactions continue to be atomic within each individual database file. But if the host computer crashes in the middle of a COMMIT where two or more database files are updated, some of those files might get the changes where others might not.https://www.sqlite.org/lang_attach.htmlreplypolyrand 1 day ago | root | parent | prev | next [\u2013]True, but I think there aren't many reasons to not run in WAL mode by default.replychasil 20 hours ago | root | parent | next [\u2013]Au contraire.replyteddyh 1 day ago | parent | prev | next [\u2013]You could replace \u2018dd\u2019 with \u2018cat\u2019 here, as in \u201cssh user@rsync.net \"cat > d_dump\"\u201d. The \u2018dd\u2019 command has absolutely no reason to be used in the vast majority of cases.replysitkack 20 hours ago | root | parent | next [\u2013]What is the computational difference between cat and dd?replyteddyh 19 hours ago | root | parent | next [\u2013]AFAIK, \u2018dd\u2019 reads and writes a block at a time (whatever the its default block size is), while \u2018cat\u2019 uses whatever buffer sizes it thinks is the most efficient for the devices it is using for that invocation.replytroyjfarrell 1 day ago | parent | prev | next [\u2013]I believe that you can echo the '.dump' command to SQLite.  echo .dump | sqlite3 db | ssh user@rsync.net \"dd of=db_dump\"It worked for me.replyrsync 16 hours ago | root | parent | next [\u2013]Thanks!I have added that one-liner to the remote commands page:https://www.rsync.net/resources/howto/remote_commands.html... although based on some of your siblings, I changed .dump to .backup ...replydmw_ng 1 day ago | root | parent | prev | next [\u2013]You can also pass special commands in the second argument to SQLite:sqlite3 db .dump | ...replythrowawaaarrgh 1 day ago | parent | prev | next [\u2013] sqlite3 my_database .dump | gzip -c | ssh foo \"dd of=db_dump\"Technically .backup is better because it locks less and batches operations, rather than doing a bunch of selects in a transaction. Do you prefer slowly filling up local disk or locking all writes?replycomex 1 day ago | parent | prev | next [\u2013]You can pass console commands as arguments:  sqlite3 /path/to/db.sqlite .dumpreplyjamietanna 1 day ago | parent | prev | next [\u2013]Couldn't you also just `cp` the SQLite DB file?replyidoubtit 1 day ago | root | parent | next [\u2013]In many cases, `cp` on the DB file won't be enough. For instance, when WAL (Write Ahead Logging) is enabled (which is much faster than the old rollback journal), some data may lie in other files aside the main DB.I once had a problem where my application couldn't read from a SQLite DB whose file was read-only. Turned out that even a read-only access to the DB required a write access to the directory, for a WAL DB. This was partly fixed years later, but I'd learned the hard way that a SQLite DB may be more than a single file.replychasil 20 hours ago | parent | prev | next [\u2013]Why don't you write one? The whole API is presented in C.https://sqlite.org/c3ref/backup_finish.htmlreplybob1029 21 hours ago | prev | next [\u2013]The whole point of SQLite for me is to get the application code as close as possible to the block storage device without getting my hands too messy in the process. Latency is a major reason you'd consider using SQLite. Simplicity is right up there too.Putting the storage in the cloud is completely orthogonal to this ideology. Both latency & simplicity will suffer dramatically. I don't think I'd ever use this feature over something like Postgres, SQL Server or MySQL.replycodethief 17 hours ago | parent | next [\u2013]> Putting the storage in the cloud is completely orthogonal to this ideology. Both latency & simplicity will suffer dramatically.I'm confused by your usage of the term \"orthogonal\". In my experience, it is used to express that something is independent of something else, similarly to how in mathematics orthogonal vectors are linearly independent and thus form a basis of their linear span. Here, however, it seems you mean to say that \"putting storage in the cloud runs counter to this ideology\"?replycaseyohara 10 hours ago | root | parent | next [\u2013]I see \"orthogonal\" used quite frequently on HN. I remember reading a comment here that explained it something like:> Ironically, the meaning of \"orthogonal\" has become orthogonal to the real meaning because now it can mean both \"perpendicular\" and \"parallel\", both \"at odds\" and \"unrelated\"Edit: found it https://news.ycombinator.com/item?id=1997093 (my memory was pretty close)replymcculley 20 hours ago | parent | prev | next [\u2013]I have some workflows where a SQLite database is built from data sets and then used read-only by multiple processes. I currently implement this by putting the SQLite file into S3 and copying it to the machines that need it. This will save the copy step.replyanyoneamous 1 day ago | prev | next [\u2013]Lots of people here talking about S3, and yet:> The system currently supports Azure Blob Storage and Google Cloud Storage.I'd interpret that as either a hard \"fuck you\" to AWS, or a sign that the S3 API is somehow more difficult to use for this purpose.replymbreese 20 hours ago | parent | next [\u2013]I thought it was a sign of who paid for the feature. I have no insight as to whether or not this is true, but leaving out S3 made me assume either Google or Microsoft (or a third party heavily tied to one of these clouds) paid for this to be added.replystevefan1999 1 day ago | parent | prev | next [\u2013]I highly suspect it would be the latter because if you just want to \"fuck\" S3 then you could just list Minio, Swift and Ceph RADOSGW support instead.replyFooBarWidget 1 day ago | parent | prev | next [\u2013]The S3 API doesn't have the concurrency control primitives necessary to guarantee consistency in the face of concurrent writes.I wrote a distributed lock on Google Cloud Storage. https://www.joyfulbikeshedding.com/blog/2021-05-19-robust-di... During my research it was quickly evident that GCS has more concurrency control primitives than S3. Heck S3 didn't even guarantee strong read-after-write until recently.replyfs111 1 day ago | root | parent | next [\u2013]> until recentlyAlmost 3 years https://aws.amazon.com/blogs/aws/amazon-s3-update-strong-rea...replyelectroly 13 hours ago | root | parent | prev | next [\u2013]While I'm sure you're right, this VFS implementation doesn't use any of that stuff. They just handwave concurrent writes away by saying the application has to ensure a single writer on its own. An S3 implementation appears to be planned; it's mentioned in the comments in the bcvmodule.c file.replyjanejeon 1 day ago | root | parent | prev | next [\u2013]Ah, I'm guessing that's the same reason why many \"cloud storage as a backend\" stuff (e.g. Terraform/Vault storage backends, Delta.io backends) require DynamodDB + S3replyfbdab103 1 day ago | prev | next [\u2013]It is not clear to me - is this an officially supported, core module? Or more, \"You can technically do this, but ehhhh\" kind of deal?Would this mean I might eventually be able to do something insane like run Datasette (from within Pyodide) against an external cloud storage?replybenatkin 1 day ago | parent | next [\u2013]It seems like they're taking a bottom-up approach. I can't see any link to it on the main site. It would probably first bubble up to the News page, like WebAssembly did on 2022-11-16. https://sqlite.org/news.html WebAssembly also has a URL inside the root that redirects to doc/trunk/www/index.wiki: https://sqlite.org/wasm/replyrickette 1 day ago | parent | prev | next [\u2013]It looks really promising, would also love to know the status of this. Can't find any announcements of this yet.replycaptn3m0 1 day ago | parent | prev | next [\u2013]I don't think the blob storage APIs (which this seems to be using, instead of accessing over the web-gateway urls) are CORS accessible. So you might have to proxy it.However, it might become possible to run datasette etc much more easily in an edge function.replyantonvs 20 hours ago | root | parent | next [\u2013]Both Google and AWS storage, at least, are CORS accessible:https://docs.aws.amazon.com/AmazonS3/latest/userguide/enabli...https://cloud.google.com/storage/docs/using-corsreplyelectroly 1 day ago | prev | next [\u2013]SQLite's VFS layer is flexible and easy-to-use. There are lots of implementations (public and private) of this \"use a SQLite database directly from cloud object storage\" idea because it's pretty obvious how to do it when you look at the VFS functions that you have to implement. If you do a read-only implementation, it's an afternoon project. It's mostly a matter of following the VFS docs and when you're about halfway done implementing the functions, SQL queries start working instead of producing errors. The only tricky bit, as always, is caching.replynoman-land 1 day ago | parent | next [\u2013]I used this[0] awesome library to do just this over http. I posted more info in my other comment. I'm still exploring but so far it's been pretty impressive to me.[0] https://github.com/phiresky/sql.js-httpvfsreplychasers 21 hours ago | prev | next [\u2013]> although ensuring that only a single client is writing to a database at any time is (mostly) left to the applicationSounds like trouble.replypachico 1 day ago | prev | next [\u2013]I am very puzzled by this. Wasn't the very point of Sqlite to be local? If it's not anymore, why would you prefer to use it rather than any other relational database?replymoonchrome 23 hours ago | parent | next [\u2013]How is this even comparable to other relational databases ?In this setup you use something like blobstore for public shared db access. Looks like single writer at a time.In traditional databases you connect to a database server.This is like having a cloud sync for your local app state - shared between devices on a cloud device.replydist-epoch 23 hours ago | parent | prev | next [\u2013]> Wasn't the very point of Sqlite to be localNot quite. The very point is not needing a server. Subtle difference.Think more data lake and less relational db.replyvbezhenar 1 day ago | prev | next [\u2013]I always wondered by never bothered to implement:What if I would implement an S3-backed block storage. Like every 16MB chunk is stored in a separate object. And filesystem driver would download/upload chunks just like it does it with HDD.And then format this block device with Ext4 or use it in any other way (LVM, encrypted FS, RAID and so on).Is it usable concept?replyDaiPlusPlus 1 day ago | parent | next [\u2013]What you're describing already exists in Azure Blob Storage (Azure's S3 compete), known as Page Blobs, which is also how you host VM HDDs (VHDs) in Azure, as it allows for page-level (i.e. disk-block-level) reads/writes.I'm not clued-in to AWS's equivalent, but a quick google suggests it's AWS EBS (Elastic Block Storage), though it doesn't seem to coexist side-by-side with normal S3 storage, and their API for reading/writing blocks looks considerably more complicated than Azure's: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-acce...replyyread 1 day ago | root | parent | next [\u2013]Their fuse-based filesystem driver even supported CACHED block access ie you would download, cache and read the blocks you needed locally instead of sending every read over the wire. Close to local fs performance for little spacereplyDaiPlusPlus 1 day ago | root | parent | next [\u2013]How does that handle concurrent writes to the same block? How is the cache invalidated?replymappu 1 day ago | root | parent | next [\u2013]The single FUSE process can coordinate all that with an in-memory mutex.This thread is in the context of filesystems like ext4, which are completely unsafe for concurrent mounts - if you connect from multiple machines then it will just corrupt horrifically. If your filesystem was glusterfs, moose/lizard, or lustre, then they have ways to handle this (with on-disk locks/semaphores in some other sector).replybob1029 21 hours ago | root | parent | prev | next [\u2013]Azure blob storage took me by surprise when I had to load a custom VHD. My experience with AWS/EC2/S3 led me to think it would take half a day or longer.Turns out, there's no transformation layers or anything. You upload the image using a special tool, it saturates your uplink for a few minutes, and before you can brew some more coffee the VM will be booting up.replyelectroly 1 day ago | root | parent | prev | next [\u2013]Behind the scenes, EBS Snapshots are stored in S3. When you first create an EBS volume from a snapshot, it pulls blocks from S3 on-demand.replydamagednoob 1 day ago | parent | prev | next [\u2013]Not sure if it's a usable concept but it sounds similar to what someone else did[1]:> ...I implemented a virtual file system that fetches chunks of the database with HTTP Range requests when SQLite tries to read from the filesystem...[1]: https://phiresky.github.io/blog/2021/hosting-sqlite-database...replykirubakaran 1 day ago | parent | prev | next [\u2013]https://github.com/s3fs-fuse/s3fs-fusereplyvbezhenar 1 day ago | root | parent | next [\u2013]It uses S3 as a filesystem. I'm talking about using S3 as a block device. Slightly different approach.replyfranky47 1 day ago | parent | prev | next [\u2013]Sounds like a very expensive way to build a filesystem.replycbluth 1 day ago | parent | prev | next [\u2013]Yes, its called s3backerreplyvbezhenar 1 day ago | root | parent | next [\u2013]Thanks, that's the thing.replycandiodari 1 day ago | parent | prev | next [\u2013]https://github.com/s3fs-fuse/s3fs-fuse/wiki/Fuse-Over-AmazonSeems like a usable concept yes.replywg0 23 hours ago | prev | next [\u2013]Why would I use it over Litestream?replyaembleton 23 hours ago | parent | next [\u2013]Because the DB you need to access might be too large for your device to downloadreplyinfamia 18 hours ago | parent | prev | next [\u2013]You could use it in coordination with Litestream as a failover or read replica. It would be a lot slower, but maybe that would be an OK tradeoff for certain use cases.replyup2isomorphism 1 day ago | prev | next [\u2013]Linus had once said database people seldom have good taste, I have to agree with him in this case.replyschemescape 1 day ago | prev | next [\u2013]Edit: I misread the date, as pointed out in a reply.Why does the forum say some messages are from 19 years ago?https://sqlite.org/cloudsqlite/forumreplybenatkin 1 day ago | parent | next [\u2013]Because they really are years old, and not days old.Except it's 1.19 years ago.And the oldest one is from 2020. https://sqlite.org/cloudsqlite/forumpost/da9d84ff6eIt might be announced recently, but it has been under development for a while.replyTekMol 1 day ago | prev | next [\u2013]I guess you could just proxy a normal SQLite DB?Should take only a few lines of PHP. Maybe just one:  echo DB::select($_GET['query']);All that is needed is a VM in the cloud. A VM with 10 GB is just $4/month these days.And you can add a 100 GB volume for just $10/month.replyjdthedisciple 21 hours ago | prev | next [\u2013]Hmm seems like a more complicated setup than a classic WebAPI-based architecture with PostgreSQL/MySQL, with no apparent benefit.Anyone care to prove me wrong?replyapi 20 hours ago | prev [\u2013]Make a plugin to put this in FoundationDB or TiKV. That'd be pretty interesting.replyGuidelines | FAQ | Lists | API | Security | Legal | Apply to YC | ContactSearch:",
    "hn_summary": "- 'Cloud Backed SQLite' allows for serving large SQLite databases in chunks and querying them with HTTP range requests.\n- A library called sql.js-httpvfs does most of the work for chunking up and uploading the database to GitHub Pages.\n- People are excited about the speed and efficiency of SQLite as a read-only database option for large datasets with no server infrastructure overhead."
  },
  {
    "id": 36612835,
    "timestamp": 1688631420,
    "title": "Backend of Meta Threads is built with Python 3.10",
    "url": "https://twitter.com/llanga/status/1676846870520291329",
    "hn_url": "http://news.ycombinator.com/item?id=36612835",
    "content": "Due to Twitter's new pricing structure, we made a difficult choice to restrict the option of unrolling tweets on the web to Premium members only. You can still unroll tweets for free by visiting Twitter and replying to the tweet with \"@threadreaderapp unroll.\" We appreciate your understanding!Thread ReaderOne-click sign-up and loginSign up or login to access your unrolled and bookmarked threads (or PDF archives if you are a Premium member!)Login with TwitterLogin with EmailLogin above to accept Thread Reader App'sTerms of Service and Privacy PolicyHelp | About | TOS | Privacy | Twitter Files",
    "summary": "- Twitter's new pricing structure has led to a restriction on the option to unroll tweets on the web, which is now only available for Premium members.\n- Users can still unroll tweets for free by visiting Twitter and replying to the tweet with \"@threadreaderapp unroll.\"\n- The change in availability of unrolling tweets on the web is due to the new pricing structure and is aimed at encouraging users to become Premium members.",
    "hn_title": "Backend of Meta Threads is built with Python 3.10",
    "original_title": "Backend of Meta Threads is built with Python 3.10",
    "score": 419,
    "hn_content": "- The backend of Meta Threads, a social networking app, is built with Python 3.10.\n- It is notable that Meta Threads is from the same company that created the largest social network built on PHP + MySQL.\n- Facebook has made significant engineering improvements to make their backend infrastructure scale, including schema sharding and a massive caching layer.\n- Facebook scaled to billions of daily active users using MySQL + InnoDB, with lots of engineering work and optimizations.\n- Facebook backed up their data every day using an unmodified mysqldump and tested disaster recovery setups.\n- Facebook uses a distributed approach to backups using small individual databases and replaying binlogs.\n- The decision to choose PHP and Python for large-scale projects like Facebook and Instagram was due to various factors such as the scalability of existing codebases and availability of libraries.\n- Django is used as the web framework for the Threads app, which was originally written in Django and is a well-established and powerful framework.\n- The choice of language for web servers (like Django or Flask) is less important compared to the performance of the database for large social networking apps.\n- The backend of Threads is running on Instagram's #Cinder fork of Django, which includes a JIT, lazy-loaded modules, and other optimizations for Python 3.10.\n- It's important to note that Threads is a new app that was rushed to market quickly, and engineering improvements may be made in the future.\n- Links to Threads can be shared, but currently require the Threads app to be installed to access the content.-Threads is a mobile-only app, similar to Instagram, and cannot be used on a desktop browser.\n-The lack of a web interface has been a point of criticism.\n-Threads does have a read-only browser view, but it is limited in functionality.\n-Currently, there is no top-level page for searching or browsing on Threads' website.\n-Threads launched in more than 100 countries, but not in any EU countries.\n-People have compared Threads' restrictions to Instagram's limitations on viewing without an account.\n-There is anticipation for a full-featured web version of Threads in the future.\n-It is suggested that a web version of Threads could be developed within a year, based on Instagram's timeline.\n-Twitter used to have a similar restriction to Instagram on viewing content without an account.\n-Threads has been in development for about 6 months and a web interface is expected to be part of the roadmap.\n-Some users find the lack of a web interface after 6 months of development disappointing.",
    "hn_summary": "- Meta Threads, a social networking app, has its backend built with Python 3.10.\n- The choice of language for web servers is less important compared to the performance of the database for large social networking apps.\n- There is anticipation and disappointment regarding the lack of a web interface for Threads, with hopes for a full-featured web version in the future."
  },
  {
    "id": 36616398,
    "timestamp": 1688653789,
    "title": "LEGO Building Instructions",
    "url": "https://archive.org/details/lego-set-instructions",
    "hn_url": "http://news.ycombinator.com/item?id=36616398",
    "content": "Skip to main contentSearch icon An illustration of a magnifying glass.UPLOAD ICON AN ILLUSTRATION OF A HORIZONTAL LINE OVER AN UP POINTING ARROW. UPLOADUSER ICON AN ILLUSTRATION OF A PERSON'S HEAD AND CHEST. SIGN UP | LOG INBOOKSVIDEOAUDIOSOFTWAREIMAGESABOUT BLOG PROJECTS HELP DONATE DONATE ICON AN ILLUSTRATION OF A HEART SHAPE CONTACT JOBS VOLUNTEER PEOPLELEGO Building InstructionsA dump of all available building instruction booklet PDFs from the LEGO website (As of March 2023)shareShareNo_FavoriteFavoriterssRSSplayPlay AllABOUTCOLLECTION6,854 RESULTSMetadataText contentsMedia TypeYearTopics & SubjectsCollectionCreatorLanguageup-soliddown-solidSORT BY VIEWSTITLEDATE PUBLISHEDCREATOR10276 - Colosseum - Building Instructionstextseye237favorite1comment04440 - Forest Police Station - Building Instructionstextseye141favorite0comment075810 - The Upside Down - Building Instructionstextseye151favorite0comment011011 - Bricks and Animals - Building Instructionstextseye58favorite0comment041945 - Neon Tiger Bracelet & Bag Tag - Building Instructionstextseye123favorite0comment060076 - Demolition Site - Building Instructionstextseye102favorite0comment010279 - Volkswagen T2 Camper Van - Building Instructionstextseye103favorite0comment021046 - Empire State Building - Building Instructionstextseye93favorite0comment060336 - Freight Train - Building Instructionstextseye130favorite0comment07939 - Cargo Train - Building Instructionstextseye114favorite0comment060325 - Cement Mixer Truck - Building Instructionstextseye153favorite0comment041704 - Main Street Building - Building Instructionstextseye135favorite0comment010309 - Succulents - Building Instructionstextseye233favorite0comment010859 - My First Ladybug - Building Instructionstextseye134favorite0comment071244 - Sonic the Hedgehog\u2122 Level Pack - Building Instructionstextseye146favorite0comment021124 - The End Portal - Building Instructionstextseye54favorite0comment031198 - The Beatles - Building Instructionstextseye120favorite0comment04954 - Model Townhouse - Building Instructionstextseye95favorite0comment011014 - Bricks and Wheels - Building Instructionstextseye58favorite0comment041700 - Beach Glamping - Building Instructionstextseye102favorite0comment060022 - Cargo Terminal - Building Instructionstextseye68favorite0comment010269 - Harley-Davidson\u00ae Fat Boy\u00ae - Building Instructionstextseye93favorite0comment010497 - Galaxy Explorer - Building Instructionstextseye135favorite1comment010273 - Haunted House - Building Instructionstextseye112favorite0comment021332 - The Globe - Building Instructionstextseye43favorite0comment010297 - Boutique Hotel - Building Instructionstextseye106favorite0comment070425 - Newbury Haunted High School - Building Instructionstextseye133favorite0comment021321 - International Space Station - Building Instructionstextseye136favorite0comment021317 - Steamboat Willie - Building Instructionstextseye87favorite0comment042031 - Cherry Picker - Building Instructionstextseye107favorite1comment021308 - Adventure Time\u2122 - Building Instructionstextseye95favorite0comment075343 - Dark Trooper\u2122 Helmet - Building Instructionstextseye114favorite0comment021306 - Yellow Submarine - Building Instructionstextseye117favorite0comment07992 - Container Stacker - Building Instructionstextseye52favorite0comment060131 - Crooks Island - Building Instructionstextseye84favorite0comment011009 - Bricks and Lights - Building Instructionstextseye104favorite0comment040632 - Aragorn\u2122 & Arwen\u2122 - Building Instructionstextseye90favorite0comment010314 - Dried Flower Centerpiece - Building Instructionstextseye74favorite0comment017101 - Creative Toolbox - Building Instructionstextseye98favorite0comment010292 - The Friends Apartments - Building Instructionstextseye137favorite0comment010867 - Farmers' Market - Building Instructionstextseye33favorite0comment011003 - Bricks and Eyes - Building Instructionstextseye116favorite0comment031125 - Fantasy Forest Creatures - Building Instructionstextseye126favorite0comment040548 - Spice Girls Tribute - Building Instructionstextseye88favorite0comment031034 - Future flyers - Building Instructionstextseye43favorite0comment060221 - Diving Yacht - Building Instructionstextseye43favorite0comment06869 - Quinjet Aerial Battle - Building Instructionstextseye138favorite0comment011019 - Bricks and Functions - Building Instructionstextseye98favorite0comment060306 - Shopping Street - Building Instructionstextseye120favorite0comment010294 - Titanic - Building Instructionstextseye172favorite0comment010265 - Ford Mustang - Building Instructionstextseye77favorite0comment021310 - Old Fishing Store - Building Instructionstextseye50favorite0comment031081 - Modular Skate House - Building Instructionstextseye88favorite0comment04893 - Revvin' Riders - Building Instructionstextseye52favorite0comment060204 - LEGO\u00ae City Hospital - Building Instructionstextseye115favorite0comment060262 - Passenger Airplane - Building Instructionstextseye136favorite0comment042148 - Snow Groomer - Building Instructionstextseye37favorite0comment010262 - James Bond\u2122 Aston Martin DB5 - Building Instructionstextseye87favorite0comment010264 - Corner Garage - Building Instructionstextseye43favorite0comment021045 - Trafalgar Square - Building Instructionstextseye76favorite0comment071360 - Adventures with Mario Starter Course - Building Instructionstextseye60favorite0comment010290 - Pickup Truck - Building Instructionstextseye87favorite0comment010306 - Atari\u00ae 2600 - Building Instructionstextseye97favorite0comment010242 - MINI Cooper - Building Instructionstextseye91favorite0comment03677 - Red Cargo Train - Building Instructionstextseye201favorite0comment08109 - Flatbed Truck - Building Instructionstextseye45favorite0comment040547 - Obi-Wan Kenobi\u2122 & Darth Vader\u2122 - Building Instructionstextseye86favorite0comment031143 - Birdhouse - Building Instructionstextseye46favorite0comment076069 - Mighty Micros: Batman\u2122 vs. Killer Moth\u2122 - Building Instructionstextseye72favorite0comment021311 - Voltron - Building Instructionstextseye90favorite0comment021320 - Dinosaur Fossils - Building Instructionstextseye109favorite0comment031131 - Downtown Noodle Shop - Building Instructionstextseye115favorite0comment08258 - Crane Truck - Building Instructionstextseye95favorite0comment010302 - Optimus Prime - Building Instructionstextseye62favorite0comment010268 - Vestas Wind Turbine - Building Instructionstextseye67favorite0comment0",
    "summary": "- This post contains a dump of all available building instruction booklet PDFs from the LEGO website as of March 2023.\n- The PDFs include instructions for various LEGO sets such as the Colosseum, Forest Police Station, The Upside Down, and many more.\n- This is a valuable resource for LEGO enthusiasts and builders who can access step-by-step instructions for building different LEGO sets.",
    "hn_title": "LEGO Building Instructions",
    "original_title": "LEGO Building Instructions",
    "score": 385,
    "hn_content": "Hacker News new | past | comments | ask | show | jobs | submit loginLEGO Building Instructions (archive.org)385 points by micah_chatt 19 hours ago | hide | past | favorite | 138 commentsJNRowe 19 hours ago | next [\u2013]I sincerely applaud everything ending up on IA. However, if you're searching for specific instructions brickinstructions is excellent as it is far more navigable. For a random example see Starguider\u00b9. I wonder if someone has already scraped that site for IA, beyond simply praying to the Wayback Machine.\u00b9 https://lego.brickinstructions.com/m/lego_instructions/set/6...replyinternetter 19 hours ago | parent | next [\u2013]Yes, we archived the entire thing in 2020[0] (~100gb). Maybe it's worth running again.[0]: https://archive.fart.website/archivebot/viewer/job/avladEdit: What this means is you can open any* link to lego.brickinstructions.com and see it in the wayback machine (IA ingests these archives)*maybe not the mobile view you linked, not links after the job ran, not pages that couldn't be found in a crawlreplyJNRowe 13 hours ago | root | parent | next [\u2013]That is great. I could see a lot it was in the wayback machine, but I have no idea what the pipeline for that is. Poking around from your link was informative, thanks!replyFeteCommuniste 16 hours ago | parent | prev | next [\u2013]Wow, that just gave me a crazy flash of nostalgia. I think I must have had this set, or at least a very similar one.replyLoic 2 hours ago | root | parent | next [\u2013]https://lego.brickinstructions.com/en/lego_instructions/set/...I played so many hours with this one...replykevinob11 12 hours ago | root | parent | prev | next [\u2013]Whoa, WHOA, I could never have named or described this but it suddenly felt like I was 8 hoping for specific christmas gifts again.replymulmen 7 hours ago | root | parent | next [\u2013]I admit to being a total sucker for Star Wars LEGO but I do love the classic sets with no \u201clore\u201d. It\u2019s some kind of space truck. People probably need trucks in space right? You figure it out kid.replyetimberg 10 hours ago | root | parent | prev | next [\u2013]Same! Just found the instructions for a set I remember getting as a kid. https://lego.brickinstructions.com/en/lego_instructions/set/...I think the lego itself is still somewhere at my parents place, but the instructions were lost long agoreplylukebbutton 14 hours ago | root | parent | prev | next [\u2013]Same, it hit hardreplyfxtentacle 15 hours ago | root | parent | prev | next [\u2013]me too :)replyel_benhameen 17 hours ago | parent | prev | next [\u2013]Thank you for sharing this. I\u2019m going to show it to my 6 year old and he\u2019s going to lose his mind. Great way to make use of my massive box of childhood legos and empty summer hours.replybombcar 17 hours ago | root | parent | next [\u2013]There is/was a website where you could upload all your parts and it would tell you what you could build.replydunham 14 hours ago | root | parent | next [\u2013]There is a app for that too, which works off of a photo of your parts: https://brickit.app/replytspike 16 hours ago | root | parent | prev | next [\u2013]Rebrickable. Very much still alive.replykazinator 18 hours ago | parent | prev | next [\u2013]When brickinstructions goes belly up, or just messes up its URLs for shits and giggles, you will need to go through archive.org to find out what used to be at that URL.replythe__alchemist 10 hours ago | parent | prev | next [\u2013]Oh my god. I thought I was such a big deal when I first saw that one - It was marked ages 6+, but I was a solid 4 or 5.replyWaterluvian 18 hours ago | prev | next [\u2013]My kids being 4 and 6 means we\u2019re full into Lego. I grew up with two brothers so we have like three hundred pounds of it. But lost most of the instructions.It\u2019s been amazing to go online and find any instruction and re-assemble these kits.It also made me realize something: half the value of buying a kit these days is that you aren\u2019t spending hours finding needles in a 300lb haystack.replykroltan 18 hours ago | parent | next [\u2013]> It also made me realize something: half the value of buying a kit these days is that you aren\u2019t spending hours finding needles in a 300lb haystack.What! That is the best part!Wading through a mound of Lego has to be one of the most satisfying sounds I know, the clatter of a bajillion pieces of precision plastic, each with their different cavities and sonority, moving around each handful you scrape off to the side... Good times.In the rare occasion I get a Lego set nowadays (no kids yet), the first thing I do is open every bag of pieces into a tray so I can do it on a smaller scale.replymirkules 17 hours ago | root | parent | next [\u2013]> no kids yetYou will know no fury as when your kids intentionally mix up all the pieces for fun. We have hundreds of LEGO people, and my kids intentionally dismembered them into their individual pieces (including HANDS!). But how can you get angry at kids playing??? twitchreplynimajneb 16 hours ago | root | parent | next [\u2013]My daughter will be getting her own Lego and possibly a selection of mine. I organized mine for the first time in my life last year. Some of the sets I've had since the very late 80s and early 90s. Those aren't getting lost :PShe can play with them supervised, but she'll have her own. This is all assuming she's even interested, she's only 2 so who knows yet.replyTade0 14 hours ago | root | parent | next [\u2013]Mine is also two and really into Duplo, so Lego will be a natural progression, especially considering that the blocks are compatible, so I wholeheartedly recommend it.Also some the ones she's playing with are currently over 30 years old and still going.replyjmmv 15 hours ago | root | parent | prev | next [\u2013]It sounds like you should watch The Lego Movie (:replyBanazirGalbasi 14 hours ago | root | parent | next [\u2013]I think having sets that you like to keep together and you don't want to mix up is fine. Too many people saw the Lego Movie and took it to mean that keeping sets as sets is bad. Note that the person you responded to isn't stopping their kids even as they cause more destruction than the Lego Movie showed, they're simply complaining about it here because what _they_ had is gone.Yes, let kids mix and match and play. But also acknowledge that we all play differently, and for some people having a model of something that they built is where the fun lies. People who like organization can still have fun, let's not shame them for their preferences.replyjmmv 5 hours ago | root | parent | next [\u2013]Uhhh... the GP was written in a kinda funny way, so it just seemed fitting to plug a reference to the movie. If you want to keep sets together, power to you. My kids have a mixture of both (sets they want to keep as is and a mountain of pieces from other sets) and... that's just fine.replyfragmede 1 hour ago | root | parent | next [\u2013]That sounds... reasonable! We can't have that! Lord Business? Bring out the Kragle!replydavely 16 hours ago | root | parent | prev | next [\u2013]> Wading through a mound of Lego has to be one of the most satisfying sounds I knowMy friend, let me introduce you to this Spotify playlist: LEGO White Noise [1][1] https://open.spotify.com/album/6qZUya0mkucuxvoIp4akVT?si=RgH...replyfluxinflex 13 hours ago | root | parent | next [\u2013]That made my day! That's soooo incredibly unbelievably mindnumbingly stupid that I love it :+1:replyjjkaczor 18 hours ago | root | parent | prev | next [\u2013]The sound of swishing through a mound/box/bin of LEGO has to be the most relaxing thing for me ever...replybombcar 17 hours ago | root | parent | next [\u2013]The word 'Gr\u00fcschteling' is a German word used by German Lego fans. It is used to describe the distinctive sound made when you sift through a large bucket of Lego, trying to find the right piece.replylukebbutton 14 hours ago | root | parent | next [\u2013]My grandfather used to say that whenever we played lego as kidsreplyWaterluvian 18 hours ago | root | parent | prev | next [\u2013]I looooove that sound. But with young kids there\u2019s no point trying to sort. And without sorting, every piece takes a while to find.replyepiccoleman 18 hours ago | root | parent | next [\u2013]One of my \"core memories\" wrt Lego is meticulously spending days sorting small parts into some of those Sterilite multi-drawer things and then knocking it over, spilling all my hard work onto the floor and undoing it.I was probably 8 or 9. From that point on, fuck it, they all go in one big box. My brothers and I would compete to see who could find the most valuable pieces. Mostly treasure chest coins, little gems, and basically anything translucent qualified - transparent single stud pieces, cone pieces, and lightsaber beams were very high value, since one could not build a respectable Lego sci-fi arsenal without all of them.replyTylerE 3 hours ago | root | parent | next [\u2013]I'm guessing that back in the day it all came in one bag?When I built Titantic last year (first Lego I'd done in maybe 30 years) it was split out over dozens of small bags, and all the parts you'd need for one section would be in that one bag with no more than, say, 200 pieces in it. Often there's be a smaller bag inside for holding the 1x1 stuff.So I built the whole thing with two tupperware containers..one decent size square \"bowl\" and s much smaller one for the tiny stuff.Killed a month off and on putting that thing together. I was recovering from foot surgery so stuck in bed.Luckily, the Titanic actually builds as 6 sections, with 3 pairs that join more or less permanently, while there are then a couple of pins and rods that hold the whole thing together (along with a rather clever tensioning gear... the main lines are there as strings, and do hang in a true catenary. )So each of the 6 sections I basically built on a hardback book.A few build pics:https://imgur.com/a/yqHR3m4Made for a very doable build, even given pretty hefty physical limitations.replykroltan 17 hours ago | root | parent | prev | next [\u2013]Ha! That was a common competition between me and my friend around that age too.He is very fortunate to be part of a reasonably affluent family, so he had like 6 60-liter boxes full of assorted Lego.We would spill a couple at a time (who am I kidding we spilled all of them) on the floor, when the flow of pieces stopped, the game was on! So many arguments about the nature of the simple shapes, like \"oh no this isn't a blue lightsaber, it is a cylinder of pure diamond!\"replydsr_ 17 hours ago | root | parent | prev | next [\u2013]My wife says that sound means that I'm happy and relaxed.replykevmarsden 18 hours ago | root | parent | prev | next [\u2013]I'm totally the opposite. That sound is grating to me. But I'm sensitive to other sounds too, so it's not just LEGO.replygertlex 18 hours ago | root | parent | prev | next [\u2013]I recently had the realization... I've carried this enjoyment onwards into how I store parts for hobbies. While I use compartmentalized containers for things, compartments are still a mix of parts. I can search for quite a while without getting frustrated, just knowing, \"those servo mounting brackets are in one of these two containers in the garage...\"I don't buy or aspire to own new Lego as an adult, but I'm still basically doing the same thing I did as a kid: every time I decide to do a hardware project is me digging through my bins of assorted parts instead Lego parts.Oh and of course, my desk is perpetually just as messy as the floor was as a kid, and I'm often fidgeting seeing how random things do/don't fit together.(also, also... building the set? nah, building my own things without instructions, and similarly writing my own code...)replylcnPylGDnU4H9OF 18 hours ago | root | parent | prev | next [\u2013]There's someone who's really into knolling (https://knolling.org/what-is-knolling) and hates this comment.replysemi-extrinsic 12 hours ago | root | parent | next [\u2013]Always Be Knolling.replylostlogin 14 hours ago | root | parent | prev | next [\u2013]> Wading through a mound of Lego has to be one of the most satisfying sounds I knowThere are two sounds I associate with Lego. The one you describe and the other.The words you can find and the tone you utter them with when you unexpectedly stand on a piece, or even better, when you kneel on a bit when trying to find the tv remote.replypbronez 16 hours ago | root | parent | prev | next [\u2013]Agree! My partner disagrees though. She wants the LEGO organized by color or set. I find this blasphemous. It\u2019s legit harder for me to find pieces when they\u2019re sorted like this. My brain is tuned with specialized LEGO bin stirring techniques that reliably turn up what I need\u2026 but that doesn\u2019t work at all when the piece has been squirreled away where it \u201cbelongs\u201d!replysuddenclarity 18 hours ago | parent | prev | next [\u2013]> It also made me realize something: half the value of buying a kit these days is that you aren\u2019t spending hours finding needles in a 300lb haystack.It's a bit of work but I found enjoyment in sorting my old childhood Lego. Don't do colors, do categories (bricks, slopes, plates, etc). Once done, I could complete my old childhood models even faster than the unsorted ones you buy new. It also lowers the threshold to break it down and build something else since it's so easy to find the parts. On the downside, it takes more space than a single bin.replypbronez 16 hours ago | root | parent | next [\u2013]Absolutely categories are better than colors. It doesn\u2019t LOOK as pretty but it\u2019s way more functional.replyfragmede 1 hour ago | root | parent | next [\u2013]https://xkcd.com/2791replypaulryanrogers 18 hours ago | parent | prev | next [\u2013]> ...half the value of buying a kit these days is that you aren\u2019t spending hours finding needles in a 300lb haystack.My guess is that is why techies keep inventing their own Lego sorting machinesreplym3kw9 16 hours ago | parent | prev | next [\u2013]You need a rule that you cannot mix more than 2000 pieces from different kits. Basically 1/3 of those organizer boxes. A balance between search ability and organization, otherwise you get in these situations where it\u2019s not feasible to rebuild a kit that you have, it\u2019s like mixing different engine parts and expect to build that same enginereplyomoikane 15 hours ago | parent | prev | next [\u2013]> you aren't spending hours finding needles in a 300lb haystack.I guess that's for people who have a specific thing in mind that they wanted to build. I find a lot fun just picking out random pieces and then thinking about where to attach them afterwards.replycortesoft 14 hours ago | parent | prev | next [\u2013]My kids never want to build the instruction versions, they only want to make their own designs.replycelticninja 18 hours ago | parent | prev | next [\u2013]Get the brickit app, saves some timereplymarak830 18 hours ago | root | parent | next [\u2013]I disagree. A whole bunch about Lego is the search. I was recently reintroduced by my son (5) and the fun of searching for what we want to try to complete a build - and occasionally redesigning due to what we find - is amazing.Also helps him learn to adjust on the fly, which is a great thing to learn at a young age.replyLeifCarrotson 17 hours ago | root | parent | next [\u2013]I have been building with my 6yo, and he has the traditional giant bin where all the sets of Creator pack of assorted bricks, plus the sets from Ninjago and Spider Man and Minecraft and various cars and so on all get disassembled after about 3 days for him to dig through.More recently, I also got out my old boxes of Knex, which I'd put away a decade ago by sorting the parts by color into about a dozen quart-size ziploc bags (there are far fewer variants of Knex than of Lego, even ignoring the myriad custom tiles and stickers). He was THRILLED to have them all sorted, and for more than a month now - probably a dozen sessions of use - has put them back in the right bags. It's like pulling teeth to get him to keep his art supplies organized, those can just be piled in a heap, it can take two hours for him to do his laundry, typical playtime with friends is an explosion of toys from bins, but it is critical that the Knex go in the right bag even during use.After seeing that, I got a compartmentalized organizer that used to hold fishing tackle, dumped all the tackle in the big tackle box, and washed it, and he has been keeping \"the good Legos\" in that. If you're curious, it turns out that the good Lego are the wheels, propellers, blocks with pins to connect to those wheels and propellers, the Technik couplers, the Ninjago transparent flames, especially the Ninjago spring-loaded bolt gun thing, and the Minecraft character heads Not the character bodies, not the Iron Man head, not even the ones that look like him and Mom and Dad, just Minecraft heads - everything else can go in the bin. I think he made a good selection, builds just seem to go together faster when those parts are available. In particular he used to need help on occasion to find the right wheels - everything seems to need wheels - and now he has them.God I hope he's more organized and tidy than me.replyWaterluvian 18 hours ago | root | parent | prev | next [\u2013]I\u2019ll have to check it out again. Last time it looked like it wanted a subscription.I would just like to pay once for an app that 100% offline scans for blocks. Let me pick an instruction book and begin pointing out pieces to me that belong in the set.Fingers crossed.replysamstave 16 hours ago | parent | prev | next [\u2013]>>*half the value of buying a kit these days is that you aren\u2019t spending hours finding needles in a 300lb haystack.*Are you NUTS?Are you trying to shame my 1980s values with LEGO?\"I KNOW that FN piece is in here!!!! I JUST SAW IT!!!!\"You're robbing your kids of a life lesson. and better image recognition, memory, sorting processing thoughts, etc.There are so many lessons embedded in working with LEGO that can only be learnt through the frustration of a F-ton of brix in a bin and your looking for that specific 1x2 -- or worse yet, 1x1 smooth piece.I used to buy things in bulk from LEGO at the mall in San Jose and just have bins of smooth pieces and other were parts...replyusefulcat 12 hours ago | root | parent | next [\u2013]I get what you're saying, but in a large pile, finding the right piece is easily 10x harder now because the number of unique LEGO parts is much, much higher than when you and I were kids.replysamstave 12 hours ago | root | parent | next [\u2013]Ah, I mis-interpreted that.. and I agree. I hate the custom/uniques that lego builds with some lame co-branding like a movie with DC/Marvel....Lego is by default the foundationaly builing block.I HATE custom pieces to a lego set.replyroryisok 14 hours ago | prev | next [\u2013]Lego themselves have an archived copy of every instruction set going back to the 80s, available here - https://www.lego.com/en-us/service/buildinginstructionsBut for whatever reason, the scans are poor quality and very dark, and it can be hard to make out what piece is which. These ones look much betterreplyaleph_minus_one 11 hours ago | parent | next [\u2013]> Lego themselves have an archived copy of every instruction set going back to the 80s, available here - https://www.lego.com/en-us/service/buildinginstructionsThis can't be true: I am very sure that there exist Lego Technic models from before 1996, which is the oldest year that can be selected.replysuddenclarity 2 hours ago | root | parent | next [\u2013]Indeed, doing an empty search only returns sets from 1996 and forward. Not even entering set numbers from my childhood (pre -96) return any results.replyjamesfinlayson 9 hours ago | parent | prev | next [\u2013]In the past I've used that site to get instructions from the late 1990s and early 2000s and I thought they were proper archives (not scans).replyphotonerd 18 hours ago | prev | next [\u2013]Probably an age thing, but I\u2019ve never understood the point of Lego instructions. Or the sets.The whole point of Lego was creative free form building. Remove that & it\u2019s dull as hell. It just becomes model building with poor quality models as the result.I\u2019m happy other people find it fun, but to me it misses the entire point in favor of weak licensed \u201ckits\u201d.replyepiccoleman 17 hours ago | parent | next [\u2013]For us growing up, the point of the sets was that you got a cool spaceship or whatever, which you would put your personal Lego guy into, park near your \"base\", and play with until some other project demanded the parts. Then it would be disassembled mercilessly and consigned to the bin as grist for the constantly evolving construction project laid out on our much-abused air hockey table.If a set was a particularly cool build, we might disassemble it and then rebuild it - but most of the time, once something got taken apart, no one was ever going to bother trying to reconstruct it from the manual, since doing so would have involved finding all 500 necessary pieces in the mega-bin.replydsr_ 18 hours ago | parent | prev | next [\u2013]My own take:Some people want to play with playsets. Some people want to display models. Some people want to create art. Some people want to construct machines. Some people want to assert allegiance. Some people want to collect.All of these aims are valid. The diversity of ways to buy LEGO supports them all, while maintaining a high-quality, largely compatible, reasonably consistent medium.replybluetomcat 18 hours ago | root | parent | next [\u2013]In recent years, there is a general drift towards \"collectible display models\". This means that the piece count in most sets is inflated by a majority of small \"finishing\" pieces. The models are finicky to build with lots of unusual building techniques (attaching bricks on sidewalls, for example) and are not easy to repurpose into something else in a reasonable amount of time.In the 1990s, it was a \"construction toy\" first, playset second, display model last. A kid could take any set and rebuild it into something else in an hour or so. Now, they would need more time only to sort the tiny 1x1 pieces before starting to build anything.replyrkangel 17 hours ago | root | parent | next [\u2013]> In recent years, there is a general drift towards \"collectible display models\"I think there is an actually an \"addition\" here rather than a change. You're an adult conversing with adults (I assume) and therefore the discussions you have and the marketing you see are more about sets targeted to AFOLs (Adult Fans of Lego).The classic Lego childhood lines (Lego City) still exist and still work just as well for play and creative construction as they ever did - and they don't use a lot of 1x1s. It's just that we've also gained these new lines of large adult sets that never used to exist.replybluetomcat 17 hours ago | root | parent | next [\u2013]Even the vehicles in 5+ City sets are affected by this trend. It takes about 50 parts stacked in intricate ways just to build the base chassis structure of a van, for example.In the 1990s, Town vehicles were 4-stud wide and didn't focus on the small detailing. The instructions for the original vehicle were just a single sheet of paper with less than 20 steps. You could build the original vehicle by memory after having built it a couple of times with instructions. The back of the box suggested alternative builds, which, although looking \"imperfect\" were a solid base for imagination.replyrkangel 16 hours ago | root | parent | next [\u2013]There is a good range of \"3-in-1\" sets that are good at starting kids off building the same bricks into multiple models: https://www.lego.com/en-gb/themes/creator-3-in-1Once they've got a few sets like that, the rebuilding into unspecified stuff seems to come naturally (at least with the cousins and friends kids I've played with).replyFreak_NL 17 hours ago | root | parent | prev | next [\u2013]Those complex sets are great for stimulating certain types of spatial reasoning, perseverance, and fine motor skills. My four year old went from 'building a tractor (60287) with dad helping' to 'building 5+ kits all by himself'.The kits don't stop him from just building his own stuff either. The two forms of play seem complimentary.replylacksconfidence 18 hours ago | root | parent | prev | next [\u2013]Personally I find the display models awesome. I'm not a big lego fan but the apollo rocket was nifty so I built it and put it on display.replyLeifCarrotson 17 hours ago | root | parent | prev | next [\u2013]The 1x1 sticker tiles sort themselves by granular convection [1] to the bottom of a Rubbermaid tote just like the sunflower seeds in a snack mix. In our house, they frequently get neglected except as gems/coins/treasure to fill a pirate chest. The large plates and bricks float to the top during shaking and digging.[1]: https://en.wikipedia.org/wiki/Granular_convectionreplyPhasmaFelis 18 hours ago | root | parent | prev | next [\u2013]See, I love all those detail bits. I love to make tiny, intricate models that say a lot in a small space. I love grabbing a couple of random gribbly bits, sticking them together, deciding they look like the beginning of something, then sticking on more bits to make it more like the thing.The \"voxel sculpture\" style where you just stack (mostly) rectangular bricks into a shape is perfectly valid, but it's less interesting to me personally.Modern Lego supports both. Both are valid. They still sell big brick buckets, and no one's stopping you from buying one of those and doing your thing.replyepiccoleman 17 hours ago | root | parent | next [\u2013]What I'd really like to see is a \"brick bucket\" that contains mostly large bricks and maybe a few doors, windows, and slanted tiles. I'm all for gribbly bits, but it seems harder to accumulate a good collection of the basics these days - because the big \"brick buckets\" you describe are probably half gribbly bits. In my experience as a kid, what we really wanted was enough mass to build walls and houses and forts, and were not as interested in small detail stuff.replydsr_ 17 hours ago | root | parent | next [\u2013]Set 10698. 790 pieces, $35 at amazon.https://www.lego.com/en-us/product/lego-large-creative-brick...replyepiccoleman 17 hours ago | root | parent | next [\u2013]That looks pretty good actually, but now I'm going to move the goalposts and wish for a similar box with less color variety so that you can build, for example, a white house with a red roof, instead of having to cobble together various colors.Still though, I just might have to top off the kids collection with one of these boxes. Good find.replylukas099 15 hours ago | root | parent | prev | next [\u2013]Sounds like a greater diversity of pieces for free-play construction to me.replyzgluck 16 hours ago | root | parent | prev | next [\u2013]Lego nailed it in 1980 with the 8860 Auto Chassis, IMO. It does all of those things in a nice balance with piece count of 662 (for a 57 cm long car) and IMO still ends up looking better than today's 3000 piece models.http://www.technicopedia.com/8860.htmlreplyhugi 18 hours ago | parent | prev | next [\u2013]I'm in my early forties but I still grew up with instructions and sets. Usually I'd assemble a set and probably learn a thing or two along the way, then I'd tear the sets down and build stuff myself.As a father of three, that's exactly how I see my kids using the sets today. The sets get built once, then they get torn down and the bricks get reused.replythirteenfingers 18 hours ago | parent | prev | next [\u2013]I personally agree about the whole point of Lego being free form building - and I still have some Lego magazines from the days when that was explicitly encouraged by Lego - but you need kits and instructions to get to the point where you can do free form building. It's like composing music, you're going to have a very difficult time of it if you don't first study a whole lot of existing, well-constructed music.replyphotonerd 15 hours ago | root | parent | next [\u2013]I mean\u2026 I didn\u2019t. At all. So I\u2019d dispute the \u201cneed\u201d, tho it\u2019s of course a learning option I guess.replyonemoresoop 18 hours ago | parent | prev | next [\u2013]Neither did I till I had a kid. My kid loves following instructions, builds a set a few times, then he goes into creative mode and builds his own way. Instructions helped my kid learn the basics of instruction following which is a good skill to have for a 5 year old.replyphotonerd 15 hours ago | root | parent | next [\u2013]Yeah I have a 2 yr old & larger blocks. He\u2019s all about free building atm.replyjedberg 16 hours ago | parent | prev | next [\u2013]The purpose of the instructions is to learn the techniques. First you build with the instructions, then you tear it apart and build what you want.Not everyone is into the instructions -- my daughter follows them meticulously and will only build with instructions. My son refuses to follow instructions and will only \"master build\".When I was a kid I'd build with the instructions, and eventually I destroyed everything and built a whole city from scratch.Every kid is different.replyroryisok 14 hours ago | parent | prev | next [\u2013]Growing up, myself and my siblings built sets when we first got them as gifts, but after that they went in the pile. We would build whatever was in our imagination, from the multicolored heap.Now I have my own kids, and they all want to build sets from instructions. The odd time we'll dive into the pile of orphaned bits and build a house or a boat or something, but mostly they want to recreate what they remember. My wife spends hours finding all the pieces of a set and bagging them up for the kids to build later (so she's gonna love this)It's tempting to say \"kids nowadays\" but I think it's just different personality types. In other media, my kids are far more creative and imaginative than I ever was, but with Lego sets they prefer to recreate the perfect image than make a hodge podge thing that never existed.replynuancebydefault 13 hours ago | parent | prev | next [\u2013]The fun of building new sets off instructions is the satisfying-ness. You know the instructions are correct, that no pieces are missing and all pieces click together satisfyingly into the result, that looks and feels nice. Each click is satisfying.It is a whole lot different from tinkering with arduino hats/sw, as frustration can creep in if things don't work as expected.replystinkytaco 17 hours ago | parent | prev | next [\u2013]I like both. I think Lego sets are in many ways my first experience of technical documentation and I still use those skills. It also helped me learn about how sets went together so I could design my own. Finally, I wanted to play with what was on the box.replyjjkaczor 18 hours ago | parent | prev | next [\u2013]I am in-between - so, the way I used instructions was for ideas on how things could be put together that were \"non-obvious\".I would build it once, then play with that model for a bit, then deconstruct it, put it into my box of loose LEGO and then build whatever I wanted - sometimes it would look similar, but it was never the same way twice.I fail to understand expensive sets that get built and sit on shelves or in glass enclosures... Might as well break out the Kragle (I think many people failed to see the point of that movie...)replyCWuestefeld 16 hours ago | parent | prev | next [\u2013]I'm with you. I remember my childhood experience with Legos. Me and a friend down the road would drag out this big bucket full of random stuff. We'd build forts, and then crazy many-wheeled trucks that would assault them.The whole thing was about those designs just springing from the imagination, and I really don't get what fun building toward a prescribed design would be, especially since it's so low fidelity.replyphotonerd 15 hours ago | root | parent | next [\u2013]Right, exactly.Like I understand the appeal of model building but Lego models aren\u2019t very good models & look like ass compared to (often a lot cheaper) model kits.replyFireBeyond 16 hours ago | parent | prev | next [\u2013]Aimed more at adults, but the Architecture Studio was intended to be more free-form:https://www.lego.com/en-gb/product/studio-21050There are no 'models' to build, and the \"instructions\" that come with it are more a discussion of architectural principles, as adapted for Lego as needed.replylubesGordi 17 hours ago | parent | prev | next [\u2013]Yeah we never had sets or instructions as a kid (of the 80s). But now doing sets it's pretty relaxing, fun, easy. It's a puzzle. Eventually everything ends up in a heap like other comments mention. I imagine once the heap is big enough we'll go back to creative free form building with the variety of generic and tailored pieces we've accrued.replygerminalphrase 18 hours ago | parent | prev | next [\u2013]Free building is great, but my experience is that my young son also wants to build his sense of competence - following the steps correctly, fixing mistakes, and making something exactly like the picture. Sure, he plays with it for a minute and then tears it apart to make something original - but, like you said, that\u2019s the beauty of Lego.replylfowles 16 hours ago | parent | prev | next [\u2013]It gives you a core set of patterns for going off on your own and building. Think of it as lego practice that shows you a neat model at the end you can then scrap :)replym3kw9 16 hours ago | parent | prev | next [\u2013]Why did you buy the specific kit just to build your own stuff? The process of going thru the process and the satisfaction of finishing is rewardingreplyphotonerd 15 hours ago | root | parent | next [\u2013]I didn\u2019t. That\u2019s my point. Kits were rare (usually just suggestions with a slight subset of blocks) and most \u201csets\u201d were 100s of pieces & so infinite options to build.Now that\u2019s still available but VERY much tertiary.replyxdrosenheim 16 hours ago | parent | prev | next [\u2013]The whole point of LEGO is to \"LEg GOdt\" (Play great/good/well, however you want to translate that).replyXCSme 16 hours ago | parent | prev | next [\u2013]It's like assembling Ikea furniture. Some people like it.replyphotonerd 15 hours ago | root | parent | next [\u2013]I like model building. But Lego models are not very good modelsreplyswayvil 13 hours ago | parent | prev | next [\u2013]I agree.It's like painting by numbers. Or drawing from one of those \"how to draw a pirate\" instructional guides.It's a completely different thing.I know a guy who prefers the instructions. He builds them and then keeps them on display, on shelves and such.replyglobular-toast 15 hours ago | parent | prev | next [\u2013]I love following instructions. It's so relaxing for me to just follow without having to figure anything out. Building my own stuff with Lego would be a completely different thing and I never enjoyed that, probably because I'm not very good at it.replymcphage 18 hours ago | parent | prev | next [\u2013]> The whole point of Lego was creative free form building. Remove that & it\u2019s dull as hell.The point is that Lego can be played with in a bunch of ways. It's parts that you can do whatever with, and it has instructions for one or more models that you can make. Some people like the sheer possibilities of making things up, and some people find that daunting. Lego supports both, and anything in between.Following the instructions does teach you techniques that you can use on designing your own builds. It's a way to learn from experts.replyphotonerd 15 hours ago | root | parent | next [\u2013]> The point is that Lego can be played with in a bunch of ways.Indeed: the exact opposite of a set of instructions & specific, custom produced, build pieces.replymcphage 12 hours ago | root | parent | next [\u2013]> specific, custom produced, build piecesHow they reuse molds in Lego models is crazy. I have a model with a pagoda, that uses bananas for the points on the eaves. My favorite is the orchid model, where the smaller orchid blossoms are demigorgon heads from the Stranger Things sets.replysxp 18 hours ago | prev | next [\u2013]For modern sets, you can also get a PDF from the official site: https://www.lego.com/en-us/service/buildinginstructions/7622...One of these days, I want to learn enough computer vision to write an LEGO instruction booklet to LCAD convertor that could be fed old instructions and generate a 3D model of the set. An archive of the instructions is nice, but a virtual archive of sets would be nicer.replyjamesfinlayson 8 hours ago | parent | next [\u2013]I thought years ago Lego had a desktop program that let you build things with virtual bricks.replyxp84 13 hours ago | parent | prev | next [\u2013]Then feed that model into a 3d printer and archive your built sets immutably in meatspace! :DreplyIG_Semmelweiss 18 hours ago | prev | next [\u2013]This is a great reminder for parents of lego-addicted kids to get their into STEM by entering in FRC. It starts early, with legos!https://www.firstinspires.org/robotics/fllreplybryanmgreen 17 hours ago | prev | next [\u2013]Over the last several years I've made a habit of downloading PDF manuals for many things I own and saving them in a Google Drive folder for safe-keeping.You never know when you need one until you do and it's a nightmare if you lost it!replyjordij1 17 hours ago | parent | next [\u2013]My manuals are sorted in folders by maker / brand name.replyOliveMate 15 hours ago | prev | next [\u2013]My old man recently got a bunch of boxes from my childhood out of his, including multiple tubs of mixed Lego and a box of incomplete instructions. This will prove to be a valuable resource in the coming months, thank you very much!I keep staring at all the artwork included on some of the early Bionicle instructions and I love that dark mysterious island aesthetic.replydumpsterdiver 4 hours ago | prev | next [\u2013]As a proud Lego collector, I'm happy to say that I have not built any of these things. All my Legos are still in the box (sunglasses).replyjjallen 18 hours ago | prev | next [\u2013]There\u2019s also an app with all of the instructions if that\u2019s more convenientreplytoastandbacon1 15 hours ago | prev | next [\u2013]So much nostalgia. I remember playing and building with tons of Legos back in the day. Then id destroy them and build my own stuff.replygumby 17 hours ago | prev | next [\u2013]It wasn't until I started buying Lego for myself (in my 20s) that I learned that Lego came with instructions. When I was a kid my parents would open the box and discard the instructions before giving it to me.Back then (60s/70s) the sets were quite general and open ended. Modern day Lego has the thinking done ahead of time, and has too many specialised pieces.replytspike 16 hours ago | parent | next [\u2013]This is definitely a \u201cget off my lawn\u201d comment. Creativity with Lego has never been more vibrant. I encourage you to visit your local Lego fan convention, or explore one of the many online forums where people share their \u201cMOCs.\u201dThose \u201cspecialized\u201d pieces are incredible fodder for sculpting. Check out newelementary.com to see some examples.replygrigri907 16 hours ago | parent | prev | next [\u2013]Agreed - the constraints of a limited set of bricks really forced creativity.However, there's been a huge paradigm shift in terms of what is \"allowed\" as far as odd brick placements so the realm of what's possible to build has expanded at least as much as the inventory of brick options.replyrnitchy 8 hours ago | prev | next [\u2013]can we create an AI that has knowledge of the size, shape, color and name of each lego brick ever made??? We then feed it 3d renders and select a desired model scale (ex: 1:4 scale), and it prints out a lists of each piece you will need, as well as instruction/brick location to assemble an item that looks similar from lego parts.replyNifty3929 7 hours ago | parent | next [\u2013]What do you mean \u201cwe?\u201dWhy don\u2019t you do it? Or at least start the project? There\u2019s already work in this space as well. I\u2019ll be happy to contribute as well.replygleenn 16 hours ago | prev | next [\u2013]I was sad not to see the original Technic Super Car. It had a working V8, 4 wheel drive with 4 wheel steering and 3 way differential, and even an actual gear box with shifter. You could see the pistons pump when you pushed it around. One of the best birthday presents I ever asked for.replyrozhok 1 minute ago | parent | next [\u2013]I was dreamed about this set back in mid-90s. Unfortunately my parents wasn't able to afford it, and I only had small and mid sets and not a single \"technics\" set.So I was doomed to re-read a paper catalog countless times hoping someday I'll get it.replymarceldegraaf 12 hours ago | parent | prev | next [\u2013]That was an amazing set. The first one I bought from my own hard-saved cash as a kid. Really fun to build and amazing (and informative) to see the working steering, differential, suspension, and gear train assemblies.I have this set laying around, mostly complete. Should really rebuild it someday!replyxdrosenheim 16 hours ago | parent | prev | next [\u2013]Do you know the set number? There is a \"Super Car\" in Technic with set number 8070, available in the archive. Not sure about the steering and differential, but it seems to feature a V8 and a stick shift.replynetsharc 16 hours ago | parent | prev | next [\u2013]The 8880: https://brickset.com/article/20017/8880-super-car-the-best-e...replyMisterTea 16 hours ago | parent | prev | next [\u2013]That was a great set - it also featured double wishbone suspension supported by spring struts.replyrhplus 17 hours ago | prev | next [\u2013]I'm surprised there's no copyright notice on these instruction booklets. Has LEGO ever stated that their booklets are freely reproducible or is this a gray area?Note: I'm talking about the layout and graphics of the booklets themselves, not the logical instructions (i.e. recipe book versus recipes).replymrweasel 18 hours ago | prev | next [\u2013]Now if someone would just make an app that can figure out which set my bricks belong to. I have at least two sets that I can't find the instructions for, because I have no idea what they're called or which number they have. The bricks are fairly unique, they can't be in more than 10 sets.replygaazoh 18 hours ago | parent | next [\u2013]You can try to find the parts that stand out on bricklink[0], which will point you to the sets they were used in. It's pretty quick, once you figure out what the part can be called or what category it fits in.If you can't figure it out, you can ask for help on the \"bricks\" StackExchange site[1].[0] https://www.bricklink.com [1] https://bricks.stackexchange.com/replylapetitejort 17 hours ago | root | parent | next [\u2013]I've attempted to find some sets based on a single complicated brick and it can be challenging. How do I find the \"official\" name of the brick based on my own vague description [0]? What is the true color? How do I find special printed bricks? I'm sure with practice it gets easier. How open is bricks stack exchange to posting just an image of a brick with not much more to go on?[0]: As an example, here the description of a brick I struggled to name. I've since figured it out, but you are welcome to guess: flat 4x1 with bumps only on the ends (yes, \"bumps\", because I don't know what the technical term is. Again, I'm sure there's a guide or glossary I could find.)replygaazoh 1 hour ago | root | parent | next [\u2013]> How open is bricks stack exchange to posting just an image of a brick with not much more to go on?Judging by the 623 answered questions with the \"part-identification\" tag (out of 636)[0], I'd say pretty open. A lot of them are just what you are asking for, people helping IDing a single part from a picture. Some are much more specific, asking about minor variations on parts, and still get a detailed answer a lot of the time.[0]https://bricks.stackexchange.com/questions/tagged/part-ident...replytoast0 16 hours ago | root | parent | prev | next [\u2013]> What is the true color?I have a palette of bricks of known color to calibrate against. If you've got a good number of sets, you'll likely start to accumulate things that are only in a few colors. If possible, it's nice to switch those up with a 1x2 brick in that color for consistency and because the 1x2s are stable on the large area maps.> As an example, here the description of a brick I struggled to name. I've since figured it out, but you are welcome to guess: flat 4x1 with bumps only on the ends (yes, \"bumps\", because I don't know what the technical term is. Again, I'm sure there's a guide or glossary I could find.)You kind of work up to it. There are very small and hard to read numbers on a lot of the parts that helps sometimes. Searching for 1x4, ignore printed parts, shows 230 parts on rebrickable (other sites may vary), looking through all those pictures gets me to \"Plate Special 1 x 4 with 2 Studs\" [1]. I don't think there's a brick like this, or I can't find it, just the plate; but then you didn't know the magic terminology that the flat pieces (1/3rd height) are plates, not bricks. Had I properly interpreted your description, I'd have jumped to the plates, special category, and skipped the search.[1] https://rebrickable.com/parts/92593/plate-special-1-x-4-with...replybennyp101 18 hours ago | parent | prev | next [\u2013]I'm sure there was a brick scanning app that appeared a while ago, or try and find a number and enter it on Lego site [1], otherwise post a picture on BrickLink and I'm sure someone will know what it is! Then you can look on BrickLink or Rebrickable to find sets that it came from[1] https://www.lego.com/en-gb/service/help/building_instruction...replytectec 18 hours ago | parent | prev | next [\u2013]Brinklink has list for each brick of the set it belongs too. I was able to use that to discover a set I didn't know my older brothers had.replyjjkaczor 18 hours ago | parent | prev | next [\u2013]There are typically numbers somewhere on bricks that you can lookup.Or ... Reverse image search.replychias 18 hours ago | prev | next [\u2013]Oh man, this sent me down a trip to memory lane. I had a lot of the Spyrius set as a little kid, and I loved them to bits. I just looked up how much they'd cost to buy them again, and they're like $1000 a pop :oreplyaeneasmackenzie 17 hours ago | parent | next [\u2013]You may be able to (entirely legally) part out the sets on bricklink, buy the generic bricks from webrick, and buy the specific bricks from bricklink sellers. This will be substantially cheaper and it\u2019s an onboard into non-Lego building bricks which have gotten really good in the last few years. The glut of vendors selling copied Lego sets has given the field a bad name, but the brick design is out of patent and there are many sellers designing their own sets as well as selling MOCs.replyendemic 16 hours ago | parent | prev | next [\u2013]nostalgia is a helluva drugreplylostlogin 14 hours ago | prev | next [\u2013]The crowd who like Lego May also enjoy the tv series Lego Masters (and it\u2019s versus regional versions). Some of the builds are actually amazing.replyamelius 11 hours ago | prev | next [\u2013]It would be nice to have 3D models of these, so I can play with them without shelling out $$$.replyalbertopv 15 hours ago | prev | next [\u2013]Amazing! I was thinking just about this a few days ago, my daughter got a tons of Lego from hers uncles, of course without instructionsreplyjonathankoren 16 hours ago | prev [\u2013]Internet Archive is a great resource, but man the interface sucks. Part of it\u2019s because there\u2019s no good way browse online, and part of it is because the search is broken. Indexing so much data in such diverse formats with questionable or missing metadata is hard. I\u2019d love a better interface, but I also suspect that a crappy interface is what help IA stay alive. There\u2019s plenty of legally questionable data hosted there if you know where to look.replyGuidelines | FAQ | Lists | API | Security | Legal | Apply to YC | ContactSearch:",
    "hn_summary": "- LEGO Building Instructions are now available on the Internet Archive, allowing users to access and view instructions for various LEGO sets.\n- Users on Hacker News discuss alternative websites like brickinstructions.com for more easily navigable LEGO instructions.\n- Some comments express nostalgia for LEGO sets from the past and the joy of building without instructions."
  },
  {
    "id": 36614678,
    "timestamp": 1688645979,
    "title": "Injunction issued in case about social media pressure from US Government",
    "url": "https://arstechnica.com/tech-policy/2023/07/judge-rules-white-house-pressured-social-networks-to-suppress-free-speech/",
    "hn_url": "http://news.ycombinator.com/item?id=36614678",
    "content": "PRELIMINARY INJUNCTION \u2014Judge rules White House pressured social networks to \u201csuppress free speech\u201dMissouri and Louisiana sued Biden over attempts to limit COVID misinformation.JON BRODKIN - 7/5/2023, 6:22 PMEnlargeGetty Images | Christopher Furlong335WITHA federal judge yesterday ordered the Biden administration to halt a wide range of communications with social media companies, siding with Missouri and Louisiana in a lawsuit that alleges Biden and his administration violated the First Amendment by colluding with social networks \"to suppress disfavored speakers, viewpoints, and content.\"The Biden administration argued that it communicated with tech companies to counter misinformation related to elections, COVID-19, and vaccines, and that it didn't exert illegal pressure on the companies. The communications to social media companies were not significant enough \"to convert private conduct into government conduct,\" Department of Justice lawyers argued in the case.But Judge Terry Doughty, a Trump nominee at US District Court for the Western District of Louisiana, granted the plaintiffs' request for a preliminary injunction imposing limits on the Department of Health and Human Services, the National Institute of Allergy and Infectious Diseases, the Centers for Disease Control and Prevention, the Federal Bureau of Investigation, the Department of Justice, the US Census Bureau, the State Department, the Homeland Security Department, the Cybersecurity and Infrastructure Security Agency, and many specific officials at those agencies. The injunction also affects White House officials.The agencies and officials are prohibited from communicating \"with social-media companies for the purpose of urging, encouraging, pressuring, or inducing in any manner the removal, deletion, suppression, or reduction of content containing protected free speech posted on social-media platforms,\" Doughty ruled. The injunction prohibits \"specifically flagging content or posts on social-media platforms and/or forwarding such to social-media companies urging, encouraging, pressuring, or inducing in any manner for removal, deletion, suppression, or reduction of content containing protected free speech.\"AdvertisementGovernment agencies and officials are further barred from urging, encouraging, or pressuring social media companies \"to change their guidelines for removing, deleting, suppressing, or reducing content containing protected free speech.\" The ruling also said the government may not coordinate with third-party groups, including the Election Integrity Partnership, the Virality Project, and the Stanford Internet Observatory, to pressure social media companies.Exceptions include voting misinformationDoughty provided several exceptions that allow the government to communicate with social media companies about criminal activity and other speech that the First Amendment doesn't protect. The Biden administration may continue to inform social networks about posts involving criminal activity or criminal conspiracies, national security threats, extortion, criminal efforts to suppress voting, illegal campaign contributions, cyberattacks against election infrastructure, foreign attempts to influence elections, threats to public safety and security, and posts intending to mislead voters about voting requirements and procedures.The US can also exercise \"permissible public government speech promoting government policies or views on matters of public concern,\" communicate with social networks \"in an effort to detect, prevent, or mitigate malicious cyber activity,\" and \"communicat[e] with social-media companies about deleting, removing, suppressing, or reducing posts on social-media platforms that are not protected free speech by the Free Speech Clause in the First Amendment to the United States Constitution.\"In addition to the Missouri and Louisiana attorneys general, the plaintiffs include professors Jayanta Bhattacharya and Martin Kulldorff, who co-authored the October 2020 \"Great Barrington Declaration\" that opposed COVID lockdowns and urged a focus on reaching herd immunity. They and other plaintiffs claim they were censored by social networks.The ruling was criticized by Jameel Jaffer, an adjunct professor of law and journalism who is executive director of the Knight First Amendment Institute at Columbia University. \"It can't be that the government violates the First Amendment simply by engaging with the platforms about their content-moderation decisions and policies,\" Jaffer told The New York Times, calling it \"a pretty radical proposition that isn't supported by the case law.\"AdvertisementWhile the government must be careful to avoid coercion in its efforts to combat false information, Jaffer said that \"unfortunately, Judge Doughty's order doesn't reflect a serious effort to reconcile the competing principles.\"Stanford Law School Assistant Professor Evelyn Douek told The Washington Post that the \"injunction is strikingly broad and clearly intended to chill any kind of contact between government actors and social media platforms.\"Judge finds \u201cunrelenting pressure\u201d on social networksDoughty previously blocked federal vaccine and mask mandates in the Head Start program. In the social media case, Doughty made it clear that he expects plaintiffs to win in a 155-page memorandum ruling explaining his decision yesterday:The Plaintiffs are likely to succeed on the merits on their claim that the United States Government, through the White House and numerous federal agencies, pressured and encouraged social-media companies to suppress free speech. Defendants used meetings and communications with social-media companies to pressure those companies to take down, reduce, and suppress the free speech of American citizens.They flagged posts and provided information on the type of posts they wanted suppressed. They also followed up with directives to the social-media companies to provide them with information as to action the company had taken with regard to the flagged post. This seemingly unrelenting pressure by Defendants had the intended result of suppressing millions of protected free speech postings by American citizens.The federal defendants \"argue they only made requests to the social-media companies, and that the decision to modify or suppress content was each social-media company's independent decision,\" Doughty wrote. \"However, when a state has so involved itself in the private party's conduct, it cannot claim the conduct occurred as a result of private choice, even if the private party would have acted independently.\"He found that defendants \"significantly encouraged\" and in some cases coerced \"the social-media companies to such extent that the decision should be deemed to be the decisions of the Government.\"Page: 1 2 Next \u2192ARS VIDEOHow The Callisto Protocol's Team Designed Its Terrifying, Immersive AudioREADER COMMENTS335WITHJON BRODKINJon has been a reporter for Ars Technica since 2011 and covers a wide array of telecom and tech policy topics. Jon graduated from Boston University with a degree in journalism and has been a full-time journalist for over 20 years.AdvertisementChannel Ars TechnicaSITREP: F-16 replacement search a signal of F-35 fail?Footage courtesy of Dvids, Boeing, and The United States Navy.SITREP: F-16 replacement search a signal of F-35 fail?Sitrep: Boeing 707The F-35's next tech upgradeUS Navy Gets an Italian AccentSITREP: DOD Resets Ballistic Missile Interceptor programSITREP: DOD's New Long-Range Air-to-Air Missile Aims to \"Outstick\" ChinaArmy's New Pistol Has Had Some MisfiresArmy's Next (Vertical) Lift En RouteSITREP: President Trump's Missile Defense StrategyHybrid Options for US's Next Top FighterThe Air Force\u2019s Senior Citizen Chopper Can\u2019t Retire YetArs Live #23: The History and Future of Tech LawPolice re-creation of body camera evidence - Pueblo, CO | Ars TechnicaVisual Labs body camera software with the Dos Palos PD | Ars TechnicaHe knew his rights; he got tased anywayMore videos\u2190 PREVIOUS STORYNEXT STORY \u2192Related Storiesby TaboolaSponsored LinksUnsold Senior Cruise Deals (Take A Look At The Prices)Senior Cruise DealsVanguard vs. Fidelity vs. SchwabSmartAssetLearn More2 Cards Charging 0% Interest Until Nearly 2025CompareCredit.comLearn MoreVirginia Banks Hate When Seniors Discover This 9% Interest AccountWalletGeniusLearn MoreMEN: You Don't Need The Blue Pill If You Do This Once DailyNitric DriveRoofers Tested 17 Gutter Guards\u2026 Here\u2019s What They DiscoveredLeafFilter PartnerLearn MoreToday on Ars",
    "summary": "- A federal judge has issued a preliminary injunction ordering the Biden administration to stop communicating with social media companies in a lawsuit filed by Missouri and Louisiana. The lawsuit alleges that the administration violated the First Amendment by colluding with social networks to suppress free speech.\n- The Biden administration argued that its communication with tech companies was aimed at countering misinformation related to elections, COVID-19, and vaccines, and that it did not exert illegal pressure on the companies. However, the judge sided with the plaintiffs and imposed limits on multiple government agencies and officials, including the White House.\n- The injunction prohibits government agencies and officials from pressuring social media companies to remove or suppress content containing protected free speech. There are some exceptions, such as posts involving criminal activity and national security threats, where the government can still communicate with social networks.",
    "hn_title": "Injunction issued in case about social media pressure from US Government",
    "original_title": "Injunction issued in case about social media pressure from US Government",
    "score": 376,
    "hn_content": "- A court has issued a preliminary injunction in a case about social media pressure from the US Government.\n- The court has ordered the government to stop its in-dispute actions until the case is resolved.\n- The court found that the government's actions may infringe on people's first amendment rights and could be viewed as coercive.\n- The injunction is significant because it highlights concerns about potential government abuse of power and censorship of free speech.\n- The judge's decision suggests that there may be a need for further investigation and discovery before a final judgment can be made.\n- The case raises questions about the balance between government intervention and the protection of free speech rights.\n- It is important for readers to be aware of this case and its potential implications for free speech and government power in social media platforms.- The ruling on the government's restriction on speech is causing controversy.\n- The injunction prohibits government agencies from pressuring social media companies to remove or censor content.\n- Some argue that the ruling is a win for freedom of speech and prevents government overreach.\n- Others believe that the ruling limits the ability of the government to combat harmful misinformation.\n- The specific details of the injunction and its impact on communication between government employees and social media companies are still being debated.- The court issued a preliminary injunction limiting how government agencies can engage with social media platforms.\n- The debate revolves around freedom of speech and whether government intervention is justified in the context of public health emergencies.\n- The judge's ruling is seen as politically motivated by some, as it aligns with the judicial branch's increased influence.\n- Critics argue that government censorship of misinformation is necessary to protect public health and counter disinformation.\n- Supporters of free speech express concerns about government overreach and the potential for suppressing dissenting opinions.\n- The ruling raises questions about the balance between public safety and individual liberties.\n- There is disagreement about the role of social media platforms in curating information and the extent of their responsibility.\n- The case highlights the complexities of regulating speech in the age of online platforms and the impact on democratic discourse.",
    "hn_summary": "- A court has issued a preliminary injunction in a case about social media pressure from the US Government, highlighting concerns about potential government abuse of power and censorship of free speech.\n- The ruling prohibits government agencies from pressuring social media companies to remove or censor content, sparking a debate about the balance between freedom of speech and government intervention.\n- The case raises questions about the role of social media platforms in regulating speech and the impact on democratic discourse."
  },
  {
    "id": 36618344,
    "timestamp": 1688660446,
    "title": "{n} times faster than C",
    "url": "https://owen.cafe/posts/six-times-faster-than-c/",
    "hn_url": "http://news.ycombinator.com/item?id=36618344",
    "content": "{n} times faster than C - part oneC performance x86 assembly2023-06-19 21:51Sometimes humans can spot optimization opportunities that a compiler can\u2019t doesn\u2019t. In this post, we start with a loop generated from C code by clang, and tweak it in various ways, measuring the speedup.\ud83d\udce2 This post was on the front page of HN. You can join in the discussion there.Disclaimer: I\u2019m not an optimization expert, by any means, in fact my expertise is in high-level, purely-functional languages, where one doesn\u2019t usually think about how a program is executed.Code listings for this post can be found on GitHub.# The FunctionWe\u2019ll start with a function that loops through a string, and increments or decrements a number, depending on the characters it sees.int run_switches(char *input) { int res = 0; while (true) {  char c = *input++;  switch (c) {   case '\\0':    return res;   case 's':    res += 1;    break;   case 'p':    res -= 1;    break;   default:    break;  } }}It increments on seeing an \u2019s\u2019 (for successor) and decrements on seeing a \u2018p\u2019 (for predecessor).It\u2019s a small enough function that gcc and/or clang should be able to optimize it pretty well. Maybe optimally? I initially wrote this to see whether gcc produced a jump table or a search.This is what clang spat out (padding noops removed, and annotated manually):pseudocodearrows# llvm-objdump -d --symbolize-operands --no-addresses --x86-asm-syntax=intel --no-show-raw-insn loop-1-clang.c.orun_switches:   xor   eax, eax      # res = 0loop:               # while (true) {   movsx  ecx, byte ptr [rdi] #  c = *input   test  ecx, ecx      #  if (c == '\\0')   je   ret         #   return   add   rdi, 1       #  input++   cmp   ecx, 'p'      #  if (c == 'p')   je   p          #   goto p   cmp   ecx, 's'      #  if (c == 's')   jne   loop        #   continue   add   eax, 1       #  res++   jmp   loop        #  continuep:  add   eax, -1       #  res--   jmp   loop        # }ret: retRuntime: 3.23s \ud83d\udc0cBitrate: 295.26MiB/sGCC spat out a little more code, that ran a little faster (not much).This code is pretty straightforward, it has three conditional branch instructions (je, je, jne), leading to four possible blocks, \u2018\\0\u2019, \u2019s\u2019, \u2018p\u2019, and a block for any other character.# Rearranging branchesHowever, we know some things about this loop. We know that the only time we break out of it is when we hit the null terminator (\u2019\\0\u2019). The code clang generates checks for the null terminator first, but this makes no sense. The maximum number of null terminators we will ever hit in this function is 1, so for every \u2018p\u2019 and \u2019s\u2019 character, we\u2019re checking for null first. We should optimize for \u2018p\u2019s, \u2019s\u2019s and other characters over null terminators.So, let\u2019s rearrange this loop a little.arrowsrawrun_switches:        xor  eax, eaxloop: \u256d\u2500\u2500\u2500\u2500\u2500\u27a4 movsx ecx, byte ptr [rdi]    \u2502    inc  rdi    \u2502    cmp  ecx, 'p'    \u2502 \u256d\u2500\u2500\u2500\u2500 je   p    \u2502 \u2502   cmp  ecx, 's'    \u2502 \u2502 \u256d\u2500\u2500 je   s    \u2502 \u2502 \u2502  test  ecx, ecx    \u251c\u2500\u2502\u2500\u2502\u2500\u2500 jne  loop    \u2502 \u2502 \u2502  retp:   \u2502 \u2570\u2500\u2502\u2500\u27a4 dec  eax    \u251c\u2500\u2500\u2500\u2502\u2500\u2500 jmp  loops:   \u2502  \u2570\u2500\u27a4 inc  eax    \u2570\u2500\u2500\u2500\u2500\u2500\u2500 jmp  loopGreat, now we branch earlier on seeing a \u2018p\u2019 or an \u2019s\u2019, than on the rare \u2018\\0\u2019.Runtime: 3.10s \ud83e\udda5Speedup:: 1.04x \ud83d\udcc8Bitrate: 307.64MiB/s# Rearranging blocksSo both of our common cases (\u2018p\u2019 and \u2019s\u2019) jump back to the top of the loop, so why don\u2019t we remove one of those branches by putting its target block (or BasicBlock\u2122, for people in compiler land), at the top of the loop?arrowsrawrun_switches:       xor  eax, eax    \u256d\u2500\u2500\u2500\u2500\u2500 jmp  loops:   \u2502 \u256d\u2500\u2500\u27a4 inc  eaxloop: \u251c\u2500\u2502\u2500\u2500\u27a4 movsx ecx, byte ptr [rdi]    \u2502 \u2502  inc  rdi    \u2502 \u2502  cmp  ecx, 'p'    \u2502 \u2502 \u256d\u2500 je   p    \u2502 \u2502 \u2502 cmp  ecx, 's'    \u2502 \u2570\u2500\u2502\u2500 je   s    \u2502  \u2502 test  ecx, ecx    \u251c\u2500\u2500\u2500\u2502\u2500 jne  loop    \u2502  \u2502 retp:   \u2502  \u2570\u27a4 dec  eax    \u2570\u2500\u2500\u2500\u2500\u2500 jmp  loopGreat, now our \u2019s\u2019 block falls through into the loop without a branch. Pretty sweet.You\u2019ll notice that we now have to jump into the loop from the function start, to avoid running the \u2019s\u2019 block. This is a pretty good tradeoff though, jumping into the loop from the function start happens once, whereas we encounter many \u2019s\u2019 characters.But is it fast?Runtime: 2.98s \ud83d\udc22Overall speedup:: 1.08x \ud83d\udcc8Bitrate: 320.02MiB/s# Replacing jumps with arithmeticConditional jumps are bad, but how about your standard garden variety unconditional jmp? What if we tried to eliminate p:\u2019s jump back into the loop?A decrement is the same as two decrements and an increment, right? So let\u2019s use that to fall through into s:.arrowsrawrun_switches:        xor  eax, eax    \u256d\u2500\u2500\u2500\u2500\u2500\u2500 jmp  loopp:   \u2502  \u256d\u2500\u27a4 sub  eax, 2s:   \u2502 \u256d\u2500\u2502\u2500\u27a4 inc  eaxloop: \u251c\u2500\u2502\u2500\u2502\u2500\u27a4 movsx ecx, byte ptr [rdi]    \u2502 \u2502 \u2502  inc  rdi    \u2502 \u2502 \u2502  cmp  ecx, 'p'    \u2502 \u2502 \u2570\u2500\u2500 je   p    \u2502 \u2502   cmp  ecx, 's'    \u2502 \u2570\u2500\u2500\u2500\u2500 je   s    \u2502    test  ecx, ecx    \u2570\u2500\u2500\u2500\u2500\u2500\u2500 jne  loop        retWell, we got rid of another branch instruction, using basic arithmetic. Good for us. Is it faster though?Runtime: 2.87s \ud83e\udd8cOverall speedup:: 1.12x \ud83d\udcc8Bitrate: 332.29MiB/sFun fact, we\u2019ve been comparing our performance to clang 16\u2019s output this whole time, but GCC 12 actually produced faster (but more) code. GCC\u2019s code runs in 2.87s as well, so we only just caught up with it, however our program consists of 13 instructions, and GCC\u2019s is 19.GCC\u2019s code seems to have unrolled the loop, and is reusing the case blocks to some extent.# Just don\u2019t branchOkay, but these conditional branches are the real problem, right? How do you make the branch predictor fast? I don\u2019t know, so let\u2019s just not use it.arrowspseudocode# rdi: char *input# eax: ouput# r8: 1# edx: -1# ecx: char c# esi: nrun_switches:      xor  eax, eax      mov  r8d, 1      mov  edx, -1loop:    \u256d\u2500\u2500\u27a4 movsx ecx, byte ptr [rdi]    \u2502  test  ecx, ecx    \u2502 \u256d\u2500 je   ret    \u2502 \u2502 inc  rdi    \u2502 \u2502 mov  esi, 0    \u2502 \u2502 cmp  ecx, 'p'    \u2502 \u2502 cmove esi, edx    \u2502 \u2502 cmp  ecx, 's'    \u2502 \u2502 cmove esi, r8d    \u2502 \u2502 add  eax, esi    \u2570\u2500\u2502\u2500 jmp  loopret:   \u2570\u27a4 retWow that removed a lot of arrows from the control flow graph\u2026Instead of branching/jumping conditionally, we\u2019re using a different value for the addition depending on the current character, using cmove, or\u2026 \u2728\u2728conditional move on equality\u2728\u2728.The rules are: by default use zero, if we\u2019re on an \u2019s\u2019, use 1, and if we\u2019re on a \u2018p\u2019, use -1. Then always add.Right, nice flex, but\u2026 Is it fast?Runtime: 0.48s \ud83d\udc06Overall speedup:: 6.73x \ud83d\udcc8Bitrate: 1.94GiB/sYes it\u2019s pretty damn fast.# Freeing up a registerx86_64 has another way of conditionally setting a (1 byte) register to 0 or 1. It\u2019s called sete. Let\u2019s use that, and remove our use of r8d.arrowspseudocoderun_switches:       xor  eax, eax       mov  edx, -1loop:    \u256d\u2500\u2500\u27a4 movsx ecx, byte ptr [rdi]    \u2502  test  ecx, ecx    \u2502 \u256d\u2500 je   ret    \u2502 \u2502 inc  rdi    \u2502 \u2502 mov  esi, 0    \u2502 \u2502 cmp  ecx, 's'    \u2502 \u2502 sete  sil    \u2502 \u2502 cmp  ecx, 'p'    \u2502 \u2502 cmove esi, edx    \u2502 \u2502 add  eax, esi    \u2570\u2500\u2502\u2500 jmp  loopret:   \u2570\u27a4 ret\u2026 But is it fast?Runtime: 0.51s \ud83e\udd81Overall speedup:: 6.33x \ud83d\udcc8Bitrate: 1.83GiB/sWell, that\u2019s slower than using cmovs. I guess there are no points for using less registers, or for using 8-bit operations instead of 32-bit ones\u2026# Other attemptsI tried unrolling the loop of our best version. This slowed down the code.I tried aligning the start of the loop to a 16-byte boundary (pro tip, you can add .align <bytes> before a label, and GNU assembler will insert nop instructions for you). This also slowed down the code.# Benchmarking setup$ uname -srLinux 6.1.33$ lscpu... Model name:      AMD Ryzen 5 5625U with Radeon Graphics  CPU family:     25  Thread(s) per core: 2  Core(s) per socket: 6  Socket(s):      1$ clang --versionclang version 16.0.1$ gcc --versiongcc (GCC) 12.2.0The C versions were compiled with -march=native, so that the C compiler knew to produce code that was fast on my specific CPU, not some generic x86_64.The benchmark runs the function over a list of one million characters (random \u2018p\u2019s and \u2019s\u2019s) one thousand times.For each version, the benchmark was run several times, and the best result chosen.# ConclusionYou can (sometimes) get a 6x speedup by hand-coding your tight C loop in assembly, and optimizing using techniques that compilers don\u2019t seem to have automated away yet.Of course, this post isn\u2019t the end. If this still isn\u2019t fast enough for you, you can read part two.",
    "summary": "- The post explores the process of optimizing a C code loop by making tweaks and measuring the resulting speedup.\n- The loop function increments or decrements a number based on characters in a string.\n- Different optimization techniques are applied, such as rearranging branches, replacing jumps with arithmetic, and avoiding conditional branches. These optimizations significantly improve the performance of the loop.",
    "hn_title": "{n} times faster than C",
    "original_title": "{n} times faster than C",
    "score": 348,
    "hn_content": "- The post discusses a comparison between hand-written assembly and C code, showcasing the potential for assembly to be faster.\n- The main focus is on the optimization of a function that counts the number of occurrences of the characters 's' and 'p' in a string.\n- The optimized assembly code yields a 6x speedup compared to the original C code.\n- The speedup is attributed to the use of conditional arithmetic rather than jumps.\n- The author acknowledges that writing assembly is not always necessary or recommended and emphasizes the importance of understanding the underlying hardware.\n- The code is tested with random input strings consisting mostly of 's' and 'p'.\n- The post is special because it offers insights into low-level optimization techniques and demonstrates the trade-offs between code simplicity and performance.",
    "hn_summary": "- The post discusses a comparison between hand-written assembly and C code, showcasing the potential for assembly to be faster.\n- The optimized assembly code yields a 6x speedup compared to the original C code by using conditional arithmetic instead of jumps.\n- The post offers insights into low-level optimization techniques and demonstrates the trade-offs between code simplicity and performance."
  }
]
