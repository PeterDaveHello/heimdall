[
  {
    "id": 36746154,
    "timestamp": 1689510032,
    "title": "Discord is not documentation",
    "url": "https://shkspr.mobi/blog/2023/07/discord-is-not-documentation/",
    "hn_url": "http://news.ycombinator.com/item?id=36746154",
    "content": "Discord is not DocumentationBy @edent on 2023-07-16 documentation Open Source rant watchy9 comments350 wordsRead ~4,549 times.I'm going to be slightly contrarian and say that I like Discord. It's great to be able to get real-time help on a problem. And it is fun to see, again in real-time, what other people are working on and struggling with.In truth, Discord is no harder to sign up to than Slack, Matrix, Gitter, IRC, or whatever. And of course Open Source projects will follow the maxim of \"go where your audience are\". There's no point posting everything to MySpace when everyone's already on Facebook.Do I care that Discord isn't open source? Well, kinda. But I can open it in Firefox and it works just fine.Discord is perfect for ephemeral communications.But it is not a fucking substitute for documentation!I'm currently getting started, and increasingly frustrated, with the Watchy development platform. They've effectively said \"here's a barebones guide to setting it up - anything else, ask on Discord\" - and it fucking sucks.There's no API documentation - I have to scroll through a million messages to find anything.I can't use search, because people don't know how to thread. So I can see questions but not replies.When I do find replies, it's hard to know how relevant they are. A typical Discord chat looks like:Alice: What's the command to go fullscreen?Bob: Anyone know how I irrevocably format my disk without confirmation?Carol: Oh, yeah, it's easy. Just pass the -f flag.Errrr...And then you get the people who get snippy with newbie for asking a question which is frequently seen! So infuriating.I'm not necessarily advocating for the Four-Document Model - which has some critics - but I just don't understand why wouldn't at least collate all of the common questions and put the answers in one place.Look, writing a FAQ is probably not the right way to approach comprehensive documentation. But if you can't even be bothered to do that, perhaps you shouldn't be releasing a product in the first place?/rantShare this post on\u2026Mastodon Twitter Facebook LinkedIn Reddit HackerNews Lobsters Pocket WhatsApp Telegram",
    "summary": "- Discord is a popular real-time communication platform that can be used for getting help and staying updated on what others are working on.\n- However, Discord is not a substitute for proper documentation. The author of the post is frustrated with a development platform that only provides a basic setup guide and expects users to ask all other questions on Discord.\n- Lack of proper documentation leads to difficulties in finding relevant information, lack of threaded conversations, and snippy responses from experienced users. The author suggests that comprehensive documentation should be provided to address common questions and issues.",
    "hn_title": "Discord is not documentation",
    "original_title": "Discord is not documentation",
    "score": 508,
    "hn_content": "- Startups are increasingly using Discord for support, but users find it to be an awful experience.\n- Users struggle with finding the right channels and searching for solutions within Discord.\n- Some believe that startups should reconsider using Discord for everything and maintain public documentation instead.\n- Google's search results for programming documentation are often dominated by SEO blogspam, making it difficult to find the official documentation.\n- The ability to talk directly to a real human is powerful, and Discord provides a low-friction way of connecting people.\n- However, Discord is not ideal for long-term storage and discoverability of information.\n- The lack of documentation and reliance on chat platforms can hinder the growth of a community.\n- There are alternative platforms like Matrix and Zulip that provide better threading and documentation features.\n- It is important for startups to strike a balance between community engagement and providing comprehensive documentation.\n- Good documentation can help scale support and improve the user experience.\n- Discord's interface can be confusing for newcomers, and its limitations on content accessibility and retention are major drawbacks.- Discord is planning to add Jira integrations in the near future.\n- Some users are skeptical of this development, arguing that old software using more resources is not the future.\n- Others defend the trend, stating that home computers becoming thin clients and webapps are the future.\n- There is a debate about the benefits and drawbacks of using Discord for support and collaboration.\n- Some users praise Discord for its real-time user feedback, user retention, user collaboration, and community help features.\n- Others argue that Discord is not an efficient means of documentation and that searching through conversations is not ideal.\n- The limitations and flaws of Discord's search functionality are also discussed.\n- Some users express concern about Discord becoming a centralized, closed, and proprietary space for documentation.\n- Others defend Discord, citing its low friction in creating and joining communities.\n- The importance of having proper documentation and the challenges of maintaining it are emphasized.\n- The issue of privacy and the requirement of phone numbers for Discord sign-up is raised.\n- The use of Discord as a support channel and the alternative approaches to combating spam are debated.\n- The younger generation and their preferences for using Discord are highlighted.\n- The need for better documentation search tools and the potential of LLM-based models is suggested.\n- Discord's impact on the web and the rise of moderator culture are also discussed.\n- The debate surrounding Discord's usefulness for documentation purposes continues.",
    "hn_summary": "- Startups are using Discord for support, but users find it difficult to navigate and search for solutions within Discord.\n- Some suggest that startups should prioritize public documentation instead of relying solely on Discord.\n- Alternative platforms like Matrix and Zulip offer better threading and documentation features."
  },
  {
    "id": 36747572,
    "timestamp": 1689518695,
    "title": "Who employs your doctor? Increasingly, a private equity firm",
    "url": "https://www.nytimes.com/2023/07/10/upshot/private-equity-doctors-offices.html",
    "hn_url": "http://news.ycombinator.com/item?id=36747572",
    "content": "ADVERTISEMENTSKIP ADVERTISEMENTThe UpshotWho Employs Your Doctor? Increasingly, a Private Equity Firm.A new study finds that private equity firms own more than half of all specialists in certain U.S. markets.Give this article240The private equity industry has turned to health care fairly recently, and it has begun purchasing doctors\u2019 practices at a steady clip.Credit...Chase Castor for The New York Times",
    "summary": "- Private equity firms have started buying doctors' practices in the healthcare industry.\n- A new study reveals that more than half of all specialists in certain U.S. markets are owned by these firms.\n- This trend is relatively new and has gained attention due to the increasing involvement of private equity in healthcare.",
    "hn_title": "Who employs your doctor? Increasingly, a private equity firm",
    "original_title": "Who employs your doctor? Increasingly, a private equity firm",
    "score": 430,
    "hn_content": "- Private equity firms have found a way to legally profit without improving society, using loopholes and taking advantage of the machinery available in the economy.\n- The risk of their investments falls on the employees and customers of the companies they acquire.\n- The rise of private equity is due to factors such as low interest rates and the difficulty of obtaining funding from traditional sources.\n- Private equity firms are often well-connected in the financial world and have access to funds that others do not, allowing them to make acquisitions.\n- The lenders in a private equity buyout are often banks, who secure the loan on the assets of the purchased company.\n- Regulation may be necessary to address the issues caused by private equity, but simply calling for regulation without understanding the underlying economic factors is not sufficient for socially beneficial action.\n- The discussion around private equity reveals the complex web of agency and financial engineering that enables these transactions. \n- There is disagreement on the voluntary nature of these transactions and the level of consent from all parties involved. \n- The interests and motivations of different actors, including private equity firms, banks, and pension funds, are discussed, shedding light on the dynamics of this industry.- The current discussion revolves around the involvement of private equity (PE) firms in the healthcare industry.\n- Private equity firms have acquired medical practices and hospitals, raising concerns about potential conflicts of interest and profit-driven decision-making.\n- Critics argue that financial incentives may lead to unnecessary procedures, increased costs, and compromised patient care.\n- Some advocate for flat salaries for medical professionals to align incentives with patient outcomes rather than financial gain.\n- The effectiveness of different incentive structures depends on the nature of the job and the ability to evaluate performance accurately.\n- The discussion highlights the complex relationship between financial incentives, healthcare delivery, and patient outcomes.\n- There is a need to strike a balance between financial considerations and the ethical obligation to provide high-quality care to patients.- Many hospitals operate under capitated contracts with insurers, which means they are responsible for the costs of services they provide but receive a flat amount for reimbursements. \n- This system encourages underutilization of care because hospitals have financial incentives to minimize costs. \n- The idea that not-for-profit hospital systems are not necessarily altruistic is highlighted in this post.",
    "hn_summary": "- Private equity firms profit from loopholes and exploit the economy without improving society, shifting the risk onto employees and customers.\n- Factors like low interest rates and difficulty obtaining traditional funding contribute to the rise of private equity.\n- Criticism surrounds the involvement of private equity in healthcare, as it raises concerns about potential conflicts of interest, compromised patient care, and the need to balance financial considerations with ethical obligations."
  },
  {
    "id": 36744090,
    "timestamp": 1689487019,
    "title": "How I run my servers (2022)",
    "url": "https://blog.wesleyac.com/posts/how-i-run-my-servers",
    "hn_url": "http://news.ycombinator.com/item?id=36744090",
    "content": "How I run my serversJAN 21, 2022I've been writing recently about servers and internet infrastructure1. A lot of this writing is predicated on running server software on a VM or physical machine, rather than using a more cloudy solution, which is somewhat unpopular these days. However, I think it's a pretty reasonable way to do things, and it's not as difficult as many people make it out to be. This post is a simple description of how I run most of the servers I operate. It mostly describes running server software that I've written myself, since that allows me to make it much more robust and easy to deploy than the vast majority of off-the-shelf software is.This describes roughly the setup for thoughts.page, hanabi.site, cgmserver, phonebridge, and a few other services.These apps run on DigitalOcean VMs \u2014 the $5/month tier. (Some of them are on the same VM, some on different VMs \u2014 more on that later). The VMs run Debian 10.The server software is written in Rust. It's statically linked, and all of the html, css, config, secrets, etc are compiled into the binary. I accomplish this with rust-musl-builder and rust-embed. This means that deployment only requires copying a single file to the server. You can do similar things in languages like Go, C++, etc, and probably others, although I don't know the details of how exactly to accomplish it in those languages. If you're using a language that doesn't let you do this easily, a good alternative would be building a Docker container as your build artifact, which similarly will give you a single file to deploy.I use systemd to ensure that the binary starts when the server is started. Most of my systemd unit files are 9 lines long and extremely simple. systemd itself is quite complicated, but just starting a server on boot does not expose you to most of that complexity.I use a simple deploy script that copies the binary to the server and restarts the server, taking a little bit of care to allow rollbacks and ensure that there will always be a valid version running, even if my connection drops while I'm deploying.Programs that require a database use SQLite, which means that the entire state of the app is kept in a single file. I have two redundant backup solutions: On a daily basis, a backup is taken via the SQLite .backup command, and saved to Tarsnap. The script to do so is run via cron. I also use Litestream to stream a copy of the database to DigitalOcean Spaces storage on a secondly basis, with snapshots taken every 6 hours. This gives me quite a lot of confidence that even in the most disastrous of cases, I'm unlikely to lose a significant amount of data, and if I wanted to be more sure, I could crank up the frequency of the Tarsnap backups.All of my servers run behind nginx running as a reverse proxy. The main advantage to this is that nginx can do TLS termination, which means my apps don't need to think about HTTPS at all. I get my HTTPS certs from Let's Encrypt via certbot \u2014 this handles automatic renewal so I don't have to do anything to keep it working. Here's what my nginx config for hanabi.site looks like. Nginx also works great for serving static files \u2014 you can just scp or rsync them from your computer to the server.This is a simple and extremely robust setup. All of the software on the serving path (except for the apps themselves) has been around for decades and is extremely battle-tested. There is essentially no maintenance involved in keeping a site like this running \u2014 as long as I keep paying my DigitalOcean bills, they'll keep going. The only times my monitoring has detected problems with these sites have been transient DigitalOcean networking issues. I do need to update things occasionally \u2014 Debian releases have 5 years of support, so I'll need to upgrade to Debian 11 in around two and a half years, and if (when) something like heartbleed happens again, I'll need to go patch it. However, events like that are quite rare.One complaint about this setup is that paying $5/month for every service you want to run is a lot. This is indeed annoying, but it's quite doable to run multiple services on the same VM. In order to provide isolation, I run each service as its own unix user account. This form of isolation has been around since the dawn of unix, and thus seems quite robust. If you want more isolation, you can also use systemd-nspawn or firejail. I usually don't bother, though \u2014 if something is really important to keep secure, I'll just pay the extra $5/month to run it on its own VM.So, the process for setting up a new project looks like:Create a new userAdd a new nginx virtual host (and run certbot to get a HTTPS cert)Add a systemd unitCommit a deploy script to the repository and run itThis can be a lot to figure out if you haven't done it before! However, one of the advantages to running things this way is that this infrastructure changes much, much more slowly than cloud infrastructure does. You only need to learn how to set up nginx once, since the config format has stayed essentially the same for the past decade2, and is likely to remain the same in the future. The last major change to Debian system administration was the switch to systemd, nearly a decade ago. One of the comforts of running things this way is that you know that no one is going to pull the rug out from under you \u2014 no cloud provider is going to deprecate the service you're using, or silently change how it works. The only dependency is your VPS provider, and if you're unhappy with them \u2014 well, servers are a commodity, and there are a thousand other providers out there.Thanks to Julia Evans for prodding me to finally write this, and for early feedback.See: Consider SQLite, There is no such thing as a static website, Servers and Desire. \u21a9Seriously \u2014 try diffing nginx-0.5.38/conf/nginx.conf and nginx-1.21.5/conf/nginx.conf, from more than 12 years apart \u2014 there are a couple changes to how SSL is configured, some changes to the directory structure, and the logline format, and that's basically it. \u21a9",
    "summary": "- The author describes their setup for running servers, including the use of VMs, Debian 10, and server software written in Rust.\n- They explain their use of systemd for starting the server, a deploy script for copying the binary, and the use of SQLite for databases with redundant backup solutions.\n- The author also discusses the use of nginx as a reverse proxy for TLS termination and serving static files, highlighting the simplicity and robustness of this setup.",
    "hn_title": "How I run my servers (2022)",
    "original_title": "How I run my servers (2022)",
    "score": 397,
    "hn_content": "Hacker News new | past | comments | ask | show | jobs | submit loginHow I run my servers (2022) (wesleyac.com)397 points by ingve 1 day ago | hide | past | favorite | 164 commentsbob1029 19 hours ago | next [\u2013]HTTP triggered cloud functions are my new favorite thing. They can evaporate complexity if you dance around the various vendors carefully enough. This is the only cloud-native abstraction that feels \"end game\" to me. I still haven't been able to deploy a cloud function and get the \"runner\" into a state where I'd have to contact support or issue arcane console commands. I've done well over 2000 deploys by now for just one app alone with a 100% success rate.Performance is fantastic (using isolated app service plans in Azure), and I am completely over the ideological principals against per-request billing. Absolutely, you can do it cheaper if you own the literal real estate the servers are running inside of. Paying for flat colo fees makes per-request costs look ludicrous on the surface. But, achieving all of the other attributes of simple HTTP triggered functions in a DIY context is very challenging without also spinning up a billion dollar corporation and hiring 1k more people. Compliance, audits, etc are where it gets real super fast.The \"what about lock-in?\" argument doesn't work for me anymore. HTTP triggers are a pretty natural interface to code against: \"I've got a HTTP request for you to review, give me some HTTP response please\". The only stuff that is vendor-specific are the actual trigger method signatures and specific contexts beyond HTTP, such as OIDC or SAML claims. You'd really have to go out of your way to design an HTTP trigger web app/API solution that is impossible to refactor for another vendor within a week or so.If your business is a personal blog, then yeah I get it. It's more fun to buy a VM in Hetzner and get all artisanal about it. Also, if you are operating in a totally unregulated industry, perhaps you can make some stronger arguments against completely outsourcing the servers in favor of splitting hairs on margin vs complexity.replyWastingMyTime89 15 hours ago | parent | next [\u2013]> But, achieving all of the other attributes of simple HTTP triggered functions in a DIY context is very challenging without also spinning up a billion dollar corporation and hiring 1k more people.I literally rolled my eyes reading that. How do you think we did before cloud computing?I am currently in charge of multiple teams scaling and deploying innovative applications for a large industrial company. We are using Azure for everything. Our cloud costs are insane for our number of users. I used to manage applications with ten times more user for one hundredth of the cost and less complexity. It\u2019s billed to another part of the company which is responsible for this dubious choice (I really hope someone is getting nice business trips paid by MS so it\u2019s not a complete waste) so I don\u2019t care but how people can blindly put faith in the cloud is beside me.replyTX81Z 14 hours ago | root | parent | next [\u2013]\u2026And you\u2019re only one mistake away from the spam/abuse detection bot from locking you out of your account and shutting off your business for 12-72 hours.replyWastingMyTime89 12 hours ago | root | parent | next [\u2013]For all the bad things I have to say about the cost, it\u2019s still Microsoft. We have a direct line to them and they are here when you need them.replybsder 10 hours ago | root | parent | prev | next [\u2013]He said Microsoft, not Google.For all of Microsoft's faults, you can get a person on the phone when you pay money.There is a reason Microsoft kicks Google's ass all over the room in the enterprise space.replyTX81Z 6 hours ago | root | parent | next [\u2013]Interesting. When you say pay money do you mean as in paying for Azure resources, or paying EXTRA for somebody to pick up the phone?replyirlib 6 hours ago | root | parent | next [\u2013]He said Microsoft. Not Amazon.replyRadiozRadioz 17 hours ago | parent | prev | next [\u2013]I work in an extremely highly regulated industry and I don't understand your last sentence. It is in our best interest to run all our own hardware. We can't even take pictures in the office, there's an absolute 0% chance we're trusting a cloud provider with anything.replybob1029 16 hours ago | root | parent | next [\u2013]> extremely highly regulated industryWhich one? We are using this stack in fintech, and are subject to PCI-DSS, SOX, AML, SOC2, etc. Many of our customers (small US banks & credit unions) are very interested in this kind of cookie-cutter, cloud-native stack in 2023.> We can't even take pictures in the office, there's an absolute 0% chance we're trusting a cloud provider with anything.Sounds like you work for an F100. Our IT budget is 5 figures and we are doing business with clients who have 6 figure IT budgets at the high end. Forcing an on-prem architecture would make our solution less secure in most situations, especially for those customers who do not have the confidence to run a complex SAAS solution on their premises. Many of our customers actively understand this reality and are very open to the idea of offloading complexity to the cloud.replyantonvs 15 hours ago | root | parent | next [\u2013]> Forcing an on-prem architecture would make our solution less secure in most situations, especially for those customers who do not have the confidence to run a complex SAAS solution on their premises.Yeah. I spent a couple of years at a billion-$ company in the telco industry which was subject to all sorts of US federal and foreign regulations (because they operated in 20+ countries.) They ran almost everything onprem, but seeing how that was managed, cloud would have 1000% more secure for them. At one point, the entire senior staff of the IT department was fired because of a security breach that was pretty clearly due to their poor decisions.Companies do exist where their onprem operations do seem very secure, but you need really big budgets and good management to do that properly. Most places are not like that, even in the highly regulated spaces.replyWhyQ 13 hours ago | root | parent | next [\u2013]Sounds very similar to Optus breach in Australia.replyantonvs 13 hours ago | root | parent | next [\u2013]This was a US company. Another fun thing that happened while I was there is that they had to throw out a major codebase and start from scratch because of security compromises, i.e. people working on it that shouldn't have been allowed to.I suppose in the end they achieve a kind of security with this behavior, but it would be a lot better to avoid such incidents in the first place - which would be perfectly possible, with good decision-making.replyRadiozRadioz 16 hours ago | root | parent | prev | next [\u2013]Ah, yes, also fintech, but different scale. The magnitude of our IT spend is very different.replyttymck 16 hours ago | parent | prev | next [\u2013]What do your functions do? If some script kiddie comes along and decides to query you 10 times per minute, how long until the function becomes more expensive than a VPS?replybob1029 16 hours ago | root | parent | next [\u2013]They are authenticated via AAD and effectively serve various SSR web applications. You can't actually invoke our functions without passing authentication first.replyhkon 17 hours ago | parent | prev | next [\u2013]Function is an ok place to host a simple api. But don't you require more things for your apps to be useful, like databases which add cost?replybob1029 16 hours ago | root | parent | next [\u2013]Yes the functions use Azure SQL Hyperscale for persistence.> which add costWe aren't interested in free. You get what you pay for.replyfauigerzigerk 15 hours ago | root | parent | next [\u2013]>You get what you pay for.I would say it's a somewhat weak correlation that breaks down completely if you consider a wider range of architectures. Back when Google was a startup \"you get what you pay for\" is what people running Oracle on Solaris would tell you.And there was a sense in which it was true. There was no more reliable and feature rich way of scaling up. But starting something like Google on top of this egregiously expensive platform would have been completely uneconomical. It just wouldn't have happened.And I think it's the same thing today. There are good reasons for using those egregiously expensive offerings from the largest incumbants but if you are starting something where servers are a significant cost factor then you are well advised to look at other options that are orders of magnitude cheaper, even accounting for labour.replyrewmie 13 hours ago | parent | prev | next [\u2013]> HTTP triggered cloud functions are my new favorite thing.What exactly are you talking about? Request handlers in HTTP servers? Function-as-a-service cloud computing services? Plain old RPC?replyrmilejczz 17 hours ago | parent | prev | next [\u2013]This has inspired me, I never thought of serving static sites on lambda but it makes a lot of sense. Cheers!replyluoc 15 hours ago | root | parent | next [\u2013]But why would one need any backend logic to fulfill that? Just upload your static files to S3, enable static website hosting and youre done. Takes you a few minutes. Haven't worked with one of the other vendors but I'd assume it's equally trivial ;)replyluoc 15 hours ago | root | parent | next [\u2013]Here's the guide: https://docs.aws.amazon.com/AmazonS3/latest/userguide/Hostin...replyrmilejczz 15 hours ago | root | parent | next [\u2013]Sure, in this case I would just use GitHub pages. Hosting a site on lambda is just something to try lolreplymatthews2 23 hours ago | prev | next [\u2013]> In order to provide isolation, I run each service as its own unix user account.systemd's DynamicUser feature could save some time here. It can allocate a uid, then create directories for logs/state with the correct permissions.https://0pointer.net/blog/dynamic-users-with-systemd.htmlreplychlorion 9 hours ago | parent | next [\u2013]It's really easy to create new \"system\" users with systemd-sysusers too, if you need the uid to be persistent!You just drop a small text file (often a single line) into /etc/sysusers.d/ with the information about the user, like username, home directory and whatever, and then invoke the sysusers command or service!replycardamomo 20 hours ago | parent | prev | next [\u2013]Thanks for sharing this! My server setup is similar to the one described in this article, minus isolating apps with separate users. I'll give dynamic users a go next time I tweak the setup.replyCHSbeachbum420 19 hours ago | parent | prev | next [\u2013]Pretty standard to use separate service principals for each service/app. Should also use separate serversreplyriskable 19 hours ago | root | parent | next [\u2013]> service principalsKerberos much? =)reply0xEFF 18 hours ago | root | parent | next [\u2013]Edit: the term service principal is current and isn\u2019t specific to Kerberoshttps://istio.io/latest/docs/concepts/security/#principalsreplypbar 15 hours ago | root | parent | prev | next [\u2013]It\u2019s all fun and games until your KDC goes down!replyRunSet 21 hours ago | prev | next [\u2013]But however will you scale to 14 billion users when, one morning, waking up from anxious dreams, you discover that in bed you have been changed into a monstrous verminous 'berg?replybioxept 20 hours ago | parent | next [\u2013]You will probably have different problems when this happens.replysmarx007 18 hours ago | parent | prev | next [\u2013]Then, Mr. Gregor Samsa, your position is not to be envied.replyusername135 20 hours ago | parent | prev | next [\u2013]Like a Zucker?replyFredPret 14 hours ago | parent | prev | next [\u2013]Time for Kafka?replysusam 23 hours ago | prev | next [\u2013]I have a similar setup for my personal and project websites. Some similarities and differences:* I use Linode VMs ($5/month).* I too use Debian GNU/Linux.* I use Common Lisp to write the software.* In case of a personal website or blog, a static website is generated by a Common Lisp program. In case of an online service or web application, the service is written as a Common Lisp program that uses Hunchentoot to process HTTP requests and return HTTP responses.* I too use systemd unit files to ensure that the website/service starts automatically when the VM starts or restarts. Most of my unit files are about 10-15 lines long.* The initial configuration of the VM is coded as a shell script: https://github.com/susam/dotfiles/blob/main/linode.sh* Project-specific or service-specific configuration is coded as individual Makefiles. Examples: https://github.com/susam/susam.net/blob/main/Makefile and https://github.com/susam/mathb/blob/main/Makefile* I do not use containers. These websites have been running since several years before containers were popular. I have found that the initialization script and a Makefile have been sufficient for my needs so far.* I use Nginx too. Nginx serves the static files as well as functions as a reverse proxy when there are backend services involved. Indeed TLS termination is an important benefit it offers. Other benefits include rate limiting requests, configuring an allowlist for HTTP headers to protect the backend service, etc.* I have a little private playbook with a handful of commands like: curl LINK -o linode.sh && sh linode.sh git clone LINK && cd PROJECT && sudo make setup https* The `make` targets do whatever is necessary to set up the website. This includes installing tools like Nginx, certbot, sbcl, etc., setting up Nginx configuration, setting up certificates, etc. Once the `make` command completes, the website is live on the world wide web.replyschemescape 19 hours ago | parent | next [\u2013]Which Common Lisp implementation do you use? If it\u2019s SBCL, has memory usage been a problem? Edit: I see SBCL in one of your Makefiles.I use a VPS with 512 MB of RAM, but each SBCL instance uses roughly 100 MB of RAM, so I can only have a couple services at once.I\u2019ve considered moving the lowest traffic services to CLISP, but it\u2019s missing at least one feature I use (package\u2014local nicknames).replyjorams 15 hours ago | root | parent | next [\u2013]SBCL needs a relatively large amount of memory to start with, but beyond that it doesn't require much. I run a few small services written in Common Lisp. Instead of running a separate process for every one of them I run a single SBCL process and run each service in a different thread.This has some downsides: Firstly they run in the same address space, so global state is shared and serious bugs can affect another service. Secondly they run as a single systemd service, so they're not easy to manage individually. Still I've found it to work quite nicely for things that are simple and don't really need attention.replyschemescape 13 hours ago | root | parent | next [\u2013]Thanks! That setup is actually my backup plan if I start to run out of memory.Maybe it\u2019s my imagination but it seems like CL isn\u2019t as suited to sharing code and read-only data pages across processes (e.g. in shared libraries). Or maybe there\u2019s a solution I just haven\u2019t found yet\u2026replysusam 18 hours ago | root | parent | prev | next [\u2013]Yes, I use SBCL. For static websites, the memory usage is not a problem because SBCL exits after generating the website.For long running services, it does consume about 100 MB of memory. For example, I have a service running right now with an uptime of 270 days. SBCL is currently consuming 108 MB of memory. This has not been a problem either because for low traffic websites like mine, this memory consumption size remains fairly stable. I have not found it to be varying much.replymichaelsalim 1 day ago | prev | next [\u2013]Over the years, I kept tweaking my setup and now settled with running everything as a docker container. The orchestrator is docker-compose instead of systemd. The proxy is caddy instead of nginx. But same as the author, I also write a deploy script for each project I need to run. Overall I think it's quite similar.One of the many benefits of using docker is that I can use the same setup to run 3rd party software. I've been using this setup for a few years now and it's awesome. It's robust like the author mentioned. But if you need the flexibility, you can also do whatever you want.The only pain point I have right now is on rolling deployment. As my software scales, a few second of downtime every deployment is becoming an issue. I don't have a simple solution yet but perhaps docker swarm is the way to go.replyelitan 1 day ago | parent | next [\u2013]I do the same as you using Caddy.To avoid downtime try using:  health_uri /health  lb_try_duration 30sFull example:  api.xxx.se {   encode gzip   reverse_proxy api:8089 {    health_uri /health    lb_try_duration 30s   }  }This way, Caddy will buffer the request and give 30 seconds for your new service to get online when you're deploying a new version.Ideally, during deployment of a new version the new version should go live and healthy before caddy starts using it (and kills the old container). I've looked at https://github.com/Wowu/docker-rollout and https://github.com/lucaslorentz/caddy-docker-proxy but haven't had time to prioritize it yet.replyremram 19 hours ago | root | parent | next [\u2013]That's neat, I wonder if there's a way to do that with nginx?edit: closest I found is this manual way, using Lua: https://serverfault.com/questions/259665/nginx-proxy-retry-w...replymichaelsalim 14 hours ago | root | parent | prev | next [\u2013]Thanks for that. Didn't know this is a thing in Caddy. Seems low effort so I'll probably do that for now. I omitted it but I'm actually using caddy-docker-proxy. It's awesome, makes the config section be part of each project nicely. Haven't seen docker-rollout though. Seems like it could be promising.replybradleyjkemp 1 day ago | parent | prev | next [\u2013]If you've got a load balancer (like Caddy) in front of your pods you can configure it to hold requests while the new pod comes up: https://twitter.com/bradleyjkemp/status/1486756361845329927It's not perfect but it means rather than getting connection errors, browsers will just spin for a couple seconds.The same technique is used by https://mrsk.dev/replycollaborative 18 hours ago | root | parent | next [\u2013]If you have more than one backend you can also reconfigure caddy on the fly to only serve from active ones while each one is being updatedreply9dev 23 hours ago | parent | prev | next [\u2013]I\u2018ve built up the software stack of the startup I work for from the beginning, and directly went for Docker to package our application. We started with compose in production, and improved by using a CD pipeline that would upgrade the stack automatically. Over time, the company and userbase grew, and we started running into the problems you mention: Restarting or deploying would cause downtime. Additionally, a desire to run additional apps came up; every time, this would necessitate me preparing a new deployment environment. I dreaded the day we\u2019d need to start using Kubernetes, as I\u2019ve seen the complexity this causes first-hand before, and was really weary of having to spend most of the day caressing the cluster.So instead, we went for Swarm mode. Oh, what a journey that is. Sometimes Jekyll, sometimes Hide. There are some bugs that simply nobody cares fixing, some parts of the Docker spec that simply don\u2019t get implemented (but nobody tells you), implementation choices so dumb you\u2019ll rip your hair out in anger over, and the nagging feeling that Docker Inc employees seem incapable to talk to each other, think things through, or stay focused on a single bloody task for once.But! There is also much beauty to it. Your compose stacks simply work, while giving you opportunities to grow in the right places. Zero-downtime deployments, upgrades, load balancing, and rollbacks work really well if you care to configure them properly. Raft is as reliable in keeping the cluster working as everywhere else. And if you put in some work, you\u2019ll get a flexible, secure, and automatically distributed, self-service platform for every workload you want to run - for a fraction of the maintenance budget of K8s.Prepare, however, for getting your deployment scripts right. I\u2019ve spent quite a while to build something in Python to convert valid Docker-spec compose files to valid Swarm specs, update and clean up secrets, and expand environment variables.Also, depending on your VPS provider, make sure you configure network MTU correctly (this has shortened my life considerably, I\u2019m sure of it).replymichaelsalim 14 hours ago | root | parent | next [\u2013]That's encouraging, thanks. Are you able to share your python convertor script by any chance?reply9dev 2 hours ago | root | parent | next [\u2013]I've extracted a gist: https://gist.github.com/Radiergummi/fe14c4ed93c68f2928a6a275...Let me know if that helps, or if you need more guidance. Maybe I could open source the whole thing properly, if that is useful to someone :)replyelitan 23 hours ago | root | parent | prev | next [\u2013]What's the correct configuration of MTU?replydijit 22 hours ago | root | parent | next [\u2013]there is no one size fits all answer to that. The standard is 1500; but MTU lowers with levels of encapsulation. (since you need those bytes for the encapsulation overhead).There's also \"Jumbo Frames\" though you're not likely to encounter that day to day in a VPS.replydirkhe 16 hours ago | parent | prev | next [\u2013]I built a similar setup but I don't like to push the images with docker save and docker import over ssh. Do you run your own registry?replymichaelsalim 14 hours ago | root | parent | next [\u2013]Nowadays I use github's packages registry. I used to run my own registry in the past along with the docker save method. But both of them are annoying to deal with. I have Github Pro so it's pretty much free. However even if I need to pay for it in the future, I'll probably do so. It's just not worth the headache.replyefrecon 1 day ago | parent | prev | next [\u2013]I do the same. Swarm is the way to go since you already have compose files, but I have made the choice that it is not worth it. Until you hit scaling issues (as in many customers/users).replyBossingAround 17 hours ago | parent | prev | next [\u2013]How often do you rebuild your containers?replymichaelsalim 14 hours ago | root | parent | next [\u2013]Whenever I have anything to deploy, so depends on the project. On actively developing ones, could be once or twice a day. On slower days maybe once every 2/3 days.replyarun-mani-j 1 day ago | prev | next [\u2013]My physical server:Podman Pods (which contains PostgreSQL database and the app) all running in localhost on ports > 5000 and Caddy running on 443 as reverse proxy.I use systemd Timer to dump all the databases at 4:55 PM in a directory. Then there is DejaDup [1] which automatically backs up $HOME (with no cache files of course) at 5 PM daily to external HDD. This backup includes the database dumps.The OS is Debian with GNOME Core [2] and a firewalld rule to allow only 80, 443 and a customized SSH port. The SSH is key based with no password auth.The most boring way but it just works :D1 - https://flathub.org/apps/org.gnome.DejaDup2 - https://packages.debian.org/bookworm/gnome-corereplyreidrac 23 hours ago | parent | next [\u2013]Out of curiosity, why do you run Gnome on your sever?replyarun-mani-j 23 hours ago | root | parent | next [\u2013]Okay here \"my\" means the University server I maintain :)GUI is needed because the office staff doesn't know SSH or CLI or Linux at all ^^(She liked GNOME once I showed it to her tho)replyAlexITC 14 hours ago | parent | prev | next [\u2013]Any reason to use systemd timers instead of cron jobs?replycasey2 13 hours ago | root | parent | next [\u2013]Exactly 1. Job security.replyAlexITC 13 hours ago | prev | next [\u2013]Interesting post, I liked the deploy script that keeps the app versioned in the server, which is helpful to do rollbacks.I have been running a similar setup for many years with some differences:1. Use `EnvironmentFile` on systemd to load environment variables instead of bundling secrets into the binary.2. Set `LimitNOFILE=65535` on the service to avoid reaching the file open limit on the app.3. Set `StandardError=journal` and `StandardOutput=journal` so that `journalctl` can display the app logs.4. Use postgres instead of sqlite, DO is taking regular backups for me and postgres maintenance is almost null for simple apps.5. Nginx can have password-protected endpoints, which are useful to expose the app logs without requiring to ssh into the VM.6. Nginx can also do pretty good caching for static assets + API responses that barely change, this is very helpful for scaling the app.At last, I use ansible but I'm considering if its worth it, replacing it seems simple and I'd be able to keep a single deploy file that runs faster than ansible.replyhk__2 23 hours ago | prev | next [\u2013]Nowadays I just use one server with a Dokku setup. It\u2019s easy to manage, easy to deploy for devs (just git push, the Heroku way), and it has a lot of plugins so it takes max 10s to add a database or set HTTPS up.replybryancoxwell 20 hours ago | prev | next [\u2013]> The server software is written in Rust. It's statically linked, and all of the html, css, config, secrets, etc are compiled into the binary.I\u2019ve recently taken to doing this in Go and absolutely love how easy it makes writing and deploying software that depends on static files.replymdtusz 18 hours ago | parent | next [\u2013]Including secrets in the compiled binary seems questionable still - using env variables or a config is the \"standard\" way for secrets, and although it adds another step before you can run, it avoids the case of sharing your binary with someone and forgetting that you had compiled in some secret that goes unnoticed. Unpacking a binary to find strings is pretty trivial.Having the static frontend assets baked in along with a default config is a huge boon though.replyComputerGuru 17 hours ago | root | parent | next [\u2013]You can include encrypted secrets and deploy the key out-of-band (eg just copy the private key with scp). This is much more secure than env variables which are prone to leakage. Our open source solution for this (cross-platform, cross-language): https://neosmart.net/blog/securestore-open-secrets-format/It supports embedding the encrypted secrets in the binary or loading them from a file. The secrets would actually be stored (encrypted) alongside the code, even versioned in git.Eg this is the rust version on GitHub: https://github.com/neosmart/securestore-rs/tree/masterreplychromatin 11 hours ago | root | parent | next [\u2013]Hey! Your rust (and C# I guess) secrets library looks super cool. I'm going to look at using this in my next project. Thanks for sharing it.replyComputerGuru 9 hours ago | root | parent | next [\u2013]Thanks for the words of gratitude, kind stranger! Glad to have potentially written something of some value to you.replyd3nj4l 20 hours ago | parent | prev | next [\u2013]I am not a fan of go but I find myself using it for this reason. Doing it with rust - especially cross compiling from mac to linux - is relatively painful, while with Go it is trivial and built into the go tool. It makes it so, so easy to remove any friction from finishing and deploying a side project.replybbkane 20 hours ago | root | parent | next [\u2013]Might be more complicated than you need, but I added Goreleaser to my CI/CD for my little tools. Now I can when I push a git tag it runs lints, runs tests, builds binaries, and updates Homebrew and Scoop repos.See https://github.com/bbkane/grabbit for an exampleMakes it trivial to run `brew/scoop update myapp` from another computerreplyAlexITC 14 hours ago | root | parent | prev | next [\u2013]> Doing it with rust - especially cross compiling from mac to linux - is relatively painfulI have used cargo-dist and the process is quite smooth, it could be worth giving it a try.replyzX41ZdbW 14 hours ago | parent | prev | next [\u2013]I'm doing the same way for https://play.clickhouse.com/play?user=playBut there is one question. The article says:> I get my HTTPS certs from Let's Encrypt via certbot \u2014 this handles automatic renewal so I don't have to do anything to keep it working.But I'm using cross-region setup with two servers and a geo-DNS. With this setup, the certbot only works for the server, located in the US, and I have to manually copy the certificates to the server in Europe. Any idea how to overcome this?PS. Read about ClickHouse Playground here: https://ghe.clickhouse.tech/replyrobmccoll 20 hours ago | parent | prev | next [\u2013]Yes! I do the same. I serve my web applications from the same statically compiled service that serves the backend API. In CI, I run an npm build process then embed the output. Makes running a local test or demo instance a snap.replyflagged24 18 hours ago | prev | next [\u2013]Once every 2 or 3 years I configure a new VPS with the latest Ubuntu LTS server release, install latest PostgreSQL, NGINX, Redis, Node.js. No containers, just standard Linux user accounts for each app. Pretty boring to be honest, but I don't have a problem that requires more complexity. I once tried a more complex distributed approach with load balancers and multiple VPN providers. Turned out the added complexity was the cause for instability and downtime.replyValtteriL 1 day ago | prev | next [\u2013]As a fan of simple setups, this looks enjoyable to work with! It is probably good enough for 99% of services.I think I would use Ansible to setup the servers and use it for the deployment script as well.This would document the servers and make deployment script perhaps simpler.I wouldn't shy away from accessing the servers manually when debugging or checking things, though.replyAlexITC 14 hours ago | parent | next [\u2013]> I think I would use Ansible to setup the servers and use it for the deployment script as well.I do use ansible but I'm reconsidering whether it is worth it, while my scripts have barely changed in the last 7 years, they tend to be slow and require me keeping multiple files around.Related to debugging, you can expose the app logs through a password-protected endpoint by nginx.replyoaiey 1 day ago | prev | next [\u2013]People sometimes forget that CI/CD and effective server management was common practice before the cloud :)replysgarland 20 hours ago | prev | next [\u2013]My self-hosted servers are Debian on clustered Proxmox. I bake the images periodically with Ansible and Packer.I used to have quite a few of them, then I shifted to K8s (or k3os, specifically), so now the only VMs other than the K8s nodes are my NAS, backup target, and a dev server. However, since Rancher has abandoned k3os and it\u2019s forever stuck at upstream 1.21, I\u2019m in the process of switching to Talos Linux for K8s. I have Proxmox running Ceph for me to provide block storage to pods.My blog was running in a tiny EC2 with a Bitnami multi-WordPress AMI, but since everyone else sharing it with me quit, I shifted that out to GitHub Pages + Hugo. So far I like that quite a bit better, plus it\u2019s free.replyscottmas 14 hours ago | prev | next [\u2013]No one is talking about redundancy though. I love setups like this but prod environments need robust forms of redundancy. Cloud run, k8s, and their ilk are extremely distasteful I\u2019ll grant you (the added complexity and cost almost never are worth it. And don\u2019t get me started on the painfully slow prod debug cycles\u2026) but the redundancy and uptime of them just can\u2019t be beat with a setup like this.Also, none of the solutions discussed here gracefully handle new connections on the new service while waiting for all connections to terminate before shutting down the old service. Maybe some of the more esoteric Ansible do idk.I TRULY want the simplicity of setups like discussed here, but I can\u2019t help but think it\u2019s irresponsible to recommend them in non hobbyist scenarios.replyadamckay 13 hours ago | parent | next [\u2013]You have to decide whether the complexity and cost of a fully redundant system is worth it and consider it against what your SLA is, especially if your redundancy increases the risk of something going wrong because of that extra complexity.From personal experience in B2B web apps, a lot of sales/business MBA type's will say they need 100% uptime, but what they actually mean is it needs to be available whenever their customer's users want to access it, and their users are business users that work 9-5 so there's plenty of scope for the system to be down (either due to genuine outage or maintenance/upgrades).You've possibly also got the bonus of the people that use the app are different to the people that pay for it, so you've also got some leeway in that your system can blip for a minute and have requests fail (as long as there's no data loss), and that won't get reported up the management chain of the customer, because hitting F5 30 seconds later springs it back into life and so they carry on with their day without bother firing an email off or walking over to their bosses desk to complain the website was broken for a second.At a previous company we deployed each customer on their own VM in either AWS or Azure, with the app and database deployed. It was pretty rare for a VM to fail, and when it did the cloud provider automatically reprovisioned it on new hardware, so as long as you configure your startup scripts correctly and they work quickly then you might be down for a few minutes. It was incredibly rare for an engineer to have to manually intervene, but because our setup was very simple we could nuke a VM, spin up another one and deploy the software back onto it in and be up and running again in under 30 minutes, which to us was worth the reduced costs.replyAlexITC 12 hours ago | parent | prev | next [\u2013]> No one is talking about redundancy though. I love setups like this but prod environments need robust forms of redundancyNot really, there are many kinds of apps that don't need such redundancy.> Also, none of the solutions discussed here gracefully handle new connections on the new service while waiting for all connections to terminate before shutting down the old service. Maybe some of the more esoteric Ansible do idk.I have dealt with this in the code with shutdown hooks on the server, waiting for existing requests to finish its processing and reject new requests, clients will just end up retrying, not all apps can accept this but many can.replystrzibny 22 hours ago | prev | next [\u2013]My setup is also kept simple and \"basic.\"Digital Ocean, Rocky Linux or Fedora, systemd services, Bash. I usually run Rails with PostgreSQL. I might use containers more going forwards although I haven't so far.I wrote Deployment from Scratch exactly for showing how to deploy with just Bash.replyquickthrower2 19 hours ago | prev | next [\u2013]I am about to embark on this myself. I was tossing up between DO's app platform (good: no server admin, bad: emphatical, lock in) or just renting a VM like this. This pushes me towards VM.Setting up a python server environment seems to be hard work, with lots of steps (gunicorn and all that) but that said they make the point about using Docker. So maybe docker compose could take a lot of the pain out of it.replyriskable 18 hours ago | parent | next [\u2013]Apache Libcloud supports DigitalOcean:https://libcloud.readthedocs.io/en/stable/compute/drivers/di...So as long as you don't mind writing your deployment scripts using Python you can make them reasonably portable (though honestly every provider has a little bit of quirkiness that needs to be worked around but it's usually trivial stuff).Should solve 95% of that \"lock in\" problem.replyAlexITC 14 hours ago | parent | prev | next [\u2013]Go for it! It isn't as complex as it seems, then, you can decide whether it is worth it.One advantage from DO is the regular backups.Like you said, you can go for executing docker compose on the server if you want to do it fast.replycpursley 19 hours ago | parent | prev | next [\u2013]Check out render.com as well.replyhairofadog 19 hours ago | root | parent | next [\u2013]I\u2019ve been eyeing render.com for a pretty standard rails stack. Have you experienced any drawbacks or limitations with it so far?replycpursley 19 hours ago | root | parent | next [\u2013]Works great with Rails. I\u2019m mostly using it with distributed Elixir natively (which other platforms can\u2019t handle), Hasura (in docker) and some static SPAs (free).I find it just as easy as Heroku, but cheaper. As someone who hates messing with servers and prefers to focus on my product, render is perfect for me.replyashishb 1 day ago | prev | next [\u2013]For web services, I would recommend Google cloud run, Azure container instances, or AWS Fargate for running containers directly. In most cases the price per service would be much lower than 5$/month - https://ashishb.net/tech/how-to-deploy-side-projects-as-web-...replystephenr 1 day ago | parent | next [\u2013]The Google calculator for cloud says anything but the tiniest configuration (256M memory) has a minimum $10/month charge just to exist.A single instance container that runs 24*7 for a month with similar cpu/memory as the $6 droplet is $30/month, before you factor in network costs.replyzokier 22 hours ago | parent | prev | next [\u2013]Idk about other clouds, but AWS Fargate pretty much requires an ELB which adds annoying fixed cost, so for tiny services bare ec2 can be cheaper. Maybe you can amortize the ELB costs over many services but its still something to take into accountreplymoojacob 15 hours ago | root | parent | next [\u2013]I employed a workaround instead of using an Elastic Load Balancer (ELB) for Elastic Container Service (ECS) by incorporating an API Gateway. This approach helped me remain within the free tier. Although Fargate doesn't fall under the free tier, I utilized the EC2 launch type, which should operate similarly. Here's the reference to my idea on Github: https://github.com/jacobduba/ratemydishes/blob/fa63f9e09d34d....replyraybb 1 day ago | parent | prev | next [\u2013]Slightly related, is it feasible to run a syncthing node on something like cloud run with persistent storage attached? If you have an always on computer then it doesn't make sense but if you just have a laptop and phone that only sync now and then it seems like it could work but I haven't seen anyone talk about it.One of the motivating factors is I had a cheap VPS as my syncthing node and it just stopped working one day and won't boot. I haven't had time to debug it and find out exactly why.replypaulkre 19 hours ago | prev | next [\u2013]Is there any reason not to use Docker instead of systemd? I like managing services with a simple docker-compose.yml on my server. It has worked great so far but I wonder if there are some downsides that I am not aware of. Performance doesn\u2019t seem to be an issue, right?replyspenczar5 18 hours ago | parent | next [\u2013]They don\u2019t quite do the same things. Systemd will do stuff like ensure the service is restarted if it ever crashes. It can also make sure system-level dependencies are up and running (\u201cservice B depends on service A, so wait for A to be up before trying to start B\u201d).Performance is not an issue in most docker setups you would ever use, correct.replyWhatsName 18 hours ago | root | parent | next [\u2013]Acutally, there are docker-compose primitives that solve just that (restart: always/on-failure and depends-on: servicename.I think it mostly comes down to what layer of abstraction you like working at.replyspenczar5 14 hours ago | root | parent | next [\u2013]True, Docker-compose has a lot more overlap with systemd.But it doesn\u2019t have system-level dependencies. For example, in systemd I can wait for a network interface to be up and have an IP assigned by DHCP. As far as I am aware, docker compose knows about the docker network and its own containers, but not the system more broadly.Also, you will likely want it to run for a long time, so something has to trigger the docker-compose process to start and restart it. You might want it to restart in case the OOM killer knocks it over. That daemom stuff is what systemd is good for.replystryan 15 hours ago | root | parent | prev | next [\u2013]Problem is you can't have it depend on anything outside of docker i.e. I can't write a docker-compose file that waits for an NFS mount.replyBossingAround 17 hours ago | root | parent | prev | next [\u2013]Podman can generate systemd units for managing containers IIRC.replyjohn-shaffer 17 hours ago | parent | prev | next [\u2013]Performance with Docker is slightly worse, but it shouldn't be an issue for a long-running process. The main problem I've run into is that, by default, Docker logs will eventually fill the disk and crash the server. You have to change the logging system and then delete and recreate all of your containers, because there is no way to change the logging system for existing containers.replyc-hendricks 18 hours ago | parent | prev | next [\u2013]I use docker-compose + systemd. systemd has come in clutch when you need to add waiting for another service to come up.I should really put my homelab setup somewhere.replyAlexITC 14 hours ago | parent | prev | next [\u2013]The author focuses on simplicity, he tries to handle everything with a single file for the app + a single file for the database.Unnecessary overhead gets introduced with docker, for example, now you need to depend on a container-registry + the authentication to pull those images from the server + other stuff.replykillthebuddha 14 hours ago | root | parent | next [\u2013]FWIW there are tons of ways to use Docker without an image (I assume you meant image) registry. If you're running Docker on the server you're deploying to then that's all you need.replyAlexITC 12 hours ago | root | parent | next [\u2013]I guess, still, the image needs to be built somewhere, my bet is that you will do this on the server itself, its unnecessary complexity.replystasmo 18 hours ago | parent | prev | next [\u2013]No not really any reason. Docker has a bit of overhead but greatly simplifies most of the things the author is doing manually with his self-described \u201cbetter than the vast majority of off the shelf solutions\u201d software.replytrufas 17 hours ago | root | parent | next [\u2013]How is setting up a Dockerfile and then a docker-compose file any simpler than just writing a unit file?This seems like a perfect application of the init system.replykebsup 23 hours ago | prev | next [\u2013]My default for websites which do not require database is docker image + Google cloud run. Costs almost nothing, easy clickops deployment from GitHub, https managed, reasonably fast cold starts.replykebsup 20 hours ago | parent | next [\u2013]Just to give some specific numbers: - 40 visits a day - costs 0.01 USD per month - cold start time: 350 ms - however request latencies are 99%: 120ms, 95%: 85ms, 50%: 5ms - there seems to be \"idle\" instance like 80% of the time The website with source: https://github.com/PetrKubes97/ts-neural-networkreplyschemescape 9 hours ago | root | parent | next [\u2013]Am I reading correctly that you\u2019re running a site with 40 visits per day and it\u2019s only costing you 1 cent per month?So you have a container with Alpine Linux and nginx and that\u2019s hosted in Cloud Run and mapped to your domain?When you say \u201cvisits\u201d do you mean the container is active 40 times per day (presumably for not very long)?Edit: what determines when to suspend the container?Edit again: answering the previous question: https://cloud.google.com/blog/topics/developers-practitioner...replykebsup 1 hour ago | root | parent | next [\u2013]Yes, that's exactly right. 40 visits, is just what plausible measures, and looking at GCloud logs, seems that container start count is in similar range.replyngshiheng 23 hours ago | parent | prev | next [\u2013]generally speaking, isnt using vps a lot less expensive than a managed service like cloud run? im assuming the \u201cwebsites\u201d doesnt require to be always available 24/7 (hence the cold start is fine)?replysauercrowd 22 hours ago | root | parent | next [\u2013]really depends on the traffic, but even if you're service ends up running 24x7 you'll end up paying about 10 dollars for a 1CPU/0.5GB RAM instance. So for a lot of stuff Cloudrun will actually work out pretty cheap.Don't underestimate cold starts though. Will be a long time until you need to worry about that if you're backend is written in Go or Rust, but you can hit painful starts pretty quickly when it's Nodejs. Really comes down to (unsurprisingly) image size.replysauercrowd 22 hours ago | root | parent | next [\u2013]Also - this is worth calling outIf coldstarts are a problem, things like fly.io are incredible. Just set the minimum amount of instances to 1, pay 5$ a month and you don't need to deal with anything.It wasn't immediately obvious to me how fly and Cloudrun compare, but the way I think about it now after having used both:In Cloudrun you don't think about any servers, you give them your image and they'll do the rest. It feels serverless in the sense that you don't think about machines.Fly meanwhile is much closer to the infrastructure. It feels more like \"we deploy a docker image to a VM for you\", which let's you much more granuarly control what's going on beyond that.Less magic, but in a good way because more predictable results. Cloudrun has a few fun corners (like no CPU between requests unless you explicitly enable it) that can lead to fun side effects and just make it harder to reason about.replyriskable 18 hours ago | root | parent | next [\u2013]Ugh... I don't want to denigrate your advice (which I'm sure is great) but at this point in the comments we're getting so far away from the, \"keep it simple\" approach in the article that it's getting ridiculous.If you're at the point where you're concerned about cold starts and using a service like fly.io why not just skip the (unbelievable, no-one-knows-this-stuff) complexity and use a $5/month VPS?replysauercrowd 18 hours ago | root | parent | next [\u2013]That's a fair point, but that's essentially what fly does. If the only purpose of your VM is to serve your app (and not as a workspace for you or stuff like that), fly's great because you don't need to do any plumbing to deploy.\"Simply\" using a 5$ VPS sounds great until you need to start writing systemd files, need to keep the box updated, want to deploy straight from GitHub,...replyprmoustache 15 hours ago | root | parent | next [\u2013]It doesn't take more to write a systemd unit file than figuring out the api request or navigating the gui of your favorite cloud service.Nowadays all linux distros offer an unattended way to do packages security updates and reboot the node.replystephenr 18 hours ago | root | parent | prev | next [\u2013]Google cloud run calculator says a 24x7 0.5G instance is $30 a month - the DO droplet with the same cpu/memory is $6/month.The 0.5G instance has a minimum cost of $10 a month, before any kind of traffic metering, or what have you.replyspapas82 14 hours ago | prev | next [\u2013]A pretty same setup with a bunch of differences:1. I'm using a single postgresql database for all apps (each with a different user) on a different server; each app has a different db user2. I use a minio instance for file/media uploads/serving3. I mostly use nginx but i'm transitioning new apps to caddy because of automatic integration with let's encrypt and much smaller config for common purposes4. I use a fab-classic (fabric 1x) script to deploy new versions: https://github.com/spapas/etsd/blob/master/fabfile.py5. For backup I do a logical db backup once per day via cron (using a script similar to this https://spapas.github.io/2016/11/02/postgresql-backup/)6. One memcache instance of all apps7. Each app gets a redis instance (if redis is needed): https://gist.github.com/akhdaniel/04e4bb2df76ef534b0cb982c1d...8. Use systemd for app controlreplyufmace 14 hours ago | prev | next [\u2013]My setup used to be pretty similar. A few changes I've made over the last few years:Moved to Ansible playbooks for all server config, checked into the same Git repo as the code for the project. Sure, I can set it up by hand fine, but then there's no documentation about how the server is currently set up. It's no fun to have to set it all up again by hand if you need to switch to a new server, or try to remember/figure out exactly what you did 3 years ago to set it up when something goes wrong.Docker for the apps. Not as big of a deal with compiled languages, but for interpreted languages, getting a non-ancient version of the interpreter on the bare metal server is a major headache, as is updating that version. Updating the dockerfile to point to Ruby 3.2 by contrast takes just a moment. Docker is also at least as good as bare systemd, probably better, at auto-restarting services, holding configuration secrets, isolating app access, managing logs, etc.I use Ansible to set up and launch the containers because it fits in with all of the other setup steps and it works well with running multiple independent apps on the same server.I've experimented with the super-integrated stuff like Cloud Run. Seems okay if you just want to run an image somewhere, but it seems to me like the complexity and potential for issues multiplies fast once you need supporting services like DBs or caches, periodic background tasks, multiple services running, etc. Might be okay in say AWS with CloudFormation or something, but I'd honestly rather go right to managed K8s instead. It's a little more complex, but quite capable and can be run on a bunch of different cloud services.replyguax 19 hours ago | prev | next [\u2013]I'm rocking a Linode VM with nginx and static html files. Very little attack surface, no complexity, etc.In the past I would have templates, analytics and the works. Today I just want to have the shit up there and that's it.replydmvdoug 13 hours ago | parent | next [\u2013]Just curious: what\u2019s the difference between the past and today? What changed for you?replynewaccount74 23 hours ago | prev | next [\u2013]I used to host everything on one or two VMs, but I've switched to using a separate VM for every service.On the one hand, it's a security thing: if one service gets breached by a catastrophic security hole, the rest of the servers should hopefully be unaffected.But the main reason for it is ease of administration. I don't need to bother with Python virtual envs or RVM for Ruby or juggle multiple PHP versions, I can just install the version I want with apt and everything just works.When I pass a project on to someone else, I can just give them access to the VM so they can easily migrate it.That convenience is worth a few Euros per month. (my total hosting bill varies but I don't think it was ever more than 50\u20ac per month)replyAlexITC 14 hours ago | parent | next [\u2013]I do the same, a VM per app, unless it's about static websites which I can host so many on a single VM.replytrustingtrust 1 day ago | prev | next [\u2013]Is there a way to buy droplets for a year at a time? Like 40$ for a year would be a sweet deal for the $4 droplet. Especially for things like PiHole and wireguard.replyxmodem 1 day ago | parent | next [\u2013]If your goal is to minimise costs, some of the cheaper providers that have offers on https://lowendbox.com/ will have reasonable annual discounts.replyKronisLV 1 day ago | root | parent | next [\u2013]Do remember that there have been cases of some of the more budget oriented providers just folding and the company disappearing altogether. That actually happened with me, with DediStation: https://lowendtalk.com/discussion/114949/is-dedistation-a-re...Nowadays I'd generally go for hosting providers that have been around for some time.Hetzner: has both great features and affordable costs (I needed to verify my ID, though)Contabo: the prices are great, but the performance is a bit worse than other optionsTime4VPS: a Lithuanian provider that I used due to them being cheaper than Hetzner, unfortunately their prices have increased noticeably, only the yearly plans are worth itDigitalOcean, Scaleway, Vultr: all have good features, but can be expensiveAzure, AWS, GCP: too complex and enterprisey for my private needsreplyzootboy 15 hours ago | root | parent | next [\u2013]I consider a provider from LowEndBox disappearing one day a near-certainty. In my experience (N = ~10), an average LEB provider will have an existence half-life of around 3 years.That's not to discourage anyone from using them; in fact, LEB VPS servers are pretty much all I use (each being ~$25 / year), and I've gotten quite good at keeping useful, tested backups, keeping redundancy in my services, and being able to stand up a new server quickly.replyyread 23 hours ago | root | parent | prev | next [\u2013]Happened to a friend of mine.His backups were the offsite but with same company so he was completely screwedreplyhabibur 1 day ago | root | parent | prev | next [\u2013]Also those hidden costs. You don't know about those until you are charged for it, and was written in their terms which you never bothered to read.replytrustingtrust 21 hours ago | root | parent | prev | next [\u2013]goal is to minimize costs from a big provider by buying in bulk. Something similar to spot instances.replysgarland 20 hours ago | parent | prev | next [\u2013]No idea about DO, but for years I bought a t3a.micro for about $30/year. If you committed to 3 years it got even cheaper.replycarlosbaraza 12 hours ago | prev | next [\u2013]Anyone considered deploying with docker compose? Simple, well known and pretty flexible. I wrote some helpers to manage monitoring, logs, and deployments: lostdock.comreplyl5870uoo9y 23 hours ago | prev | next [\u2013]Neat setup. Regarding the deploy script. I have just setup a separate VPS for proxying database queries using various Node database drivers for my own project[1] and only used Github Actions managing it[2]:- add build script using Github Action that fails the entire build pipeline if code doesn't build- add deploy script (essentially a few commands ssh into your VPS and pulling, install, building and restarting)I was surprised how easy it was. Naturally you need to get your hands a bit dirty compared to managed solutions, but using AWS with Lambda, Gateway, NAT (since I required a static IP) would have taken way time and costed significantly more.[1]: https://aihelperbot.com/[2]: https://gist.github.com/danielwetan/4f4db933531db5dd1af2e69e...replydcminter 22 hours ago | prev | next [\u2013]> It's statically linked, and [...] secrets [...] are compiled into the binaryDepends a lot on what you're doing this for; in particularly for personal stuff then you do you - but this particular item does give me pause.But then I use AWS for pretty much all my personal stuff, so I guess I have the overkill mindset already?replyAlexITC 15 hours ago | parent | next [\u2013]The way I do it is to set the `EnvironmentFile` entry in the service definition.I'd guess that the author's idea is that if someone gains access to the server, the secrets would be either dumped from the binary or the environment file, if so, why to bother with another file?replylockhouse 22 hours ago | parent | prev | next [\u2013]Do you use LightSail or is it just regular AWS?I\u2019ve never used LightSail but it looks like a good deal.replydcminter 17 hours ago | root | parent | next [\u2013]Nope - in fact right now I'm not running much at all; just some static hosting with S3 and CloudFront which costs pennies a month. For a blog that's pretty much write-only and that not very often.When I'm playing with more complex stuff I spin up an ECS with Fargate hosted containers. That's mostly for fun though.replyrmilejczz 19 hours ago | parent | prev | next [\u2013]Cloudformation gang representreplybavarianbob 13 hours ago | prev | next [\u2013]> One complaint about this setup is that paying $5/month for every service you want to run is a lot.Oh, you sweet summer child.replykillthebuddha 14 hours ago | prev | next [\u2013]Since we're all sharing our favorite simplest solutions, I guess I'll throw https://fly.io out there. The DX is far from perfect right now so this answer is _ever-so-slightly theoretical_ but, if you know how to use Docker, `fly launch` is extremely hard to beat.replyidazuwaika 20 hours ago | prev | next [\u2013]Is this really enough? What about oscap-scanning regularly, EDR/XDR protection with CrowdStrike or Wazuh, dependency scanning, anti-virus and general vulnerability management?replyicedchai 13 hours ago | parent | next [\u2013]Nobody outside the enterprise does this.replyjauntywundrkind 19 hours ago | parent | prev | next [\u2013]If you only install Debian packages & the apps you compile is is quite unlikely you need \"edr/xdr protection, dependency scanning, anti virus\".The author has snapshots faced every 6 hours. Even if something did happen, I feel like the time to recovery would be not bad. And the time & bad energy saved not worrying about all this obnoxious & almost certainly irrelevant enterprise grade security concerns seems greatly relieving.replyUnixSchizoid 21 hours ago | prev | next [\u2013]I just have everything running on proxmox with mostly FreeBSD vms.replybackendanon 17 hours ago | prev | next [\u2013]\"a reverse proxy. The main advantage to this is that nginx can do TLS termination\"I use Apache for the same purpose, works great, always has.replyAlexITC 15 hours ago | parent | next [\u2013]Rate limiting and caching is another big advantage, setting it up with nginx is a piece of cake, setting it up in the app, not so much.replyrenegade-otter 14 hours ago | prev | next [\u2013]Didn't we have a thread recently about the dangers of using Let's Encrypt?If on AWS, and if your servers are behind a load balancer, just install a certificate on those. Isn't that a little better?replyAlexITC 14 hours ago | parent | next [\u2013]> If on AWS, and if your servers are behind a load balancer, just install a certificate on those. Isn't that a little better?My take from the post is that author's goal is simplicity, AWS isn't simple, also AWS load balancers are expensive.replysiliconc0w 18 hours ago | prev | next [\u2013]I really don't understand the sqlite fad, you can run postgres on the same instance and get a much more capable database but also have the freedom to expand to a tiered architecture if you want.For personal things I just use an EC2 instance w/ docker compose.replyadamckay 17 hours ago | parent | next [\u2013]Because Postgres is another thing you have to run, maintain and monitor, and you have to make a judgement whether that extra complexity is worth it - for a lot of simple projects, it's not.SQLite is a library you use in your application process that writes to a file. There's a bit of care you have to do to ensure you back up that file safely, but there's no extra monitoring or maintenance above what you do for your app anyway.I agree that running Postgres isn't terribly difficult, but no matter how simple you try to make a small Postgres instance, SQLite is simpler.replyAlexITC 15 hours ago | parent | prev | next [\u2013]I run a setup that's very similar to the author's one, but, I run postgres.For a simple setup, postgres maintenance is practically null.replyxmodem 1 day ago | prev | next [\u2013]I'm a fan of this approach in general, but I've been looking for a way to accomplish almost the same thing, except I would like to have the version defined in a git repository.I suppose I could git pull on a cron job, copy over the systemd unit files, and restart, but I'd like to have just a little more smarts than that. I've been working on my own tool to accomplish this but it's not super stable just yet.replyturboponyy 1 day ago | parent | next [\u2013]NixOS, whilst being a huge time sink, delivers exactly on that promise and then some.replyfhaldridge7 1 day ago | root | parent | next [\u2013]I switched from Ansible and YAML-hell to NixOS and never looked back. Still learning Nix but it's easy to get started with the basics and then refactor things laterreplyxupybd 1 day ago | parent | prev | next [\u2013]I do this with gitlab and Cron. Commit to main on gitlab and a ci script builds the project and sftps a zip to the staging server. A Cron job checks for new zips in the directory and unzips, then installs the update. After that it restarts the job and I have a new version ready to test in staging.replyJ_tt 23 hours ago | root | parent | next [\u2013]Have you considered installing a GitLab runner on your deploy machine to run jobs specifically tagged to deploy that app?It\u2019s a super easy setup and saves managing SSH keys in env variables etc while still being really quick!replyxupybd 22 hours ago | root | parent | next [\u2013]I didn't think about doing that. It's a great idea.replygkhartman 1 day ago | parent | prev | next [\u2013]I've been using Ansible to deploy ~10 services from git repos to a set of KVMs. After paying the time tax of writing the playbooks, I just update a release version variable for the service I want to update and rerun the playbook. It will even take care of the systemd restarts.I'm pretty happy with that set up. Ansible has just enough smarts to be less tedious than shell scripting, but dumb enough that it's behavior is easy to figure out in most cases.Now I'm tempted to try running it nightly from cron.replyAlexITC 15 hours ago | root | parent | next [\u2013]We are on the same boat, my ansible scripts have barely changed in the past 7 years, still, I have been wondering about getting rid of ansible for simple scripts to handle everything, the main reasons being speed and simplicity (1 file vs many files).replykubanczyk 20 hours ago | parent | prev | next [\u2013]> I suppose I could git pull on a cron job, copy over the systemd unit files, and restart, but I'd like to have just a little more smarts than that.How complex... You know that you can simply git push to just about any ssh account, right?replyxmodem 13 hours ago | root | parent | next [\u2013]Of course, but the point is not just to get configuration into git, it's also to get out of the business of SSH'ing to individual servers.replyZoolaris 22 hours ago | parent | prev | next [\u2013]I made a small python flask app that would listen to a webhook and then do a git pull on the directory. This has worked super well for the few random website projects i hostreplymarcrosoft 15 hours ago | prev | next [\u2013]I do the same. OpenBSD, Go, SQLite, and rcctl.replymamcx 16 hours ago | prev [\u2013]Almost same, but mines are:- NixOS:Was hard to figure out at first but is the MOST no-brained deployment setup after +20 years doing things. Is super easy to upgrade, add-remove things in a predictable way. Also, I love how ALL the config + security tweaks are in a single place (I Just do a big NixOS config to see everything at once).Another big win with nixos is that you can do a very constrained setup and if for some reason need to do something that require a install you can do it once without polluting the install and it disappear after it (like: Install node, run things, get out and node and their dirt gone!)- PGI wish to use only Sqlite but it lack vital features for me (like proper stored procedures) and have the ability to access the DB with TailScale is a big plus when tracing a problem with a customer.replyGuidelines | FAQ | Lists | API | Security | Legal | Apply to YC | ContactSearch:",
    "hn_summary": "- HTTP triggered cloud functions are highly praised for their simplicity and performance.\n- The use of a reverse proxy like nginx or Apache is beneficial for TLS termination, rate limiting, and caching.\n- The author emphasizes simplicity and cost-effectiveness in their server setup, with a focus on maintaining and monitoring their own infrastructure."
  },
  {
    "id": 36747893,
    "timestamp": 1689520297,
    "title": "The Pacific Northwest Tree Octopus",
    "url": "https://zapatopi.net/treeoctopus/",
    "hn_url": "http://news.ycombinator.com/item?id=36747893",
    "content": "About HELP! FAQs Sightings Media Activities LinksThe Pacific Northwest Tree OctopusRare photo of the elusive tree octopus(Enhanced from cropped telephoto)The Pacific Northwest tree octopus (Octopus paxarbolis) can be found in the temperate rainforests of the Olympic Peninsula on the west coast of North America. Their habitat lies on the Eastern side of the Olympic mountain range, adjacent to Hood Canal. These solitary cephalopods reach an average size (measured from arm-tip to mantle-tip,) of 30-33 cm. Unlike most other cephalopods, tree octopuses are amphibious, spending only their early life and the period of their mating season in their ancestral aquatic environment. Because of the moistness of the rainforests and specialized skin adaptations, they are able to keep from becoming desiccated for prolonged periods of time, but given the chance they would prefer resting in pooled water.An intelligent and inquisitive being (it has the largest brain-to-body ratio for any mollusk), the tree octopus explores its arboreal world by both touch and sight. Adaptations its ancestors originally evolved in the three dimensional environment of the sea have been put to good use in the spatially complex maze of the coniferous Olympic rainforests. The challenges and richness of this environment (and the intimate way in which it interacts with it,) may account for the tree octopus's advanced behavioral development. (Some evolutionary theorists suppose that \"arboreal adaptation\" is what laid the groundwork in primates for the evolution of the human mind.)Reaching out with one of her eight arms, each covered in sensitive suckers, a tree octopus might grab a branch to pull herself along in a form of locomotion called tentaculation; or she might be preparing to strike at an insect or small vertebrate, such as a frog or rodent, or steal an egg from a bird's nest; or she might even be examining some object that caught her fancy, instinctively desiring to manipulate it with her dexterous limbs (really deserving the title \"sensory organs\" more than mere \"limbs\",) in order to better know it.Map of estimated tree octopus maximum range, including spawning watersTree octopuses have eyesight comparable to humans. Besides allowing them to see their prey and environment, it helps them in inter-octopus relations. Although they are not social animals like us, they display to one-another their emotions through their ability to change the color of their skin: red indicates anger, white fear, while they normally maintain a mottled brown tone to blend in with the background.The reproductive cycle of the tree octopus is still linked to its roots in the waters of the Puget Sound from where it is thought to have originated. Every year, in Spring, tree octopuses leave their homes in the Olympic National Forest and migrate towards the shore and, eventually, their spawning grounds in Hood Canal. There, they congregate (the only real social time in their lives,) and find mates. After the male has deposited his sperm, he returns to the forests, leaving the female to find an aquatic lair in which to attach her strands of egg-clusters. The female will guard and care for her eggs until they hatch, refusing even to eat, and usually dying from her selflessness. The young will spend the first month or so floating through Hood Canal, Admiralty Inlet, and as far as North Puget Sound before eventually moving out of the water and beginning their adult lives.Why It's EndangeredRoute 101, separating the rainforests of the Olympic Peninsula from Hood CanalAlthough the tree octopus is not officially listed on the Endangered Species List, we feel that it should be added since its numbers are at a critically low level for its breeding needs. The reasons for this dire situation include: decimation of habitat by logging and suburban encroachment; building of roads that cut off access to the water which it needs for spawning; predation by foreign species such as house cats; and booming populations of its natural predators, including the bald eagle and sasquatch. What few that make it to the Canal are further hampered in their reproduction by the growing problem of pollution from farming and residential run-off. Unless immediate action is taken to protect this species and its habitat, the Pacific Northwest tree octopus will be but a memory.The possibility of Pacific Northwest tree octopus extinction is not an unwarranted fear. Other tree octopus species\u2014including the Douglas octopus and the red-ringed madrona sucker\u2014were once abundant throughout the Cascadia region, but have since gone extinct because of threats similar to those faced by paxarbolis, as well as overharvesting by the now-illegal tree octopus trade.Tree Octopus hat from 1923The history of the tree octopus trade is a sad one. Their voracious appetite for bird plumes having exhausted all the worthy species of that family, the fashionistas moved on to cephalopodic accoutrements during the early 20th Century. Tree octopuses became prized by the fashion industry as ornamental decorations for hats, leading greedy trappers to wipe out whole populations to feed the vanity of the fashionable rich. While fortunately this practice has been outlawed, its effects still reverberate today as these millinery deprivations brought tree octopus numbers below the critical point where even minor environmental change could cause disaster.While efforts were made in the past to preserve remaining tree octopus habitat, these were met with resistance by the timber industry, which has traditionally viewed the tree octopus as a nuisance, both because the octopuses favor the valuable, moss-shrouded trees of old growth forests\u2014pitting conservation needs against lucrative sources of lumber\u2014and because octopuses hiding among felled trees often gummed up sawmills and stained pulp vats with their ink.Traveling sideshow exhibits, such as this one by Glen \"Bones\" Hartzell from 1942, demonized tree octopuses to the ignorant masses(Click to enlarge)These nuisances led many loggers to regard tree octopuses as bad luck, resulting in the pointless killing of octopuses on sight at logging camps in a misguided attempt at eradicating the troublesome species. Anti-octopus sentiment was so strong among loggers that some even began to fear that the octopuses were prone to attacking humans.These fears were fueled in no small part by gratuitous stories involving tree octopuses harassing lumberjacks and distressing damsels in Northwestern-themed pulp magazines of the 1930-40s and variously \"nipping\", \"entangling\", or \"suckering the flesh\" of the heroes of men's action magazines of the 1950-60s. (The magazine publishers depended on cheap paper made from wood pulp and were glad to contribute to the anti-octopus propaganda campaign of the timber industry.)To this day, misunderstanding and fear of these gentle creatures can still be found among many old timers, although education campaigns\u2014and special octopus-separators installed at sawmills\u2014have largely halted the practice of tree octopus eradication.How You Can HelpActivism:Want to become a Tree Octopus Activist? How You Can Help...Activities:Spread awareness and help a tree octopus with our Tree Octopus Activities...More Tree Octopus InformationPosters motivate the citizenry to action! Post them!Tree Octopus FAQs \u2014 Frequently asked questions, now with answers.Tree Octopus Sightings \u2014 Includes photos of and behavioral research on the Pacific Northwest Tree Octopus and other tree octopus species.Tree Octopus In The Media \u2014 appearances of tree octopuses, both real and fictional, in the media and popular culture.Research On Other Tree Octopus Species:Pitch-Chewing Tree Octopuses Of British Columbia \u2014 Octopuses in BC have long been reported chewing the pitch of Sitka spruce like gum, and will even go into the trees to forage for it.Olive Loving Tree Octopuses Of Antiquity \u2014 Octopuses in Greece were known since ancient times to climb olive trees to feast on the tasty fruit.More On Old World Tree Octopuses \u2014 Ancient writers, such as Aristotle and Pliny the Elder, tell of octopuses that venture onto land, including one that used a tree to commit burglary.The Ara-Eaters: Tree Octopuses Of Polynesia \u2014 Reports from the 1800s tell of island octopuses that are attracted to the fragrant flowers of the pandanus tree.Nicharongorong: Tree Octopuses of Micronesia \u2014 Reports of Palauan tree octopuses that give birth in mangrove trees and eat lizards.Devon Hedge Octopus \u2014 Species of octopus that once lived in the primeval forests of Devon, UK, until deforestation drove them into the hedges and possibly to extinction.About HELP! FAQs Sightings Media Activities LinksThe author of this article and its subsections is Lyle Zapato.This site is not associated with any school or educational organization,other than the Kelvinic University branch of the Wild Haggis Conservation Society.Not to be confused with the Pacific Northwest Octopus Tree.",
    "summary": "- The Pacific Northwest tree octopus is a rare and unique creature found in the temperate rainforests of the Olympic Peninsula on the west coast of North America. It is the only known amphibious species of cephalopod.\n- The tree octopus has advanced behavioral development and explores its arboreal world using its sensitive suckers and eyesight comparable to humans. It displays emotions through changing the color of its skin.\n- The tree octopus is currently endangered due to habitat destruction, road construction, predation by foreign species, and pollution. Immediate action is needed to protect its habitat and prevent extinction.",
    "hn_title": "The Pacific Northwest Tree Octopus",
    "original_title": "The Pacific Northwest Tree Octopus",
    "score": 363,
    "hn_content": "Hacker News new | past | comments | ask | show | jobs | submit loginThe Pacific Northwest Tree Octopus (zapatopi.net)363 points by cratermoon 18 hours ago | hide | past | favorite | 168 commentsblamazon 18 hours ago | next [\u2013]I don't mean to spoil the fun, downvote me if this is not in the spirit, but it took me way too long to figure this out and others may be as slow as me and save some time by reading this comment:> The Pacific Northwest tree octopus is an Internet hoax created in 1998 by a humor writer under the pseudonym Lyle Zapato. Since its creation, the Pacific Northwest tree octopus website has been commonly referenced in Internet literacy classes in schools and has been used in multiple studies demonstrating children's gullibility regarding online sources of information. [1][1]: https://en.wikipedia.org/wiki/Pacific_Northwest_tree_octopusreplyoatmeal1 17 hours ago | parent | next [\u2013]> I don't mean to spoil the fun, downvote me if this is not in the spirit, but it took me way too long to figure this out and others may be as slow as me and save some time by reading this comment:I believed it too. The thing is, this is something no one is really incentivized to lie about. If some website says \"politician did X\", then your lie detector turns on, because it's worth it for lots of websites to lie or mislead about that. It would be very hard to go through life questioning the veracity of every inconsequential bit of information that no one has an incentive to lie about. I don't think it demonstrates much that students believed it. And I especially don't think it means anything about gullibility about information found online. Almost certainly, if it were printed in a book, they'd be even more likely to believe it.replymegmogandog 15 hours ago | root | parent | next [\u2013]It reminds me of a friend in high school who convinced me that he grew scallions in his bathroom. It seemed weird but he described it in some detail, how the humidity from the shower is good for them, etc. Then when I believed him he said of course I don't do that, how could you think something so ridiculous. I don't and didn't feel like believing him in this context made me gullible for the same kinds of reasons you outline, why doubt something so inconsequential, communicated 'sincerely'?replyClamchop 10 hours ago | root | parent | next [\u2013]I get just a little annoyed, a reasonable amount, when someone leans into a lie for a long time, gives details, won't give it up, and even if I started out skeptical, I eventually start to believe them, only for them to pull the rug out and call me gullible or stupid or something.No, I just made the mistake of trusting you and your persistence!replyDunati 1 hour ago | root | parent | prev | next [\u2013]I was talking to my kids about this sort of thing recently, but in the context of scientific scepticism.I don't think believing makes you gullible, is just that the consequences for believing in this case are negligible. At worst, you repeat the story to someone else, as second-hand fact. Mostly likely however, you'd never think of this conversation again, and it would have no effect on your behaviour. I think it says much more about the person telling the lie (this is a shitty thing to do to a friend) than the person accepting the lies.Extraordinary claims may require extraordinary evidence, but it really only matters at the point where believing those claims affects one's behaviour and the consequences are tangible and different from refutation of those claims.replyadonovan 7 hours ago | root | parent | prev | next [\u2013]My daughters recently showed me how easy it is to grow scallions: too easy. Just cut off the bottom inch (the white bit with little roots hairs) and stick in a jar of water by a window. A week later: a complete scallion!replyawwaiid 15 hours ago | root | parent | prev | next [\u2013]Best response / revenge is to actually grow scallions in your bathroom.Or at least pretend to.replyethbr0 13 hours ago | root | parent | next [\u2013]Best response would be to sneak into your friend's bathroom and leave baby scallions.reply__MatrixMan__ 5 hours ago | root | parent | next [\u2013]In the back of the toilet.replytopato 15 hours ago | root | parent | prev | next [\u2013]I could easily imagine an episode of Seinfeld where Kramer grows scallions in his bathroomreplymarkdown 14 hours ago | root | parent | next [\u2013]They'd be destroyed by the elephant showerhead.reply__MatrixMan__ 5 hours ago | root | parent | prev | next [\u2013]My wife grows plants in our shower for that reason. Not scallions, but it's other the same story. I bet he did have plants in his bathroom and for some reason switched gears about wanting to talk about it.replyaklemm 5 hours ago | root | parent | next [\u2013]Sure she doesreplytchaffee 11 hours ago | root | parent | prev | next [\u2013]He may have gotten this from real story from a distant relative or family friend as this is a real hobby and the humidity is a key factor. At almost $16 for a small bottle of XO sauce[1] with the main ingredient being dried scallops, it's a highly profitable home hobby.[1] https://en.m.wikipedia.org/wiki/XO_saucereplyhooverd 11 hours ago | root | parent | next [\u2013]Green onions, not shellfish. Close!replytchaffee 10 hours ago | root | parent | next [\u2013]Gotchareplyhooverd 10 hours ago | root | parent | next [\u2013]I would like to know more about growing scallops in the tub. Bathtub aquaculture is the Bitcoin.replyZuider 6 hours ago | root | parent | next [\u2013]You can use the Polynesian palm scallop, which attaches itself to the damp bathroom wall in picturesque clusters like roof shingles. It is an aerial filter feeder, capable of subsisting on household dust (which is mainly organic matter) though for faster growth, one can use a fine-mist spray of blended sausage meat and soggy marrowfat peas. They are also excellent for repelling rats, their natural predator, by emitting sharp bursts of ultrasound when the rodent's presence is detected.The problem is in getting hold of them, as trade in this protected species is illegal.replyramesh31 10 hours ago | root | parent | prev | next [\u2013]It's an important life lesson for honest people that yes, in fact many other people will lie straight to your face with things made up from whole cloth that they have zero incentive to lie about. You think \"people wouldn't literally just make something up\", but they do. They do all the time.replyjimmydddd 13 hours ago | root | parent | prev | next [\u2013]Agreed. I think the fact that it was just \"scalions\" adds to the credibility.replyta8903 4 hours ago | root | parent | prev | next [\u2013]Don't let it get to you, we live in a trust based society after all.replyNatsu 12 hours ago | root | parent | prev | next [\u2013]Then they get you on the flip side when somebody does something way out there that's almost unbelievable. It took a couple of decades for Epstein to be shut down, after catching him once and him getting away with a slap on the wrist.replyretrocryptid 15 hours ago | root | parent | prev | next [\u2013]Pablo Picasso once said \"Art is the lie that reveals the truth.\" Except that he didn't really say that. What he said was \"Art is a lie that makes us realize truth, at least the truth that is given us to understand.\" (The Arts: An Illustrated Monthly Magazine Covering All Phases of Ancient and Modern Art, NYC, 1923)Is there a subtle truth to your friend's lie? It need not be related to scallions. We perceive the world through narrative. Perhaps your friend was introducing a fundamental truth through the revelation of scallions growing in a bathroom. Or at least that's how we would interpret it on my home planet of Zeta Reticulii IV. Of course the \"fact\" that I'm from Zeta Reticulii IV is a lie. I grew up in Texas. You can make your own decisions regarding the relative adherence to consensual reality between Texas and Zeta Reticulii IV.Perhaps the story of growing scallions in the bathroom is nothing other than the creation of a shared history. Does it matter that history is counter-factual? We're social beings. We do things like that.replyZuider 6 hours ago | root | parent | next [\u2013]In must cultures of the world, shared history is a consensual fiction, which is regarded as being truer than the truth.replyalwaysbeconsing 17 hours ago | root | parent | prev | next [\u2013]> The thing is, this is something no one is really incentivized to lie aboutI don't think it's lying in the sense of trying to make someone else actually believe it. It's just a form of creative fiction writing. It can be a lot of fun to write in this mode; when well done it's a pleasant kind of erudite humor because to produce it (and get it) you have to be somewhat knowledgeable in the topic. Mockumentaries might be the film/TV equivalent. Unfortunately (especially for certain subjects) it also confuses and causes strife if readers take it too seriously.replyZuider 6 hours ago | root | parent | next [\u2013]The British Flat Earth Society is a joke society in this vein. They amuse themselves by writing very erudite debunkings of the nefarious Spherical Earth conspiracy theory, and sending strongly worded Cease & Desist notices to NASA.replydragonwriter 16 hours ago | root | parent | prev | next [\u2013]> The thing is, this is something no one is really incentivized to lie about. If some website says \"politician did X\", then your lie detector turns on, because it's worth it for lots of websites to lie or mislead about that.The purpose of misleading about \u201cpolitician did X\u201d is to sell a call to action. Any time there is a call to action supported by a claim, there is an obvious motivation for misrepresentation (the very same one present when \u201cpoliticia did X\u201d is the claim.) This contains a call to action, ergo, it has an obvious motivation for misrepresentation.> I don't think it demonstrates much that students believed it.I think it demonstrates a lot that half of 13-year-old students in the US study believed a page which referenced a fictitious nation-state in the Pacific Northwest was reliable, leaving aside the other indicia of deception. Though whether what it says is about internet literacy or complete failure of education on geography perhaps less clear.replygodelski 15 hours ago | root | parent | next [\u2013]> I think it demonstrates a lot that half of 13-year-old students in the US study believed a page which referenced a fictitious nation-state in the Pacific Northwest was reliable, leaving aside the other indicia of deception.I'm just going to leave this here>> Although the tree octopus is not officially listed on the Endangered Species List, we feel that it should be added since its numbers are at a critically low level for its breeding needs. The reasons for this dire situation include: decimation of habitat by logging and suburban encroachment; building of roads that cut off access to the water which it needs for spawning; predation by foreign species such as house cats; and booming populations of its natural predators, including the bald eagle and sasquatch.replysimondw 12 hours ago | root | parent | prev | next [\u2013]> fictitious nation-stateAre you referring to Cascadia? That's a perfectly non-fictional name for the region (https://en.wikipedia.org/wiki/Pacific_Northwest).Or maybe I missed another reference?replydragonwriter 9 hours ago | root | parent | next [\u2013]Cascadia is a perfectly non-fictional name for the region, the Republic of Cascadia Department of Cephalopod Conservation, OTOH, is an extremely fictional agency of an equally fictional government.replymolticrystal 14 hours ago | root | parent | prev | next [\u2013]Well there are mudskippers [0] [1] which can end up crawling up to and resting on branches and trees growing out of the water. So while it seems untrue, it wouldn't be far fetched for a species of octopus adapted to end up doing so, especially if the out of water circumstances are narrow enough(very temporary, trunks & branches very close to water, etc).[0] https://en.wikipedia.org/wiki/Mudskippers[1] https://www.youtube.com/watch?v=LNCYSCHipvwreplymr_toad 10 hours ago | root | parent | next [\u2013]There is a species of octopus that does crawl out of the water to hunt (Australian, of course), but they don\u2019t climb trees.https://www.youtube.com/watch?v=ebeNeQFUMa0replyLilBytes 9 hours ago | root | parent | next [\u2013]Well that Octopus and I have a lot of common.* live in Australia* love to eat Blue Swimmer CrabsreplyRajT88 7 hours ago | root | parent | prev | next [\u2013]And there's enough improbable animals out there it doesn't sound crazy. Shrimps that live in the desert, crabs that live on land, frogs which live in trees, lobsters and mussels and shrimps and jellyfish that live in fresh waters.replyJuanPosadas 8 hours ago | root | parent | prev | next [\u2013]> It would be very hard to go through life questioning the veracity of every inconsequential bit of information that no one has an incentive to lie about.Some fish-looking sea creatures are actually mammals. Sea horses have pregnant males. Deep sea fish look like horror monsters. A fresh water octopus just isn't that unbelievable.replybrnt 4 hours ago | root | parent | prev | next [\u2013]The incentive is practice in the conspiracy ideas market. It's fun to fool people, and these days it's profitable. Enter a popular conspiracy forum and you'll see how many are there to sell things. They create their own market.replysetgree 10 hours ago | root | parent | prev | next [\u2013]So I immediately googled because it rang an alarm bell that some octopuses would develop specialized air-breathing apparatuses \u2014 that conflicts with my basic understanding of evolution. But I wasn\u2019t googling it to falsify, but rather to see from a more \u2018objective\u2019 source if/how this occurred.I think it\u2019s the same basic principle as hanging up if a relative calls you begging for money or proclaiming to be kidnapped and calling you back. The costs for double-checking incredible claims is often not that high.replySelf-Perfection 6 hours ago | root | parent | prev | next [\u2013]Even widespread information can be false. For instance, you can not \"catch cold\" by getting cold, the name of the illness is misleading.I mean absence of incentive to lie is far from universal criteria to distinguish false information.replybrewdad 9 hours ago | root | parent | prev | next [\u2013]The site does include a call to action. I think that\u2019s the point where one needs to question things. I certainly don\u2019t want to be the one that writes my Congressperson about this \u201choax\u201d. The next time I need something truly important, I\u2019m likely to fall to the bottom of the pile.replyMattGaiser 17 hours ago | root | parent | prev | next [\u2013]Add in that the animal world is full of wacky creatures that don't fit heuristic models for plausibility.People thought the Platypus was a hoax was it was initially discovered. It is real.replydragonwriter 16 hours ago | root | parent | next [\u2013]> Add in that the animal world is full of wacky creatures that don't fit heuristic models for plausibility.The animal involved not meeting heuristic models for plausibility may be something that should trigger skepticism, but its not the thing that should tell you this is a lie.replystephenr 16 hours ago | root | parent | prev | next [\u2013]People still call the dropbear a hoax.replyUncleSlacky 14 hours ago | root | parent | next [\u2013]And haggis hunting: https://darachcroft.com/news/haggis-hunting-season-tips-and-...replybuildbot 16 hours ago | root | parent | prev | next [\u2013]Is it not? The Wikipedia article literally has in the tagline: famous hoax\u2026replyrpeden 15 hours ago | root | parent | next [\u2013]That's certainly what the dropbears want you to believe.replystephenr 9 hours ago | root | parent | prev | next [\u2013]Don\u2019t believe everything you read on the internet.There are people who say birds aren\u2019t real, or that Australia isn\u2019t real, or that the earth is flat.replymc32 17 hours ago | root | parent | prev | next [\u2013]Add the propensity to colloquially grant newly discovered things names that borrow from existing things: sea cow, catfish, etc. so why couldn\u2019t there be something called a tree octopus?replydragonwriter 16 hours ago | root | parent | next [\u2013]> Add the propensity to colloquially grant newly discovered things names that borrow from existing things: sea cow, catfish, etc. so why couldn\u2019t there be something called a tree octopus?There could be. The name of the animal isn't what gives the lie away.replyMattGaiser 16 hours ago | root | parent | prev | next [\u2013]Today I learned that a tree crab is a thing. I knew a tree lobster was a thing. There is something that could plausibly be called a tree clam.replygweinberg 7 hours ago | root | parent | prev | next [\u2013]Of course they would be more likely to believe a book, they should be. That's the point: making a web page is super easy, anyone can do it. Making a convincing fake issue of a science magazine would be a lot harder, it's highly unlikely someone would do it just for a joke.But really, if there were something as bizarre as a tree octopus, you would have heard of it.replytshaddox 16 hours ago | root | parent | prev | next [\u2013]If no one is incentivized to lie about it, is anyone incentivized to tell the truth about it?replyTeever 16 hours ago | root | parent | prev | next [\u2013]> this is something no one is really incentivized to lie about.'Click here to donate to my gofund me to save the amphibious octopus.'replyreplygirl 17 hours ago | root | parent | prev | next [\u2013]i know enough about octopuses and forests that i don't have to care about the author's motives--i just have to skim the text or look at the photoshop. thinking a tree octopus is real because you saw a lot of words and can't relate them to a nexus of disinformation is a perfect example of gullibilityreplyBaseballPhysics 17 hours ago | root | parent | next [\u2013]There are large crabs that climb trees and eat coconuts.There are fish that can survive on dry(-ish) land for extended periods of time.And don't get me started on the utterly bizarre slime mold.The number of species that defy our expectations is countless.Bluntly, there's a lot of arrogance in the claim that anyone should be able to easily and automatically rule out the existence of some species based on their personal knowledge, and that anyone who fails to do so is \"gullible\".replyreplygirl 17 hours ago | root | parent | next [\u2013]> there's a lot of arrogance in the claim that anyone should be able to easily and automatically rule out the existence of some species based on their personal knowledgesome, certainly yes.i don't think anyone would disagree that some claims are more plainly ridiculous than others. i'm replying to someone who let themselves be convinced the tree octopus was real by a page picturing an octopus climbing a tree. let's not abdicate our regard for common sense.replyBaseballPhysics 17 hours ago | root | parent | next [\u2013]I think you'll find your idea of \"common sense\" is perhaps not so universal as you think.For example, why is a tree octopus any less likely than the platypus, a venomous aquatic mammal that has a beak, lays eggs, and detects prey by sensing electric fields like a shark?replyMichelangelo11 15 hours ago | root | parent | next [\u2013]The reason the tree octopus as described by that page seems obviously, totally fake to me is the absolutely janky \"photo\". Let's count the issues:1) obviously photoshopped -- a real octopus on a tree branch would look totally different, it would sag in some places, it would affect the pine bristles underneath, it wouldn't have a shadow that makes it look like it's hovering an inch above the branch, etc. Also, that octopus image looks totally out of proportion, but I can't pin down why -- I _think_ it's because the level of detail is higher than for the branches.2) It looks exactly like a regular octopus. Not only should an animal the size of a small bird have different proportions from a regular octopus (compare e.g. bats and fruit bats, or cats and tigers), but it should also look only distantly related to a regular octopus because it's adapted to a totally different biome.All that leads me to the following conclusion: Common sense, in the sense of broadly understanding how the world works, really is what prevents you from getting fooled, and the more things you understand, the less likely you are to get fooled. Also, the more information a hoax has, the more likely it is to get exposed, because just one sufficiently glaring inconsistency can sink it.replyhoosieree 16 hours ago | root | parent | prev | next [\u2013]Platypus seriously? If you're going to make up an animal, at least try to give it a realistic sounding name.replysaltcured 15 hours ago | root | parent | prev | next [\u2013]See, if they had said the tree octopus is found in some remote corner of Australia and has a pouch to raise its young, more of us would buy it...replyreplygirl 16 hours ago | root | parent | prev | next [\u2013]call me arrogant but i won't stoop to the level i have to be at to take your question seriously.do i think i'm as intelligent as anyone, or that everyone is as intelligent as me? of course not. but i do think your standard for gullibility is too high if you don't think believing the linked article satisfies it.replyBaseballPhysics 16 hours ago | root | parent | next [\u2013]Stoop? I challenge you with a perfectly valid example of an unlikely animal, and your response is to claim I'm somehow, what, failing to argue at your level?I suppose that's enough to make my point for me.replyreplygirl 16 hours ago | root | parent | next [\u2013]you asked me how i would ascertain that an animal documented to exist is more likely to be real than a hypothetical animal depicted with _a photoshop of a different animal climbing a tree_, as if there is no reasonable expectation of intelligence or intuition for an abled, functioning adultthe difference between people who initially believed this and those who didn't is gullibility, and this is a great example of gullibility because of how outlandish the claim is and appears to be. that's all i'm arguing. the counteraguments i see boil down to \"but if someone is gullible enough, they'll think it's actually not outlandish and accept it on face value\" which is not contrary to what i'm saying.if you were one of the gullible ones, sorry! sucks to be more deficient than others in some way, but we all have deficiencies.replyHelloMcFly 15 hours ago | root | parent | next [\u2013]I think the point is that it seems highly unimaginative (or perhaps just highly unempathetic, if there's a difference in this situation) to not see how a casual reader could just take it at face value and go on with their day. This seems especially plausible to me if I think of someone who knows little of the natural world beyond the odd thing they've come across on the internet, doubly so if not from America. At face value it seems as plausible as anything else, with just a bit of scrutiny it clearly doesn't hold up.But I suppose you have your deficiencies too, same as those who thought it to be real (however briefly).replyMattGaiser 16 hours ago | root | parent | prev | next [\u2013]Which of the following are real?- Tree lobster - Tree crab - Tree clam - Tree fishreplyreplygirl 16 hours ago | root | parent | next [\u2013]you're presenting an entirely different scenario from the OP. try again with photos, maps, propaganda posters, and a few thousand words on each, and replace your question with an assertion. in absence of that i do a quick search and find out three are real and one is not but may be a colloquial term referring to a sporadic phenomenonreplyScarblac 15 hours ago | root | parent | prev | next [\u2013]And the first time I read about those crabs, I checked Wikipedia to see if they were real too. Too many hoaxes on the Internet, but most of them are trivial to find out if they're real.replymeesles 16 hours ago | root | parent | prev | next [\u2013]> And I especially don't think it means anything about gullibility about information found onlineYou really think it means absolutely _nothing_ about this topic? It's literally an example of people believing what they read online! I think you're having an overly defensive reaction to probably falling for it.> It would be very hard to go through life questioning the veracity of every inconsequential bit of information that no one has an incentive to lie aboutThe issue is you may not understand or fathom the reasons someone may lie about something. Imagine the strange traditions that leaders have maintained throughout history to help control their subjects. To those subjects, I'm sure they weren't even imagining that these things they thought were spiritual were just fictions.As for my point - yes you should try go through life with a certain level of curiosity and apprehension when people tell you things. I feel like a lot of our societal issues are a result of things continuing for no good reason, just because we've done it in the past. It's become fairly easy to fact-check, and while not popular at parties, it's important if you're actually trying to learn and build an accurate mental model.If people were more comfortable questioning all aspects of our society (and if society was receptive to the criticism), I feel like we would be better off.replybantou_41 17 hours ago | parent | prev | next [\u2013]I think part of the purpose of sharing this website without saying anything about it might be to show that, in the age of the internet and AI, we don\u2019t really verify information before consuming it. It\u2019s not just children who are gullible. A lot of what we read on the internet is second hand information, facts with subjective interpretations, opinions, or straight up false information.replyHendrikto 14 hours ago | root | parent | next [\u2013]> in the age of the internet and AI, we don\u2019t really verify information before consuming itAs if this had ever been different. I would even argue that, because it is simply much easier to do, people are more incentivized to fact-check imformation, than 100 years ago.replyhn_throwaway_99 7 hours ago | root | parent | next [\u2013]I for one think it used to be very different.That is, there used to be some pretty universal, trusted sources of information. Encyclopedia Brittanica, for one simple example. And I'm not saying these sources never had errors or they didn't embed some of the societal biases in their reports, but they clearly had an institutional desire to report facts correctly, and pretty much nobody questioned that intent, regardless of political leanings.The ease with which anyone can publish anything on the Internet is a double-edged sword. It makes it more possible to challenge the status quo, but it also means that some crackpot can produce a slick video that, to many people, is just as valid as some well-researched documentary that at least attempts to be unbiased.replytejohnso 13 hours ago | parent | prev | next [\u2013]Well I for one appreciate it. I was drawn in after a couple of paragraphs, and then started to doubt and figured I'd check the comments for exactly this kind of thing before I run off and tell my child about an amazing animal I just heard about. Thank you.After reading about parasites that turn ants into zombies to do their bidding, I'm pretty much all out of \"that's just a nonsense story\" when it comes to nature's variety. I'll be skeptical, but I tend not to outright dismiss immediately.replyPeritract 18 hours ago | parent | prev | next [\u2013]> others may be as slow as me and save some time by reading this commentBut then they wouldn't learn anything about reading critically.replyAndrewKemendo 17 hours ago | parent | prev | next [\u2013]Had it not been for your comment it would\u2019ve definitely taken me longer to figure out, and I would\u2019ve most likely made a fool out of myself by telling people about it.I was extremely susceptible to this story, because I absolutely love octopuses, and everything related to them. However I\u2019m not an expert and it would not surprise me at all (given how surprising octopuses are generally) that there was a octopus group that could adapt to an extremely high humidity area, so it seems plausible!I like getting fooled like this occasionally cause it keeps you on your toes and shows you how vulnerable and easily fooled we all are.replyjmckib 14 hours ago | root | parent | next [\u2013]I immediately thought this looked too absurd to be real, but I wonder if my lack of octopus knowledge helped me out here. I know octopi are pretty smart, but I don\u2019t think of them as being too surprising in their capabilities.replyortusdux 15 hours ago | parent | prev | next [\u2013]To be fair, tree octopuses sound about as outlandish as land crabs, which I still have trouble believing are real.https://arthropoda.files.wordpress.com/2010/01/coconut-crab....replyhn_throwaway_99 7 hours ago | root | parent | next [\u2013]I think this is a great point. It's easy to come back with a \"hah, look how gullible you are\" when someone believes hoaxes like this, but that ignores the reality that \"truth is often stranger than fiction.\" I mean seriously, a coconut crab specifically evolved a special breathing apparatus to survive on land - why should that be any different from an octopus having \"special adaptations\" to keep it from getting desiccated when out of the water for extended periods?It's like when I used to read through Snopes feeds, and 9 times out of 10 I'd think \"wow, that's so dumb, how could anyone believe that\", and then the tenth time I'd think the same thing for a story that actually ended up being true.replyUncleSlacky 14 hours ago | root | parent | prev | next [\u2013]Not to mention the land shark: https://en.wikipedia.org/wiki/Land_Shark_(Saturday_Night_Liv...and the prairie squid: https://subgenius.fandom.com/wiki/Prairie_squidreplyMarkMarine 13 hours ago | root | parent | next [\u2013]And drop bearsreplypschastain 8 hours ago | parent | prev | next [\u2013]Reading the headline I thought it was going to be an article about the octopus tree: https://www.atlasobscura.com/places/octopus-tree-of-oregonreplylo_zamoyski 16 hours ago | parent | prev | next [\u2013]> has been used in multiple studies demonstrating children's gullibilityAnd not to make everything about this, but in light of this, interpret various currently fashionable and harmful pseudoscientific ideologies being peddled in schools and backed by the force of the regime.Children are very gullible. That's one major reason why they need parents, to protect them from predation and to guide them toward the minimum of adulthood. Worse still when parents themselves buy into these ideologies.replyRajT88 7 hours ago | parent | prev | next [\u2013]Another one like this, which you have to dive a bit deeper to find the give-aways:https://objectiveministries.org/(But once you've gone down the rabbit hole, there are some spectacular give-aways)replyandreskytt 3 hours ago | parent | prev | next [\u2013]Oh, but dear sir, you forgot about the AI!replytracerbulletx 17 hours ago | parent | prev | next [\u2013]The poster at the bottom kind of gives away the parody. Pretty fun though, I wish there was a tree octopus now.reply1024core 6 hours ago | parent | prev | next [\u2013]I saw the photos of snow and immediately realized it was fake.replygreggsy 13 hours ago | parent | prev | next [\u2013]The article lists as bald eagles and Sasquatch as natural predators\u2026replyfourthark 7 hours ago | root | parent | next [\u2013]That's when I finally caught on!replyparentheses 13 hours ago | parent | prev | next [\u2013]I scanned it and thought. HN post. Must be legit. Good reminder to RTFx.reply01100011 15 hours ago | parent | prev | next [\u2013]It was obvious when the page mentioned rainforests, which are on the western flank of the Olympics, but had a map showing only the eastern flank.replybeej71 17 hours ago | parent | prev | next [\u2013]It was good! I got to the end thinking, \"I don't know if I've been had or not.\"The WP article is a great read--recommend.replyretrocryptid 15 hours ago | parent | prev | next [\u2013]Meh. You have a parochial opinion of facts.replyonlyrealcuzzo 8 hours ago | parent | prev | next [\u2013]A little similar to Birds Aren't Real.replymorelisp 18 hours ago | parent | prev | next [\u2013]Unfortunately the campaign was unsuccessful and octopus paxarboli went extinct not long after the page first was published, before internet access was common and before smartphones could easily take pictures of it etc. Just because there's minimal evidence of something from before the internet, on the internet, doesn't make it a hoax.replydragonwriter 16 hours ago | root | parent | next [\u2013]> Unfortunately the campaign was unsuccessful and octopus paxarboli went extinct not long after the page first was published,Largely, the campaign failed because of the joint US/Canadian invasion of the Republic of Cascadia based on (ironically, false) claims of Weapons of Media Deception (WMD) being deployed with imminent plans for use against North American civilian targets.replycivilitty 18 hours ago | root | parent | prev | next [\u2013]Not to mention that 100% of all octopus fossils have been found on land.We have zero evidence of octopus fossils in the ocean.replypetre 15 hours ago | parent | prev | next [\u2013]I've always liked this one better:https://zapatopi.net/belgium/\u201cTourists, business travelers, and other visitors are allowed to \"come\" to the \"country\" in order to \"witness\" its \"existence.\" In reality, these people are waylaid at the common borders of Germany, France, the Netherlands, and Luxembourg and taken to NWO branch facilities where they have false memories of vast sprout fields and chocolate factory tours implanted.\u201dreplyfreitzkriesler2 17 hours ago | parent | prev | next [\u2013]It's the Washington Oregon version of the Dropbear.replystephenr 16 hours ago | root | parent | next [\u2013]Droptopus?replycratermoon 17 hours ago | parent | prev | next [\u2013]It's revealing that a substantial part of that wikipedia article is about Internet literacy studies.replyComputerGuru 18 hours ago | prev | next [\u2013]I randomly come across a link to this every ten years or so. It is put together splendidly well.I must admit however that I\u2019m a tad disappointed that the list of factors contributing to the critical endangerment of this wonderful specimen still has not been updated to include mention of the extinction of its once-primary source of nutrition, the harvest of the spaghetti tree [0].Perhaps in ten more years this oversight will have been corrected![0]: https://arstechnica.com/gaming/2020/04/that-time-the-bbc-foo...replyStratoscope 13 hours ago | prev | next [\u2013]People often ask why the Pacific Northwest Tree Octopus has such a successful ecological niche that alternates between the rainforest and under the water.The reason is that unlike humans and other land creatures, they are completely immune to the toxic effects of Dihydrogen Monoxide (DHMO). In fact, they require regular immersion in it.This also explains why the octopuses don't migrate farther south. When on the land, they still require ongoing contact with DHMO, which on the Olympic Peninsula is found in abundance in the very air!https://dhmo.org/replyqwertox 13 hours ago | prev | next [\u2013]This makes me sad. I once saw my nephew looking at a dino book and I joined him, and for some reason he ended up telling me that they exist in some part of the world. Stupid me laughed at him and told him that they no longer exist, and this has haunted me for years.I say this, because there was a photo of blue teddy-octopi's legs hanging from a tree on the site, and I started imagining a dad telling his kid how this is something real, that he/she should watch for them to see if he/she can spot them occasionally.Hurts my heart, but the site is nice, like a cherished thought which someone wanted to keep alive.replyPeritract 2 hours ago | parent | next [\u2013]If you haven't already read it, you might like Terry Pratchett's Hogfather [1].[1](https://www.goodreads.com/work/quotes/583655-hogfather)replykibibyte 6 hours ago | prev | next [\u2013]This was part of my childhood (almost 20 years ago!). Growing up, we had a lesson in either elementary or middle school in which we were all asked to read this website on the Pacific Northwest Tree Octopus and fill out a research assignment on it. At the end of it, the teacher asked us if we thought it was real and revealed that it wasn't, with the lesson that, yes, even though the internet is a valuable research tool, that we shouldn't believe everything we read.As a bonus, I think we were also asked to review some information on the aluminum foil hat. https://zapatopi.net/afdb/build.htmlreplybrendev 16 hours ago | prev | next [\u2013]I used to teach a computer science class to elementary-middle school kids.I always did a week on internet literacy, and would open the lesson with a worksheet that included this fella, along with a number of other fake animals, and some that look fake, but aren't.Each kid was supposed to come up with a summary of what the animal was, where they live, what they eat, etc.It was a lot of fun, but I've got to say... Parents: please take some time to teach your kids how to critically evaluate information that they read online.replyyissp 18 hours ago | prev | next [\u2013]This is great, reminds me of a classic from my childhood, the house hippo https://m.youtube.com/watch?v=TijcoS8qHIEreplyreilly3000 7 hours ago | prev | next [\u2013]I miss when Snopes was about this sort of thing. It still is, but you have to find it amongst a lot of noise.https://www.snopes.com/fact-check/tree-octopus/replykrupan 18 hours ago | prev | next [\u2013]Terry Pratchett added these wonderful animals to the world in which his book Nation takes place (one of his very best books, if you ask me). He undoubtedly was inspired by this websitereplycmehdy 18 hours ago | parent | next [\u2013]Sir Pterry was inspired by just about everything, which in itself is an inspiration to always digest what this world throws at us and turn it into all sorts of fantastic things.replywood_spirit 17 hours ago | prev | next [\u2013]The context of this showing up on HN made me kinda assumed it was a chatgpt generated thing.A quick google shows it seems to be a well known classic hoax from the late 90s.But there really are crabs and lobsters that live in trees and things, as do lots of type of mollusc (eg slugs and snails). So it isn\u2019t completely silly.So it\u2019s not like a tree octopus is any more ridiculous than the coconut crab?It seems there is no good way to know the truth anymore, as searching the internet might just find collaborating lies and conjecture\u2026replyCydeWeys 16 hours ago | parent | next [\u2013]> So it\u2019s not like a tree octopus is any more ridiculous than the coconut crab?It is a lot more ridiculous though because land crabs are a well known thing (e.g. hermit crabs) whereas land octopuses don't exist. Octopuses are very much a water-only type of organism.It just requires a little prior knowledge about the broad strokes of animalian orders.replyPepperdineG 8 hours ago | root | parent | next [\u2013]>Octopuses are very much a water-only type of organism.They're not though. Octopi generally don't like being out of water, but they're capable of traveling on land short distances and in fact the Abdopus Aculeatus octopus regularly goes on land by choice in order to hunt crabs in different tidepools. Sir David Attenborough discusses the octopus here, which this octopus was one of the animals featured in The Hunt documentary: https://www.youtube.com/watch?v=ebeNeQFUMa0replywood_spirit 15 hours ago | root | parent | prev | next [\u2013]Octopuses are molluscs, and there are lots of land living molluscs, right?replydvt 14 hours ago | root | parent | next [\u2013]To make things even more murky, some octopuses can actually breathe air out of water (which I knew prior to seeing the page), so I was actually semi-fooled by the article as well. An arboreal octopus is actually not that far-fetched.replyClamchop 10 hours ago | root | parent | prev | next [\u2013]People learn new things all the time, but an octopus that lives in trees would probably be pretty famous.replyfuryofantares 17 hours ago | parent | prev | next [\u2013]> The context of this showing up on HN made me kinda assumed it was a chatgpt generated thing.It's very likely OP discovered it through the link on this HN post that was at the top yesterday: https://news.ycombinator.com/item?id=36739920replyJayPalm 16 hours ago | root | parent | next [\u2013]Yeah, this occurred to me too. Guess we'll likely be inundated with 90's websites for a few days.replyfuryofantares 12 hours ago | root | parent | next [\u2013]I hope soreplyyosito 13 hours ago | parent | prev | next [\u2013]I asked midjourney for photos of the Pacific Northwest Tree Octopus and the results were impressive. Time to update the sightings page of the website.replyBMc2020 17 hours ago | prev | next [\u2013]Let's not forget the ice worms:Ice Worms and Their Habitats on North Cascade Glaciershttps://glaciers.nichols.edu/iceworm/and the Australian Drop Bearhttps://australian.museum/learn/animals/mammals/drop-bear/replyworik 14 hours ago | parent | next [\u2013]> and the Australian Drop BearUrban legend I was told (In Auckland - not Australia)In the war the US army moved vast reserves into North Australia for quite obvious reasons.Tanks on exercises in the Australian desert got very hot, so naturally kept their hatches open whenever they could.Massed tanks on manoeuvres in the desert will from time to time run into trees.Koala spend 90% of their time asleep in trees.Completing the picture a tank blunders into a tree and koala are dislodged and rain down.Through open tank hatches.The \"Great Australian Drop Bear\" is a recently woken angry Koala in fight mode in a crowded tank.....replycperciva 8 hours ago | root | parent | next [\u2013]See also kangaroos armed with stinger missiles: https://www.snopes.com/fact-check/shoot-me-kangaroo-down-spo...replycorndoge 17 hours ago | parent | prev | next [\u2013]Devilishhttps://en.wikipedia.org/wiki/Ice_wormreply6D794163636F756 16 hours ago | parent | prev | next [\u2013]Aren't iceworms real though?replycarabiner 16 hours ago | root | parent | next [\u2013]Ya if you spend time on Cascade glaciers you'll see them wiggling. Pretty common.replyDaunk 16 hours ago | prev | next [\u2013]I wasn't until I read that the sasquatch was its natural predator that I started to question things...replyzw123456 13 hours ago | prev | next [\u2013]Yeah, but How Fucking Cool would it be it if was a real thing.I think it is begging for B movie treatment... OK Down vote me as being Reddit-esque... But come on, it's Sunday afternoon, have a little fun...Tree Octopus's on a Plane.. Tree Octopus- nado Suction cups... We're gonna need a bigger backpack.Sorry, I just couldn't resist.I love this PNW Myth, deserves love right up there with Sasquatch and DB Cooper.replytivert 5 hours ago | prev | next [\u2013]Decades ago, there was a Discovery Channel speculative \"documentary\" about far future history that had tree octopuses. I wonder if they got the idea from this website and ran with it:https://en.wikipedia.org/wiki/The_Future_Is_Wild#Hothouse_Wo...https://youtu.be/gnasRyT52FU?t=1114replykfarr 3 hours ago | prev | next [\u2013]Reminds me of this classic https://web.archive.org/web/19961031232918/http://media.circ...replycalibas 18 hours ago | prev | next [\u2013]> Although the tree octopus is not officially listed on the Endangered Species List, we feel that it should be added since its numbers are at a critically low level for its breeding needs. The reasons for this dire situation include: decimation of habitat by logging and suburban encroachment; building of roads that cut off access to the water which it needs for spawning; predation by foreign species such as house cats; and booming populations of its natural predators, including the bald eagle and sasquatch.replyortusdux 14 hours ago | prev | next [\u2013]Crazy link timing! I just got my mug in the mail last week:https://postimg.cc/gallery/YY7f3x3replywlonkly 11 hours ago | prev | next [\u2013]Wow, that brings back memories. I had a link to this in my Usenet sig.. well, back in the era where one had a Usenet sig.replydenkmoon 9 hours ago | prev | next [\u2013]This may be an internet hoax, but always watch for drop bears when camping in the bush.replyLanternLight83 16 hours ago | prev | next [\u2013]Somewhat relatedly, there's the marshmello farming mockumentery: https://youtu.be/yflTu150QZwreplyrikroots 16 hours ago | parent | next [\u2013]But marsh mallow plants are real! I grew up with themhttps://en.wikipedia.org/wiki/Althaea_officinalisreplysparcpile 16 hours ago | prev | next [\u2013]There was a Discovery Channel special about future evolution that took this idea and ran with it. They had an idea of octopi being more land dwelling and becoming the dominant species.replytspike 17 hours ago | prev | next [\u2013]My uncles spent a summer working tours near Aspen in the 80s. They worked tirelessly to educate the tourist population about the dangers of the Rocky Mountain Alpine Shark.replyfultonb 17 hours ago | prev | next [\u2013]It's always crazy running in to one hiking up therereplythyrsus 13 hours ago | prev | next [\u2013]I was completely taken in until the octopus hat. There's no way 1920s fashionistas go from feathers to a pile of brown turds on their heads. The 2nd ddg hit was the Wikipedia article, the second word of which was \"fictitious\".replyEamonnMR 13 hours ago | prev | next [\u2013]Our librarian used this site in a class about media literacy, with the lesson being that you can't believe everything you read on the internet. I guess it was a good lesson because I still remember it.replychmod600 15 hours ago | prev | next [\u2013]I am not quite sure what tipped me off, but I suspected something was off in the first paragraph or two and went to Wikipedia.I think it just seemed out of place, like someone bringing up a topic in a forced way. Kind of \u201ctrying too hard\u201d.replybmmayer1 17 hours ago | prev | next [\u2013]Didn't know it was a hoax. This is the Wiki: https://en.wikipedia.org/wiki/Pacific_Northwest_tree_octopusreplynotorandit 16 hours ago | prev | next [\u2013]For a moment...https://en.m.wikipedia.org/wiki/Pacific_Northwest_tree_octop...replypvaldes 14 hours ago | prev | next [\u2013]Yep. Inoculating the idea that science is something not to be trusted is a lot of hard work. Very funny, ha ha...replyuser6723 16 hours ago | prev | next [\u2013]They're out of the water now? Once they learn how to use fire we are all doomed, we're DONE. Sell all your stocks but HODL your BTC.replyhinkley 16 hours ago | parent | next [\u2013]What if he\u2019s got a pointed stick?replyhackeraccount 16 hours ago | root | parent | next [\u2013]Or a board with a nail in it.replyModified3019 17 hours ago | prev | next [\u2013]http://www.lakemichiganwhales.com/replymiga 10 hours ago | prev | next [\u2013]There is enough spam here, please avoid posting this one.replybooleandilemma 13 hours ago | prev | next [\u2013]That photo was so ridiculous but I badly wanted to believe it was real!replyyalogin 16 hours ago | prev | next [\u2013]Without the reference to the Sasquatch I wouldn\u2019t have figured out this is made up. Well donereplyBorrible 17 hours ago | prev | next [\u2013]Early ancestors of the Squibbon.replywoahitsraj 18 hours ago | prev | next [\u2013]Classic! I remember convincing friends and family members that this was real when I was young. There was something incredibly fun and powerful being a child and able to fool adults who would believe anything they read on the internet. It's amazing how websites like this inoculated myself and many other young people from obvious misinformation on the internet in a fun and mostly harmless wayreplyCrzyLngPwd 14 hours ago | prev | next [\u2013]Fetch me a sky hook, I need to capture a tree octopus!replywzy 17 hours ago | prev | next [\u2013]Reminds me of the endangered \"Australian Drop bear\".replyeaseout 17 hours ago | prev | next [\u2013]https://www.snopes.com/fact-check/tree-octopus/replywaynecochran 12 hours ago | prev | next [\u2013]Blaming Sasquatch is hilarious!replymlongval 9 hours ago | prev | next [\u2013]Love it!replyaerodog 17 hours ago | prev | next [\u2013]I asked ChatGPT if octopuses exist in trees, and to my surprise, ChatGPT 'got it'replychowells 17 hours ago | parent | next [\u2013]Why is that a surprise? Every single text on the subject explains the joke eventually. It's the exact sort of high correlation GPT is good at finding.replySubiculumCode 9 hours ago | prev | next [\u2013]If I had encountered this link on social media I would have been much less likely to entertain the veracity of the claim. But coming from the front page of HN, and only lightly skimming for a couple of seconds, I started being fooled. Shows the power of reputation.reply99_00 12 hours ago | prev | next [\u2013]In the past, if you believed something just because it was on the internet you were seen as foolish.replyeinpoklum 12 hours ago | prev | next [\u2013]I was reminded of the initiative for Cascadian secession...https://en.wikipedia.org/wiki/Cascadia_movementwhich, when I first read about it, I questioned as a potential hoax. But - no, if you're not from the US, you should know that it's a very real thing, and apparently, a full third (!) of people 18-34 years old support it, according to relatively recent polling mentioned at the link.replyuoaei 13 hours ago | prev | next [\u2013]Critical thinking is hard. Stay vigilant.The photoshopped image of an octopus and a sasquatch hand was what first tipped me off. I wanted to believe this was a real animal, octopuses are magnificent creatures.replyvoz_ 13 hours ago | prev | next [\u2013]This kind of thing is malicious. It was maybe cute in the 90s/00s, but now? Too much fake news abound.replybrador 15 hours ago | prev | next [\u2013]It's fake. https://en.wikipedia.org/wiki/Pacific_Northwest_tree_octopusreplyrootsudo 17 hours ago | prev | next [\u2013]I didn't believe it and was widely thinking it is fake, and then I come to the comments and there we are.First the scientific name, obscura just sold it out as fake - but as someone who lived in the area - it would've been much more obvious and probably involved in tons of actual campaigns and protests.replydarkclouds 17 hours ago | prev | next [\u2013]Its a two hour drive from Microsoft headquarters, the perfect location to search for gullible Microsoft employees looking for this octopus, as they would become useful assets for the intelligence community. Think like a spook!replyOctokiddie 10 hours ago | prev [\u2013]> The reasons for this dire situation include: decimation of habitat by logging and suburban encroachment; building of roads that cut off access to the water which it needs for spawning; predation by foreign species such as house cats; and booming populations of its natural predators, including the bald eagle and *sasquatch*.I feel like I should have figured out this was a gag sooner...replyGuidelines | FAQ | Lists | API | Security | Legal | Apply to YC | ContactSearch:",
    "hn_summary": "- The Pacific Northwest tree octopus is an Internet hoax created in 1998 by a humor writer.\n- The website has been commonly referenced in Internet literacy classes and used in studies on children's gullibility.\n- This post is special because it highlights the importance of critically evaluating information found online."
  },
  {
    "id": 36746014,
    "timestamp": 1689508868,
    "title": "6 days to change 1 line of code (2015)",
    "url": "https://edw519.posthaven.com/it-takes-6-days-to-change-1-line-of-code",
    "hn_url": "http://news.ycombinator.com/item?id=36746014",
    "content": "It Takes 6 Days to Change 1 Line of Code(A true story.)Philip (President): Our factory is underutilized by 10%. Either we start building more of our backlog or we lay people off. I'd rather keep everyone busy, build inventory, and get ahead of the curve before the busy season. How can we do that?Lee (Operations Manager): Company policy restricts us from building more than 3 months of backlog. If you just change that to 4 months, we'll have plenty of work.Philip: Done. Now how do we implement that?Lee: I'm not really sure. I think we'd have to change a setting in the legacy software.David (IT Director): No problem. It's probably one line of code in our core routine. Fill out a ticket and submit it to IT Services.Judy (IT Admin): I'm assigning this request Ticket# 129281. But it still needs the section on Business Impact completed and Director approval.David: It's for Philip. It we don't do this right away, we'll have to have a layoff.Judy: OK, then I'll fill out that section myself and put this on the fast track.2 days later.David: What's the status of 129281?Judy: It's the first Enhancement in the Developer Queue, after 14 Bug Reports.David: Forget the queue. Mark it urgent and send it to Ed immediately.1 hour later.Ed (programmer): On line 1252 of Module ORP572, I changed the hard-coded variable MonthsOfBacklog from \"3\" to \"4\". I unit tested this successfully and ran 2 batch test runs. The Operations work queue increased 10% as expected. This is good to go. I just submitted it to Code Review and moved in to Homer for User Acceptance Testing.Shirley (Code Review): It is now against company policy to have any hard-coded variables. You will have to make this a record in the Parameters file. Also, there are 2 old Debug commands, an unassigned variable warning message, and a hard-coded Employee ID that will all have to be fixed before this module can be moved to production.Ed: Fuck that shit.Shirley: That may very well be true. But since you were assigned ORP572, you are responsible for fixing preexisting errors that violate new company policy. I cannot promote this as it is.2 hours later.Ed: OK, done. I just resubmitted it to Code Review.Julie (IT Testing): Homer is not available for User Acceptance Testing because Fred is running a controlled test for month-end accounting close. Use Marge instead.Ed: I don't have access to Marge.Julie: Then contact Joe in IT Security. He'll get you permissions.2 hours later.Joe (IT Security): I cannot grant you access to Marge without David's signature. He's out of town. Can this wait until Monday?Ed: I don't think so. Philip wants this right away. Get him to grant access.Shirley: Your new Parameters record \"MonthsOfDemand\" needs a better name. The offshore programmers won't understand what this means. Also, it should have an audit trail of changes.Ed: What policy is that?Shirley: It's not exactly written down anywhere. The offshore team is 3 months late updating the wiki, but I assure you, all new Parameter records must satisfy new naming requirements and keep audit trails.1 day later:Ed: I renamed the Parameters record \"MonthsOfDemand\" to \"SelectedMonthsOfBacklogDemand\" and added Module PAR634 to maintain that record and its audit trail. I have submitted it to Code Review.Tony (IT Testing): I see 129281 on Marge, but I have no Test Plan.Ed: Just run it the old way and the new way and note the increase in the total on the WorkOrdersHours report.Tony: That's your test plan? No. This affects everything in the factory. I have to have user selected Test Cases, Expected Results, documented Test Runs, and user sign-off.2 days later:Philip: David, tell Tony to move Ed's program to production immediately.David: Yes sir.Total elapsed time: 6 days.Lines of mission critical code changed: 1.Bytes of mission critical code changed: 1.Excedrin eaten: 24Pissed off hours spent on Hacker News: 14.",
    "summary": "- A company needs to change a setting in their software to increase their backlog limit from 3 months to 4 months in order to keep everyone busy and avoid layoffs.\n- It takes 6 days for a programmer to change just one line of code to implement this setting change.\n- The programmer faces challenges and setbacks, including having to fix preexisting errors, gaining access to necessary systems, and addressing naming and documentation requirements.",
    "hn_title": "6 days to change 1 line of code (2015)",
    "original_title": "6 days to change 1 line of code (2015)",
    "score": 337,
    "hn_content": "- The core issue highlighted in the post is the pushback from reviewers when making changes to code, which can lead to delays and scope creep.\n- The importance of making focused pull requests (PRs) and pushing back against reviewer demands for scope creep is emphasized.\n- The post highlights the importance of good management in identifying key stakeholders and effectively communicating urgency and importance.\n- The discussion touches on the trade-off between resolving tech debt and completing tasks, with differing opinions on whether resolving tech debt should be a requirement for completing a task or should be planned separately.\n- The use of automated tools, such as static analysis, is mentioned as a potential solution to remove trivial comments and make feedback faster, but opinions on their effectiveness vary.\n- The impact of code quality on architectural issues and the need for code to be maintainable and readable is emphasized.\n- The post discusses the value of code reviews in catching bugs and promoting shared knowledge of the codebase.\n- The challenges of code reviews and potential issues with comment overload are addressed.\n- The role of static analysis tools in catching bugs and enforcing code style rules is mentioned, but their limitations are also acknowledged.\n- The need for communication and collaboration in code reviews, as well as the value of feedback from more experienced reviewers, is highlighted.\n- The negative aspects of bureaucratic processes and the potential delays they can introduce are acknowledged.- This post highlights the challenges and frustrations that can arise when implementing changes in a large organization.\n- The story revolves around a critical one-line code change that needed to be made urgently to prevent layoffs.\n- The bureaucratic processes and requirements for code review, testing, and documentation caused delays and frustration for the programmers involved.\n- The importance of clear communication, prioritization, and efficient decision-making in order to implement changes quickly and effectively is highlighted.\n- The post highlights the need for a balance between implementing necessary changes and adhering to important policies and procedures.\n- The urgency and impact of the code change make it unique and interesting for readers, as it demonstrates the real-world challenges faced by software engineers in large organizations.",
    "hn_summary": "- The core issue highlighted in the post is the pushback from reviewers when making changes to code, which can lead to delays and scope creep. The importance of making focused pull requests (PRs) and pushing back against reviewer demands for scope creep is emphasized.\n- The post discusses the value of code reviews in catching bugs and promoting shared knowledge of the codebase. The challenges of code reviews and potential issues with comment overload are addressed.\n- The story revolves around a critical one-line code change that needed to be made urgently to prevent layoffs. The bureaucratic processes and requirements for code review, testing, and documentation caused delays and frustration for the programmers involved. The urgency and impact of the code change make it unique and interesting for readers, as it demonstrates the real-world challenges faced by software engineers in large organizations."
  },
  {
    "id": 36750716,
    "timestamp": 1689536659,
    "title": "Underwater ears everywhere",
    "url": "https://computer.rip/2023-07-15-underwater-ears-everywhere.html",
    "hn_url": "http://news.ycombinator.com/item?id=36750716",
    "content": ">>> 2023-07-15 underwater ears everywhereProgramming note: the subscribe link was broken for a while because I am bad at computers (yet another case of \"forgot to enable the systemd unit\"). It's fixed now. The unsubscribe link was also broken and is now fixed but, you know, maybe that was a feature. Did wonders for reader retention.You may have seen some recent press coverage about events surrounding the Titanic and another notable loss at sea. I'm not going to rehash much of anything around the Titan because it's sort of an exhaustively covered topic in the mainstream press... although I will defend the Logitech controller by noting that Playstation-style controllers are extremely popular interfaces in robotics and 3D navigation (two symmetric analog sticks, unlike other major game controllers), and considering the genuine PS4 controller's terrible Bluetooth pairing UX with non-Playstation devices, the Logitech is probably a more reliable choice. And they did have spares on board!I actually want to talk a bit about remote sensing, but of a rather different kind than I usually mention: hydrophones and wide-area sonar. This little-discussed military surveillance technology played a major role in the saga of the Titan, and it's one that seems poorly understood by both journalists and internet randos. I've seen a lot of Bad Takes about the Navy's involvement in Titan and I want to suggest a few things that might cause you to interpret the situation differently.Submarines are very difficult to detect. This is a bad property for tourist ventures to the deep sea, but a very useful property to the military. Further, radio communications underwater are extremely difficult. Salt water attenuates radio signals very quickly, and while the effect decreases as you go to lower frequencies, it never goes away. Even the US Navy's sophisticated VLF systems require submarines to be relatively close to the surface (or rather use a wire antenna relatively close to the surface) for reception---VLF signals only penetrate seawater by up to about 40 meters. ELF offers better penetration into hundreds of meters, but ELF facilities are extremely expensive to build and operate and the receive antennas are formidably large, so the US Navy retired its ELF infrastructure in 2004.For this reason, submersibles like Titan communicate with their surface support vessels via acoustic modems. This method is surprisingly reliable but produces a very low bitrate, thus the limitation of text messaging. Similar technology is used in deep-sea oil exploration, Titan likely used a commercial product for the data link.The thing that propagates best underwater, in fact far better than above water and even better as you get deeper, is sound. The potential of sound for detecting and locating submarines is well-known. The first prominent use of this approach, widely called sonar, came about during the First World War when an anti-submarine surface ship successfully detected a submarine directly below it via reflected sound. This type of sonar works well for locating nearby submarines, but it is an active technique. That is, an active sonar must emit a sound in order to receive the reflection. This is actually quite undesirable for many military applications, because emitting a sound reveals the presence (and with sufficient receiving equipment, location) of the sonar device. Anti-submarine ships stopped using active sonar on a regular basis fairly quickly, since it prominently advertised their presence to all of the submarines in the area.Much more appealing is passive sonar, which works by listening for the sounds naturally created by underwater vehicles. With a sensitive directional hydrophone (an underwater microphone), you can hear the noise created by the screws of a submarine. By rotating the directional hydrophone, you can find the point of peak amplitude and thus the bearing to the submarine. This basic submarine hunting technique remains the state of the art today, but the receiving equipment has become far more capable and automated.There is an arms race here, an arms race of quietness. I am resisting here the urge to quote the entire monologue from the beginning of The Hunt for Red October, but rest assured that [the Americans] will tremble again, at the sound of [the Soviet's] silence. In practice the magnetohydrodynamic propulsion technology depicted on the Red October has never proven very practical for submarines, although it was demonstrated in one very futuristic surface vessel built by Mitsubishi and called Yamato 1 (fortunately it fared better than the battleship by that name). Instead, the battle of submarine silence has mostly revolved around obscure technical problems of fluid dynamics, since one of the loudest noises made by submarines is the cavitation around the screw. I don't know if this is true today, but at least years ago the low-noise design of the screw on modern US submarines was classified, and so the screw was covered by a sheath whenever a submarine was out of the water.Passive sonar can be performed from ships and even aircraft-deployed buoys, but for the purpose of long-term maritime sovereignty it makes sense to install permanent hydrophones that function as a defensive perimeter. Just such a system was designed in the 1950s by (who else?) AT&T. AT&T had the expertise not only in acoustic electronics, but also undersea cable laying, a key component of any practical underwater surveillance system. Large arrays of hydrophones, spaced along cables, were laid on the ocean floor. The sounds detected by these hydrophones were printed on waterfall diagrams and inspected by intelligence analysts, who relied on experience and no small amount of educated guessing to recognize different types of marine life, geological phenomena, and vessels at sea.This system, called SOSUS for Sound Surveillance System, remained secret until 1991. The secrecy of SOSUS is no great surprise, as it was one of the most important military intelligence systems of the Cold War. It presented a problem as well, though, as few in the Navy were aware of the details of the system and ship crews sometimes felt the abbreviated, zero-detail intelligence messages from SOSUS to be confusing and unreliable. They were being told of likely submarine detections, but knowing nothing about the system they had come from, they didn't know whether or not to take them seriously.By the 1960s, SOSUS consisted of hundreds of individual hydrophones installed in long, cable-tethered arrays. Cables connected the hydrophone arrays to highly secured terminal facilities on the coast, which the Navy explained with a rather uninspiring cover story about undefined survey work. Over the following decades, computers were applied to the task, automatically detecting and classifying acoustic signatures. This early automation work inspired significant research and development on signal processing and pattern matching in both the military and Bell Laboratories, creating early precedents for the modern field of machine learning. Additionally, computer and telecommunications advancements allowed for remote control of the arrays, significantly reducing the staff required for the program and leading to the eventual closure of many of the terminal naval facilities.In 1984, SOSUS was renamed to IUSS, the Integrated Underwater Surveillance System. This new name reflected not only the increasing automation, but also the inclusion of several surface vessels in the system. These vessels, initially the USNS Stalwart and USNS Worthy, functioned as mobile IUSS arrays and could be moved around to either expand coverage or provide more accurate locating of a suspected target.The existence of IUSS was finally declassified in 1991, although it was well known before that point due to several prominent press mentions. Since the declassification of IUSS it has enjoyed a dual-use role with the scientific research community, and IUSS is one of the primary sources of hydrophone data for marine biology. Today, IUSS automatically detects and classifies both submarines and whales.The potential of passive sonar systems to detect submarine accidents is well-known. The 1968 loss of Soviet submarine K-129 was detected by SOSUS, and the location estimate produced by SOSUS facilitated the recovery of K-129 by the Hughes Glomar Explorer, one of the most fascinating naval intelligence operations of American history. 1968 was a bad year for submarines with four lost with all hands, and SOSUS data was used to locate at two of them (Soviet K-129 and US Scorpion. French Minerve and Israeli Dakar would not be found for decades).This all brings us to the modern era. Titan was lost on, presumably, the 18th of June. It was not located on the sea floor until the 22nd, four days later. Press reporting after the discovery included a Navy statement that IUSS had detected and located the implosion.This has lead to a somewhat common internet hot take: that the Navy had definitive information on the fate of Titan and, for some reason, suppressed it for four days. I believe this to be an unwarranted accusation, and the timing of the location of the wreck and the statement on IUSS are readily explainable.First, we must consider the nature of remote sensing. Remote sensing systems, whether space-based or deep underwater, produce a large volume of data. The primary source of actionable information in modern real-time remote sensing are computer systems that use machine learning and other classification methods to recognize important events. These computer systems must be trained on those events, using either naturally or artificially created samples, in order to correctly classify them. A major concern in naval intelligence is the collection of up-to-date acoustic signatures for contemporary vessels so that IUSS can correctly identify them.A secondary method is retrospective analysis, in which human intelligence analysts review historic data to look for events that were not classified by automation when they occurred. Retrospective analysis, particularly with new signature information, can often yield additional detections. Consider the case I have previously discussed of the Chinese spy balloons: once signature information (almost certainly RF emissions) were collected, retrospective analysis yielded several earlier incidents that were not detected at the time due to the lack of signatures.Like the RF spectrum, the ocean contains a lot of noises. They come from wildlife, from geological processes, and from commercial shipping, all besides naval operations. The Navy does not rigorously investigate every sound underwater, it can't possibly do so.When the Navy became aware of the missing Titan, analysts almost certainly began a retrospective analysis of IUSS data for anything that could indicate its fate. They apparently detected loud noises and were able to locate the source as near the Titanic wreckage, probably fairly quickly after the Titan was first reported missing.Here is the first challenge, though: the Titan was a new submersible of novel (if not necessarily well thought out) construction. The Navy has some familiarity with the acoustic signatures of imploding military submarines based on incidentally lost submarines and, in at least one case, the intentional torpedoing of a submarine to record the resulting acoustics (the Sterlet). This data is used to produce a signature against which new signals can be compared. Because of the significant differences in size and construction between Titan and military submarines, the Navy likely had very low confidence that known acoustic signatures of catastrophic losses were applicable. The total number of submarines to have ever imploded underwater is quite small, and none were of similar size and construction to Titan. The point is that while intelligence analysts likely suspected they had evidence of implosion, they probably had low confidence in that conclusion.It is unwise, in the course of a search and rescue operation, to report that you think the vessel was irrecoverably lost. Doing so can compromise search operations by creating political pressure to end them, while making the situation of families and friends worse. It is customary to be very cautious with the release of inconclusive information in events like this. The problems are exemplified by the Coast Guard's announcement that another passive sonar system had detected possible banging sounds, which motivated a lot of reporting making wild conclusions based on acoustic signatures that were likely unrelated.The more damning accusation, though, is this: did the Navy withhold information on the detection from searchers out of concern for secrecy? Setting aside that this makes little sense considering that SOSUS and its capabilities have been widely known to the public for decades, and the search site was well within historically published coverage estimates for SOSUS, this accusation doesn't align with the timeline of the search.The first search vessel capable of deep undersea exploration, the ROV Pelagic Odysseus 6k, arrived on the scene on the morning of the 22nd. Just five hours later, Odysseus had located the wreckage. Considering that the descent to depth alone would have taken Odysseus over an hour, the wreckage was located extremely quickly in the challenging undersea environment. One reason is obvious: the wreckage of Titan was close to the Titanic, although the Titanic debris field is large and searching it all would have taken hours. The second reason became known shortly after: when Odysseus began its search, they had almost certainly already been tipped off by the Navy as to the location of the possible implosion.The Navy did not withhold information on the detection for four days out of some concern for secrecy. Instead, the information was not known to the public for four days because that was when the search team was first able to actually investigate the Navy's possible detection.Indeed, the idea that the Navy suppressed the information seems to come only from the rumor mill and internet repetition of half-read headlines. The original press coverage of the IUSS detection, from the WSJ, states that the Navy reported the finding to the Navy commander on-scene at the search effort immediately. It does include the amusing sentence that \"the Navy asked that the specific system used not be named, citing national security concerns.\" This might seem like a huge cover up to those unfamiliar with intelligence programs, but it's perfectly in line with both normal military concerns around classified systems (which are often known by multiple names which must be kept compartmentalized for unclassified contracting) and the specific history of IUSS, which during its period of secrecy had problems with being accidentally named in unclassified reports multiple times.IUSS is now a smaller system than it once was, although with improving technology its coverage has probably expanded rather than contracted. It still serves as a principal method of detecting submarines near the US, an important concern since submarines are one of the main delivery mechanisms for nuclear weapons. IUSS is just one of several semi-secret underwater sensing systems used by the Navy.A not totally related system that will nonetheless be of interest to many of my readers (who I suspect to be somewhat concentrated in the San Francisco Bay Area) is the San Francisco Magnetic Silencing Range. A small building in the parking lot of Marina Green, complete with a goofy little control tower from the era of manned operation, is the above-water extent of this system that uses underwater magnetometers to measure the magnetic field of Navy vessels passing through the Golden Gate. Since underwater mines are often triggered by magnetometers, the Navy ensures that the magnetization of vessel hulls does not exceed a certain limit. If it does, the vessel can be degaussed at one of several specially-equipped Navy berths---inspiration for at least one episode of The Next Generation. Similar arrays exist at several major US ports.The building itself is long-disused, and the array is now fully remote controlled. When I lived in San Francisco it was abandoned, but I see that it has apparently been restored to function as the harbormaster's office. I appreciate the historic preservation effort but something is lost with the removal of the Navy's sun-faded signage.",
    "summary": "- Hydrophones and wide-area sonar are important military surveillance technologies that are used to detect and locate submarines underwater.\n- Submarines are difficult to detect and communicate with underwater due to the attenuation of radio signals by salt water, leading to the use of acoustic modems for communication.\n- The US Navy's Sound Surveillance System (SOSUS), now known as the Integrated Underwater Surveillance System (IUSS), is a secret underwater surveillance system that uses hydrophone arrays to detect and classify submarines. IUSS has also found dual-use in marine biology research.",
    "hn_title": "Underwater ears everywhere",
    "original_title": "Underwater ears everywhere",
    "score": 305,
    "hn_content": "Hacker News new | past | comments | ask | show | jobs | submit loginUnderwater ears everywhere (computer.rip)305 points by lonk11 14 hours ago | hide | past | favorite | 97 commentssupernova87a 10 hours ago | next [\u2013]An almost mandatory entertaining article, whenever topics about cables, ocean floor, submarines come up:https://www.wired.com/1996/12/ffglass/\"Mother Earth, Mother Board\" (stories about laying undersea cable and the history of wiring the Earth up\"(or unpaywalled: https://archive.is/ICkHe)replyabsoflutely 6 hours ago | parent | next [\u2013]Sadly the unpaywalled version is also paywalledreplysupernova87a 6 hours ago | root | parent | next [\u2013]Oh, sorry about that. If you roll back a couple versions it's here:https://archive.is/19MsireplyDavy_Crockett 6 hours ago | root | parent | prev | next [\u2013]https://github.com/iamadamdev/bypass-paywalls-chromereplydundarious 8 hours ago | prev | next [\u2013]Related but off topic (so I could understand being flagged, etc.), but in all likelihood, these capabilities could say a lot about what happened surrounding the Nord Stream pipeline explosions. I think it's a reasonable assumption that the US has these detectors beyond the borders of the US -- I've seen others claim as much: https://www.thenation.com/article/world/nord-stream-pipeline...reply01100011 7 hours ago | parent | next [\u2013]That area of the ocean is probably one of the most heavily surveilled areas in the world. Intelligence agencies absolutely know the ships involved.I still maintain it could have been anyone with about $300k. Work class ROVs capable of planting the explosives at that depth are commonplace in underwater construction and maintenance.replyFirmwareBurner 3 hours ago | root | parent | next [\u2013]300k ROVs still need a mother ship and pretty sure navies and intelligence agencies know which ships go where and when.reply01100011 1 hour ago | root | parent | next [\u2013]That's what I'm saying. That's the point of the first paragraph.replya_bonobo 2 hours ago | prev | next [\u2013]There's an interesting link between K-129 and the current 'boom' around deep sea mining: https://en.wikipedia.org/wiki/Project_AzorianThe cover-story to build the Glomar Explorer to recover K-129 was that Howard Hughes thought that it was economically feasible to mine manganese nodules from the deep sea. A lot of engineering research started that year (1974) that now, 2023, bears fruit in several large companies trying to mine the ocean floor with approvals to start probably happening this year: https://www.nature.com/articles/d41586-023-02290-5Without the cover-story and Howard Hughes I wonder how many researchers would have ever looked at deep sea mining.replydoubledad222 12 hours ago | prev | next [\u2013]> this writing is so clear and good > Today, IUSS automatically detects and classifies both submarines and wales.Do the British know ?replyjcrawfordor 11 hours ago | parent | next [\u2013]I am proud to say I noticed that one about two minutes before I saw your comment. It's not that I never copy edit, I just usually don't do it until two days later.replystuff800 8 hours ago | prev | next [\u2013]> Instead, the battle of submarine silence has mostly revolved around obscure technical problems of fluid dynamics, since one of the loudest noises made by submarines is the cavitation around the screw.Cavitation is loud, but usually only happens if they're running full out. What they're really listening for now are reactor plant noises.> I don't know if this is true today, but at least years ago the low-noise design of the screw on modern US submarines was classified, and so the screw was covered by a sheath whenever a submarine was out of the water.Many US fast attack (Virginia, Seawolf) and the upcoming Columbia SSBN use some sort of external pump jet. I'm not sure if they cover those up out of water like they did with more 'traditional' screws.replynickelpro 5 hours ago | parent | next [\u2013]Huh, I wouldn't classify any of those propulsion trains as pump-jets (and I never heard them called that aboard said vessels ;-P), but wikipedia seems to agree with you.They're ducted propulsors, a direct evolution of the classic submarine prop that integrates a pressure-increasing shroud and stator vane assembly. A \"pump jet\" classically involves some sort of centrifugal pump element or at least a vectoring mechanism.You typically wouldn't call a ducted fan (ex, on the X-22 [1]) a jet, but I guess in the water we do.[1]: https://en.wikipedia.org/wiki/Bell_X-22replywkat4242 21 minutes ago | root | parent | next [\u2013]Wow that is one cool aircraft. Never heard of it.replynamibj 4 hours ago | root | parent | prev | next [\u2013]I counter (ultra) high bypass turbofan.replyDoxin 3 hours ago | parent | prev | next [\u2013]> What they're really listening for now are reactor plant noises.Which is why old timey diesel electric submarines still sometimes have the edge over modern subs. No plant noises at all if they are running silent.This leads to some hilarity in joint naval exercises every now and then. e.g. when HNLMS Walrus managed to \"sink\" among others the USS Theodore Roosevelt before getting away, to great consternation of the Americans.replydefrost 3 hours ago | root | parent | next [\u2013]C'mon though, which US joint exercise partner hasn't 'sunk' a USS craft at one time or another yet?Not to mention the actual real sinkings that are a standard feature of pretty much every RIMPAC nav-mil-cosplay LARP event:* https://gcaptain.com/australian-sub-sinks-us-navy-ship-pract...* https://www.businessinsider.com/us-australia-japan-practice-...* https://news.usni.org/2020/08/31/video-rimpac-2020-exercise-...The thing about ships from the Netherlands though, they pretty much sink themselves locally:https://en.wikipedia.org/wiki/Shipwrecks_of_Western_Australi...replywossab 2 hours ago | root | parent | next [\u2013]It wasn't just a sunk craft. They sunk a carrier. That's painful. Your wikipedia entry is kind of weird, since it's about Australia and there are no Dutch ships in the list for the last century or so.replydefrost 2 hours ago | root | parent | next [\u2013]Australia has 'sunk' USS carriers in war games also - there are entire books written about how carriers are hard to defend in modern warfare - they're painful to lose but (shhh, don't tell anyone) relativey easy targets in all manner of ways.The wikipedia entry is about 1400+ ships that were mostly Dutch - from the days of the Dutch East Indies and Spice trades.It's of interest as that coast was one of the main drivers to develop \"GPS 0.1\" aka clocks capable of reliable determination of Longitude and one of the (relative to monetary value at the time) largest technology prizes offered.They stopped stacking up on the West Australian coast once accurate navigation became commonplace but for a while there .. yep, Dutch ships sank themselves.replymcpackieh 6 hours ago | parent | prev | next [\u2013]They do seem to cover the intake and output: https://www.thedrive.com/content/2020/01/werw.jpg?quality=85replyKennyBlanken 6 hours ago | parent | prev | next [\u2013]> . What they're really listening for now are reactor plant noises.Yep; a fanatical obsession with reducing plant noise is why US subs were so quiet compared to everyone else. The author knows fuck-all about what he's talking about going on about cavitation.It's also why diesel hybrid subs from Sweden are nearly undetectable. There's virtually no plant noise - probably just a coolant pump or two - while running on battery. They are sometimes 'hired' by other navies for exercises because they're so incredibly quiet.He's spouting pure bullshit about the Navy retroactively going back over their 'tapes'. He first explains that for decades the Navy has run computerized classification systems, but then we're supposed to believe that a highly sensitive listening array did not detect the extremely energetic implosion that would sound like nothing else?Cameron said that buddies in the navy told him very quickly that they'd heard the implosion, but they were confirming what he already knew when he heard that telemetry was lost at the same time as comms; telemetry came from a completely separate external pressure vessel. It going silent means it was destroyed, and the only way that could have happened was the sub imploding.The bit about it being unrecognizable as an implosion because of its unique construction is complete supposition.This is what happens when you have an article about submarines written by a guy who checks is a github engineer who likes 80's and 90's phone technology.replytommiegannert 2 hours ago | prev | next [\u2013]Reminded me of this story: https://en.wikipedia.org/wiki/Toshiba%E2%80%93Kongsberg_scan...Toshiba wasn't allowed to export a 9-axis (C)NC-machine to the Soviet union, because it could (and would) be used to create ultra-silent submarine props, in the 80s.Asianometry video about it: https://www.youtube.com/watch?v=uaRyqAVIkwIreplysamwillis 12 hours ago | prev | next [\u2013]On this:> Instead, the battle of submarine silence has mostly revolved around obscure technical problems of fluid dynamics, since one of the loudest noises made by submarines is the cavitation around the screw. I don't know if this is true today, but at least years ago the low-noise design of the screw on modern US submarines was classified, and so the screw was covered by a sheath whenever a submarine was out of the water.I wander if they are Toroidal or \"tipless\" propellers? They create less turbulence and cavitation.https://en.m.wikipedia.org/wiki/Toroidal_propellerPrevious posts on HN:> Toroidal propellers turn your drones and boats into noiseless machineshttps://news.ycombinator.com/item?id=34571282> Sharrow MX-1: Tipless propellerhttps://news.ycombinator.com/item?id=33949895replyjacquesm 10 hours ago | parent | next [\u2013]https://www.thingiverse.com/thing:5867831replyalexvoda 52 minutes ago | prev | next [\u2013]I wonder if an active sonar array would be desirable. It would of course be easy to locate the beacons but they would probably be relatively cheap. Also, that much sonar noise would probably be bad for marine life. Would it give us capabilities we currently do not have?replyTepix 36 minutes ago | parent | next [\u2013]It's not just the location of the active beacon that you're giving away. It also tells the enemy in which regions of the world's oceans you are listening.replymanzanarama 13 hours ago | prev | next [\u2013]This writing is so clear and good. I can't tell you how many NYT articles I read where the paragraphs feel out of order, chopped up and there is no consistent flow. This reads very enjoyably.replySkyMarshal 12 hours ago | parent | next [\u2013]That kind of modern journalism is absurd. Originally the rule in journalism was, the first paragraph must contain who, when, what, where, then subsequent paragraphs fill in the details in either chronological or logical order.Now the first paragraph must contain an emotional human-interest style \u201chook\u201d to rope in the reader, then bury the lede in some random spot in the remainder of the text, in an attempt to keep the reader searching for it, like a slot machine.As soon as I realize that\u2019s how something is written, I take that as signal it lacks the quality to stand alone and I discard it and move on.replychongli 12 hours ago | root | parent | next [\u2013]Yeah. I can usually tell within the first couple of words if the article is worth reading or not. Anything that seems to start with a complete non-sequitur or some variant of \u201conce upon a time\u201d is an immediate back-button bounce for me!replysimplicio 1 hour ago | root | parent | next [\u2013]How can you start with a non-sequitur?replyquickthrower2 49 minutes ago | root | parent | next [\u2013]Non-sequitur to the headline?replydylan604 10 hours ago | root | parent | prev | next [\u2013]> Now the first paragraph must contain an emotional human-interest style \u201chook\u201d to rope in the readerSo news sites have become a recipe site? Except, you\u2019ve limited to a single paragraph vs 7/8 of the pagereplySkyMarshal 9 hours ago | root | parent | next [\u2013]It's more that they're using Skinner Box variable rate reinforcement bs to rope readers in and keep them reading, which explains why the text feels so randomized and out-of-any-logical-order.https://www.nirandfar.com/want-to-hook-your-users-drive-them...replykhy 7 hours ago | root | parent | prev | next [\u2013]\"John Smith is buttering his toast with a spoon, much to the bemusement of our waitress Jane at the All Day Diner on the outskirts of Duluth Minnesota...\"replyhammock 7 hours ago | root | parent | prev | next [\u2013]NPR features are the same now, only on the radioreplyhengheng 11 hours ago | root | parent | prev | next [\u2013]Condensing inflated long-form articles back to their useful size would be a worthwhile AI application, just like searchable podcast transcriptions.replyp1mrx 10 hours ago | root | parent | next [\u2013]https://www.boringreport.org/app does that, at least until the IP lawyers figure out what to do with it.replyProAm 9 hours ago | root | parent | prev | next [\u2013]How many news or journalism sites are you currently subscribed to?replySkyMarshal 8 hours ago | root | parent | next [\u2013]None, why? Are paywalled articles written in the traditional way since they already have a revenue source and don\u2019t need to addict people?replyProAm 7 hours ago | root | parent | next [\u2013]So you dont pay for any of it and then complain this is what they have to do to get views and clicks. Chicken meet egg, egg meet chicken, pot meet kettle.replySkyMarshal 6 hours ago | root | parent | next [\u2013]This whole thread we\u2019re in was started by someone observing how well-written and clear the original article is, so I don\u2019t think the only way to get clicks is to write in the way I\u2019m complaining about.replythe-printer 12 hours ago | parent | prev | next [\u2013]The fact that he publishes informative pieces at such a steady rate is remarkable as well. And the fact that he resisted to use the phrase \"deep dive\" in this particular one is indicative of a high level of discipline with his prose.replymicromacrofoot 12 hours ago | parent | prev | next [\u2013]writers rarely have complete control over what editors do to their pieces before the nyt publishes them, and in this case there are no middlemen muddling things upreplymaxbond 12 hours ago | prev | next [\u2013]Somewhat tangentially, I've been wondering why the Soviets weren't able to locate K-129. From what I've read, they searched in a location hundreds of miles away from where SOSUS detected an implosion - why didn't the Soviets pick it up? Surely they had a hydrophone array?replyjcrawfordor 11 hours ago | parent | next [\u2013]Well, one answer is that US hydrophone technology was probably superior at the time - but that's not necessarily a well-established fact, mostly an assumption. Still, it would stand to reason. SOSUS benefited greatly from cutting-edge research into acoustics that Bell Labs had been performing for other reasons, the Soviet Union probably didn't have the hydrophone technology or the undersea cable technology it relied on.There's a more interesting answer if you want one, although this is decidedly a conspiracy theory with, I would say, \"medium\" credibility within the realm of conspiracy theories. Some believe that both K-129 and Scorpion were sunk by enemy action, K-129 having been sunk by an accidental collision with the Swordfish and Scorpion having then been torpedoed in retaliation. The story goes that the admiralty of both countries, agreeing this situation could rapidly escalate into an undesirable war, agreed to suppress information on the cause of both incidents. The Soviet search for K-129 and American search for Scorpion could both have been cover operations.Yeah, it doesn't make total sense, and the evidence supporting this theory is a combination of circumstantial and recollections of people in their 80s. Besides, in the later sinking of the Kursk, Russian leadership immediately blamed a collision with a US submarine. But obviously the Russian political climate of 2000 was very different from 1968. It's a fun conspiracy theory.A more interesting conspiracy theory is that K-129 was on a rogue mission to launch nuclear weapons on the US and was torpedoed by the US (once again perhaps by Swordfish, it was in the right place at the time) to prevent this after being tipped off by by the USSR. If that sounds a bit like the plot of The Hunt for Red October, well, it does. The evidence for this story is not nonexistent but it's pretty limited, and no one takes it very seriously.Still, it gets at one of the oddities of K-129: the Soviet Union searched for it in its assigned patrol area, but the wreck was ultimately found far away from its assigned patrol area. I don't think anyone has a really good explanation for this. It was not at all typical for Soviet submarines to go off on their own, Moscow kept very tight control of them. So it seems that either Moscow didn't know where K-129 was (perhaps suggesting some kind of plot, whether of defection or rogue attack who knows), or they knew where it was and searched elsewhere to avoid showing their hand (suggesting K-129 was on some sort of very secret mission). I tend to suspect the latter is more likely, K-129 may have been ordered to leave its patrol area and approach the US as a show of force (this happened at other points in the Cold War) and when it was lost the search was conducted in the normal patrol area to avoid revealing that had happened. All indications are that SOSUS was successfully kept secret from the USSR for quite some time, although certainly not all the way until 1991.Tom Clancy seems to have based The Hunt for Red October at least in part on rumors about K-129. Yeah, I watched too many submarine movies and read too many submarine books as a kid. What can I say, I had a middle-aged father.replymaxbond 11 hours ago | root | parent | next [\u2013]Gotcha. Thank you for the detailed response.I think maybe I'm underestimating the complexity of the technology. It seems like it shouldn't be that hard, I'm kinda imagining something like a weather station or a seismometer. But one thing you've helped me realize is that, at minimum, that comparison fails to account for the complexities of operating in a marine environment.And the undersea cables operative to passive sonar? Or are they more to prevent the stations from being identified and their signals intercepted, as would be the case of if it were over radio?> The wreck was ultimately found far away from its assigned patrol areaMaybe I'm just naive to submarine stuff, I know very little, but this doesn't seem that weird to me. If everyone died onboard from, say, a fire, the vessel might keep steaming for a long time. Presumably, the CIA has a good idea if that's the case, for all the good that does us.replyjcrawfordor 11 hours ago | root | parent | next [\u2013]I think one of the big challenges at the time was how to install the hydrophones, although as I recall there was also a novel type of hydrophone being used. AT&T had invested a lot of effort into figuring out how to not only build long cables that would survive in undersea conditions, but also deliver power on those cables to active equipment (repeaters in the case of undersea telephone cables, hydrophones in the case of SOSUS). This involved putting several-kV (I think into the tens of kV on long cables) DC onto elements of the cable, and it was hard to design a cable that was reasonable to lay but could take that potential without dielectric breakdown. Remember this was in an era where paper was still a popular insulating material on communications cables, if not lead. DC had to be used instead of AC because on these extremely long cables the capacitance between the two current-carrying elements would end up eating up most of the power you put into it.Between Bell Labs and Western Electric, AT&T had a lot of practical expertise in designing and manufacturing some really complex cable bundles with high voltage and sensitive communications pairs nearby. This pretty much all became obsolete as soon as fiber started taking over in the '80s, but it was pretty incredible how many coaxial pairs AT&T was cramming into a buried cable (along with power for all the en route equipment!) in the '70s. Hell, AT&T famously held off on fiber for years because they had a plan to bury long microwave waveguides like cables!replyetimberg 10 hours ago | root | parent | prev | next [\u2013]The book Red Star Rogue by Kenneth Sewell goes in depth on the theory that K-129 sank while on some kind of mission to launch a nuclear weapon.replyjcrawfordor 10 hours ago | root | parent | next [\u2013]I kind of wanted to say Sewell but I wasn't sure I remembered the name right and I guess I was too lazy to look it up---but that's the one. Sewell is a big advocate of this theory but I think most people, even conspiratorial ones, think of him as kind of a crank. I haven't read the book so I won't judge too harshly, I just know that the rogue nuclear mission theory sort of hinges on a lot of political currents within the Kremlin and KGB that aren't in evidence elsewhere.replyapawloski 9 hours ago | root | parent | prev | next [\u2013]Re: Scorpion, I\u2019ve been persuaded by the argument put forth In Blind Man\u2019s Bluff, that a faulty torpedo battery overheated and kicked off a sequence of events ultimately resulting in sinking and implosion.replyericbarrett 8 hours ago | root | parent | next [\u2013]I'm about 3/4 of the way through Blind Man's Bluff. Highly recommended if you have any interest in Cold War history; it's a gripping read.replyAlbertCory 4 hours ago | prev | next [\u2013]A question about ELF and VLF for whoever knows:I just finished reading Thunderstruck (Erik Larson, author of Devil in the White City), which I don't recommend. It ineffectively juxtaposes the story of Marconi with Hawley Crippen, a murderer in London whose case became famous around 1910. (I say \"ineffectively\" because their stories really don't intersect, IMHO) The book goes on and on about all the demos and tests he ran for years and years, to the point of being eye-glazingly boring. All that aside...Anyhow: at the very end, the author tells us that Marconi discovered near the end of his life that higher frequencies obviate the need for the gigantic transmitters and receivers he'd been using. Yet he never tells us what frequencies Marconi was using! Does anyone know?replyjs2 4 hours ago | parent | next [\u2013]I loved Devil in the White City so it's too bad to hear that you didn't find Thunderstruck very good.Marconi was working on developing microwave transmission at the time of his death. Microwave antenna are small but are only good for line of sight transmission.replygrog454 12 hours ago | prev | next [\u2013]An excellent read but one thing caught my attention:> The Navy did not withhold information on the detection for four days out of some concern for secrecy.I think it's more likely than not that the statement is correct, but what gives the author the authority to make the claim so definitively? The author's bio indicates he's a consultant and there is no indication of direct involvement in this or any other SAR effort.While the workings of the SOSUS and IUSS systems may be declassified, the deployments and capabilities (mostly range and computation related) of such systems most likely are not. And there is always the possibility that there is yet another system the author simply isn't aware of.IMO, it isn't negligence to value the secrecy of systems used for defense above some number of lives, in some situations.replyjcrawfordor 12 hours ago | parent | next [\u2013]Well, the clearest source is that no one claims the information was withheld, as far as I can tell that idea was just synthesized by podcasters and internet commenters. The Navy states, the WSJ reports (probably based on the Navy statement), and the Coast Guard mention that Navy intelligence reported the possible implosion almost immediately after it was discovered. The only thing that didn't happen until four days later was the release of that information to the public.Many aspects of IUSS are still classified, and for example we can assume that the actual data will never be released because of sensitivity of the collection system. But the news that the Navy detected the implosion is nothing new, it would probably be more surprising if the Navy didn't (I don't know that the sound levels associated with a vessel of this type imploding are well known, maybe it could be explained away as the implosion having somehow produced almost no acoustic signature). We know that in the '60s the Navy detected submarine implosions (admittedly of larger submarines) further afield, and we also know that IUSS has seen major upgrades including new sensor arrays since then.replymaxbond 12 hours ago | root | parent | next [\u2013]> As far as I can tell that idea was just synthesized by podcasters and internet commenters.I don't use Twitter so can't confirm, but what I've heard in the news is that the OceanGate lawyer tweeted some vague, borderline conspiratorial stuff about not getting proper cooperation from the Coast Guard. I think the commentary people you refer to then boosted and expounded upon that idea.ETA: Partial confirmation here https://nypost.com/2023/06/20/oceangate-adviser-rips-us-gove...The statements quoted here don't match the description \"vague and borderline conspiratorial,\" but they could be misinterpreted that way, and maybe there were others.replytw04 12 hours ago | parent | prev | next [\u2013]>While the workings of the SOSUS and IUSS systems may be declassified, the deployments and capabilities (mostly range and computation related) of such systems most likely are not. And there is always the possibility that there is yet another system the author simply isn't aware of.But they confirmed it 4 days later - which would be admitting to its capabilities. The entire talk track of: \"they kept it secret because of conspiracy theory X\" makes no sense when they didn't actually keep it secret, they simply didn't make it public until AFTER the team was there to search - for the fairly obvious reasons the author stated. Mainly it creates unnecessary publicity that is hurtful to the relatives of the folks that are at the bottom of the ocean, and political pressure to \"not spend money on the search\" which was already coming from some circles even without the Navy's information.replygrog454 12 hours ago | root | parent | next [\u2013]And those are all valid reasons to delay release. My point is that they are not mutually exclusive with declassification, or verification that the information is OK to release publicly from a security standpoint. I'm not sure why secrecy automatically means \"conspiracy theory\".replytw04 12 hours ago | root | parent | next [\u2013]>I'm not sure why secrecy automatically means \"conspiracy theory\".It doesn't automatically, but literally everyone claiming the Navy was \"hiding something\" was going down the conspiracy theory route. I'm not talking about generalities, I'm talking about the specific situation in question which is the Titan sub.>the information is OK to release publicly from a security standpoint.What information are you referring to? It's already public that the navy has the system in question. It's already public that it is analyzing data realtime. Nothing about the system would have been compromised by publicly announcing they had detected an anomaly the day of the event vs 4 days later. The logical conclusion is that all of the aforementioned reasons are why they waited 4 days. You don't need clearance to get to the conclusion.replygrog454 9 hours ago | root | parent | next [\u2013]> Nothing about the system would have been compromised by publicly announcing they had detected an anomaly the day of the event vs 4 days later.Have you worked on classified detection systems? Actions and conclusions don't always appear to follow logic when your priors are wrong.replyXorNot 10 hours ago | root | parent | prev | next [\u2013]Releasing the information 4 days later implies it took 4 days to properly process and categorize. It probably did take some time to properly process and categorize it, because anomalous sounds happen underwater all the time, and unless it's a subsea nuclear detonation or a Russian propeller screw then it's going to go into the \"figure it out later\" bucket.So what we know is it took no more then 4 days to categorize it. We don't know whether or not the system flagged it immediately, or flagged it as part of background process, or how long that took.Joe Internet-Commentator looks at that and says \"oh it was totally instant, probably\".Bill Submarine-Commander for a Hostile Power on the other hand is very interested in exactly how quick any particular detection was, to what resolution, and what implied noise-cutoffs of the network. What sort of sonic events are handled in real time vs. handled in later analysis. Because for Bill the question is \"how long before I'm detected and surface ships start dropping buoys, depth charges and torpedos to kill me\".replyfbdab103 9 hours ago | root | parent | next [\u2013]>Joe Internet-Commentator looks at that and says \"oh it was totally instant, probably\".Kind of, yeah. There is a good timeline on when the ship was in water, when an event would have occurred, plus a very narrow geographical search area. That is significantly more information than is ever available when chasing ghost submarines.It is difficult for me to imagine some bored analyst did not pop open a graph of activity within a 30 minute window of suspected loss of contact time for the area. If detectable, a ship implosion is likely a pretty aberrant signal in the data.replyglompers 7 hours ago | root | parent | next [\u2013]But why precisely does the sloppy sub operator or the mass media audience deserve the information their tax dollars are paying an analyst staff to harvest? Your idea still seems to me like potential question-begging; the fact that the habit would be of interest to people and save lives at some point is not surprising, but lifesaving is not the nature of the pointed interest of most OceanGater polemics in the first place...replyfbdab103 7 hours ago | root | parent | next [\u2013]I never said it had to be shared. Just that I think it incredibly likely that if a Naval sensor did detect the event, it would have been identified in short order. Potentially not definitively as an implosion, but that the Navy could have rapidly pinpointed the event in the data.I am not qualified to state what was the appropriate timeline to give a public response nor it if should have been made.replyglompers 7 hours ago | root | parent | next [\u2013]That's fair. I apologize for my tone.replyXorNot 7 hours ago | root | parent | prev | next [\u2013]Sure, but literally everything they're looking at is classified capability or may include classified capability. They don't have permission to just post a hot-take on Twitter, and definitely don't have permission to unilaterally release supporting data.All of that has to run through the chain of command and declassification process.reply7speter 5 minutes ago | parent | prev | next [\u2013]The author could have friends in high places, for all we know.What could also be possible is that US has improved its sensory technology, and while its known that the US is capable of listening to the sea, they may have some new edge they want to keep obscured from the likes of russia.I\u2019m just some guy, but it struck me as a possible way for the US to flex on the russians, especially right now when Putin is threatening to use nukes, and the US, by the book wouldnt want to because the US may not know where all of russias nuclear subs are supposed to be. It was a great opportunity for the US military apparatus to turn on a sort of fog of war machine\u2026 for all we know intelligence may have told the likes of James Cameron and Rob Ballard to say they got early news from their navy friends.replyscotty79 30 minutes ago | prev | next [\u2013]And despite all those ears they let newsagencies milk the suspense about the fate of Titan submersible for days.replyVecr 13 hours ago | prev | next [\u2013]I really think SAR should be realistic about what's going on and quickly publish what they are trying. Otherwise you can get people who could help showing up with the wrong equipment, or not showing up at all, or people showing up who think they can help but can't and don't know it due to the lack of information.replyjcrawfordor 13 hours ago | parent | next [\u2013]Search and rescue authorities very much do not want people just showing up with equipment based on what they heard on the news---if you are involved in search and rescue, disaster response, or related areas, one of the first things drilled into you is that you must never \"self-activate.\" It puts an enormous workload on the people in charge of the incident if you expect them to keep the entire world informed about the state of the search, and an even bigger workload if people start showing up without having been asked. Organizations like the Coast Guard have a public information function to manage the press and cold contacts, and a logistics function to call upon resources. Volunteered resources are rarely useful if they have not been vetted and had operational procedures established in advance.My experience is only in wildfire and structure fire, but everything I've heard is that the situation is much the same in SAR and I can only imagine the issues with needing to having resources prepared in advanced are only more significant at sea where integration is very complex.replyschoen 13 hours ago | root | parent | next [\u2013]How does this interact with the norm of commercial vessels responding to distress calls at sea?I know distress calls aren't at all the same as search and rescue, but in some incidents both phases must occur.replyjcrawfordor 12 hours ago | root | parent | next [\u2013]Ships nearby responding to a distress call is a matter of expedience rather than good planning - something is better than nothing. But typically once an organization like a coast guard gets involved, they start giving orders to other responding ships, including sending ships away if they aren't needed and adding to the fray. This general concept is called incident command or the incident command system (ICS) after a set of practices that I think originated in firefighting but are now broadly taught by FEMA to all sorts of disaster responders. Basically that there needs to be someone in charge of the incident and there need to be standardized and controlled flows of information, otherwise it's very easy for the response to be ineffective and even dangerous because of poor communications, miscoordination, etc.replyschoen 10 hours ago | root | parent | next [\u2013]Thanks! I studied ICS as part of a neighborhood emergency response training some years ago, but I don't feel that familiar with it anymore.So I guess the basic idea is that volunteers should provide aid as they can, but once a response coordination authority is established, the volunteers should either leave the scene or put themselves under that authority's direction? (Including potentially being directed to leave the scene.)replyfredoralive 12 hours ago | root | parent | prev | next [\u2013]There\u2019s a bit of a difference between a ship already at sea altering it\u2019s course to get near and assist a vessel in distress (where they might be first on he scene), vs ship going to sea especially for an event I guess? You don\u2019t want the area too crowded with \u201cgood Samaritans\u201d who\u2019ve all gone to sea just to assist.I recall some comments saying that operators of a submersible that could hypothetically rescue a sub stranded on the bottom being discouraged from deploying for the Titan by the coast guard, which perhaps means they already knew the fate of the vessel. Although it could be that they already had a suitable submersible arranged already and didn\u2019t want more in the area causing complications with coordination etc.replysaqadri 13 hours ago | prev | next [\u2013]Amazing read, convincingly explains a lot of confusion around the aftermath of the search operation. And kind of mind blowing that IUSS exists primarily to detect submarine movements around the world.I would love to learn more about the technology \u2014 are these wireless transmitters? Undersea cables all around the oceans of the world?replyjcrawfordor 12 hours ago | parent | next [\u2013]Historically the hydrophones were attached to cables that were laid using AT&T cable-laying vessels, so technology extremely similar to the transoceanic cables of the time (thus AT&T's involvement). The change to IUSS added the ability of mobile sensors to report into this system, so there's apparently something available there (I would assume satellite). We also know that the Navy possesses buoys that trail hydrophones, and I would assume these can be integrated into IUSS as well. The modern details get to be classified though.As I understand it most of the original SOSUS arrays are still in operation, but I think they're more useful for scientific research than submarine surveillance at this point just because the newer arrays are much more sensitive. The locations of the original SOSUS arrays aren't totally public but you can put together some pretty good inferences about a lot of them, for example based on the NAVFACs that had similar cover stories and then closed at around the same time. Each one would have been the landing station and control point for a '60s array.replybatch12 5 hours ago | prev | next [\u2013]> This website is begrudgingly generated by the use of software. Letters to the editor are welcome via facsimileWhat does this mean? Is it a reference I'm missing, a vague disclaimer for generated text, or am I reading too much into the footer?replyshoo 5 hours ago | parent | next [\u2013]facsimile refers to communication by fax machine, an ancient method of written communication over telephone lines that was popular pre-email, and is still popular in remaining pre-email societies such as federal government departments and japan.> begrudgingly generated by the use of softwareread the top of https://computer.rip/replyjtwaleson 5 hours ago | parent | prev | next [\u2013]I think it just means the author does not like software too much and can be reached via fax.replystall84 9 hours ago | prev | next [\u2013]I guess I'm feeling a little dumb and outlying on my immediate theory to the delay between USN officially reporting hearing the implosion, but here it is anyway: It would make sense to me that in the vast world of US Intelligence, especially when combined with signals-intelligence (like listening on what channels in Russia or China are communicating internally to each other), that when you have an event like Titan imploding, relatively close to US waters, you would want to not show those cards, and listen to hear if anyone else reports hearing anything .. Kind of like a sophisticated game of counterespionage .. That way you can get an idea of whoever else might have equipment in the water very near your own. But idk .. just the first thing that came to mind. Love this read btwreplyEMCymatics 13 hours ago | prev | next [\u2013]I wonder what supercavitation sounds likereplykayodelycaon 12 hours ago | parent | next [\u2013]I looked it up and if the video is accurate, it sounds like static. About what I expected a large stream bubbles to sound like. (Imagine a shaken soda bottle can overflowing.)replydarkclouds 13 hours ago | prev [\u2013]>Much more appealing is passive sonar, which works by listening for the sounds naturally created by underwater vehicles.Experts in marine biology. Reminds me of the night vision camera the british military were showing off on BBC Countryfile program. Who would have thought the military are experts in biology, but probably explains why the brits took off sunglasses in Iraq when talking to people, but the US didnt. You should see the british scarecrows as well!> Instead, the battle of submarine silence has mostly revolved around obscure technical problems of fluid dynamics, since one of the loudest noises made by submarines is the cavitation around the screw.https://en.wikipedia.org/wiki/Toroidal_propeller Difference in cavitation. https://youtu.be/k0yzBTTqfzs?t=436Dont know if these toroidal propellers scale up to submarine sizes, they keep them hidden under an large oily rag along with the front of the subs.> did the Navy withhold information on the detection from searchers out of concern for secrecyLocation of sensors maybe, after all something like the titanic will attract treasure hunters, why wouldnt interested govt's deploy remote sensors to detect who is in the area? Submarines make it easy for crew to be kept in the dark on missions as not many can use the periscope or other sensors.I read somewhere once that a sensor, sonar or hydrophone, in UK waters could detect the sounds come from a New York harbour, which gives an insight into the distance sounds can travel underwater, but considering all the noises that can be detected, having sound processing abilities, a little bit better than something like Dolby Noise Reduction, is the key part of the underwater arms race.https://www.theguardian.com/environment/2023/may/15/listen-t...https://news.sky.com/story/titanic-sub-search-what-are-the-s...replyjcrawfordor 12 hours ago | parent | next [\u2013]> I read somewhere once that a sensor, sonar or hydrophone, in UK waters could detect the sounds come from a New York harbour, which gives an insight into the distance sounds can travel underwater, but considering all the noises that can be detected, having sound processing abilities, a little bit better than something like Dolby Noise Reduction, is the key part of the underwater arms race.I didn't really get into this in the article but there's a phenomenon called SOFAR (I think this does stand for something but the acronym is sort of a joke). It's basically a specific static water pressure (and thus depth) in which sound \"ducts\" sort of like how HF radio can duct in the ionosphere. As I understand it, it's not at all unreasonable for a sound in the SOFAR channel to go clear around the world. I know there are cases where hydrophones have recorded a particularly loud sound multiple times because of it coming \"the long way around\" as well as echo effects. Some of these sounds have been things like \"perhaps the loudest sound ever produced\" and are attributed to seismic phenomenon, but there are a lot of strange things going on in the ocean and hydrophones continue to provide plenty of questions for marine researchers to answer. And, of course, at least some of the IUSS sensors are very intentionally placed within the SOFAR channel to capitalize on this effect.replydarkclouds 11 hours ago | root | parent | next [\u2013]It is interesting a bit like catching the sound of a distant rave on the wind.https://en.wikipedia.org/wiki/SOFAR_channelreplyindymike 12 hours ago | parent | prev | next [\u2013]> I read somewhere once that a sensor, sonar or hydrophone, in UK waters could detect the sounds come from a New York harbour, which gives an insight into the distance sounds can travel underwater, but considering all the noises that can be detected, having sound processing abilities, a little bit better than something like Dolby Noise Reduction, is the key part of the underwater arms race.In a typical attack sumbarine, a substantial amount of the ship's volume is dedicated to acoustic sensors: https://media.defenceindustrydaily.com/images/SHIP_SSN_Virgi...This arms race is very old, and the state of the art even 20 years ago is pretty impressive.replydarkclouds 10 hours ago | root | parent | next [\u2013]403 forbidden link with your link but the wayback machine lets me see it.https://web.archive.org/web/20230123071023/https://media.def...Detecting (background) radiation is the new state of the art and improvements in tech seen in peoples mobile phones.https://icecube.wisc.edu/news/press-releases/2017/11/first-l...https://www.youtube.com/watch?v=XwKKOPd-5cUhttps://www.royalnavy.mod.uk/news-and-latest-activity/news/2...replymicromacrofoot 12 hours ago | parent | prev [\u2013]what\u2019s the difference with british scarecrows? eyes or something?replytomcam 12 hours ago | root | parent | next [\u2013]Yeah, that comment fascinated me too. I can only say that the character of British scarecrows is\u2026 very different from those in the US, although I can\u2019t articulate one reason exactly why: https://www.google.com/search?&q=british+scarecrow&replyandrelaszlo 12 hours ago | root | parent | prev | next [\u2013]They take their sunglasses off when talking to people. It's more polite.replydarkclouds 11 hours ago | root | parent | prev [\u2013]5 eyes perhaps.replyGuidelines | FAQ | Lists | API | Security | Legal | Apply to YC | ContactSearch:",
    "hn_summary": "- The article discusses the use of passive sonar and hydrophones to detect submarine movements around the world.\n- There is speculation about whether the Navy withheld information on the detection of the implosion of the Titan submersible from searchers.\n- The ability to detect sounds underwater, such as the SOFAR channel phenomenon, plays a crucial role in the underwater arms race."
  },
  {
    "id": 36749059,
    "timestamp": 1689526397,
    "title": "SoundStorm: Efficient Parallel Audio Generation",
    "url": "https://google-research.github.io/seanet/soundstorm/examples/",
    "hn_url": "http://news.ycombinator.com/item?id=36749059",
    "content": "SoundStorm:Efficient Parallel Audio Generation[paper]Zal\u00e1n Borsos, Matt Sharifi, Damien Vincent, Eugene Kharitonov, Neil Zeghidour, Marco TagliasacchiGoogle ResearchAbstract. We present SoundStorm, a model for efficient, non-autoregressive audio generation. SoundStorm receives as input the semantic tokens of AudioLM, and relies on bidirectional attention and confidence-based parallel decoding to generate the tokens of a neural audio codec. Compared to the autoregressive generation approach of AudioLM, our model produces audio of the same quality and with higher consistency in voice and acoustic conditions, while being two orders of magnitude faster. SoundStorm generates 30 seconds of audio in 0.5 seconds on a TPU-v4. We demonstrate the ability of our model to scale audio generation to longer sequences by synthesizing high-quality, natural dialogue segments, given a transcript annotated with speaker turns and a short prompt with the speakers' voices.Your browser does not support HTML video.Dialogue SynthesisSoundStorm, coupled with the text-to-semantic modeling stage of SPEAR-TTS (Kharitonov et al., 2023), can synthesize high quality, natural dialogues, allowing one to control the spoken content (via transcripts), speaker voices (via short voice prompts) and speaker turns (via transcript annotations). When synthesizing dialogue segments of 30 seconds, we measured a runtime of 2 seconds on a single TPU-v4. The following text and speakers have not been seen during training.Text Voice Prompt Synthesized DialogueWhere did you go last summer? | I went to Greece, it was amazing. | Oh, that's great. I've always wanted to go to Greece. What was your favorite part? | Uh it's hard to choose just one favorite part, but yeah I really loved the food. The seafood was especially delicious. | yeah | And the beaches were incredible. | uhhuh | We spent a lot of time swimming, uh sunbathing, and and exploring the islands. | Oh that sounds like a perfect vacation! I'm so jealous. | It was definitely a trip I'll never forget | I really hope I'll get to visit someday! Your browser does not support the audio element. Your browser does not support the audio element. Your browser does not support the audio element.Something really funny happened to me this morning. | Oh wow, what? | Well, uh I woke up as usual. | Uhhuh | Went downstairs to have uh breakfast. | Yeah | Started eating. Then uh 10 minutes later I realized it was the middle of the night. | Oh no way, that's so funny! Your browser does not support the audio element. Your browser does not support the audio element. Your browser does not support the audio element.I'm going to Istanbul for the Champions League final. | That's awesome. Who are you supporting? | Liverpool. I've always been a big fan. | Ah Liverpool is a great team but I I think it will be it will be a close match. | Yeah, I can't wait, you know, I'm super excited to be going there! | Yeah I can imagine. | Are you coming as well? | Ah, no, unfortunately, I I can't. Your browser does not support the audio element. Your browser does not support the audio element. Your browser does not support the audio element.I've always wanted to learn how to play the guitar. | What kind of guitar do you have in mind? | Um I'm not sure, I guess I'd uh like to learn to play both acoustic and electric. | Yeah, that's a great idea. Both types of guitars have their own uh their own unique sounds and uh and playing styles. | I know, but uh it's hard to decide which one to start with. | Well, um if you're not sure, I would recommend starting with an acoustic guitar. | Interesting | They're a little easier to learn on | ah | and they can be played anywhere. | That's good to know. Your browser does not support the audio element. Your browser does not support the audio element. Your browser does not support the audio element.I didn't sleep well last night. | Oh, no. What happened? | I don't know. I I just couldn't seem to uh to fall asleep somehow, I kept tossing and turning all night. | That's too bad. Maybe you should uh try going to bed earlier tonight or uh maybe you could try reading a book. | Yeah, thanks for the suggestions, I hope you're right. | No problem. I I hope you get a good night's sleep. Your browser does not support the audio element. Your browser does not support the audio element. Your browser does not support the audio element.Unprompted and Prompted GenerationWe demonstrate the capabilities of SoundStorm to generate audio conditioned on the semantic tokens of AudioLM (Borsos et al., 2022) with and without 3-second voice prompts. SoundStorm samples different speakers in the unprompted case, and maintains the speaker's voice with high consistency in the prompted case, while generating audio two orders of magnitude faster than AudioLM's acoustic generator. The original samples are from LibriSpeech test-clean.Original Unprompted PromptedYour browser does not support the audio element. Your browser does not support the audio element. Your browser does not support the audio element. Your browser does not support the audio element. Your browser does not support the audio element.Your browser does not support the audio element. Your browser does not support the audio element. Your browser does not support the audio element. Your browser does not support the audio element. Your browser does not support the audio element.Your browser does not support the audio element. Your browser does not support the audio element. Your browser does not support the audio element. Your browser does not support the audio element. Your browser does not support the audio element.Your browser does not support the audio element. Your browser does not support the audio element. Your browser does not support the audio element. Your browser does not support the audio element. Your browser does not support the audio element.BaselinesWhen generating audio in the prompted case, SoundStorm generations have higher acoustic consistency and preserve the speaker's voice from the prompt better than AudioLM. Compared to RVQ level-wise greedy decoding with the same model, SoundStorm produces audio with higher quality.Original AudioLM Greedy SoundStormYour browser does not support the audio element. Your browser does not support the audio element. Your browser does not support the audio element. Your browser does not support the audio element.Your browser does not support the audio element. Your browser does not support the audio element. Your browser does not support the audio element. Your browser does not support the audio element.Your browser does not support the audio element. Your browser does not support the audio element. Your browser does not support the audio element. Your browser does not support the audio element.Your browser does not support the audio element. Your browser does not support the audio element. Your browser does not support the audio element. Your browser does not support the audio element.Broader impactSoundStorm is a model for high-quality, efficient generation of neural audio codec-derived representations of audio. In this work, we use it as a replacement for the acoustic generation pipeline of AudioLM and SPEAR-TTS. We acknowledge that the audio samples produced by the model may be influenced by the biases present in the training data, for instance in terms of represented accents and voice characteristics. In our generated samples, we demonstrate that we can reliably control speaker characteristics via prompting. However, a more thorough analysis of any training data and its limitations would be an area of future work in line with our responsible AI principles. In turn, the ability to mimic a voice can have numerous malicious applications, including bypassing biometric identification and for the purpose of impersonation. Thus, it is crucial to put in place safeguards against the potential misuse: to this end, we have verified that, after such a replacement, the generated audio remains detectable by a dedicated classifier (98.5% using the same classifier as Borsos et al. (2022)). Hence, as a component of a larger system, we believe that SoundStorm would be unlikely to introduce additional risks to those discussed previously by Borsos et al. (2022) and Kharitonov et al. (2023). At the same time, we hope that relaxing the memory and computational requirements of AudioLM would make research in the domain of audio generation more accessible to a wider community. In the future, we plan to explore other approaches for detecting synthesized speech, e.g., audio watermarking, so that any potential product usage of this technology strictly follows our responsible AI principles.",
    "summary": "- SoundStorm is a model for efficient audio generation that produces high-quality audio faster than previous methods.\n- It uses bidirectional attention and confidence-based parallel decoding to generate neural audio codec tokens.\n- The model can synthesize natural dialogues and mimic different speakers' voices based on transcripts and voice prompts.",
    "hn_title": "SoundStorm: Efficient Parallel Audio Generation",
    "original_title": "SoundStorm: Efficient Parallel Audio Generation",
    "score": 271,
    "hn_content": "Hacker News new | past | comments | ask | show | jobs | submit loginSoundStorm: Efficient Parallel Audio Generation (google-research.github.io)271 points by sh_tomer 17 hours ago | hide | past | favorite | 118 commentsqwertox 14 hours ago | next [\u2013]In CGI there were always these milestones which I observed getting reached. Like trees with leaves finally looking close to realistic, wind blowing in grass looking almost realistic, hair, jelly, and it were usually Pixar shorts pointing out what they have been focusing on and then seeing it applied to their movies.Then mocap, mapping digital faces on real actors which was first mind-blowing to see in Pirates of the Caribbean, then the apes in one of the Planet of the Apes movies... So much in the CGI industry has already reached a point where the hardest problems seem to have been solved.When I now clicked play on the first Synthesized Dialoge from Dialogue Synthesis \"Where did you go last summer? | I went to Greece, it was amazing.\", I was blown away. It's as if we've now reached one of those milestones where a problem appears to be fixed or cracked. Machines will be able to really sound like humans, indistinguishable from them.10-5 years ago, if you wanted to deal with TTS, the best option you had was to let your Android phone render a TTS into an audio file, because everything else sounded really bad. Specially Open Source stuff sounded absolutely horrible.So how long will it be until we will be able to download something of this quality onto a future-gen Raspberry Pi which can do some AI processing, where we make an HTTP call and it starts speaking through the audio out in a perfect voice without relying on the cloud? 5 years?replyamelius 12 hours ago | parent | next [\u2013]Another question, how long until we have systems that can sing 10 octaves and we don't need/want any actual human singers anymore?replyPaulDavisThe1st 10 hours ago | root | parent | next [\u2013]To answer that question, it is necessary to answer the question \"why did we want actual human singers in the past?\"If you think it is because there was no alternative, then you will see no barriers to the adoption of the sort of system you imagine.But if you think it is because all human art is a form (however weird, tangled and opaque) of story telling, and for it to work, the person experiencing the art needs to be believe that there must be a story to be told, then your imagined system is not that interesting.However, we are seeing an overwhelming propensity even today for people (even people who ought to know better) to ascribe intentionality and even emotion to computer systems that demonstrably do not have it (and as far back as Eliza in the 1970s). It seems likely to me that most people will rapidly come to believe in a sufficiently intentional and emtional backstory to your putative wunder-singer that their belief will satisfy their desire for \"a person behind the art\".replyanileated 2 hours ago | root | parent | next [\u2013]Whether a machine can sing like a human does not matter much as far as appreciation of art: all art is self-expression, and self-expression always requires a self to express and a self to receive. Someone programmed the voice to sing something to someone for some reason.Both human and software-generated singing exist today, and either can be boring nonsense or speak to you and leave an emotional impact.(That said, if said machine is actually a derivative work produced from vocal samples without appropriate licensing, that\u2019d make it dubious legally or morally. To my knowledge, preexisting software-generated singing like Vocaloid does not suffer from this problem.)replycivilitty 7 hours ago | root | parent | prev | next [\u2013]With multimodal vocal-LLMs we\u2019ll be able to prompt any kind of personality to the singer.\u201cYou are a castrato who sailed with Black Beard and survived the holocaust with a degree in Klingon studies from Oxbridge\u2026\u201dreplytolien 7 minutes ago | root | parent | prev | next [\u2013]Star Trek: Voyager \"Virtuoso\" thought of that already. Their answer was that you get something which is barely recognisable as music.replyttul 11 hours ago | root | parent | prev | next [\u2013]As a choral singer, if there\u2019s an app that one day allows me to sing with a fake choir of extremely good singers, I would enjoy doing that all day long. And it would allow my actual choir to practice way more, making our performances far better.replynraford 11 hours ago | root | parent | next [\u2013]This exists right now!Not as an app exactly, but you should check out Holly Herndon and Mat Dryhurt\u2019s suite of tools called \u201cHolly Plus\u201d:https://holly.plus/I\u2019m pretty sure you can access their model somehow and even train your own voice using their \u201cspawning\u201d approach.She did an awesome TED talk demonstrating this:https://www.ted.com/talks/holly_herndon_what_if_you_could_si...Here\u2019s a cool example, using Dolly Parton\u2019s song \u201cJolene\u201d:https://www.youtube.com/watch?v=kPAEMUzDxuoI don\u2019t think it\u2019s quite at the level of consumer use yet, but I know they\u2019re working on it. Definitely check it out.replysporkl 10 hours ago | root | parent | prev | next [\u2013]From what I've seen, the music industry (all genres including pop, classical, etc.) tends to be more about personality than actual content these days, so it's not really an issue.Virtual singers are already pretty good anyways, I feel we've already passed the point of diminishing returns.And even if you look at virtual singers, the ones which are popular are the ones from ten years ago, not the newer ones with more realistic voices.replyLockal 1 hour ago | root | parent | next [\u2013]What do you mean by \"ten years ago\"? Yamaha Corporation produces vocal synths since 2000s, but it is quite pointless to use technologies of Vocaloid 4 if you can use Vocaloid 6.replywodenokoto 2 hours ago | root | parent | prev | next [\u2013]> these daysHow far back are you counting as these days? I'd the entire recording industry has always been about attaching an image to songs.replyjayd16 12 hours ago | root | parent | prev | next [\u2013]People like to song along though.replytialaramex 11 hours ago | root | parent | next [\u2013]People like playing drums too, but a drum machine means that if you're not any good at it or too busy but you need drum sounds you can have drum sounds.There are rights issues if the result is it replaces a particular singer, if you made it so that Sneaker Pimps can fire Kelli but still have her voice on subsequent songs that's a problem. But suppose you're a bedroom musician, and you realise you've got a piece that really wants somebody with a different voice than yours to make it work - you can pay someone, but technology like this offers a cheaper, easier option.replyrossjudson 5 hours ago | parent | prev | next [\u2013]Over the years I've also watched CGI progress and been amazed by the steps there -- the joy of seeing yet another complex part of reality rendered was a constant.These days, though...every new technique developed to simulate and replicate human creativity and behaviors builds on a constant sense of unease.If I view or read, do I have the right to know if it's generated?replynine_k 13 hours ago | parent | prev | next [\u2013]In you need a really compact form factor, you can buy a Jetson right now and run more complex models on it. It's pricey though.replyJonathanFly 12 hours ago | parent | prev | next [\u2013]>So how long will it be until we will be able to download something of this quality onto a future-gen Raspberry Pi which can do some AI processing, where we make an HTTP call and it starts speaking through the audio out in a perfect voice without relying on the cloud?5 years? It's probably possible roughly whenever the larger Whisper models can run on it. Probably the next Raspberry Pi, running quantized or optimized versions of some audio model.It may be almost possible right now if you tried really realy hard, and you used a small model fine-tuned on a single voice, instead of something larger and more general purpose that can do any voice. I think whisper-tiny works on a Pi on real time, right? And that's not leveraging the GPU on the Pi. (https://github.com/ggerganov/whisper.cpp/discussions/166)Edit: looks like medium is 30x slower on the Pi than tiny model, so I may have been overly optimistic. I didn't realize Whisper tiny was that much faster than medium.This method works pretty well with Tortoise, letting you use the super fast Tortoise quality settings but get quality similar to the larger models. Fine-tuning the whole thing on just one voice removes a lot of the cool capabilities of course. With Tortoise, that would still be way too slow for a Pi but potentially that same strategy could work with faster models like SoundStorm.In terms of quality there's still a lot of room to go with long term coherence, like long audio segments. When a real person reads an audiobook the words at the top the page have a pretty big impact on how many words at the bottom the page are read. And there can be some impact at any distance, page 10 to page 300. When you try audiobooks on super high end TTS models and listen carefully you really notice the mismatch. It's like the reader recorded the paragraphs out of order, or a video game voice lines where you can tell the actors recorded all the lines separately, and were not reacting to each other's performance.You can bump the context windows, a minute, two minutes. That's gonna get you closer and probably good enough for some books. In the short term a human could simply adjust all the all the audio samples and manually tweak things to sound correct. So this will enable fan-created audiobooks where they take the time to get it right. But for fully automated books the mismatch drives me nuts. The performance is just soooo close for certain segments that when you get a tonal mismatch it hurts.replybckr 14 hours ago | parent | prev | next [\u2013]I would bet 2 years topsreplyog_kalu 16 hours ago | prev | next [\u2013]It's good that Bing, Bard are using the latest Microsoft, Google Cloud offerings but it would be nice to see these speech advances (along with audio palm - https://google-research.github.io/seanet/audiopalm/examples/ etc) hit public api's and/or user interfaces.Bard's TTS is alright but it's clearly behind.On that note, Bing's English/Korean TTS is really good. I also didn't realize Microsoft uses the best offerings for free TTS on edge so it blows google's default tts voices away.replyGordonS 14 hours ago | parent | next [\u2013]I used Azure TTS for a product demo voice-over recently, and nobody I showed it to knew it wasn't a human doing it!Some of Azure's voices are better than others, and the TTS web app has a few minor bugs, but overall I was really pleased with the whole experience.replyjameszhao00 13 hours ago | parent | prev | next [\u2013]Have you tried Google Cloud Studio voices?https://cloud.google.com/text-to-speech/docs/wavenet#studio_...replyog_kalu 13 hours ago | root | parent | next [\u2013]Yes. I'm not saying Google's Top Cloud offerings are bad although i still think microsoft's stuff is better.Just that1. It's behind their current sota research2. You can only use those voices extensively by paying for it. Microsoft offers their best stuff on edge for free. So for reading aloud a pdf or web page, microsoft is far better.replyskybrian 13 hours ago | root | parent | next [\u2013]It's disappointing, but I wouldn't expect research algorithms to be available immediately unless they held it back until the product is ready. I guess Apple would do that?replyjameszhao00 13 hours ago | root | parent | prev | next [\u2013]By \u201cSOTA\u201d tts I think you mean LLM based TTS? With sound and language tokens trained GPT style?Without going into too much details, imo they\u2019re not really usable right now for TTS use cases.replyrefulgentis 14 hours ago | parent | prev | next [\u2013]> I also didn't realize Microsoft uses the best offerings for free TTS on edge so it blows google's default tts voices away.This sounds really interesting - can you share a bit more? I'm behind in this space, my parser got all jammed up, something like: \"Microsoft uses [the best offerings for free TTS](as in FOSS libraries, or free as in beer SaaS?) [on edge](Edge browser, or on the edge as in client's computer?)(Is the implication that all TTS on the client's computer blows Google's default TTS voices away?)\"replyog_kalu 14 hours ago | root | parent | next [\u2013]The top voices you'd pay for on Azure's TTS services can be used for free to read web page(and PDF) text on Microsoft Edge. I don't mean Open source.This is not the case with Googlereplywg0 13 hours ago | root | parent | next [\u2013]I didn't know that. Edge is too good. Just downloaded and such features are great.replyGranPC 14 hours ago | root | parent | prev | next [\u2013]I believe they mean that the free TTS feature in Microsoft Edge uses their best technology, and that said tech is better than Google's default offering.replyShamelessC 16 hours ago | parent | prev | next [\u2013]> public api's and/or user interfacessigh. Google used to release _some_ models. Guess the fun early days are coming to an end.replyog_kalu 16 hours ago | root | parent | next [\u2013]Ha i'm not even asking for code/model releases. It's just a bit funny that what you can *pay* google to use is so far behind what they have up and running collecting dust.replyRaed667 14 hours ago | root | parent | next [\u2013]I'm speculating here, but for me it looks like the product (R&D) teams are not working closely with the research teams.Even the demo website is on Github Pages instead of a Google domain/blog.replyShamelessC 16 hours ago | root | parent | prev | next [\u2013]Also true.replyLegend2440 16 hours ago | root | parent | prev | next [\u2013]Google is a business and this is clearly a valuable product.replyShamelessC 16 hours ago | root | parent | next [\u2013]Sure, but there was a time not too long ago when companies were still in the \"good will\" phase of handing out even highly valuable models like CLIP, guided-diffusion, etc. Come to think, it was mostly OpenAI doing this. And they kinda still do? But far more selectively. I'm just preemptively romanticizing that.replyrasz 16 hours ago | root | parent | prev | next [\u2013]Product is something you sell to make money. The only real Google product is users sold to advertisers.replyjsnell 15 hours ago | root | parent | next [\u2013]Google's non-advertising revenue in the latest quarter was about $15 billion. Is that significant amount of non-ads product revenue? At least that is higher than the revenue of any of IBM, HP, Oracle, Intel, Cisco, Netflix, Broadcom, Qualcomm, or Salesforce in that same quarter.I think their non-ads businesses alone would be the 6th largest US tech company by revenue. (Amazon, Apple, Microsoft, the ads business of Alphabet, Meta. Am I forgetting something?)replyrasz 14 hours ago | root | parent | next [\u2013]Revenue is easy when you lose money on every dollar. Last quarter Ads printed $21B of income, rest was a loss except cloud not losing hundreds of $millions for the very first time.https://abc.xyz/assets/investor/static/pdf/2023Q1_alphabet_e...replyvore 15 hours ago | root | parent | prev | next [\u2013]Uh, what about all of their paid cloud offerings?replyrasz 14 hours ago | root | parent | next [\u2013]Distraction. Generated whole 1% of overall profit last quarter, and that was the first time it didnt lose money. https://www.cnbc.com/2023/04/25/googles-cloud-business-turns...replyShamelessC 10 hours ago | root | parent | prev | next [\u2013]How in gods name is this a controversial take? Good lord.replybinary132 12 hours ago | prev | next [\u2013]When people wax eloquent about how the artisans will just find something new to do for work, what they fail to mention is that the new work is often a menial and lower-paid job. When Amazon puts mom and pop shops out of business, they don\u2019t go start new businesses, they go get jobs at Wal-Mart.replyJonathanFly 16 hours ago | prev | next [\u2013]Interesting that SoundStorm was trained to produce dialog between two people using transcripts annotated with '|' marking changes in voice. But the exact same '|' characters seem to mostly work in the Bark model out of the box and also produce a dialog?Maybe a third or a bit more of Bark outputs are a dialog person talking to themselves -- and it often misses a voice change. But the pipe characters do reliably produce audio that sounds like a dialog in the performance style.https://twitter.com/jonathanfly/status/1675987073893904386Is there some text-audio data somewhere in the training data that uses | for voice changes?Amusingly, Bark tends to render the SoundStorm prompts sarcastically. Not sure if that's a difference in style in the models, or just Google cherry picking the more straightforward line readings as the featured samples.replyog_kalu 16 hours ago | parent | next [\u2013]The creators won't say as far as i know but bark looks to be trained on lot of youtube corpora (rather than typical ML audio datasets) where audio may have transcripts like that and why stuff like [laughs] workreplyneilv 13 hours ago | root | parent | next [\u2013]In the future, will children think it's normal to talk like, \"Hey, what up, Youtube! ... Be sure to like and subscribe! ... Smash that like button! ... Let me know in the comments down below!\"?I wonder how ML trained on the tone transitions to a sponsored segment dripping with secret shame... would infect general speech.replypaulmd 2 hours ago | root | parent | next [\u2013]https://img.ifunny.co/images/4053eb689b6bc2d1d8635dfe53c7acd...replyJonathanFly 15 hours ago | root | parent | prev | next [\u2013]Yeah I often try to think about what might be in a YouTube caption when finding prompts that work in Bark. But pipe character isn't one I remember seeing on YouTube. Maybe it's part of some other audio dataset though. Or maybe it's on YouTube but only in non English videos.replyasutekku 13 hours ago | prev | next [\u2013]The most impressive part of this is that they are seemingly able to produce 30 seconds of TTS with just 3 seconds of source material. That is super cool and honestly much more further in the curve that I expected it to be.replybutz 14 hours ago | prev | next [\u2013]With all recent advances, are there any decent TTS voices for Linux that are not complicated to set up for regular user?replymg 16 hours ago | prev | next [\u2013]I wonder if work marketplaces like UpWork and Fiverr will adapt quickly enough to this new situation, where many of their services, which in the past were done by humans, can now be done by software.Their current marketplace interface seems inadequate for this. Instead of contacting a human and then wait for them to finish the work, buyers will want to get results right away.Therefore they will have to change their platform to work like an app store. Where the sellers connect their services and buyers can use these services.replyLegend2440 16 hours ago | parent | next [\u2013]Why does everybody focus on \"how will this replace humans?\" It's just a really good text-to-speech.replypjmlp 14 hours ago | root | parent | next [\u2013]Maybe because I no longer hear friendly human voices on train stations, rather computer generated train announcements?While those people are now looking for jobs elsewhere.replyrelativ575 13 hours ago | root | parent | next [\u2013]Announcements often get played repeatedly -- \"Train 101 to Lisbon is now on track 5\". Why do you want to torture station's workers with that?Instead, make an effort to start a conversation with your fellow travelers, or graciously respond to such effort from them. Apologize if you already do.replypjmlp 12 hours ago | root | parent | next [\u2013]Better a tortured job that puts food on the table than none at all.replyBHSPitMonkey 2 hours ago | root | parent | next [\u2013]Taken to its conclusion, doesn't this just mean we should outlaw all forms of mechanization in order to preserve human jobs as much as possible? Would this be better for a country than just allocating a portion of the economy's output and using it to provide social safety nets?replypjmlp 1 hour ago | root | parent | next [\u2013]Since you mention it, there was some news a while back of some African countries not using construction machines to build roads on purpose, as means to foster more jobs.Likewise in many countries, having someone at the gas station to fill in the tank is still a job, and most likely even with EV they would be the ones taking care of the charging.replycpill 11 hours ago | root | parent | prev | next [\u2013]tell that to the kids in Nike sweat shopsreplypjmlp 4 hours ago | root | parent | next [\u2013]Their family appreciate.As do everyone that buys Nike.replydtjb 10 hours ago | root | parent | prev | next [\u2013]At the beginning of the 20th century in the US, 3 in 4 workers were either laborers, farmers, miners, or household service workers. By the end of the century that number had fallen to 1 in 4.Of course that wasn't a net loss, it was part a larger economic transformation that created more higher paying jobs.replypjmlp 4 hours ago | root | parent | next [\u2013]Looking at the employment rate across US doesn't look like it.Specially the people living from paycheck to paycheck, without any kind of healthcare support.replyLegend2440 13 hours ago | root | parent | prev | next [\u2013]Fantastic! That's a massive efficency gain.We will not run out of productive things to do with our time. Labor force participation has stayed in 60-70% despite centuries of automation.replypjmlp 12 hours ago | root | parent | next [\u2013]Lovely capitalism.replyPhasmaFelis 16 hours ago | root | parent | prev | next [\u2013]Because it will replace humans, and that's worth thinking about?replyImHereToVote 16 hours ago | root | parent | prev | next [\u2013]Personally I can't wait for all the streets to be lined with the homeless like in SF. So good.replyakaij 14 hours ago | root | parent | next [\u2013]It's kinda sad to see you believe that this is the inevitable outcome.replypjmlp 14 hours ago | root | parent | next [\u2013]Well, if we imagine that the only thing that will be left are physical jobs that can't be done by computers.At least until they get clever enough to start a transformers line factory.replyLegend2440 13 hours ago | root | parent | next [\u2013]This is the lump of labor fallacy. It's not about \"what jobs will be left\", it's about the new jobs we'll invent with all the time we'll have on our hands.There was never a fixed number of jobs, there's a fixed number of workers.replybigfudge 3 hours ago | root | parent | next [\u2013]The nature of the jobs change too though. Do you believe jobs will become more or less skilled/autonomous and connect people more or less with their fellow man? Some of us are pessimistic about those questions.replyslaterbug 3 hours ago | root | parent | prev | next [\u2013]> There was never a fixed number of jobs, there's a fixed number of workers.Isn\u2019t this the \u2018problem\u2019 that AI is trying to solve?replyImHereToVote 4 hours ago | root | parent | prev | next [\u2013]I didn't think you understand. We aren't about to automate all things humans can \"currently\" do. We are about to automate everything that separates us from a brick. What can possibly be left, and why would an unemployed person pay for whatever what is left?replypjmlp 12 hours ago | root | parent | prev | next [\u2013]Well, we can also return to feudalism.replyseydor 16 hours ago | parent | prev | next [\u2013]> where many of their services, which in the past were done by humans, can now be done by software.Their users are already using AI to do the work that they are supposed to do. i think that's finereplythrow47474777j 16 hours ago | parent | prev | next [\u2013]Why wouldn't people just use existing software markets?replymg 16 hours ago | root | parent | next [\u2013]For example?replythrow47474777j 16 hours ago | root | parent | next [\u2013]App Stores, the web, etc. How else does software as a service get sold? It\u2019s not a new thing. Probably a lot of these things will just end up as features in existing systems.replymg 16 hours ago | root | parent | next [\u2013]Existing appstores like the ones on iOS and Android mostly target casual use cases, mobile devices and on-device software. Not \"buy once\" experiences for work via software as a service. They also do not offer a unified experience. Two \"text-to-speach\" apps could have completely different user interfaces.The web does not have good discovery and reputation management and also does not provide a unified interface. That is why market places like Booking.com, Amazon, Spotify etc have become so big.replyup2isomorphism 4 hours ago | prev | next [\u2013]No, I am not interested play a game generated this way because the exact reason I want to listen to NPC conversations is because they are written by human.replysquarefoot 10 hours ago | prev | next [\u2013]Impressive, although the first example fails at the very last second when the virtual guy's voice glides up while saying \"what?\" and the autotune-ish pitch correction effect is clearly audible. Other examples are nothing short of incredible. If it really can output minutes of credible voice just by training it with a few seconds, next step will be to make it sing. I foresee a legal storm approaching when someone will use a similar technology to put for example Elvis' voice -without naming him- in some advertising, so that fans would recognize him but the audio wouldn't match neither any of his lyrics nor any existing songs by him.replylinhns 6 hours ago | parent | next [\u2013]I don't believe the first example is created by Soundstorm. It sounds coercive and modulated to me.replymgaunard 2 hours ago | prev | next [\u2013]Why would you choose to synthesize audio using such awful valley girl accents?replyvarunpant 4 hours ago | prev | next [\u2013]https://github.com/lucidrains/soundstorm-pytorchreplywillemmerson 11 hours ago | prev | next [\u2013]I don't have anything intelligent to say about this but it's ALOT of fun making all the samples play at the same time - sort of like the HTML version of Ableton Live.replyglobular-toast 53 minutes ago | prev | next [\u2013]That name is a blast from the past. Anyone remember Nvidia SoundStorm?replynwoli 13 hours ago | prev | next [\u2013]Seems like we wouldn\u2019t be far at all from just correlating this to face movement (including subtle iris movement and blinks, not just the mouth). As long as you clearly label it as CGI it\u2019s harmless and I\u2019m excited for the day to come. Might be quite fun to chat with a little buddy this wayreplytagyro 14 hours ago | prev | next [\u2013]I've wasted (counting) about 300 seconds of my life listening to these audio files and they all sound and seem fake...replyjeffbee 13 hours ago | parent | next [\u2013]Did you read the paper? They intentionally steered the quality to ensure they sound fake. Their generated speech is \"very easy to detect\" according to the reference at the end of the paper.replysvantana 14 hours ago | parent | prev | next [\u2013]I found that in my (high quality) studio monitors, the audio sounded fine and hard to distinguish from 24kHz wav. But in headphones, the artifacts were pretty obvious. So probably some reverberation will do a lot to cover up artifacts. In the paper, they only do a subjective comparison between the generated audio and the soundstream-encoded original audio, which seems a bit disingenuous. Listening to soundstream audio in headphones, I can hear those same artifacts.replytagyro 14 hours ago | parent | prev | next [\u2013]just to be clear, one could mistake them for some (voice) actor reading a book (maybe) but even to my untrained ear they sound fake and artificial.Am i missing something?replykvn8888 12 hours ago | root | parent | next [\u2013]It's meant to sound artificial. The focus is on speed and consistencyreplyelAhmo 13 hours ago | prev | next [\u2013]This is nothing short of amazing. It is exciting, a bit scary as well, what the future will bring.It just makes me sad that I cannot open this page on Safari. It will not play a single audio, yet Chrome plays it fine. So here we are, able to generate audio, video, code, do amazing things with AI, but a simple website that has text and audio is not working on the most popular laptop out there.replylern_too_spel 9 hours ago | parent | next [\u2013]If you want to use the modern multimedia web, you can't use Lynx or Safari.replyelAhmo 3 hours ago | root | parent | next [\u2013]They are not comparable.I understand that some applications might prefer \"other browsers\", but a simple page that plays audio snippets was really a disappointment.replybozhark 9 hours ago | prev | next [\u2013]Close. Too flat of a sound overall.replyanigbrowl 14 hours ago | prev [\u2013]Good for fraudsters and spammers, bad for anyone who ever hoped to make a living from voice acting. I'm perplexed by AI technologists' seemingly incessant drive to automate away the existence of artistic performers.replywg0 13 hours ago | parent | next [\u2013]LLMs aren't great and can't be relied upon in business setting or at least I would not.But think open world games. GTA VII for example where all NPCs have their dialogs auto generated in real time but also converted to audio in real time.That's going to be a world which would be a lot more spontaneous with lot less effort.Right now, If memory serves me right, GTA V dialogs alone are 5000 pages or more, hand written.replyanigbrowl 13 hours ago | root | parent | next [\u2013]That's all true, but I think it's a pity that the jobs that currently exist for voice artists will disappear. Gamers and consumers will have somewhat better interactive experiences, which is good. Indie game developers will also be able to put out games with lower budgets, which is nice for them. But the market for voice acting work is largely going to dry up and blow away for people who are not already at the top of that field. People who could previously have made a modest but sufficient living as voice performers will be replaced by computer-generated voices. It will be almost impossible to make a living in that field within 5 years.replywg0 12 hours ago | root | parent | next [\u2013]Generative models around images are nothing new and have been around for a while already. But even today, if you really want creative control and expression, you need a designer that's good with Photoshop or Illustrator etc.This is applicable to LLMs as well. You can get it to write plausible BS but if you really want a rooted in reality, well articulated write up about something, a human has to be taken onboard.This equally extends to voice over. If you really want expressive and creative control to put some outstanding rendering of something, AI isn't going to cut it.replyanigbrowl 12 hours ago | root | parent | next [\u2013]This is only true if you assume AI isn't going to keep improving. It gets significantly better on a quarterly basis, far faster than the time it takes for an actor to develop their craft and career. The output quality of todays' cutting edge models would have been science fiction only 2-3 years ago.replywg0 11 hours ago | root | parent | next [\u2013]I'm not so sure about the future. Such models, all the models don't have a well understood input output mapping and that's going to be a problem for a very long time.replybrucethemoose2 5 hours ago | root | parent | prev | next [\u2013]With some select exceptions, the quality of AAA storytelling has detiorated.I welcome any tech that makes indies more competitive.replyLegend2440 14 hours ago | parent | prev | next [\u2013]You are being deliberately pessimistic. There are a million fantastic, practical uses for text-to-speech.replyanigbrowl 13 hours ago | root | parent | next [\u2013]I am not. The use cases like interactive assistants for the blind will generate very little commercial activity compared to the uses (and abuses) for entertainment and marketing purposes. A good example of this from the real world is the absence of cheap/open ASL interpretation for deaf people.replysignatoremo 13 hours ago | root | parent | next [\u2013]Ever notice big huge font on the phone of older people? So big that a screen may only contain a few lines of text. Or that people has to pull out their reading glasses every time they check their phone? Text to speech is a godsend in that case. Enormous benefits to an increasingly older population.replyanigbrowl 13 hours ago | root | parent | next [\u2013]'helping blind people' was literally the first use case I mentioned. Maybe you should have read the comment before reacting to it.replysignatoremo 12 hours ago | root | parent | next [\u2013]Huh? How big is the blind group compared to the older population?You are saying it\u2019s not economical to use tech to speech to support blind people. I\u2019m saying the benefits are huge for older population. It isn\u2019t just for fraudsters or spammers as you claim.replyanigbrowl 12 hours ago | root | parent | next [\u2013]No, I'm not saying that at all. I'm saying the resources invested in helping people will be dwarfed by those invested in crap designed to exploit them economically or criminally.replysignatoremo 11 hours ago | root | parent | next [\u2013]Set asides the fact that you have absolutely no proof of that claim, the criminal world is tiny compared to the people who benefit from TTS (God forbid if that isn\u2019t the case). Encryption, as an example, is hugely beneficial to the regular people despite being used or exploited extensively in the shady and questionable activities.replyLegend2440 13 hours ago | root | parent | prev | next [\u2013]Imagine having an app on your phone that turns any ebook into an audiobook.Imagine replacing crappy phone menus with polite virtual assistants that actually understand what you're saying.Imagine an AI language tutor that speaks every language in the world fluently. Or a universal speech-to-speech translator.And that's just off the top of my head. Clever people will come up with a lot more uses, I'm sure.replyanigbrowl 13 hours ago | root | parent | next [\u2013]I don't need your help imagining use cases; I've been in this field a lot longer than you, and have talked up the technological possibilities of AI-powered TTS here for *years. I understand the technology very well and am bullish on it. What I'm saying is that too much of the effort is being spent in solving the wrong problems. Please try reading what I wrote instead of your imaginary subtext.replycroes 14 hours ago | parent | prev [\u2013]Why spare artists if everyone else gets replaced by technology?replyanigbrowl 14 hours ago | root | parent [\u2013]They don't, otherwise there would be many former CEOs living in tents. In reality, those who control large amounts of capital are quite willing (and increasingly, say so in the open) to to deprive others of their livelihoods, homes, and ability to feed themselves in order to realize a marginal increase in their own wealth.replybrucethemoose2 6 hours ago | root | parent [\u2013]The function of CEOs and board members are closer to being replaced than, say, roofers or garbage workers.It will be interesting to see what happens when that pressure is applied...replyGuidelines | FAQ | Lists | API | Security | Legal | Apply to YC | ContactSearch:",
    "hn_summary": "- The development of SoundStorm, a parallel audio generation system, has reached a significant milestone in creating synthetic dialogue that sounds indistinguishable from human speech.\n- In the past, the quality of text-to-speech (TTS) systems was poor, but recent advancements in AI have led to the creation of more realistic voices.\n- While the technology has potential applications in various fields such as gaming and accessibility, there are concerns about its impact on the job market, particularly for voice actors."
  },
  {
    "id": 36748043,
    "timestamp": 1689521070,
    "title": "Forth: The programming language that writes itself: The Web Page",
    "url": "http://ratfactor.com/forth/the_programming_language_that_writes_itself.html",
    "hn_url": "http://news.ycombinator.com/item?id=36748043",
    "content": "- The post discusses the journey of Charles H. Moore in discovering and developing the programming language Forth.\n- Usenet newsgroups in the 1990s provided a platform for programmers to discuss programming languages like Forth.\n- Forth is a flexible programming language created by Chuck Moore that allows you to change the values of integers easily.\n- Forth uses Reverse Polish Notation (RPN) syntax, which puts operators after the operands instead of between them.\n- Forth is stack-based, meaning it uses a data stack for storing and manipulating values.\n- Combinatory programming is a concept related to Forth that involves composing functions simply by putting them in sequence.\n- Combinators are higher-order functions that take other functions as input and produce a new function as output.\n- Forth supports higher-order functions with \"execution tokens\" and the EXECUTE word, allowing for the creation of combinatorial words.\n- Forth was developed to address the need for an interactive and flexible programming language, allowing for on-the-fly modifications and reducing the need for recompiling.\n- Chuck Moore had a critical view of complex programming languages and the standardization of Forth, believing that innovation was hindered by standardization.\n- Forth was used in various computing environments, including astronomical observatories, and was ported to different computer systems like IBM 360/50 and Honeywell 316.\n- Charles H. Moore's work with Forth contributed to the advancement of interactive computing and on-line data reduction in the field of astronomy.- Forth is a programming language that was created incrementally to serve the needs of its creator, Chuck Moore.\n- One of the unique features of Forth is its postfix notation, which makes it easy to implement and allows for a minimalistic interpreter.\n- Forth is stack-oriented, meaning it uses a stack to store and retrieve values, which makes it compact and flexible.\n- Forth is interpreted, allowing for interactive development and fast changes on the fly.\n- Forth is self-hosting, meaning it can be bootstrapped from a handful of words implemented in assembly and then write the rest in Forth.\n- Forth is extremely compact and efficient, which was a crucial advantage in its early days when computers had limited memory.\n- Forth can run on various architectures and is highly adaptable to different machine architectures.\n- The Forth system is based on threaded code, which stores a list of addresses to execute subroutines.\n- The simplicity and extensibility of Forth make it an excellent tool for learning and experimentation.\n- Forth's flexibility allows programmers to define their own words and extend the language as needed.\n- Understanding Forth requires implementing or porting it from scratch, which provides valuable insights into its inner workings.\n- Forth's simplicity of syntax and powerful dictionary make it an ideal candidate for creating new programming languages or tools.- Open Firmware is an interactive programming language used to efficiently test and bring up new hardware\n- Open Firmware was used in notable space exploration missions, such as the Space Shuttle ESN\n- The Jupiter Ace, a British home computer from the 1980s, used Forth as its default programming language\n- Forth is a complete computing system that uses no operating system and stores code as source code in disk blocks\n- Chuck Moore, the inventor of Forth, has designed his own processors, such as the Novix N4000 and the GreenArrays GA144 chips\n- Forth is known for its simplicity and machine-sympathetic design, making it suitable for low-energy computing\n- Forth has applications in embedded systems, microcontrollers, and parallel computing",
    "summary": "- Forth is a flexible programming language created by Chuck Moore that allows for easy modification of values and uses a stack-based approach for manipulating data.\n- Forth's syntax, known as Reverse Polish Notation (RPN), is unique and places operators after operands.\n- Forth is used in various computing environments, from astronomical observatories to embedded systems and parallel computing.",
    "hn_title": "Forth: The programming language that writes itself: The Web Page",
    "original_title": "Forth: The programming language that writes itself: The Web Page",
    "score": 250,
    "hn_content": "Hacker News new | past | comments | ask | show | jobs | submit loginForth: The programming language that writes itself: The Web Page (ratfactor.com)250 points by ingve 18 hours ago | hide | past | favorite | 77 commentsttsiodras 14 hours ago | next [\u2013]As soon as I met Forth, I felt I had to hack my own (https://github.com/ttsiodras/MiniForth/) - and did so over a single week, two years ago. I targeted the Blue Pill and the original Arduino, but developed via cross-compilers so that I could test my code in the host.I became so obsessed with the project that I was looking forward to tinkering with it after coming back from work every day; so it was hacked in 5 evenings and a weekend. It was that much fun, to build a Forth.I highly recommend the process; I think the only other time I felt so enlightened was when I first met Lisp macros (https://www.thanassis.space/score4.html#lisp).replylolinder 14 hours ago | parent | next [\u2013]> I became so obsessed with the project that I was looking forward to tinkering with it after coming back from work every day; so it was hacked in 5 evenings and a weekend. It was that much fun, to build a Forth.Yep. In my computer architecture class as a freshman, we were supposed to do a final project of our choosing for the LC-3 (a RISC instruction set with emulator). I had dabbled briefly in Forth (with the RedPower 2 Minecraft mod) and thought it'd be fun to implement one. It ate up essentially all of my free time that semester: There was one morning where I only realized I'd stayed up all night when the sun started to come up and I finally checked the clock.I've never found a practical use for Forth in my \"real\" life, but building one from scratch was an experience almost best described in religious terms. It was a pure distillation of Fred Brooks's description of programming:> The programmer, like the poet, works only slightly removed from pure thought-stuff. He builds his castles in the air, from air, creating by exertion of the imagination. Few media of creation are so flexible, so easy to polish and rework, so readily capable of realizing grand conceptual structures.> Yet the program construct, unlike the poet's words, is real in the sense that in moves and works, producing visible outputs seperate from the construct itself. It prints results, draws pictures, produces sounds, moves arms. The magic of myth and legend has come true in our time. One types the correct incantation on the keyboard, and a display screen comes to life, showing things that never were nor could be.replyadastra22 11 hours ago | root | parent | next [\u2013]In terms of practical usage, FYI both bitcoin script and postscript (for printers) are Forth based, as are some aerospace chips.replywhartung 7 hours ago | root | parent | next [\u2013]It\u2019s arguable how much, if any, Forth is in PostScript. It is, indeed, a stack based language, but that\u2019s pretty much where the similarities end.There\u2019s more to what makes a Forth a Forth than a parameter stack.More discussion at https://wiki.c2.com/?ForthPostscriptRelationshipreplyandromaton 7 hours ago | parent | prev | next [\u2013]Fully agree. About 40,000 eons ago I wrote a Forth compiler in ZX81 basic. It went from taking 19 seconds to print 1000 numbers on the screen to instantly. I also learned a great lesson: I looked at the machine code it generated (it had a pinhole optimizer because the output was PUSH HL, PUSH DE, POP DE, POP HL everywhere), and I thought it was perfection - impossible to improve. The day later I came back and made it much faster.replysubmeta 13 hours ago | prev | next [\u2013]If you wonder: How does it write itself? Isn\u2019t it just the ability to write functions?In a way, yes, but it's a bit more than that. Many programming languages allow you to define functions or methods, but Forth takes this concept further by allowing you to define new \"words\" that can become part of the language itself. These words can be used just like built-in operations, and they can even change the way the language behaves.Also, because Forth is an extensible language, you can create words that define new control structures or modify the language's syntax. This is a level of flexibility that's not commonly found in other languages. In this sense, Forth can be seen as a language that \"writes itself\" because it allows programmers to customize and extend the language in a very fundamental way.The ability to extend Forth by defining new words is somewhat similar to the macro system in Lisp. Both provide a way to extend the language and customize it to suit your needs.In Lisp, macros allow you to define new syntactic constructs in the language. They work by transforming your program at compile-time, essentially letting you create your own domain-specific language within Lisp. This is a powerful feature that makes Lisp highly flexible and adaptable.Similarly, in Forth, you can define new words that become part of the language and can be used just like built-in words. This allows you to extend the language's syntax and functionality, making Forth highly extensible and customizable.replyAnimalMuppet 10 hours ago | parent | next [\u2013]Neat, I suppose, but... In nearly 40 years as a professional programmer, the problem has never been the syntax. It's always the semantics. (I mean, yes, if you're doing something like matrix multiplication it's nicer to be able to say A = B + C * D; rather than having to explicitly spell out which functions you're calling. I have never actually hit that situation, though.)Do I just lack imagination?Is this domain-specific, and I've just never been in the domain where it was useful?Is Forth so crippled in syntax that you need to be able to extend it to make it something more useful?Do people just want to be able to customize their language, the way some people do their cars?Why do people really care about this?replyt-3 8 hours ago | root | parent | next [\u2013]A lot of the focus on simplicity is about ease of implementation. A compiler/interpreter for a language without syntax (Forth) is much faster/easier/simpler to write than one with syntax. Originally Forth was an OS as much as a programming language, and the strength of the concatenative paradigm for command languages can be seen in the enduring popularity of pipes in *nix shell. The syntax is not considered a problem because it will be invented as you go along and write the words that implement your application.replywhartung 7 hours ago | root | parent | prev | next [\u2013]Because most semantics manifest through syntax. Syntax is how the programmer communicates their intent and gets access to the semantics of the underlying system.A contrived case is the construction and use of lists built of CONS cells in lisp style languages. You can certainly do this in most any language, but creating CONS cells readily without something like an S-expression would be tedious and awkward indeed, to the point that folks would drift to something else more naturally represented in their language than something based on CONS cells.replysyntheweave 6 hours ago | root | parent | prev | next [\u2013]What makes computer languages odd is in having syntax persistently be \"born\" in tandem with a desire for a certain semantics, and the two being hard to separate upon close inspection. You have to know the domain and have the experience to see when and where it occurs, but a need for additional syntax always appears beyond a certain point.The reason why this is the case is because the computer's ultimate use lies in automation of some task: to automate you have to define the problem domain, and to define the problem domain you have to configure something, and as you expand the amount of configuration taking place from a single-use app like your usual batch-processing shell script towards a more bespoken front-end for a certain kind of task, you end up with valid and invalid ways of configuration. If you define an input mechanism that automates a configuration with \"good defaults and helpful rules\", you haven't concretely changed the underlying semantics - and this sort of thing is in the realm of what a linter does - but you have changed the syntax by which the problem is approached, and pushed the train of thought onto a certain rail.And most of the time we ultimately aim to shove that concern into a graphical front-end, a form of syntax that is easy to browse through and discover your configuration options with, and enables some unique semantics with data visualization and inputs. But it's a layered process with multiple entry points - sometimes you change a configuration not by clicking around, but by editing a text file, and sometimes you change it by writing a different program. You also rely on having an operating system, files, sockets, etc. The concepts are made within an ecosystem of software and dependencies are assumed. And this is a predictable outcome of Algol.In Algol-derived languages you have one, general-purpose syntax(and maybe an extra one, like the C preprocessor), and it does a bunch of things that are hard to enforce just with programmer discipline, so it gives you your structured loops and function calls and class methods and such. And you get access to libraries and those all expose the same kind of syntax with new vocabulary.But then when you have to extend an Algol, you often end up in a place where you have enough configuration taking place to want it to be parsed in some degree. Maybe you decide you will generate code during the build process, or you have a little interpreter that enforces business rules, or something of that sort. You access it by calling a function, but that doesn't describe how you talk to it. You've started using a different protocol, all of the sudden, and your language tools correspondingly change. The boundaries are pretty hard.And the way in which both Lisps and Forths differ from the Algol approach is in making it really easy to grab the metaprogramming you want, when you need it, so if you need a little compiler for a thing, the barrier to it is a modest \"set a toggle so the logic occurs when compiling this other function, instead of at runtime\". This is a thing that newer Algol-likes have chipped away at, but in general the priority is \"common things are easy, hard things are possible\", vs \"you have the expressive power to design ideal solutions\".Forth's approach is more low-level than Lisp in that what it gives you to start with is almost nothing except the raw tools to define that syntax in a dictionary, enter the compilation mode, access memory and manipulate some bits. No safety or anything - you build that yourself when and where you want it. It's a useful \"bring-up\" language for new hardware because it's very permissive in that sense: you have a REPL available from the get-go and it can let you start banging bits. But it lacks the kind of standardization and collaboration that would result in an ecosystem like a C or Java, and that's also by definition: Forth has the expressive power to monopolize the entire path between the final application and the hardware, and if you aim to make it exist in a standardized context like a \"web app\" or a \"Windows app\", it suddenly does little of interest - that means you are defining the problem in web terms or Windows terms, and not as a mapping of hardware to solution.It's a very isolated way of working on software, and a \"software company\" is nearly allergic to it, since the human factors dictate that the software should be collaborative and often hegemonic.replymikewarot 5 hours ago | prev | next [\u2013]Long ago, when OS/2 came out, a friend relayed to me that \"You can't write programs in assembler for OS/2, they have to be written in C\".In defiance of that statement, I built Forth/2.[1] It was a direct threaded, native code Forth Compiler for OS/2 written in assembler. Brian Matthewson wrote an amazing manual for it, and it found a few dozen users.[1] https://sourceforge.net/projects/forth2/replyalexwennerberg 15 hours ago | prev | next [\u2013]One of the most interesting Forth projects to me currently is Dusk OS, a 32-bit operating system written in Forth that includes its own C compiler, with various porting efforts under wayhttps://duskos.org/replywhartung 7 hours ago | parent | next [\u2013]I cannot speak to DuskOS, I don\u2019t know anything about it.While historically Forth has been \u201cits own OS\u201d, it\u2019s a kind of crummy one. Especially for anything a modern reader might think of when they think of an OS.I mean, for sure, what do you want from something that can run in 8K of RAM. But while it offers primitives, historically it doesn\u2019t of any concept of things like drivers or most any other abstractions. Code is loaded from source code (which is slow). Linking is just loading blocks in the right order. Loading a new program you must first remove the current one.Arguably not much better than CP/M, which routinely cold started the machine to exit a program, but at least it separated the BIOS from the BDOS.replyeggy 15 hours ago | parent | prev | next [\u2013]I missed this one. Thanks for the link. I was just reading \"Beyond the Collapse\" and my Lisp and APL/J and C skills would not allow me to approach Forth's simplicity at the OS level. I'll definitely check this out by next weekend.replyLargoLasskhyfv 15 hours ago | parent | prev | next [\u2013]That is indeed interesting. THX for making me aware of it.replybenhoyt 12 hours ago | prev | next [\u2013]My first programming languages were x86 assembly and Forth. My Dad was into Forth, and I learned programming from him. I wrote several x86 Forth systems for DOS as a teenager, culminating in a somewhat-polished ANS compatible one I called \"Third\": https://github.com/benhoyt/third -- it's kind of amazing being able to have a fully bootstrapped Forth compiler (including an assembler) in a couple thousand lines of code.Just the other day I transcribed an old article I had co-written for the Forth Dimensions magazine. I still like the ideas in Forth, but the stack manipulation quickly gets tedious and is very hard to read. Just look at the code examples in https://benhoyt.com/writings/forth-lookup-tables/ -- especially Search-Table. Yikes! Yes, naming things is hard, but apparently not naming them is even harder.reply5- 11 hours ago | parent | next [\u2013]> but the stack manipulation quickly gets tediousit might just be that you (and i) are not chuck moore. his code generally has very little stack shuffling. e.g.http://www.merlintec.com/download/color.htmlreplyanta40 2 hours ago | parent | prev | next [\u2013]I just take a look at third's source code. Looks interesting. When bootstrapping, kernel.com is called.OK, how did you build kernel.com?replybenhoyt 1 hour ago | root | parent | next [\u2013]I'm pretty sure I wrote the first version of kernel.com in assembler.Update: actually, more likely it was built using the meta compiler running on top of one of my previous Forths (I wrote a few). It's been too long to remember exact details, and I didn't use revision control back then. :-)replythrowaway7868 10 hours ago | parent | prev | next [\u2013]> a somewhat-polished ANS compatible one I called \"Third\"Or should Forth++ == Sixthreplythesuperbigfrog 17 hours ago | prev | next [\u2013]Related Chuck Moore talk: \"Programming a 144 Computer Chip to Minimize Power\" (2013)https://www.youtube.com/watch?v=0PclgBd6_ZsHow Forth powers ultra-low power computers:\"GreenArrays is shipping its 144-core asynchronous chip that needs little energy (7 pJ/inst). Idle cores use no power (100 nW). Active ones (4 mW) run fast (666 Mips), then wait for communication (idle).\"replykmstout 7 hours ago | parent | next [\u2013]\"I always considered that size and speed were important for amateurs. But in the modern context, there's only three parameters that matter: power, power, and power.\"--Chuck Moorehttps://youtu.be/0PclgBd6_Zs?t=389replyagumonkey 17 hours ago | parent | prev | next [\u2013]I genuinely wonder if this topology won't make a come back in the coming years.replymananaysiempre 15 hours ago | root | parent | next [\u2013]To me GA144 looks less like a state-of-the-art CPU or DSP replacement and more like an FPGA replacement\u2014and that would actually be lovely to see, given how inefficient and expensive FPGAs are nowadays compared to doing the same thing with a custom chip (if you only overlook the design cost for the latter). The \u201ccomputer\u201d marketing makes little sense to me.Unfortunately, GA don\u2019t seem to have gotten the memo about cheap entry-level dev tools that the microcontroller world has been circulating since 2010 or so. At the prices they charge for their devboards, you wouldn\u2019t really get one just to play with, even if the chips themselves are actually somewhat cheap compared to getting the same amount of compute on an FPGA.(It\u2019s $500 per devboard and $20 per chip, with each chip capable of 2e9 16-bit multiplies/sec. Somebody[1] is selling a breakout board with only the chip for a much more reasonable price of $35, but you\u2019ll need to figure out how to wire up the thing yourself.)Charles Moore is known for aggressively patenting his hardware, though. (Well, he and every other modern chip designer.) So we might not get to see anybody else do this stuff for a long, long time. Adapteva\u2019s Epiphany/Parallella design used a broadly similar idea with an explicit grid interconnect and also aimed for a piece of the FPGA/ASIC pie, but they had much beefier, synchronous cores with separate message routers attached to them.[1] https://schmartboard.com/schmartboard-ez-qfn-88-pins-0-4mm-p...replyoptimalsolver 17 hours ago | prev | next [\u2013]A great introduction is the book Starting Forth [0].It has the most charming illustrations I've ever seen in a text book.[0] https://www.forth.com/starting-forth/replyvanderZwan 16 hours ago | parent | next [\u2013]There is also Thinking Forth, which is a kind of sequel[0] https://www.dnd.utwente.nl/~tim/colorforth/Leo-Brodie/thinki...replyJtsummers 15 hours ago | root | parent | next [\u2013]https://thinking-forth.sourceforge.net/ <- A better source. The one you linked includes a number of typographical errors early on (OCR errors?) that were grating for me to try and read. None of the errors I noticed in your link were present in the copies I checked out here.replyvanderZwan 14 hours ago | root | parent | next [\u2013]Thank you for the correction, sadly my post can't be edited any morereplyvanderZwan 15 hours ago | prev | next [\u2013]Tangent: I remember reading this in its original presentation-prototype form, which is basically this article with much less text and more plotholes. The reason I'm mentioning it is because it's also a beauty of minimalism in terms of underlying website technology.[0] http://ratfactor.com/forth/forth_talk_2023.html[1] http://ratfactor.com/minslides/replyrwmj 14 hours ago | parent | next [\u2013]Is there something about writing your own FORTH and writing your own simplified presentation software :-? https://www.mankier.com/1/techtalk-psereplyspaintech 12 hours ago | prev | next [\u2013]It's interesting to note that even in Rust, there exists a Forth compiler, as depicted in these resources [1]. Its usage remains somewhat unclear to me [2], but its existence has been previously discussed here [3]. It boasts a robust implementation and, while it isn't a REPL Forth VM, it stands as an impressive VM implementation.I've been contemplating - given that FORTH is a VM - if there's a need for a compact and efficient system capable of managing streaming data, it could be the optimal choice for exceptional performance, close to the bare metal. There's no need to contend with the operating system. Isn't this essentially what FPGA\u2019s do, but on standard CPUs? I envision it as a specialized system, minus the requirement to create every driver for all the hardware you'd need to interface with.[1] https://docs.rs/rust-forth-compiler/latest/src/rust_forth_co...[2] https://docs.rs/fortraith/latest/fortraith/[3] https://news.ycombinator.com/item?id=23501474replymighmi 17 hours ago | prev | next [\u2013]Ah, what beautiful paradigms there are which we toil away without. Retro (a modern Forth) looks very interesting. The textbook Thinking Forth is near SICP in terms of opening your mind to a new paradigm.Is anyone using Forth in production these days with stories to tell?replyeggy 15 hours ago | parent | next [\u2013]I only wrote some file munging and reporting programs in Factor, a batteries-included Forth. Nobody would need these tools, so I was free to make and use for myself. They had people scraping HTML and Excel reports to do their reporting before. I exported my results to HTML and Excel. Sneaky fun for myself!replyGordonjcp 16 hours ago | parent | prev | next [\u2013]Probably not. It turns out that it doesn't map to modern computer processors terribly well.It's an amazing and elegant language, but anything that does register-to-register operations is always going to be faster than register-to-memory.replyslavapestov 16 hours ago | root | parent | next [\u2013]Stack code can be mapped to register code trivially if you impose some restrictions (each word has a static effect and both branches of a conditional have the same effect). Then lowering to SSA form performs an \u201cabstract interpretation\u201d where evaluating a word pops SSA values from a \u201cabstract stack\u201d, creates an SSA node and pushes its output values on the stack.replyvanderZwan 16 hours ago | root | parent | next [\u2013]I wouldn't say that sounds trivial exactl...> slavapestov... ok, fair enough: it probably is trivial for you, lol.(For the uninitiated: Slava Pestov created Factor, a modern concatenatvie language which (IIRC) did a lot of innovative stuff regarding optimizations in that domain)[0] https://factorcode.org/slava/replycarapace 14 hours ago | root | parent | next [\u2013]Ha!Whenever I work on compiling Joy code I have to fight the urge to just write Joy-in-Factor and lean on all that crunchy goodness.(I wrote Joypy (mentioned in TFA), now Thun (someone took Joypy on PyPI so I renamed it) which includes interpreters in C, Nim, OCaml, and Prolog. I made a few feints at compiling Joy so far, but it's just kid's play compared to Factor. \"I am but an egg.\")replyastrobe_ 12 hours ago | root | parent | prev | next [\u2013]There's a bunch a vendors still alive, mainly the historic Forth, Inc. and MPE. Both publish complete systems and native compilers that apparently perform well enough. If raw execution speed was all that matters, I can name a bunch of popular programming languages that wouldn't have survived long enough to be saved by JIT, or to become to big to fail (that is, their ecosystem).replyjacquesm 15 hours ago | root | parent | prev | next [\u2013]> Probably not.Probably yes.replyGordonjcp 12 hours ago | root | parent | next [\u2013]In which case, I'm sure you can give some examples.replyjacquesm 11 hours ago | root | parent | next [\u2013]Is Google down again? Bummer.FORTH is still used to bring up new silicon because of its tiny core, you only need a couple of working assembly instructions to bootstrap yourself into a working system, you could do this entirely in cache or a small static RAM if you don't have a working memory controller yet.It is also used all over the place in embedded controllers, https://arduino-forth.com/ , http://www.piclist.com/techref/microchip/language/forths.htm , https://github.com/nimblemachines/muforth , from PICs to ARMs and everything in between.You won't see a lot of hype around it and repos tend to be old because they 'just work', typically a user of such a system would download it and customize it to the point that sharing it would be pointless, the whole idea is to extend the language to become the application.replyGordonjcp 2 hours ago | root | parent | next [\u2013]Did you forget what the OP asked? Is anyone using Forth in production?I very much doubt it.replyjacquesm 53 minutes ago | root | parent | next [\u2013]You are probably using it yourself, right now. You just don't realize it because embedded stuff isn't sexy, won't make it to the blogosphere and just sits there doing it's job, year after year. Every vehicle, every boot of a larger machine probably uses FORTH at some stage.Not everything is web based and not everybody is part of the hype cycle.Since you're asking 'anyone' one example should be enough to satisfy you with proof: every IBM Power series system has Open Firmware on it which you can boot into: https://www.ibm.com/docs/en/power9/0009-ESS?topic=asmi-power... . Note that that doesn't even mention Forth by name.Also note that the world is a lot larger than just the English speaking part of it, and that bringing up new systems is usually transitory: as soon as you can bootstrap yourself out of a FORTH environment you do so because it is a bit limiting.Finally, as long as https://en.wikipedia.org/wiki/Chandra_X-ray_Observatory Chandra is still online at least someone is using FORTH in production.It's just one of many space missions where FORTH plays a role.replysnitty 16 hours ago | prev | next [\u2013]I learned Forth when it was the only language that had an interpreter than ran on PalmOS. So you could write and execute it on your PalmPilot while you were bored in class in the 90s.replyFullyFunctional 6 hours ago | parent | next [\u2013]OT: There was at least also LispMe. I used it extensively and wrote a medium large app in it.replykristianpaul 9 hours ago | prev | next [\u2013]And there is a cpu as well https://excamera.com/files/j1.pdfreplyloscoala 15 hours ago | prev | next [\u2013]I have implemented yet another forth by myself. It works a little bit different and it is not intended to be a true copy of the original idea.Since the post says you can discover Forth, here's my part:https://github.com/loscoala/goforthThe main difference is that in this Forth variant, the source text is completely translated into bytecode and there is no runtime in the sense of classic Forth. This makes it easy to translate the bytecode to C.I use my own Forth to generate C code with it, which I then embed in other software.replyjacquesm 15 hours ago | parent | next [\u2013]That can be very productive and clever, but be - and stay - aware that such polyglot solutions tend to be maintenance headaches in the longer run.There is a really nice open source project out there that allows you to train your hearing and your sightreading, but it's written in the authors own language which in turn compiles to JavaScript and the headache to set up their toolchain is such that I haven't bothered fixing any of the bugs that I'm aware of (and there are plenty).https://sightreading.training/https://github.com/leafo/sightreading.trainingIt's written in a language called 'Moonscript':https://github.com/leafo/moonscriptWhich compiles to Lua. Which compiles to JS.Madness. Nice madness, but still, it stopped me from being a contributor.replynmz 11 hours ago | root | parent | next [\u2013]It's a little strange to talk about moonscript as something obscure, luarocks the main package manager for lua is written in it, not to mention itch.io. It's a proven language that's at least easier to learn than lua. (well, its at least more programmer friendly)replyjacquesm 11 hours ago | root | parent | next [\u2013]Sorry, but it just doesn't cross my threshold for 'mainstream', whereas Lua does at least get within striking distance.replyweinzierl 13 hours ago | prev | next [\u2013]Open Firware uses Forth. It's sad, that it didn't win over UEFI.I also think to remember that it was used in movie productions to control movement and other parameters of props.replyZuider 4 hours ago | parent | next [\u2013]Forth was created to control the aiming of a radio telescope. It was used in the original Star Wars movie to direct the complex motions of the model space ships.replymassifist 11 hours ago | prev | next [\u2013]I remember hearing about a computer called the Jupiter Ace that used Forth. I think it was similar to the ZX Spectrum.replysedatk 3 hours ago | parent | next [\u2013]The article mentions that.replyFullyFunctional 6 hours ago | parent | prev | next [\u2013]it was similar to the ZX81 (monochrome and character only). Spectrum added higher resolution graphics and a highly constrained color option.replybehnamoh 15 hours ago | prev | next [\u2013]Why did some ancient programming languages emphasize on CAPITAL LETTERS? Was there no \"Shift\" button on keyboards back then?replypmcjones 15 hours ago | parent | next [\u2013]Lower-case was not common on printers and terminals in the 1950s and 1960s (and into the 1970s).replythemadturk 9 hours ago | parent | prev | next [\u2013]The Apple II computers, for example, had only upper-case characters in ROM (and screens were 40 characters wide). Lower -case characters would have required a second ROM, which obviously increased costs. Eventually models with lower-case capabilities were added, as was 80-column output.replydsand 5 hours ago | parent | prev | next [\u2013]Ancient languages ran on ancient machines with 6-bit character sets. No available way to key in or print lowercase letters.replySindisil 15 hours ago | parent | prev | next [\u2013]No, in some cases there were not. In addition, capitals served as a method of differentiation for language keywords and such.replyriidom 12 hours ago | root | parent | next [\u2013]Maybe worth to add that syntax highlighting was not a thing back then.replyagumonkey 17 hours ago | prev | next [\u2013]anecdata (and warning some people might not like that domain brought here), there's a mini vm in bitcoin that a subset of forthhttps://en.bitcoin.it/wiki/ScriptI just learned that this weekreplycornholio 16 hours ago | parent | next [\u2013]It's a stack machine, but calling it a subset of Forth is maybe an exaggeration if you can't (afaik) define new words.replyagumonkey 15 hours ago | root | parent | next [\u2013]fair point, they say \"forth like\", I pushed it too farreplyjacquesm 15 hours ago | parent | prev | next [\u2013]By that rule the JVM is a 'subset of FORTH'.replyagumonkey 14 hours ago | root | parent | next [\u2013]yeah apologies, I can't edit my comment now or I wouldreplyjacquesm 12 hours ago | root | parent | next [\u2013]I got the gist of it though, and I think you do have a point: FORTH showed the power of stack machines (and the HP calculators of course did too) in a way that not much else did and I'm pretty sure that the ease with which you can bring one up to bootstrap a new environment is part of the reason why they were (and still are) more popular than many people realize for embedded stuff and first silicon of new and experimental CPUs. You can bootstrap to an interactive system in an afternoon in FORTH and some of the JVM instructions are definitely reminiscent of FORTH.So it isn't all that farfetched to see the link between the Bitcoin embedded scripting language and the FORTH language, especially the stack section of the opcodes. I'd say they're of the same family, not necessarily a subset, and the lack of Turing completeness is of course a purposefully limiting factor.Stackmachines are fascinating, incredibly simple and yet quite powerful. There are a couple of such concepts in computing (NAND gates on the hardware side, the Lambda function on the software side and FORTH as well as for/if/jsr/load/store, and even brainfuck (and ook!)) which all allow you to build just about anything. Each of them warrants study.replyagumonkey 11 hours ago | root | parent | next [\u2013]Stack machines are really interesting. And Forth also had creative ways to think about code.I still need to read http://fpgacpu.ca/publications/Second-Generation_Stack_Compu... (amongst others)replyjacquesm 11 hours ago | root | parent | next [\u2013]A very interesting chip was the NOVIX: https://en.wikichip.org/wiki/novix/nc4016replybeanjuiceII 17 hours ago | prev | next [\u2013]really great read, thank you for putting this all togetherreplyidatum 14 hours ago | prev | next [\u2013]I forgot about dc! A NetBSD instance I have still has it. Love going back in time to these original utilities.replyfuzztester 12 hours ago | parent | next [\u2013]If you mean the calculator, bc is based on dc, IIRC.See you later, alliterator.replyidatum 12 hours ago | root | parent | next [\u2013]Yes, dc calculator, mentioned in this article. Here's the Wikipedia link also given: https://en.wikipedia.org/wiki/Dc_%28computer_program%29Here's the NetBSD man page: https://man.netbsd.org/dc.1replyfuzztester 11 hours ago | root | parent | next [\u2013]Yes, I knew about both of them (dc and bc) from before, having worked on Unixen for years.And have used bc a lot.Check out the useful bc -l option.Here is the page for bc:https://en.m.wikipedia.org/wiki/Bc_(programming_language)which is mentioned in the dc page's See Also section, which is what I alluded to in my earlier comment above, i.e. that bc is built on dc.See the History section of the bc page.replyfuzztester 12 hours ago | parent | prev | next [\u2013]me 12/4replyDonHopkins 12 hours ago | prev | next [\u2013]Reposting this about a historic project that Charles Moore himself worked on:https://news.ycombinator.com/item?id=29261868DonHopkins 8 months ago | parent | context | favorite | on: Forth vs LispCoco Conn and Paul Rother wrote this up about what they did with FORTH at HOMER & Assoc, who made some really classic music videos including Atomic Dog, and hired Charles Moore himself! Here's what Coco Conn posted about it, and some discussion and links about it that I'm including with her permission:Peter Conn:https://imgur.com/a/4Bmb4xuHomer & Associates (1982):http://leftbrain.us/rotherHistory/homer.htmlPeter Conn Papers at Stanford:https://library.stanford.edu/blogs/special-collections-unbou...https://oac.cdlib.org/findaid/ark:/13030/c8n303pn/entire_tex...George Clinton - Atomic Dog (Official Music Video) HDhttps://www.youtube.com/watch?v=LMVZ36VA0wgSteve Miller Band - Abracadabrahttps://www.youtube.com/watch?v=tY8B0uQpwZsSteve Miller Band - Bongo Bongohttps://www.youtube.com/watch?v=_NrsRZdMI-AFlying Logos for 1989 Siggraph Electronic Theater:https://www.youtube.com/watch?v=9hIOfEiy4lc>First shown at the 1989 Siggraph Electronic Theater to a rave response, this 3 minute humourous film went on to win several top computer graphic awards that same year including Niccograph of Japan.>Coco: This was a show favorite at the SIGGRAPH film show that year. The year before the conference committee decided that showing demos wasn't the way to go anymore. Peter wrote Flying Logos as a way to sneak our demo reel into the show by turning it into a story. It worked and we made it into the film show.>Don: I truly believe that in some other alternate dimension, there is a Flying Logo Heaven where the souls of dead flying logos go, where they dramatically promenade and swoop and spin around each other in pomp and pageantry to bombastic theme music. It would make a great screen saver, at least! Somewhere the Sun Logo and the SGI Logo are still dancing together.----Peter Conn and I [Coco Conn] had a company called HOMER & Assoc. which was located at the Sunset Gower Studios from 1977 until we closed shop in 1997. We made music videos, commercials & computer graphics/special effects for feature films. One cool note, we worked with Paul Verhoven on both RoboCop in 1986 and the x-ray scene for Total Recall in '89.HOMER was actually a real time visual mixing console that our in-house engineer spent 1978 - 1981 designing and building, from scratch. The name HOMER stood for \"Hybrid Optical Montage Electronically Reproduced.\" I helped as well, soldering the LEDs on the console and running cables. Peter built his own optical printer and three years into the build we also bought an early computer paint system. Our engineer finished building the console and promptly decided to move to England. We hadn\u2019t used it because we still hadn\u2019t found the right software to run the system. Luckily that\u2019s when Paul Rother joined the company.The joy stick on our console would bump you to the next line of code (being a command or sequence of events: fade, cut, dissolve, etc.) The console had touch sensitive fader pads. There were no dials. I think they were made by Allison? Each channel (which controlled either a slide projector or a film projector) was touch sensitive. After recording a sequence we could then tweek the current version using additional effects the channels offered such as momentary, additive, on/off, etc. For instance if you wanted to crossfade two images, you could either program it or perform it. Of course everything you did was recorded and would play back on the next round. You literally performed a sequence of visual effects with your hands. Peter would do countless passes until everything was perfect. This performance would then be played back to IP film on the optical printer. Each slide tray or film real would be individually run, one by one, to IP film. Sometimes there would be 10-15 or more passes to get all the elements transferred. Once that was done we would then convert the IP film to video and do additional video editing and effects. A totally nuts analogue system. But it worked.---------------HOMER Explained by Paul Rother, in-house programmer, (1982):The photo is Paul sitting in front of the Optical Printer 7-bit Paint system, Homer and Associates, circa 1982. Homer and Associates was really one of a kind kinda of company. Founded by Peter Conn, originally I got hired to program Homer II, a visual realtime mixing console. Homer I is another whole story, but before my time. Homer II consisted of 16 slide projectors, 4 movie projectors, a 4 track tape recorder, 24 visual channels (each with its own Z80) touch sensitive sliders, a master Z80 S100 bus system and featuring \"the joy stick bumper \" control, which looked liked the gear shift right out of a 1964 mustang convertible.The idea was that you would program a visual sequence, then play the sequence in sync with the sound track on the joystick, including cascades, bumps, cuts, etc. The whole thing would be recorded, and if you wanted to, like an audio mixer, go back and do over dubs, making corrections. Then once you had the perfect \"hero\" recording, you take the 8\" floppy disc with the hero recording and the trays of slides to the optical printer, and record it to IP motion picture film, making multiple passes, one tray at a time. Now that I think about it, it was a crazy idea. We actually got the whole thing to work. And it worked great!Forth & Charles MooreWe hired Forth, Inc. and got Charles Moore, the inventor of FORTH to program the console host computer. I learned FORTH and worked with Charles. I programmed the 2K byte EPROM in each visual channel. On the Master Z80 system we ran PolyForth a multi tasking system in 32K bytes. We had an extra 16K RAM for buffers and things. If I remember right, the system ran four tasks, but that was 20 years ago, my memory may be hazy.Anyway, I learn not only FORTH from Charles Moore, but also how to factor code in to small reusable routines, WORDs they're called in FORTH. I learned Object Oriented Programming without knowing it. Also a lot of use of vectors. Its a cool language. Charles Moore was a great inspiration to me, and really taught me a great deal that they never taught me in computer programming school.CAT-700After we got the basic Homer II working and were able to record on the optical printer, Peter had another idea. He wanted to be able to see the movement of the optical printer, and see a prior frame compared to the current frame. We already had a video assist on the Fries Mitchell 35mm. What we needed was a Frame Buffer. We heard of S100 video board called the CAT-100, which was 1-bit frame buffer, good enough for what we needed. Somehow we never found a 1-bit version, but we found 7-bit version in the recycler!We flew to Reno, rented a car and drove to a log cabin up in the hills of Truckie California. We got a demo of the thing. The guys were super secret and didn't want us to see the controlling program. It worked, so we bought it, and then flew onto Palo-Alto and met the French guy who designed it. They checked it out and it was OK. This was the days before computer designed boards, and all the traces on the board were curvy, kinda like a Van Gogh painting. We learned that it was 7-bit (CAT-700) because it would have been an 8-bit, but they could not get the 8th bit to work. We spent the night in Palo Alto with a Stanford friend of Peters working on a crazy secret Apple project, the Lisa. 32KByte Paint SystemSo I got the CAT-700 frame buffer to work, programmed in FORTH. So in that 32K we had an optical printer control system, and a paint system, all in one. (Also the OS, compiler, debugger, etc.) We later hooked up a Summigraphic Bitpad (before the Watcom tablet) and were able to draw on top of digitized frames. It got to the point where we needed TWO optical printers, one to digitize from film, and the other to record to film. Rube Goldberg is not strong enough descriptive to describe the system, with the filter wheels and all on stepper motors, it made music. The first use of the system was effects for Steve Miller Music Video, Abracadabra. I also remember using it on the George Clinton Video, Atomic Dog.This photo was taken right after we got the system to work. I had hooked up an analog slider box, which controlled things like color. There were 4 color maps we could switch between instantly We did a lot of work in planes, using 2 planes for the original image to be rotoscoped, and the other 5 planes to draw onto. This photo was taken for an article in Millimeter Magazine. The photo ended up being a two page color spread, and I think Peter was pissed, cause I got premier exposure.TTL logicAt Homer and Assoc. I also learned TTL logic and designed a number of computer boards for the S100 bus. One that controlled stepper motors with a timer chip (Motorola 6840). Another to control the Slide Projectors also using the same Motorola timer chip to control the lamp triacs. My favorite thing, about the system, was the use of the cassette storage interface as a cheap timecode reader/writer.replyCyberDildonics 13 hours ago | prev [\u2013]Forth was influential, but it is somewhere between obsolete and niche. It is much more difficult to program in than even raw C, let alone C++ and offers no advantage in speed on modern hardware where memory access is the by far the highest priority.replyGuidelines | FAQ | Lists | API | Security | Legal | Apply to YC | ContactSearch:",
    "hn_summary": "- Forth is a programming language that allows you to define new \"words\" that become part of the language itself, providing a high level of flexibility not commonly found in other languages.\n- Forth is an extensible language, allowing programmers to customize and extend the language in a fundamental way, similar to the macro system in Lisp.\n- Forth has practical applications such as Bitcoin script and PostScript, and is used in some aerospace chips."
  },
  {
    "id": 36750554,
    "timestamp": 1689535592,
    "title": "How to register a Kei truck in Pennsylvania",
    "url": "https://danwilkerson.com/posts/2023-05-30-how-to-register-a-kei-truck-in-pa",
    "hn_url": "http://news.ycombinator.com/item?id=36750554",
    "content": "HomePostsProjectsContactHow to register a Kei truck in Pennsylvania2023-05-30Kei trucks are a special designation of Japanese car that have very small engines (660cc) and dimensions (~10m^3). Tell 'em, Wikipedia. Whoever coined the idea of \"creative constraints\" should take a gander at Kei trucks; there's definitely an upper bound:Japan's tax incentives have created a brisk export business for often lightly used trucks. As a result, they're available for purchase in the US.I recently decided to do just that and had a heck of a time getting on the road. This guide serves as a lamp in the dark, helping guide fellow fools to road-legal ownership.Why did I want one? I'm glad you ask - Kei trucks:Have a 6ft bedWhich can fold flatAnd carry ~1000lbsWith 4WD (including a locking rear diff1 and axle)While getting 40 MPGFor $X,000.0With very low mileage (22k miles in my instance)I often need to haul stuff and had gotten sick of U-Haul rentals. I decided to find a cheap 90s/early 00s small truck. Pandemic prices were getting me rusted-out Rangers or 250k mile Tacomas2; then the Kei came into my life. Libby and I were pulling in to Construction Junction when a couple in a Honda Acty pulled in behind us. I picked the guy's brain about how useful it was, getting it insured, and so forth; it all sounded pretty straightforward, and I was sold.Step 0: Find a truckYou have some choices here: you can import it yourself, buy from an importer, or risk craigslist. Prices rise as you work down that list.You'll need to find a truck that is at least 25 years old. In the US, cars more youthful than that must comply with FMVSS (safety standards). If you buy a more recent vintage, you won't be able to get it registered anywhere, so pay attention to that model year!There are exporter websites out there promising a truck for ~$3-5k all in, provided you can pick it up at the port and are willing to do the paperwork. As I understand it, the importation process is high stakes - if you make a mistake, US Customs puts your truck in a garbage compactor and you're out the money. If you're brave enough to try it, I wish you the best - come back here after you're leaving your port of choice.The safer route is to buy from an importer. If you're smart, you'll find an importer who has already titled the vehicle and you'll be set. Of course, you wouldn't be Googling \"how to title a kei truck Pennsylvania\" in that case, but here we are. \"Don't worry,\" you thought, \"it can't take that long to get a title.\" 3Step 1: Getting the car titledWait, back it up - you're going to need some paperwork only the seller can get you. Otherwise I honestly have no idea what will happen to you or your truck.Right, uh, Step -1: Make sure the seller has the paperworkBefore you buy, make sure you'll be able to get everything you need to title the thing. You'll need:The Export Certificate - this should look like thisProof you paid sales tax - PennDOT will really, really want you to prove this, likea lot. I sent in a photocopy of the receipt from the place I bought the truck, Twin Ridge Lawn and Garden.Great, back to Step 1a: Translate your CertificateSo you're gonna need a translation of that certificate. It's not required, but it supposedly helps to have the document notarized with an American Translation Association seal. You definitely need the translation to be accompanied by a sworn affadavit from the translator, though; they should know what to do.I used the American Translators Association directory and emailed a handful of eligible translators. The prices and response times were all over the map. In the end I ended up working with Patricia Pringle; Patricia was super responsive and very reasonably priced!Step, I don't know, 3? 1b? 2.5?: How much does your truck weigh?Okay, so you've got your translated export certificate, you've got your proof of paying sales tax. Forget all that - now you're going to need to prove you know how much your truck weighs. Why? Because in the state of Pennsylvania that information is absolutely crucial to verifying the VIN of your vehicle. You're going to need an MV-41, but first, you're going to need to get the unladen weight of your shiny new truck.You'll need to get your truck to a salvage yard or other weigh station4 where a weighmaster can weigh and certify the weight of your vehicle - I visited D&D Auto Salvage on the recommendation of my mechanic, Tim Walters. Thanks, Tim!Take this slip of paper to a mechanic along with your MV-41 and your truck4. They'll need to fill out the MV-41, verifying the weight from the weighmaster and the VIN in your truck (which may be in an unusual location - mine was stamped on the wheel well). If you're lucky, you'll find a guy who's done this recently and also thinks imports are super cool - thanks Naiel!Step 4: InsuranceThis was actually relatively easy. Don't even bother trying the \"Request a Quote\" forms, just start calling shops that give you multiple quotes (e.g. Zebra). They'll help tremendously. Almost all the providers declined to cover my dangerous exotic trash hauler minitruck, but Safco gave me an acceptable rate on liability insurance5. Getcher self a copy of your proof of insurance.Step 1000: Submit the paperworkOnce you've gotten your:Original export certificateTranslated export certificateProof of paid PA sales taxFilled out MV-41The mileage on your odometer, converted to milesThe gross weight of the vehicle, converted to poundsProof of insuranceA photo or two of the truck6It's finally time to fill out the big kahuna - the MV-1, a request for a title. You won't find this form online - only an authorized agent can fill one out. There are some helpful instructions for filling this out properly, I went with AAA here in Pittsburgh. You're also going to find out that you can only register these vehicles as antiques in PA. This isn't as onerous as it once was. You can't use the vehicle for commercial purposes, and you're not meant to use it more than occasionally - for most folks, that should fit the bill just fine.Once you've got an agent, they'll take a look at all your documents and ask you a few questions about the vehicle. It's important that you:Explain that the truck can be registered as an antiqueDemonstrate repeatedly that yes, you have paid the PA State sales tax7Request it be titled as a truckEnsure that they send in the original export certificate and not a copyAt this point I'd like to share a bit of wisdom I received early on in this process: this is a once-in-a-lifetime type situation for whomever you're going to work with. You are the edge case and corner case they've been warned about. You are going to be their anecdote about the wild stuff that comes through the door. \"Some kind of crazy tiny truck from Japan,\" they'll laugh, \"My God! Months!\". They'll accentuate that last point by waving their hands in the air, like they're waving an imaginary beachball from side-to-side. Be ready to be patient.Once the paperwork is submitted, you'll wait about ~30 days before you hear from PennDot. If you're super lucky you'll get a plate in the mail along with the title in a few weeks. If you're a little lucky, they'll send your agent feedback on your packet that you can correct and resubmit. You're going to need to follow up with your agent - they're probably not going to reach out. Once you've addressed their concerns, it'll be another 30 days before you'll know if things are fixed. If you're really unlucky, you'll do this loop, oh, I don't know, three or four times8? Finally, you'll get a thick envelope in the mail and inside will be your prize - an antique PA plate.Step 1001: Go buy some screwsAh, crap, sorry - you could have done this way sooner. The holes in the plate won't line up with the holes in your plate holder - damn metric system. Grab a drill and a pencil, mark where the holes should be, apply drill, and you'll be all set. You'll need two M6 20mm galvanized screws, which you can find at any hardware store.So what's the downside?In case you're still weighing the pros and cons, here's my take as of a few months into ownership.It attracts a lot of attention. This might be a little overwhelming.You're topping out at 60 MPH, maybe.No air bags, air conditioning, power steering, or crumple zones.Parts are all across an ocean.Right-hand drive is unsettling for everyone involved.I've been really happy with it - it's a lot cheaper than a similarly sized truck would have run me, with way fewer miles on the odometer. For bopping around town hauling lumber, yard waste, and furniture, it's perfect. Just don't expect to be cruising on the interstate in one of these.Not really sure why this is important, but this blog post might help\u21a9My dad, who is smarter than me, simply bought a minivan. \"Look,\" he gloats, \"I can fit a whole sheet of plywood in here! And there's a DVD player!\"\u21a9The artist deploys a technique known as foreshadowing.\u21a9How to get your unregistered vehicle to these places is left as an exercise for the reader.\u21a9Pro-tip: most insurers offer AAA-style roadside assistance for way less - I pay $5 a year for the service.\u21a9Like you haven't already take a bunch. (Note: this is mostly for illustrative purposes)\u21a9This will still not land, you will still get the packet returned from PennDot, and you'll send it back with lots of arrows and highlighter pointing to the tax line on your receipt.\u21a9Yup, I bought my truck in February and only got it on the road in May. Eat your heart out, Kafka.\u21a9",
    "summary": "- Kei trucks are a special type of Japanese car that have small engines and dimensions and are available for purchase in the US due to Japan's tax incentives.\n- The process of registering a Kei truck in Pennsylvania involves finding a truck that is at least 25 years old, obtaining necessary paperwork from the seller, translating the export certificate, proving the weight of the truck, getting insurance, and submitting the paperwork to PennDot.\n- The registration process can be lengthy and may require patience, but ultimately allows for road-legal ownership of a Kei truck in Pennsylvania.",
    "hn_title": "How to register a Kei truck in Pennsylvania",
    "original_title": "How to register a Kei truck in Pennsylvania",
    "score": 247,
    "hn_content": "- There is a push at the state level to disallow the registration of kei trucks in certain states, led by the American Association of Motor Vehicle Administrators.\n- Kei trucks are popular in the Pacific Northwest and have utility for hauling capacity and off-road adventures.\n- Kei trucks are narrow, allowing them to navigate through obstacles on overgrown trails and cause less trail erosion.\n- Kei cars are specifically illegal in Oregon, but the policy is not based on law.\n- Bill Gates successfully lobbied for the \"Show or Display\" law to import his Porsche 959, which was made illegal by a previous law.\n- Kei cars are generally not manufactured for US highways and don't meet federal regulations.\n- Some states are enforcing their interpretation of federal laws, which is being challenged in ongoing lawsuits.\n- US states have individual interpretations of laws on certain things, like marijuana regulations and firearms, including local differences in alcohol regulations.\n- There are inconsistencies and variations in state laws and regulations in the US due to the power of states in the governing structure.\n- Kei vehicles are not allowed on US roads if they don't meet current safety standards.\n- There is interest in importing kei trucks for their small size and great fuel economy.\n- The US car market often prioritizes size and power over efficiency and practicality.\n- Motorcycle safety is another area of concern, as they are allowed on the road despite higher risks.\n- There is a 25-year rule that allows the import of vehicles that are older than 25 years without needing to comply with current regulations.\n- There are various state laws and regulations specific to vehicles and driving, causing inconsistency across the country.- People are discussing the popularity of Kei trucks in the US\n- Kei trucks are small, lightweight vehicles popular in Japan\n- Kei trucks are not common in the US due to regulations and registration difficulties\n- Some people argue that Kei trucks are practical for specific purposes such as living on large properties or in rural areas\n- Others suggest that alternatives like vans or rental trucks may be more cost-effective\n- There are debates about the safety of trucks and the need for larger vehicles in certain situations\n- The discussion includes mentions of US regulations on vehicle imports and inspections\n- There is interest in electric alternatives to Kei trucks, such as the Telo electric mini-truck\n- Some people have found niche markets for importing and selling Kei trucks within the US\n- The difference in regulations and cultural attitudes towards vehicles between Japan and the US is highlighted\n- There are discussions about the pros and cons of owning a traditional pickup truck versus a Kei truck or alternative options",
    "hn_summary": "- There is a push at the state level to disallow the registration of kei trucks in certain states, led by the American Association of Motor Vehicle Administrators.\n- Kei trucks are popular in the Pacific Northwest and have utility for hauling capacity and off-road adventures.\n- The US car market often prioritizes size and power over efficiency and practicality."
  },
  {
    "id": 36743784,
    "timestamp": 1689483098,
    "title": "How to Use AI to Do Stuff: An Opinionated Guide",
    "url": "https://www.oneusefulthing.org/p/how-to-use-ai-to-do-stuff-an-opinionated",
    "hn_url": "http://news.ycombinator.com/item?id=36743784",
    "content": "Discover more from One Useful ThingTranslating academic research into mostly useful insights, with some ephemera on the side. Mostly AI stuff recently. By Prof. Ethan MollickOver 60,000 subscribersSubscribeContinue readingSign inHow to Use AI to Do Stuff: An Opinionated GuideCovering the state of play as of Summer, 2023ETHAN MOLLICKJUL 15, 202331635ShareIncreasingly powerful AI systems are being released at an increasingly rapid pace. This week saw the debut of Claude 2, likely the second most capable AI system available to the public. The week before, Open AI released Code Interpreter, the most sophisticated mode of AI yet available. The week before that, some AIs got the ability to see images.And yet not a single AI lab seems to have provided any user documentation. Instead, the only user guides out there appear to be Twitter influencer threads. Documentation-by-rumor is a weird choice for organizations claiming to be concerned about proper use of their technologies, but here we are.I can\u2019t claim that this is going to be a complete user guide, but it will serve as a bit of orientation to the current state of AI. I have been putting together a Getting Started Guide to AI for my students (and interested readers) every few months, and each time, it requires major modifications. The last couple of months have been particularly insane.This guide is opinionated, based on my experience, and focused on how to pick the right tool to do things. I have written separately about the kinds of tasks you may want AI to do, which might be useful to read first.The Major Large Language ModelsWhen we talk about AI right now, we are usually talking about Large Language Models, or LLMs. Most AI applications are powered by LLMs, of which there are just a few Foundation Models, created by a handful of organizations. Each company gives direct access to their models via a Chatbot: OpenAI makes GPT-3.5 and GPT-4, which power ChatGPT and Microsoft\u2019s Bing (access it on an Edge browser). Google has a variety of models under the label of Bard. And Anthropic makes Claude and Claude 2.There are other LLMs I won\u2019t be discussing. The first is Pi, a chatbot built by Inflection. Pi is optimized for conversation, and really, really wants to be your friend (seriously, try it to see what I mean). It does not like to do much besides chat, and trying to get it to do work for you is an exercise in frustration. We also won\u2019t cover the variety of open source models that anyone can use and modify. They are generally not accessible or useful for the casual user today, but have real promise. Future guides may include them.So here is your quick reference chart, summarizing the state of LLMs:The first four (including Bing) are all OpenAI systems. There are basically two major OpenAI AIs today: 3.5 and 4. The 3.5 model kicked off the current AI craze in November, the 4 model premiered in the Spring and is much more powerful. A new variation uses plugins to connect to the internet and other apps. There are a lot of plugins, most of which are not very useful, but you should feel free to explore them as needed. Code Interpreter as is an extremely powerful version of ChatGPT that can run Python programs. If you have never paid for OpenAI, you have only used 3.5. Aside from the plugins variation, and a temporarily suspended version of GPT-4 with browsing, none of these models are connected to the internet. Microsoft\u2019s Bing uses a mix of 4 and 3.5, and is usually the first model in the GPT-4 family to roll out new features. For example, it can both create and view images, and it can read documents in the web browser. It is connected to the internet. Bing is a bit weird to use, but powerful.Google has been testing its own AI for consumer use, which they call Bard, but which is powered by a variety of Foundation Models, most recently one called PaLM 2. For the company that developed LLM technology, they have been pretty disappointing, although improvements announced yesterday show they are still working on the underlying technology, so I have hope. It has already gained the capability to run limited code and interpret images, but I would generally avoid it for now.The final company, Anthropic has released Claude 2. Claude is most notable for having a very large context window - essentially the memory of the LLM. Claude can hold almost an entire book, or many PDFs, in memory. It has been built to be less likely to act maliciously than other Large Language Models, which means, practically, that it tends to scold you a bit about stuff.Now, on to some uses:Write stuffBest free options: Bing and Claude 2Paid option: ChatGPT 4.0/ChatGPT with pluginsFor right now, GPT-4 is still the most capable AI tool for writing, which you can access at Bing (select\u201ccreative mode\u201d) for free or by purchasing a $20/month subscription to ChatGPT. Claude, however, is a close second, and has a limited free option available.These tools are also being integrated directly into common office applications. Microsoft Office will include a copilot powered by GPT and Google Docs will integrate suggestions from Bard. The implications of what these new innovations mean for writing are pretty profound.Here are some ways to use AI to help you write.Writing drafts of anything. Blog posts, essays, promotional material, speeches, lectures, chose-you-own adventures, scripts, short stories - you name it, AI does it, and pretty well. All you have to do is prompt it. Prompt crafting is not magic, but basic prompts result in boring writing, but getting better at prompting is not that hard, just work interactively with the system. You will find AI systems to be much more capable as writers with a little practice.Make your writing better. Paste your text into an AI. Ask it to improve the content, or for suggestions about how to make it better for a particular audience. Ask it to create 10 drafts in radically different styles. Ask it to make things more vivid, or add examples. Use it to inspire you to do better work.Help you with tasks. AI can do things you don\u2019t have the time to do. Use it like an intern to write emails, create sales templates, give you next steps in a business plan, and a lot more. Here is what I could accomplish with it in 30 minutes in supporting a product launch.Unblock yourself. It is very easy to get distracted from a task by one difficult challenge. AI provides a way of giving yourself momentum.Some things to worry about: In a bid to respond to your answers, it is very easy for the AI to \u201challucinate\u201d and generate plausible facts. It can generate entirely false content that is utterly convincing. Let me emphasize that: AI lies continuously and well. Every fact or piece of information it tells you may be incorrect. You will need to check it all. Particularly dangerous is asking it for references, quotes, citations, and information for the internet (for the models that are not connected to the internet). Bing will usually hallucinate less than other models, because GPT-4 is generally more grounded and because Bing\u2019s internet connection means it can actually pull in relevant facts. Here is a guide to avoiding hallucinations, but they are impossible to completely eliminate.And also note that AI doesn\u2019t explain itself, it only makes you think it does. If you ask it to explain why it wrote something, it will give you a plausible answer that is completely made up. When you ask it for its thought process, is not interrogating its own actions, it is just generating text that sounds like it is doing so. This makes understanding biases in the system very challenging, even though those biases almost certainly exist.It also can be used unethically to manipulate or cheat. You are responsible for the output of these tools.Make imagesMost transparent option: Adobe FireflyOpen Source Option: Stable DiffusionBest free option: Bing or Bing Image Creator (which uses DALL-E), Playgound (which lets you use multiple models)Best quality images: MidjourneyThere are four big image generators available for most people:Stable Diffusion, which is open source and you can run from any high-end computer. It takes effort to get started, since you have to learn to craft prompts properly, but once you do it can produce great results. It is especially good for combining AI with images from other sources. Here is a nice guide to Stable Diffusion if you go that route (be sure to read both parts 1 and part 2).DALL-E, from OpenAI, which is incorporated into Bing (you have to use creative mode) and Bing image creator. This system is solid, but worse than Midjourney.Midjourney, which is the best system in mid-2023. It has the lowest learning-curve of any system: just type in \"thing-you-want-to-see --v 5.2\" (the --v 5.2 at the end is important, it uses the latest model) and you get a great result. Midjourney requires Discord. Here is a guide to using Discord.Adobe Firefly, built into a variety of Adobe products, but it lags DALL-E and Midjourney in terms of quality. However, while the other two models have been unclear about the source images that they used to train their AIs, Adobe has declared that it is only using images it has the right to use.Here is how they compare (each image is labelled with the model):Prompt: \u201cFashion photoshoot of sneakers inspired by Van Gogh\u201d - the first images that were created by each modelSome things to worry about: These systems are built around models that have built-in biases due to their training on Internet data (if you ask it to create a picture of an entrepreneur, for example, you will likely see more pictures featuring men than women, unless you specify \u201cfemale entrepreneur\u201d), you can use this explorer to see these biases at work.These systems are also trained on existing art on the internet in ways that are not transparent and potentially legally and ethically questionable. Though technically you own copyright of the images created, legal rules are still hazy.Also, right now, they don\u2019t create text, just a bunch of stuff that looks like text. But Midjourney has nailed hands.Come up with ideasBest free option: BingPaid option: ChatGPT 4.0, but Bing is likely better because of its internet connectionsDespite of (or in fact, because of) all its constraints and weirdness, AI is perfect for idea generation. You often need to have a lot of ideas to have good ideas, and AI is good at volume. With the right prompting, you can also force it to be very creative. Ask Bing in creative mode to look up your favorite unusual idea generation techniques, like Brian Eno's oblique strategies or Mashall McLuhan's tetrads, and apply them. Or ask for something weird, like ideas inspired by a random patent, or your favorite superhero\u2026Make videosBest animation tool: D-iD for animating faces in videos. Runway v2 for creating videos from textBest voice cloning: ElevenLabsIt is now trivial to generate a video with a completely AI generated character, reading a completely AI-written script, talking in an AI-made voice, animated by AI. It can also deepfake people, as you can see in this link where I deepfaked myself. Instructions and more information here. Use with caution, but this can be great for explainer videos and introductions.The first commercially available text-to-video tool was also recently released, Runway v2. It creates short 4-second clips, and is more of a demonstration of what is to come, but is worth taking a look at if you want a sense of the future development in this space.Some things to worry about: Deep fakes are a huge concern, and these systems need to be used ethically.Work with documents and dataFor data (And also any weird ideas you have with code): Code InterpreterFor documents: Claude 2 for large documents or many documents at once, Bing Sidebar for smaller documents and webpages (the sidebar, part of the Edge browsers can \u201csee\u201d what is in your browser, letting Bing work with that information, though the size of the context window is limited)I wrote about Code Interpreter last week. It is a mode of GPT-4 that lets you upload files to the AI, allows the AI to write and run code, and lets you download the results provided by the AI. It can be used to execute programs, run data analysis (though you will need to know enough about statistics and data to check its work), and create all sorts of files, web pages, and even games. Though there has been a lot of debate since its release about the risks associated with untrained people using it for analysis, many experts testing Code Interpreter are pretty impressed, to the degree that one paper suggests it will require changing the way we train data scientists. Go to my previous post if you want more details on how to use it. I also made an initial prompt to set up Code Interpreter to create useful data visualizations. It gives it some basic principles of good chart design & also reminds it that it can output many kinds of files. You can find that here.For working with text, and especially PDFs, Claude 2 is excellent so far. I have pasted in entire books into the previous version of Claude, with impressive results, and the new model is much stronger. You can see my previous experience, and some prompts that might be interesting to use, here. I also gave it numerous complex academic articles and asked it to summarize the results, and it does a good job! Even better, you can then interrogate the material by asking follow-up questions: what is the evidence for that approach? What do the authors conclude? And so on\u2026Some things to worry about: These systems still hallucinate, though in more limited ways. You need to check over their results if you want to ensure accuracy.Get information and learn stuffBest free option: BingPaid option: Usually Bing is best. For children, Khanmigo from Khan Academy offers good AI-driven tutoring powered by GPT-4.If you are going to use AI as a search engine, probably don\u2019t do that. The risk of hallucination is high and most AIs are not connected to the Internet, anyway (which is why I suggest you use Bing. Bard, Google\u2019s AI, hallucinates much more). However, there is some evidence that AI can often provide more useful answers than search when used carefully, according to a recent pilot study. Especially in cases where search engines aren\u2019t very good, like tech support, deciding where to eat, or getting advice, Bing is often better than Google as a starting point. This is an area that is evolving rapidly, but you should be careful about these uses for now. You don\u2019t want to get in trouble.But more exciting is the possibility of using AIs to help education, including helping us learn. I have written about how AI can be used for teaching and to help make teachers\u2019 lives easier and their lessons more effective, but it can also work for self-guided learning as well. You can ask the AI to explain concepts and get ver good results. This prompt is a good automated tutor, and use can find a direct link to activate the tutor in ChatGPT here. Because we know the AI could be hallucinating, you would be wise to (carefully!) double-check any critical data against another source.And more?Thanks to rapid advances in technology, these are likely the worst AI tools you will ever use, as the past few months of development have shown. I have no doubt I will need to make a new guide soon. But remember two key points that remain true about AI:AI is a tool. It is not always the right tool. Consider carefully whether, given its weaknesses, it is right for the purpose to which you are planning to apply it.There are many ethical concerns you need to be aware of. AI can be used to infringe on copyright, or to cheat, or to steal the work of others, or to manipulate. And how a particular AI model is built and who benefits from its use are often complex issues, and not particularly clear at this stage. Ultimately, you are responsible for using these tools in an ethical manner.We are in the early days of a very rapidly advancing revolution. Are there other uses you want to share? Let me know in the comments.This post is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.SubscribeShare316 Likes\u00b722 Restacks31635SharePrevious",
    "summary": "- The post provides an opinionated guide on how to use AI for various tasks.\n- It covers the current state of AI, including the most powerful AI systems available to the public.\n- It offers recommendations for AI tools for writing, creating images, generating ideas, making videos, working with documents and data, and acquiring information.",
    "hn_title": "How to Use AI to Do Stuff: An Opinionated Guide",
    "original_title": "How to Use AI to Do Stuff: An Opinionated Guide",
    "score": 241,
    "hn_content": "Hacker News new | past | comments | ask | show | jobs | submit loginHow to Use AI to Do Stuff: An Opinionated Guide (oneusefulthing.org)241 points by Brajeshwar 1 day ago | hide | past | favorite | 63 commentsp-e-w 1 day ago | next [\u2013]What the article barely touches upon is that all currently available AIs-as-a-service- permit themselves to store and use your inputs essentially as they see fit, for essentially any purpose- have mechanisms designed to \"prevent abuse\", without defining what that actually means- are engineered to \"keep you safe\", without stating clearly what they want to keep you safe from, and without any option to disable those so-called safeguards- have been carefully tuned to align their outputs with the Upper Middle Class U.S. West Coast Tech Scene political zeitgeist of the day, and that is what you'll get from them, even if it is completely inappropriate in your own cultural environment.Caveat emptor.replyroseway4 16 hours ago | parent | next [\u2013]Caveat emptor indeed. LLM-as-a-Service vendors know their customer and this customer\u2019s needs. It\u2019s not you. They\u2019re selling an API to companies for whom safety and governance are part of the value proposition.As others have mentioned, the data retention aspect is specifically /not/ an issue with OpenAI (and other vendors\u2019) APIs.I don\u2019t really get the saltiness so many on this site have towards LLM vendors. It just sounds entitled.replysebzim4500 14 hours ago | root | parent | next [\u2013]It's sort of frustrating to know that OpenAI has a better model that wouldn't cost them anything to release, but they don't do it for PR/whatever reasons.replyroseway4 14 hours ago | root | parent | next [\u2013]What \u201cbetter model\u201d? If you\u2019re referring to whatever LLM GPT-4 was before RLHF, by what measure might this model be better? As I pointed out above, what OpenAI is selling is \u201cbest\u201d for their customers.replyswyx 15 hours ago | root | parent | prev | next [\u2013]there is a particular type of person, who, when presented with a marvelous new thing (idea, product, person), focuses on its flaws rather than its unique merits.we need them to ensure an equitable and sustainable world, but they do not drive progress. i bet they are also as a group far less successful and happy throughout their miserable lives. most will just impotently fart their misery unto others, and only a rare few will actually do something about it\u2026\u2026at which point they wrap around back to becoming makers of imperfect things for the next round of criticism.replysebzim4500 23 hours ago | parent | prev | next [\u2013]Agree with most of this, but your first point is not true of OpenAI. Their terms of service forbid them from training on API inputs unless you explicitly opt in.replyesperent 23 hours ago | root | parent | next [\u2013]That's totally false, and you can't even save a chat history on ChatGPT unless you leave this option set to on.replylosteric 19 hours ago | root | parent | next [\u2013]OpenAI API is not ChatGPT UIAnd the prior poster is right, OpenAI API eula/tos clearly state data is not retained by default. I've been involved with legal counsel reviews, on that point there's zero ambiguity.replyspdustin 15 hours ago | root | parent | next [\u2013]To be clear, API data is retained for 30 days, to be used for determining usage policy violations.replyactualwitch 23 hours ago | root | parent | prev | next [\u2013]Whole point of ChatGPT is to collect data to do reinforcement learning, gp is talking about API access which has different terms (and wasn't banned in eu because of that).replyesperent 22 hours ago | root | parent | next [\u2013]> Whole point of ChatGPT is to collect data to do reinforcement learningNo, the point of ChatGPT is to provide a UI to chat with GPT models. Taking the data generated by users and using it for commercial purposes without consent is very likely to be illegal in the EU. Unfortunately they often take years to tackle this kind of stuff.replydaveguy 18 hours ago | root | parent | next [\u2013]It does comply with EU GDPR laws -- EU users are allowed to opt out of training. This was after regulators in Italy shut it down. The US FTC is investigating too.https://www.reuters.com/technology/us-ftc-opens-investigatio...replyesperent 4 hours ago | root | parent | next [\u2013]To comply with GDPR it has to be opt in, and choosing not to opt in has to not affect the app's functionality.Currently, it's opt-out, and doing so destroys your chat history. They did manage to satisfy Italian regulators but I expect they'll get called out on this more thoroughly in the future.Or maybe they just changed the way this works for Italy?replymsla 15 hours ago | root | parent | prev | next [\u2013]I doubt there's enough enforcement behind that to make it plausible.replysebzim4500 14 hours ago | root | parent | next [\u2013]I don't see why the guarantees you get by using e.g. Azure's LLM api are any different from the ones you get when using Azure for anything.I guess I can see why you would trust AWS/Azure/GCP over OpenAI, since they are bigger companies arguably with more to lose.replyIG_Semmelweiss 18 hours ago | parent | prev | next [\u2013]What is a casual or nontechnical poweruser to do if the user wants to use LLM for work or education , without worry of the many points you mention?replyraincole 17 hours ago | root | parent | next [\u2013]Simple. Just stop worrying them. They're non-issues for average \"casual or nontechnical powerusers\".replyjstarfish 10 hours ago | root | parent | next [\u2013]Nah. Give it 10 years and it'll be the Robinhood fiasco all over again.Instead of anticipated trades, all these nontechnical power users with novel ideas will make the mistake of telling them to an AI-- and had their ideas stolen and rushed to market by whoever paid for access to mine the logs companies told us they weren't collecting.We already don't trust cloud providers not to spy on our infrastructure. There is little consequence in lying to us. AI will bring us IP theft at scale.Don't discuss anything sensitive or groundbreaking with cloud LLMs. No Google Collab, no OpenAI, nothing.Make do with a local LLM in the form of a Vicuna 13/30B GGML. And even there, you have to watch out for backdoors in Gradio/posthog or weird models that insist on you enabling remote code execution. This domain is unbelievably shady and I can only assume it's because of the low-level access it provides to our collective stream of consciousness.This is going to turn out to be bad news long term. Don't trust cloud LLMs.replybluecoconut 1 day ago | prev | next [\u2013]Pretty good examples and simple explanations. I didn't realize Claude 2 was so good at working with PDFs natively. I wonder if they're doing anything special? Is this just due to larger context length they have?Also, biased opinion on my part: I'm especially interested in watching how these things affect data science and data literacy as a whole. Code interpreter is a game changer in my opinion, the most powerful tool that I think deserves all the press it is getting. Also: I released an open source code-interpreter for data (https://github.com/approximatelabs/datadm) and even though I know how to code and use Jupyter daily, I still find myself doing analysis with it instead.All in all, it does seem like the different models and agents are gaining \"specialization\" skill is actually good for the user (rather than just using a single jack of all trades super chat model). Even though GPT-4 takes the language model crown, there's still specialization that matters and improves quality for different tasks as discussed here.I wonder if in 2-5 years we'll all use \"a single\" AI chat interface for everything, or every specialization continues to \"win at its own vertical\" and we just have AI embedded inside of every appreplyehnto 1 day ago | parent | next [\u2013]I think they necessarily need to specialize, as certain information is only available in the context of the domain. I think bigger context windows will hit a limit, and you'll need to have actually trained and guided the AI on specifics of the domain to be useful.At the moment it's only the fact that public documentation is available for so many tools that it's proving useful for so many things. But what about massive, closed source, boutique enterprise systems? You can feed it docs as context, but it would be better if it were trained on docs, support tickets and internal forums then properly aligned.replyhooande 1 day ago | root | parent | next [\u2013]This will create an excellent search engine but a terrible reasoning machine.There are a lot of ways to search through docs and support tickets now. The ability of an LLM to draw inferences and summarize all of that information comes from being trained on a very large amount of data with billions of parameters. The data can be highly specialized. There just needs to be several thousand gigs of it for the AI to do things that are rare and useful.replylevmiseri 19 hours ago | prev | next [\u2013]One other use case is \u2014 generating large amount of data on a scale not really possible before. I built https://meoweler.com - a travel site with all of the content generated by AI.replyssd532 5 hours ago | parent | next [\u2013]What a creativity, mate! The website is absolutely beautiful!replySKILNER 17 hours ago | parent | prev | next [\u2013]That's an awesome site. What tools did you use?replylevmiseri 17 hours ago | root | parent | next [\u2013]Thanks! The site itself is built with SvelteKit. For content it's all GPT4 and Midjourney.replyextr 1 day ago | prev | next [\u2013]Nice article. I've been trying to stress to my coworkers, the bar for AI right now is not \"it literally does my entire job for me with zero assistance or additional context\". It's just a tool that if you learn to use correctly can dramatically speed up some tasks.As an aside, Claude 100K looks very cool, but how many people even have access? Our CTO reached out to Anthropic directly they wouldn't even give him the time of day. It seems like if you aren't planning on spending 5 figures monthly on it it's a lost cause. I get it, but, lame.replysimonw 20 hours ago | parent | next [\u2013]Claude is now free for anyone (in certain countries) to use online at https://claude.aiTheir API still has an opaque waitlist though.replyvisarga 21 hours ago | parent | prev | next [\u2013]I got ignored but recently got access through the job, Claude is pretty good. I think I had the longest AI-assisted brainstorming session.replyesperent 23 hours ago | parent | prev | next [\u2013]I think you can get limited access through poe.com, although I haven't tried it myself.replyoli5679 12 hours ago | prev | next [\u2013]One usecase that isn't mentioned here is call transcription. There are a lot of usecases where recording your own call and having some automated way to turn it into a transcript, and possibly generating some structured summary is a big time-saver.OpenAi's Whisper is the most accurate transcription model that I know of. The weights are open-sources, so it can be self-hosted, or you use the API. The downside is that you have to roll your own diarization (seperating the text between speaker A/B). I used pynote audio.Paid services like fireflies, and transcription tools built into your call software, are much easier to use, but lead to some transcription quality dropoff.replyreacharavindh 1 day ago | prev | next [\u2013]As interesting as the article is, I stopped reading because of the login wall :-( I hate these websites that make you login.What motivates people to write on such platforms? Is sun stack like Medium? Do they pay the authors for content?At the least I wish HN had a tag on posts like [$] for pay walled content, and [Ad] for walled by login content so that I don\u2019t waste my attention..replyd1sxeyes 1 day ago | parent | next [\u2013]It\u2019s not a wall, more like a gate. You can just click to continue reading. It\u2019s a bit frustrating that it uses a dark pattern to make it seem like you are required to log in, but you can continue reading without logging in or subscribing or anything.replyfastball 1 day ago | root | parent | next [\u2013]I'm not sure this is really \"dark pattern\" \u2013 it's a full screen modal, sure, but it's not like the close button is hidden or anything (and you can close with ESC as others mentioned).replyd1sxeyes 15 hours ago | root | parent | next [\u2013]It\u2019s not \u201chidden\u201d but the modal pops up after scrolling far enough down that you\u2019re absorbed in the content, the \u201ccontinue reading\u201d is not styled as a button, and is accompanied by a chevron to the right which implies navigation away from the current content (I want to scroll down, not go right), which I think pushes it over the edge into dark pattern territory.replyabwizz 1 day ago | root | parent | prev | next [\u2013]it interrupts the user doing something desired for something that is not in the users interest.replyhaswell 19 hours ago | root | parent | next [\u2013]It's arguably in the user's interest if you look at the blogger and reader as participants in an ecosystem.The current state of the ecosystem is such that getting someone to subscribe is extremely important for ongoing engagement, and ongoing engagement is often the prerequisite for continued writing.If you're a reader interested in the kind of content the author is writing, and if you want to find more of this kind of content going forward, an easily escapable call to action is in the user's interest.Is it annoying? Also yes. But in a world where everyone runs an ad blocker and social aggregators are fragmenting, it's better than a fully erected paywall, and better than nothing at all.replyevandale 18 hours ago | root | parent | next [\u2013]> It's arguably in the user's interest if you look at the blogger and reader as participants in an ecosystem.I don't want to be part of the ecosystem. I want to read the article, leave, and never come back. It's not in this user's best interest to be bothered by a popup.In fact, I believe it's actually the best interests of the author that's being looked after, not the users or readers, by using a modal popup to interrupt somebody's reading. It's as rude as walking up to someone while they're reading a book and waving your hands between their eyes and the book they're reading to get their attention if you noticed they were reading a book you personally wrote in an effort to sell them more books or to ask them for their email so you can send them special offers.I suppose I could stop going to the park where authors think this is acceptable to do and limit my reading to parks where \"ecosystem\" authors avoid, but eventually other people start using their annoying tactics and you can't escape it no matter where you go.replyhaswell 17 hours ago | root | parent | next [\u2013]> I don't want to be part of the ecosystem.We're part of that ecosystem whether we want to be or not.As the beneficiaries of free content, it seems like a complete non-issue to just say \"no thanks\" when alternatives include: no content, or fully paywalled content. If you're just expecting free content that caters to you in every way possible way, I'm curious how this is sustainable for any author, or why authors should be expected to work this way.> it's actually the best interests of the author that's being looked after, not the users or readersThere are no users/readers if there is no content. There is no content if there are no engaged users/readers. My point is that actively building an audience (good for the author) is actively good for the reader, because it makes continuing to write a viable thing for the author to spend their time on.If you're just coming for a single article and you'll never return again, that's understandable and your prerogative, but you're now a double beneficiary: of the author, and of the readers who do return.> It's as rude as walking up to someone while they're reading a book...I couldn't disagree more. Perhaps the moment you pay for the blog post you'd have more standing to complain about the conditions surrounding its presentation.And I'm also not saying the state of the ecosystem is good, or that I like it. I'm also not saying that the ecosystem can't or shouldn't change. But I think it's unreasonable to expect writers not to have self interests, while taking a stance that is wholly self interested.replyjoshuacc 23 hours ago | root | parent | prev | next [\u2013]It interrupts, yes, but you\u2019re not in a position to judge what is in every individual\u2019s best interest.replyKarunamon 19 hours ago | root | parent | prev | next [\u2013]\"Annoying\" is not synonymous with \"dark pattern\"replyd1sxeyes 15 hours ago | root | parent | next [\u2013]I agree. But there are a few things which I think make this a dark pattern: the modal pops up after scrolling far enough down that you\u2019re absorbed in the content, the \u201ccontinue reading\u201d is not styled as a button, and is accompanied by a chevron to the right which implies navigation away from the current content (I want to scroll down, not go right).replyfastball 19 hours ago | root | parent | prev | next [\u2013]Right, I don't think \"interrupting\" is a dark pattern intrinsically.YouTube ads interrupt the middle of your video and they're not a \"dark pattern\".replyscarface_74 21 hours ago | root | parent | prev | next [\u2013]How is it a \u201cdark pattern\u201d when the link is clear \u201ccontinue reading\u201d?replysimonw 20 hours ago | root | parent | next [\u2013]Because people don't read microcopy, and the designers of that subscribe widget know that.A lot of people, when faced with that box, will miss the \"continue reading\" button and assume they have to subscribe to finish reading the article.replyscarface_74 19 hours ago | root | parent | next [\u2013]It\u2019s not \u201cmicro copy\u201d even on a phone it\u2019s a normal font size and saw it immediately.Is \u201cdark pattern\u201d the new \u201cmonopoly\u201d on HN - ie \u201canything a company does that I don\u2019t like\u201d?replysimonw 17 hours ago | root | parent | next [\u2013]Microcopy doesn't mean small in terms of font size: https://uxwritinghub.com/what-is-microcopy/Dark pattern is a well defined term too: https://en.wikipedia.org/wiki/Dark_patternreplylelanthran 1 day ago | parent | prev | next [\u2013]Medium annoys me no end.How hard can it be to have a dark mode?[1]If someone's self hosted blog doesn't have a media query for dark mode, that's fine, but a platform that sells a itself as the authoring platform should make that minimal effort to prove a second colour palette.[1] Maybe this has changed since I last read a medium article.replymoffkalast 23 hours ago | root | parent | next [\u2013]> How hard can it be to have a dark mode?So hard that most of the internet doesn't have it. Easier to just use a dark reader extension that inverts colours.replyspyder 19 hours ago | parent | prev | next [\u2013]Same and it pops up only when you are in the middle of reading (on scrolling down) which was so distracting I didn't even continue reading.Probably they know or measured that immediately showing pop up on a page load gets ignored and closed so they sneaked in the middle of reading, together with the small print dismission text they look pretty UX evil.replytroupo 1 day ago | parent | prev | next [\u2013]> What motivates people to write on such platforms?Unlike Medium, Substack's purpose is literally to let authors get money for their writing.And you can dismiss that modal by pressing Esc, or by clicking \"continue reading\".replyWA 1 day ago | parent | prev | next [\u2013]You can dismiss the login wall with a single click.replyrifty 1 day ago | root | parent | next [\u2013]Conveniently you can also hit escape to dismiss it.replyabwizz 1 day ago | root | parent | prev | next [\u2013]it's more the fact that i have to that is the problemreplye12e 19 hours ago | prev | next [\u2013]Nice article(s)! I also found this older one from Kagi interesting (posted in another thread - and to hn, bit without traction):https://blog.kagi.com/kagi-ai-search#philosophyreplyjmainh 13 hours ago | prev | next [\u2013]Maybe Phind is missing, at least for programming and in some cases obtaining technical information about something related to programming is really useful.replymellosouls 1 day ago | prev | next [\u2013]Excellent article. Perhaps for the next version some coverage of audio options; speech, music etc.replys9w 22 hours ago | prev [\u2013]> These systems are built around models that have built-in biases [...] (if you ask it to create a picture of an entrepreneur, for example, you will likely see more pictures featuring men than womenHow is that a bias? That's realityreplysimonw 20 hours ago | parent | next [\u2013]You should revise the meaning of \"bias\". Bias does not mean an unfair thing that is not reflected in reality.replyvisarga 21 hours ago | parent | prev [\u2013]`reality we don't likereplyGuidelines | FAQ | Lists | API | Security | Legal | Apply to YC | ContactSearch:",
    "hn_summary": "- Current AI services may store and use inputs without clear definition of abuse prevention or option to disable safeguards.\n- OpenAI's data retention policies and API access differ from other LLM vendors.\n- Some users express frustration with OpenAI not releasing a better model and question the trustworthiness of different vendors.\n- Specialization in AI models improves quality for different tasks.\n- AI models like Claude 100K and Whisper have potential for various applications.\n- Some users discuss the annoyance of login walls on certain websites."
  }
]
