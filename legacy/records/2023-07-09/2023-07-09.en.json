[
  {
    "id": 36644895,
    "timestamp": 1688827413,
    "title": "When an app asks for permissions, it should have a \"feed fake data\" option",
    "url": "https://mastodon.gamedev.place/@Nifflas/110668040598715116",
    "hn_url": "http://news.ycombinator.com/item?id=36644895",
    "content": "Nifflas@Nifflas@mastodon.gamedev.placeWhen an app asks for permissions, the OS should not only let you answer yes or no. Every category should have a \"yes, but feed the app fake data\" option.Want my contacts for no reason? Have these generated fake ones! Wanna listen to my microphone? Here's random ambiance sounds! Location? I'm on a tiny 5x5m island!Hell yeah! Put it all in your databases mfers!Actively punishing services wins over boycotts any day. Didn't want that junk in the database? Don't ask for it!Jul 06, 2023, 16:18 \u00b7 Edited Jul 06, 16:33 \u00b7 \u00b7 Mastodon for Android \u00b73.4K\u00b74.5KNifflas@Nifflas@mastodon.gamedev.placeWhen an app asks for permissions, the OS should not only let you answer yes or no. Every category should have a \"yes, but feed the app fake data\" option.Want my contacts for no reason? Have these generated fake ones! Wanna listen to my microphone? Here's random ambiance sounds! Location? I'm on a tiny 5x5m island!Hell yeah! Put it all in your databases mfers!Actively punishing services wins over boycotts any day. Didn't want that junk in the database? Don't ask for it!Jul 06, 2023, 16:18 \u00b7 Edited Jul 06, 16:33 \u00b7 \u00b7 Mastodon for Android \u00b73.4K\u00b74.5K",
    "summary": "- When an app asks for permissions, users should have the option to provide fake data instead of granting full access.\n- This approach would allow users to protect their personal information while still being able to use the app.\n- Actively punishing services by feeding them fake data can be more effective than boycotting them.",
    "hn_title": "When an app asks for permissions, it should have a \u201cfeed fake data\u201d option",
    "original_title": "When an app asks for permissions, it should have a \u201cfeed fake data\u201d option",
    "score": 957,
    "hn_content": "- Discussion revolves around the idea of app permissions and the need for a \"feed fake data\" option.\n- Users express frustration with apps that require an account to function.\n- Apple's policy regarding punishment for denying permission is mentioned, with some skepticism about its enforcement.\n- Users discuss various examples of apps that require or don't require an account to run.\n- There is mention of XPrivacy, an app that provided fake data, and the disappearance of similar features in LineageOS.\n- The need for user control over their devices and the idea of a \"free market\" app ecosystem is raised.\n- Users highlight the importance of privacy and control over personal data.\n- The discussion touches on the debate surrounding DRM and the rights of content creators.\n\nThe most important thing to note is the ongoing debate about users' control over their data, the impact of app permissions, and the need for transparency and accountability from app developers and device manufacturers. The discussion highlights concerns about privacy and user autonomy, and the potential for new developments in the future.- Users discuss the implementation of region localization on the App Store, expressing dissatisfaction with the current system and suggesting alternative solutions.\n- Users also discuss the use of DRM (Digital Rights Management) in streaming apps and its impact on taking screenshots while streaming content.\n- Some users propose the idea of having an option to feed fake data to apps that request permissions, while others debate the feasibility and effectiveness of such a feature.\n- The conversation touches on the limits of user privacy and the role of app developers and app stores in ensuring user control over their data.\n- There are references to eugenics and natural selection, but these comments are not central to the main discussion.\n- The use of fake data in GPS and location-based apps is briefly mentioned, with users expressing the need for greater control over location data sharing.",
    "hn_summary": "- Ongoing debate about users' control over their data, the impact of app permissions, and the need for transparency and accountability from app developers and device manufacturers.\n- Concerns about privacy and user autonomy, and the potential for new developments in the future.\n- Discussions on the implementation of region localization on the App Store, dissatisfaction with the current system, and suggestions for alternative solutions."
  },
  {
    "id": 36643670,
    "timestamp": 1688818726,
    "title": "If PEP 703 is accepted, Meta can commit three engineer-years to no-GIL CPython",
    "url": "https://discuss.python.org/t/a-fast-free-threading-python/27903/99",
    "hn_url": "http://news.ycombinator.com/item?id=36643670",
    "content": "James Webberjamestwebber13dChris Angelico:pmf = sum(counters) # does this work? can't rememberThis will work as long as you give it an initial empty Counter to start with (otherwise it starts with 0 and complains)1",
    "summary": "- The statement \"pmf = sum(counters) # does this work? can't remember\" will work if an initial empty Counter is provided.\n- Without an initial empty Counter, the statement will start with 0 and raise an error.\n- This information is relevant for understanding how to use the statement correctly in programming.",
    "hn_title": "If PEP 703 is accepted, Meta can commit three engineer-years to no-GIL CPython",
    "original_title": "If PEP 703 is accepted, Meta can commit three engineer-years to no-GIL CPython",
    "score": 600,
    "hn_content": "- PEP 703, if accepted, could lead to the removal of the Global Interpreter Lock (GIL) in CPython.\n- The removal of the GIL would not break the majority of existing Python code, but it would require a new ABI and potential changes to existing C-API extensions.\n- The transition to a GIL-less Python would involve rebuilding and updating C-API extensions, which could be a major undertaking for codebases that heavily rely on them.\n- The GIL has been a key factor in Python's popularity and ease of writing extensions, but its removal would offer improved parallelism and performance.\n- The proposed change is still under discussion and has gained support from many in the Python community, but caution is warranted due to the potential impact on existing code and the need for proper tooling and support.- Guido van Rossum, the creator of Python, has stated that Python 4 is considered taboo and is unlikely to happen.\n- The Python core development team has learned from the transition from Python 2 to Python 3 and wants to avoid similar compatibility issues.\n- Python now follows a strict annual release schedule, with the version numbering going up to 3.99 before adding another digit.\n- There are discussions and proposals, such as PEP 703, to make changes to Python, including the option to disable the Global Interpreter Lock (GIL).\n- Facebook (Meta) has committed to investing engineer years in improving the Python interpreter and making it possible to disable the GIL.\n- The debate includes discussions about how other interpreted languages handle similar issues and the trade-offs involved.\n- Meta (formerly Facebook), along with other FAANG companies, has made significant contributions to open source projects, such as React, PyTorch, TensorFlow, Chromium, and more.\n- There is a discussion about the responsibility of large companies to give back to the open source community, and the potential benefits and limitations of different open source licenses.",
    "hn_summary": "- PEP 703, if accepted, could lead to the removal of the Global Interpreter Lock (GIL) in CPython, offering improved parallelism and performance.\n- The transition to a GIL-less Python would require rebuilding and updating C-API extensions, which could be a major undertaking for codebases heavily relying on them.\n- Facebook (Meta) has committed to investing engineer years in improving the Python interpreter and making it possible to disable the GIL."
  },
  {
    "id": 36642796,
    "timestamp": 1688808492,
    "title": "Software engineers hate code",
    "url": "https://www.dancowell.com/software-engineers-hate-code/",
    "hn_url": "http://news.ycombinator.com/item?id=36642796",
    "content": "Software EngineeringSoftware engineers hate code.Dan CowellJul 8, 2023 \u2022 4 min readA software engineer recoils in disgust from a screen full of code - Photo by Nubelson Fernandes / UnsplashThis is the best-kept secret of the software engineering profession: engineers hate code. Especially code written by other people. It's why they love working on greenfield projects so much. No code, no maintenance, no headaches!Ever wondered why microservices took off in teams of all sizes? A microservice architecture is the perfect way to pretend that the code you wrote last month no longer exists! Now that it has been stuffed into a container and tucked behind a load balancer it's a service and we can forget all about it until it breaks, then we deprecate it as legacy and replace it with something new. Rolling green fields forever!Got a question about how one of your dependencies works? You could look at its implementation, or the test suite, but most engineers prefer to go to the place that everyone congregates to talk about - but not look at - code. Stack Overflow is a great resource for finding the code needed to solve your problem without having to look at a lot of code yourself!I'm sure you've been stuck for hours begging your colleagues to review your pull request. Why do you think it's taking so long? You're asking them to do the thing they hate most - look at someone else's code!Most people reading this have at one point or another approved a non-trivial pull request with a simple \"LGTM.\" You got tagged in on a bad day and didn't have the time to take a proper look at code written by someone else. You had work to do!Only one thing can overcome engineers' hatred of code: their love of writing code.Software engineers will lock themselves in a room and do nothing but write code for hours. Some forget to eat, sleep or poop.Notable engineers online invest hours of time writing about their code, or about how they write code. Paradoxically, engineers love reading this stuff, even if they never read the example code attached!Meetings of all kinds, technical and user documentation, testing, post-release monitoring, refactoring - all are common sources of frustration that cut into valuable time that could otherwise be spent writing code!Engineers will spend enormous effort learning or building tools to help them write more code. In the past couple of years, we've seen an entirely new generation of tooling emerge that can actually write code by itself, turning 10x engineers into 1,000x engineers*!* Scientists observing engineers using AI in the wild have seen them writing 100x more SLOC/hour!Rarely, you will encounter engineers who have learned to temper their baser instincts and instead find a sick kind of joy in reading, understanding, modifying and even deleting other peoples' code. We call these odd folks \"Senior Engineers.\"Senior engineers have learned through hard-won experience that writing code is the ultimate diminishing return.They know that code becomes legacy the moment the first byte is saved to disk. The rolling green fields of their youth are a happy delusion, distracting from the cold, hard truth that all code demands maintenance. They have felt the pain of an unmaintained system breaking at the worst possible time.There are a limited number of hours in the day. The more code that gets written, the more things there are to break, and more of those precious hours will be taken up by maintenance.The only logical course of action is to minimize the amount of code in production at any given time. Senior engineers' passion for writing code has been augmented with an even stronger desire to delete it.Code that doesn't exist can't hurt us, or the people we love.It demands no maintenance; it causes no downtime; it requires no testing. Senior engineers understand that unnecessary code should be eliminated at all costs, and all new code must prove its worth before being allowed to live. This is part of what drives them to pore over other peoples' code and provide meticulous review.This isn't to say that senior engineers are cynics. There's still beauty to be found in creating an elegant solution to a complex problem. The joy of creation hasn't diminished, but it has been tempered by an understanding that less is more, and that every line of code they write comes at a cost.Senior engineers hate extraneous code. They hate seeing time and effort invested in building yet another solution to an already-solved problem. They hate code that doesn't need to exist; code that isn't providing value.Be mindful of the cost that your code incurs.Don't write new code when you can use, improve or fix what already exists. If you must write new code, write only what you need to get the job done.Understand your tools, and the systems your code runs on. Leverage the features of those systems to minimize the code you need to write, and by extension, the cost that it imposes on you and your team.\ud83d\udca1Some artistic liberties have been taken in this post for the sake of the narrative, however the qualities described above reflect attitudes I've witnessed in engineers that I've worked with in the past.There's more to being a senior engineer than just a healthy skepticism about writing code to solve a problem, but it's an important quality to develop, and will serve any engineer well.\ud83d\udcacThere\u2019s a great discussion about this post going on on Hacker News. Join the conversation!",
    "summary": "- Software engineers often dislike working with code, especially code written by others. They prefer greenfield projects that require minimal maintenance and troubleshooting.\n- Stack Overflow is a popular resource for finding code solutions without extensive code analysis. \n- Senior engineers prioritize minimizing unnecessary code and deleting existing code, understanding that code incurs maintenance and risk. They advocate for improving and reusing existing code rather than creating new solutions.",
    "hn_title": "Software engineers hate code",
    "original_title": "Software engineers hate code",
    "score": 341,
    "hn_content": "- Software engineers often dislike working with existing code because it can be complex and difficult to understand. They prefer working on greenfield projects where they can start from scratch and avoid the challenges of maintaining and modifying existing code.\n- However, there are engineers who enjoy the process of working with existing code, improving it, and adding new features. They see it as a way to gain a deep understanding of the codebase and make incremental improvements.\n- The analogy of a house is used to describe the frustration that engineers feel when they have to deal with code that was written by others and may not meet their standards. The analogy highlights the importance of well-designed code and the challenges that arise when it is not maintained properly.\n- It's important to strike a balance between writing new code and working with existing code. Sometimes a rewrite from scratch is necessary, especially if the existing codebase is outdated, difficult to maintain, or doesn't meet modern requirements.\n- The decision to rewrite code should be based on a careful cost-benefit analysis, considering the projected costs of maintaining the existing code and the potential benefits of a rebuild. It's important to weigh the long-term impact and potential risks of both options.\n- LGTM (Looks Good to Me) culture, where code reviews are not thorough and everything is approved quickly, is not conducive to maintaining high-quality code. It's important to take the time to review and improve code, even if it means investing more effort upfront.\n- Good engineers should take pride in their work, strive for clean and maintainable code, and understand the long-term benefits of writing quality code. They should aim to create a smooth running system that is easy to maintain and extend.\n- Rebuilding code from scratch should be approached with caution and considered in the context of the specific project and its requirements. It's important to weigh the risks, costs, and potential benefits of a rebuild before making a decision.- Employing software developers requires delivering value at a minimum cost, otherwise developers may lose their jobs.\n- Hidden costs of software development only become apparent when they are no longer bearable.\n- Well-designed software can hide costs for longer periods of time compared to poorly designed software.\n- Following the advice to use existing code can be difficult for developers in practice.\n- Refactoring existing code to align with current standards can reduce the cost of maintaining it.\n- Reusing code can lead to issues if not done carefully, potentially breaking other components.\n- Tests can help prevent issues when reusing code.\n- Building a wrapper around a codebase can lead to entanglement and maintenance issues in the future.\n- Understanding the structure and evolution of code requires going through the journey of writing it.\n- Reading code and looking at implementations can be productive for learning and understanding.\n- The process of shaping and updating old software can be enjoyable and rewarding.\n- Developers appreciate simplicity within the complexity of code, as it either works or it doesn't.\n- Code that is simple, documented, and well-written is easier to maintain and understand.\n- Engineers are motivated to maximize the ratio of their own code to others' code.\n- Engineers may dislike code that is designed to impress or show off, as it can lead to complexities and difficulties in maintenance.\n- Readable code is hard to achieve but leads to maintainable code and reduces technical debt.\n- Management may see developers as expensive and try to replace them with code-free solutions.\n- Skilled software engineers learn to work with and improve other people's code.\n- There are times when code needs to be rewritten, but often it is due to a lack of practice and skill in code surgery.\n- Bugs and dependencies make code surgery and improvements necessary.\n- Some engineers struggle with reading code due to getting bored or glossing over details.\n- Working with horrible code and feeling disempowered can cause frustration for software engineers.",
    "hn_summary": "- Software engineers often dislike working with existing code because it can be complex and difficult to understand.\n- It's important to strike a balance between writing new code and working with existing code, considering the projected costs of maintaining the existing code and the potential benefits of a rebuild.\n- Good engineers should take pride in their work, strive for clean and maintainable code, and understand the long-term benefits of writing quality code."
  },
  {
    "id": 36645575,
    "timestamp": 1688831779,
    "title": "Langchain Is Pointless",
    "url": "https://old.reddit.com/r/LangChain/comments/13fcw36/langchain_is_pointless/",
    "hn_url": "http://news.ycombinator.com/item?id=36645575",
    "content": "MY SUBREDDITSPOPULAR-ALL-RANDOM-USERS | ASKREDDIT-WORLDNEWS-GAMING-FUNNY-PICS-NEWS-MOVIES-EXPLAINLIKEIMFIVE-TODAYILEARNED-LIFEPROTIPS-TIFU-TWOXCHROMOSOMES-OLDSCHOOLCOOL-JOKES-VIDEOS-DATAISBEAUTIFUL-SHOWERTHOUGHTS-AWW-GIFS-BOOKS-SCIENCE-IAMA-ASKSCIENCE-DIY-MUSIC-NOSLEEP-UPLIFTINGNEWS-FOOD-SPACE-FUTUROLOGYMORE \u00bbreddit.com LangChaincommentsother discussions (3)Want to join? Log in or sign up in seconds.|Englishthis post was submitted on 12 May 2023109 points (97% upvoted)shortlink:remember mereset passwordloginSubmit a new linkSubmit a new text postGet an ad-free experience with special benefits, and directly support Reddit.Get Reddit PremiumLangChainjoin4,565 readersa community for 5 monthsMODERATORSMESSAGE THE MODSdiscussions in r/LangChain<>XDo Any Tools Using LangChain?Welcome to Reddit.Come for the cats, stay for the empathy.BECOME A REDDITORand start exploring.\u00d7109Langchain is pointless (self.LangChain)submitted 1 month ago * by SuperConductiveRabbiIt's filled with crap like this:  for i in range(n_results, 0, -1):    try:      return self._collection.query(        query_texts=query_texts,        query_embeddings=query_embeddings,        n_results=i,        where=where,        **kwargs,      )and this:def embed_documents(self, texts: List[str]) -> List[List[float]]:  texts = list(map(lambda x: x.replace(\"\\n\", \" \"), texts))  embeddings = self.client.encode(texts, **self.encode_kwargs)  return embeddings.tolist()and this:class CharacterTextSplitter(TextSplitter):  \"\"\"Implementation of splitting text that looks at characters.\"\"\"def __init__(self, separator: str = \"\\n\\n\", **kwargs: Any):  \"\"\"Create a new TextSplitter.\"\"\"  super().__init__(**kwargs)  self._separator = separatordef split_text(self, text: str) -> List[str]:  \"\"\"Split incoming text and return chunks.\"\"\"  # First we naively split the large input into a bunch of smaller ones.  if self._separator:    splits = text.split(self._separator)  else:    splits = list(text)In short: https://i.imgur.com/OffEJTR.gifvEmbeddings is just a do-nothing wrapper for SentenceTransformers. Chroma is just a do-nothing wrapper for ChromaDB. It's filled with \"helper\" functions that just call normal Python functions. A dedicated TextSplitter that calls split() from builtins.py? What? Why? Templates are no more useful than calling .replace() on a string. \"texts\" are just strings and \"documents\" are just a pointless dict that contain \"texts.\" Just load the strings from your datasource yourself. The README is both grandiose and vague. The documentation is out-of-date and inconsistent. The import footprint is weirdly massive--highly modularized but nothing seems to do anything that'd take more than a few CPU cycles. There's not really a standard interoperable datatype, so you're actually led further afield than if you had just clearly defined the simple lists and strings required for hitting an LLM.The very concept of chaining operations when interacting with LLMs doesn't really make sense to me: it's basically one requests call to a generation backend, but it's not like it even handles websockets and streaming for you. Why chain together wrapper classes when you can just do the operations yourself?This seems like a beginner's project that blew up because it's riding a tidal wave of interest in the broader topic.106 commentssharesavehidereportall 106 commentssorted by: bestWant to add to the discussion?Post a comment!CREATE AN ACCOUNT[\u2013]catpissflannigan 27 points 1 month ago Langchain is unfortunately very poorly designed and is filled with overlapping abstractions which leads to a lot of confusion. The documentation suffers from poor organisation toopermalinkembedsavereportreply[\u2013]SuperPanda09 6 points 1 month ago So I will be very honest. We found langchain documentation to be very poor. For using internally, we made something like a ChatGPT on top of Langchain's code and docs. hosted it on https://langchainx.web.app/.We are eventually not using any langchain functions or helpers but still keeping the portal available for the langchain community. Let me know if you use it and find it helpfulpermalinkembedsaveparentreportreply[\u2013]krrish253 1 point 1 month ago Can you think of any alternative of langchain for now?permalinkembedsaveparentreportreply[\u2013]catpissflannigan 2 points 1 month ago Griptapepermalinkembedsaveparentreportreply[\u2013]mapcat 1 point 14 hours ago GriptapeOnly Python? No thankspermalinkembedsaveparentreportreply[\u2013]Just-Contribution834 1 point 10 days ago I AM LOOKING FOR LITERALLY ANY ALTERNATIVE TO LANGCHAIN that is not in python,anything that is .net or .cppPLEASE!!!permalinkembedsaveparentreportreply[\u2013]dev-8060 1 point 17 hours ago How about Ruby? Check out the boxcars gem - https://github.com/BoxcarsAI/boxcarspermalinkembedsaveparentreportreply[\u2013]UniversalJS 1 point 16 hours ago Op seems to look for an efficient version... So going from python to Ruby is not helpingpermalinkembedsaveparentreportreply[\u2013]dammit_reddit_ 1 point 15 hours ago An efficient version of a library that chains slow as fuck non-deterministic APIs over http? Any efficiency gain would be indistinguishable.permalinkembedsaveparentreportreply[\u2013]5fec 1 point 11 hours ago As u/damnit_reddit_ points out you seem confused about the idea of efficiency and speed in software engineering. How could this problem possibly be CPU-bound on the client side? GP is presumably asking for .NET or C++ because that is their ecosystem. Either that or they share your confusion.permalinkembedsaveparentreportreply[\u2013]UniversalJS 1 point 5 hours ago Not really, question for you why the OP asked for anything else than the python version?permalinkembedsaveparentreportreply[\u2013]5fec 1 point 5 hours ago It sounds like they don't like Python. But Python's slow interpreter speed relative to compiled languages isn't relevant in an IO-bound problem like this. If I had to guess, GP doesn't understand that. You get it, right?permalinkembedsaveparentreportreply[\u2013]UniversalJS 1 point 5 hours ago I'm not sure about your interpretation ... OP is talking about .NET & C++ those 2 languages have types and are pretty perfomant in all aspects.On the other side Ruby is similar to python that OP doesnt like...permalinkembedsaveparentreportreply[\u2013]5fec 1 point 2 hours ago Look I'm sorry if this seems patronizing but I'm trying to help you here :) It seems like we're both programmers, so I'm thinking that we both get some pleasure out of understanding the field. There's something you're not understanding, but I've mentioned it twice (and the sibling commenter once) and you're not stopping to think about what we're saying: this problem is \"IO-bound\". That means that performance is determined by how quickly the network requests get done, not by how quickly the stuff on the client side happens. That means that the choice of language on the client side is 100% irrelevant to performance in this case. Please research what I'm saying if it's not clear! It's a good thing to understand.permalinkembedsaveparentreportreplycontinue this thread[\u2013]azhenley 1 point 16 hours ago Semantic Kernelpermalinkembedsaveparentreportreply[\u2013]StefanSabev 1 point 15 hours ago .netsemantic kernel is in .netpermalinkembedsaveparentreportreply[\u2013]pixiedustnomore 1 point 15 hours ago Not very popular: https://github.com/LagPixelLOL/ChatGPTCLIBotpermalinkembedsaveparentreportreply[\u2013]PhroznGaming 1 point 13 hours ago .NET == Semantic Kernelhttps://github.com/microsoft/semantic-kernelpermalinkembedsaveparentreportreply[\u2013]Spitfire3788 1 point 11 hours ago We launched in mid of January and are working on improving architecture design, usability and debugging of neuro-symbolic systems with strong focus on LLM research.https://github.com/Xpitfire/symbolicai https://symbolicai.readthedocs.io/en/latest/README.htmlpermalinkembedsaveparentreportreply[\u2013]uhohritsheATGMAIL 19 points 1 month ago I don't disagree, but I'm mostly here for the interoperability + agents.This is one of those 'Yes I know how to code, no I don't want to spend hours working on boilerplate.'permalinkembedsavereportreply[\u2013]119b63 2 points 10 days ago Eh, except when the boilerplate is an obstacle. Try building a retrieval QA chain _with_ memory using langchain. You can't unless you override one of the chain's prompt templates. Which means you have to dig into the code with a debugger to figure out exactly where it happens and what to do.Cobbled together the same exact thing with plain openai and chromadb in like an hour. If you know what you're doing sometimes langchain works against you. And I'm a huge fan of libraries and frameworks and whatever makes your life easier but I found langchain to, well, not do that.Even agents are simply loops with a carefully crafted prompt that gives you whatever you need in the right format so you can use it to call external functions (which is now kinda pointless with openai's function calls). The value added of langchain, so far, doesn't justify its bloatedness.permalinkembedsaveparentreportreply[\u2013]uhohritsheATGMAIL 2 points 10 days ago Yes I agree.Lucky that as you mentioned, you can throw that example together in an hour.permalinkembedsaveparentreportreply[\u2013]whyzantium 25 points 1 month ago Say you wrote a program without langchain that uses GPT3.5 as a language model, chroma for your vector store, and you wrote some code for splitting your text docs.Now let's say a week later you want the same program to use a local Llama language model, faiss for vectors, and a want to split PDF docs instead of text docs.You'd pretty much have to rewrite the whole thing.But because langchain's codebase is written with substitutionality at its core, you could swap out the model, vector store and splitter in under a minute.That's not the only reason to use langchain of course. But these kind of libraries are written in a way that saves you time in the long run.If you just want to write a one off script, then of course you could do this without langchain.permalinkembedsavereportreply[\u2013]SuperConductiveRabbi[S] 4 points 1 month ago That's definitely a risk, but the solution isn't to abstract everything you possibly can. Are you really going to want to split your text with a different underlying text splitter? No. The solution is to be smart about what you plan for. We know models change constantly so you should abstract that--make an interface with _call like Langchain does, that makes sense, then your consumer code can be agnostic as to whether it's hitting OpenAI, ooba, kobold, etc.permalinkembedsaveparentreportreply[\u2013]allisonmaybe 2 points 1 month ago LangChain has a place in the world and the ability to swap out functionality could have a lot of value to the discerning user. That said, most of Langchain use is for TikTok hypepermalinkembedsaveparentreportreply[\u2013]Icaruswept 2 points 9 days ago* Not true. I got stuck in this specific use case and ended up spending pointless days trying to figure out the data types langchain is passing underneath its poorly documented classes.It\u2019s a nice springboard in theory, but in practice it turned out to be far easier to just write my own functions (with the exception of using llangchain to load the model; it\u2019s a wrapper on top of the python llama.cpp library, and doesn\u2019t do much, but it\u2019s readable).permalinkembedsaveparentreportreply[\u2013][deleted] 1 month ago [deleted][\u2013]chat_harbinger 3 points 1 month ago Main problem is how do you write a program that uses gpt 3.5 as a language model if langchain don't let you change a prompt. It is a huge task to rewrite a prompt for something more specific.Is this a joke or are you actually this bad at programming?If you answer me without getting offended, I'll tell you exactly how to do it.permalinkembedsavereportreply[\u2013]Nokita_is_Back 3 points 1 month ago Wo you woke up and chose to be a gaslighting cunt ey?permalinkembedsaveparentreportreply[\u2013][deleted] 1 month ago [deleted][\u2013]chat_harbinger 1 point 1 month ago Choosing to remain ignorant isn't the optimal decision, but it certainly is a bold one.permalinkembedsavereportreply[\u2013]water_bottle_goggles 3 points 1 month ago \ud83e\udd26you can change the prompts of the chainpermalinkembedsavereportreply[\u2013][deleted] 1 month ago [deleted][\u2013]Narrow-Importance65 0 points 18 days ago just open that file and change the prompt what is so hard about it?permalinkembedsavereportreply[\u2013]uhohritsheATGMAIL 0 points 1 month ago Want to code in Spanish? Portuguese? French?No, I never have.permalinkembedsavereportreply[\u2013]SnooCompliments7527 1 point 1 day ago In practice, no foundation model beats the OAI suite and you'd probably have to redo much of your prompts (and maybe some of your internal logic anyway) if you wanted to switch away.On the vector db front, I am not as certain, but I'm still pretty certain that Chroma will be a top tier competitor for the foreseeable future.That said, even if you did decide you wanted to move away from the OAI suite, langchain poorly abstracts over it, hence why langchain's Anthropic is \"model_name\" and langchain's OAI is \"model\" (or the other way around, I forget).permalinkembedsaveparentreportreply[\u2013]zeugmasyllepsis 1 point 15 hours ago But because langchain's codebase is written with substitutionality at its core, you could swap out the model, vector store and splitter in under a minute.Pragmatically, that has not been my experience. I've been digging into Langchain over the last few months for just this promise. In reality, swapping between models leads to a rabbit hole of installing new dependencies (sometimes requiring custom configuration or compiling from scratch - like bitsandbytes), swapping custom document logic out for a JSONLoader errors because of shell escaping issues in the underlying jqbindings, and you burn time trying to figure out exactly what the difference between load_qa_chain(..) and RetrievalQA.from_chain_type(..) are.I think the motivation behind Langchain is good. The ecosystem is hungry for abstractions over common use-cases and components, but the landscape as a whole is still so unstable, and it's not clear that Langchain has identified the right abstractions yet to me. Too many details leak through from underlying implementations, too much overlap between components, and the rate of change fast outpacing the documentation to support those changes. Hopefully contributors keep driving the project to something closer in quality to the Scikit-Learn model interfaces, and are able to deliver on the promise of seamless swapability.permalinkembedsaveparentreportreply[\u2013]Weaves87 1 point 10 hours ago I agree with your thoughts 100%.LangChain leads you to believe you can easily abstract away which LLM you're using, but my experience has shown this is not the case in practice.For these applications, 80% of the work is going to be the prompt engineering. You aren't going to get the same reliable quality results from different LLMs using the same prompts. I've noticed that often times you need to dramatically change some prompts, depending on the model you're using.Because of this, a lot of the abstractions LangChain exposes are kind of wasted effort and just unnecessarily adding to overall complexity.Sure, you can hotswap which LLM you're using with LangChain's composable approach: but what's the use of that simple one line change when you wind up having to rewrite all of the prompts anyway? You may as well had used an official API - especially because the official APIs (e.g. OpenAI, HuggingFace Transformers, etc) support newer features much sooner, and in my experience tend to be way more stable and fast.I really, really want to like LangChain. It does have some good stuff and I think there are noble intentions behind some of its design principles. But I had way too many issues with some things being broken (streaming tokens from OpenAI), very frequent API changes that completely break my code in sometimes silent ways, and just having to wrestle with some of the abstractions way too much.In the end I wound up writing my own code in far less time, and just borrowed a few conceptual principles from LangChain, and I couldn't be happier with this approachpermalinkembedsaveparentreportreply[\u2013]Les-El 8 points 1 month ago Idk, man. I can't code. Like, seriously, I need to look up how to try statements. But with LangChain, I've got my own custom chatbot who even gives me lip from time to time. I hope to have him browsing on his own by this weekend. And when I decide it's time to change my prompts, or my tools, or even my LLM, the modular switching out is super easy.I would say LangChain has its points.permalinkembedsavereportreply[\u2013]SuperConductiveRabbi[S] 3 points 1 month ago It does look like a good way for beginners to get started, and the tutorials tend to be short, as long as you don't stray away from what they want to do. But as you want to do more advanced things I think you can naturally learn more (and ask ChatGPT how to learn what you need, too). So maybe \"pointless\" is too harsh. But the README and the hype does make it seem like it's more advanced and deeper than it is.permalinkembedsaveparentreportreply[\u2013]ladybaybee 1 point 1 month ago What are the more advanced things that I can ask GPT to teach me? Actually very curious, I\u2019ve started to play with LangChain but already seems like I am late to the party. Incredible how fast things are movingpermalinkembedsaveparentreportreply[\u2013]SuperConductiveRabbi[S] 1 point 1 month ago Basically ask it anything you'd ever ask a programmer sitting there with you. It can be basic, like, \"what does def __init__(self) do?\" or \"I'm new to Python and using LangChain. I heard it's calling underlying libraries but I don't know what that means. I think I'm using the Pycharm IDE. How can I learn more?\" etc.There's no limit at this point, it's amazing.But if you mean more advanced like, what to do to move beyond LangChain, that depends too on what you want to do. But either see what it's doing under the hood and start there (like run SentenceTransformers yourself, make your own prompt templates, etc.) or pick some project you'd like to accomplish.permalinkembedsaveparentreportreply[\u2013]crazysim 4 points 1 month ago I think of it like an ORM. A lot of the comments around here seem to be similar to ones in ORM vs non-ORM debates. I think there's a place and time for both.permalinkembedsavereportreply[\u2013]allisonmaybe 4 points 1 month ago I'm sure the entire thing was whipped up in the first month of this new AI revolution. I never quite thought any of these toolkits were amazing considering how quickly they came out. The hype train is a hell of a drug tho.I'm working on an LLM toolkit of my own that includes context management, embedding tools, an embedding based command chooser, chaining, and optimized TTS that works with chunks as they're coming in.More than anything it's a way to learn all I possibly can about LLMs and how to work with them. Its not quite there yet but considering it's only been 3 months since chat came out, that's understandable.permalinkembedsavereportreply[\u2013]Zealousideal-Cry7806 2 points 1 month ago So what is the lesson here? Should I just look for particular libs to recreate what langchain is doing?permalinkembedsavereportreply[\u2013]kyrodrax 3 points 1 month ago Seen this one? https://www.reddit.com/r/Python/comments/13djuec/github_griptapeaigriptape_python_framework_for_ai/?utm_source=share&utm_medium=ios_app&utm_name=ioscss&utm_content=1&utm_term=1permalinkembedsaveparentreportreply[\u2013]SuperConductiveRabbi[S] 1 point 1 month ago If you're a beginner I'd recommend starting with Langchain, nothing wrong with that. But as you go use \"go to declaration\" in your IDE from time to time and see what it's doing under the hood. In most cases you can just use the underlying library, like the examples I gave above.permalinkembedsaveparentreportreply[\u2013]fujiitora 2 points 1 month ago Yeah, a higher up wanted me to base a project off of this, but constant bugs and improper documentation led me to just building my own tooling :/permalinkembedsavereportreply[\u2013]productboy 2 points 1 month ago Came for the abstraction; stayed for the agents\u2026permalinkembedsavereportreply[\u2013]NSynca 2 points 1 month ago just prototyped something simple for js/ts: https://github.com/gsidsid/gptio. imo just making custom tools the default practice for ppl adding long term memory or document stuff is the way, esp when it's all evolving so quick. obv there are limits to this approachpermalinkembedsavereportreply[\u2013]Holiday_Piccolo3380 2 points 1 month ago My favorite is the PrompTemplate class AKA an f string !!!!permalinkembedsavereportreply[\u2013]SnooCompliments7527 1 point 1 day ago Yes, I was personally quite surprised when I realized it was nothing other than an f-string lolpermalinkembedsaveparentreportreply[\u2013]Narrow-Importance65 2 points 18 days ago My main problem with it is how so many modules explain how to do one or two things then if you dig into the code you realize theres like 10 things built in there that arent documented AT ALL. i guess thats what happens when you grow that fast.permalinkembedsavereportreply[\u2013]SnooCompliments7527 2 points 1 day ago The documentation is awful. There are many times that I have to traverse the source code myself to figure out what something does. Even then, it's miserably awful because you find the source code is literally all just func(**kwargs): next_func(**kwargs)...Oh, and tons and tons and tons of Pydantic line noise...permalinkembedsavereportreply[\u2013]chat_harbinger 1 point 1 month ago So where are your push requests, big guy?permalinkembedsavereportreply[\u2013]AlgoTrade 4 points 1 month ago Lmao. It\u2019s a pull request, new guy.permalinkembedsaveparentreportreply[\u2013]chat_harbinger 1 point 1 month ago Ex-fucking-scure you?New to what? Automated, by the way. Every single day I was pushing commits to existing repos that had updates and creating a repo a day for my new work. Everyday for a whole summer. New to what?permalinkembedsaveparentreportreply[\u2013]AlgoTrade 5 points 1 month ago* Lol, it\u2019s a pull request, pal.Even the simplest google would show you that.You push commits to your branch and then open a pull request to merge your code to master.I\u2019m assuming your 2021 internship didn\u2019t work out, but I have some constructive criticism that might make you a better teammate in the future!\u201cOften wrong, but never in doubt\u201d is just about the worst thing you can do when working in a job, be open to criticism and learn from those that came before you. Don\u2019t try to prove how smart you are by fighting, do it by contributing, and learning from other. I think you\u2019d do well to look at your attitude and how you learn from others, we all feel on top of the world when we start, but need to remain humble and remind ourselves that you are sitting on the shoulders of giants.All the best.permalinkembedsaveparentreportreply[\u2013]chat_harbinger 1 point 1 month ago I absolutely cannot wait for people like you to be out of work on breadlines. Can't fucking wait.SMD and die painfully.permalinkembedsaveparentreportreply[\u2013]Best_Mord_Brazil 1 point 17 hours ago I miss this mentality in software. Sometimes pedants like the person replying above you need to feel a little bit of pain.permalinkembedsaveparentreportreply[\u2013]danysdragons 1 point 16 hours ago In this particular case, correcting them is the nice thing to do, since it could save them from embarrassing themselves later in a situation that's much higher-stakes than a reddit thread. It's a correction on a very basic thing, not a pedantic correction on some obscure esoteric point.permalinkembedsaveparentreportreply[\u2013]reredef 1 point 8 hours ago* \u201cPush\u201d vs \u201cpull\u201d is not semantics or pedantry, it means you fundamentally have no clue what DVCS is about. Which marks you as a new guy, exactly as OP said.permalinkembedsaveparentreportreply[\u2013]pickle9977 1 point 16 hours ago Just remember, if you are doing this as a career, your goal should be to be a better engineer tomorrow then you are today, the only way to do that is to be humble, learn from mistakes and realize that today you are the worst programmer you will be for the rest of your life.permalinkembedsaveparentreportreply[\u2013]Trolann 2 points 1 month ago* You don't request a push, you request a pull.And this is the same argument everyone gives when you criticize something they like. 'Well then make your own Twitter!'Or just accept not everything is perfect and be happy people are criticalETA: the TLC got suspended for brigading me into my universities sub and threatening violence.Because he didn't understand git.permalinkembedsaveparentreportreply[\u2013]chat_harbinger -1 points 1 month ago You don't request a push, you request a pull.Oh, okay. So when you're done editing your branch and want to commit changes, what command are you going to give git in bash? Is it git pull, sensei? And when you're ready to merge that branch into the master (that isn't your repo), you're just going to go ahead and do it, right? No approval required, right?Rampant autism in the programming community notwithstanding, you knew what I meant, buddy.And this is the same argument everyone gives when you criticize something they like. 'Well then make your own Twitter!'If you are a programmer and you are saying that something is wrong, and it is a public repo, the mature thing to do would be to fix the problem (the one you so obviously know how to fix since you identified it as a problem, implying a correct reference structure in your mind to compare it to), not whatever this is.Or just accept not everything is perfect and be happy people are criticalWhile critique is generally useful for creators, telling them how they can improve, the fact that folks like you don't view things like LangChain as a communal effort, don't really seem to want to put work in to help improve it, and generally seem to think that having this negative posture in the one of the most interesting epochs of technology development to happen in your lifetime is pretty disconcerting. No one is telling you to stop b!tching, but maybe flex those fingers to whip up some code while you're b!tching.permalinkembedsaveparentreportreply[\u2013]SuperConductiveRabbi[S] 5 points 1 month ago the mature thing to do would be to fix the problemThe Mature Reddit Coding Student fixes his eyes on his dream goal: a gleaming city in the distance, where master programmers are so adept they erect towers that are beautiful and deeply functional. He sets off down the path towards it, and boldly enters the forest. Instantly he notices poor programs all around the path, many of whom have problems, and he's moved to tears. Eyes shimmering, he bends down to fix their problems, even the obviously self-inflicted ones, even the ones where any beginner would know better, even the ones where ten alternative programs may very well exist if he just goes further down the path--he helps them all.Though most programs thank him gladly, for every one he stoops to help, he notices ten more. But he's a good programmer. So he helps and helps. Old friends down the path call out to him, and one even says \"you're wasting your time!\" and \"if you come down here you'll see you shouldn't even bother!\" How dare they! He yells back in anger that they lack perspective, as he stoops again.One day, years later, his nose brushes a pavestone on the path. \"Finally!\" he sighs in relief, as he looks up to see if he's at the city yet. But he's shocked to see he's at the entrance of the forest! All his selfish friends have abandoned him and are specs in the distance. He realizes with dread that there'll be ten-thousand-fold more broken programs along that path all needing the help of a mature programmer like him. It's too much, and he curses everyone else's failure to do the right thing as he storms out of the forest.permalinkembedsaveparentreportreply[\u2013]chat_harbinger 1 point 1 month ago ...We're working on AGi and this is what you think is going to happen?Is this a joke?permalinkembedsaveparentreportreply[\u2013]SuperConductiveRabbi[S] 3 points 1 month ago ...We're working on AGiYou're one push request away from making AGI. Keep goingpermalinkembedsaveparentreportreply[\u2013]Trolann 3 points 1 month ago This whole chain is absolute gold and sadly it's gonna get buried.permalinkembedsaveparentreportreply[\u2013]AlgoTrade 3 points 1 month ago I'm here for it man! And its absolutely hilarious. I'm pretty sure /u/chat_harbinger is the exact type of person that makes LangChain such a joke.permalinkembedsaveparentreportreply[\u2013]SuperConductiveRabbi[S] 1 point 1 month ago People always think I have a problem with being disagreed withI wonder why his internship didn't work out.He blocked me after a snarky reply, so sadly no more back-and-forthpermalinkembedsaveparentreportreply[\u2013]chat_harbinger -1 points 1 month ago If I'm being honest, the number one reason why I think that I Have No Mouth And I Must Scream may occur is because of people being dickheads on the internet.Kinda like you right now.permalinkembedsaveparentreportreply[\u2013]SuperConductiveRabbi[S] 2 points 1 month ago I tried to help you and it didn't work. No one is obligated to tell you what you want to hearpermalinkembedsaveparentreportreply[\u2013]chat_harbinger 0 points 1 month ago The Reddit Autist Socialization Student fixes his eyes on his dream goal: a gleaming city in the distance, where people accept him as an equal and speak to him in ways that are neither derisive nor satirical. He sets off down the path towards it, and boldly enters the forest. Instantly he notices poor redditors all around the path, many of whom need help, and he leaps to action, thinking to himself that this is a chance to demonstrate his value. Eyes shimmering, he bends down to help them, even though the Redditors are telling him in every way they know of to get lost, to beat it, and to just keel over already--he \"helps\" them all.Though most Redditos choose not to block him immediately being a bellend, for every two he stoops to \"help\", one recognizes that he is an utterly hopeless menagerie of neurodivergence and arrogance and decide he's not worth their time.. But he wants desperately to be normal. So he \"helps\" and \"helps\". Redditors who he mistakes for old friends, but who are really people who have barely tolerated his existence and have their fingers hovering over the block button at all times, down the path call out to him, and one even says \"take a fucking hint!\" and \"if you could understand social cues, you'd understand you're not wanted\" How dare they! He yells back in anger that they lack perspective, as he stoops again.One day, years later, his nose brushes a pavestone on the path. \"Finally!\" he sighs in relief, as he looks up to see if he's at the city yet. But he's shocked to see he's at the entrance of the forest! All his \"friends\", who at the very least know how to mask marginally better than him, have abandoned him and are specks* in the distance. He realizes with dread that there'll be ten-thousand-fold more Redditors along that path all needing the \"help\" of a Reddit Autist Socialization Student like him. It's too much, and he curses everyone else's failure to do the right thing as he storms out of the forest.RASShole.permalinkembedsaveparentreportreply[\u2013]SuperConductiveRabbi[S] 2 points 1 month ago I didn't think that me saying your advice was bad would be that offensive to you. My point is that your assumption that developers who discover problems in random open source projects are obligated to help is silly and will distract you from more meaningful work. Langchain is one of those projects that aren't worth it, because they don't do anything novel, and you were being silly and naive for implying it's my fault for not making pull requests to it rather than discussing the problem and abandoning it for something better (the underlying libraries, in this case). Maybe I can allow others to avoid wasting their time on Langchain like I did.And by the way, you're being an asshole too by calling people you disagree with autists, neurodivergent, \"retard assholes,\" etc. Even when they just correct your \"push request\" mistakes.permalinkembedsaveparentreportreplycontinue this thread[\u2013]Seefufiat 1 point 28 days ago Like you being hateful towards neurodivergent people? Weirdpermalinkembedsaveparentreportreply[\u2013]pixelies 1 point 1 month ago \ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\udc80\ud83d\udc80\ud83d\udc80permalinkembedsaveparentreportreply[\u2013]Trolann 2 points 1 month ago Are the other AGi developers in the room with us right now?permalinkembedsaveparentreportreply[\u2013]TotesMessenger 1 point 28 days ago I'm a bot, bleep, bloop. Someone has linked to this thread from another place on reddit:[/r/bestof] /u/SuperConductiveRabbi explains the plight of the push to a youthful programmer in AI.[/r/bestofnopolitics] /u/SuperConductiveRabbi explains the plight of the push to a youthful programmer in AI. [xpost from r/LangChain] If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads. (Info / Contact)permalinkembedsaveparentreportreply[\u2013]Trolann 1 point 1 month ago Ok Mr. Every Problem Must Have A Solution.Maybe if someone doesn't have a solution yet they could post here with their critiques and we could all help? Maybe have a community?Nah, forget it. You make a good point.I hope you take it easier on yourself going forward.ETA: same argument back to you. If you don't like the open nature of reddit, this sub or otherwise, go make your own langchain variant, sub or otherwise and dedicate your life to it.Or just complain on the internet like OP is doing.permalinkembedsaveparentreportreply[\u2013]pixelies 1 point 1 month ago Push request!!! \ud83d\ude02\ud83e\udd23\ud83d\ude02\ud83e\udd23\ud83d\ude02\ud83e\udd23\ud83d\ude02\ud83e\udd23permalinkembedsaveparentreportreply[\u2013]rismay 1 point 1 month ago* To l33t programmers like OP, he could just be writing his own library\u2026 yet he\u2019s not writing it in c++ like all major AI houses do for prod.permalinkembedsavereportreply[+][deleted] (2 children)[\u2013]Turbulent-Swimmer390 1 point 1 month ago As a hobbyist (and beginner) I thought langchain was the go to tool for coders given it\u2019s popularity amongst the YouTube tutorials on this subject.I feel misled reading opinions of people who actually code for a living.Is there an actual library I can study and use for my own use cases? Huggingface\u2019s transformers maybe?permalinkembedsavereportreply[\u2013]AlgoTrade 4 points 1 month ago It\u2019s all basic api requests, langchain is just a clunky library with some prebuilt stuff. Learn what\u2019s going on there, and if it works for your pet project, all good! But it\u2019s not likely going to be production ready, and anything you see in the langchain repo is probably better custom built for your own use.permalinkembedsaveparentreportreply[\u2013]stormelc 2 points 1 month ago Langchain is great to learn what is going on. Look at their code and study it. It's a decent collection of utilities but not the end all be all that people seem to think it is.permalinkembedsaveparentreportreply[\u2013]g0rth 1 point 1 month ago I feel you, but ultimately anything library that is built around a LLM will aways just be fancy string parsers. I wouldn't expect much from them either way.permalinkembedsavereportreply[\u2013]Alarmed-Individual-5 1 point 1 month ago ... and what do you guys think about the JavaScript version? Is that better designed?permalinkembedsavereportreply[\u2013]stormelc 1 point 1 month ago This seems like a beginner's projectIt absolutely is a beginner project that blew up. There has been so much movement in this space, and it's sufficiently new to a lot of people that people naturally gravitated towards a library with high number of stars on github.permalinkembedsavereportreply[\u2013]AmountFar 1 point 1 month ago What is the alternative to langchain?permalinkembedsavereportreply[\u2013]SuperConductiveRabbi[S] 0 points 1 month ago It depends on the specific functionality, but if you go one layer down in their code you can see the actual libraries doing the work. I pointed out SentenceTransformers, ChromaDB, and requests for what I was looking at.permalinkembedsaveparentreportreply[\u2013]Spitfire3788 1 point 10 hours ago SymbolicAI https://github.com/Xpitfire/symbolicai https://symbolicai.readthedocs.io/en/latest/README.htmlpermalinkembedsaveparentreportreply[\u2013]diamondbishop 1 point 4 hours ago Just write the small amount of glue code needed (and hey, you can even get help from openai directly to do that). Most of what langchain does I just implemented directly for my own use case because it\u2019s easier to manage and update that way and in the end it was such a small amount of work that was better to understand the underlying APIs anyway.permalinkembedsaveparentreportreply[\u2013]Wishmaster04 1 point 1 month ago My path with langchain was :- Ok, this seems widely used, must learn about it- Mmhhh, do I really need to use this ? Is this actually helping me or is it a weight ? I will only use chains and templates for my project, then we'll see.- * Sees a reddit post about it*I would say the LLM client wrapper is useful because it creates an abstraction with many LLMspermalinkembedsavereportreply[\u2013]nicognaw 1 point 15 days ago I'm trying to build a production-level LLM-powered app, and LangChain makes me a lot of pain; the documents are inconsistent, it passes parameters so randomly but still checks types with pydantic, so some use cases fail and some do not, and the time I spent debugging custom tools and chains is even enough for me to implement one from scratch.If I just wanted a data science lab or an LLM toy, LangChain would be great, but for production-level systems, I don't think so.permalinkembedsavereportreply[\u2013]AsliReddington 1 point 17 hours ago It's just abstraction to do stuff quickly, definitely better to use alternative approaches for basic actionpermalinkembedsavereportreply[\u2013]TotesMessenger 1 point 16 hours ago I'm a bot, bleep, bloop. Someone has linked to this thread from another place on reddit:[/r/hypeurls] Langchain Is Pointless If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads. (Info / Contact)permalinkembedsavereportreply[\u2013]Voxandr 1 point 16 hours ago Haystack is much better , well oragnized langchain alternative.permalinkembedsavereportreply[\u2013]drivenkey 1 point 16 hours ago What about lamaindex? (Or that suffer from same issues...)https://www.llamaindex.ai/permalinkembedsavereportreply[\u2013]Bulky_Highlight_3352 1 point 15 hours ago try deepset Haystack, it is a thought through and well designed library that comes with production level codepermalinkembedsavereportreply[\u2013]demofunjohn 1 point 15 hours ago I was beginning to feel this way after watching some videos of the founder. It\u2019s like a big marketing push with the hopes of filling the gaps along the way. But I couldn\u2019t find any value, seems like basic python is all you need here.permalinkembedsavereportreply[\u2013]resiros 1 point 13 hours ago I believe the abstractions in Langchain are inherently flawed. The core problem resides in the composability of chains. While it offers a handy way to create prototypes, it becomes restricting when you desire to modify a specific element within the chain. The hierarchical design of chains in Langchain conceals the component you wish to alter and obscures the parts developers might want to adjust, making the process of experimenting and refining the pipeline difficult.The optimal abstraction for LLM apps, in my view, should resemble a DAG or a state machine. This alternative exposes the distinct stages in the pipeline rather than masking them in a hierarchy. Yes, adopting this new abstraction might lead to more code but it offers superior control. It's hardly surprising that many users start prototyping with Langchain, but then, when ready, they clone the prompts and construct their own systems.Fixing this fundamental issue would be very difficult. It would necessitate reworking the library from the ground up.permalinkembedsavereportreply[\u2013]sandys1 1 point 12 hours ago I think that Generative AI applications is a config management problem. Think Prompts X Chains X LLMs. Your prompts wont work across everything and everything will break on model change. Coding this into ur classes is what everyone does.I think the better answer is to declaratively pull out the prompts X chains as jsonnet code. Call it trauma & learnings from the K8s/Borg world. We have formats that have evolved as a result of millions of lines of code wrangling clusters/terraform/etc - so we decided to build a SDK over it.that is what we did here - https://github.com/arakoodev/EdgeChains/releases/tag/0.2.0EdgeChains is basically Generative AI prompt engineering modeled as config management.permalinkembedsavereportreply[\u2013]reredef 1 point 8 hours ago Ironically, a modern AI would have produced much better code.permalinkembedsavereportreply[\u2013]HybridRxN 1 point 3 hours ago Thank you! How did they raise SO MUCH money!!permalinkembedsavereportreplyaboutblogaboutadvertisingcareershelpsite rulesReddit help centerreddiquettemod guidelinescontact usapps & toolsReddit for iPhoneReddit for Androidmobile website<3reddit premiumreddit coinsUse of this site constitutes acceptance of our User Agreement and Privacy Policy. \u00a9 2023 reddit inc. All rights reserved.REDDIT and the ALIEN Logo are registered trademarks of reddit inc.\u03c0",
    "summary": "- Langchain is a popular but poorly designed library for working with language models.\n- It is filled with overlapping abstractions, leading to confusion and frustration.\n- The documentation is disorganized and inconsistent, making it difficult to use effectively.",
    "hn_title": "Langchain Is Pointless",
    "original_title": "Langchain Is Pointless",
    "score": 313,
    "hn_content": "Hacker News new | past | comments | ask | show | jobs | submit loginLangchain Is Pointless (reddit.com)314 points by behnamoh 18 hours ago | hide | past | favorite | 148 commentsLASR 12 hours ago | next [\u2013]The reason why Langchain is pointless is that it's trying to solve problems on top of technical foundations that just cannot support it.The #1 learning is that there is no reusability with the current generation of LLMs. We're using GPT-4 and 3.5T exclusively.Over the last several months, my team has been building several features using highly sophisticated LLM chains that do all manner of reasoning. The ultimate outputs are very human-like to the point where there is some private excitement that we've built an AGI.Each feature requires very custom handwritten prompts. Each step in the chain requires handwritten prompts. The input data has to be formatted a very specific way to generate good outputs for that feature/chain step. The part around setting up a DAG orchestration to run these chains is like 5% of the work. 95% is really just in the prompt tuning and data serialization formats.None of this stuff is reusable. Langchain is attempting to set up abstractions to reuse everything. But what we end up with a mediocre DAG framework where all the instructions/data passing through is just garbage. The longer the chain, the more garbage you find at the output.We briefly made our own internal Langchain. We tore it down now. Again not that our library or Langchain was bad engineering. It's just not feasible on top of the foundation models we have right now.replyrchaves 4 hours ago | parent | next [\u2013]100% this! What is worse is that LangChain hides their prompts away, I had to read the source code and mess with private variables of nested classes just to change a single prompt from something like RetrievalQA, and not only that, the default prompt they use is actually bad, they are lucky things work because GPT-3.5 and GPT-4 are damn smart machines, with any other open LLM, things break. I was hoping for good defaults, but they are not, the prompt I wrote over 6 months ago little after the launch of ChatGPT to do some of the same things work much better.Would you have anything you can share with us about those \"several features using highly sophisticated LLM chains that do all manner of reasoning\", I'm really curious about the challenges, the process and insights therereplysjnair96 51 minutes ago | root | parent | next [\u2013]Can you share some insights/examples, if you can, on how you improved the prompts? One I feel is particularly poor is the next question generation/past question condensation prompts which are used to refine the user's input based on the history, so that the query includes all the context required for the question, and hence, incorporating \"memory\".replyrchaves 4 hours ago | root | parent | prev | next [\u2013]this inspired me on writing a new section in my project \"Prompts on the outside\" (https://github.com/rogeriochaves/litechain#prompts-on-the-ou...)replykrainboltgreene 9 hours ago | parent | prev | next [\u2013]> where there is some private excitement that we've built an AGIThis is a great litmus test for if you need to get a reality check.reply8f2ab37a-ed6c 11 hours ago | parent | prev | next [\u2013]Any chance you might have shared some of these hard-earned lessons, so that the rest of us could learn from them as well?replytensor 10 hours ago | parent | prev | next [\u2013]And then they release an updated GPT that breaks all your tuned prompts.replymeghan_rain 10 hours ago | root | parent | next [\u2013]Especially where \"updated\" actually means \"lobomized to be less offensive\"replyspace_fountain 12 hours ago | parent | prev | next [\u2013]How do you deal with the prompt iteration phase and how coupled is that to the DAG phase? I've only worked on a few proofs of concept in this phase, but a thing I struggled with was a strong desire to allow non technical colleagues to mess with the prompts. It wasn't clear to me how much the prompts need to evolve in tandem with the the DAG and how much they can exist separatelyreplyLASR 12 hours ago | root | parent | next [\u2013]There are a few increasingly harder things when it comes to prompt customization:1. Prompts ask LLM to generate input for the next step2. Prompts ask LLM to generate instructions for the next step3. Prompts ask LLM to generate the next stepDoing #3 across multiple steps is the promise of Langchain, AutoGPT et al. Pretty much impossible to do with useful quality. Attempting to do #3 very often either ends up completing the chain too early, or just spinning in a loop. Not the kind of thing you can optimize iteratively to good enough quality at production scale. \"Retry\" as a user-facing operation is just stupid IMO. Either it works well, or we don't offer it as a feature.So we stopped doing 3 completely. The features now have a narrow usecase and a fully-defined DAG shape upfront. We feed some context on what all the steps are to every step, so it can understand the overall purpose.#2, we tune these prompts internally within the team. It's very sensitive to specific words. Even things like newlines affects quality too much.#1 - we've found it's doable for non-tech folks. In some of the features, we expose this to the user somewhat as additional context and mix that in with the pre-built instructions.So #2 is where it's both hard to get right and still solvable. Every prompt change has to be tested with a huge number of full-chain invocations on real input data before it can be accepted and stabilized. The evaluation of quality is all human, manual work. We tried some other semi-automated approaches, but just not feasible.All of this is why there is no way Langchain or anything like it is currently useful to built actually valuable user-facing features at production scale.replyremmargorp64 8 hours ago | root | parent | next [\u2013]What if you built a scoring system for re-usable action sequences that are stored in a database, and then have the LLM generate alternate solutions and grade them according to their performance?An action sequence of steps could be graded according to whether it was successful, it\u2019s speed, efficiency, cleverness, cost, etc.You could even introduce human feedback into the process, and pay people for proposing successful and efficient action sequences.All action sequences would be indexed and the AI agent would be able to query the database to find effective action sequences to chain together.The more money you throw at generating, iterating, and evolving various action sequences stored in your database, the smarter and more effective your AI agent becomes.replysandGorgon 2 hours ago | parent | prev | next [\u2013]this is precisely the problem i encountered and tried to solve with Edgechains. we think Generative AI is a config management problem (like Terraform or Kubernetes).>None of this stuff is reusable. Langchain is attempting to set up abstractions to reuse everything. But what we end up with a mediocre DAG framework where all the instructions/data passing through is just garbage. The longer the chain, the more garbage you find at the output.chains X prompts X LLMs == pods X services X nodes in Terraform.So we model it on top of config management grammar that is proven to work in large production config - jsonnet.A trivial example is this - https://github.com/arakoodev/EdgeChains/blob/main/Examples/r...Would love to get an example of complex chains (even if u have an ARxiv paper) that you think we could solve in Edgechains-jsonnet ?replyDer_Einzige 11 hours ago | parent | prev | next [\u2013]Much of why this stuff is not reusable is that eventually someone in the NLP world is going to properly migrate the features for promopt engineering that the coomers over in stable-diffusion/automatic1111 land have \"pioneered\", such as token weighting, negative prompts, token averaging, or etc. Literally all of these techniques work with regular LLMs (if you don't believe me, see here: https://gist.github.com/Hellisotherpeople/45c619ee22aac6865c...). NLP folks just haven't built the right tooling for it. Particularly sad since there's supposed to be an \"Automatic1111 for LLMs\" project called \"Oogabooga\" but it doesn't have any of the good features.The future of LLM prompting will involve highly specialized and engineered prompts, much as is the case with most images seen on civit.aiWe are all likely to eventually throw away a lot of our current promptsreplysandGorgon 2 hours ago | root | parent | next [\u2013]Automatic111 is the domain of Jupyter - desktop experimentation. When you go into production, there are tons of additional pieces of complexity that start hitting you - like prompt routing. So the problem space is different.We have a simple concept - Generative AI is config management. We model it on top of config management grammar that is proven to work in large production config - jsonnet.A trivial example is this - https://github.com/arakoodev/EdgeChains/blob/main/Examples/r...Do u think this is something that works for you ?replyapplgo443 12 hours ago | parent | prev | next [\u2013]I saw your comment, got curious, and looked at a lot of your old comments. Lots of interesting insights - Thanks for sharing them.If you don't mind me asking, what do you do? I'm a researcher at FAANG working on language models and starting a new company in the space. Would love to connect. Feel free to email me - idyllic.bilges0p@icloud.comreplyteaearlgraycold 12 hours ago | parent | prev | next [\u2013]100% agreed. I've used GPT professionally and we would try out different hosts, AI21, etc. and it there were always clear quality issues with just re-using your prompt and hyperparameters. Some of that was down to other models being lesser quality, but we'd also need to re-tune prompts when upgrading to new OpenAI models for the best effect. It turns out that LLMs aren't quite a commodity.replydigitcatphd 3 hours ago | root | parent | next [\u2013]This is precisely why open source models will be limited. Most of the capabilities distinguishing GPT and later Gemini are emergent behaviors from the large parameter count the open source community is saying is not needed (at least for now).replymoneywoes 12 hours ago | parent | prev | next [\u2013]In that case what pattern do you use for integrations?replyminimaxir 14 hours ago | prev | next [\u2013]I have a full-on \"The Problem With LangChain\" blog post in the pipeline, and the reason I made a simple alternative (https://news.ycombinator.com/item?id=36393782) because I spent a month working with LangChain and coming to the conclusion that it's just easier to make my own Python package than it is to hack LangChain to fit my needs.A few bullet points:- LangChain encourages tool lock-in for little developer benefit, as noted in the OP. There is no inherent advantage into using them, and some have suboptimal implementations.- The current implementations of the ReAct workflow and prompt engineering are based on InstructGPT (text-davinci-003), and are extremely out of date compared to what you can do with ChatGPT/GPT-4.- Debugging a LangChain error is near impossible, even with verbose=True.- If you need anything outside the workflows in the documentation, it's extremely difficult to hack, even with Custom Agents.- The documentation is missing a lot of relevant detail (e.g. the difference between Agent types) that you have to go diving into the codebase for.- The extreme popularity of LangChain is warping the entire AI ecosystem around the workflows to the point of harming it. Recent releases by Hugging Face and OpenAI recontextualize themselves around LangChain's \"it's just magic AI\" to the point of hurting development and code clarity.Part of the reason I'm hesitant to release said blog post is because I don't want to be that asshole who criticizes open source software that's operating in good faith.replyTeMPOraL 11 hours ago | parent | next [\u2013]> Part of the reason I'm hesitant to release said blog post is because I don't want to be that asshole who criticizes open source software that's operating in good faith.Beyond the \"extreme popularity of LangChain is warping the entire AI ecosystem around the workflows to the point of harming it\", hasn't it recently become an attractor for substantial amount of investment money? I'm not saying you should be an ass about it, but the ecosystem will keep getting warped further if knowledgeable people won't speak up, and LangChain doesn't seem to be a random small open source project anymore.EDIT:From https://news.ycombinator.com/item?id=36647616:> Remember, this is the project that raised ~$30m from Benchmark and Sequoia.I think we're past the point of good-faith, small, volunteer-made open source project. If it can take $30M, it can stand some informed criticism too.replyminimaxir 10 hours ago | root | parent | next [\u2013]I'm not worried about LangChain not taking criticism well, it's more the fanboys who have a vested interest in maintaining the status quo and I don't have the free time to deal with annoying \"you're just nitpicking because you're jealous\" and \"it's open source, why don't you just make a PR to fix everything instead of whining?\" messages.replylayer8 48 minutes ago | root | parent | next [\u2013]You can just ignore those fanboy messages?replyntindle 7 hours ago | root | parent | prev | next [\u2013]This is our worry with building Auto-GPT as well. We have had a number of rather involved discussions on why we don\u2019t use it. I\u2019d love if you published so I can point to it rather than rehashing it every few days.replytryfinally 1 hour ago | parent | prev | next [\u2013]> Debugging a LangChain error is near impossible, even with verbose=True.(A while ago) I tried using LangChain and shortly gave up after not finding any way whatsoever to actually debug what\u2019s going on under the hood (eg. see the actual prompts, LLM queries). It\u2019s pretty ridiculous that this isn\u2019t basic functionality, or at least it isn\u2019t very discoverable.I cannot imagine spending extended time with a framework without knowing what the internals are doing. I do realize this isn\u2019t achievable on all levels with LLMs, but introducing more black boxes on top of existing ones isn\u2019t solving any problems.replyPUSH_AX 2 hours ago | parent | prev | next [\u2013]> Part of the reason I'm hesitant to release said blog post is because I don't want to be that asshole who criticizes open source software that's operating in good faith.I agree with your restraint, this feels like it might be more productive in another format. Ultimately this either needs to be broached with the maintainers or an alternative should be started.replyntindle 7 hours ago | parent | prev | next [\u2013]We\u2019ve had a lot of similar concerns when working on Auto-GPT and have been repeatedly asked why we don\u2019t use it. You\u2019ve solidified a lot of the reasons it\u2019s not fit for purpose for large complex projects.We\u2019ve received a lot of commentary on our unwillingness to use it, and I don\u2019t blame you for being hesitant. I don\u2019t want to be the open-source project that says it\u2019s not good when it\u2019s not suitable for our uses.replyjangletown 14 hours ago | prev | next [\u2013]I agree, I really don\u2019t like LangChain abstractions, the chains they say are \u201ccomposable\u201d are not really, you spend more time trying to figure out langchain than actually building things with it, and it seems it\u2019s not just me after talking to many peopleTheir code seems all rushed, and seems it worked out for initial popularity, but with their current abstractions I personally don\u2019t think it\u2019s a good long term framework to learn and adoptThat\u2019s why I built my own alternative to it, I call it LiteChain, where the chains are actual composable monads, the code is async streamed by default not ducktaped, it\u2019s very bare bones yet but I\u2019m really putting effort on building a solid foundation first, and having a final simple abstractions for users that don\u2019t get in the way, check it out:https://github.com/rogeriochaves/litechainreplyibains 14 hours ago | parent | next [\u2013]Why is this just not ETL, why do you need anything here? There is no new category or product needed here.replyjangletown 13 hours ago | root | parent | next [\u2013]Just saw the video you shared on the other comment using prophecy, very coolGenerally I don\u2019t care much about the embedding and retrieval and connectors etc for playing with the LLMs, I imagined much more robust tools were available already indeed, my focus was more on the prompt development actually, connecting many prompts together for a better chain of thought kinda of thing, working out the memory and stateful parts of it and so on, and I think there might be a case for an \u201cLLM framework\u201d for that, and also a case for a small lib to solve it instead of an ETL cannonHowever, I am indeed not experienced with ETLs, have to play more with the available tools to see if and how can I do the things I was building using themreplyrchaves 3 hours ago | root | parent | prev | next [\u2013]hmmm, just had a chat with GPT-4, it didn't seem convinced that ETLs would do well the same things that LiteChain is trying to achieve: https://chat.openai.com/share/88961bd1-8250-45f0-b814-0680ba...I'd be happy to see some more examples of LLM application building on ETLs like the video you shared thoughreplykrawczstef 5 hours ago | root | parent | prev | next [\u2013]Totally! As a person driving a project like https://github.com/DAGWorks-Inc/hamilton I couldn't agree more!replyibains 16 hours ago | prev | next [\u2013]It is pointless - LlamaIndex and LangChain are re-inventing ETL - why use them when you have robust technology already?1. You ETL your documents into a vector database - you run this pipeline everyday to keep it up to date. You can run scalable, robust pipelines on Spark for this.2. You have a streaming inference pipeline that has components that make API calls (agents) and between them transform data. This is Spark streaming.Prophecy is working with large enterprises to implement generative AI use cases, but they don\u2019t talk so much on HN.Here\u2019s our talk from Data+AI Summit: Build a Generative AI App on Enterprise Data in 13 Minutes https://www.youtube.com/watch?v=1exLfT-b-GMHere\u2019s a blog/demo https://www.prophecy.io/blog/prophecy-generative-ai-platform...replylmeyerov 16 hours ago | parent | next [\u2013]We also do platform & customer work there (cool pipelines to feed louie.ai or real-time headless versions), and agreed those pipelines have simple uses of LLM where langchain is mostly useful just for a vendor neutrality. Think BYO LLM as it is now a zoo. Basically apache nifi or spark streaming with simple LLM & vector DB call outs. Our harder work here is more at the data engineering level.But....a lot of our louie.ai work happens for less trivial scenarios where it isn't just the ETL NLP 2.0 tier . That logic is much more complicated, so structured programming abstractions matter a LOT more for AI-style business logic. Think talk to your data and generate on-the-fly analytics pushdown with an interactive data viz UI. That's.. a lot of code.replytechwizrd 15 hours ago | root | parent | next [\u2013]I agree that it's a little silly, but I mostly use it to abstract over BYO LLMs and extract information from documents. It's nice to be able to quickly prototype something and swap out the underlying language model than set up a whole pipeline with Apache Tika, ETL, etc. Once the idea is feasible, then sure.That said, langchain is really inefficient and I often find I can re-implement the pieces I need much faster than dealing with langchain's bugs and performance issues.replyibains 14 hours ago | root | parent | next [\u2013]That\u2019s assuming you\u2019re not using low-code. There are inbuilt connectors to read data, transform data, read/write to pinecone, make api calls to LLMs. It is much faster to prototype with Prophecy.ioreplycodeptualize 14 hours ago | prev | next [\u2013]I have looked for the value and never really found it.It seems to mostly be (bad) abstractions around things you could easily do without langchain.Take one of the most important llm things: prompt templates. What does langchain add over a simple function and an f string? Maybe I'm missing the point, but I can't find anything.Anyway, it seems people like it so who am I to judge, but I don't like making our codebase dependent on a huge new library with unnecessary abstractions and little or no value add.replyTeMPOraL 11 hours ago | parent | next [\u2013]> Take one of the most important llm things: prompt templates. What does langchain add over a simple function and an f string? Maybe I'm missing the point, but I can't find anything.Seconding.Ever since learning about it, then seeing a co-worker use it for some simple embedding job (and being impressed in how few lines of code it took, but that's actually not thanks to LangChain), then reading its docs end-to-end, about once a week, I find myself going through the following sequence of thoughts:1. Alright, let's set up LangChain and implement my ${most recent harebrained idea};2. Oh, but it's in Python. I don't like Python, I don't know Python, I hate dealing with its dependency issues even more than with NPM ones. Could I do things I need from it directly in ${my preferred environment, which half the time is just Emacs}?3. Wait a minute. Chaining \"DAGs\" the way it does is basically equivalent to a sequence of function calls in a while loop, occasionally mixed with some if/else or goto. Generating prompts is... string interpolation that can be wrapped in a helper function. LMAO.4. No, really. Why bother? The only useful thing here seems to be discoverability - i.e. a list of toolkits it supports, and said support working as intro 101 tutorial. Given the surface areas of those plugins are so small, I can literally wrap what I need in a bunch of functions, and then do the \"chain\" part as... plain old sequential code.So yeah, right now, I think about the only value this project has is in being a convenient list of AI tools with examples of using their APIs. Everything else seems better done either by coding it directly, or (for certain needs) by building up a more complex dataflow framework.replycodeptualize 1 hour ago | root | parent | next [\u2013]Fair assessment. Maybe you have found the value: it\u2019s a library of code snippets. There is truly something to say for that, but maybe it had worked better as a documentation site (kinda ironic as their docs are not super great).> plain old sequential codeThis!! Besides the templates this is the most confusing thing, it is indeed the same as running lines of code sequentially.P.S. for python dependencies, check out Poetry, not perfect but a lot more sane than the other options.replydavesque 14 hours ago | parent | prev | next [\u2013]Honestly, it's hard to even tell if people really like it or if the LangChain team have just done a really good job of evangelizing for it. I saw that they did some kind of interview with Andrew Ng the other day. I feel like that sort of thing doesn't just happen by accident, but because someone actively reached out to him, especially considering that LangChain has only been on the scene for a couple of months.replycodeptualize 13 hours ago | root | parent | next [\u2013]True, you gotta respect the marketing, they definitely got that covered and actually created some real value there, a $10M seed round to be precise.I think they got the timing right and the idea is kinda alluring as well: have everything standardized, pluggable and swappable sounds neat. Just doesn't really work.They are also doing a great job at maintaining the mirage of adding value. Templates for example will work totally fine, as they are just f strings. It seems there are plenty of people who don't really think twice about it, and they have captured that audience very well.There is also a low barrier to contribute as everything is kinda basic, that must help a lot as well.replyminimaxir 13 hours ago | root | parent | prev | next [\u2013]LangChain has been active since last year (after the ReAct paper was released), but gained most of its popularity after the ChatGPT hype.replytrolan 14 hours ago | parent | prev | next [\u2013]I actually found a lot of value when I left the LangChain ecosystem and started using jinja templates. The syntax from home assistant moved over and I can just pass dictionaries to render a prompt now.replysaulpw 14 hours ago | parent | prev | next [\u2013]I agree, and that's why I've been working on AIPL[0]. Our first v0.1 release should be in the next few days. https://github.com/saulpw/aiplIt's basically just a simple scripting language with array semantics and inline prompt construction, and you can drop into Python any time you like.replycodeptualize 13 hours ago | root | parent | next [\u2013]With peace and love, why would I not just write some code?LLM pipelines are not very complex: it's string manipulation, api calls, and storage, there is not much more too it. All are quite easy to do, often needing nothing else but the standard library.For more complex cases or bigger scale you have a plethora of battle tested solutions to manage things like queues, back off and retries, concurrency, etc.Maybe it's me missing the point (again), but I wonder what the added value is of learning a new language to do things that are super easy to do in Python/JS/whatever my language of choice is? Or maybe I'm just not be your target audience, very possible.replyReticularas 12 hours ago | root | parent | next [\u2013]I get this feeling too \"maybe I'm not the target audience\" This feeling is followed closely by \"Who is the target audience?\". Some abstract concept of an audience doing complex LLM work to accomplish... something?The value in statistics analysis for LLMs is clear, the value in chaining responses is very unclear.replyrdli 12 hours ago | parent | prev | next [\u2013]I found it helpful for prototyping and learning some basics, but I quickly found the abstractions were not useful and had to implement my own.replysenko 15 hours ago | prev | next [\u2013]Remember, this is the project that raised ~$30m from Benchmark and Sequoia.There was a controversial \"quality doesn't matter for software products\" post and discussion[0] here on HN a few days ago and this is a beautiful example.Product may matter eventually, but you can sure surf the hype for a long time before the reckoning comes (and if you're lucky, you may even be able to get someone else to hold the bag then).0: https://news.ycombinator.com/item?id=36615286replyweyj4 10 hours ago | parent | next [\u2013]Thanks for this post, I hadn't seen the linked conversation when it happened. Here's my reading. The conversation blog post you linked begrudgingly points out that companies aren't sunk by bugs, technical debt, or inefficient development practices. If you have a good sales team and a product that people want, need, or will be forced to use, you can succeed even if you have to burn money on dev, ops, customer support. However I think what this langchain conversation is about is overeager VCs and a product that maybe doesn't do anything we need. It's not that langchain is slow or hard to use; it's that we can just do this stuff with Python or whatever. I don't have enough langchain experience to substantiate these claims but I think that's what I'm reading here.replynextworddev 14 hours ago | parent | prev | next [\u2013]Any ideas what valuation range that might imply?replyPhoenixReborn 14 hours ago | root | parent | next [\u2013]The rumored valuation was around $200M, and the product is pre-revenue right now. So that seems pretty ridiculous.replyShamelessC 11 hours ago | root | parent | next [\u2013]I\u2019m curious - who gets screwed over the most here? Is it investors who got tricked into over valuing? Or langchain who now can\u2019t meet their expected revenue targets and will be forced to pivot?Speaking in hypothetical terms of course. I\u2019m assuming the langchain folks are probably paying themselves pretty well and not working super hard (at least not on engineering stuff)?replynextworddev 10 hours ago | root | parent | prev | next [\u2013]What is the product?replyRC_ITR 12 hours ago | parent | prev | next [\u2013]We\u2019ve seen the top dog fall from grace in the VC world before (KPCB missing social and mobile after a truly epic run in the 90s)Is that what we are starting to see for Sequoia?Like KP, I doubt they\u2019ll fold, but it would be interesting to live in a world where sequoia is just top half instead of top 1.replyjchonphoenix 2 hours ago | root | parent | next [\u2013]Sequoia never figured out their edge in the enterprise world. They likely won't fall from grace since they're still investing in the space, but their filter is certainly poorer than their other areas of investment.replynojvek 4 hours ago | root | parent | prev | next [\u2013]KPCB = Kleiner Perkins Caufield & Byers (KPCB)Today I learnt.replydereg 15 hours ago | prev | next [\u2013]Since last year, before I heard about langchain, I've been building my own stack of tooling for my own LLM projects that probably now covers about 10-20% of Langchain's functionality. I heard about Langchain earlier this year and groaned, thinking that I did a lot of work for nothing....Then I actually used langchain. I was shocked at how poorly performant the code is. Some operations took 10x longer than how I did it, and all the while producing worse results. As tempting as it is to just roll with langchain from day one, I'd highly advise against it. Think deeply about what you're actually trying to accomplish and instead of just injecting langchain in the middle of everything as this messy, amorphous glue code thing.replyTostino 9 hours ago | parent | next [\u2013]Yeah I've got a few thousand lines of langchain code now for a data cleaning pipeline... I've been fighting it every step of the way. Trying to replace sections of the pipeline to use a local LLM instead of OpenAI has had me have to replace the templates entirely, the chat based templates won't allow me to assign the proper user/assistant names, so the performance for the local LLM is terrible (stupid). They have zero actual composibility when you look at it slightly differently than they expect.It's a useless abstraction for every single purpose I've actually tried it for.Will be extricating it from my code base as soon as I find something else that works any better.replysandGorgon 2 hours ago | root | parent | next [\u2013]I have an attempt in the same domain, would love feedbackWe think - Generative AI is config management. We model it on top of config management grammar that is proven to work at K8s/Terraform scale - jsonnet.https://github.com/arakoodev/EdgeChains/blob/main/Examples/r...Prompts live outside the code. We didnt invent a new markup - we used jsonnet which is used in large scale kubernetes and has a grammar that has been well tested for config mgmt.replyFemmeAndroid 14 hours ago | parent | prev | next [\u2013]I had this exact same experience. I was happy to move to something good, but I couldn\u2019t find a lot of benefit. Maybe I\u2019m missing something, but the added complexity is not worth it to me for what it provides.replyrmonvfer 43 minutes ago | prev | next [\u2013]I've had a similar experience with LangChain. Initially, I was really impressed with it while developing an MVP, but as soon as I needed to add complexity or specific features, things started to go downhill.A significant chunk of my time was spent navigating through LangChain's codebase, trying to make sense of missing or outdated documentation. Plus, there's a significant disparity between the features of the JS/TS and Python versions. Identifying which version supports which features can be a real challenge.I don't want to sound overly critical, as I'm currently using it in production. However, I had to modify it so extensively that it barely resembles the original project anymore. Looking back, I can't help but think that adopting this library might have been a misstep. Perhaps we should have taken the time to create our own.replyarpowers 16 hours ago | prev | next [\u2013]Proper term is that it's a \"false abstraction\"...It abstracts some work only to introduce introduce it's own API (which is ultimately more complicated, less documented, introduces limits and constraints, and comes with its own bugs and dev politics)...But nobody asked me, keep using itreplyjoshka 13 hours ago | parent | next [\u2013]To coin a portmanteau: that's the Fauxcade pattern ;)(though it does exist already) https://www.urbandictionary.com/define.php?term=fauxcadereplyrobbywashere_ 16 hours ago | prev | next [\u2013]Sad to hear the news, I have 7 years of langchain experience on my resume, now what am I going to do!?replybeepbooptheory 16 hours ago | parent | next [\u2013]You should probably not mention it by name on a resume anyway, but emphasize your actual skills, experience, and familiarity with the lower level technologies and APIs that underly it.This hype train isn't going to last forever, and it's probably better to advertise sustainable, evergreen skills rather than being an expert in the flavor of the week. With that much experience, you shouldn't have to feel tied to any one company's software.replyta988 15 hours ago | root | parent | next [\u2013]It was a joke, langchain was released last year.replybeepbooptheory 14 hours ago | root | parent | next [\u2013]Ha! I guess I don't really get the joke, but relieved for gp's sake it is one, despite the egg on my face.replypessimizer 14 hours ago | root | parent | next [\u2013]*didn't really get the joke,If you don't get it now, I'm worried about you:)replybeepbooptheory 13 hours ago | root | parent | next [\u2013]No no, that is the right tense! I thought initially it was like light sarcasm targeting the conceit of the reddit post, i.e., \"how could it be pointless if I have amassed all this experience.\" Beyond that.. not sure (I'm not that smart).Perhaps its just something like: \"the scandal that this library is bullshit amounts to not a lot considering it's still pretty new thing.\" But the, erm, strong showing of downvotes of my original post makes me think its a better bit than that!Indulge me with the joke if you'd like, but don't worry about me! I'm doing pretty good, despite my slow mind.replydrdrey 11 hours ago | root | parent | next [\u2013]The context for the joke is that some job listings have inflated requirements, like N years of experience from framework/language X that realistically nobody has (or in this case, can have)replyskwirl 16 hours ago | root | parent | prev | next [\u2013]Whoooshreplykrychu 12 hours ago | prev | next [\u2013]Using an LLM framework at this moment doesn\u2019t make sense and can be damaging, in my humble opinion. Ways to extract value from LLMs are in early exploration stage. Look at research in prompting: chain of thought, react, reflection, tree of thoughts, zero vs few hot etc. Then completion vs conversational interfacing. Then memory management via vector databases and prompt expansion vs compression vs progressive summarization etc. All these are fairly recent developments. They are not abstractions worth cementing, this is search and creative phase. LLMs threw everything in the air, but the dust is far from settling. I think it\u2019s important to recognize the phase we\u2019re in and pick your weapon accordingly. You have to stay nimble and light, ready to experiment with a new idea that will come out next week. You should be hacking these things together by yourself. If you pick a framework at this stage know that the framework will have to pay the price of trying to cement things in the times of storm. And you\u2019ll be a few steps behind. Of course this is my personal take.replyresiros 13 hours ago | prev | next [\u2013]I believe the abstractions in Langchain are inherently flawed. The core problem resides in the composability of chains. While it offers a handy way to create prototypes, it becomes restricting when you desire to modify a specific element within the chain. The hierarchical design of chains in Langchain conceals the component you wish to alter and obscures the parts developers might want to adjust, making the process of experimenting and refining the pipeline difficult.The optimal abstraction for LLM apps, in my view, should resemble a DAG or a state machine. This alternative exposes the distinct stages in the pipeline rather than masking them in a hierarchy. Yes, adopting this new abstraction might lead to more code but it offers superior control. It's hardly surprising that many users start prototyping with Langchain, but then, when ready, they clone the prompts and construct their own systems.Fixing this fundamental issue would be very difficult. It would necessitate reworking the library from the ground up.replypharmakom 3 hours ago | parent | next [\u2013]A DAG is not expressive enough for some applications. Lang chain is actually a poorly implemented free monad.replyjoshka 13 hours ago | parent | prev | next [\u2013]Take a look at https://promptfile.org/ for an alternative approach to the prototyping -> app flow.replysandGorgon 2 hours ago | root | parent | next [\u2013]Promptfile is written in markdown, which is unsuited for templates and config management.I have an attempt in the same domain, would love feedbackWe didnt invent a new markup - we used jsonnet which is used in large scale kubernetes and has a grammar that has been well tested for config mgmt.https://github.com/arakoodev/EdgeChains/blob/main/Examples/r...Prompts live outside the code.replyravenstine 15 hours ago | prev | next [\u2013]I had the same thought about Langchain, and it's essentially my same criticism of most wrapper libraries and SDKs. What are they actually doing that can't be just as easily done with straight up string manipulation and HTTP requests? Usually very little. ORMs might be one of the few exceptions in some cases.Even so, ORMs sell a similar false promise to Langchain, which is that you can \"easily\" swap out the underlying thing; a migration that is rare in practice and almost always not that simple.You might not need Langchain.replyrefulgentis 14 hours ago | parent | next [\u2013]It's a really interesting question: the converse of this is its _really_ tricky nailing all this down, much harder than you'd think -- see the GPT4 GA thread earlier this week for people who swear up and down the OpenAI API acts in bizarre ways, you'll note that it almost seems fantastical that it could be that bizarre: it is fantastical. If you're truly used to it, it reads like \"hey I have auto retries enabled in my HTTP client framework. p.s. whats 'context size'?\"But Langchain is far, far, _far_ away from being truly helpful with that. It's glorious that we're 5 months into GPT-4 and most people either got bored or are building on rickety rushed structures in Python to rush out a proof of concept web app.replyversion_five 17 hours ago | prev | next [\u2013]I don't know enough to agree that it's pointless, but I'd agree that when I looked at it I saw a lot of abstraction of already simple stuff (like the examples the post gives) and decided that for what I was doing it would be faster and easier to understand to just write my own python script. Though I can picture for very inexperienced developers the abstractions may be helpful short term?replypaulgb 15 hours ago | parent | next [\u2013]I had a similar experience; looked into using it for something, and felt that it would be easier to recreate the things I would use langchain for in Jinja2, than it would be to reshape my code to the interface that langchain wanted.replyCGamesPlay 11 hours ago | prev | next [\u2013]Langchain was useful to me personally for two reasons: using their prompt templates as a starting point for my own, and seeing how their \u201ctools\u201d were built to learn about good Python libraries to build my own tools with.Viewed through this lens, LangChain was more a \u201csample codebase\u201d than a library for me, and it was reasonably good for that.replyTostino 9 hours ago | parent | next [\u2013]When you actually get down to it, they're pointless and counterproductive. Templates are pretty useless and have inconsistently implemented features which make them non-compatible with different LLM backends without changing all your code. Honestly, cannot recommend avoiding the library all together high enough.replycrosen99 13 hours ago | prev | next [\u2013]I keep going back to LangChain thinking it just hasn't found its legs yet, but every time I do I retreat exasperated. I don't find their abstractions useful or intuitive, and their documentation is woefully scattered and incomplete. Things are moving so quickly with LLMs that theirs is no easy task, but so far they haven't really cracked the nut of making LLM app development easier.replylmeyerov 17 hours ago | prev | next [\u2013]I've definitely got heartache here, and they merit criticism, but it is realWe need a lot of pluggability to support diff vendor LLMs and BYO LLMs in Louie.ai, so having langchain has been nice for helping code to interfaces vs vendor lockin. It definitely has growing pains - ex: sync & multithreading is important for us so we are generally coding around langchain while that smooths out. Likewise, we ended up building much of our conversational and multitool capabilities as custom libraries vs using theirs for similar quality reasons. We can't use any of the codegen capabilities because they are massive security holes so doing our own work there too.If anyone is into that kind of work (backend, AI & web infra, ...), definitely hiring for core platform & cool customer projects here: louie.ai / Graphistry.com/careersreplylmeyerov 16 hours ago | parent | next [\u2013]Also, the thread title is unintentionally funny: I'd like the interface to be more functional so we can write truly 'point-free' pipelines, especially around areas like memory. Ex: When dealing with multithreading, that makes it a lot safer. There are projects exploring that, but langchain is winning as a pluggable interface for many new LLM providers.Edit: link - https://en.wikipedia.org/wiki/Tacit_programmingreplyrgrieselhuber 14 hours ago | prev | next [\u2013]I've built a few LLM-based projects now and quickly discovered that Langchain was overkill (and not even very good overkill) for my use cases. I thought it was just me, glad to hear it's not.replycodeptualize 14 hours ago | prev | next [\u2013]Coming from a frontend background this reminds me a lot of the frontend situation some years ago when it was super common to npm install the stupidest pointless packages.Of course some people still do, but hard lessons were learned and all experienced people I know are a lot more mindful and cautious what dependencies they add.It seems to me that this space, and maybe data science more broadly, is currently in that situation. Maybe it's the lack of coding skills, maybe it's the transition from one-off research notebooks to production applications, or maybe it's just the norm to have big do it all libraries (like pandas, scikit etc), idk, but I expect the same lessons will be learned.For Langchain I wonder how they will keep up with changes in all the things they have their abstractions on. I guess having a huge community helps, but that doesn't help you with compatibility. It would not surprise me if that will get really ugly.replyShamelessC 11 hours ago | parent | next [\u2013]The problem is that coders are used to dealing with code. GPT-4 is a robust processor for semantics as conveyed by strings of characters. The whole point is that you don\u2019t need code. You just ask it what you want.But programmers love to think they can still make improvements to such a system using code. In reality, any improvements that can be made are the responsibility of f-strings and/or a templating mechanism and even that may be overkill in many cases.replycodeptualize 1 hour ago | root | parent | next [\u2013]Often there is still a lot of programming to do, as a lot of the use cases involve some sort of integration into a bigger systems, or you might have to process larger quantities of data which gets you into queues and for example managing rate limits.That said I 100% agree that often the basic tools are sufficient to solve these problems, and where it gets complex there are many battle tested solutions.replyanonzzzies 3 hours ago | prev | next [\u2013]Everyone was so hyped up by this useless thing that I thought I was going crazy. Literally everything is done faster and easier and more readable and more maintainable doing it with a lines of Python yourself. Lot of hype with AI frameworks, especially this one.replym3kw9 15 hours ago | prev | next [\u2013]Langchain is as pointless as one of those kitchen tools that specifically cuts egg into slices, but you could have done that with a knife.replyearleybird 12 hours ago | parent | next [\u2013]I like that analogy. I have one of those slicers and every time I use it I have two thoughts. First, this slices so quick and evenly. Second, there's a whole lot more I have to clean up compared to the knife.replythelastparadise 10 hours ago | root | parent | next [\u2013]I find the egg slicers to be a bit fragile. I'm on my 3rd one. The cutting wires keep breaking.replyhybridrxn 2 hours ago | prev | next [\u2013]100% agree. It is just a tactical way to SLOW LLM startups down with debugging hell. Highly would not recommend.replyhospitalJail 16 hours ago | prev | next [\u2013]Does it introduce more lines of code? YesDoes it introduce features that you don't need to implement yourself? YesDoes it make it easy to drop OpenAI? YesWhat's the problem?replyteaearlgraycold 15 hours ago | parent | next [\u2013]You'll still need to re-tune your prompt and the hyperparameters when switching models. So the actual effort of switching models is not improved much if at all.replycelestialcheese 13 hours ago | root | parent | next [\u2013]This. I'll still use langchain for token/cost counting and some nice abstractions on top of the LLM, and the document loader system is semi-useful, but all of the retriever/chain stuff abstracts away the most important part - the prompt.replyTostino 7 hours ago | root | parent | next [\u2013]I've tried to switch out prompts between LLM's and I've had to change every bit of code provided by laying chain with a different implementation between them. It is an entirely useless abstraction. The prompt template is not at all transferrable.replyredox99 12 hours ago | root | parent | prev | next [\u2013]Hopefully as LLMs get smarter, you'll need less prompt engineering and stuff will \"just work\" across models.replysandkoan 12 hours ago | prev | next [\u2013]Wholeheartedly agree\u2014it adds layers of bloat and abstraction between you and the actual ReAct pattern, which can be trivially implemented in maybe 50 sloc.replyPaulHoule 15 hours ago | prev | next [\u2013]Every system I\u2019ve seen for managing this kind of system has flaws, including the ones that I have written.For instance scikit-learn implements excellent algorithms for model selection that would apply, in principle, to a model based on huggingface transformers that might take 2 hours to train. skl is a fast machine if memory fits in RAM on a single computer, but it is not up to task for multiple computers or anything mortal to a single process such as the computer bring turned off.HF has model selection algorithms too, but not as nice. They don\u2019t take the same kind of datasets as all so it would be a hassle to import my ski models into HF.I have to be able to compare models generated with any kind of tools so I think I will build a universal model selection framework (builds and test models) but then you run into the problems langchain did where there is a lot of structure imposed and all sorts of quirks and performance losses because of that structure.For instance my current skl selector wastes a lot of resources computing stuff from scratch over and over again and if the code were properly organized it could get the job done 3 times faster but the same trick wouldn\u2019t work for every other experiment I might want to do.So we are all running into hurdles and finding ways to jump over them, making a lot of mistakes because we are in a rush and don\u2019t know better yet.replynamuol 14 hours ago | prev | next [\u2013]I tried to improve the type coverage of the JS package and I came to a lot of the same conclusions. It feels like a lot of unnecessary and poorly conceived indirection and abstraction. There\u2019s basically just a lot more to learn especially if you\u2019re just getting started.It\u2019s maybe useful as a repository of prompting techniques, but I found myself constantly monitoring the actual prompt text being generated rather than reading the code that produces it\u2026replysandGorgon 12 hours ago | prev | next [\u2013]I think that Generative AI applications is a config management problem. Think Prompts X Chains X LLMs. Your prompts wont work across everything and everything will break on model change. Coding this into ur classes is what everyone does.I think the better answer is to declaratively pull out the prompts X chains as jsonnet code. Call it trauma & learnings from the K8s/Borg world. We have formats that have evolved as a result of millions of lines of code wrangling clusters/terraform/etc - so we decided to build a SDK over it.that is what we did here - https://github.com/arakoodev/EdgeChains/releases/tag/0.2.0EdgeChains is basically Generative AI prompt engineering modeled as config management.replyjpulec 13 hours ago | prev | next [\u2013]I've been using the JS version of langchain for a few months now, and despite there being a lot of valid criticism, (especially around the abstractions it provides) I'm still glad to be using it.We get the benefits of a well used library, which means making certain changes is easy. For example, swapping our vector database was a one line change, as was swapping our cache provider. When OpenAI released GPT-4, we were able to change one parameter, and everything still just worked.Sure, it's moving fast, and could use a lot better documentation. At this point, I've probably read the entire source code several times over. But when we start testing performance of different models, or decide that we need to add persistent replayability to chains of LLM calls, it should be pretty easy. These things matter to production applications.replymmq 13 hours ago | parent | next [\u2013]> When OpenAI released GPT-4, we were able to change one parameter, and everything still just worked.Wouldn't that be the same if you used the OAI js library directly? Basically swapping the model parameter?replyjpulec 12 hours ago | root | parent | next [\u2013]It's not. The API is different, since GPT-4 is a chat based model, and davinci isn't. It's not a huge difference, but these little sort of things add up.replydbish 3 hours ago | root | parent | next [\u2013]It is a very minor change (made the changes in minutes and didn't have to bring in a new framework for it).replymmq 12 hours ago | root | parent | prev | next [\u2013]I see, thought you were using GPT-3.5 and moved to GPT-4.replyholografix 8 hours ago | prev | next [\u2013]Langchain is an obvious VC / investor hustle by a handful of smart developers who are betting on the low sophistication of entrants to ML and Data science.It doesn\u2019t do much but it wraps some obvious functionality with method names and paper thing abstractions that speaks the language of people who don\u2019t know Python beyond Jupiter Notebooks.All power to them, they saw a gap and pounced.reply0xPetra 1 hour ago | prev | next [\u2013]LangChain is a \"utils\" libraryChange my mind.replycloudking 17 hours ago | prev | next [\u2013]What business problems are you solving with Langchain and LLMs?replywahnfrieden 16 hours ago | parent | next [\u2013]Reselling access to Langchain and LLMsreplycloudking 15 hours ago | root | parent | next [\u2013]Perfect.. I've seen so many demos showing people feeding data to LLMs so they can \"ask questions about their data\" but still not seen any real business use cases. Is anyone using these tools in production for a real problem?replyramoz 14 hours ago | root | parent | next [\u2013]The enterprise search domain has evolved quite a bit, utilizing & integrating retrieval-rerank architectures for a few years now. That includes embedding/vector storage, as well as LLM usage (eg using Google T5 for query understanding and model rerank)\u2026 there\u2019s some generative modeling but not really like GPT\u2026 more like structuring an abstract tree from a complex Boolean query, and sending that tree into an custom retrieval approach over ANN & rerank ensemble.If you\u2019re doing that type of work in a serious manner you don\u2019t use libraries like langchain or lamaindex. They are a bit late/irrelevant to the engineering that exists in that type of environment.replyshon 16 hours ago | root | parent | prev | next [\u2013]Lolreplyhcks 15 hours ago | parent | prev | next [\u2013]It\u2019s LLM wrappers all the way downreplyhamhamed 17 hours ago | prev | next [\u2013]I tried using langchain.js after a bit of hype and overwhelming dev support and incremental releases, but it became added complexity for no reason for our case.OpenAI's NPM is much easier to use. A lot of what langchain promised out of the box didn't work like caching. Anyways it's still beta i believereplylgrammel 7 hours ago | prev | next [\u2013]If you\u2019re using JS/TS and want to have a nicer API for LLM calls (and a bit more), check out https://github.com/lgrammel/ai-utils.jsreplyjmilldotdev 7 hours ago | prev | next [\u2013]Stop doing prompt ops.https://pbs.twimg.com/media/FzZxxmIacAEBPof?format=png&name=...replydmezzetti 10 hours ago | prev | next [\u2013]If you'd like another option built on a foundation of open LLMs, open models and open source, check out txtai (https://github.com/neuml/txtai).Disclaimer: I am the author of txtaireplyteaearlgraycold 17 hours ago | prev | next [\u2013]I have done a bit of research trying to figure out why anyone would use langchain. The main two reasons I\u2019ve found are these:1. Newbies that want to play with LLMs don\u2019t know where to start or what the major building blocks even are. Despite the complaints here about documentation their getting started docs will walk you through the concepts. Going from total ignorance and confusion to now having a rough understanding of loading a prompt with chat history, using an embeddings database, calling a completions endpoint, etc. will make people feel accomplished. And then lang chain has earned some loyalty just because they were there for you first.2. In the case that you don\u2019t know which embedding db, AI host, or model you want to use you can quickly swap those in and out and measure the results. That means there\u2019s little reason to complicate your back end code with lang chain (I\u2019ve always just written my own abstraction layer to make this possible with very few lines of code). But for a python notebook it can make sense.replyjmugan 16 hours ago | prev | next [\u2013]I found that you need to dig into the actual code and debug it while it is running to see what is going on to actually use the library (both with Langchain and LlamaIndex). That's unfortunate, but it does show a path to get you to where you want to go and is probably faster in the long run than writing your own code because you can swap components (e.g., which LLM or which vector DB) in and out.replytedtimbrell 15 hours ago | prev | next [\u2013]For me the biggest benefit is just following the project and seeing what the community is doing with llms (It\u2019s also not bad for quick proofs of concept).That said especially in python it\u2019s not that hard to reimplement things yourself in a cleaner way. Output parsing for agents was nice but with the function update from OpenAI it\u2019s not really necessary (if you\u2019re just using their API)replympaepper 13 hours ago | prev | next [\u2013]I agree it's not so easy to work with Langchain.That's wy I built the simple LLM agents repo which you can understand in 5 minutes:https://github.com/mpaepper/llm_agentsreplysolomonb 13 hours ago | prev | next [\u2013]LangChain is a perfect example of unnecessary abstraction. You could build a much simpler and more composable library for working with LLMs simply using functions and function composition. This isn't rocket science.replyaiunboxed 14 hours ago | prev | next [\u2013]Thank god, there is someone else who feels the same way. There are tons of modules and none of them is production ready.It feels good for hobby / college projects, but would not use it for production.The pace at which they release features is also scary.replytippytippytango 10 hours ago | prev | next [\u2013]It\u2019s technical rent seeking and premature abstraction.replyszopa 13 hours ago | prev | next [\u2013]At one point I got so frustrated with langchain that I wrote my own stuff in go: https://github.com/ryszard/agencyreplystan_kirdey 15 hours ago | prev | next [\u2013]there is an alternative that is production-grade - deepset haystack https://haystack.deepset.ai/p.s. i am contributor so there could be biasreplyDrDroop 17 hours ago | prev | next [\u2013]const THE_LEFT_HANDED_IDEAL_FOR_THE_EVEN_NUMBERS_OF_THE_NATURAL_NUMBERS_UNDER_MULTIPLICATION = 2replyjdprice 14 hours ago | prev | next [\u2013]Completely agree. I had this exact thought last week. It's been helpful to go through their repo to see how they've done certain things, but it's a textbook leaky abstraction.replymoneywoes 12 hours ago | prev | next [\u2013]Didn\u2019t they raise at a $200 million valuationreplydonpark 7 hours ago | prev | next [\u2013]I agree that LangChain is pointless for experienced ML developers building products. For the rest, I disagree as just getting to the point where same observation can be made is worthwhile.replyzoba 14 hours ago | prev | next [\u2013]I want an off the shelf \u201ctalk to PDFs\u201d solution and was hopeful langchain was it.replyufo 14 hours ago | prev | next [\u2013]What is langchain?replynoman-land 14 hours ago | parent | next [\u2013]I pasted your question directly into DDG and the entire first page has the answer.https://duckduckgo.com/?q=What+is+langchainreplyhandonam 16 hours ago | prev | next [\u2013]the consistency and conventionality of the methods in the langchain library are very sporadic, imoreplyrevskill 16 hours ago | prev | next [\u2013]I don't trust them, because they never talk about their \"tradeoffs\". Every software has its tradeoff.replypolitelemon 14 hours ago | parent | next [\u2013]I've rarely ever seen software talk about its tradeoffs. They want you to use the software.K8s and react are wildly popular, huge tradeoffs, but mention none of them.replyshermix011 12 hours ago | root | parent | next [\u2013]DuckDB does on their page. https://duckdb.org/replyDer_Einzige 17 hours ago | prev | next [\u2013]This guy's analysis is terrible. I literally built a retrieval augmented generation with memory in langchain last night (comments claim you can't do this)Sure, langchain has poor documentation and useless helper functions. That doesn't mean that it's pointless.replytehsauce 16 hours ago | parent | next [\u2013]Just fyi, if you use a standard knn library like faiss and pretty much any embedding + language model raw from huggingface or an API, it will require ~15 lines of code to do what you describe. I\u2019m not sure how much shorter langchain made your implementation but I can\u2019t imagine it saving too much.replyrisyachka 16 hours ago | parent | prev | next [\u2013]The point is in 99% of use cases no one will ever swap OpenAI or vector storage db for anything else. All Langchain does in these cases is introduces useless abstraction that takes longer to implement and makes things less transparent.And when you need some customization instead of taking you 10 minutes it takes an hour to work around this abstraction.replychpmrc 16 hours ago | parent | prev | next [\u2013]Could you please share the code? I tried doing the same and, like the people in that thread, could not. TIA!replysiva7 17 hours ago | prev [\u2013]It's easy to hate on langchain. Sure, the architecture isn't the best but it's where the crowd is so it's a safe betreplytikhonj 17 hours ago | parent [\u2013]That just makes it easier to hate. Our collective tendency to build atop mediocre foundations just because they got popular first is exhausting.replyGuidelines | FAQ | Lists | API | Security | Legal | Apply to YC | ContactSearch:",
    "hn_summary": "- Langchain is criticized for trying to solve problems on top of technical foundations that are not suitable.\n- Users find that the custom prompts and prompt tuning required for each feature in Langchain are not reusable and result in subpar output.\n- Many developers have found it more efficient to build their own solutions using simpler methods and libraries, rather than using Langchain's abstractions."
  },
  {
    "id": 36646791,
    "timestamp": 1688838448,
    "title": "I stopped buying new laptops (2020)",
    "url": "https://solar.lowtechmagazine.com/2020/12/how-and-why-i-stopped-buying-new-laptops/",
    "hn_url": "http://news.ycombinator.com/item?id=36646791",
    "content": "How and Why I Stopped Buying New LaptopsAs a freelance journalist \u2013 or an office worker if you wish \u2013 I have always believed that I should regularly buy a new laptop. But older machines offer more quality for much less money.Written by Kris De DeckerTranslations fr de nl plImage: Low-tech Magazine is now written and published on a 2006 ThinkPad X60s.Being an independent journalist \u2013 or an office worker if you wish \u2013 I always reasoned that I needed a decent computer and that I need to pay for quality. Between 2000 and 2017, I consumed three laptops that I bought new and which cost me around 5,000 euros in total \u2013 roughly 300 euros per year over the entire period. The average useful life of my three laptops was 5.7 years.In 2017, somewhere between getting my office, I decided not to buy any more new laptops. Instead, I switched to a 2006 second-hand machine that I purchased online for 50 euros and which does everything that I want and need. Including a new battery and a simple hardware upgrade, I invested less than 150 euros.If my 2006 laptop lasts as long as my other machines \u2013 if it runs for another 1.7 years \u2013 it will have cost me only 26 euros per year. That\u2019s more than 10 times less than the cost of my previous laptops. In this article, I explain my motivations for not buying new laptops, and how you could do the same.Energy and material use of a laptopNot buying new laptops saves a lot of money, but also a lot of resources and environmental destruction. According to the most recent life cycle analysis, it takes 3,010 to 4,340 megajoules of primary energy to make a laptop \u2013 this includes mining the materials, manufacturing the machine, and bringing it to market. 1Each year, we purchase between 160 and 200 million laptops. Using the data above, this means that the production of laptops requires a yearly energy consumption of 480 to 868 petajoules, which corresponds to between one quarter and almost half of all solar PV energy produced worldwide in 2018 (2,023 petajoules). 2 The making of a laptop also involves a high material consumption, which includes a wide variety of minerals that may be considered scarce due to different types of constraints: economic, social, geochemical, and geopolitical. 34The production of microchips is a very energy- and material-intensive process, but that is not the only problem. The high resource use of laptops is also because they have a very short lifespan. Most of the 160-200 million laptops sold each year are replacement purchases. The average laptop is replaced every 3 years (in business) to five years (elsewhere). 3 My 5.7 years per laptop experience is not exceptional.Laptops don\u2019t changeThe study cited dates from 2011, and it refers to a machine made in 2001: a Dell Inspiron 2500. You are forgiven for thinking that this \u201cmost recent life cycle analysis of a laptop\u201d is outdated, but it\u2019s not. A 2015 research paper discovered that the embodied energy of laptops is static over time. 5The scientists disassembled 11 laptops of similar size, made between 1999 and 2008, and weighed the different components. Also, they measured the silicon die area for all motherboards and 30 DRAM cards produced over roughly the same period (until 2011). They found that the mass and material composition of all key components \u2013 battery, motherboard, hard drive, memory \u2013 did not change significantly, even though manufacturing processes became more efficient in energy and material use.The reason is simple: improvements in functionality balance the efficiency gains obtained in the manufacturing process. Battery mass, memory, and hard disk drive mass decreased per unit of functionality but showed roughly constant totals per year. The same dynamic explains why newer laptops don\u2019t show lower operational electricity consumption compared to older laptops. New laptops may be more energy-efficient per computational power, but these gains are offset by more computational power. Jevon\u2019s paradox is nowhere as evident as it is in computing.The challengeAll this means that there\u2019s no environmental or financial benefit whatsoever to replacing an old laptop with a new one. On the contrary, the only thing a consumer can do to improve their laptop\u2019s ecological and economic sustainability is to use it for as long as possible. This is facilitated by the fact that laptops are now a mature technology and have more than sufficient computational power. One problem, though. Consumers who try to keep working on their old laptops are likely to end up frustrated. I shortly explain my frustrations below, and I\u2019m pretty confident that they are not exceptional.Image: The three new laptops I used from 2000 to 2017.My first laptop: Apple iBook (2000-2005)In 2000, when I was working as a freelance science and tech journalist in Belgium, I bought my first laptop, an Apple iBook. Little more than two or three years later, the charger started malfunctioning. When informed of the price for a new charger, I was so disgusted with Apple\u2019s sales practices \u2013 chargers are very cheap to produce, but Apple sold them for a lot of money \u2013 that I refused to buy it. Instead, I managed to keep the charger working for a few more years, first by putting it under the weight of books and furniture, and when that didn\u2019t work anymore, by putting it in a firmly tightened clamp.My second laptop: IBM ThinkPad R52 (2005-2013)When the charger eventually died entirely in 2005, I decided to look for a new laptop. I had only one demand: it should have a charger that lasts or is at least cheap to replace. I found more than I was looking for. I bought an IBM Thinkpad R52, and it was love at first use. My IBM laptop was the Apple iBook counterpart, not just in terms of design (a rectangular box available in all colours as long as it\u2019s black). More importantly, the entire machine was built to last, built to be reliable, and built to be repairable.Circular and modular products are all the hype these days, its lifetime could be extended endlessly by gradually repairing and replacing every part that it consists of. The question is not how we can evolve towards a circular economy, but instead why we continue to evolve away from it.The question is not how we can evolve towards a circular economy, but instead why we continue to evolve away from it.My Thinkpad was more expensive to buy than my iBook, but at least I didn\u2019t spend all that money on a cute design but a decent computer. The charger gave no problems, and when I lost it during a trip and had to buy a new one, I could do so for a fair price. Little did I know that my happy purchase was going to be a once-in-a-lifetime experience.Image: The IBM ThinkPad R52 from 2005.My third laptop: Lenovo Thinkpad T430 (2013-2017)Fast forward to 2013. I am now living in Spain and I\u2019m running Low-tech Magazine. I\u2019m still working on my IBM Thinkpad R52, but there are some problems on the horizon. First of all, Microsoft will soon force me to upgrade my operating system, because support for Windows XP is to end in 2014. I don\u2019t feel like spending a couple of hundred euros on a new operating system that would be too demanding for my old laptop anyway. Furthermore, the laptop had gotten a bit slow, even after it had been restored to its factory settings. In short, I fell into the trap that the hardware and software industries have set up for us and made the mistake of thinking that I needed a new laptop.Having been so fond of my Thinkpad, it was only logical to get a new one. Here\u2019s the problem: in 2005, shortly after I had bought my first Thinkpad, Lenovo, a Chinese manufacturer that is now the largest computer maker in the world, bought IBM\u2019s PC business. Chinese companies don\u2019t have a reputation for building quality products, especially not at the time. However, since Lenovo was still selling Thinkpads that looked almost identical to those built by IBM, I decided to try my luck and bought a Lenovo Thinkpad T430 in April 2013. At a steep price, but I assumed that quality had to be paid for.My mistake was clear from the beginning. I had to send the new laptop back twice because its case was deformed. When I finally got one that didn\u2019t wobble on my desk, I quickly ran into another problem: the keys started breaking off. I can still remember my disbelief when it happened for the first time. The IBM Thinkpad is known for its robust keyboard. If you want to break it, you need a hammer. Lenovo obviously didn\u2019t find that so important and had quietly replaced the keyboard with an inferior one. Mind you, I can be an aggressive typist, but I have never broken any other keyboard.I grumpily ordered a replacement key for 15 euros. In the months after that, replacement keys became a recurring cost. After spending more than 100 euros on plastic keys, which would soon break again, I calculated that my keyboard had 90 keys and that replacing them all just once would cost me 1,350 euros. I stopped using the keyboard altogether, temporarily finding a solution in an external keyboard. However, this was impractical, especially for working away from home \u2013 and why else would I want a laptop?There was no getting around it anymore: I needed a new laptop. Again. But which one? For sure it would not be one made by Lenovo or Apple.Image: Replacing all keys on my Lenovo T430 would have cost me 1,350 euros.My fourth laptop: IBM Thinkpad X60s (2017-now)Not finding what I was looking for, I decided to go back in time. By now, it had dawned on me that new laptops are of inferior quality compared to older laptops, even if they carry a much higher price tag. I found out that Lenovo switched keyboards around 2011 and started searching auction sites for Thinkpads built before that year. I could have changed back to my ThinkPad R52 from 2005, but by now, I had become accustomed to a Spanish keyboard, and the R52 had a Belgian one.In April 2017, I settled on a used Thinkpad X60s from 2006. 6 As of December 2020, the machine is in operation for almost 4 years and is 14 years old \u2013 three to five times older than the average laptop. If I loved my Thinkpad R52 from 2005, I adore my Thinkpad X60s from 2006. It\u2019s just as sturdily built \u2013 it already survived a drop from a table on a concrete floor \u2013 but it\u2019s much smaller and also lighter: 1.43 kg vs. 3.2 kg.My 2006 Thinkpad X60s does everything I want it to do. I use it to write articles, do research, and maintain the websites. I have also used it on-stage to give lectures, projecting images on a large screen. There\u2019s only one thing missing on my laptop, especially nowadays, and that\u2019s a webcam. I solve this by firing up the cursed 2013 laptop with the broken keys whenever I need to, happy to give it some use that doesn\u2019t involve its keyboard. It could also be solved by a switch to the Thinkpad X200 from 2008, which is a newer version of the same model and has a webcam.Image: My ThinkPad X60s.How to make an old laptop run like it\u2019s newNot buying any more new laptops is not as simple as buying a used laptop. It\u2019s advisable to upgrade the hardware, and it\u2019s essential to downgrade the software. There are two things you need to do:1. Use low energy softwareMy laptop runs on Linux Lite, one of several open-source operating systems specially designed to work on old computers. The use of a Linux operating system is not a mere suggestion. There\u2019s no way you\u2019re going to revive an old laptop if you stick to Microsoft Windows or Apple OS because the machine would freeze instantly. Linux Lite does not have the flashy visuals of the newest Apple and Windows interfaces, but it has a familiar graphical interface and looks anything but obsolete. It takes very little space on the hard disk and demands even less computing power. The result is that an old laptop, despite its limited specifications, runs smoothly. I also use light browsers: Vivaldi and Midori.Having used Microsoft Windows for a long time, I find Linux operating systems to be remarkably better, even more so because they are free to download and install. Furthermore, Linux operating systems do not steal your personal data and do not try to lock you in, like the newest operating systems from both Microsoft and Apple do. That said, even with Linux, obsolescence cannot be ruled out. For example, Linux Lite will stop its support for 32-bit computers in 2021, which means that I will soon have to look for an alternative operating system, or buy a slightly younger 64-bit laptop.2. Replace the hard disk drive with a solid-state driveIn recent years, solid-state drives (SSD) have become available and affordable, and they are much faster than hard disk drives (HDD). Although you can revive an old laptop by merely switching to a light-weight operating system, if you also replace the hard disk drive with a solid-state drive, you\u2019ll have a machine that is just as fast as a brand new laptop. Depending on the storage capacity you want, an SSD will cost you between 20 euro (120 GB) and 100 euro (960 GB).Installment is pretty straightforward and well documented online. Solid-state drives run silently and are more resistant to physical shock, but they have a shorter life expectancy than hard disk drives. Mine is now working for almost 4 years. It seems that both from an environmental and financial viewpoint, an old laptop with SSD is a much better choice than buying a new laptop, even if the solid-state drive needs replacement now and then.Spare laptopsMeanwhile, my strategy has evolved. I have bought two identical models for a similar price, in 2018 and early 2020, to use as spare laptops. Now I plan to keep working on these machines for as long as possible, having more than sufficient spare parts available. Since I bought the laptop, it had two technical issues. After roughly a year of use, the fan died. I had it repaired overnight in a tiny and messy IT shop run by a Chinese man in Antwerp, Belgium. He said that my patched fan would run for another six months, but it\u2019s still working more than two years later.Then, last year, my X60s suddenly refused to charge its battery, an issue that had also appeared with my cursed 2013 laptop. It seems to be a common problem with Thinkpads, but I could not solve it yet. Neither did I really have to because I had a spare laptop ready and started using that one whenever I needed or wanted to work outside.Image: Three identical 2006 laptops, all in working order, for less than 200 euros.Image: Inside the Thinkpad X60s. Source: Hardware Maintenance Manual.The magical SD-cardNow to introduce you to my magical SD-card, which is another hardware upgrade that facilitates the use of old (but also new) laptops. Many people have their personal documents stored on their laptop\u2019s hard drive and then make backups to external storage media if all goes well. I do it the other way around.I have all my data on a 128 GB SD-card, which I can plug into any of the Thinkpads that I own. I then make monthly backups of the SD-card, which I store on an external storage medium, as well as regular backups of the documents that I am working on, which I temporarily store on the drive of the laptop that I am working on. This has proven to be very reliable, at least for me: I have stopped losing work due to computer problems and insufficient backups.The other advantage is that I can work on any laptop that I want and that I\u2019m not dependent on a particular machine to access my work. You can get similar advantages when you keep all your data in the cloud, but the SD-card is the more sustainable option, and it works without internet access.Hypothetically, I could have up to two hard drive failures in one day and keep working as if nothing happened. Since I am now using both laptops alternately \u2013 one with battery, the other one without \u2013 I can also leave them at different locations and cycle between these places while carrying only the SD-card in my wallet. Try that with your brand new, expensive laptop. I can also use my laptops together if I need an extra screen.In combination with a hard disk drive, the SD-card also increases the performance of an old laptop and can be an alternative to installing a solid-state drive. My spare laptop does not have one and it can be slow when browsing heavy-weight websites. However, thanks to the SD-card, opening a map or document happens almost instantly, as does scrolling through a document or saving it. The SD-card also keeps the hard disk running smoothly because it\u2019s mostly empty. I don\u2019t know how practical using an SD-card is for other laptops, but all my Thinkpads have a slot for them.The costsLet\u2019s make a complete cost calculation, including the investment in spare laptops and SD-card, and using today\u2019s prices for both solid-state drives and SD-cards, which have become much cheaper since I have bought them:ThinkPad X60s: 50 euroThinkPad X60s spare laptop: 60 euroThinkPad X60 spare laptop: 75 euroTwo replacement batteries: 50 euro240 GB solid-state drive: 30 euro128 GB SD-card: 20 euroTotal: 285 eurosEven if you buy all of this, you only spent 285 euros. For that price, you may be able to buy the crappiest new laptop on the market, but it surely won\u2019t get you two spare laptops. If you manage to keep working with this lot for ten years, your laptop costs would be 28.5 euros per year. You may have to replace a few solid-state drives and SD-cards, but it won\u2019t make much difference. Furthermore, you save the ecological damage that is caused by the production of a new laptop every 5.7 years.Image: My laptop needs are met for the foreseeable future.Don\u2019t take it too farAlthough I have used my Thinkpad X60s as an example, the same strategy works with other Thinkpad models \u2013 here\u2019s an overview of all historical models \u2013 and laptops from other brands (which I know nothing about). If you prefer not to buy on auction sites, you can walk to the nearest pawnshop and get a used laptop with a guarantee. The chances are that you don\u2019t even need to buy anything, as many people have old laptops lying around.There\u2019s no need to go back to a 2006 machine. I hope it\u2019s clear that I am trying to make a statement here, and I probably went as far back as one can while keeping things practical. My first try was a used ThinkPad X30 from 2002, but that was one step too far. It uses a different charger type, it has no SD-card slot, and I could not get the wireless internet connection working. For many people, it may serve to choose a somewhat younger laptop. That will give you a webcam and a 64-bit architecture, which makes things easier. Of course, you can also try to beat me and go back to the 1990s, but then you\u2019ll have to do without USB and wireless internet connection.Your choice of laptop also depends on what you want to do with it. If you use it mainly for writing, surfing the web, communication, and entertainment, you can do it as cheaply as I did. If you do graphical or audiovisual work, it\u2019s more complicated, because in that case, you\u2019re probably an Apple user. The same strategy could be applied, on a somewhat younger and more expensive laptop, but it would suggest switching from a Mac to a Linux operating system. When it comes to office applications, Linux is clearly better than its commercial alternatives. For a lack of experience, I cannot tell you if that holds for other software as well.This is a hack, not a new economical modelAlthough capitalism could provide us with used laptops for decades to come, the strategy outlined above should be considered a hack, not an economical model. It\u2019s a way to deal with or escape from an economic system that tries to force you and me to consume as much as possible. It\u2019s an attempt to break that system, but it\u2019s not a solution in itself. We need another economical model, in which we build all laptops like pre-2011 Thinkpads. As a consequence, laptop sales would go down, but that\u2019s precisely what we need. Furthermore, with today\u2019s computing efficiency, we could significantly reduce the operational and embodied energy use of a laptop if we reversed the trend towards ever higher functionality.Significantly, hardware and software changes drive the fast obsolescence of computers, but the latter has now become the most crucial factor. A computer of 15 years old has all the hardware you need, but it\u2019s not compatible with the newest (commercial) software. This is true for operating systems and every type of software, from games to office applications to websites. Consequently, to make laptop use more sustainable, the software industry would need to start making every new version of its products lighter instead of heavier. The lighter the software, the longer our laptops will last, and we will need less energy to use and produce them.Kris De DeckerImages: Jordi Manrique Corominas, Adriana Parra, Roel Roscam AbbingProofreading: Eric WagnerSubscribe to our newsletter.Support Low-tech Magazine via Paypal or Patreon.Read Low-tech Magazine offline.CommentsTo make a comment, please send an e-mail to solar (at) lowtechmagazine (dot) com. Your e-mail address is not used for other purposes, and will be deleted after the comment is published. If you don\u2019t want your real name to be published, sign the e-mail with the name you want to appear.76 ReactionsDeng, Liqiu, Callie W. Babbitt, and Eric D. Williams. \u201cEconomic-balance hybrid LCA extended with uncertainty analysis: case study of a laptop computer.\u201d Journal of Cleaner Production 19.11 (2011): 1198-1206. https://www.sciencedirect.com/science/article/abs/pii/S0959652611000801 \u21a9\ufe0eInternational Renewable Energy Agency (IRENA). https://www.irena.org/solar \u21a9\ufe0eAndr\u00e9, Hampus, Maria Ljunggren S\u00f6derman, and Anders Nordel\u00f6f. \u201cResource and environmental impacts of using second-hand laptop computers: A case study of commercial reuse.\u201d Waste Management 88 (2019): 268-279. https://www.sciencedirect.com/science/article/pii/S0956053X19301825 \u21a9\ufe0e \u21a9\ufe0eBihouix, Philippe. The Age of Low Tech: Towards a Technologically Sustainable Civilization. Policy Press, 2020. https://bristoluniversitypress.co.uk/the-age-of-low-tech \u21a9\ufe0eKasulaitis, Barbara V., et al. \u201cEvolving materials, attributes, and functionality in consumer electronics: Case study of laptop computers.\u201d Resources, conservation and recycling 100 (2015): 1-10. https://www.sciencedirect.com/science/article/abs/pii/S0921344915000683 \u21a9\ufe0eLenovo took over IBM\u2019s PC business in 2005 and so strictly speaking I bought a Lenovo Thinkpad X60s. However, the hardware had not changed yet, and the laptop only carries the new brand name along that of IBM. My spare laptop, an almost identical model from the same year (X60 instead of X60s), has no reference to Lenovo whatsoever. \u21a9\ufe0eRelated ArticlesThemes: ICT Solar Powered WebsiteThe Printed Website: Volume III & The CommentsThe printed archives of Low-tech Magazine now amount to four volumes with a total of 2,398 pages and 709 images.December 2, 2021How Sustainable is a Solar Powered Website?We present our website\u2019s energy and uptime data, calculate the embodied energy of our configuration, consider the optimal balance between sustainability and server uptime, and outline possible improvements.January 28, 2020The Solar Powered Website in Spanish, French, and Other LanguagesDuring the last months we have been working on transforming Low-tech Magazine into a multilingual publication.January 27, 2020Low-tech Magazine: The Printed WebsiteRead Low-tech Magazine with no access to a computer, a power supply, or the internet.March 31, 2019",
    "summary": "- The author explains why they stopped buying new laptops and instead switched to using a second-hand 2006 machine that cost them significantly less money.\n- Not buying new laptops not only saves money but also reduces resource consumption and environmental destruction associated with laptop production.\n- The author provides tips on how to make an old laptop run like new by using low-energy software and replacing the hard disk drive with a solid-state drive.",
    "hn_title": "I stopped buying new laptops (2020)",
    "original_title": "I stopped buying new laptops (2020)",
    "score": 297,
    "hn_content": "- The author of the article discusses their experience of using older laptops for their needs and upgrading certain components to improve performance.\n- They mention that many laptops today are not upgradable and that soldered components like RAM and storage limit the lifespan and repairability of these machines.\n- The post discusses the issue of software updates and how they can affect older laptops, particularly in terms of performance and usability.\n- The author raises concerns about planned obsolescence in laptop designs, particularly with regards to non-replaceable components like batteries and soldered RAM.\n- There is a discussion in the comments about the need for more than 4GB of RAM for office and browsing tasks.\n- Some users mention their positive experiences with older laptops and upgrading components like RAM and storage, which have improved performance.\n- The conversation also touches on the limitations of older hardware for tasks such as video editing, 3D modeling, and gaming.\n- The author and commenters highlight the importance of considering individual needs and use cases when deciding whether to buy a new laptop or stick with an older one.- The article discusses the issue of rapidly replacing laptops and the environmental impact it has.\n- Buying secondhand devices can be more affordable and better for the environment than buying new ones.\n- Some people argue for buying the fastest laptop available to improve productivity, while others prioritize a high-quality screen for a better user experience.\n- The cost of new laptops should be considered in terms of their impact on the environment and the importance of the features they offer.\n- Upgradability and repairability of laptops are important factors to consider to reduce electronic waste.\n- The article mentions the issue of battery life in older laptops and the improvements in battery performance over the years.\n- The focus of the article is on encouraging readers to think critically about their laptop purchasing habits and to consider the environmental impact of their choices.- Discussion about consumerism and the mindset of buying new tech every year\n- Some argue that consumerism is a problem, while others believe people should be able to spend their own money as they see fit\n- Mention of batteries changing and the need for impulse control\n- Reference to a video about laptop battery life\n- Reference to modular GPU technology\n\nIn this post, there is a debate about consumerism and the pressure to buy new tech every year. It explores the mindset behind these purchases and whether it is worth the money. The discussion also touches on the importance of impulse control and the idea that people should be able to spend their own money as they see fit. Additionally, there are references to changing batteries and a video about laptop battery life. The post also mentions the use of modular GPU technology.",
    "hn_summary": "- The article explores the debate around consumerism and the pressure to buy new tech every year.\n- It discusses the mindset behind these purchases and whether they are worth the money.\n- The post mentions changing batteries and references a video about laptop battery life."
  },
  {
    "id": 36647364,
    "timestamp": 1688841306,
    "title": "Learn electronics by practice",
    "url": "https://beletronics.wordpress.com/",
    "hn_url": "http://news.ycombinator.com/item?id=36647364",
    "content": "Heidobito says:July 17, 2022 at 11:44 pmVery nice \ud83d\ude42Liked by 1 personReply",
    "summary": "- This post titled 'Learn electronics by practice' is for people who are interested in learning about electronics through hands-on practice.\n- The post provides a practical approach to learning electronics, which is especially useful for beginners who are new to the field.\n- Readers can expect to gain valuable knowledge and skills in electronics through the step-by-step guidance and practical examples provided in this post.",
    "hn_title": "Learn electronics by practice",
    "original_title": "Learn electronics by practice",
    "score": 296,
    "hn_content": "Hacker News new | past | comments | ask | show | jobs | submit loginLearn electronics by practice (beletronics.wordpress.com)296 points by Sandman 15 hours ago | hide | past | favorite | 52 commentsvector_spaces 4 hours ago | next [\u2013]I'm a math dropout, now self-taught software engineer who has been spending the summer filling in gaps in my CS education. Programming language implementation finally started to click for me -- bytecode interpreters and compilers are much less intimidating for me than they were several months ago. And now having implemented my own (toy) interpreters, I'm interested for the first time in understanding some of the nitty gritty details of how hardware components work. So I started working through the nand2tetris projects and tinkering with breadboards, and wow. This stuff is so much fun! I'm bummed I didn't start soonerI never really imagined I would be interested in this stuff, much less find it kind of beautiful. Pure math brain, if you aren't careful, can train you to view anything applied with disdain, and something as earthy as hardware even moreso. But it's kind of beautiful how there are deep and inevitable connections between some of the most abstract theory computer science has to offer (plt, pl design and implementation) and the way physical objects are harnessed for computation. I guess if you consider that von Neumann was a mathematician first and foremost then it starts to make more senseEither way, I'm having a great time -- definitely recommend anyone in a similar position learn this stuff whenever you're ready for itreplyyard2010 49 minutes ago | parent | next [\u2013]Nand2tetris[0] is hands down the best course I took in my CS BSc, Nissan and Shocken did such a wonderful job making this great content accessible. It was a fun and rewarding experience in which I built a toy computer bottom-up from scratch.[0] https://www.nand2tetris.org/replyaryamaan 1 hour ago | parent | prev | next [\u2013]Share more about your journey. These days I am feeling to having an interest rising about such things. Picked Codes book one night and got really hooked up.replykaishiro 8 hours ago | prev | next [\u2013]I opened this thinking I was the target audience - a longtime developer who has always wanted to get into electronics. However, this first paragraph...> In order to present our paradigm in learning electronics, we can take an example of a full adder chip that enables binary addition. Let us use a top-down approach, and look at the datasheet of the TTL (Transistor-Transistor Logic) chip 7483. We will immediately notice that the chip performs the addition of two 4-bit binary words, A and B....and the associated diagram, just immediately left me feeling like I was standing in a room full of people who were smarter than me. Is this really where one starts while learning basic electronics?replydpwm 2 hours ago | parent | next [\u2013]If you look up a data sheet for any 7483 variant, it is immediately notable: the first lines are something like \"4-bit binary full adder\" and the description says \"\u2026accept two 4-bit binary words\" If you skip to the next paragraph, you\u2019ll see they are onto transistors. Ideally the author could show a data sheet, but there may be reasons they can\u2019t.I found the material that followed to be a clear exposition of the fundamentals \u2013 this is as somebody who has tried to learn electronics over the years but nothing ever stuck. This did a better job than anything else at a pace that is about right for me.But YMMV and I personally relish being in a room full of people who are smarter than me.replydgacmu 7 hours ago | parent | prev | next [\u2013]I think this is mostly poor writing on the part of the author. You being able to \"immediately notice\" is contingent upon having read the data sheet, which was not linked nor reproduced, but the way it was presented made it seem like the diagram was sufficient. If you were to have read the data sheet, it would have stated up front that the circuit performs four-bit addition. But the page did not facilitate that...replyWalterBright 6 hours ago | root | parent | next [\u2013]> this is mostly poor writing on the part of the authorIndeed. The correct way is:\"It is trivially obvious to the most casual observer that the chip performs the addition of two 4-bit binary words\"replypfyra 2 hours ago | root | parent | next [\u2013]There should be a \"clearly\" in there as well as that word by itself is commonly believed to bring a lot of clarity.replySanderNL 2 hours ago | parent | prev | next [\u2013]You are plenty clever.This is the equivalent of introducing programming by giving a piece of ARM assembly and stating that it is immediately obvious that we are dealing with a merge sort implementation.I\u2019m not sure why, but I see this often in other domains as well. Math in particular. I guess it\u2019s the curse of knowledge.replytinco 2 hours ago | root | parent | next [\u2013]Except that when I was in highschool, programming in assembly was not in the curriculum, but designing simple logic circuits was. I am pretty sure we practiced designing a half adder in physics class as part of the electronics chapters.The bad part of the writing is the assumption that all that technical language and knowledge is stil at the top of your memory when you just picked up this book.replyHunpeter 1 hour ago | root | parent | next [\u2013]I wish we had done anything of that sort in my high school.replyAnimats 2 hours ago | parent | prev | next [\u2013]I once took a computer architecture course from the designer of the Burroughs 6700, who had us do a similar exercise. But that was back when people actually built things out of 74xx TTL. Few people do that any more. It would be very unusual to use a 4-bit adder chip today, unless you're deliberately doing retro stuff. And even more unusual to start there. Also, a 4-bit adder, a stateless device, is only useful when surrounded by latches and clocks so that something useful happens.Here's a real beginner level presentation, from Adafruit.[1] This may be too simplified for some.The Art of Electronics by Horowitz and Hill is highly recommended, but the original audience was physics grad students who needed to build instrumentation for physics experiments. The order of presentation is good, but it's a big book. Because it mentions current components by part number, the book ages rapidly.[1] https://learn.adafruit.com/guides/beginnerreplymatmann2001 8 hours ago | parent | prev | next [\u2013]In my experience in a university ECE program, you'd start with understanding the high level properties of transistors, then combining transistors to make AND and OR gates, then XOR and other gates, then MUXes and half/full adders, then flip-flops and eventually into synchronous (clocked) logic.The lab component of such coursework did start with TTL chips but the timing of the coursework was such that you'd have most of the asynchronous logic theory taught by the time the chips came out.replymike50 5 hours ago | root | parent | next [\u2013]Was it an Electrical Engineering, Electronics Engineering or Electrical Engineering Technology Program? My digital course skipped over transistor level and spent that time on basic FPGA's instead.replysimonbarker87 3 hours ago | root | parent | next [\u2013]Not OP but I did Electrical and Electronic Engineering undergrad and we started with diodes at the materials level, then BJT and FET transistors, then logic gates, flip flops, timers, ALUs and eventually working up to build a Motorola 68K micro controller from mid level components. There was some VHDL and FPGA in the later stages as well from memory.replyporknubbins 4 hours ago | parent | prev | next [\u2013]In my experience all serious electronics/electrical engineering learning material is written like this, as if the student knows everything about electronics except the one topic the author is explaining. Probably an artifact of being written for industry users. You can get used to it though, kind of putting boxes around certain circuits and just looking at behavior without asking how it works until you need to understand then doing a deep dive.replyjghn 3 hours ago | parent | prev | next [\u2013]It might have to do with how longtime \"longtime developer\" means.I took a look at TFA because of this. My experience caps out at doing a few heathkits in the early 80s and one single soldering of a resistor on my Synology to repair an issue a few years ago. I *mostly* understood the diagram, most of which was due to seeing it during CS adjacent classes in the early 90s.Unfortunately it's often the case that these ELI5 type articles assume baseline knowledge that's less than baseline.replyJKCalhoun 8 hours ago | parent | prev | next [\u2013]Nope, here: https://youtu.be/wvJc9CZcvBcreplyJKCalhoun 8 hours ago | prev | next [\u2013]It goes without saying that Ben Eater's 8-bit computer kits [1] are like Legos for wannabe-electronics nerds. The kits themselves were the response of the outpouring of requests from viewers of his amazing YouTube channel where he first rose to notoriety for his breadboard CPU and computer.I am currently assembling his 6502 breadboard computer (with the 16 x 2 LCD character display).Someone put together an awesome \"1-100 Transistor Projects\" as a PDF [2] for learning how transistor circuits work. The PDF + breadboard + a dozen or so transistors and small parts will keep you busy.There's a sequel \"101-200 Transistor Circuits\" [3], one on IC circuits [4] and one on the venerable 555 timer chip [5].The above should keep you busy for the rest of the year. If not, be sure to skim through some of the electronics hobbyist magazines [6].[1] https://eater.net[2] https://archive.org/details/1To100TransistorCircuits[3] https://www.talkingelectronics.com/projects/200TrCcts/101-20...[4] https://www.talkingelectronics.com/projects/100%20IC%20Circu...[5] https://www.talkingelectronics.com/projects/50%20-%20555%20C...[6] https://worldradiohistory.com/Popular-Electronics-Guide.htmreplyjboy55 4 hours ago | parent | next [\u2013]There's also a great game that walks through a bunch of these concepts and ends up with a working computer starting from gates.https://turingcomplete.game/reply_Microft 6 hours ago | parent | prev | next [\u2013]There is also http://www.555-timer-circuits.com/replypolalavik 10 hours ago | prev | next [\u2013]This is great - been building a list of resources to learn electronics[1] and will definitely be adding this![1] https://hardwareteams.com/docs/analog/circuits-resouces/replyhospitalJail 8 hours ago | prev | next [\u2013]If I learned this way, it would have been off-putting.So much nicer to grab an ardunio, motor, led, some sensors, etc...Then graduate to esp8266/esp32.But maybe I'm thinking embedded and my 2 years as an electrical engineer filled in some of the gaps when calculating things.Eh, just my opinion.replylinker3000 1 hour ago | parent | next [\u2013]If that's the route you want to take then that's absolutely fine.That area of electronics is \"modular digital electronics\" and doesn't take you through the principles of basic passive components (resistors, capacitors, inductors) and then into analogue circuit theory and semiconductors, digital logic and so on.The only thing that bugs me is when that approach is suggested as a response to 'how do I learn electronics' without any qualification or elaboration.replyCyberdog 8 hours ago | parent | prev | next [\u2013]I agree that learning with an Arduino/Pi Pico is personally more fun and gets you to the stage of making something practical, or at least interesting, much more quickly. That said, doing things fully at the resistor and diode level still has its place, since someone has to understand stuff well enough at that level to design the Arduinos and Picos that the rest of us play with.replymike50 5 hours ago | prev | next [\u2013]Someone rewrote a bunch of text books from the 1970s and put them on the internet. Unless you work in IC development you don't need to know how comparators work internally. The logic gate examples are slighly less obsolete (early 1980s). This is yet another joke introduction written by a hobbyist who wants to mess with individual transistors for no purpose. There are no practical applications for these examples and there is no learning value in them.replySanderNL 2 hours ago | parent | next [\u2013]You ever built a computer this way? If nothing else it\u2019s great fun and kind of magical TBH.replyteleforce 12 hours ago | prev | next [\u2013]Please check this book by Ex-Google, Cisco, Sun engineer and adjunct professor of UC Berkeley,Ed Lipiansky on electronics fundamentals (analog and digital):Electrical, Electronics, and Digital Hardware Essentials for Scientists and Engineers:https://www.wiley.com/en-us/Electrical,+Electronics,+and+Dig...replysriram_malhar 5 hours ago | parent | next [\u2013]Wow, this book's pricey. Is it worth it for a beginner?btw, Ed wasn't an adjunct at Berkeley. He taught at the UC Berkeley and UC Santa Cruz _extension_ program.replyagnosticmantis 11 hours ago | parent | prev | next [\u2013]Thanks for sharing! Does this teach one how to design circuits too?Also, someone suggested \u2018basic electronics: theory and practice\u2019 by Westcott & Westcott [0] for learning hobby electronics. Could someone familiar with both explain how they compare?0: https://books.google.com/books/about/Basic_Electronics.html?...replylinker3000 14 minutes ago | root | parent | next [\u2013]The former is more abstract on individual component theory and dives more deeply into the maths as it goes along. It is best suited to study for an electronics certification (or to supplement a main cert such as electrical engineering) if you want to understand the whole gamut of basic principles because, for example, you will be designing complete analogue and digital circuits from scratch.The Westcotts' book is more practical and gets stuck in to building things more quickly. It's not a course syllabus type book and is better for the hobbyist/tinkerer working with tried-and tested, classic chips (timers, amplifiers) and platforms (Raspberry Pi, Arduino).replyfabatka 13 hours ago | prev | next [\u2013]FWIW, it's digital electronicsreplymax_ 13 hours ago | parent | next [\u2013]What other kinds of \"electronics\" are there?reply_Microft 13 hours ago | root | parent | next [\u2013]Analog electronics [0] uses a continuously variable signal while digital electronics interprets the signal with thresholds that define states like 0 and 1.Here is a simple example: using a few discrete parts, like two transistors (Darlington pair), a LED and resistor, you can create a simple circuit that shows varying brightness of the LED depending on how close you move your hand or an object to an antenna connected to one of the transistors (forming a sort of proximity sensor). No microcontroller, SBC or even a hint of a digital signal involved at all.[0] https://en.m.wikipedia.org/wiki/Analogue_electronicsreplyrramadass 3 hours ago | root | parent | next [\u2013]> Here is a simple example: using a few discrete parts, like two transistors (Darlington pair), a LED and resistor, you can create a simple circuit that shows varying brightness of the LED depending on how close you move your hand or an object to an antenna connected to one of the transistors (forming a sort of proximity sensor)Do you have some book/video/etc. recommendations for this \"type\" of Electrical/Electronics circuit engineering? I only know how to program a MCU :-(replytiedieconderoga 12 hours ago | root | parent | prev | next [\u2013]\"Digital electronics\" communicate using discrete values, 1s and 0s.\"Analog electronics\" communicate using voltage/current/temperature/etc levels.One of the simplest examples is a voltage divider: if you put two resistors across a DC voltage source, like this:  V+-[R1]-\u00a2-[R2]-GNDThe voltage at the \u00a2 point will be:  V+ * (R2 / (R1 + R2))There are infinite possible values for that voltage, depending on the voltage source and the two resistors. It cannot necessarily be expressed exactly in a digital circuit, and it will fluctuate over time as the environment changes in temperature, humidity, EM noise, and so on.I usually recommend The Art of Electronics as a well-written, beginner-friendly textbook which covers the basic concepts.replymindcrime 10 hours ago | root | parent | prev | next [\u2013]Classifications are messy, but in addition to the other items mentioned already, I would say that some people would break out \"power electronics\"[1] as its own field.[1]: https://en.wikipedia.org/wiki/Power_electronicsreplydktnj 12 hours ago | root | parent | prev | next [\u2013]Probably the wrong way to look at it. Digital electronics doesn't really exist outside of theoretical spaces. It's all analogue underneath and any experienced digital designer will know that and what the consequences for things like signal integrity, noise immunity and latency.replydragontamer 3 hours ago | root | parent | next [\u2013]I mean... Analog electronics doesn't exist either, or for that matter, electronics in general.All of electronics assumes Kirchhoff's Current Law and Kirchoff's Voltage law, which does not truly exist in reality. Electrons often escape a circuit (see antennas, which throw the voltage / current into a wave that is emitted out of your designs). All wires are antennas, so even the most basic circuit doesn't have all the current return in a loop.The assumptions of KVL and KCL are just over-simplifications of true physics, Maxwell's equations. Because working with Maxwell's equations directly is too much effort in practice.--------------Electronics itself is a huge abstraction upon physics. You could, in theory, calculate all the voltages and currents using Maxwell's equations, except this isn't useful at all.Similarly: most of \"Analog Electronics\" uses simplifications as well: OpAmps are often assumed to be ideal (aka: infinite gain), which is good enough in most cases.replytonmoy 11 hours ago | root | parent | prev | next [\u2013]It\u2019s all about layers of abstraction. A web developer doesn\u2019t need to know about analog circuits to program computersreplyII2II 9 hours ago | root | parent | next [\u2013]It's better to describe analog and digital electronics as a subset of electronics. For the most part, they look at different domains. Even though they are based upon the same underlying principles, the simplifying assumptions are different. A more dramatic example is with RF electronics. While it may look like you are dealing with the same sort of things as the more common low frequency analog electronics, you are going to have a difficult time coaxing an analog circuit to work in the RF domain.Contrast that to web developers. They are dealing with very different principles from web browser developers, who are mostly working with different principles than operating system developers, who are working with entirely different principles from those who design hardware. It's not that they are working with a different subset of the same thing because one layer of abstraction is directly on top of the one below it and (ideally) the layers below completely hide how they work from the layers above.replyanthk 11 hours ago | root | parent | prev | next [\u2013]This. Digital is not that \"discrete\" as it looks, but just a threshold of values. FFT works on this pretty well, it's the basics.replynudgeee 10 hours ago | root | parent | prev | next [\u2013]Analog ElectronicsMicrowave/RF ElectronicsPower Electronicsreplymetaphor 6 hours ago | root | parent | prev | next [\u2013]https://en.wikipedia.org/wiki/Electronics#Subfieldsreplypatmorgan23 11 hours ago | root | parent | prev | next [\u2013]Analog, Radio and television were both developed before digital electronics was.replyAnimats 2 hours ago | root | parent | next [\u2013]Digital systems, using relays, predate analog electronics.There were relays used for railroad signaling in the 19th century. Union Switch and Signal was formed in 1881. The first active electronic device, the deForest Audion, was developed in 1906.replyhishamk 13 hours ago | root | parent | prev | next [\u2013]Analog, of course.replydonw 12 hours ago | root | parent | prev | next [\u2013]Russian.replyIndrekR 13 hours ago | root | parent | prev | next [\u2013]Microwave.replyChris2048 13 hours ago | root | parent | prev | next [\u2013]analoguereplyttarr 3 hours ago | prev | next [\u2013]Personally, this guy[0] eased me back into electronics, very clear explanations and beginner friendly.[0] https://vocademy.net/replysaboot 10 hours ago | prev [\u2013]Do any of these books have a purchase list of components to purchase?replyGuidelines | FAQ | Lists | API | Security | Legal | Apply to YC | ContactSearch:",
    "hn_summary": "- The HN thread discusses the experience of learning electronics by practice.\n- Nand2tetris is mentioned as a recommended course for learning electronics.\n- The article is criticized for its poor writing in explaining complex concepts.\n- Several resources, such as books, videos, and websites, are shared for learning electronics.\n- There is a mention of kits, like Ben Eater's 8-bit computer kits, that are ideal for learning electronics.\n- The importance of understanding both digital and analog electronics is highlighted."
  },
  {
    "id": 36648794,
    "timestamp": 1688850475,
    "title": "PdfGptIndexer: Indexing & searching PDF text data using GPT-2 & FAISS",
    "url": "https://github.com/raghavan/PdfGptIndexer",
    "hn_url": "http://news.ycombinator.com/item?id=36648794",
    "content": "PdfGptIndexerDescriptionPdfGptIndexer is an efficient tool for indexing and searching PDF text data using OpenAI's GPT-2 model and FAISS (Facebook AI Similarity Search). This software is designed for rapid information retrieval and superior search accuracy.Libraries UsedTextract - A Python library for extracting text from any document.Transformers - A library by Hugging Face providing state-of-the-art general-purpose architectures for Natural Language Understanding (NLU) and Natural Language Generation (NLG).Langchain - A text processing and embeddings library.FAISS (Facebook AI Similarity Search) - A library for efficient similarity search and clustering of dense vectors.Installing DependenciesYou can install all dependencies by running the following command:pip install langchain openai textract transformers langchain faiss-cpuHow It WorksThe PdfGptIndexer operates in several stages:It first processes a specified folder of PDF documents, extracting the text and splitting it into manageable chunks using a GPT-2 tokenizer from the Transformers library.Each text chunk is then embedded using the OpenAI GPT-2 model through the LangChain library.These embeddings are stored in a FAISS index, providing a compact and efficient storage method.Finally, a query interface allows you to retrieve relevant information from the indexed data by asking questions. The application fetches and displays the most relevant text chunk.Advantages of Storing Embeddings LocallyStoring embeddings locally provides several advantages:Speed: Once the embeddings are stored, retrieval of data is significantly faster as there's no need to compute embeddings in real-time.Offline access: After the initial embedding creation, the data can be accessed offline.Compute Savings: You only need to compute the embeddings once and reuse them, saving computational resources.Scalability: This makes it feasible to work with large datasets that would be otherwise difficult to process in real-time.Running the ProgramTo run the program, you should:Make sure you have installed all dependencies.Clone the repository to your local machine.Navigate to the directory containing the Python script.Replace \"<OPENAI_API_KEY>\" with your actual OpenAI API key in the script.Finally, run the script with Python.python3 pdf_gpt_indexer.pyPlease ensure that the folders specified in the script for PDF documents and the output text files exist and are accessible. The query interface will start after the embeddings are computed and stored. You can exit the query interface by typing 'exit'.Exploring Custom Data with ChatGPTCheck out the post here for a comprehensive guide on how to utilize ChatGPT with your own custom data.",
    "summary": "- PdfGptIndexer is a tool that helps you quickly find and search information in PDF documents using advanced AI models.\n- It uses libraries like Textract, Transformers, Langchain, and FAISS to process and store the text data in a compact and efficient way.\n- Storing the text embeddings locally speeds up the retrieval process, allows offline access, saves computational resources, and enables working with large datasets.",
    "hn_title": "PdfGptIndexer: Indexing and searching PDF text data using GPT-2 and FAISS",
    "original_title": "PdfGptIndexer: Indexing and searching PDF text data using GPT-2 and FAISS",
    "score": 273,
    "hn_content": "Hacker News new | past | comments | ask | show | jobs | submit loginPdfGptIndexer: Indexing and searching PDF text data using GPT-2 and FAISS (github.com/raghavan)273 points by raghavankl 12 hours ago | hide | past | favorite | 118 commentschaxor 12 hours ago | next [\u2013]The most frustrating thing about the many, many clones of this exact type of idea is that pretty much all of them require OpenAI.Stop doing that.You will have way more users if you make OpenAI (or anything that requires cloud) the 'technically possible but pretty difficult art of hoops to make it happen' option, instead of the other way around.The best way to make these apps IMO is to make them work entirely locally, with an easy string that's swappable in a .toml file to any huggingface model. Then if you really want OpenAI crap, you can make it happen with some other docker secret or `pass` chain or something with a key, while changing up the config.The default should be local first, do as much as possible, and then if the user /really/ wants to, make the collated prompt send a very few set of tokens to openAI.replyJimmyRuska 11 hours ago | parent | next [\u2013]It's difficult to compete. A small business might answer 10,000 requests to their chat bot. The options are- Pay openai less than $50mo- Manage cloud gpus, hire ml engineers > $1000/mo- Buy a local 4090 and put it under someone's desk, $no reliability +$1500 fixedAny larger business will need scalability and you still can't compete with openai pricing.Maybe one of you startup inclined people can make an openllama startup that charges by request and allows for finetuning, vector storagereplyxigency 10 hours ago | root | parent | next [\u2013]I\u2019ve got an expensive GPU at home I\u2019m not even using because there aren\u2019t that many things to do with it. Give me more local options.replyJimmyRuska 10 hours ago | root | parent | next [\u2013]https://github.com/oobabooga/text-generation-webuihttps://github.com/bentoml/OpenLLMhttps://www.reddit.com/r/LocalLLaMA/top/?t=monthreplyignoramous 3 hours ago | root | parent | next [\u2013]Andhttps://github.com/go-skynet/LocalAIhttps://github.com/juliooa/secondbrainhttps://github.com/louisgv/local.aireplyPeterStuer 3 hours ago | root | parent | prev | next [\u2013]Even if you are not into coding there are many good AI tools that run local. Two very easy examples:I've had great fun with the \" Easiest 1-click way to install and use Stable Diffusion on your computer.\"https://github.com/easydiffusion/easydiffusionAnd while Whisper is OpenAI, it is trivial to use locally and extremely usefullhttps://github.com/chidiwilliams/buzzreplytikkun 10 hours ago | root | parent | prev | next [\u2013]https://faraday.dev/replyfragmede 9 hours ago | root | parent | prev | next [\u2013]Let other people pay you to run their stuff on your hardware with Vast.ai.replysrcthr 11 hours ago | root | parent | prev | next [\u2013]People don't scale. This is personal. Only 3 is a good choice for people in a site with the name hacker something.replyrmbyrro 8 hours ago | root | parent | prev | next [\u2013]It depends heavily on the use case, not org size. I consult for a ~70 people org that needs to process ~1M tokens per day. That costs $30K per day on OpenAI ChatGPT API. I'm sure this is not an extraordinary case.replyserjester 7 hours ago | root | parent | next [\u2013]Each person in the org needs 1M GPT-4 token and semantic search can\u2019t be used to trim queries? I would be super curious to know more about this use case.replywhoiscroberts 11 hours ago | root | parent | prev | next [\u2013]I have a 4080, let\u2019s do a startup. #cancode #hashomelabreplyrolisz 5 hours ago | root | parent | prev | next [\u2013]FastChat-T5 can work for such a use case and it runs on (beefy) CPUs. With a 700$/month instance, it can do 4 conversations simultaneously, without needing GPUs.The instant a company has sensitive data, this becomes very viable.replytikkun 10 hours ago | root | parent | prev | next [\u2013]Doing this. We soft launched yesterday with a paid Falcon-40B playground - 3 models for now Falcon 40b instruct, uncensored, and base. Adding API and per token pricing this week.https://api.llm-utils.org/And more models coming soon.Vector storage isn\u2019t on the roadmap (what stops using a separate vector store from working well? Could add to roadmap but want to add understand more first), and we could add fine tuning if it\u2019s a common request.replyJimmyRuska 10 hours ago | root | parent | next [\u2013]Lots of people using LLMs to make chat bots from their existing datasets: customer service troubleshooting, FAQs, billing, scheduling. Being able to upload their own pdfs, spreadsheets, docx, crawl their home page, lets the chat bot become personalized to their use case. While you could locally query your own vectordb before prompting, people buy paid service so they won't have to manage any of the technical details.If people can drag and drop some files from their nas, you parse them with apache tika or similar https://tika.apache.org/ , they can start using personalized branded bots. It also lets you do things like refusing to answer, if the vector database returns nothing and the use case requires a specific answer from the docs only (not the llm to make stuff up).replytikkun 10 hours ago | root | parent | next [\u2013]For those use cases the \u201ccustom ChatGPT\u201d tools I linked here might be better https://news.ycombinator.com/item?id=36649777replytartakovsky 3 hours ago | root | parent | prev | next [\u2013]Not secure... NET::ERR_CERT_COMMON_NAME_INVALID Subject: *.safezone.mcafee.comIssuer: McAfee OV SSL CA 2Expires on: Aug 3, 2023Current date: Jul 8, 2023PEM encoded chain: -----BEGIN CERTIFICATE----- MIIGfzCCBWegAwIBAgIQKt9VNrFtaozA1bILX1OcfzANBgkqhkiG9w0BAQsFADBk MQswCQYDVQQGEwJVUzELMAkGA1UECBMCQ0replyswader999 9 hours ago | root | parent | prev | next [\u2013]Wait until winter time and heat your house!replyquickthrower2 8 hours ago | root | parent | next [\u2013]Good double use of that low entropy energy. Heat pumps excepted.replyjstummbillig 11 hours ago | parent | prev | next [\u2013]What do you (or anyone else, feel free to chime in) do with other LLMs that makes them useable for anything that is not strictly tinkering?Here is my premise: We are past the wonder stage. I want to actually get stuff done efficiently. From what I have tested so far, the only model that allows me to do that halfway reliably is GPT-4.Am I incompetent or are we really just wishfully thinking in HN spirit that other LLMs are a lot better at being applied to actual tasks that require a certain level of quality, consistency and reliability?replymcmoor 10 hours ago | root | parent | next [\u2013]I still wonder what makes GPT-4 so much better than its contemporaries. That's why I saw tons of people trying to explain how GPT-4 works starting from simple neural network distasteful, tons of people already knew and do that but none of them is nearly close to GPT-4.lreplylosteric 9 hours ago | root | parent | next [\u2013]> I still wonder what makes GPT-4 so much better than its contemporaries.OpenAI have had many years to craft their dataset down from the noisy public datasets, and GPT4 is (supposedly) a mixture of 8 \"expert models\" each of which is 220B (5x+ larger than the Falcon 40B) with a total of 1.7B parameters (3x+ Google's huge 540B PaLM). The hardware and software to train networks of that scale is also a deep moat. Relatively speaking, the model architecture (\"gpt from scratch\") is the easiest piece.replytwo_in_one 9 hours ago | root | parent | prev | next [\u2013]From my understanding. GPT-4 is the biggest, or one of the biggest. It was trained on low quality internet datasets, like the others. What makes it different is post-training on custom data with human supervision. We know they even outsourced that to Africa. Second, they integrated it with external tools. Like Python interpreter, internet browser. But the first is most important. Also most likely they have experimented and found some tricks which make it bit better.replysp332 8 hours ago | root | parent | prev | next [\u2013]They pay tons of people to type out conversations that they can feed into it. It's just a lot of people doing a lot of work.replyxmprt 10 hours ago | root | parent | prev | next [\u2013]This line of thinking only works if it's impossible to imagine a world where OpenAI isn't the leader. In 2 years if the non OpenAI models are better then it will serve us much better to allow these tools to work with other models as well.replyjstummbillig 3 minutes ago | root | parent | next [\u2013]Since OpenAI is all just APIs with simple interfaces, I don't think that plugging a different, capable model in whatever tool you are building is going to be an issue.replyfreediver 4 hours ago | root | parent | prev | next [\u2013]You are correct in this assesment. A majority of individuals and startups playing around with turning LLMs into products aim to be prepared for the arrival of the subsequent generation of models. When that occurs, they'll already have a product or company in place and can simply integrate the new models.Models are getting commoditized, well executed ideas are not.replybendtb 32 minutes ago | parent | prev | next [\u2013]#Chaxor: I fully agree with this. I am not keen on this being a one horse race, and for privacy reasons would like to deploy these models locally. However, it seems for many programmers it is somewhat easy to build something that can query into OPenAI so they can put it on their resume.Do you know of any FAISS / open source / one-click install w<windows app here I can search in my PDFs via vectors? I can see Secondbrain.sh will have the function in the future, but currently it does not.I have around 500 documents I want to be able to search in.replyakira2501 11 hours ago | parent | prev | next [\u2013]> is that pretty much all of them require OpenAI.They're not here to release an actual product. They're here to release part of a CV proving they have \"OpenAI\" experience. I'm assuming this is the result of OpenAI not actually having any homegrown certification program of their own.replygumby 11 hours ago | root | parent | next [\u2013]> OpenAI not actually having any homegrown certification programA bit off topic but where are certifications (e.g. Cisco, Microsoft) useful? I am sure they are useful (both to candidates and companies) because people go to the effort to get these certs, and if they were useless everyone would have stopped long ago. I don't assume people do it for ego satisfaction.But I've never worked anywhere where it has come up as an interview criterion (nobody has ever pointed it out when we are looking at a resume, for example). Is it a big business thing? Is it just an HR thing?replycodingdave 10 hours ago | root | parent | next [\u2013]It is a consulting / business partner thing. Different levels in the business partner programs require minimum number of certified employees in your consulting firm. So if you work in that slice of the industry, certifications matter. Outside of that... not so much.replytw04 11 hours ago | root | parent | prev | next [\u2013]Mainly when applying for a corporate job where you have 0 referrals. It's a guidepost that you at least have some idea what you're doing and are worth interviewing when people can't find someone who knows you and your previous work.replyhalfcat 10 hours ago | root | parent | prev | next [\u2013]Years ago, companies could get discounts if they were a \u201ccertified gold partner\u201d or whatever.To be a partner, the company would need a certain number of certifications among their employees, so there was tangible value to companies who either used a ton of Microsoft licensing or Cisco/Dell hardware, or resold those to their own clients (better discount equating to higher margin).In some cases, getting the higher level certifications like Cisco CCIE was a virtual guarantee of a good job.I feel like this has become less of a thing in recent years, but I\u2019m not involved in that space anymore.replyatenni 6 hours ago | root | parent | next [\u2013]Definitely still a thing with Azure and Atlassianreplyn4te 11 hours ago | root | parent | prev | next [\u2013]I've only ever seen it as a people who don't have a job thing.replyanton5mith2 10 hours ago | parent | prev | next [\u2013]https://mudler.pm/posts/smart-slackbot-for-teams/ with LocalAI?replybehnamoh 9 hours ago | root | parent | next [\u2013]This is a well-written tutorial and it's exactly what I was looking for! Thanks so much.replyhospitalJail 11 hours ago | parent | prev | next [\u2013]ClosedAI has freaked me out with how much power they have, and how irresponsible they are with it.I'm so horrified that they are going to take away the ability to ask medical questions when the AMA comes knocking at their door.replytrolan 11 hours ago | parent | prev | next [\u2013]The only OpenAI 'crap' being used here is to generate the embeddings. Right now, OpenAI has some of the best and cheapest embeddings possible, especially for personal projects.Once the vectors are created tho, you're completely off the cloud if you so choose.You can always swap out the embedding generator too, because LangChain abstracts that for your exact gripes.Everything else is already using huggingface here and can be swapped out for any other model besides GPT2 which supports the prompts.replyaledalgrande 4 hours ago | root | parent | next [\u2013]> Once the vectors are created tho, you're completely off the cloud if you so choose.Ehr no? You'll need to also create an embedding of your query, which makes you totally dependent on OpenAI. If you swap out embedding algorithm you will have to regenerate all the embeddings as well, they might not be even the same size.replyspace_fountain 11 hours ago | root | parent | prev | next [\u2013]Do you have citations on OpenAI embeddings being some of the cheapest and best? The signs I've seen points almost in the opposite direction?replyben_w 11 hours ago | root | parent | next [\u2013]The only embeddings I currently see listed on https://openai.com/pricing are Ada v2, at $0.1/million tokens.Even if the alternative is free, how much do you value your time, how long will it take to set up an alternative, and how much use will you get out of it? If you're getting less than a million tokens and it takes half an hour longer to set up, you'd better be a student with zero literally income because that cost of time matches the UN abject poverty level. This is also why it's never been the year of linux on the desktop, and why most businesses still don't use Libre Office and GIMP.I can't speak for quality; even if I used that API directly, this whole area is changing too fast to really keep up.replyakiselev 10 hours ago | root | parent | next [\u2013]If you look at a embeddings leaderboard [1], one of the top competitors called InstructorXL [2] is just a pip install away. It's neck and neck with Ada v2 except for a shorter input length and half the dimensions, with the added benefit that you'll always have the model available.Most of the other options just work with the transformers library.[1] https://huggingface.co/spaces/mteb/leaderboard[2] https://github.com/HKUNLP/instructor-embeddingreplyrolisz 5 hours ago | root | parent | prev | next [\u2013]If you've never coded or used Python before, yeah, go with OpenAI. Otherwise, generating embeddings with SentenceBERT takes 5 minutes.And from my personal experience Ada embeddings are not the best. They are large (makes aproximate searching harder), are distributed weirdly, and zimply put, other embeddings give better results for retrieval.Another advantage is that you are not an OA's whim: they just announced the deprecation of some previous model. What are you going to do when they will deprecate Ada v2 and you've built a huge system on top of it? You'll have to regenerate embeddings and hope everything still works just as well.replyspace_fountain 4 hours ago | root | parent | next [\u2013]Yes, exactly this, I also want to say I'm not someone who generally thinks open models are better. I think embeddings just haven't been a focus for OpenAI and it shows. Maybe in the future they will focus on itreplyavereveard 4 hours ago | root | parent | prev | next [\u2013]Setting up an embedding alternative out of huggingface sentence transformers is fairly easy, the magical thing openai does is that they will create embedding of 8192 characters at a time while most other emerging will force you to chunk your documents in 512 characters long sequences, losing lot of context, multiplying your queries result, search times etcreplyarrowsmith 9 hours ago | root | parent | prev | next [\u2013]Running models on your own hardware isn't just about cost, there are privacy concerns too.replycolobas 11 hours ago | root | parent | prev | next [\u2013]Can you elucidate on what those signs are? Thanks in advancereplymuggermuch 11 hours ago | root | parent | next [\u2013]As per the Massive Text Embedding Benchmark (MTEB) Leaderboard maintained by Huggingface, OpenAI's embedding models are not the best.https://huggingface.co/spaces/mteb/leaderboardOf course, that's far from saying that they're the worst, or even headed that way. Just not the best (those would be a couple of fully opensource models, including those of the Instructor family, which we use at my workplace).replythrowaway675309 11 hours ago | root | parent | prev | next [\u2013]What? It's only one file, and it definitely looks like it's using openAI to make the actual queries.  qa = ConversationalRetrievalChain.from_llm(OpenAI(temperature=0.1), db.as_retriever())replysp332 8 hours ago | root | parent | next [\u2013]You can change the arguments to from_llm() to point to a local model instead. Example here: https://huggingface.co/TheBloke/MPT-7B-Instruct-GGML/discuss...replydmezzetti 11 hours ago | parent | prev | next [\u2013]txtai makes it easy to use Hugging Face embeddings and Faiss, all local and configurable. https://github.com/neuml/txtaipaperai is a sub-project focused on processing medical/scientific papers. https://github.com/neuml/paperaiDisclaimer: I am the author of bothreplysheeshkebab 11 hours ago | parent | prev | next [\u2013]Amen, local first should be the default for anything that sucks all my data.Although until these things can do my laundry none of them deserve any of my compute time either.replyzikohh 12 hours ago | parent | prev | next [\u2013]Have you seen PrivateGPT. It's quite good and free.replymvkel 11 hours ago | root | parent | next [\u2013]It's not nearly usable. It's functional in that it spits out a response. Can that response be used for anything useful? No.replyyoyopa 12 hours ago | root | parent | prev | next [\u2013]what hardware do you need for that?replyqingcharles 10 hours ago | root | parent | next [\u2013]It runs (slowly) on my 6 year old i5 laptop.replydrdaeman 11 hours ago | root | parent | prev | next [\u2013]Consumer-grade, AFAIK it's GPT4All with LLaMA.replyraffraffraff 3 hours ago | root | parent | next [\u2013]That's doesn't really answer the question.Neither does the github \"System requirements\" section, which I find disappointing. Ideally, it should give minimum memory requirements and rudimentary performance benchmark table for a sample data set, across a handful of setups (eg, Intel CPU, Apple M1, AMD CPU, with/without a bunch of common GPUs). With that information I would know whether or not it's worth my time even trying it out on my laptop.Edit: lol, I went through 2 pages of the issues on the github page and most of them could be avoided by putting this basic information into the system requirements:https://github.com/imartinez/privateGPT/issues/174 https://github.com/imartinez/privateGPT/issues/179 https://github.com/imartinez/privateGPT/issues/104 https://github.com/imartinez/privateGPT/issues/141 https://github.com/imartinez/privateGPT/issues/282 https://github.com/imartinez/privateGPT/issues/316 https://github.com/imartinez/privateGPT/issues/333... And lots more! Some of these people have 128gb memory and 32 cores, and still find it \"very slow\". Others having memory pool errors. Some of the answers hand-waving at needing \"a more better computer\"I reckon a lot of these issues could be closed and linked to a single ticket for proper hardware requirements in the readme.replyEGreg 11 hours ago | root | parent | prev | next [\u2013]Link?replyhoopsman 11 hours ago | root | parent | next [\u2013]Presumably https://github.com/imartinez/privateGPTreplyAussieWog93 11 hours ago | parent | prev | next [\u2013]Honestly, for me, getting good quality results matters way more than keeping my searches private. And for that, nothing compares with GPT4.replybicx 6 hours ago | parent | prev | next [\u2013]> Stop doing that.This commanding attitude on HN seems to be getting worse lately. Not a fan.replypersedes 11 hours ago | parent | prev | next [\u2013]Gpt4all does exactly that. You can choose between local model or bring your own openai token.replyDer_Einzige 11 hours ago | parent | prev | next [\u2013]Even GPT-3.5-turbo-16K isn't good enough for most retrieval augmented generation tasks.Locally ran LLMs are far worse.I don't like it either, but for now, if you want good RAG, you have to use GPT-4replybella001 3 minutes ago | prev | next [\u2013]Losing assets or crypto is common these days, and I don't see why anyone should be ashamed to admit it. The frightening thing is that anyone can become a victim, regardless of their intelligence. The good news is that there are recovery agencies that can help you get your money back; all you have to do is phone one that is reliable. I went online to look for help after losing money, and I came upon an article about victims' optimism. You can reach out to them by email (Freddictine At consultant com). I decided to give them a chance, and I was pleasantly surprised by how professional and dedicated they were to getting all of my money back.replyhi 12 hours ago | prev | next [\u2013]Keep your data private and don't leak it to third parties. Use something like privateGPT (32k stars). Not your keys, not your data.\"Interact privately with your documents using the power of GPT, 100% privately, no data leaks\"[0][0] https://github.com/imartinez/privateGPTreplywoeirua 6 hours ago | parent | next [\u2013]It\u2019s significantly worse than OpenAIs offerings, and I\u2019m tired of people pretending as though these models are totally interchangeable yet. They are not.replyunshavedyak 11 hours ago | parent | prev | next [\u2013]Is this robust enough to feed all your emails and chat logs into it and have convos with it? Will it be able to extract context to figure out questions to recent logs, etc?replyqingcharles 10 hours ago | root | parent | next [\u2013]In theory, yes.I've not got it to work yet though, it ends up hallucinating answers to all the questions about documents I feed it.replyleach 12 hours ago | parent | prev | next [\u2013]How does this run on an Intel Mac? I have a 6 core i9. Haven't been able to get an M series yet so Im wondering if it would be more worth it to run it in a cloud computing environment with a GPU.replyhi 11 hours ago | root | parent | next [\u2013]>Mac Running Intel When running a Mac with Intel hardware (not M1), you may run into clang: error: the clang compiler does not support '-march=native' during pip install.If so set your archflags during pip install. eg: ARCHFLAGS=\"-arch x86_64\" pip3 install -r requirements.txthttps://github.com/imartinez/privateGPT#mac-running-intelreplyleach 11 hours ago | root | parent | next [\u2013]I\u2019m curious about the response times though, i imagine they will be quite slow on an intel MacreplyTempla 5 hours ago | parent | prev | next [\u2013]Having something that could be used with confluence would be so nice. Having documentation written and just asking questions about it.replySecurityNoob 11 hours ago | parent | prev | next [\u2013]100% private? Hmm. I think with the amount of paranoia that the folks in power have about local LLM\u2019s, I wouldn\u2019t be in the slightest surprised that the Windows telemetry will be reporting back what people are doing with them. And anyone who thinks otherwise is in my view just absolutely naive beyond hope.replyastrange 9 hours ago | root | parent | next [\u2013]Don't have so much pride in yourself. Nobody actually cares what you're doing. Well, China might.And this is probably illegal in several countries besides that since queries might have medical information or other protected data.replyeminent101 11 hours ago | prev | next [\u2013]Is it going to send my personal data to OpenAI? Isn't that a serious problem? Does not sound like a wise thing to do, not at least without redacting all sensitive personal data from the data. Am I missing something?replytedsanders 9 hours ago | parent | next [\u2013]By default, data sent to the OpenAI API is never used for training and is deleted after a maximum of 30 days (mostly).Data usage policies: https://openai.com/policies/api-data-usage-policiesData usage policies by model: https://platform.openai.com/docs/models/how-we-use-your-datareplynomilk 8 hours ago | root | parent | next [\u2013]A few weeks ago GitHub made a strong statement about code in repos not being viewed by humans, that was very liberating.If OpenAI could offer similar privacy statements it would immediately be much more useful. E.g. if they simply add a 'private' option, I'd pay double or triple for it.OpenAI's tools are incredibly good and so easy to use, it's just that I simply cannot use them for most the things I want to do with them because of the privacy considerations, and that sucks.I suspect OpenAI value the insights they get from looking at the data more than they do the extra revenue they'd receive if they could ensure privacy.replybaby_souffle 9 hours ago | parent | prev | next [\u2013]This is my question as well. Is there a more nuanced way to tell how personal data is used other than confirming that an OpenAI key is or is not needed?replyImnimo 7 hours ago | prev | next [\u2013]This readme is very confusing. It says we're going to use the GPT-2 tokenizer, and use GPT-2 as an embedding model. But looking at the code, it seems to use the default LangChain OpenAIEmbeddings and OpenAI LLM. Aren't those text-embedding-ada-002 and text-davinci-003, respectively?I don't understand how GPT-2 enters into this at all.replyAJRF 12 hours ago | prev | next [\u2013]Is there a company that makes a hosted version of something like this? I quite want a little AI that I can feed all my data to to ask questions to.replyluccasiau 12 hours ago | parent | next [\u2013]https://libraria.dev/ offers this and more as a service. It has added conveniences like integration with your google drive, youtube videos, and suchreplysdan 8 hours ago | parent | prev | next [\u2013]If you subscribe to ChatGPT plus, you can use ChatWithPDF (https://plugins.sdan.io) which has 50k+ daily active users!reply_pdp_ 5 hours ago | parent | prev | next [\u2013]https://chatbotkit.comreplytikkun 10 hours ago | parent | prev | next [\u2013]https://news.ycombinator.com/item?id=36649777replyegonschiele 12 hours ago | parent | prev | next [\u2013]Depending on the size of your data, chiseleditor.com is a free option.replycloudking 11 hours ago | prev | next [\u2013]Am I the only one who doesn't need to search across my data? What are the use cases herereplydkh 9 hours ago | parent | next [\u2013]Sometimes I have the data, but I'm not sure where it is.Sometimes I know where the data is, but there's a lot of it and all I'm looking for is a quick explanation of something.Sometimes I have a lot of data from a lot of sources, but what I want in the end is a summary based on what most/all of them agree on, or possibly a summary of how they differ.There's a lot of use-cases here, many of which I think people don't get a \"lightbulb moment\" about their usefulness until they've dug in and seen what is possible, because we are so used to how we approach these tasks normally.But the range of uses is quite broad. A project I'm working on for myself is a variation of this, where I've ingested years and years of my own notes and journals, and make queries for the purposes of my own introspection and personal growth. (I think there's a lot of of potential in this arena in general)replyBeetleB 9 hours ago | parent | prev | next [\u2013]Example use case:We have a group at work that meets and discusses various investment topics. The guy organizing it is fairly well connected and every week he tries to get an external speaker to come and present. Very educational.I have raw notes for each of these presentations. My goal has always been to go through those notes, and properly organize the knowledge in there into a wiki of sorts. It's been 3 years since this all started and I still haven't found the time to do it. If I want to be realistic, I should accept that it'll never happen.How do I go about finding information that I have in those notes? I could use text search but it's too sensitive to my search string - I'll often fail to find what I need. Also, the information may be scattered across several files, and I'd have to open all the hits and scan to find what I need.With technology like this, I can put all my notes into some vector DB, and then use AI to ask in plain English what I need. Locally the system interprets my query and finds the most relevant documents in the DB. It then sends my query and those hits to OpenAI to interpret my question, and find the answer amongst my notes. A while ago I used Langchain to set it up and I got it working as a proof of concept. An Aha moment was when I asked it something and it gave me a response with information that was scattered over two different presentations. My challenge is that there are so many parameters I could play with, and I haven't yet thought of a way/metric to assess the performance of my system (any pointers would be appreciated!)There's nothing personal in these notes, so no privacy concerns. I did want to set a similar thing up with over 20 years of emails, but didn't due to privacy. Also, I use a mail indexer (notmuch) which is fairly good so the need to use AI is not as strong.But for other (non-personal) notes? If I can get this system working fairly well, it'd be a life saver. I've made so many notes on so many topics over the years, and it's worth real money not to have to organize it well. Just let me write my notes, and use an AI to retrieve what I need.replytheonlybutlet 6 hours ago | root | parent | next [\u2013]You're creating additional hardship for yourself. Why create a pdf only to convert it out of pdf again. Just insert all your notes into the LLM model.replymuspimerol 1 hour ago | root | parent | next [\u2013]Because that requires retraining the model every time you take new notes. And this way you also still have the raw notes as similarity matches from the vector db, rather than them \"disappearing\" into the LLM model.replyJimmyRuska 12 hours ago | prev | next [\u2013]Anyone know how milvus, quickwit, pinecone compares?I've been thinking about seeing if there's consulting opportunities for local businesses for LLMs, finetuning/vector search, chat bots. Also making tools to make it easier to drag and drop files and get personalized inference. Recently I saw this one pop into my linkedin feed, https://gpt-trainer.com/ . There's been a few others for documents I've foundhttps://www.explainpaper.com/https://www.konjer.xyz/Nope nope, wouldn't want to compete with that on pricing. Local open source LLMs on a 3090 would also be a cool service, but wouldn't have any scalability.Are there any other finetuning or vector search context startups you've seen?replytikkun 10 hours ago | parent | next [\u2013]Pinecone and Milvus would be alternatives for their use of FAISS for the vector store and search component. I think more of the embeddings difference would be noticed by what\u2019s used for creating the embeddings (eg the ones here https://news.ycombinator.com/item?id=36649579 instead of the OpenAI embeddings API they used), rather than noticing differences from the embedding store/search alternatives which I can\u2019t think of what the difference would be other than maybe performance at a large scale and cost and personal preference / developer experience.Hadn\u2019t heard of Quickwit but from a quick glance at their site it doesn\u2019t look like a vector store, seems perhaps unrelated.For tools for making custom ChatGPTs see my list: https://llm-utils.org/List+of+tools+for+making+a+%22ChatGPT+...Fine tuning as a service there\u2019s Lamini AI, aimed at enterprises.Other embeddings startups there\u2019s Weaviate.replysdan 8 hours ago | parent | prev | next [\u2013]I am working on a simple vector db just with numpy: https://github.com/sdan/vliteI think milvus, quickwit, and pinecone are geared more towards enterprise and are hard to use.replyeddieweng 9 hours ago | parent | prev | next [\u2013]qdrant is better in my opinionreplyzikohh 11 hours ago | prev | next [\u2013]Also what does this do that llamaindex doesn't?replysyntaxing 12 hours ago | prev | next [\u2013]gpt4all has this truly locally. I recommend those with a decent GPU to give it a go.replyfbdab103 11 hours ago | parent | next [\u2013]I assume this is the link: https://github.com/nomic-ai/gpt4all ?replycsjh 11 hours ago | prev | next [\u2013]Why have the OpenAI dependency when there's local embeddings models that would be both faster and more accurate?replyyawnxyz 11 hours ago | parent | next [\u2013]Which ones?replyminimaxir 11 hours ago | root | parent | next [\u2013]all-MiniLM-L6-v2 from SentenceTransformers is the most popular one as it balances speed and quality well: https://www.sbert.net/docs/pretrained_models.htmlreplyquickthrower2 12 hours ago | prev | next [\u2013]The author has a demo of this here: https://www.swamisivananda.ai/replygigel82 11 hours ago | prev | next [\u2013]I don't get it, GPT-2 is (one of the few) open models from OpenAI, you can just run it locally, why would you use their API for this? https://github.com/openai/gpt-2replysimonw 5 hours ago | parent | next [\u2013]It's not using GPT-2 - the README is incorrect.It's using \"from langchain.embeddings import OpenAIEmbeddings\" - which is the OpenAI embeddings API, text-embedding-ada-002The only aspect of GPT-2 this is using is GPT2TokenizerFast.from_pretrained(\"gpt2\") - which it uses as the length function to count tokens for the RecursiveCharacterTextSplitter() langchain utility.Which doesn't really make sense - why use the GPT-2 tokenizer for that? May as well just count characters or even count words based on .split(), it's not particularly important how the counting works here.replysumedh 8 hours ago | parent | prev | next [\u2013]I am assuming GPT 4 will provide better answers to your queries compared to GPT 2.replyeinpoklum 11 hours ago | prev [\u2013]Don't build a personal ChatGPT, and don't let OpenAI, Microsoft and their business partners (and probably the US government) have a bunch of your personal and private information.replytedsanders 9 hours ago | parent | next [\u2013]By default, data sent to the OpenAI API is never used for training and is deleted after a maximum of 30 days (mostly).Data usage policies: https://openai.com/policies/api-data-usage-policiesData usage policies by model: https://platform.openai.com/docs/models/how-we-use-your-datareplytwo_handfuls 7 hours ago | root | parent | next [\u2013]So, they don\u2019t promise they won\u2019t look at it - just that they won\u2019t use it for training.replyeinpoklum 3 hours ago | root | parent | prev | next [\u2013]You many want to read about National Security Letters:https://www.eff.org/issues/national-security-letters/faqreplyWhackyIdeas 11 hours ago | parent | prev [\u2013]So avoid all Microsoft products too?replycj 10 hours ago | root | parent [\u2013]Does Microsoft have an AI opt out?AWS has an AI opt out at the organizational level that prevents them from using your data to \u201cimprove\u201d their other services.(I personally recommend everyone opt out now in AWS if you haven\u2019t already\u2026)https://docs.aws.amazon.com/organizations/latest/userguide/o...replyGuidelines | FAQ | Lists | API | Security | Legal | Apply to YC | ContactSearch:",
    "hn_summary": "- Users are frustrated with the requirement of using OpenAI or cloud services for similar applications.\n- The default approach for these apps should be local-first, with the option to use cloud services if desired.\n- There are alternative options available, such as locally running LLMs, that can provide similar functionality without the need for cloud services.\n- Some users are interested in running LLMs locally on their own hardware, but are looking for guidance on how to do so effectively.\n- OpenAI's pricing and data usage policies are a concern for some users, who are exploring alternative options for privacy reasons.\n- There are several open-source tools and libraries available for building and customizing LLMs, such as txtai and ChatGPT.\n- Users are looking for solutions that allow them to search and access information from their own documents and data.\n- There is a discussion about the privacy implications of using AI models and cloud services, especially for personal and sensitive data.\n- Some users are interested in certifications and qualifications related to AI models and technologies, while others do not see the value in them.\n- There are competing options and startups in the field of fine-tuning and vector search that offer alternatives to OpenAI.\n- Users are discussing the advantages and limitations of different embedding models, such as GPT-2, GPT-4, and custom embeddings.\n- Users are also exploring the use of other tools and libraries, such as Milvus, Quickwit, and Pinecone, for vector storage and search.\n- There is interest in using AI models to search and analyze personal data, such as emails and chat logs.\n- The importance of privacy and data security is highlighted, with concerns about third-party access to personal and sensitive information.\n- Users are interested in finding hosted versions and services that provide AI capabilities for data analysis and retrieval.\n- The potential use cases for indexing and searching data using AI models are discussed, such as organizing notes, retrieving information, and generating summaries.\n- There is a debate about the effectiveness and reliability of different AI models and embeddings, including GPT-2, GPT-4, and others.\n- Users are sharing their experiences and recommendations for running AI models locally on different hardware configurations, such as Intel Macs.\n- The availability of open-source alternatives and libraries, such as privateGPT and vlite, is highlighted.\n- The benefits of using AI models for document search and personal knowledge management are discussed, including enhanced retrieval and summarization capabilities.\n- Concerns about the misuse and potential abuse of AI models, including medical information and privacy infringement, are raised.\n- Some users express frustration with the lack of documentation and information on hardware requirements and performance benchmarks for AI models.\n- Users share their experiences with different tools and approaches for using AI models, such as services that allow private interactions with documents and embeddings."
  },
  {
    "id": 36640769,
    "timestamp": 1688783016,
    "title": "The Horror Game of the Year Is a Doom II Mod",
    "url": "https://kotaku.com/doom-2-free-mods-myhouse-download-gzdoom-goty-1850616515",
    "hn_url": "http://news.ycombinator.com/item?id=36640769",
    "content": "THE A.V. CLUBDEADSPINGIZMODOJALOPNIKJEZEBELKOTAKUQUARTZTHE ROOTTHE TAKEOUTTHE ONIONTHE INVENTORYGaming Reviews, News, Tips and More.HOMELATESTNEWSTIPS & GUIDESREVIEWSTHE BESTSCULTUREREPORTOPINIONANIMEWe may earn a commission from links on this pageODDS AND ENDSThe Horror Game Of The Year Is A Doom II ModMyHouse.wad is the perfect scary story and the perfect game according to its cult followingScreenshot: Veddge / id SoftwareByAshley BardhanPublishedFriday 4:35PMComments (23)To some of MyHouse.wad\u2019s biggest fans, the free mod for 1994\u2019s Doom II might even be the best horror game released this year. There are two reasons for this: the technology and the people.It took some trial and error, but players who downloaded MyHouse.wad from its Google Drive eventually realized that the map included things that were not possible in Doom, like mutated, two-story buildings. They methodically began searching for more of its secrets on a still-active, 58-page-long Doomworld discussion thread. Then, there\u2019s the faceless person (or, some say, ghost) who started it.ADVERTISEMENTDoomworld user Veddge had been planting strange seeds for a year, telling strangers that he hasn\u2019t been sleeping recently, and wondering if other modders also felt like their \u201cmap had a mind of its own.\u201d When he ultimately posted MyHouse.wad\u2014a \u201cpretty adorable\u201d map his deceased friend Thomas modeled after his own house in the 2000s, he said, that he completed after recently discovering it on a floppy disc\u2014on March 2 and then disappeared, users wanted to scavenge his secrets, too. They dissected his game and Google Drive folders with Reddit threads and hours of YouTube documentaries, but found nothing satisfying other than the mutual understanding that\u2026this shared restlessness? This throbbing stomach ache for truth? It\u2019s the mark of a perfect horror game.MyHouse.wad is the horror GOTY\u201cI don\u2019t care if it doesn\u2019t count, this is going in my [Game of the Year] 2023 lineup,\u201d says a popular comment in a Reddit discussion on MyHouse. \u201cIt\u2019s crazy good. [...] It pulls off so much shit I didn\u2019t know DOOM was capable of, even with [source port] GZDoom.\u201did Software co-founder and Doom designer John Romero also called it \u201cgreat\u201d after playing it in June, and Mark Danielewski, who wrote psychological horror novel House of Leaves, shared a video on Twitter explaining the connection between his book and MyHouse\u2019s story and hallucinatory level design.ADVERTISEMENTBut the way that Veddge tells it in a journal entry, the house and its flustering idiosyncrasies\u2014the rooms that light on fire when you\u2019re not looking, like in Layers of Fear, the filled bathtubs that are portals, the hallways that feel infinite\u2014were not on purpose. They\u2019re evidence that the \u201cmap [was] using [him],\u201d shoving him toward bad dreams of storm clouds and dead babies, trapping him in a void without his friend, without anything.\u201cI tried to delete this map but it continues to change and evolve without any input from me,\u201d says a txt file Veddge put in the mod\u2019s Google Drive. \u201cWhat began as a tribute to a lost friend has consumed my entire life.\u201dIgnoring Veddge\u2019s urges not to and playing MyHouse anyway indicates as much. MyHouse starts as expected, in a Middle America clapboard house with healthy shrubs outside and Doom demons inside. But once all the doors disappear and you find out you can phase through mirrors into another unnatural world, you accept that the house isn\u2019t a happy memory. You\u2019re the food it\u2019s playing with.\u201c[The mod] builds you up as the demon-slaying Doomguy with a simple looking map, before robbing you of your power fantasy with an enemy[\u2014the house\u2014]you can\u2019t understand, let alone defeat, even though it\u2019s all around you,\u201d Jack Nicholls, the YouTuber behind the video Danielewski shared (which now has nearly seven million views) tells me over email. Each of MyHouse\u2019s three possible endings also remind you there\u2019s no outrunning the inevitable; \u201cIn dark, uncertain awe it waits / The common doom, to die,\u201d says Walt Whitman.ADVERTISEMENTThis sketchbook Cerberus lives in Veddge\u2019s Google Drive.Photo: VeddgeAs the house map shifts and flips around you, it lets the music drop out suddenly sometimes, or repopulates enemies for no clear reason. Its fickleness seems to encourage you to kneel so that fate can run you over. Once you surrender, you\u2019re free from responsibility, and can now keep dreaming until you can\u2019t.\u201c[While I was playing,] it was like my feet weren\u2019t touching the floor, and I had no comprehension where I was or what constituted \u2018where\u2019 anymore,\u201d Nicholls says. That\u2019s the only gratifying thing about being trapped\u2014it feels dangerous, but it\u2019s not your fault. \u201cI wouldn\u2019t change a single thing about it,\u201d he continues.Though, in terms of its reception \u201cI did find it disappointing that some took things too far,\u201d Nicholls says, \u201ctrying to find the identities of the author and where the House itself was, leading to the Doomworld thread needing to be locked.\u201dADVERTISEMENTInto another portalWhat makes a worthwhile mystery also reddens a deep itch in your brain. Answers might extinguish your wonder, but they at least satisfy your curiosity.For months, Doomworld users fixated on details, like when Veddge first started posting (2006), where they might have seen that game location before (on a 4chan copypasta), and whether or not it would be a good idea to try to find the house on Google Maps (no).Veddge, who continues to be anonymous and did not respond to Kotaku\u2019s requests for comment, apparently contacted a forum member to tell them he was disappointed to \u201cwatch the [public\u2019s] focus be on anything other than a journey of grief\u201d presented in the mod. Another forum member kevansevans, who tells me over private message they assisted Veddge with GZDoom\u2019s \u201cfancy scripting language\u201d ZScript, says that Veddge never expected \u201cthe virality.\u201d\u201cWe definitely knew it had a really high chance of becoming popular in the community,\ufeff\u201d kevansevans says, but \u201ccommunity content for classic Doom these days is a niche corner of the internet. Even the most ambitious maps never leave discussions outside the community.\u201dADVERTISEMENT\u201cAnything actually leaving the circle [...] is recognized as a big achievement and very unexpected,\u201d they continue.While anonymous accounts discussed the merits of background checks and other 3 a.m. theories, along with effusive praise\u2014\u201cI\u2019ve come out of [MyHouse] feeling I see things differently,\u201d Nicholls tells me, \u201cMy time with it has been unforgettable.\u201d\u2014Veddge\u2019s soon-to-be ex-wife Amy was posting the suburban truth on TikTok.The mystery of loveAccording to her replies to comments from curious MyHouse fans (Amy did not immediately respond to a request for comment), the Doom mod is a computer adaptation of their impending divorce.\u201cAs our marriage fell apart, so did the house in the game,\u201d she said.ADVERTISEMENTThe small details players dissected into rice grains then atoms turned out to be one-to-one DoomCute copies of Veddge\u2019s life, including a painting on the living room wall of pink lotus flowers, or a set of black-and-white triptychs that, in the mod, catalogue found items.\u201cHe hid so many things about our life in the game,\u201d she said, \u201cI\u2019m sure even I don\u2019t know all of it.\u201dI\u2019ve been surprised by how few MyHouse players, despite their dogged search for resolution, have acknowledged Amy\u2019s perspective. It seems possible that once a game\u2014or, more accurately in this case, a tangle of unshakeable fear, a snake around the neck\u2014has inflamed so many imaginations, real life stops feeling real. People want answers, but they don\u2019t want them to be boring.ADVERTISEMENTBut \u201cit can\u2019t be helped: boredom is not simple,\u201d French theorist Roland Barthes writes in his 1973 book The Pleasure of the Text. \u201cIt is bliss seen from the shores of pleasure.\u201dAs a whole, even with real life attached to it, MyHouse.wad is now an infamous piece of internet horror, though it\u2019s too popular to be tied directly to its creator\u2019s experience. For people that make art, its ability to stand on its own can be terrifying (the map has a mind of its own, after all)\u2014it can feel wrong, but it can also be connective.Horror has the same effect. Once you experience that feeling with someone, like letting them sip your favorite cherry Coke, you\u2019re bonded. So while MyHouse.wad may have been an unlikely GOTY contender, its artful, personal horror was always going to bring people together. That\u2019s just what happens when you share something from the heart, as dark as it can be. Show all 23 comments",
    "summary": "- MyHouse.wad, a Doom II mod, is being hailed as the best horror game of the year by its cult following. The mod introduces new technology and features that were previously thought to be impossible in Doom II.\n- The mod was created by a mysterious user named Veddge, who left cryptic messages and disappeared shortly after releasing it. This sparked a frenzy among players who were eager to uncover the secrets of the mod and its connection to Veddge's personal experiences.\n- The game's unsettling atmosphere and mind-bending gameplay make it a unique and unforgettable horror experience that has garnered praise from both players and industry professionals, including Doom designer John Romero and author Mark Danielewski.",
    "hn_title": "The Horror Game of the Year Is a Doom II Mod",
    "original_title": "The Horror Game of the Year Is a Doom II Mod",
    "score": 260,
    "hn_content": "Hacker News new | past | comments | ask | show | jobs | submit loginThe Horror Game of the Year Is a Doom II Mod (kotaku.com)260 points by bryan0 1 day ago | hide | past | favorite | 67 commentsanotherhue 1 day ago | next [\u2013]How to play:  1. Read the supporting material for context  2. gzdoom -iwad \"/data/steam/steamapps/common/Doom 2/base/DOOM2.WAD\" -file myhouse.pk3replyImAnAmateur 1 day ago | parent | next [\u2013]Going to the forum page, reading the release post, and then clicking on the download link there is part of the experience.https://www.doomworld.com/forum/topic/134292-myhousewad/The page is tall enough to avoid spoilers. Going in blind is the right choice.replyanotherhue 1 day ago | root | parent | next [\u2013]Agreed, we're in art territory here so convenience takes a back-seat.replyimplements 20 hours ago | parent | prev | next [\u2013]3. Don\u2019t panic if the level takes a while to load.(Gleaned from the John Romero play through on: https://www.youtube.com/watch?v=gIl_TqFJNO8 - there\u2019s some UI config tips there, too)replyINTPenis 22 hours ago | parent | prev | next [\u2013]I just want to add to that, for all the Silverblue users, that you can start it from a Flatpak of GZDoom like this.  flatpak run org.zdoom.GZDoom -file ~/.var/app/org.zdoom.GZDoom/.config/gzdoom/pwads/MYHOUSE.WADNote that you still need one of the official game wads or the Flatpak of GZDoom will not start at all.replyjammaloo 21 hours ago | root | parent | next [\u2013]Worth noting, that the myhouse.wad file, at least for me, does not contain the full level. You instead need to use the myhouse.pk3 file.replyINTPenis 20 hours ago | root | parent | next [\u2013]Oh yeah? I'm at the 4th level already, not sure how deep it goes.replyImAnAmateur 18 hours ago | root | parent | next [\u2013]If you've reached MAP03 - The Gantlet at any point then you're not playing the right version.replyINTPenis 15 hours ago | root | parent | next [\u2013]Oh I must try the pk3 then, thanks for the heads up.replybitsinthesky 1 day ago | prev | next [\u2013]I at first thought this was referring to the dementia mod (youtube below), which seems interesting enough to warrant sharing here (I haven't played it), but I appreciate the artistry and learning about the MyHouse (above).https://www.youtube.com/watch?v=MwgytHBu4sgreplyImAnAmateur 1 day ago | prev | next [\u2013]Don't even read the news article on it. Go to the forum page, download it, and play it. It's great.I wouldn't put it in the horror genre. It's a thriller.replyFuzzwah 1 day ago | parent | next [\u2013]Equally though, when you think you've finished it; have a read / watch about all the fantastic things that you missed.The entire project, and including the journal on the Google drive, is just incredible.I very much enjoyed this video that goes through all the content:https://www.youtube.com/watch?v=5wAo54DHDY0Also, this one to learn about the methods used to create \"myhouse\" in the doom2 engine.replyImAnAmateur 1 day ago | root | parent | next [\u2013]This mod doesn't give up its secrets easily. I ended up using that video as a guide to figure out what I missed. It wasn't ideal but it worked out. I wish HN had a spoiler tag so I could gab about this in more detail!I bought House of Leaves and am on the third chapter. It tells a very different story. MyHouse.wad is certainly inspired by it but they're completely different.replyFuzzwah 1 day ago | root | parent | prev | next [\u2013]Also, the link I failed to pastehttps://youtube.com/watch?v=Iq1-TZXz9xoreplymxmilkiib 20 hours ago | root | parent | next [\u2013]I made a small playlist with playthroughs that each touch on more and more aspects of the level. Then just some notable other playthroughs n the music. https://www.youtube.com/playlist?list=PLi4842O5fEfIQT6sti69A...replyGigachad 1 day ago | prev | next [\u2013]I basically can't play horror games because they are all too intense, but I watched a video on this mod and found it interesting but not at all scary.replysokz 1 day ago | parent | next [\u2013]I couldn't play Wolfenstein because it got too intense. I took a multi-year break from video games and I like what I see, but many FPSes are just too intense to me with its sensory overload. I get the appeal of Fortnite and other Battle Royale style games though, they got that sweet spot of competitiveness and ease of getting into them perfectly.replyrightbyte 1 day ago | root | parent | next [\u2013]I can't stand FPS:es anymore. They are so repetitive and you need to concentrate too much. Also I guess I don't think violence is cool/exciting anymore since I got older.replyehnto 21 hours ago | root | parent | next [\u2013]Yes after years of playing FPS, the S in the acronym is pretty boring. I love the First Person perspective, I just wish more games would explore non-combat mechanic possibilities.It's not a morality thing either, I am just bored of it and feel it is a massive crutch of an industry that's petrified to make a game without combat.replyrc5150 18 hours ago | root | parent | next [\u2013]Agreed entirely. The Metroid Prime series scratches that itch for me. Perfect balance of combat and exploration. Now if only they\u2019d finish MP4\u2026replyewams 21 hours ago | root | parent | prev | next [\u2013]Ever tried Subnautica?replyehnto 20 hours ago | root | parent | next [\u2013]I have, I loved both games, exactly the kind of thing I mean too. The Occupation is another good example I like to recommend.replymidasuni 23 hours ago | root | parent | prev | next [\u2013]Hadn\u2019t played a fps for 20 or so years (since UT , Q3, and Half Life) but decided to play duke nukem 3D for the first time in foreverThose face sucking aliens in the dark corridors are hella scary, far scarier now than they were as a teenager in the 90s.replyCyberdog 1 day ago | parent | prev | next [\u2013]It\u2019s more unnerving than outright scary. I wouldn\u2019t call it a horror game.replylordfrito 20 hours ago | prev | next [\u2013]Spoilers here...Second warning...Apparently this is the TikTok of the creators wife, where she has pictures of the house and some of the wall art that show up in the game. She days they're getting a divorce, it seems he channeled some of that energy into the game and it's artifacts. [1][1] https://www.tiktok.com/@bananapantsamyreplylordfrito 17 hours ago | parent | next [\u2013]FYI to those concerned about doxxing (I assume that's why the downvotes?).She purposely posted this information about their house. She is aware of the myhouse.wad and posted the info, and she says she right in her feed that she did this with the consent of her ex. She masked him out of the photo he's in.The mod is great, and I found seeing the real life house just as fascinating.replywildpeaks 17 hours ago | prev | next [\u2013]Talking of excellent Doom mods, Ashes 2063 is a mix of S.T.A.L.K.E.R. and Fallout.It's standalone, so no need to patch an existing Doom install: https://www.moddb.com/mods/ashes-2063/downloads/ashes-stand-...RagnarRox even made a video about it a week ago (which is how I found out about it): https://www.youtube.com/watch?v=y5_zJoJhbOM&t=418sreplycooldrcool3 13 hours ago | parent | next [\u2013]I liked it but a lot of the map is too dark to navigate properly.replydumdumchan 1 day ago | prev | next [\u2013]How do I play it? \"gzdoom myhouse.wad\" doesn't work. \"gzdoom -wad myhouse.wad\" doesn't work either. There's also a pk3 file in the drive. What is it for?replyImAnAmateur 1 day ago | parent | next [\u2013]1: Get gzdoom set up. 2: Get gzdoom to run Doom II so you know everything is working. 3: Run myhouse.pk3 with gzdoom.The file myhouse.wad does work, but it's very short.replymanvillej 1 day ago | parent | prev | next [\u2013]watch the video: https://youtu.be/5wAo54DHDY0replyowlninja 1 day ago | root | parent | next [\u2013]I was a Doom II junkie back in the day and probably don't consume youtube videos like some people - but this video kept my attention.replytempodox 1 day ago | parent | prev | next [\u2013]Follow the download link from [1], download `myhouse.zip`, put `myhouse.wad` from the zip where your other WADs are. Run GZDoom and use the [Browse\u2026] button in the initial dialog to load `myhouse.wad`. Voil\u00e0.[1]: https://www.doomworld.com/forum/topic/134292-myhousewad/replyhales 1 day ago | root | parent | next [\u2013]No, do NOT use the .wad version. Use the .pk3 version.The .wad was added at a later date, it's not the mod, it's a stripped down vanilla level with no magic.replyImAnAmateur 1 day ago | root | parent | next [\u2013]I'm pretty sure the .wad was always there. It was just hidden in the .zip file in the Google Drive download as a red herring. It's not something to be avoided, just play the .pk3 file afterwards.replyviraptor 1 day ago | parent | prev | next [\u2013]You add doom2.wad (Doom II \u2013 Hell on Earth (v1.9)), then run the pk3 file with gzdoom.replypinkcan 1 day ago | root | parent | next [\u2013]where is the doom2.wad coming from?replyviraptor 1 day ago | root | parent | next [\u2013]Your purchased Doom copy of course ; ) (just search for it, come on, the top results give it to you - just like the search results for \"how to run myhouse.wad\")replypinkcan 1 day ago | root | parent | next [\u2013]I just purchased I and II from GOG, they're EXEs; i'm on a macos machine :'(replythristian 1 day ago | root | parent | next [\u2013]GOG's installers are made with InnoSetup, you can use a tool like InnoExtract to get the files out of them (source at https://constexpr.org/innoextract/ or in MacPorts/Homebrew).replybogantech 1 day ago | root | parent | prev | next [\u2013]IIRC they can be extracted using innoextract: https://github.com/dscharrer/innoextractNeeds to be used with the offline installer files from GOGreplyindrora 15 hours ago | root | parent | prev | next [\u2013]You can uhfind them on the internet.I wont tell you that the record 2020_03_22_DOOM on archive.org has it. I can't confirm.replyanthk 1 day ago | root | parent | prev | next [\u2013]Or just use freedoom2.wad from the FreeDOOM project and rename it as doom2.wadreplyaidenn0 1 day ago | root | parent | prev | next [\u2013]There's an encrypted copy on the Quake CD.replygsich 22 hours ago | root | parent | prev | next [\u2013]my gzdoom download had one included iirc.replythescriptkiddie 1 day ago | root | parent | prev | next [\u2013]magnet:?xt=urn:btih:7b97c87435e91b6b38eee8fcc601c6588d44e89ereplyanthk 1 day ago | parent | prev | next [\u2013]Get freedoom2.wad from https://freedoom.github.io and rename it to doom2.wadreplyAgentME 23 hours ago | root | parent | next [\u2013]You're going to have not the same textures as regular Doom 2 so plenty of designs and custom textures based on the originals used alongside them will look out of place. For playing with MyHouse for the proper experience, it would be best to get proper Doom 2.replyanthk 23 hours ago | root | parent | next [\u2013]Most environment textures of FreeDoom (if not all) are designed to be compatible on art style so you can play IWADs with no art clashing.I played Requiem, STRAIN and lots of classical PWADs (even Back To Saturn) and the megawads always looked great on every level.replytempodox 1 day ago | prev | next [\u2013]Nice to see that GZDoom WADs are alive and kicking. Nothing like a round of Doom mayhem to start the day.replypinkcan 1 day ago | prev | next [\u2013]on mac?go to gog.com and buy a doom2 copy, then forget about itsearch for doom2.wad and get it from the archiveget gzdoom 4.xmkdir -r ~/Library/Application Support/GZDoom && open ~/Library/Application Support/GZDoomput the doom2.wad in that folderdownload the myhouse.pk3 from the google drive and drop it on the gzdoom appenjoy!replyanthk 1 day ago | parent | next [\u2013]Or just get freedom WADs from https://freedoom.github.io and rename freedoom2.wad to doom2.wadreplyralfd 22 hours ago | parent | prev | next [\u2013]> illegal option -- rDoesnt work for me?replyaustinjp 21 hours ago | root | parent | next [\u2013]At a guess, probably should be mkdir -preplypinkcan 19 hours ago | root | parent | next [\u2013]this is right \u2013 I apologise for misleading folks on creating that foldermy local alias is actually: mkdir='mkdir -pv'replyCyberdog 1 day ago | parent | prev | next [\u2013]As mentioned elsewhere in the thread, you can download the Windows offline installer from GOG, then use innoextract to extract the desired files: https://constexpr.org/innoextract/A Mac GUI version of innoextract can be found here: https://macsourceports.com/utilitiesAside from Doom engine games, this also works for Build engine (Duke Nukem 3D), idTech games, and countless others. Very useful tool for being able to play these games legitimately with a modern engine.replyLarsDu88 1 day ago | prev | next [\u2013]Posts like this make me realize the target audience of HackerNews is mid to late 30 something to early 50s dudes (speaking as a big Doom fan myself!)replyno_time 23 hours ago | parent | next [\u2013]This WAD in particular has wide appeal I think. Some of the scenery/references are pretty fresh.replyroody15 19 hours ago | parent | prev | next [\u2013]Think your right \u2026 almost 45 here :). Thought the same thing the other day on a thread about old sierra adventure games \u2026replyLarsDu88 16 hours ago | root | parent | next [\u2013]The late teens early 20s crowd -- they're making shit in Minecraft and Terraria.Even Kerbal Space Program enthusiasts would be in their early 30s by now!replydrclegg 1 day ago | prev | next [\u2013]This is a really great experience, but go in as blind as you can.replyhyperman1 1 day ago | prev | next [\u2013]I'd never thought I'd see Romero and Danielewski mentioned in 1 article, yet here we are. Now I never fully stopped playing doom, so this one goes on my todo list.replytnecniv 1 day ago | prev | next [\u2013]I am so excited to play this tomorrowreplyrasz 20 hours ago | prev | next [\u2013]>Doom II ModLets make it clear, its a GZDoom mod reusing some Doom2 assets. Features used https://zdoom.org/wiki/Teleport_Line are impossible in original Doom 1/2 engine. Later Doom source mods received Non Euclidean Geometry support inspired by other engines like Portal System based Build engine (duke3d etc). https://www.dfdoom.com/gzdoom-portal-tutorial/ https://www.youtube.com/watch?v=oUCji83Xt50replydeafpolygon 22 hours ago | prev [\u2013]Game is great, but GOTY it is not.replyim3w1l 17 hours ago | parent [\u2013]Yeah I'm sure that it's amazing for doom veterans that are unnerved by all the things that are slightly off, but as someone who never played original doom this doesn't particularly speak to me.replyrasz 15 hours ago | root | parent [\u2013]Replace Doom GUI and you might have Stanley Parable in there.replyGuidelines | FAQ | Lists | API | Security | Legal | Apply to YC | ContactSearch:",
    "hn_summary": "- \"The Horror Game of the Year Is a Doom II Mod\"\n- Play the game by following the steps and downloading the necessary files\n- Reading the supporting material and forum posts enhances the experience\n- The level may take a while to load, but don't panic\n- You can start the game from a Flatpak of GZDoom if you're a Silverblue user\n- The myhouse.wad file does not contain the full level, you need to use the myhouse.pk3 file\n- The mod is a thriller, not a horror game\n- There are secrets and hidden content in the game that may require external resources to discover\n- The mod is inspired by the book \"House of Leaves,\" but they are different stories\n- There are several YouTube videos available that go through the content and the methods used to create the mod\n- Some people find horror games too intense, but this mod is interesting without being scary\n- FPS games can become repetitive and too intense for some players\n- There is a desire for more non-combat mechanic possibilities in games\n- The mod is praised for its artistry and creativity\n- There are other Doom mods mentioned for those interested in exploring more options\n- The process of setting up and playing the mod may require downloading additional files and copying them to specific folders\n- There are options for obtaining the necessary game files, such as purchasing Doom II or using the Freedoom project\n- The mod has wide appeal and attracts a diverse audience\n- The game is highly anticipated and generates excitement among players\n- The mod utilizes features that were not possible in the original Doom engine\n- The game is praised for its attention to detail and unsettling atmosphere\n- The mod may not be appealing to those who are unfamiliar with the original Doom games"
  },
  {
    "id": 36646890,
    "timestamp": 1688838894,
    "title": "Why use Pascal?",
    "url": "https://castle-engine.io/why_pascal",
    "hn_url": "http://news.ycombinator.com/item?id=36646890",
    "content": "Support us on  72% of $250Castle Game EngineDownloadFeaturesNewsDocumentationVideosViewer for glTF, X3D...Forum, Discord...GalleryWhy use Pascal?1. Short answer2. More elaborate answer2.1. Modern clean language to develop maintainable applications2.2. Fast2.3. Cross-platform2.4. Welcoming2.5. General purpose2.6. Ecosystem of tools1. Short answerObject Pascal is amodern,readable,fast,type-safe,cross-platformprogramming language.It is also easy to pick up if you know any OOP language. Learn more in our Modern Object Pascal Introduction for Programmers.2. More elaborate answer2.1. Modern clean language to develop maintainable applicationsObject Pascal is a modern programming language. It supports classes, units, properties, generics, interfaces, reflection, closures\u2026 Everything you expect from a modern OOP language.The syntax puts emphasis on readable code.The language is type-safe. E.g. special types for booleans, strings, chars, sets, enums, ranges. Type conversions are either really safe, or have to be done explicitly.There are additional run-time checks, e.g. array range checking, integer overflow checking, assertions, memory leak checking. Notes:You can turn off these checks in release version, but use them in debug. When compiling using CGE build tool / editor, we have debug / release modes that automatically do this for you.What are range and overflow checks (and errors) in PascalDetecting Memory Leaks2.2. FastIt is compiled to a native code and so is fast \"out of the box\". There\u2019s seldom any need to do low-level optimizations.But if you need to, language can be as low-level as you want. E.g. you can use pointers, do pointer math, write OS and CPU-specific code, even add pieces in assembly. You can work on the same level as C or C++ does.NOTEBut you will probably not need to get too \"low level\" in usual applications. E.g. Castle Game Engine has zero assembler code to maximize portability and code readability and we\u2019re still fast.Compilation is also fast.2.5 seconds to get desktop build, 10.1 seconds to get Android build of a new project, opened for the 1st time. Try to match that with your engine :)2.3. Cross-platformDesktop (Windows, Linux, macOS, Raspberry Pi, FreeBSD, probably every Unix\u2026),mobile (Android, iOS),consoles (Nintendo Switch, special in CGE),web (both WebAssembly and JS (using pas2js)).See also Castle Game Engine platforms supported.2.4. WelcomingIn Castle Game Engine case, engine code and game code are in the same language. Every user is contributor!And the engine is open-source.Don\u2019t hesitate to fork CGE to adjust it to your needs.2.5. General purposeThere are existing libraries (units) in Pascal for everything:databaseXML, JSONA.I.blockchainnetworkingMoreover you can easily integrate with (link to) any existing library with C API. Any renderer, sound library, physics - we can use everything.You can also use Python libraries in Pascal easily.2.6. Ecosystem of toolsFPC - Free Pascal Compiler, open-source.Lazarus - IDE for Pascal, on top of FPC, also open-source.Delphi - commercial compiler and IDE for Pascal.VS Code support - CGE, as well as many others in the Pascal ecosystem, explicitly support integration with VS Code.To improve this documentation just edit this page and create a pull request to cge-www repository.Copyright Michalis Kamburelis and Castle Game Engine Contributors.This webpage is also open-source and we welcome pull requests to improve it.We use cookies for analytics. See our privacy policy.",
    "summary": "- Pascal is a modern, readable, and fast programming language that can be used to develop maintainable applications.\n- It is cross-platform, meaning it can be used to create software for different operating systems and devices.\n- Pascal has a welcoming and supportive community, with a wide range of tools and libraries available for developers to use.",
    "hn_title": "Why use Pascal?",
    "original_title": "Why use Pascal?",
    "score": 254,
    "hn_content": "- The post discusses the use of Pascal, an older programming language that still has a loyal following.\n- Lazarus, an open-source recreation of Delphi, is mentioned as a popular IDE for Pascal.\n- The FpcUpDeluxe tool is introduced as a way to automate the installation of the Pascal IDE and additional modules.\n- Free Pascal (FPC) can run on various platforms and compiles code natively for fast execution.\n- The post includes a discussion about the limitations and advantages of Pascal, including its verbosity and lack of modern features.\n- Some commenters express their nostalgia for Pascal and its simplicity, while others criticize it for not evolving with modern programming practices.\n- The use of Pascal in educational settings is mentioned as one of the reasons people still use it.\n- The potential benefits of learning Pascal and using its ecosystem are highlighted for those who are new to the language.- FPC (Free Pascal Compiler) is relatively fast and allows for rapid iteration in building applications.\n- The positives of using FPC include a fast IDE, rich framework, and a relatively easy time contributing to Lazarus.\n- Lazarus is a popular IDE in the Pascal community, with limited alternatives such as Qt Creator.\n- Performance in Pascal, particularly with optimization and algorithmic changes, can be decent for 3D game development.\n- Pascal is often regarded as a good teaching language for beginners due to its clear syntax and easy understanding of imperative programming.\n- The use of Pascal, specifically Object Pascal, still has a niche following and continues to rank among popular programming languages.\n- Although Pascal may not be as widely used in industry, it offers benefits such as fast compilation and a more rigid structure for learning and understanding programming concepts.",
    "hn_summary": "- The post discusses the use of Pascal, an older programming language that still has a loyal following.\n- Lazarus, an open-source recreation of Delphi, is mentioned as a popular IDE for Pascal.\n- The FpcUpDeluxe tool is introduced as a way to automate the installation of the Pascal IDE and additional modules."
  },
  {
    "id": 36643630,
    "timestamp": 1688818351,
    "title": "Scams upon scams: The data-driven advertising grift",
    "url": "https://anotherangrywoman.com/2023/07/05/scams-upon-scams-the-data-driven-advertising-grift/",
    "hn_url": "http://news.ycombinator.com/item?id=36643630",
    "content": "Scams upon scams: The data-driven advertising griftDigital advertising is a scam from top to bottom. In fact, it\u2019s several scams stacked on top of each other, wearing a trenchcoat, and some of the foundations of fibs are so effective that otherwise reasonable people entirely buy into them.Data-driven ads are anything butI\u2019ll start with a few examples of the data which is definitely held on me, and just how entirely bad my targeted advertising is.Facebook know my age and date of birth. They have had this data since I signed up for the website, 15 years ago. They know exactly how old I am. They also know where I live. Hell, sometimes I used to check into places with my location on. Despite knowing I am way north of 30 and way south of Birmingham, they are incredibly keen on advertising me events explicitly limited to people under the age of 30 in the Birmingham area.Google knew I wanted to buy a mattress. They knew this because I googled it. And I clicked through to a brand selling mattresses, and I bought myself a mattress. The brand know I googled said mattress. Google know I clicked through. From Google\u2019s own analytics, they ought to know I bought the mattress. Since buying that mattress, I\u2019ve been constantly advertised mattresses, especially the one I already own and they know I already own.Some might claim that in fact the advertisers are being incredibly smart and they\u2019re advertising me activities for women under 30 in Birmingham so I go and tell my friends who are under 30 in Birmingham to go and do that. But of course, Facebook would also know that I don\u2019t have any friends in that demographic. Or maybe that mattress seller is trying to tell me to refer a friend to buy that mattress by reminding me that I own a very nice mattress. In which case, why isn\u2019t it advertising the referral programme, which I know they have because I received several emails and a physical leaflet about it with the fucking mattress?The more simple answer is that the advertisers aren\u2019t being data driven at all. They\u2019re ticking default boxes or casting wider nets. I\u2019m getting advertised mattresses because I have ~an interest in mattresses~. I\u2019m getting activities for women under 30 in Birmingham because I\u2019m under 40 and on the same island as Birmingham.For all the buzzwords about \u201cdata-driven\u201d and \u201csmart\u201d and whatever else you want to call it, the advertisers are just going \u201ceh, sounds about right\u201d and letting a robot automate their job.This, then, is the first grift in the chain. Despite claiming to their boss that they\u2019re using \u201cdata-driven\u201d advertising, they\u2019re targeting their ads even less than taking out a quarter page in the local newspaper.The product: they could spy on you (but don\u2019t)Everyone is rightly nervy about the sheer quantity of data that big companies hold on us. Social media companies know all about your demographic information, social connections and interests. Amazon knows exactly when you have an outbreak of aphids because you buy things to kill the nasty little beasties, and it probably also knows when you\u2019ve had a nasty breakup because nobody listens to Fleetwood Mac\u2019s Rumours on repeat at 3am when they\u2019re in a good place. Google basically knows everything about you.At least that\u2019s the theory. And that\u2019s the product that they\u2019re selling to advertisers. They have an enormous dataset from which everything an advertiser could ever dream of about a person can be garnered. They\u2019re the world\u2019s biggest, bestest spy network, which means they have quality data to help your business be the biggest, bestest business reaching the biggest, bestest customers.At least that\u2019s what they say.Actual spying requires actual spies. There\u2019s a reason intelligence agencies are such big employers: they have all of their fancy spy computers, but they know they need to hire humans to actually deduce patterns and sort signal from noise. They\u2019re aware that a human brain is always superior to a computer in figuring this out, so they get humans to do the work.Meanwhile, tech companies break into hives at the thought of getting a human to do a job. Their ethos is that if a human can do a task, a machine can do that task better, and not cost them anything such as salary, pensions or or a basic level of respect. Tech companies are fatally allergic to getting a human to do a human job, so content moderation is largely an algorithm looking for the word \u201cboobies\u201d. A tech company would go into anaphylactic shock at the very notion of employing a human to analyse their vast dataset.So it\u2019s all machine learning, and the machines are very, very stupid. Have you ever looked at your list inferred interests on a social media platform? If you ever tweeted \u201cI don\u2019t like Game of Thrones, it\u2019s not for me,\u201d you\u2019ll be classified as interested in Game of Thrones and possibly get served ads for it. These machines may also attempt to deduce your age, gender, and so forth based on half-baked crap fed into them, and it seldom comes up right. Maybe that\u2019s why it thinks I\u2019m under 30 and in Birmingham. Perhaps I internet in a Brummie accent.It\u2019s no wonder that on multiple occasions, big tech has been caught out completely making things up when communicating with advertisers, and they continue to do so. Facebook was famously found to have inflated or outright fabricated video metrics. GA4 very quietly admits that the data is padded out with machine learning. The data is a lie, and a lot of it is because they literally haven\u2019t the first clue on what to do with it, they just need to steeple their fingers and act all evil so advertisers think they have it.Advertisers, then, are getting served a steaming turd on a plate rather than the medium-rare filet mignon they were promised.And meanwhile, the spies don\u2019t even need that data, because your posts are public anyway.But enough about that. The problem is this grift is, too, built upon a grift.Marketing science is a griftI work in marketing, for my sins. This is mostly why I\u2019m so entirely down on the marketing industry and many of the people who work in it. I also happen to have an MSc in psychology \u2013 actual psychology! \u2013 with a focus on behaviour change.On day 1 of your class about behaviour change in a science course, you learn that behaviour change is not a simple matter of information in, behaviour out. Human behaviour, and changing it, is big and complex.Meanwhile, on your marketing courses, which I have had the misfortune to attend, the model of changing behaviour is pretty much this: information in, behaviour out.The thing with the entire \u201cscience\u201d of marketing is the underpinning theory base is basic common sense which has been treated with a bit of a brand makeover, turned into a couple of overcomplicated diagrams with some neologisms obscuring meaning. Digital marketing has become very popular because baked into it are a whole bunch of metrics so you have something to show your manager that you\u2019re not spending the entire day tending your geraniums, but do the metrics really mean anything?The metrics that marketers are told they need are marketed to them by the marketing department of a company that specialises in making products for marketers. And that company was probably started up by someone who worked in marketing.Marketing theory is never tested rigorously. The common sense incredibly sound scientific view based on heaps of scientific evidence view \u2013 showing your ads to people more likely to buy your product is more efficient because they\u2019re more likely to buy your product anyway \u2013 is entirely untested.There\u2019s an anecdote that a glitch with Facebook led to ads no longer being targeted over a period of several weeks. And absolutely nobody noticed because the metrics all looked normal, the engagement and purchasing was just the same.There isn\u2019t any evidence to suggest that an ad targeted to 35 year old men with children with an interest in football is any more likely to result in sales of Football Dad socks than a poster for Football Dad socks at a bus stop. But an entire industry is based on pretending that this is the case.tl;drFacebook will try to sell you Football Dad socks even if you\u2019re a 55 year old childfree woman who posted once about hating football, because that data is utterly useless.Spies are probably reading your posts though, no matter how boring._Enjoyed what you read? Consider becoming a Patron or leave a tipSHARE THIS:FacebookTwitterTumblrRedditLoading...RELATEDTwo alternatives to #WomenBoycottTwitter that don\u2019t rely on women\u2019s silencingOctober 13, 2017In \"not angry just disappointed\"Using Twitter\u2019s new view counters to see if Twitter Blue increases reach (it doesn\u2019t)December 30, 2022Liked by 2 peopleTop tips for staying on Twitter as Jack fucks it upAugust 17, 2018In \"not angry just disappointed\"July 5, 2023stavversUncategorized",
    "summary": "- Digital advertising is filled with scams and deceptive practices, with multiple layers of deceit stacked on top of each other.\n- Data-driven ads, which claim to use personal information to target ads accurately, often fail in their targeting and bombard individuals with irrelevant ads.\n- Tech companies have vast amounts of data on users, but their algorithms are not sophisticated enough to make accurate predictions or deliver meaningful insights to advertisers. As a result, advertisers are sold a false promise and end up with ineffective advertising campaigns.",
    "hn_title": "Scams upon scams: The data-driven advertising grift",
    "original_title": "Scams upon scams: The data-driven advertising grift",
    "score": 234,
    "hn_content": "- The author argues that data-driven advertising is a scam, based on personal experiences and anecdotes.\n- They criticize the idea that targeted ads are more effective than traditional forms of advertising, suggesting that there is no evidence to support this claim.\n- The author questions the effectiveness of algorithms in advertising, suggesting that they may not be as smart or accurate as they are claimed to be.\n- They highlight the disconnect between advertisers and their target audience, arguing that advertisers often fail to understand the needs and preferences of consumers.\n- The author suggests that the advertising industry is focused on selling advertising services rather than driving actual sales for businesses.\n- They point out the complexities and challenges of advertising, including the need for data and statistical analysis to make informed decisions.\n- The author expresses skepticism towards the claims made by advertising platforms, such as Facebook and Google, suggesting that their algorithms may not deliver the promised results.\n- They emphasize the importance of questioning the effectiveness and value of data-driven advertising and the need for more rigorous testing and analysis.\n- The author suggests that advertisers should be cautious and critical when evaluating the effectiveness of data-driven advertising.- The article discusses the practices of companies and how they aim to meet the needs and desires of their customers, particularly advertisers.\n- The author acknowledges that they lack access to data and cannot independently confirm the practices, suggesting that it is important not to jump to conclusions or make assumptions about the intentions of these companies.\n- One commenter mentions that certain events on Meetup exclude people over the age of 30, possibly indicating that there are age-specific dating events or group-interest events that have specific age ranges.\n- Another commenter shares their observations on Meetup, noting the abundance of interesting local groups and a large number of single women in their 20s-40s. They find it odd since they don't live in California and speculate about the dating scene for people who prefer \"on-prem\" (non-California) lifestyles.\n- This post offers insight into the practices of companies and provides observations on the demographics and interests seen on Meetup. It encourages readers to consider the data and avoid making assumptions.",
    "hn_summary": "- The author argues that data-driven advertising is a scam and questions the effectiveness of targeted ads and algorithms.\n- They highlight the disconnect between advertisers and their target audience and suggest that the advertising industry is focused on selling services rather than driving sales.\n- The author emphasizes the importance of questioning the effectiveness of data-driven advertising and the need for more rigorous testing and analysis."
  }
]
