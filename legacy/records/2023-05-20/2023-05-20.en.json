[
  {
    "id": 36000631,
    "timestamp": 1684497000,
    "title": "Google Photorealistic 3D Tiles & Unreal Engine",
    "url": "https://nilsbakker.nl/portfolio/3d-tiles/",
    "hn_url": "http://news.ycombinator.com/item?id=36000631",
    "content": "Google Photorealistic 3D Tiles & Unreal EngineUsing the power of Unreal Engine 5.1, I embarked on a technical adventure when the Google Maps 3D tiles API was released. With an ambitious goal in mind, I challenged myself to complete this project within a tight one-week deadline. On this page I try sharing the process behind creating this interactive experience.Combining the Google 3D tiles and ChatGPT APIs, I harnessed the capabilities of Unreal Engine to create an immersive experience that pushes the boundaries of what\u2019s possible. Leveraging the flexibility of blueprints in Unreal, I seamlessly integrated the ChatGPT API, enabling users to enter prompts and receive dynamic responses.The Prompt:Answer the following question in the following format. << Latitude, Longitude >> ((City Name)) [Country name] ^^a fun fact about this place^^nothing else. Use that format include the <, > and {} and ().[USER INPUT]Every time a user enters a prompt, it triggers a specific function with the provided prompt. The answer provided by ChatGPT is then split into four sections: XY coordinates, city name, country, and an interesting fact about the location. This data is then first parsed into 3D text and placed in the virtual world.But how do we bring this virtual world to life with accurate location data? Here\u2019s where the Google Maps API comes into play. I utilized another function to translate the XY coordinates obtained from the prompt to retrieve the location data through the Google Maps API. The location data is then used to fetch the 3D geometry, thanks to the remarkable Cesium platform and plugin for Unreal Engine.Once the location and geometry data are gathered, the 3D geometry is loaded onto the designated location. To seamlessly transition the user from their current position to the new location. I used the Niagara particle system to create a portal mechanism that cleverly hides the transition process.Of course, we can\u2019t forget about the practicalities of teleportation. Since ground levels vary across the world, we need to ensure that the player doesn\u2019t spawn underground or high above the ground level. By checking for ground collision, we make certain that the player spawns at an appropriate height above the ground. Additionally, to enhance the user experience, we position the player slightly backward from the intended location, providing them with a clear view of the destination upon arrival.Blueprint function that detects the ground level.During the teleportation process, we also set the time of the location. Although the current implementation generates a random value for time, the original plan was to retrieve actual time and weather data from another API. However, given the time constraints of the project, that feature will have to wait for future development.This project has been an incredibly fun and rewarding experience. It showcases the immense power of Unreal Engine and demonstrates the endless possibilities that arise from integrating tools like Google 3D tiles and ChatGPT. If you have any questions about this project, don\u2019t hesitate to reach out. I\u2019d be more than happy to share more insights!",
    "summary": "- A developer used Google Photorealistic 3D tiles API and Unreal Engine 5.1 to create an immersive experience that combines location data with dynamic responses from the ChatGPT API.\n- The experience allows users to enter prompts in a specific format and receive information about a location, including interesting facts, which are displayed in 3D text in the virtual world.\n- The developer used the Google Maps API and Cesium platform to retrieve location and geometry data and created a clever portal mechanism using the Niagara particle system to transition the user from their current location to the new location.",
    "hn_title": "Google Photorealistic 3D Tiles and Unreal Engine",
    "original_title": "Google Photorealistic 3D Tiles and Unreal Engine",
    "score": 571,
    "hn_content": "Google has released a new API that allows developers to make photorealistic 3D maps of any location on Earth through its location data technologies. It uses 3D Tiles which render efficiently and quickly and stream over a network. Different platforms like Cesium and Unreal Engine support the API now. A lot of people have been expressing excitement at this new technology, with some suggesting that it could be integrated into games to let users drive through their hometowns in 3D. Developers, however, must keep in mind the quota limitations of this API, as it's still in beta and has limits per website.A developer has created a 3D map of the world using Google Maps data and a plugin for Unreal Engine called 3D Tiles, combined with an AI model called ChatGPT, in order to generate text descriptions for locations. The result is a virtual globe that can be navigated in great detail, with a text box that suggests places to visit based on interests entered by the user. However, some have raised concerns over the project's legality, given the use of copyrighted Google Maps data. Others have pointed out that drone regulations make the kind of mapping required illegal in some areas.",
    "hn_summary": "- Cesium and Unreal Engine now support this API, potentially enabling 3D drive-throughs of users' hometowns in games.\n- The API has quota limitations in its beta version, and some have raised concerns over the legality of using Google Maps data and drone regulations for mapping."
  },
  {
    "id": 35999835,
    "timestamp": 1684491431,
    "title": "Orb Farm",
    "url": "https://orb.farm/",
    "hn_url": "http://news.ycombinator.com/item?id=35999835",
    "content": "Orb.farmCO2O2ResetinfoClearGlassSandStoneWoodWaterAlgaeDaphniaGrassBacteriaFishGoldFishOrb.FarmWelcome to Orb.Farm!This is your personal aquatic ecosystem to nurture, sculpt, and observe.1/4Next >",
    "summary": "- Orb Farm is a personalized aquatic ecosystem for nurturing, sculpting, and observing.\n- The system includes various components such as sand, stone, wood, water, algae, daphnia, grass, bacteria, fish, and goldfish.\n- The website allows users to reset, view information, and clear their ecosystem.",
    "hn_title": "Orb Farm",
    "original_title": "Orb Farm",
    "score": 487,
    "hn_content": "Orb.Farm, a virtual aquatic ecosystem, has gained popularity among tech enthusiasts. Users express admiration for the project's creator Max Bittker and their similar project Sandspiel. Sandspiel's technical build is discussed in detail. Other users share their own simulation projects, such as symbiants, Noita, and Ant-Simulation. Orb.Farm's flaws, such as balancing issues with daphnia, algae, and bacteria, are also discussed, but users still find the project entertaining and mesmerizing. Additionally, discussions about Sandspiel Studio, a visually programmable sequel, and other visually programmed artificial life-based projects are included. Finally, users mention other sandbox games, such as The Powder Toy.",
    "hn_summary": "- Users admire the creator Max Bittker and compare it to other simulation projects like Sandspiel.\n- Some users point out balancing flaws in Orb.Farm but still find the project entertaining while others discuss Sandspiel Studio and other visually programmed artificial life-based projects."
  },
  {
    "id": 36000407,
    "timestamp": 1684495827,
    "title": "Linux tool to show progress for cp, mv, dd",
    "url": "https://github.com/Xfennec/progress",
    "hn_url": "http://news.ycombinator.com/item?id=36000407",
    "content": "progress - Coreutils Progress ViewerWhat is itThis tool can be described as a Tiny, Dirty C command that looks for coreutils basic commands (cp, mv, dd, tar, gzip/gunzip, cat, etc.) currently running on your system and displays the percentage of copied data. It can also show estimated time and throughput, and provides a \"top-like\" mode (monitoring).(After many requests: the colors in the shell come from powerline-shell. Try it, it's cool.)progress works on Linux, FreeBSD and macOS.Formerly known as cv (Coreutils Viewer).How do you install itOn deb-based systems (Debian, Ubuntu, Mint, etc.) run:apt install progressOn archlinux, run:pacman -S progressOn rpm-based systems (Red Hat, CentOS, Fedora, SUSE, etc.), run one of these:dnf install progressyum install progressOn macOS, with homebrew, run:brew install progressOn macOS, with MacPorts, run:port install progressHow do you build it from sourcemake && make installOn FreeBSD, substitute make with gmake.It depends on library ncurses, you may have to install corresponding packages (may be something like 'libncurses5-dev', 'libncursesw6' or 'ncurses-devel').How do you run itJust launch the binary, progress.What can I do with itA few examples. You can:monitor all current and upcoming instances of coreutils commands in a simple window: watch progress -qsee how your download is progressing: watch progress -wc firefoxlook at your Web server activity: progress -c httpdlaunch and monitor any heavy command using $!: cp bigfile newfile & progress -mp $!and much more.How does it workIt simply scans /proc for interesting commands, and then looks at directories fd and fdinfo to find opened files and seek positions, and reports status for the largest file.It's very light, and compatible with virtually any command.",
    "summary": "- Progress is a tool that runs on Linux, FreeBSD, and macOS and displays the percentage of copied data for basic commands like cp, mv, dd, tar, gzip/gunzip, and cat.\n- It can show estimated time, throughput, and has a \"top-like\" mode for monitoring.\n- Progress is easy to install and run on deb-based, archlinux, rpm-based systems, macOS with homebrew or MacPorts, and can be built from source with ncurses library.",
    "hn_title": "Linux tool to show progress for cp, mv, dd",
    "original_title": "Linux tool to show progress for cp, mv, dd",
    "score": 438,
    "hn_content": "A Linux tool has been developed to show progress for cp, mv and dd commands. The comments include general discussion about dd and tips for using pv, a command-line tool for monitoring progress of data through a pipeline. One user shared a personal story about how a game engine called Raydium and one of their games called Mania Drive, built by @xfennec had a huge impact on him in his childhood and got him into programming and game development.Discussion about using progress indicators in Linux commands like dd, with suggestions for tools like pv and Pipe Watch. Some mention the implementation of SIGINFO on *BSD systems and newer versions of Linux dd's support for status=progress. One user suggests that progress indicators are useful but not necessary as \"no news is good news\". There is some debate around formatting standards in the code mentioned in the post. Some mention possible alternatives to using dd, such as ddrescue or rsync, and discuss the benefits of slowing down transfers to prevent overloading shared connections.A discussion thread on Hacker News covers different methods for displaying progress when running command-line transfer utilities such as mv and cp. The original post proposes using a signal handler to display progress by displaying the current offset in the kernel file. Comments suggest alternative utilities such as rsync and pv, which give more detailed information about data transfer rates and remaining time estimates. There are some specific suggestions for macOS users, as well as a debate on whether commands should have built-in progress indicators or whether separate utilities are preferable.",
    "hn_summary": "- Discussions on using progress indicators in Linux commands, including suggestions for tools like pv and Pipe Watch\n- Alternatives to dd, such as ddrescue or rsync, are discussed, along with the benefits of slowing down transfers to prevent overloading shared connections."
  },
  {
    "id": 36006423,
    "timestamp": 1684527771,
    "title": "Nyxt: The Hacker's Browser",
    "url": "https://nyxt.atlas.engineer/",
    "hn_url": "http://news.ycombinator.com/item?id=36006423",
    "content": "FAQManualDownloadForumArticlesChatSourceFeedApplicationsLoginNyxt:the hacker's browser.Out of the box Nyxt ships with tens of features that allow you to quickly analyze, navigate, and extract information from the Internet. Plus, Nyxt is fully hackable- all of its source code can be introspected, modified, and tweaked to your exact specification.Download FAQ ArticlesJump headings.Navigate large documents with ease. Fuzzily search through headings.Map selection.Utilize the power of running commands against multiple objects to avoid repeating yourself. In the example below, we select and close all buffers that match the string \"ele\".Execute commands easily.Fuzzy search relevant commands to instantly run them. No more digging through menus.Instantly switch buffers.Use fuzzy search to instantly switch between buffers. No more hunting!Powerful link hinting.Use link hinting to quickly jump around. Jump to a link by URL, title, or shortcut.Built-in programmability.Use the built-in REPL to program Nyxt. Run short scripts, and try out new workflows. Everything in Nyxt is fully extensible and modifiable.Smart bookmark search.Use the prompt buffer to intelligently search your tagged bookmarks.Customizable autofills.Use autofills to fill in forms. Autofills can be functions or plain strings. In the case of functions, you can make them intelligent. For example, you may want an autofill to fill in the current date.Clipboard history.Anything you copy is remembered so that you can re-paste it at any time. No more looking for the 'last thing' you pasted!Lossless tree history.A tree based history ensures that you never lose track of where you've been. All pages you've visited are stored in a tree that you can traverse and search. No more losing items in your history.LegalContactWork with usAbout usStore",
    "summary": "- Nyxt is a browser with many built-in features for analyzing, navigating, and extracting information from the internet.\n- The browser is fully customizable and hackable, with its source code open and available for modification.\n- Some of Nyxt's unique features include powerful link hinting, smart bookmark search, and built-in programmability through a REPL.",
    "hn_title": "Nyxt: The Hacker's Browser",
    "original_title": "Nyxt: The Hacker's Browser",
    "score": 381,
    "hn_content": "The post discusses the usability of Nyxt, a browser inspired by Vim, and its default bindings causing issues for non-US keyboards. The debate revolves around the inefficiency of old-fashioned UX paradigm in Vim and Emacs as compared to the latest research in UX. Several users suggested changing keyboard layout, adaptation to English UX, or using an IDE with Vim plugin, and there is a call for customizable, module-based browser with a pure shell and a commitment to web renderer excellence. The post provides insight into the debate on the unshakable legacy of old technology and the importance of user experience in making technological advancements.Developers on HN are discussing the lack of customization options and extensibility for traditional web browsers. Some are interested in creating open-source, extensive, and customizable browsers that can be controlled with prompts or even voice commands. Furthermore, they believe that building modular browsers with APIs for automation and customization would be more efficient and innovative than tweaking old-fashioned browsers. One such browser, Nyxt, offers a minimalist and flexible interface that supports different web engines and even web scraping and automation. Other browsers mentioned are qutebrowser, Orion Browser, and Browsh, which focus on privacy, speed, and text-based browsing. Overall, developers are seeking to create browsers that allow them the freedom and control that traditional browsers do not offer.- Nyxt is a keyboard-driven web browser designed for power users, inspired by Emacs and Vim\n- It has familiar keybindings (Emacs, vi, CUA), and is infinitely extensible in Lisp\n- Nyxt just had a major 3.0.0 release, and some users are excited to try it out\n- Users are discussing lightweight web browsers' security and attack surface\n- Nyxt uses WebKit and WebEngine, but some consider these renderers too buggy to be a main browser\n- Users discuss how Nyxt could potentially add Unix CLI tools to the browser and run on a server\n- Users also discuss the possibility of running Nyxt on Android and inserting a JS polyfill layer that could stub any weird API with an extension\n- Nyxt may not be suitable for the OSINT community, but it's a good option for power users who prioritize keyboard-driven UI and extensibility",
    "hn_summary": "- Nyxt just had a major 3.0.0 release, and some users are excited to try it out.\n- Developers are seeking to create modular browsers with APIs for automation and customization that allow more freedom and control than traditional browsers."
  },
  {
    "id": 35999950,
    "timestamp": 1684492522,
    "title": "Cities Aren't Loud: Cars Are Loud (2021) [video]",
    "url": "https://www.youtube.com/watch?v=CTV-wwszGw8",
    "hn_url": "http://news.ycombinator.com/item?id=35999950",
    "content": "",
    "summary": "- A video shared by the Vox YouTube channel explores how cars are the biggest source of noise pollution in cities, and that loud cars are not a necessary feature of transportation technology.\n- The video argues that car companies promote the idea of loud cars to signal status and attract attention, and that quieter alternatives, such as electric vehicles, can provide a more sustainable and enjoyable city environment.\n- The video suggests that cities should prioritize policies that reduce car use and promote public transportation and active transportation modes, such as biking and walking.",
    "hn_title": "Cities Aren't Loud: Cars Are Loud (2021) [video]",
    "original_title": "Cities Aren't Loud: Cars Are Loud (2021) [video]",
    "score": 366,
    "hn_content": "The post on Hacker News highlights the annoyance of traffic noise in urban environments. The author proposes that quieter areas tend to have moderate-density areas with mixed-use buildings and more walkable streets, citing examples from Europe and Japan. The comments section features a discussion on the benefits and pitfalls of Soviet-era city planning, including the trade-off between community and surveillance. The impact of cars on urban spaces and their potential solutions are a major focus, with some lamenting the removal of benches and playgrounds in favor of parking spaces. Others point out that while city planning can be important, remote work and other technological advancements may be the best paths to reducing traffic and emissions.No meaningful content for a tech-focused publication.A discussion on air pollution and noise pollution caused by cars in North America and Japan on a YouTube channel leads to comments about air pollution in Tokyo. Some individuals argue that cities in Japan are not free from traffic and construction, with the majority of people living with constant traffic noise and terrible air quality. Others suggest that air pollution in Japan may not be as bad as people think and that it's hard to compare metro areas without actually living there. The discussion also covers noise from other sources, such as scooters and motorcycles, and how they are gradually being replaced by electric vehicles. It's concluded that it's essential to improve air and noise quality in general, and policies such as diesel bans, EVs, and congestion pricing can help achieve that goal.The comments discuss the issue of noise pollution caused by vehicles and the preference for quieter, more walkable neighborhoods. There is a debate regarding government regulation vs. free-market solutions, such as electric cars or quieter tires. Some argue that cities can create zoning laws to reduce noise, while others argue that the issue is the fault of car manufacturers and drivers. The loudness of cars is seen as a form of pollution, and some suggest that noise pollution is just as harmful as other forms of pollution. The comments also mention preferences for living near shops, public transportation, parks, and good schools.- Noise pollution from cars, especially those with intentionally loud modifications, is a major issue in urban areas.\n- Motorbikes and mopeds without exhaust dampening are also a problem.\n- Tyre noise produces \"white noise\" which can be attenuated using physical barriers.\n- A framework for thinking about car traffic as industrial activity highlights the need to prioritize walking and biking infrastructure.\n- A reduction in car usage is necessary but requires increased awareness, political action, and reallocating resources towards mass transit systems.\n- The noise reduction from EVs depends on factors other than the type of propulsion system.\n- Modern cars generate significant noise from their tires even if they are EVs.Electrification makes a significant difference in cities with noisy vehicles such as motorcycles and diesel buses. With EVs becoming more dominant in central London, noticeable differences in noise levels at busy intersections have been observed. London's electric buses have large enough battery packs to run all day without charging, and the fleet is planned to be fully electric by 2034. The tire noise for ICEs becomes louder than the engine at around 50kmph. New tyres are rated in the EU for noise, wet grip, and fuel efficiency. Noise levels from tires break down and fill the air with particulate, contributing to pollution. European regulation requires electric vehicles to make noise when driving at low speeds to make them safer for pedestrians and cyclists. Ultimately, electric vehicles are beneficial in reducing noise and pollution levels in cities.A discussion on the safety concerns of electric vehicles (EVs) being quieter than petrol cars on the road. The commenters debate whether the noise of cars is important for situational awareness for pedestrians and cyclists. Some argue that EVs need to make artificial noise to mimic the sounds of other vehicles, while others argue that looking both ways before crossing is essential and that a horn or siren is a driver's only way to communicate. Additional comments discuss noise pollution in cities and how loud trucks are compared to cars. The discussion highlights the importance of situational awareness for all road users.The article discusses different sources of noise in various cities, such as emergency sirens, construction noise, and motor vehicles. Some commenters also discuss the impact of new technology on noise levels, such as electric buses and hybrid cars. Overall, the article illustrates the subjective nature of noise and how it can vary depending on the individual's environment.",
    "hn_summary": "- Possible solutions include physical barriers to attenuate tire noise, prioritizing walking and biking infrastructure, and reducing car usage through increased awareness, political action, and mass transit systems.\n- Electrification can help reduce noise and pollution levels in cities, but there is a debate on whether electric vehicles need to make artificial noise for pedestrian safety."
  },
  {
    "id": 36002574,
    "timestamp": 1684507480,
    "title": "FreeBSD spends 7% of its boot time running a bubblesort on its SYSINITs",
    "url": "https://twitter.com/cperciva/status/1659558311920914432",
    "hn_url": "http://news.ycombinator.com/item?id=36002574",
    "content": "Thread ReaderOne-click sign-up and loginSign up or login to access your unrolled and bookmarked threads (or PDF archives if you are a Premium member!)Login with TwitterLogin with EmailLogin above to accept Thread Reader App'sTerms of Service and Privacy PolicyHelp | About | TOS | Privacy | Twitter Files",
    "summary": "- When the FreeBSD kernel boots in Firecracker (1 CPU, 128 MB RAM), it now spends 7% of its time running a bubblesort on its SYSINITs.\n- O(N^2) can bite hard when you're sorting over a thousand items.  Time to replace the bubblesort with something faster.",
    "hn_title": "FreeBSD spends 7% of its boot time running a bubblesort on its SYSINITs",
    "original_title": "FreeBSD spends 7% of its boot time running a bubblesort on its SYSINITs",
    "score": 347,
    "hn_content": "FreeBSD spends 7% of boot time running a bubblesort on its SYSINITs, which is a sign of poor scaling; O(n^2) algorithms often cause performance issues; profiling software can help identify performance issues even in live-service games; a list should be sorted before use; there are several ways to implement offset pagination while avoiding O(n^2) performance issues; bubblesort is not the best sorting algorithm to use when coding in assembly; it's important to choose the right sorting algorithm based on your needs.This thread discusses the challenges of implementing sort algorithms in C language, especially in boot code. Some claim that it's not trivial to convert theoretical optimization into code, and others argue that high-quality C sorting libraries exist. The lack of a unified package management system, a strong universal error handling mechanism, and memory allocation were listed as some of the challenges in using C libraries. Despite some disagreement, people generally agree that coding in C requires a certain level of expertise.C++ programmers are discussing the complexities of using a sorting library in C++, especially with custom types. Passing function pointers to the library creates potential for bugs or undefined behavior, and defining different assignment operator styles for each library is difficult. There is no standard build system for C++, and building dependencies is tedious and error-prone. Some users suggest that Rust would be a better alternative for generic programming or easy creation of generic data structures and sorting algorithms. A recent improvement of 4.5ms in the FreeBSD boot time is considered noteworthy but some argue that  such a reduction in boot time is negligible for most people.Amazon is testing a new sort technique to optimize boot time in its EC2 instances for cold starts and Firecracker VMs used in AWS Lambda functions. FreeBSD developers have criticized the qsort technique as \"fundamentally broken.\" Amazon is trying to reduce boot time, which impacts customers who pay by the second for cloud instances. The company claims that the new sort is expected to trim the time it takes to sort the entire virtual filesystem bookkeeping data during the boot process by 7 percent. Though raising questions as to the practicality of such a small improvement, Amazon maintains that the small differences will add up when applying the change across millions of instances.FreeBSD has started using the quicker qsort method to enumerate SATA drives in the AHCI driver instead of the slow bubble sort, which reduced kernel boot time by nearly two milliseconds. The process of booting kernels too often could create a delay that might become noticeable. There were discussions on Reddit about whether other operating systems already used the qsort-like system to bypass SATA drives' slower enumeration, which tends to involve some form of waiting to ensure all hard drives have started up. Moreover, the post mentioned the use case of Amazon's Firecracker MicroVMs, which is sometimes booted for batch jobs and HTTP requests, and every additional 2ms adds up in the overall cold response time. This might be seen as a solution for running individual code on personal devices or remote servers.Experts discuss the slowest part of kernel boot time and the potential optimizations that can be made, with some pointing out the prevalence of stupid algorithms and structurally slow code. The conversation also touches upon the optimization of boot times for a range of devices, including AWS lambdas and routers, and the tradeoff between speed and compatibility with the world. One commenter notes the issues with BIOS initialization as the reason why a modern desktop couldn't boot in milliseconds. Some optimizations include quicker enumeration for PCI devices and using better algorithms, such as merging sorting instead of bubble sorting. A few individuals also discuss the \"BBBB problem,\" where an algorithm's worst-case complexity is observed when repeated characters are present, as seen in Git conflict markers.- Linux distros like Fedora, RHEL/CentOS/et al, Debian, Ubuntu, Arch and derivatives use systemd\n- Gentoo, Void, Alpine and Android (which is not considered a Linux distro in the same sense) are some of the major user-facing Linux distros without systemd\n- Embedded systems may or may not use systemd, with openwrt not using it, and yocto and buildroot using it optionally\n- The opinion of \"what makes a distro\" is subjective and arbitrary\n- The author of the tweet has given talks and made written articles about his work on speeding up the FreeBSD boot\n- Large systems need to initialize a lot of DRAM at power-on, but a reboot of a running Linux desktop should take single-digit seconds\n- Some network routers take up to 30 minutes to cold boot from what is heard, but they essentially never cold boot because they are on UPS",
    "hn_summary": "- Sorting algorithms are complex to implement in C and C++ programming language, Rust may be a better alternative for generic programming or easy creation of generic data structures and sorting algorithms\n- Amazon is testing a new sort technique to optimize boot time in EC2 instances for cold starts, while FreeBSD has started using the quicker qsort method to enumerate SATA drives in the AHCI driver to reduce kernel boot time. The slowest part of kernel boot time and the potential optimizations that can be made were discussed."
  },
  {
    "id": 36004925,
    "timestamp": 1684519073,
    "title": "Migrating from Supabase",
    "url": "https://blog.val.town/blog/migrating-from-supabase",
    "hn_url": "http://news.ycombinator.com/item?id=36004925",
    "content": "- Val Town migrated from Supabase to a simpler database setup at Render due to problems encountered with Supabase not being able to scale to their team's needs.\n- The biggest problem encountered with Supabase was local development, which was made difficult due to the lack of documentation and broken toolchain for the Supabase CLI, and having all development happen in production.\n- Val Town also experienced downtime due to Supabase's auto-resizing scheme for their databases, and they encountered issues with the Supabase web interface when trying to use their database as Postgres. \n- Val Town ultimately switched to using a \u201cvanilla\u201d Postgres service at Render, where they could test migrations locally before applying them in production, and eliminated triggers, stored procedures, and row-level security rules, simplifying their database usage and architecture. They also used drizzle-orm to build SQL queries.\n- Migrating the data from Supabase to Render took a week due to the size of their database, and they gradually migrated their critical data before eventually migrating the historical data.- Val Town is evolving its database with traditional migrations and developing the application locally\n- The ability to \u2764\ufe0f a val was shipped in a couple of hours and without anxiety\n- In the past, touching the database schema was scary\n- Val Town sometimes misses the friendly table view of Supabase interface, but they are spending their innovation tokens elsewhere and shipping faster because of it",
    "summary": "- Val Town migrated from Supabase to Render due to problems encountered with scalability and local development issues.\n- Supabase's lack of documentation and broken toolchain for the CLI made local development difficult, and being limited to production was a major issue.\n- Val Town ultimately switched to a simpler \"vanilla\" Postgres service at Render, eliminating complex features and dependencies for a more streamlined database architecture.",
    "hn_title": "Migrating from Supabase",
    "original_title": "Migrating from Supabase",
    "score": 305,
    "hn_content": "Supabase CEO responds to customer feedback and criticism:\n\n- Developers should use Migrations once project is live and not modify the database live using Dashboard\n- Supabase goal is to make all of Postgres easy but not obligatory; adding more examples to the Docs beyond \"the Supabase way\"\n- Building CLI experience, debugging tooling, index advisors, and making usage clear to make \"all of Postgres\" easy to use\n- Supabase's core principles include portability and the ability to migrate away easily\n- Local development is a potential issue for some users, but some find it easy to use\n- Row Level Security is a great backstop, but Supabase is over-reliant on it for security\n- Supabase is investigating moving everyone to PITR (point in time recovery) backups\n- Users can use RLS and SQL for multi-tenant defense in depthA discussion among developers and users of Postgres-based Supabase highlights some of the product's strengths and weaknesses. While Supabase is praised for its ease of use in both development and production, some issues were noted, including slow execution times due to recursive row level security checks and the complexity of migrations in the cloud-based database service. Some users have found that it is better to treat the database as a persistence layer rather than an application and to move logic to the application level. Suggestions for improvement include better documentation, improved CLI tools, and better tools for previewing migrations and enforcing best practices in production. Some users recommended using self-hosted Supabase or other tools like Prisma and custom Node backends.- Choice of programming language and location of code in SQL or memory are key considerations in database logic\n- Supabase is a popular option for database and authentication, but some users may encounter limitations and performance issues\n- Some users prefer alternative options such as Clerk.dev or rolling their own authentication solution\n- Supabase CLI updates frequently, which may cause inconvenience for some users\n- There are community-contributed resources, such as StackGres, that can assist with running Supabase on Kubernetes",
    "hn_summary": "- Supabase's goal is to make Postgres easier, but not mandatory; better documentation and more examples recommended\n- Suggestions for improving CLI tools, migration preview and enforcement, and treating the database as a persistence layer, not an application"
  },
  {
    "id": 36000079,
    "timestamp": 1684493720,
    "title": "Apple Restricts Employee Use of ChatGPT, Joining Other Companies Wary of Leaks",
    "url": "https://www.wsj.com/articles/apple-restricts-use-of-chatgpt-joining-other-companies-wary-of-leaks-d44d7d34",
    "hn_url": "http://news.ycombinator.com/item?id=36000079",
    "content": "By Aaron TilleyFollowand Miles KruppaFollowUpdated May 18, 2023 7:35 pm ETShareResizeListen(2 min)Sam Altman, CEO of ChatGPT creator OpenAI, touted the benefits of AI and acknowledged potential downsides of the technology during a Senate subcommittee hearing. Photo: Patrick Semansky/Associated PressApple AAPL 0.06%increase; green up pointing trianglehas restricted the use of ChatGPT and other external artificial intelligence tools for some employees as it develops its own similar technology, according to a document reviewed by The Wall Street Journal and people familiar with the matter.Continue reading your article witha WSJ subscriptionMemorial Day Sale$1 Per WeekSubscribe NowAlready a subscriber? Sign In",
    "summary": "- Apple has restricted the use of ChatGPT and other AI tools for some employees.\n- This is in line with Apple's development of its own similar technology.\n- The move is in response to leaks from employees, as other companies have also been wary of such leaks in recent years.",
    "hn_title": "Apple Restricts Employee Use of ChatGPT, Joining Other Companies Wary of Leaks",
    "original_title": "Apple Restricts Employee Use of ChatGPT, Joining Other Companies Wary of Leaks",
    "score": 305,
    "hn_content": "Apple has restricted employee use of ChatGPT, a decision that follows other companies that are wary of leaks. The move does not reference an outright ban but simply restricts usage of the service. OpenAI, which developed ChatGPT, has introduced a business subscription designed to offer more granular data control to professionals and enterprises. Users can choose whether to enable the training of AI functions on data generated through the API, while OpenAI recently revealed that it does not use customers\u2019 data for selling its services, advertising, or creating individual profiles. The site aims to reassure customers with a banner warning them AI is dangerous and urging them to sign up to protect themselves.Users express concern over Apple's implementation of Siri, and note the lack of new, competitive capabilities, indicating little experience in the natural language processing space. Some speculate whether Apple could be building its own AI assistant similar to OpenAI's ChatGPT, but with Apple's internal siloing culture, it may be difficult to know. Some companies are exploring private API access for ChatGPT hosted on Azure, but concerns remain over data privacy and security.Apple has banned the use of OpenAI's GPT-3 and other language models (LLMs) for confidential work. The move comes due to concerns over sensitive data, which could be inadvertently leaked through submission in servers and databases. However, some critics have questioned the ban, asserting that users should be accountable and more educated. Nevertheless, some have voiced their frustration with the lack of viable open-source alternatives to popular Big Tech platforms like Facebook and Twitter. Meanwhile, users of LLMs have argued their benefit, with some even saying they rely upon them to learn and troubleshoot.The post discusses the use of AI tools like ChatGPT and LLMs for writing code and other tasks. Different users have varying opinions on the usefulness of AI tools, with some finding them extremely helpful in saving time and effort, while others feel they are leaving something on the table in terms of learning. The post also mentions the legal implications of using generative AI, which some see as a means of copyright laundering. However, others argue that such tools can be beneficial for tasks that involve boilerplate writing or writing things that are not subject to copyright laws. Overall, the post highlights the potential and limitations of AI tools for various tasks and the ongoing debate around their ethical and legal implications.Developers discuss the use of ChatGPT and the implications of its training data and copyright infringement. Some suggest using a synthetic data approach to avoid copyright issues. Companies ban the use of ChatGPT due to copyright concerns, while others make it centrally available to employees. Some argue that using AI to solve technical problems is a significant advantage, though others have not seen such benefits in practice. The amount of effort required to produce useful data is a topic of discussion, with some arguing that creating the digital resource over the last 20-30 years requires a tremendous amount of labor. Labor theory of value is debated and its relevancy to ChatGPT is discussed.Developers discuss the limitations of using AI tools like ChatGPT for complex or codebase-specific questions, and suggest using copilot or pasting relevant code into the chat instead. Companies are concerned about the potential risks of using ChatGPT, including the potential for violating corporate policies and regulations by uploading proprietary code or IP to a third-party AI service. Some developers express a need for \"spoon-feeding\" and may benefit from AI tools like ChatGPT, while others see it mostly as a learning aid for junior devs. OpenAI's ChatGPT interface is similar to a public sharing site, while their B2B products have better controls and limits to minimize potential risks. Companies should not blindly adopt every novelty, but consider the benefits and potential risks of AI-driven development.OpenAI's ChatGPT is set to exclude API access to protect user data from being used for training models, but those who use chat.openai.com will still share their data by default. Users can turn the option off in the settings, but it may make companies uncomfortable. OpenAI reportedly plans to release ChatGPT Business, which would give users more control over their data. The lack of data privacy in OpenAI's GPT models is concerning, as the company retains the ability to look at user data if needed. Companies that fail to take advantage of LLM may be replaced by those that do. However, open source models are currently not close to GPT-3.5 or GPT-4 in terms of coding capability. Apple may roll its own GPT model due to OpenAI's privacy concerns.",
    "hn_summary": "- OpenAI introduces business subscription with more granular data control to reassure customers of privacy concerns and urge them to sign up for protection\n- The post discusses the potential and limitations of AI tools like ChatGPT and LLMs for various tasks and the ongoing debate around their ethical and legal implications."
  },
  {
    "id": 36003096,
    "timestamp": 1684510119,
    "title": "Venture Predation",
    "url": "https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4437360",
    "hn_url": "http://news.ycombinator.com/item?id=36003096",
    "content": "Product & ServicesSubscribeSubmit a paperBrowseRankingsBlog\u2197ContactCreate accountSign inDownload This PaperOpen PDF in BrowserAdd Paper to My LibraryShare:Venture PredationJournal of Corporation Law, ForthcomingCardozo Legal Studies Research Paper, No. 70868 Pages Posted: 4 May 2023 Last revised: 17 May 2023Matthew WansleyYeshiva University - Benjamin N. Cardozo School of LawSamuel WeinsteinYeshiva University - Benjamin N. Cardozo School of LawDate Written: May 3, 2023AbstractPredatory pricing is a strategy firms use to suppress competition. The predator prices below its own costs to force its rivals out of the market. After they exit, the predator raises its prices to supracompetitive levels and recoups the cost of predation. The Supreme Court has described predatory pricing as \u201crarely tried\u201d and \u201crarely successful\u201d and has established a liability standard that is nearly impossible for plaintiffs to satisfy. We argue that one kind of company thinks predatory pricing is worth trying and at least potentially successful\u2014venture-backed startups.A venture predator is a startup that uses venture finance to price below its costs, chase its rivals out of the market, and grab market share. Venture capitalists (VCs) are motivated to fund predation\u2014and startup founders are motivated to execute it\u2014because it can fuel rapid, exponential growth. Critically, for VCs and founders, a predator does not need to recoup its losses for the strategy to succeed. The VCs and founders just need to create the impression that recoupment is possible, so they can sell their shares at an attractive price to later investors who anticipate years of monopoly pricing. In this Article, we argue that venture predation can harm consumers, distort market incentives, and misallocate capital away from genuine innovations. We consider reforms to antitrust law and securities regulation to deter it.Suggested Citation:Wansley, Matthew and Weinstein, Samuel, Venture Predation (May 3, 2023). Journal of Corporation Law, Forthcoming, Cardozo Legal Studies Research Paper, No. 708, Available at SSRN: https://ssrn.com/abstract=4437360 or http://dx.doi.org/10.2139/ssrn.4437360Download This PaperOpen PDF in BrowserDo you have a job opening that you would like to promote on SSRN?Place Job OpeningPaper statisticsDOWNLOADS1,201ABSTRACT VIEWS24,053RANK32,022PlumX MetricsRelated eJournalsCardozo Law School Legal Studies Research Paper SeriesFollowCorporate Law: Corporate & Financial Law: Interdisciplinary Approaches eJournalFollowFeedbackSubmit a PaperSection 508 Text Only PagesSSRN Quick LinksSSRN SolutionsResearch Paper SeriesConference PapersPartners in PublishingJobs & AnnouncementsSpecial Topic HubsSSRN RankingsTop PapersTop AuthorsTop OrganizationsAbout SSRNSSRN ObjectivesNetwork DirectorsPresidential LetterAnnouncementsContact usFAQsCopyright Terms and Conditions Privacy PolicyWe use cookies to help provide and enhance our service and tailor content.To learn more, visit Cookie Settings.",
    "summary": "- Predatory pricing is a strategy used by firms to suppress competition.\n- Venture predators are startups that use venture finance to price below their costs and chase rivals out of the market to grab market share.\n- Venture predation can harm consumers and misallocate capital away from genuine innovations, and reforms to antitrust law and securities regulation may be needed to deter it.",
    "hn_title": "Venture Predation",
    "original_title": "Venture Predation",
    "score": 304,
    "hn_content": "Amazon uses ultra-cheap money to invest in the business and bleed competitors dry, according to a report in Slate.com. It uses its access to capital at cheaper rates than most countries to put rivals under pressure. Amazon is able to run negative or break-even margins, killing off competitors. company founder Marc Lore (sold Jet.com to Walmart for $3.3bn) is a premium food delivery service called Wondery that raised $350m at a $3.5bn valuation last year; none of Lore's companies has turned a profit. It is possible that by killing off companies like Wondery, Amazon could raise its power and prices later, squeezing suppliers more and ratcheting up prices for customers.\nThe debate centers around whether or not startups that sell goods below the cost of production are guilty of \"dumping\" and whether or not this a phenomenon unique to VC-backed companies. Some commentators argue that this is just how startups operate and that it's not uncommon for losses to be incurred initially, while others claim that businesses that sell products at a price they know will never be sustainable are damaging the wider industry. Uber is cited as an example. There is a debate about whether they are guilty of \"dumping,\" with some saying they could be profitable if they wanted to be, while others claim that they are selling shares in the company rather than discounted rides.Venture capitalism and \"startup culture\" have surged in recent years, partly thanks to the easy flow of investment money. However, the demand for \"unicorns\" - startups worth over $1bn - has resulted in a push toward what is known as \"venture predation,\" in which companies offer unsustainable prices or business models that can force competitors out of the market. Critics argue that this practice is unethical and against the principles of entrepreneurship. Additionally, some people question whether many startups genuinely add value to our lives, asking whether their products contribute positively to society overall. Ultimately, some say, venture predation may have adverse effects on innovation and the economy.A discussion on the predatory practices of venture-backed startups has caused concern among tech-savvy individuals. Such practices involve using venture finance to price products below costs but creating the illusion that recoupment is possible in order to sell shares at an attractive price to later investors. This approach can fuel exponential growth but doesn't necessarily need to recoup losses to succeed. While some argue that it's not immoral, others claim that it's venture predation and prevents new innovations. The discussion also touched on the potential implications of Cloudflare's device attestation, while a debate about loss leaders and their financial implications took place.VC funded startups use below-cost pricing to drive out small businesses and monopolize markets, a practice known as \"venture predation.\" This approach can benefit consumers in the short term, but once competition is destroyed, they are at the mercy of the predator's higher prices. Ride-hail companies like Uber and Lyft used this strategy to gain dominance in the market, and regulators face difficulty curbing such actions. Academic discussions use the terms \"venture dumping\" or \"predatory pricing.\" While Amazon operates on narrow margins, they aim to have a durable cost advantage in the long term. Regulators responding to the \"Uber problem\" will likely lead to higher ride costs and lower-paid drivers.No meaningful content provided.",
    "hn_summary": "- The debate centers around whether startups that sell below cost are guilty of \"dumping\" and whether this is unique to VC-backed companies\n- The surge in the demand for \"unicorns\" has resulted in a push toward \"venture predation,\" raising concerns about ethics and impacts on innovation and the economy."
  },
  {
    "id": 35999438,
    "timestamp": 1684486614,
    "title": "Satellites reveal widespread decline in global lake water storage",
    "url": "https://www.science.org/doi/10.1126/science.abo2812",
    "hn_url": "http://news.ycombinator.com/item?id=35999438",
    "content": "www.science.orgChecking if the site connection is securewww.science.org needs to review the security of your connection before proceeding.Ray ID: 7ca2622ebb00f99fPerformance & security by Cloudflare",
    "summary": "- Satellite observations, climate models, and hydrologic models indicate that more than 50% of large natural lakes and reservoirs have experienced volume loss over the past 30 years due to both human activities and climatic factors.\n- The decreasing water volume in these lakes and reservoirs poses a significant threat to essential ecosystem services, including freshwater storage, food supply, waterbird habitats, the cycling of pollutants and nutrients, and recreation. \n- Yao et al.'s findings highlight the urgent need for improved water management strategies to conserve and protect these vital freshwater resources.",
    "hn_title": "Satellites reveal widespread decline in global lake water storage",
    "original_title": "Satellites reveal widespread decline in global lake water storage",
    "score": 272,
    "hn_content": "Satellites reveal a widespread decline in global lake water storage, with a net rate of natural lake volume declining at a rate of -26.38 \u00b1 1.59 Gt per year. Climate change and human activities increasingly threaten lakes that store 87% of Earth's liquid surface freshwater. Between 1984 and 2015, 90,000 km2 of permanent water area was lost by satellites, equivalent to the surface of Lake Superior, and 184,000 km2 of new water bodies, primarily reservoirs, were formed elsewhere. The discussion covers the expected change over the same period and challenges the alarmist culture of climate change science. The article calls for responsibility from societies to manage their natural resources sustainably.Various users on HN comment on the problems with water shortage due to climate change and mismanagement, and discuss possible solutions such as building desalination plants powered by clean energy, using salt as a building material, or focusing on conservation and waste reduction alongside afforestation and better water distribution practices. The conversation touches on nuclear power as a potential solution, but also considers the negative ecological impacts of desalination and salt farming practices. The thread points to the interrelated challenges of managing resources such as energy, water and land, while also mitigating the impacts of climate change and adapting to new ecological conditions.\u2022 1.35 billion ha of agriculture land in 1800 | 2.54 billion ha of agriculture land in 1900 | 4.93 billion ha of agriculture land in 2016\n\u2022 Animal agriculture takes up 75% of agriculture land\n\u2022 Beef is responsible for deforestation\n\u2022 Vegetation plays a significant role in water cycle and its removal or degradation can worsen drought conditions\n\u2022 Farmers use high speed pumps or camouflage them in streams to get by water restrictions\n\u2022 Rainfall isn't evenly distributed through both space and time\n\u2022 Earth is a closed system, so we should expect to see water storage decline in some areas and flooding increase in some areas\n\u2022 We're currently using water faster than rain replenishes it in many places, and in some places, aquifers have collapsed from over-pumping\n\u2022 Biodiversity loss impacts water recycling through transpirationAs temperatures increase, there will be a net increase in ocean-driven evaporation, leading to a concern that the only available water will be too salty to drink or too destructive to capture. Higher global average temperatures will cause an increase in specific humidity, meaning less condensation. Oceans only evaporate from the surface, while the air retains moisture by volume. Desalination is expensive, and many places rely on farming and industry, which are both water-intensive processes. There is potential to move water-intensive industrial processes to where the water is, and to switch to crops that require less water. Current desalination costs would consume almost all the income for someone living below the poverty line. We lose atmosphere to space every day, but Earth is not an open system and can still take in energy from the sun.",
    "hn_summary": "- The article calls for responsibility from societies to manage their natural resources sustainably.\n- HN users discuss possible solutions for water shortage, including clean energy-powered desalination, conservation and waste reduction, afforestation, better water distribution, and moving water-intensive industrial processes to water sources."
  }
]
