[
  {
    "id": 35847715,
    "timestamp": 1683430879,
    "title": "macOS Internals",
    "url": "https://gist.github.com/kconner/cff08fe3e0bb857ea33b47d965b3e19f",
    "hn_url": "http://news.ycombinator.com/item?id=35847715",
    "content": "macOS InternalsUnderstand your Mac and iPhone more deeply by tracing the evolution of Mac OS X from prelease to Swift. John Siracusa delivers the details.Starting PointsHow to use this gistYou've got two main options:Under Highlights, read all the links you're interested in, orUse \"OS X Reviewed\" as an index and just read all the reviews end to end. (This is not the fast option, but it inspired me to gather all these highlights.)In either case, to get the greatest benefits of context and intuition, I recommend that you read in chronological order.OS X ReviewedNearly 15 years ago, I wrote my first review of Mac OS X for a nascent \u201cPC enthusiast\u2019s\" website called Ars Technica. Last fall, I wrote my last.HighlightsThese chronologically-ordered highlights jump into the middle of long, paginated articles. Topics often span a few pages, so look for the \"Next Page\" links.Quartz 2D: PDF-based drawingI've chosen to define the three generations of display layer technology in order to illustrate the most important changes over the years.Packaged Applications and FrameworksThe three main \"subspecies\" of Bundles are Application Packages, Frameworks, and Loadable Bundles.The Window ServerIt has two main responsibilities: Event routing, and composing and displaying on-screen elements.Project Builder, better known as XcodeWhat may not be so obvious is that Project Builder is built on top of popular open source development tools: everything from gcc, gdb, and cvs to smaller tools like diff.Memory on macOSMac OS X manages memory very differently than classic Mac OS. The first key to understanding memory usage in Mac OS X is to be understand how a modern virtual memory system works.Rendezvous, now known as Bonjour and ZeroconfRendezvous enables a local network of devices to configure themselves without the aid of any centralized servers.GPU-accelerated display compositingIt's slightly confusing to think about the window server as an OpenGL application, but that's what it is.\"Sherlocking\"As the Watson FAQ explains, although Apple's new version of Sherlock is a dead-ringer for Watson, there is no formal relationship between the two applications.Spatial window management and Expos\u00e9Panther includes a new window management feature that effectively increases the size of your screen by shrinking all of your windows temporarily. Following Apple's recent Gallic naming trend, it's called Expos\u00e9.launchdOne launch daemon to rule them all.Extended file attributesMac OS X now includes support for arbitrarily extensible file system metadata.SpotlightSpotlight is a system service that accepts a query and returns all file system objects (files and folders) that match the query.GPU-accelerated window drawingThe only thing left for the CPU to do is to send (relatively tiny) drawing commands to the video card through the driver.DTrace and InstrumentsThis application was called Xray for most of its development life, which explains the icon. It's now called Instruments for reasons that surely involve lawyers.FSEventsTo be aware of all relevant file system changes, the notification mechanism must exist at the choke point for all local i/o: the kernel. But the kernel is a harsh mistress, filled with draconian latency and memory restrictions.Core AnimationCore Animation's original name, Layer Kit, reveals a lot about its design. At its heart, Core Animation manages a collection of 2D layers.Time Machine\"I know I should back up, but I never do. I wouldn't even know how to do something like that anyway.\" Well, enough of that.LLVM, Clang, and Objective-C BlocksBy committing to a Clang/LLVM-powered future, Apple has finally taken complete control of its development platform.GCD: Grand Central DispatchThe bottom line is that the optimal number of threads to put in flight at any given time is best determined by a single, globally aware entity.The Recovery PartitionThe new partition is actually considered a different type: Apple_Boot. The Recovery HD volume won't be automatically mounted upon boot and therefore won't appear in the Finder.Hidden scroll bars and natural scroll directionLion further cements the dominance of touch by making all touch-based scrolling work like it does on a touchscreen.Modernized Document ModelAt this point, a little bit of \"geek panic\" might be setting in.Automatic TerminationWhereas Sudden Termination lets an application tell the system when it's okay to terminate it with extreme prejudice, Automatic Termination lets an application tell the system that it's okay to politely ask the program to exit.App Sandboxing and EntitlementsA sandboxed application must now include a list of \"entitlements\" describing exactly what resources it needs in order to do its job.ARC: Automatic Reference CountingThere is no process that scans the memory image of a running application looking for memory to deallocate. Everything ARC does happens at compile time.FileVault whole disk encryptionThis encryption is completely transparent to all software (including the implementation of HFS+ itself) because it takes place at a layer above the volume format.Document revision storageUnlike earlier incarnations of autosave, you won't see auto-generated files appearing and disappearing alongside the original document. But the data obviously has to be stored somewhere, so where is it?iCloudApple provides three different kinds of iCloud data storage APIs, with very little overlap between them in terms of functionality and intended purpose.Gatekeeper, code signing, and quarantineGatekeeper is the latest stop in Apple's long, ongoing journey toward a more secure, worry-free computing experience on the Mac. Once again, iOS is the model.Objective-C 2.0 syntaxEven if you have no idea what any of that means, I believe you may still find the table below compelling.Power NapIn this mode, the audio and graphics systems remain powered down, but the disk, CPU, and networking hardware are all active.Finder TagsLabels were introduced way back in System 6 in 1988. Since Apple made both the Finder and the file system, it reserved a place in the file system metadata for what it called \u201cFinder Info.\u201dApp Nap and Background TasksBy coalescing the work into a contiguous burst of high activity, transitional waste has been cut to a bare minimum, and the amount of idle time has been maximized.Compressed MemoryLike the HFS+ compression feature introduced in Snow Leopard, compressed memory trades relatively abundant CPU cycles for decreased disk I/O.iCloud DriveReplacing the existing iCloud document storage is the new iCloud Drive\u2014and I do mean replacing.App ExtensionsThough they are distributed inside an application\u2019s bundle, Extensions are not just applications launched in a special mode. They are separate, purpose-built binaries, with their own containers, code signatures, and entitlements.HandoffWhen all the dots connect, it really is a neat experience. Now let\u2019s talk about those dots.SwiftPerhaps this mission statement is so grandiose\u2014so preposterous, even\u2014that readers are inclined to gloss over it or dismiss it. But it\u2019s the key to understanding the design of Swift.",
    "summary": "- This post provides a chronological evolution of Mac OS X to Swift to help understand Mac and iPhone better.\n- The post includes highlights such as quartz 2D, packaged applications and frameworks, memory management, and Gatekeeper code signing.\n- It covers newer features like compressed memory, iCloud Drive, app extensions, handoff, and Swift, with explanations and examples.",
    "hn_title": "macOS Internals",
    "original_title": "macOS Internals",
    "score": 704,
    "hn_content": "A Hacker News post on the GitHub page for macOS Internals, specifically discussing the lack of magic behind operating systems and databases, and how learning about their lower-level APIs can lead to more realistic expectations. The conversation between users includes book recommendations, historical context for computing, and musings on technology as a series of abstractions, with some mentions of the complexity of the WindowServer in macOS and the usefulness of the rcmd app for window management. Despite the lack of a central topic, the conversation provides insight into the mindset of those in the tech industry and offers suggestions for further reading.The post discusses the ease of programming for Apple's platforms today compared to 15 years ago. Despite the availability of programming guides, it's uncertain whether newcomers would use them. Readers recommend macOS-related blogs and podcasts for technical insights. A commentator also shares love for the old Ars Technica reviews and the work of John Siracusa. A commenter praises macOS's IPC system, bundling, launch services, APFS, and CPU architecture migrations. Mac OS X and iOS Internals: To the Apple's Core is a recommended read. Issues discussed include problems with code signing, app updates, and lack of high level GCd/managed language for the platform. Swift is seen as a good upgrade.Code signing for Win32 announced at BlueHat IL 2023.\nDiscussion on WinDev's use of COM and difficulties with cross-language interop.\nMentions of various package managers available for macOS to keep software up to date.\nRequest for a macOS version of SysInternals and suggestions for alternatives.\nClarification on the purpose and benefits of frameworks.\nNote on the memory usage of pixel-based interfaces.",
    "hn_summary": "- Readers recommend book recommendations, blogs, and podcasts for technical insights related to macOS.\n- The conversation provides insight into the mindset of those in the tech industry and offers suggestions for further reading."
  },
  {
    "id": 35848894,
    "timestamp": 1683445252,
    "title": "Walkout at global science journal over 'unethical' fees",
    "url": "https://www.theguardian.com/science/2023/may/07/too-greedy-mass-walkout-at-global-science-journal-over-unethical-fees",
    "hn_url": "http://news.ycombinator.com/item?id=35848894",
    "content": "An Elsevier facility in Missouri. They company has been accused of preying on the academic community. Photograph: Kristoffer Tripplaar/AlamyThe ObserverPeer review and scientific publishing\u2018Too greedy\u2019: mass walkout at global science journal over \u2018unethical\u2019 feesEntire board resigns over actions of academic publisher whose profit margins outstrip even Google and AmazonAnna FazackerleySun 7 May 2023 03.00 EDTMore than 40 leading scientists have resigned en masse from the editorial board of a top science journal in protest at what they describe as the \u201cgreed\u201d of publishing giant Elsevier.The entire academic board of the journal Neuroimage, including professors from Oxford University, King\u2019s College London and Cardiff University resigned after Elsevier refused to reduce publication charges.Academics around the world have applauded what many hope is the start of a rebellion against the huge profit margins in academic publishing, which outstrip those made by Apple, Google and Amazon.Neuroimage, the leading publication globally for brain-imaging research, is one of many journals that are now \u201copen access\u201d rather than sitting behind a subscription paywall. But its charges to authors reflect its prestige, and academics now pay over \u00a32,700 for a research paper to be published. The former editors say this is \u201cunethical\u201d and bears no relation to the costs involved.Professor Chris Chambers, head of brain stimulation at Cardiff University and one of the resigning team, said: \u201cElsevier preys on the academic community, claiming huge profits while adding little value to science.\u201dHe has urged fellow scientists to turn their backs on the Elsevier journal and submit papers to a nonprofit open-access journal which the team is setting up instead.He told the Observer: \u201cAll Elsevier cares about is money and this will cost them a lot of money. They just got too greedy. The academic community can withdraw our consent to be exploited at any time. That time is now.\u201dElsevier, a Dutch company that claims to publish 25% of the world\u2019s scientific papers, reported a 10% increase in its revenue to \u00a32.9bn last year. But it\u2019s the profit margins, nearing 40%, according to its 2019 accounts, which anger academics most. The big scientific publishers keep costs low because academics write up their research \u2013 typically funded by charities and the public purse \u2013 for free. They \u201cpeer review\u201d each other\u2019s work to verify it is worth publishing for free, and academic editors collate it for free or for a small stipend. Academics are then often charged thousands of pounds to have their work published in open-access journals, or universities will pay very high subscription charges.Stephen Smith, professor of biomedical engineering at Oxford University and formerly editor-in-chief at Neuroimage, said: \u201cAcademics really don\u2019t like the way things are, but individuals feel powerless to get the huge publishers to start behaving more ethically.Researchers put up with it because they want to publish in prestigious journals that will help their careers and ensure their work is widely read and cited.\u201dBut he warned publishers, \u201cEnough is enough. By taking the entire set of editors across to start the new journal, we are taking the reputation with us.\u201dA spokesperson for Elsevier said: \u201cWe value our editors very highly and are disappointed [with the resignations], especially as we have been engaging constructively with them over the last couple of years.\u201dHe said the company was \u201ccommitted to advancing open-access research\u201d and its article publishing charges were \u201cbelow the market average relative to quality. The fee for NeuroImage is below that of the nearest comparable journal in its field.\u201dMeanwhile, university libraries are angry about the cost of the online textbooks they say students now overwhelmingly want to read \u2013 often many times more expensive than their paper equivalent. Professor Chris Pressler, director of Manchester University Library, said: \u201cWe are facing a sustained onslaught of exploitative price models in both teaching and research.\u201dAccording to a spreadsheet of costs quoted to university librarians, Manchester University gave a recent example of being quoted \u00a375 for a popular plant biology textbook in print, but \u00a3975 for a three-user ebook licence. Meanwhile Learning to Read Mathematics in the Secondary School, a textbook for trainee teachers published by Routledge, was \u00a335.99 in print and \u00a3560 for a single user ebook.A spokesperson for Taylor and Francis, which owns Routledge, said: \u201cWe strive to ensure that book prices are both affordable and a fair representation of their value.\u201d He said a print book could be checked out for weeks at a time whereas ebooks could be checked in and out rapidly and had a much wider distribution.He added: \u201cAcademic publishers provide services that are essential to a well-functioning research and scholarly communication ecosystem, and most researchers recognise this is a valuable service worth paying for. \u201cCaroline Ball, librarian at Derby University and co-founder of the academic campaign EbookSOS, said: \u201cThis is creating a digital hierarchy of haves and have-nots. There are institutions that just can\u2019t afford these prices for texts.\u201dTopicsPeer review and scientific publishingThe ObserverPublishingResearch fundingScience and nature booksReuse this content",
    "summary": "- Over 40 leading scientists have resigned from the editorial board of a top science journal due to what they describe as the \"greed\" of academic publisher Elsevier's publication charges, which they consider unethical.\n- Neuroimage, a leading journal focused on brain-imaging research and one of many open access journals, charges over \u00a32,700 for a research paper to be published, and academics feel that the cost bears no relation to the costs involved.\n- Academics are urging fellow scientists to submit papers to a nonprofit open-access journal which the resigned team is setting up instead, and hope this marks the start of a rebellion against the large profit margins associated with academic publishing.",
    "hn_title": "Walkout at global science journal over \u2018unethical\u2019 fees",
    "original_title": "Walkout at global science journal over \u2018unethical\u2019 fees",
    "score": 501,
    "hn_content": "A global science journal, Elsevier, is accused of unethical fees, and suggestions are made that it's rampant within the academic publishing space. People, including the researchers, are being affected by the skyrocketing fees; no matter who ends up getting stuck with the unnecessary bill, they are being ripped off. Many researchers and authors are arguing that there should be an improved, less expensive, alternative scientific publishing model to replace Elsevier. Sci-hub's affordability has been stated as a life-saver for unaffiliated researchers and individuals researching a medical condition, but it is only one-third of the solution to cutting out the middleman; a credible place for researchers to publish is still required. The current publishers are trying to hold on to a dead model but failing, and suggestions like AI-generated papers are coming in as expected replacements, but real, sustainable solutions are still evasive.Several commenters on HN are discussing the nature of academic and national politics, with some arguing that academic politics is more vicious due to issues such as arbitrary publication criteria, fear of being scooped, and the way large-scale projects are run. Publishers such as Elsevier are being criticized for endemic rent-seeking behaviors similar to those in the US healthcare system, and prestige remains the primary driver in both academic publishing and politics. The replication crisis is being used to argue in support of open publishing, while others point out that replication numbers tend to be better in fields with freely available papers. Academia remains reluctant to change its current systems.This post is a collection of comments on academic publishing from various users on Hacker News. The comments discuss the high prices of academic journals, the role of prestige in academic publishing, and the impact of publishing in prestigious journals on the careers of researchers. There are also examples of alternative models for academic publishing in computer science and a comparison between academic prestige and Veblen goods. The comments highlight the problem of the high cost of academic publishing and how it affects both researchers and taxpayers.Academic research has seen increased reliance on metrics like journal rankings and citation indexes that have become the basis of prestige publishing which enables them to charge exorbitant fees. Prestige can be helpful for building careers, but equally, long-term fallout may be associated with prioritizing such metrics. It has resulted in a natural monopoly of sorts for the top academic journals and a need for university presses to emerge. As tax dollars fund scientific research, and with the current scenario, publishers end up pocketing taxpayer dollars, resulting in research being behind paywalls. On the other hand, curation adds value and increases the importance of\u00a0journals. Overall, there's no dire need to change the academic publishing business model, but conventional control will remain as the system won't fall for a long time.The University of California (UC) has signed a deal with Elsevier publishing, resulting in greater open access, while retaining similar prices. The mismatch lies in government and university-funded faculty contributions versus the captured profits by publishers. Elsevier's strategy is to be dominant in open access, a more guaranteed revenue stream. UC's agreement may be a transformative open access agreement which could change the publishing industry. The publishing sector is attempting to counter the disruption while the academics move towards altering the market's economic arrangements. The publishing industry controls the majority of prestigious publications in the academic sphere, making it the only metric used to assign research positions; changing it is fundamental to alter the academic journal system.Academics are evaluated based on the impact factor of the journal they publish in, leading to a system in which prestigious journals like Nature hold power over careers. This has led to a lack of investment in new journals that don't have an impact factor, meaning that even if new, more affordable platforms are created, they are unlikely to attract highly-cited papers. Peer reviewers are volunteers, and journals like Elsevier are essentially just hosting PDFs of papers. There are attempts to provide alternatives, such as open access and open-source solutions, but the problem lies in the financial incentives and power structures of the academic publishing system. The EU has recently announced plans toward no-cost open access mandates.Scientists are staging a mass resignation from the editorial boards of journals owned by the scientific publisher Elsevier. Protesters claim the Dutch firm charges excessive fees and operates a closed system. The firm argues the fees support its activities, pointing out it has invested heavily in technology to support digital publishing, and worked to expand the reach of academic work. However, some experts say publishing costs have come down, rendering the fees charged by Elsevier and other academic journals\u00a0unjustified. The issue has been complicated by the need to access publishers for peer review purposes.- Y Combinator, a startup accelerator, has opened applications for its Summer 2023 program\n- Y Combinator is known for investing in successful startups like Airbnb and Dropbox\n- The program offers startups funding, mentorship, and resources for growth and development\n- Y Combinator's success can be attributed to its \"moat,\" or barriers that prevent others from undercutting their business model \n- Applying to Y Combinator can be highly competitive and requires a strong pitch and team",
    "hn_summary": "- Academic publishing relies on metrics like journal rankings and citation indexes for prestige, which results in natural monopolies and high fees\n- Initiatives like open access and no-cost mandates from the EU may help alleviate the problem, but financial incentives and power structures may hinder real change in the industry"
  },
  {
    "id": 35849060,
    "timestamp": 1683447076,
    "title": "I'm never investing in Google's smart home ecosystem again",
    "url": "https://www.androidauthority.com/google-smart-home-3319869/",
    "hn_url": "http://news.ycombinator.com/item?id=35849060",
    "content": "NewsFeatures & opinionsReviewsThe bestHow-to's & guidesAll topicsMoreBest daily dealsAffiliate links on Android Authority may earn us a commission. Learn more.SMART HOMEI'm never investing in Google's smart home ecosystem againYou can't build a smart home around products with a murky future.By Dhruv Bhutani\u2022May 6, 2023Dhruv BhutaniOpinion PostI believe in a future where homes are connected, smarter, and automated enough not to require switches or repetitive voice-based input. However, till we get there, I\u2019ve been documenting my journey in creating an affordable, fully connected home and have invested a lot of money in picking up some of the best Google Home accessories. In fact, I was first in line to get a Google Home speaker when it launched as my smart home\u2019s central hub. But I\u2019m not going to beat around the bush here. I\u2019m done with Google. Here\u2019s why.Are you satisfied with Google's smart home products?23323 votesYes, It works just fine for me.No, I am not satisfied.I use an alternate system.Google keeps self-sabotaging its smart home ecosystemGoogle\u2019s directionless approach towards where it envisions its smart home ecosystem has been a long time coming. However, the recent spate of announcements killing additional features on the Nest Hub and support for third-party smart displays was the last straw for me.A few weeks back, Google announced it would no longer issue software updates or support new features on Google Nest alternatives like the Lenovo Smart Display, JBL Link View, or any other Google Assistant-compatible smart display. This follows an earlier update in January that disabled the web browser on all non-Nest Hub displays, rendering my Lenovo Smart Display rather useless.Google is clearly pushing users to its in-house products, but its not as if those are immune to the directionless approach.To me, it\u2019s clear. Google intends to push users toward the company\u2019s in-house product portfolio of smart home gear. That would make a lot of sense if the Nest smart home products offered an infallible experience. Unfortunately, the Nest Hub, too, is not immune to Google\u2019s directionless approach.Alongside the feature cuts to third-party hardware, Google has recently killed support for Assistant voice apps and games on its own hardware. So if you\u2019ve been using the Nest Hub to call up educational experiences for your children or to kill time, you\u2019d better enjoy it all you can until June 2023.Killing product lines and features isn\u2019t restricted to just the Nest Hub line either. As we\u2019ll talk about later in the article, it\u2019s a malady that afflicts practically every segment of Google\u2019s smart home ecosystem. And I, for one, am done having to find workarounds.I\u2019m done working around Google\u2019s messJimmy Westenberg / Android AuthorityI\u2019d understand some of these moves if the rest of the Nest Hub experience lived up to the promise. However, the fact is that Google has been dropping the ball on the overall experience for a while now.Ever since the Fuschia OS upgrade landed up on my Nest Hub, the user experience has been in a free fall. Voice prompts don\u2019t always work; when they do, they often present irrelevant information. Just the other night, my Google Nest Hub gave me a brief history of bagels when I asked about the weather. All too often, music playback stops, and sometimes, never even starts. Meanwhile, my colleague penned down her woes with something as basic as setting up her Google Home Mini following the Sonos lawsuit. Suffice it to say, it\u2019s not pleasant.The Fuschia OS upgrade and tiff with Sonos have further degraded an already iffy user experience.Google\u2019s tiff with Sonos over patent infringement and proprietary technology further added to my woes. It made it impossible to adjust volume levels across a multi-speaker group using a single slider. Similarly, using my phone\u2019s volume keys, I can no longer adjust volume levels for a smart speaker. As an end consumer, I shouldn\u2019t have to deal with the repercussions of Google\u2019s corporate dealings, yet here we are.Read More On This TopicSay goodbye to the best Nintendo Switch emulator for AndroidWhat is generative AI and how does it work?Earbuds are a recurring cost that you\u2019re not prepared forPowered by PlaywireIt doesn\u2019t end there, though. The aforementioned update on the Lenovo Smart Display nerfed the one thing I used it most for \u2014 streaming web video content in the kitchen. Not to mention the general sluggishness I\u2019ve been facing for a while now. I\u2019m afraid I will end up with a gigantic piece of plastic e-waste despite the hardware being more than serviceable for its intended task. That\u2019s not the future I was promised, nor am I okay with being forced to buy new hardware because Google can\u2019t decide what it wants to do.The lack of trust in Google\u2019s smart home ambitions isn\u2019t mine alone. My family members bought into Google\u2019s Nest Secure home monitoring solution a few years ago on my recommendation. Launched in 2017, Google unceremoniously pulled the plug on the product in 2020 and has officially deprecated it as of 2023.I struggle to understand what Google is thinking; the upgrade cycle for a security system should be measured in ten-plus years, if not more. Certainly not a scant few years like a smartphone. Sure, Google is happy to discount some users on their new ADT-based home security solution, but for many people, that means calling in the professionals. Try reasoning with middle-aged Indian uncles in New Jersey over a video call that they\u2019ll have pull out their home surveillance system because Google decided to stop supporting it. Fun times.One time is a mistake, thrice is a patternJimmy Westenberg / Android AuthorityI can understand a misstep or a failed product or two. It happens. However, constant self-sabotage with Google\u2019s smart home portfolio has left me completely jaded. In some ways, it reflects the increasingly insular nature of the connected devices industry. I know Matter is trying to correct that; however, Matter is far from maturity. Google, on the other hand, is further still. At least as far as smart home ecosystems are concerned.I'm gradually phasing out Google hardware from my home, and you should consider it too.The fact remains that the paying customer shouldn\u2019t have to struggle. Unlike a smartphone, a smart home product affects everyone in a home. Expecting customers to deal with Google\u2019s changing whims and fancies or telling a child they can no longer play their favorite game because Google decided to change its development strategy is not what users signed up for. If Google wants to rebuild trust in its smart home strategy, it must portray a strong vision of the future \u2014 both for software and hardware.As it stands, I\u2019ve lost all faith in the company and am gradually phasing out all Google hardware from my home. It barely works as is. Step by step, my goal is to build out an entirely self-hosted ecosystem. Since I only use my Google Nest speakers and displays for music, replacing them won\u2019t take much. I\u2019d urge you to look elsewhere as well.FEATURESOPINIONSGoogleSmart HomeCommentsDeal: 85% off Office Professional Plus 2021, and more Microsoft Office dealsDeals",
    "summary": "- The author of the post is done with Google's smart home ecosystem due to their directionless approach towards their product line.\n- Google has been killing off product lines and features and pushing users towards their in-house smart home gear, which doesn't offer a reliable experience either.\n- The lack of trust in Google's smart home ambitions is becoming more apparent among their customers and the author is gradually phasing out all Google hardware from their home.",
    "hn_title": "I'm never investing in Google's smart home ecosystem again",
    "original_title": "I'm never investing in Google's smart home ecosystem again",
    "score": 451,
    "hn_content": "A user shares their negative experiences with Google's smart home ecosystem, citing instances where Google stopped supporting products or forced changes, causing inconvenience. Other users share their own experiences of smart devices being unnecessarily complicated, privacy-invading, and prone to break easily. However, some users argue that smart devices do not always have to be cloud-connected and can be built locally to avoid these issues by using products like Matter, Zigbee, or Zwave. Overall, users agree that smart homes are not worth the cost and hassle and advocate for local, DIY solutions over buying commercial products.The conversation revolves around the disposable nature of tech products and the frustrations and security concerns involved in the forced obsolescence of devices via software updates and planned obsolescence. Some commenters express frustration with companies like Google, who they feel have become more business-minded and less focused on providing long-term support for their products. Others debate the necessity of constantly updating devices and the importance of analog options that last longer and require less maintenance. Some commenters raise security concerns with internet-connected devices that can potentially leave systems vulnerable to hacking. Overall, the sentiment suggests that many people are frustrated with the current state of technology and long for more durable, reliable options that do not require frequent updates and subscriptions.Comments on a Hacker News post cover a range of topics related to Google products and services. Users mention frustration with YouTube's \"Shorts\" feature being hard to disable, dissatisfaction with inconsistent Google Assistant functionality, complaints about Google Photos content-based search no longer working well, and debates over the usefulness and longevity of open source hardware and software. One user noted that Google may be intentionally releasing amateurish or incomplete products to avoid regulation.Multiple tech enthusiasts discuss their use of smart speakers and Bluetooth speakers in the shower, with some preferring the hands-free and multi-functionality of smart speakers like Amazon Alexa and Google Home, while others find their Bluetooth speakers satisfactory and easy to use. Some mention specific issues and advantages of each type of speaker, while others express interest in repurposing old smart speakers for alternative uses like media players or smart home controllers. No major new releases or developments are mentioned in the discussion.Users discuss their frustrations with Google products, including the discontinuation of services such as Google Fi and Google Photos, and the reduction of functionality in products like the Google Home Mini. Some users suggest alternatives, while others express hope for a future of long-lasting and customized home automation technologies. The conversation also includes technical details about integrating Google Assistant with Home Assistant and debates about the benefits and drawbacks of IoT. The article prompts discussion about the impact of corporatism on technological innovation and the importance of consumer rights.Google has been criticized for its lack of direction and purpose, resulting in a decline in its products and services. Nest, Google's smart home subsidiary, has been criticized for its lack of features, poor APIs, and upcoming shutdowns of services. Users are advised to be cautious of investing in hardware that relies on proprietary RPC endpoints and to opt for open-source options. Self-hosted smart home setups are growing in popularity, but they require technical knowledge. The article suggests that companies like Apple and Microsoft may not be inherently better than Google regarding smart home options. Disconnects between Google's different units have resulted in worsening user experiences, leading to a steady decline in users' dependence on Google products. As Google ceases to innovate and improve, many users are leaving the company for other services.Google Photos receives criticism for making it difficult to download batches of original quality photos with metadata together, which can cause data loss and inconvenience. Some users have also expressed concerns about Google's control of their data and privacy, prompting them to switch to alternative platforms like Apple. Some users recommend using Home Assistant, Photoprism, or Photo Structure instead. Others criticize Google for killing off many of its products and services, suggesting that the company lacks proper product management.",
    "hn_summary": "- Some users argue for local, DIY solutions like Matter, Zigbee, or Zwave to avoid cloud-based issues and privacy concerns.\n- People express concerns with the disposable nature of tech products and desire more durable, reliable options with less maintenance and frequent updates."
  },
  {
    "id": 35852192,
    "timestamp": 1683471625,
    "title": "Pixel phones are sold with bootloader unlocking disabled",
    "url": "https://www.fitzsim.org/blog/?p=545",
    "hn_url": "http://news.ycombinator.com/item?id=35852192",
    "content": "Pixel phones are sold with bootloader unlocking disabledPosted byThomas Fitzsimmons May 5, 2023 1 Commenton Pixel phones are sold with bootloader unlocking disabledRequest to Google: ungrey the \u201cOEM unlocking\u201d toggle in the factory, before shipping store.google.com devices to customers. Do not make your customers connect the device to the Internet before they are allowed to install the operating system they want.My wife had a requirement to use Android1, and she wanted to run GrapheneOS; I experimented with other devices and ROMs to ensure the specific application she needed would run on GrapheneOS.As part of my research, I read the GrapheneOS installation guide2, which stated:Enabling OEM unlockingOEM unlocking needs to be enabled from within the operating system.Enable the developer options menu by going to Settings > About phone and repeatedly pressing the build number menu entry until developer mode is enabled.Next, go to Settings > System > Developer options and toggle on the \u2018OEM unlocking\u2019 setting. On device model variants (SKUs) which support being sold as locked devices by carriers, enabling \u2018OEM unlocking\u2019 requires internet access so that the stock OS can check if the device was sold as locked by a carrier.\u201dNone of the many many YouTube videos I watched about bootloader unlocking covered whether or not you need Internet connectivity. Nor did any of Google\u2019s official documentation3. GrapheneOS documentation is the only place on the Internet that documents this requirement, so, well done GrapheneOS documentation team!GrapheneOS only supports recent Google Pixel phones. Those phones are nice hardware4, and I can easily (so I thought) install a different operating system, so I decided to buy one. To be as future-proof as possible, I bought a Pixel 7 Pro from store.google.com (Canada).I thought (based on the aforementioned GrapheneOS docs) that the device model variant I bought, being sold \u201cunlocked\u201d7 by Google, would not need the Internet connection. NOPE; Google sold it to me with \u201cOEM unlocking\u201d greyed out:I consider this a customer-hostile practice. I should not have to connect a piece of hardware to the Internet, even once, to use all of its features. If I hadn\u2019t connected the Pixel 7 Pro to the Internet, then \u201cOEM unlocking\u201d would have stayed greyed out, thus I would not have been able to unlock the bootloader, thus I would not have been able to install GrapheneOS5.Keep in mind that I bought this phone full price6 from store.google.com, where it was advertised right in the FAQ as an \u201cunlocked smartphone\u201d7. There is zero carrier involvement here, so carriers cannot be blamed for this policy. Also, I paid full price for the phone, so this is not a case of \u201cif you don\u2019t pay for the product, you ARE the product\u201d.I probably should have returned the device for a refund. Instead, I set up a network debugging environment to see what activity happens when I connect the Pixel 7 Pro to the Internet.By tailing some log files and watching them closely, I was able to determine that the final site accessed just before \u201cOEM unlocking\u201d goes from greyed to ungreyed is \u201cafwprovisioning-pa.googleapis.com\u201c. Here is the video of \u201cOEM unlocking\u201d ungreying:Here is the rest of the network activity, all of which is TLS-encrypted by keys buried in the stock Google operating system, and thus not controlled by the device purchaser:Hostname Downloaded to phone Uploaded from phonestorage.googleapis.com 383 MiB 8 MiBfonts.gstatic.com 137 MiB 3 MiBafwprovisioning-pa.googleapis.com 18 MiB 1 MiBwww.gstatic.com 8 MiB 287 kiBgooglehosted.l.googleusercontent.com 8 MiB 345 kiBota-cache1.googlezip.net 3 MiB 175 kiBdl.google.com 3 MiB 86 kiBinstantmessaging-pa.googleapis.com 1 MiB 300 kiBwww.google.com 46 kiB 24 kiBssl.gstatic.com 25 kiB 3 kiBota.googlezip.net 17 kiB 6 kiBdigitalassetlinks.googleapis.com 17 kiB 4 kiBclients.l.google.com 14 kiB 7 kiBgstatic.com 13 kiB 3 kiBmobile-gtalk.l.google.com 8 kiB 1 kiBmobile.l.google.com 5 kiB 1 kiBlpa.ds.gsma.com 5 kiB 4 kiBconnectivitycheck.gstatic.com 3 kiB 3 kiBapp-measurement.com 1 kiB 0 bytestime.android.com 180 bytes 180 bytesOnly Google knows precisely what all that data is and what it is used for.As the video shows, the ungreying did happen; I had the Settings application open, then connected the phone to the Internet. I had to close then re-open the Settings application; the access to \u201cafwprovisioning-pa.googleapis.com\u201d seemed to be co-timed with the Settings application restart. After the Settings appliation restart, the \u201cOEM unlocking\u201d option was operable.I don\u2019t know what subset of the hosts in the above table need to be accessible to the phone for ungreying to take place; I considered firewalling each individually using a script, but I ran out of time. I also don\u2019t know if a factory reset of the phone results in \u201cOEM unlocking\u201d being greyed again. I ended my experimentation when the ungreying took place and I proceeded to install GrapheneOS successfully (the rest of the process was very straightforward, thanks to GrapheneOS\u2019s great documentation and installation scripts).All in all, cheers to Google for releasing Android as Free and Open Source software, and for selling devices which are (with steps) bootloader-unlockable; both of which make GrapheneOS feasible8. Jeers to Google for selling devices from store.google.com that cannot have their bootloaders unlocked without first connecting them to the Internet.FootnotesOne day I hope we can both use PinePhones. ^https://grapheneos.org/install/cli#enabling-oem-unlocking ^https://source.android.com/docs/core/architecture/bootloader/locking_unlocking\u201cDevices should deny the fastboot flashing unlock command unless the get_unlock_ability is set to 1. If set to 0, the user needs to boot to the home screen, open the Settings > System > Developer options menu and enable the OEM unlocking option (which sets the get_unlock_ability to 1). After setting, this mode persists across reboots and factory data resets.\u201d ^Google Pixel devices lack several features of my PinePhone; luxuries such as a 3.5mm audio jack, a swappable battery, a microSD card slot, and HDMI output (with a hardware mod). ^The \u201clock\u201d/\u201dunlock\u201d terminology is hopelessly overloaded; as a result, confusion abounds online, even among phone enthusiasts. The \u201cOEM\u201d term here is also at best confusing and at worst misleading. I hope the screenshot and video make clear the specific context of this post, but here are definitions, and the states of the device I\u2019m discussing:\u201cgreyed\u201d => the user interface element is inoperable\u201cungreyed\u201d => the user interface element is operable\u201cOEM unlocking\u201d toggle is greyed (this is the state of the device after unboxing and before letting it have an Internet connection)\u201cOEM unlocking\u201d toggle is ungreyed (the device must be connected to the Internet for this ungreying to take place (see video))\u201cOEM unlocking\u201d toggle is ungreyed and toggled to \u201cdisabled\u201d\u201cOEM unlocking\u201d toggle is ungreyed and toggled to \u201cenabled\u201d\u201cOEM unlocking\u201d toggle is ungreyed and toggled to \u201cenabled\u201d and bootloader is locked\u201cOEM unlocking\u201d toggle is ungreyed and toggled to \u201cenabled\u201d and bootloader is unlocked (this is the state required to install GrapheneOS)At this point I don\u2019t care about SIM unlocking or carrier unlocking or any other type of unlocking. There are plenty of horror stories on forums of people having purchased new Pixel phones from carriers at full price and then, via this same mechanism, the carrier never allowing bootloader unlocking (while apparently allowing various forms of SIM and carrier unlocking which are useless for running alternate operating systems like GrapheneOS). ^With a Black Friday discount. ^https://store.google.com/product/pixel_7_pro\u201cFrequently asked questionsWhat is an unlocked smartphone?An unlocked smartphone is a phone that isn\u2019t tied to a specific carrier. When you purchase an unlocked Google Pixel phone, you get to choose which carrier or plan works best for you. Most phones in the Google Store come unlocked. Important: Google Pixel phones work with all major carriers. But not all Google Pixel 4a (5G) and later phones have 5G functionality on all 5G networks. See a list of certified carriers to make sure your smartphone works on its 5G network.To use a SIM-unlocked phone:Buy an unlocked Google Pixel phone from the Google Store.Contact a mobile carrier.Follow their instructions to set up your phone with their service plan.For 5G, some carriers may require a 5G plan (sold separately). Contact carrier for details. See g.co/pixel/networkinfofor info.\u201d ^ ^Other major phone vendors and operating systems are not in this blog\u2019s Overton window. ^Posted byThomas FitzsimmonsMay 5, 2023Posted inUncategorized",
    "summary": "- Google Pixel phones come with bootloader unlocking disabled, and customers must connect the device to the internet to enable unlocking, causing inconvenience.\n- OEM unlocking requires internet access to check if the device is sold as locked by a carrier.\n- GrapheneOS is the only place on the internet that documents the requirement of internet connectivity for OEM unlocking and supports limited Google Pixel phones.",
    "hn_title": "Pixel phones are sold with bootloader unlocking disabled",
    "original_title": "Pixel phones are sold with bootloader unlocking disabled",
    "score": 431,
    "hn_content": "Pixel phones are sold with a disabled bootloader unlocking feature, making it impossible for customers to install their desired operating system of choice. The ownership rights of such devices are therefore withheld from the customers, with the only way to unlock them being to pay someone in China to do so, given that U.S carriers' phones cannot be unlocked once permanently disabled. Xiaomi and Samsung are other brands known for similar requirements to install custom recovery software. These measures are explained as a security measure by some, while others believe it's an infringement of a user's personal property rights, with limited freedoms. Some believe that such controls are in place to prevent theft and fraudulent activities in the market.The tech community discusses the issue of carrier locking and hard-locking of devices, raising questions about ownership rights and potential violations of law. The \"phoning home\" process required to unlock the bootloader has sparked debate, with some arguing that it takes away ownership rights from users. Some speculate that this may be related to zero-touch enrollment of Android Enterprise/Android for Work, where unboxed phones need to contact a provisioning server at least once to verify there is no pending zero-touch enrollment configuration. Others note that while not allowing the bootloader to be unlocked on company-owned devices makes sense, applying the same setup to all phones implies that the default phone is a company-owned device. Many argue that Google should consider providing two different SKUs as a user-friendly option to cater to different use cases.Pixel phones can only be unlocked after connecting to the internet, but once unlocked, there are no restrictions on bootloader unlocking for devices purchased directly from Google. Some commenters feel that this restriction is inconsequential, and it exists to ensure that devices aren't carrier-locked. Others opine that the policy is a result of protection against stolen hardware. OnePlus has no such restrictions for its devices, while Samsung's restrictions appear to be burdensome. Many commenters state that Pixel devices are some of the easiest products to unlock, and it is a big advantage over other mainstream vendors. However, some express concerns about vendor bloatware and spyware. Motorola and Sony appear to be possible alternatives for those who want to root and install custom ROM on their devices.The post contains a discussion thread around concerns with Google's practice of locking bootloaders on their phones. The conversation includes comments on the availability and freedom of Chinese Androids, the possibility of unlocking and flashing other operating systems on devices, and network activity of Google OS. Some commenters call for increased legislation to ensure transparency and consent of data sharing, while others express confusion about the expectation of being free to use software of choice on a given hardware.An Android component called \"isOemUnlockAllowedByCarrier()\" has been found responsible for carrier restrictions on bootloader unlocking on Pixel phones. The Android Settings app grays out the \"OEM unlocking\" toggle if the value is false. A previously discovered exploit has been made defunct by both software updates and signed blobs required by the oemlock HAL. GrapheneOS offers a Google-free experience on Pixel phones, which are the only ones supported by their project. Banking apps do not support sideloading or running on rooted Android devices. It is suggested that carriers prevent phone unlocking while Google should ungrey the \"OEM unlocking\" toggle in factory settings.Google is making all future Pixel phones bootable, with previous models to follow, despite concerns surrounding the potential for stolen phones and supply chain attacks. Google's decision is next to Samsung's, for whom this has been standard since 2016. Stolen phones with locked bootloaders are worth less than those unlocked and reflashed with a new OS, therefore unlocking Pixel bootloaders in factories or in shipment is a security risk. A Pixel phone with an unlocked bootloader will display a warning on boot, and unlocking it will not affect the phone's warranty, but it is permanent. PinePhone can boot from an SD, so it is not a completely new feature. Apple has a BootROM feature that can be used to provision the device from a blank flash.- There is a contrast between European and US government approaches in protecting consumers from corporate abuse.\n- Some individuals accused of supporting Google are downvoting comments related to this issue.\n- Applications for Y Combinator's Summer 2023 program are now open, with more information available on their website.",
    "hn_summary": "- The tech community is discussing the issues of carrier locking and hard-locking of devices, raising questions about ownership rights and potential violations of law.\n- Google has decided to make all future Pixel phones bootable, with previous models to follow, despite concerns surrounding the potential for stolen phones and supply chain attacks."
  },
  {
    "id": 35847860,
    "timestamp": 1683432872,
    "title": "Belgium legalises ethical hacking",
    "url": "https://www.law.kuleuven.be/citip/blog/belgium-legalises-ethical-hacking-a-threat-or-an-opportunity-for-cybersecurity/",
    "hn_url": "http://news.ycombinator.com/item?id=35847860",
    "content": "ARTIFICIAL INTELLIGENCE &AUTONOMOUS SYSTEMSCOMPETITION &INNOVATIONDATA ACT SERIESDATA PROTECTION &PRIVACYEHEALTHLINKEDINTWITTERGOOGLE+RSSABOUTRESEARCHPUBLICATIONSEVENTSUSEFUL LINKSCONTACTARTIFICIAL INTELLIGENCE &AUTONOMOUS SYSTEMSCOMPETITION &INNOVATIONDATA ACT SERIESDATA PROTECTION &PRIVACYEHEALTHINTELLECTUAL PROPERTY &OPEN DATAMEDIA &TELECOMMUNICATIONSSECURITY &CRIMEOTHERBelgium legalises ethical hacking: a threat or an opportunity for cybersecurity?BY CHARLOTTE SOMERS, KOEN VRANCKAERT AND LAURA DRECHSLER - 03 MAY 2023On 15 February 2023, Belgium saw the entering into force of a new \u2018whistleblower\u2019 law, which legalised \u2018ethical hacking\u2019 even for cases where the hacked entity did not consent to it. In order to benefit from such decriminalisation, the law poses a number of conditions for ethical hacking, that have to be fulfilled in order for the hacker to be excused from any criminal liability. In this blogpost, we give an overview of the new Belgian whistleblower law from its definition of ethical hacking to the conditions for decriminalisation and conclude on the potential consequences of the law for the state of cybersecurity in Belgium and beyond.When is hacking \u2018ethical\u2019?A hacker is commonly understood in an IT context as somebody who gains unauthorised access to a computer system or network. Such unauthorised access can be motivated by criminal intentions, for example the extortion of money from those hacked by blocking them from accessing their system until they pay a ransom fee (so-called \u2018ransomware attack\u2019). Such hackers are typically referred to as \u2018black hat hackers\u2019. Yet, there are also hackers motivated by other considerations, for example when hackers hack a computer system or network in order to demonstrate a vulnerability that could be exploited by a black hat hacker. These \u2018ethical\u2019 hackers are also called \u2018white hat hackers\u2019. The work of ethical hackers can be of great advantage for organisations managing computer or network systems, as they will be able to address any cybersecurity vulnerabilities before they are exploited and thus prevent cybersecurity incidents from occurring. Such ethical hacking can therefore be a means to improve the cybersecurity of IT systems from both companies and public authorities.When is \u2018ethical\u2019 hacking legal under the new Belgian law?Before the new Belgian whistleblower law, all forms of hacking, including ethical hacking, were punishable under Belgian criminal law, unless the entity being hacked had consented to it. The latter exception already enabled a variety of Belgian organisations to make use of ethical hackers to increase their level of cybersecurity, for example by putting in place (financial) rewards, so-called \u2018bug bounties\u2019, for ethical hackers that helped them discover a vulnerability. Cooperations between ethical hackers and organisations typically took place in the context of a \u2018coordinated vulnerable disclosure policy\u2019 (CVDP). A CVDP is a set of rules created by the organisation managing an IT system, which offers a legal framework for collaborations between that organisation and ethical hackers. It has to be published online, for example on the website of an organisation. Ethical hackers could try to indicate via the CVDP that they had consent for their activities in order to avoid criminal liability. A CVDP was however no bulletproof way of escaping liability for the ethical hacker, and such activities were therefore always conducted with the potential risk of criminal prosecution.The new Belgian whistleblower law (Klokkenluiderswet) has changed the legal situation for ethical hacking in Belgium. A natural or legal person is now authorised to investigate organisations in Belgium for potential cybersecurity vulnerabilities, even if they have not consented to such investigations. This authorisation is dependent on the fulfilment of four conditions set by the law and can therefore not be understood as providing hackers with a \u2018carte blanche\u2019 for all forms of cybersecurity research. Only if these conditions are followed will the hacking no longer fall under the criminal prohibition for hacking of the Belgian Criminal Code.The first condition set by the law is that ethical hackers cannot have the intent to cause harm or to obtain illegitimate benefits with their activities. The law therefore excludes that ethical hackers request payment in order to reveal any potential vulnerabilities that they discovered, unless this has been agreed upon in advance, for example as part of a bug bounty programme or a CVDP. Extorsion is not an activity endorsed by the law.The second condition mandates that ethical hackers report any uncovered cybersecurity vulnerability as soon as possible to the Centre for Cyber Security Belgium (CCB), which is the national computer security incident response team of Belgium. Ethical hackers also need to report their findings to the organisation they were investigating, the latest at the time they are notifying the CCB over a vulnerability.The third condition requires ethical hackers to not go further in their hacking than necessary and proportionate in order to uncover a cybersecurity vulnerability. Ethical hackers have to limit themselves to those activities that are strictly necessary for the objective of notifying a cybersecurity vulnerability. This condition is for example breached if a vulnerability is discoverable with less intrusive means than those chosen by the ethical hacker. Ethical hackers are also required to ensure that their activities do not affect the availability of the services of the organisation under investigation.The final condition is an obligation for ethical hackers to not disclose information about the uncovered vulnerability to a broader public without the consent of the CCB. Ethical hackers can therefore not report on uncovered cybersecurity vulnerabilities in the media, for example by noting it in a blog post, unless they have the authorisation of the CCB.What are the consequences of the new Belgian rules for cybersecurity?The new Belgian whistleblower law only applies in Belgium. If a cybersecurity vulnerability concerns an IT system outside of Belgium, hacking might be covered by the rules of the country where the system is located. While the Belgian law is based on a European Union (EU) Directive (Directive 2019/1937), Belgium has decided to go beyond what is required, meaning that even within the EU there is a risk that the activities now legal under Belgian law are no longer so when its territorial boundaries are crossed. Any consequences of the new rules for cybersecurity are therefore limited in scope to Belgium.Despite this inherent limitation of the new law, it can still be expected to facilitate the work of ethical hackers in Belgium, and consequently their contribution in the uncovering of cybersecurity vulnerabilities. Preventing cybersecurity incidents from occurring remains an important but hard-to-realise component of cybersecurity that benefits not only organisations by saving them from the reputational and economic damage associated with a severe cybersecurity incident but also individuals, who otherwise might suffer cybersecurity harms, such as identify theft.That being said, questions remain about the exact delineation between legal (ethical) hacking and illegal hacking criminalised by the Belgian Criminal Code. This is because the new law uses the rather open terms \u2018necessary and proportionate\u2019 to describe what activities are now permitted. Necessity and proportionality will always depend on the concrete situation at hand making it at times difficult to predict which techniques can and cannot be used for ethical hacking. Moreover, the law omits to give certain details when it comes to notifying the public about cybersecurity vulnerabilities. As noted, ethical hackers cannot publish their findings without permission of the CCB, but there are no additional rules on how and when the CCB has to give such permission. This might impair an ethical hackers\u2019 ability to warn the wider public of a vulnerability in cases the organisation is not willing or able to address it.In the end, only time will tell the extent to which Belgium\u2019s pioneering attempt at legalising ethical hacking factually improves cybersecurity in Belgium. Its provisions can however be considered as a (small) step towards increasing preventive cybersecurity practices among Belgian organisations.This article gives the views of the author(s), and does not represent the position of CiTiP, nor of the University of Leuven.ABOUT THE AUTHOR \u2014 CHARLOTTE SOMERS @SOMERSCHARLOTTECharlotte Somers holds a Master in Law (cum laude) from the KU Leuven and an LL.M. in IP & ICT Law (cum laude) from the KU Leuven (campus Brussels). She is a legal researcher at CiTiP where she predominantly focuses on cybercrime law, cyber security, media law, privacy and data protection.VIEW ALL POSTS BY CHARLOTTE SOMERSABOUT THE AUTHOR \u2014 KOEN VRANCKAERT @VRANCKAERTKOENKoen Vranckaert obtained a Master of Laws from KU Leuven in 2015. In 2016, he completed the Master of IP & ICT Law at KU Leuven (Brussels Campus) (cum laude). Before joining CiTiP, Koen practiced as a lawyer for 3.5 years specializing in commercial litigation, intellectual property and data protection. At CiTiP, Koen is working on the CoSMoS project, where he provides legal basis on the impact of AI-based systems on liability in construction. Koen is also affiliated with the Knowledge Centre for Data & Society.VIEW ALL POSTS BY KOEN VRANCKAERTABOUT THE AUTHOR \u2014 LAURA DRECHSLER @DRECHSLERLAURADr. Laura Drechsler is a research fellow at the Centre for IT and IP Law (CiTiP) \u2013 imec of the KU Leuven working on the EU-funded LAGO project. In November 2022, she successfully defended her PhD thesis on data subject rights in international personal data transfers. .VIEW ALL POSTS BY LAURA DRECHSLERTAGGED AS: CYBERCRIME, CYBERSECURITY, ETHICAL HACKING, FEATUREDSECURITY & CRIMESHARE THIS POSTnicht mit Facebook verbunden nicht mit Twitter verbunden nicht mit Google+verbunden nicht mit LinkedIn verbunden SIMILAR ARTICLESHow much of your privacy are you willing to sacrifice to stay fit & healthy? (Part II)BY ALIKI BENMAYOR25 APRIL 2023DATA PROTECTION & PRIVACYHighlights of the Spanish Act on Data Protection in the Area of Police and Criminal Justice (Organic Law 7/2021)BY KATHERINE QUEZADA15 JUNE 2021SECURITY & CRIMEECJ, the floor is yours! The never ending story between Data Retention and Right to PrivacyBY LAW CITIP28 MARCH 2019DATA PROTECTION & PRIVACYData, ICT services, AI, \u2026: Standardisation and Certification as the new law of everything? \u2013 The expert roundtable organised by CiTiP on 17th September 2019BY CHARLOTTE DUCUING01 OCTOBER 2019OTHERCOMMENTSABOUTRESEARCHPUBLICATIONSEVENTSUSEFUL LINKSCONTACTDESIGNED BY SMUKKEBERG.",
    "summary": "- Belgium has legalised 'ethical hacking' under a new whistleblower law, which allows the investigation of organisations for potential cybersecurity vulnerabilities without their consent.\n- The law includes four conditions that must be fulfilled for ethical hacking to be decriminalised, such as reporting any uncovered vulnerabilities to the Centre for Cyber Security Belgium, avoiding harm or illegitimate benefits, and limiting the hacking only to what is necessary and proportionate.\n- The law is seen as a step towards increasing preventive cybersecurity practices for Belgian organisations, but questions remain around its exact delineation between legal and illegal hacking, and its limitations to only apply within Belgium.",
    "hn_title": "Belgium legalises ethical hacking",
    "original_title": "Belgium legalises ethical hacking",
    "score": 427,
    "hn_content": "Belgium has passed new legislation allowing ethical hackers to test potential cybersecurity vulnerabilities in organisations, without consent, as long as they disclose their findings to the Centre for Cyber Security Belgium (CCB). However, they are obligated not to disclose any information about uncovered vulnerability to the public without CCB's approval. Critics have questioned the CCB's right to determine what makes a vulnerability disclosure appropriate, and the effect this has on public trust and security. While beneficial for improving Belgium's cybersecurity, it remains uncertain if the new law can have meaningful impact on solving cybersecurity problems on a global scale. Some commentators ask for whistleblowing laws to become standard elsewhere, which could improve the security for everyone's data.The comments section on a news post about hacking into servers reveals a variety of viewpoints on the pros and cons of ethical hacking and the new EU laws that allow it. One person points out that EU laws only apply to servers with an EU presence, while another lists cloud datacenters in Belgium. There are also examples of ethical hackers facing repercussions, including charges and equipment confiscation. Some commenters argue that companies should have proper security measures in place, while others question the ability to guarantee complete security. One commenter asserts that most attacks on websites do not do much damage, and another commenter argues that physical business security cannot guarantee complete safety.",
    "hn_summary": "- Critics question the CCB's right to control vulnerability disclosure and the impact on public trust and security.\n- Debate in the comments section shows various viewpoints, including discussion of EU laws only applying to servers with an EU presence, examples of repercussions for ethical hackers, debates over companies having proper security measures, and debates over the ability to guarantee complete security."
  },
  {
    "id": 35853148,
    "timestamp": 1683477393,
    "title": "The Prime Video microservices to monolith story",
    "url": "https://adrianco.medium.com/so-many-bad-takes-what-is-there-to-learn-from-the-prime-video-microservices-to-monolith-story-4bd0970423d4",
    "hn_url": "http://news.ycombinator.com/item?id=35853148",
    "content": "adrian cockcroftMay 6\u00b74 min readSo many bad takes \u2014 What is there to learn from the Prime Video microservices to monolith storyExcerpt from Serverless First deck first published in 2019The Prime Video team published this story: Scaling up the audio/video monitoring service and reducing costs by 90%, and the internet piled in with opinions and bad takes, mostly missing the point. What the team did follows the advice I\u2019ve been giving for years (here\u2019s a video from 2019):\u201cWhere needed, optimize serverless applications by also building services using containers to solve for lower startup latency, long running compute jobs, and predictable high traffic\u201dThe Prime Video team had followed a path I call Serverless First, where the first try at building something is put together with Step Functions and Lambda calls. They state in the blog that this was quick to build, which is the point. When you are exploring how to construct something, building a prototype in a few days or weeks is a good approach. Then they tried to scale it to cope with high traffic and discovered that some of the state transitions in their step functions were too frequent, and they had some overly chatty calls between AWS lambda functions and S3. They were able to re-use most of their working code by combining it into a single long running microservice that is horizontally scaled using ECS, and which is invoked via a lambda function. This is only one of many microservices that make up the Prime Video application. The problem is that they called this refactoring a microservice to monolith transition, when it\u2019s clearly a microservice refactoring step, and is exactly what I recommend people do in my talks about Serverless First. I don\u2019t advocate \u201cServerless Only\u201d, and I recommended that if you need sustained high traffic, low latency and higher efficiency, then you should re-implement your rapid prototype as a continuously running autoscaled container, as part of a larger serverless event driven architecture, which is what they did. If you built it as a microservice to start with, it would probably take longer (especially as you have to make lots of decisions about how to build and run it), and be less able to iterate as you figure out exactly what you are trying to build.Excerpt from Serverless First deck published in 2019In contrast to commentary along the lines that Amazon got it wrong, the team followed what I consider to be the best practice. The result isn\u2019t a monolith, but there seems to be a popular trigger meme nowadays about microservices being over-sold, and a return to monoliths. There is some truth to that, as I do think microservices were over sold as the answer to everything, and I think this may have arisen from vendors who wanted to sell Kubernetes with a simple marketing message that enterprises needed to modernize by using Kubernetes to do cloud native microservices for everything. What we are seeing is a backlash to that messaging, and a realization that the complexity of Kubernetes has a cost, which you don\u2019t need unless you are running at scale with a large team. Ironically, many enterprise workloads are intermittent and small scale and very good candidates for a serverless first approach using Step Functions and Lambda. See The Value Flywheel Effect book for more on serverless first, and read Sam Newman\u2019s Building Microservices: Desiging Fine-Grained Systems book to get the best practices on when and how to use the techniques to effectively build, manage and operate this way. His first edition in 2015 was foundational, and he updated it in 2021 with a second edition. He is also clear about when microservices aren\u2019t useful.Finally, what were they building? A real-time user experience analytics engine for live video, that looked at all users rather than a subsample. This is a very good thing to have, in fact Netflix built in monitoring for all users at the start of it\u2019s streaming launch in 2007, and it was the very first workload that moved to AWS in 2009. Now that Netflix has also added live broadcasts, I assume they\u2019ve extended their own capabilities to do something similar to what Prime Video describes. If you happen to be running a video streaming service and don\u2019t have real time user experience monitoring built in to your architecture, I suggest you take a look at Datazoom.io which provides this as a service and where the chief architect and CTO are both ex-Netflix colleagues of mine. So maybe the answer to the question of whether to build with microservices or a monolith is neither, you should be calling an existing service rather than rolling your own.",
    "summary": "- The Prime Video team scaled up their audio/video monitoring service and reduced costs by 90%, with a combination of serverless and container solutions. \n- They followed a Serverless First approach, building a quick prototype with Step Functions and Lambda, then refactored it into a long-running microservice. \n- The team's process was not a monolith transition, but a microservice refactoring step, and it's a best practice for high-traffic, low-latency workloads.",
    "hn_title": "The Prime Video microservices to monolith story",
    "original_title": "The Prime Video microservices to monolith story",
    "score": 422,
    "hn_content": "The article discusses the Prime Video team's move from lambda to container microservices. It highlights the importance of not getting caught up in flashy tech stacks and instead focusing on practical, maintainable architecture. The article also touches on the role of Amazon's promotional culture in driving complexity. The comments section features a debate on the merits of microservices and their scalability. Some argue that the team could have saved time and money had they started with a plain service rather than microservices. There are also discussions on the importance of estimating serverless resources and predicting performance. Overall, the article provides insight into the challenges and debates around creating architecture for modern tech environments.Amazon's Prime Video team recently refactored parts of its architecture from microservices to a monolith, although critics have argued Amazon was using the term \"microservices\" too loosely in describing its original architecture. While some took the move as an argument against the microservices architecture model, others argued that both microservices and monolith architectures have their strengths and weaknesses and there is no one-size-fits-all approach to application design. The debate has also covered the appropriateness of different tools, such as the AWS Lambda serverless compute service, in different contexts and applications. The article highlights the importance of understanding the trade-offs involved in different design decisions and becoming educated about the pitfalls associated with certain architectural approaches.The debate over monolithic vs microservices is still ongoing, with both strategies having their own tradeoffs. However, the desire to move forward is about finding the right tool for a given task and unlocking new capabilities. Many believe that microservices come with bigger tradeoffs and consequences than a regular application design, but native AWS cloud applications are built by combining various AWS services, using Lambda as the glue in between them. The conversation should focus on the engineering aspect and keeping things separated, rather than polarizing the discussion on monolith vs microservices. Serverless first is not always the best approach, and it should be used where advantages are actually useful. The cost of serverless is beyond expensive and can lead to poor architectural decisions to work around runtime limitations.The article is a discussion thread about the pros and cons of serverless computing. The comments cover a range of topics, including spaghetti code, cold boot performance, infinite concurrency, lock-in, infrastructure as code overhead, and runtime and execution time limits, among others. There is debate about whether platforms like Cloud Run or Fargate fall under the category of serverless, and opinions about the cost-effectiveness and ease of use of serverless computing compared to traditional hosting paradigms like k8s. Some commenters argue that k8s is not as difficult to learn as advertised, while others highlight the importance of storage, load balancing, networking, and other considerations beyond just managing the cluster.Kubelets' persistent volume storage can be problematic, requiring pods to remain on a specific kubelet, which can make the application vulnerable to data loss. Stateful pod draining logic can be used to move pods to different kubelets, but this can be complicated. Managed stateful solutions are a simpler solution. Kubernetes is not complicated by itself, but integrating it with other cloud-native projects can be. Kubernetes was designed with the assumption that it is surrounded by a feature-rich IaaS platform, providing load balancers, VM auto-scaling pools, iSCSI volumes, and non-throughput-bottlenecked object storage. Managed Kubernetes offerings like Anthos are intriguing as they provide Kubernetes with the required features and infrastructure with minimal hassle. Running everything on a few stacks, choosing PostgreSQL, and running it on k8s is a great solution. PHP might not be a good option as it is less performant than a JVM solution and will not succeed in every use case. Kotlin has supplanted Java in popularity and utility, and it allows for easier adoption for those coming from a dynamic language background.The article discusses the use of 'serverless' solutions and Kubernetes in managing app environments. The debate over the superiority of these tools is often driven by personal experience. Serverless technology offers an efficient solution for background tasks, while Kubernetes is thought to be more effective in handling apps depending on the use case. However, Kubernetes has a steeper learning curve compared to serverless while serverless is prone to some performance issues depending on requirements. Ultimately, the choice depends on a team's preference and experience.The thread discusses the use of serverless architecture, with some arguing that it is a good choice for certain applications and others arguing against it.\n\nKey points:\n- Serverless is successful for some applications and can allow for fast market entry and feature development.\n- However, it may not be the best choice for all applications and can create complex microservice architectures.\n- Stateless and event-driven architecture are touted as benefits, but some argue that they may not be as modular or easy to reason about as claimed.\n- The discussion raises questions about the tradeoffs of different architectural choices and the importance of considering specific use cases.A software developer provides personal experience with Beanstalk, a \"serverless\" deployment platform, which is still suitable for certain purposes. The adoption of Kubernetes (k8s) has changed the landscape, providing more portability, though the effort involved in adopting k8s may not be worthwhile for small teams. Using a \"solid choice\" stack, like Beanstalk or k8s, may not make sense for every purpose and should be evaluated on a project-by-project basis. It is possible to migrate from Beanstalk to k8s later if necessary. One developer shared their experience migrating from Cloudflare to Cloudflare Workers and advocated for the adoption of state-while-revalidate support. There is no one-size-fits-all solution when it comes to infrastructure choices, and each project must be evaluated in context.The post argues about the practicality of using containers and Kubernetes compared to serverless in terms of time and cost for an MVP. The comment section debates the advantages and disadvantages of each approach, including issues related to vendor lock-in and migration costs. There are also discussions about the usage of various technologies such as Heroku, JVM, Postgres, and SparkSQL in the context of serverless and data science work. Some comments express support for the \"standardize on boring tech\" approach, while others defend the use of serverless for cost savings and productivity.Experts discuss the use of Kubernetes in modern architecture, with some arguing that it is overcomplicated, while others find it to be a simple solution to common problems. The debate also touches on the benefits and drawbacks of serverless technology. Some point out issues with using relational databases in modern web applications. A large-scale migration to Kubernetes is discussed, along with the potential for vendor lock-in and organizational complexity. Overall, the discussion highlights the importance of understanding user needs and having a smooth sales process as key factors in achieving a competitive advantage, rather than simply relying on technology choices.",
    "hn_summary": "- There is a debate on the merits of microservices vs plain service and the importance of estimating serverless resources.\n- The comments cover topics such as the appropriateness of different tools, tradeoffs in different design decisions, and the importance of evaluating specific use cases."
  },
  {
    "id": 35849043,
    "timestamp": 1683446899,
    "title": "EU sends Apple stark warning over USB-C charging on new iPhones",
    "url": "https://www.techradar.com/news/apple-may-not-restrict-usb-c-charging-on-new-iphones-after-all",
    "hn_url": "http://news.ycombinator.com/item?id=35849043",
    "content": "Home News Mobile PhonesEU sends Apple stark warning over USB-C charging on new iPhonesBy Axel Metz published 3 days agoBad news for Apple, good news for you(opens in new tab)(opens in new tab)(opens in new tab)(opens in new tab)(Image credit: Apple)We\u2019re all but certain that Apple will be equipping the iPhone 15 and its siblings with USB-C charging ports come September, and a new European Union (EU) directive suggests the company will be forced to level the playing field when it comes to charging speeds. The tech giant is reportedly planning to implement MFi (\u2018Made for iPhone\u2019) certification on its range of USB-C accessories, which had led many \u2013 including us \u2013 to speculate that these Apple-produced chargers would enable faster charging speeds on the iPhone 15 than third-party chargers from other manufacturers. The EU, however, has warned Apple against imposing such limitations. According to Germany newspaper Die Zeit(opens in new tab), EU Industry Commissioner Thierry Breton has told the company that it will prevent iPhones from being sold in member countries (such as France, Germany and Spain) if it attempts to skirt around the EU\u2019s new USB-C charging policy.\u201cDevices that do not meet the requirements for the uniform charger are not approved on the EU market,\u201d Breton reportedly wrote in a letter to Apple, having already reminded the company of the new rules in March.RECOMMENDED VIDEOS FOR YOU...Owing to the significant amounts of electronic waste caused by unused chargers and the inconvenience suffered by Android and iPhone users who need different cables for different devices, European policymakers have been keen to implement a single mobile charging standard for more than a decade.Apple must add USB-C charging to all new iPhones sold in EU countries from 2024 (Image credit: Shutterstock / charnsitr)The EU finalized its common charger regulation in October 2022, with companies \u2013 including Apple \u2013 expected to include universal USB-C charging ports on all new technology products sold in EU countries from the end of 2024. As such, there\u2019s no legal obligation for Apple to follow the rules before that date, meaning the iPhone 15 line \u2013 and possibly even the iPhone 16 line \u2013 may still arrive with charging ports optimized for Apple-produced accessories. That sounds like good news, but since Apple no longer includes chargers in the box with iPhone purchases, you\u2019d almost certainly have to fork out extra cash for one of the company\u2019s proprietary charging accessories if you want to get the most from your iPhone 15. To be clear: if Apple does decide to go its own way until 2024, you\u2019ll still be able to use third-party USB-C chargers to power your iPhone 15, but these accessories won\u2019t work their magic quite as quickly as comparable first-party chargers bought directly from Apple.That said, it wouldn\u2019t be a great look for Apple to knowingly circumvent legislation that it knows is coming into effect in the near future, so we\u2019re expecting the company to swallow its pride \u2013 or rather, tone down its desire for profit \u2013 with the iPhone 15 line. We\u2019ll be keeping abreast of all the latest iPhone 15 news, rumors and leaks as and when they surface, so stay tuned to TechRadar for the most up-to-date info on what's likely to be 2023\u2019s hottest smartphone launch.TechRadar NewsletterSign up to receive daily breaking news, reviews, opinion, analysis, deals and more from the world of tech.Contact me with news and offers from other Future brandsReceive email from us on behalf of our trusted partners or sponsorsBy submitting your information you agree to the Terms & Conditions(opens in new tab)and Privacy Policy(opens in new tab)and are aged 16 or over.Axel MetzStaff WriterAxel is a London-based staff writer at TechRadar, reporting on everything from the newest movies to latest Apple developments as part of the site's daily news output. Having previously written for publications including Esquire and FourFourTwo, Axel is well-versed in the applications of technology beyond the desktop, and his coverage extends from general reporting and analysis to in-depth interviews and opinion. Axel studied for a degree in English Literature at the University of Warwick before joining TechRadar in 2020, where he then earned an NCTJ qualification as part of the company\u2019s inaugural digital training scheme. SEE MORE MOBILE PHONES NEWSMORE ABOUT MOBILE PHONESLeaked Samsung Galaxy Z Flip 5 case images show off its updated designGoogle IO 2023 \u2013 the 7 biggest reveals to expectLATESTRumored ultra-wide RF-S lens is what Canon APS-C cameras badly needSEE MORE LATEST \u25baMOST POPULARThis might be the most secure browser in the world - but also the leastBy Mike MooreMay 06, 2023Microsoft could be planning to let widgets loose on the Windows 11 desktopBy Darren AllanMay 06, 2023Quordle today - hints and answers for Saturday, May 6 (game #467)By Marc McLarenMay 06, 2023This $12 gadget can convert your old SSD into a portable SSD in 10 secondsBy Desire AthowMay 06, 2023Gmail caught mixing ads with regular emails, annoying many on the internetBy Cesar CadenasMay 05, 2023Getting a new 15-inch MacBook Air after WWDC will be much easier this time aroundBy Oliver HaslamMay 05, 2023Google Bard podr\u00eda llegar pronto a tu tel\u00e9fono PixelBy Alexa HernandezMay 05, 2023AMD could relaunch these ultra-budget CPUs and give your wallet a breakBy Allisa JamesMay 05, 2023Google Home app gets new secret features \u2013 here's how to try themBy Cesar CadenasMay 05, 2023This ransomware gang used the emergency broadcast system to tell university students they've been attackedBy Sead Fadilpa\u0161i\u0107May 05, 2023The next Galaxy Z foldable might actually look like a ZBy Michael AllisonMay 05, 2023",
    "summary": "- From 2024, all new technology products sold in EU countries must include universal USB-C charging ports as per EU's regulation.\n- EU has warned Apple against imposing limitations through MFi certification on its USB-C accessories that may enable faster charging speeds on iPhones than third-party chargers.\n- Apple will face a ban on selling iPhones in EU member countries, such as France, Germany, and Spain, if it attempts to skirt around the EU's new USB-C charging policy.",
    "hn_title": "EU sends Apple stark warning over USB-C charging on new iPhones",
    "original_title": "EU sends Apple stark warning over USB-C charging on new iPhones",
    "score": 363,
    "hn_content": "The EU has warned Apple to adhere to USB-C charging for its new iPhones, but concerns have been raised about the longevity of this standard. The law mandates that the standard be reviewed every few years to consider whether it remains the best choice, or if technological progress justifies switching to a newer standard. Arguments have been made that regulatory stances, such as the one the EU has taken, can discourage research for a better cable as huge regulatory bodies may block its adoption. However, such regulatory stances can also reduce electronics waste as they encourage standardisation, which could even motivate companies to innovate and find better ways to improve the standard.The article discusses the issue of e-waste caused by incompatible charging cables. While some argue that companies are not incentivized to produce incompatible cables, others point out that it is easier to design a device with arbitrary input voltage and max power. The EU has mandated a single charger/cable standard, starting with micro-USB, which has reduced waste. However, there are concerns about innovation stifling if new standards are not allowed. The article highlights how the industry needs to work together to design the new version in the open, with a focus on consumer benefit. Overall, the article emphasizes the need for a balance between standardization to reduce waste and incentivizing innovation.The EU has made the decision to regulate USB-C cables, citing a lack of progress in both standardization and technical improvement. USB-C cables from nine years ago likely do not support current standards for power delivery and data transfer. Despite this, USB-C is already very flexible and capable of negotiating what will go over the pins. The EU previously mandated that phones use USB for charging, resulting in the adoption of Micro USB and USB-C, improvements for consumers and the environment. Some argue that the lack of regulation on USB-C innovation promotes the development of technology to be shared for the benefit of everyone, rather than vendor lock-in. There is a consensus that a new plug is not urgently needed, and that backward compatibility should be encouraged to use current equipment. There is some debate on whether the EU regulating technology drives innovation from companies and entrepreneurs to regulators.New EU regulation mandates the use of USB-C charging ports on electronic devices, with the aim of reducing electronic waste and increasing interoperability. Many commenters debate the effectiveness and impact of the regulation, discussing the benefits and limitations of USB-C versus other charging ports, the potential for innovation, and concerns about bureaucratic overreach and compatibility issues. Some criticize the impact on Apple users who will need to switch from their proprietary Lightning ports to USB-C. One commenter points out that Magsafe 3 will use USB-C on the other end and deliver up to 240 watts, and Apple could conceivably patent and popularize this technology if they chose.The EU has updated their law to enforce USB-C as a standardized power input for electronic devices. Apple's Lightning connector would not have been released if micro-USB had been mandated in the same way USB-C is now. Lightning is capable of faster data transfer speeds but probably not worth the cost to put that in Apple's phones when basically nobody transfers data on their phone using a cable. There is no need to worry about being stuck to USB-C because regulations can be updated regularly. Standardization is good for everyone, even when standards are old and outdated. It turns existing solutions into widespread commodities and the EU follows industry standards set by the USB-IF. The goal is to have an industry-wide discussion on adopting new standards for everyone and not to inhibit the existence of other power delivery options for customers with special needs.The post discusses the EU's mandate to standardize chargers, specifically USB-C, to reduce e-waste and improve convenience. Some commenters criticize the method as authoritarian or a threat to competition, while others argue that following public standards is fair and will benefit the environment. The debate also touches on the longevity of various connector types, the role of companies in shaping standards, and the downsides and benefits of government regulations. Overall, the post highlights the tension between market forces, environmental concerns, and government oversight in the technology industry.The EU has now mandated that all smartphone manufacturers must include a USB-C port on their devices. This will help to standardize charging across devices and reduce electronic waste. However, there are some limitations to USB-C, including a power limit of 100W and a data transfer limit of 40Gbps. The law is similar to a previous Memorandum of Understanding (MoU) that asked manufacturers to use Micro-USB ports. The USB-C law is a real law that cannot be ignored and will need to be updated when new ports, such as USB-D, are released. While there may be some resistance to the idea of government regulation, the goal is to encourage standardization for the benefit of consumers and the environment.The topic of discussion is the EU mandate for USB-C, and commenters debate the impact the regulation will have on innovation. Some highlight the potential for entrepreneurs to create and market new charging cables, while others argue that USB-C has overwhelming advantages. The conversation touches on the role of the EU, the differences in attitudes towards business between the US and Europe, and the potential for unintended consequences of regulation. Overall, commenters express a range of opinions on the regulation and its potential impact, but there is agreement that consumers will have to adjust to the new standard.- Apple users discuss the benefits and drawbacks of different types of charging ports, including Adaptive Charging and Magsafe.\n- Some commenters express concern over the potential lack of innovation and increased costs associated with standardizing charging ports.\n- The EU's mandate to standardize charging ports is a topic of discussion, with some expressing support for the regulation and others questioning the government's involvement in tech decisions.\n- Commenters debate the potential for a new, better plug to replace USB-C in the future.",
    "hn_summary": "- There are concerns about the potential stifling of innovation with a standard port, but also benefits of standardization.\n- Commenters debate the impact of regulation on innovation and the role of government in tech decisions."
  },
  {
    "id": 35849384,
    "timestamp": 1683449981,
    "title": "Burnout",
    "url": "https://drewdevault.com/2023/05/01/2023-05-01-Burnout.html",
    "hn_url": "http://news.ycombinator.com/item?id=35849384",
    "content": "It kind of crept up on me. One day, sitting at my workstation, I stopped typing, stared blankly at the screen for a few seconds, and a switch flipped in my head.On the night of New Year\u2019s Eve, my backpack was stolen from me on the train from Berlin to Amsterdam, and with it about $2000 worth of equipment, clothes, and so on. A portent for the year that was to come. I generally keep my private and public lives carefully separated, but perhaps I will offer you a peek behind the curtain today.It seems like every week or two this year, another crisis presented itself, each manageable in isolation. Some were independent events, others snowballed as the same problems escalated. Gossip at the hackerspace, my personal life put on display and mocked. A difficult break-up in February, followed by a close friend facing their own relationship\u2019s hurtful end. Another close friend \u2013 old, grave problems, once forgotten, remembered, and found to still be causing harm. Yet another friend, struggling to deal with depression and emotional abuse at the hands of their partner. Another friendship still: lost, perhaps someday to be found again.Dependable Drew, an ear to listen, a shoulder to cry on, always knowing the right words to say, ready to help and proud to be there for his friends. Friends who, amidst these crises, are struggling to be there for him.These events, set over the background of a world on fire.One of the more difficult crises in my purview reached its crescendo one week ago, culminating in death. A selfish end for a selfish person, a person who had hurt people I love; a final, cruel cut to the wounds we were trying to heal.I took time for myself throughout these endless weeks, looked after myself as best I could, and allowed my productivity to wane as necessary, unburdened by guilt in so doing. I marched on when I had the energy to, and made many achievements I\u2019m proud of.Something changed this week. I have often remarked that when you\u2019re staring down a hard problem, one which might take years or even decades to finish, that you have two choices: give up or get to work. The years are going to pass either way. I am used to finding myself at the base of a mountain, picking up my shovel, and getting started. Equipped with this mindset, I have patiently ground down more than one mountain in my time. But this week, for the first time in my life, as I gazed upon that mountain, I felt intimidated.I\u2019m not sure what the purpose of this blog post is. Perhaps I\u2019m sharing an experience that others might be able to relate to. Perhaps it\u2019s healing in some way. Maybe it\u2019s just indulgent.I\u2019m going to take the time I need to rest. I enjoy the company of wonderful colleagues at SourceHut, who have been happy to pick up some of the slack. I have established a formal group of maintainers for Hare and given them my blessing to work without seeking my approval. My projects will remain healthy as I take a leave. See you soon.",
    "summary": "- The author discusses experiencing burnout, which is when someone becomes mentally, emotionally, and physically exhausted due to stress and overwork.\n- The author shares personal struggles, including the loss of a backpack with valuable possessions and experiencing multiple crises with friends and in the world.\n- The author takes time off and delegates responsibilities to others to focus on rest and recovery.",
    "hn_title": "Burnout",
    "original_title": "Burnout",
    "score": 281,
    "hn_content": "A thread on Hacker News discusses the concept of mental energy and how it affects productivity. The discussion explores how various activities, such as work, physical activity, and socializing, can either drain or fill one\u2019s \u201cmental energy meter.\u201d Physical illness is recognized as a significant factor in negatively impacting mental energy levels. Burnout is also discussed, with contributors expressing their experiences of non-work-related burnout, such as from parenting, and the factors that lead to burnout in a corporate environment, including constant pressure, arbitrary deadlines, and interruptions. Value-mismatch problems are highlighted as being the root cause of burnout, as opposed to simply working long hours. The thread also includes links to resources related to chronic illness and burnout. The discussion emphasizes the importance of understanding mental energy and making self-care a priority.The post discusses the author's experience with work burnout and recovery, as well as the experiences of other commenters. Many recount extended periods of time off, therapy, and lifestyle changes required to recover. Some offer advice on how to avoid burnout and maintain mental health and boundaries. One commenter notes that burnout can be a non-reversible event, but that it can be integrated into a person's life and become a powerful part of their being. Some recommend finding deeper purpose and motivation to maintain work-life balance, while others emphasize the need to prioritize personal boundaries and enforce them.The post discusses burnout and the expectations of productivity in the workplace. People share their experiences with burnout and their interactions with management, with some feeling unsupported and others finding accommodating employers. The conversation also touches on the fixation on productivity and the building of identity around it and the need to prioritize self-care and boundaries in order to avoid burnout.The post discusses one person's experience with burnout and how they coped with it. Some readers suggest a four-day workweek as a solution to burnout, while others argue that the cause of burnout is often related to negative social interactions at work. Some readers have quit full-time jobs to become freelancers or start their own companies to avoid burnout. Overall, the post highlights the importance of recognizing burnout and taking steps to address it before it becomes a more severe problem.- A person is struggling after quitting their job and getting divorced\n- They have been unable to find a new partner or job, and are burning through savings\n- The person feels burned out and lacks discipline, and has been abusing drugs\n- They are hesitant to take a break, unsure if it will fix underlying issues\n- Others suggest seeking counseling or taking a break to gain new perspectives and improve mental health.",
    "hn_summary": "- Burnout is explored, with root causes being value-mismatch problems and constant pressure in corporate environments.\n- Importance of understanding mental energy and prioritizing self-care and boundaries to avoid burnout is emphasized."
  },
  {
    "id": 35846726,
    "timestamp": 1683420008,
    "title": "Nintendo reportedly issues DMCA takedown for Switch homebrew projects",
    "url": "https://gbatemp.net/threads/nintendo-reportedly-issues-dmca-takedown-for-switch-homebrew-projects-skyline-switch-emulator-development-ceased.632406/",
    "hn_url": "http://news.ycombinator.com/item?id=35846726",
    "content": "Front-pageNintendo reportedly issues DMCA takedown for Switch homebrew projects, Skyline Switch emulator development ceasedWritten byKrista Noren (Chary)Chief EditorMay 6, 2023 at 7:22 PM13,562 165 13Some fallout from the early leak of The Legend of Zelda: Tears of the Kingdom appears to be taking place. As players are loading the game into emulators and playing them unofficially on their computers, prior to the launch date, Nintendo is taking action to prevent that from happening. Lockpick and Lockpick_RCM are homebrew tools that allow users to dump unique keys from their Nintendo Switch console, which are required for numerous Switch hacking-related programs, including the Ryujinx and Yuzu Switch emulators. While Lockpick has been around for years, Nintendo has reportedly decided to go after it, by issuing a DMCA takedown to the GitHub project page, igniting concern and discussion within the community.At the time of writing, Lockpick_RCM's repository is still active, it could be due to GitHub providing a grace period following a DMCA notice. Twitter user Simon Aarons was made aware of the takedown, after forking Lockpick, and allegedly receiving an email from GitHub, on behalf of Nintendo of America's legal team, who asserts that Lockpick is \"circumvention software that infringes Nintendo\u2019s intellectual property rights. Specifically, the reported repository provides Lockpick to users. The use of Lockpick with a modified Nintendo Switch console allows users to bypass Nintendo\u2019s Technological Measures for video games; specifically, Lockpick bypasses the Console TPMs to permit unauthorized access to, extraction of, and decryption of all the cryptographic keys, including product keys, contained in the Nintendo Switch. The decrypted keys facilitate copyright infringement by permitting users to play pirated versions of Nintendo\u2019s copyright-protected game software on systems without Nintendo\u2019s Console TPMs or systems on which Nintendo\u2019s Console TPMs have been disabled. Trafficking in circumvention software, such as Lockpick, violates the Digital Millennium Copyright Act of the United States (specifically, 17 U.S.C. \u00a71201), and infringes copyrights owned by Nintendo.\"Shortly after this, Skyline Emulator, a Switch emulator for Android devices, made the decision to shut down development, via a post on their Discord Server. Since you need the keys dumped from Lockpick in order to run Skyline, the team behind the emulator is concerned that it means Nintendo will target them for also violating their copyright.It is with great sadness that we bring you this news. Recently, Nintendo has issued a DMCA takedown notice against Lockpick RCM which will likely come into effect on Monday, Lockpick is a core part of legally dumping keys from the Switch. They claim that it circumvents their copy protection (TPMs) and therefore violates their copyright. We find ourselves in a position where we are potentially violating their copyright by continuing to develop our project, Skyline, by dumping keys from our own Switches.The Skyline team will be making their incomplete source code public, at the very least, and will keep the emulator's GitHub page active. Other homebrew projects are rumored to have been hit with DMCA notices as well. Ryujinx's emulator team stated that they will not be shutting down, following worries after Skyline.Reactions:Kazalber, SaulFabre, eduall and 40 othersReply",
    "summary": "- Nintendo issues DMCA takedown notice for Lockpick, a homebrew tool that allows users to dump unique keys from their Nintendo Switch console, required for numerous Switch hacking-related programs, including Switch emulators.\n- Skyline Emulator, a Switch emulator for Android devices, ceases development due to concerns about potential copyright violations from using dumped keys from Lockpick.\n- Other homebrew projects are rumored to have been hit with DMCA notices as well.",
    "hn_title": "Nintendo reportedly issues DMCA takedown for Switch homebrew projects",
    "original_title": "Nintendo reportedly issues DMCA takedown for Switch homebrew projects",
    "score": 252,
    "hn_content": "Nintendo has reportedly issued DMCA (Digital Millennium Copyright Act) takedown notices to Github for various Switch homebrew projects. Homebrew projects are created by gaming enthusiasts who modify software and hardware to make additional features for a system that were not intended by the manufacturer. Several people have criticized the DMCA, stating that there should be a clause that provides the means for people to exercise their fair-use rights. Additionally, people complained that False DMCA claims should result in severe penalties, and some proposed that before sending a notice of infringement, copyright holders must give consideration to fair use. Reverse engineering is a protected activity so long as the creator doesn't distribute a DRM circumvention device or copyrighted content. However, some circuit courts have ruled that if the EULA says \u201cno reverse-engineering,\u201d it is a violation of contract to try to reverse-engineer the software.The post discusses the use of DRM in copyrighted works and how it affects fair use rights. Some argue that if DRM is used, the work does not enter into the public domain after the limited time of copyright expires. Others argue that DRM prevents the work from ever going back to the public domain. The flaws in the DMCA system are highlighted, as companies can abuse it to stifle innovation and competition without proper checks and balances. The ease of pirating Switch games is also mentioned, leading to discussion about homebrew and the potential for running Linux or having access to a terminal on the Switch. Some users note the need for soldering to achieve this on the Switch Lite.Developers are discussing the difficulty of pairing Nintendo Switch controllers to Linux systems using Bluetooth and discussing emulators. One person suggests that Nintendo should hire these capable programmers, but another points out that Japanese companies tend to prefer cooperative individuals over talented \"wild ninja rockstars\". A few individuals recall that Sega has allowed some of their homebrew developers to work for the company, while Nintendo is known for pressuring those who 'hack' their consoles. In response, users recommend anonymity and guerrilla software distribution as a way of combating the corporate pressure from Nintendo and other big companies. Some suggest that emulator developers need to combat piracy, but others argue that they should not be responsible for the misuse of their product. Overall, the discussion revolves around the challenges and legal implications of emulator development and homebrew programming.The post discusses a user's experience playing Metroid Dread on the Nintendo Switch, seeing a streamer play the game at 4X resolution, and wishing for better hardware to run the game. Emulation is discussed, with some arguing that it is primarily used for piracy, while others believe it is a public good and the only way to play older games no longer in production. The ethics of piracy are debated, with some arguing that it harms small businesses and studios, while others point out that it can be the only way to access out-of-print games. Nintendo's hardware is criticized for being outdated, and their business model of re-releasing old games is discussed. Some argue that Nintendo should allow emulators that only play purchased games.- Discussion on piracy and its impact on the society and creators.\n- Some believe that piracy harms the financials of the creators while others believe it's necessary for preservation.\n- Availability, pricing, value proposition, regional parity, and affordability play a significant role in the piracy rate.\n- Steam and F2P have been successful in reducing piracy for games, while streaming services have done the same for movies.\n- The equation for paying or not paying for a product is quite simple: if it's good, people will pay, and if it's not, people won't.\n- Hobbyists and their reverse-engineering skills can benefit companies and grow their user base.",
    "hn_summary": "- People have criticized DMCA for not providing a clause to exercise their fair-use rights and suggested severe penalties for False DMCA claims.\n- The flaws in the DMCA system are highlighted, and companies can abuse it to stifle innovation and competition."
  },
  {
    "id": 35850044,
    "timestamp": 1683456015,
    "title": "Contrast Rebellion",
    "url": "https://contrastrebellion.com/",
    "hn_url": "http://news.ycombinator.com/item?id=35850044",
    "content": "CONTRASTREBELLIONLow-contrast font color and unreadable texts?To hell with them!LET'S START WITH THE CASUS BELLI!Tweethttps://www.awwwards.com/sites/contrast-rebellionLook at these websites. They look fabulous indeed but how good is thatif people can't read them?Look at these examples (there's an alarming number of them):NO CONTRASThttp://reederapp.com/2/#/2/features\u2022 \u2022 \u2022 \u2022 \u2022 \u2022WHY DOES READABILITY MATTER?Because a website's content isprimarily there to be read.Don't give your visitors a headache only because gray or any other low-contrast font color looked better on the design comps than black.Remember:Content\u2260IllustrationContent\u2260IllustrationWAIT, WHY ARE THERE LOW-CONTRAST SITES THEN?Because sometimes we only think about aestheticsClearly, aesthetics are important but aren't the ultimate goal of design. And often poor readability doesn't get noticed during the design process, as we are not like our users. We don't read the texts as a visitor does.When makingthe contrast ofthe text lowerand lower...designers needto think ofelderly userswith bad visionlow qualitymonitorsbad lightingand glarereading ontiny screensSO SHOULD WE DITCH AESTHETICS?Wait, contrasty dark textcan look equally good:(apart from being a blessing to users who are actuallyinterested in what you'd like to say)HIGH CONTRASThttp://37signals.com\u2022 \u2022 \u2022 \u2022 \u2022 \u2022OK-OK, BUT ISN'T IT JUST YOUR OPINION?Glad you asked.No, it's not just our opinion.W3C's Web Content Accessibility Guidelines set the minimum contrast between text and its background so that it can be read by people with moderately low vision (which is quite common).A readability experiment conducted on web pages shows the importance of sufficient contrast between the text and the background.Another experiment confirms that reading time is lower when there's high contrast between the text and the background. What's more, contrast sensitivity declines with age. Also, see more papers on readability.Connie Birdsall from Lippincott says that \"Ensuring print legibility presents a creative challenge to the design community and prompts us to re-examine what we do. It also reminds us to keep audience needs top of mind when we design.\"Usability expert Jakob Nielsen has shown many, many times that reading on the computer screen is harder than reading printed material even without making the font illegible. And mobile is worse... and many have written about why gray text is a crime here and here...SO WHAT WE'RE TRYING TO SAY IS...Let's put an end to this low-contrast, light gray nonsense and use typography for its purpose:MAKING TEXT READABLE.AGREE? LET'S CHANGE THE WORLD TOGETHER!JOIN THE REBELLION!and spread the word!TweetZolt\u00e1n G\u00f3cza / @goczazoltanUX designer in Z\u00fcrich, Switzerland. Author of UX Myths. Passionate about fine interaction design and usable, beautiful products.Richard Gazdik / @richardgazdikA peaceful interactive designer from a mostly harmless planet whose religion is simplicity, and his god is usability. He prays for a good contrast for mankind every day.\u00a9 2011 the contrast rebellion / contact",
    "summary": "- Low-contrast font colors can make website content unreadable for many users, causing headaches and difficulties in reading.\n- Web design aesthetics are important but should not sacrifice content readability; designers should consider elderly users with bad vision, low-quality monitors, bad lighting, glare, and reading on tiny screens.\n- Web Content Accessibility Guidelines set the minimum contrast between text and background, and experiments confirm that reading time is lower when there's high contrast. Let's make an end to low-contrast, light gray nonsense and prioritize typography for its purpose: making text readable.",
    "hn_title": "Contrast Rebellion",
    "original_title": "Contrast Rebellion",
    "score": 250,
    "hn_content": "A Hacker News post discusses the issue of low contrast on websites and argues for better accessibility. One commenter notes that the example website, Contrast Rebellion, has low mobile font sizes due to missing meta tags, but another argues that not all websites need to be designed for mobile. Some commenters criticize Hacker News itself for its low-contrast design, particularly for downvoted and text posts. The idea of using WCAG guidelines for website accessibility is debated, with some arguing that the current standards are flawed due to sRGB calculations.The discussion on HackerNews revolves around the readability of the website's text and design. Some users find the font size or contrast insufficient, while others do not agree and suggest it is subjective. The idea of using a slightly-off black color instead of pure black is debated, with some arguing that it is better for aesthetics and others considering it an unnecessary hindrance to readability. The discussion also touches upon the use of grayed-out or low-contrast text to indicate downvoted or flagged posts, with some arguing that it makes the site less accessible. Overall, the conversation emphasizes the challenges of design and readability on websites and the difficulty of pleasing everyone's preferences.Web design experts and users criticize low contrast text in modern web design leading to eye strain, difficulties in reading, and unwanted scrolling. The debate centers on the ideal level of contrast that designers should use between the headings, text, and background, with some arguing that more contrast is better. Meanwhile, others point out that contrast levels can vary between different displays and environments, which complicates the design process. Some suggest that a more practical solution would be to respect the \"@prefers-color-scheme\" preference for dark or light mode while others advocate for using tools like the Dark Reader extension or using browser default colors. Ultimately, the argument boils down to the balance between aesthetics and accessibility in web design.- There is a discussion on the importance of text readability in web design.\n- A new text display format called BeeLine is mentioned as a solution to poor readability.\n- The use of high contrast color choices is suggested as a straightforward solution.\n- Some readers suggest using Vantablack as a font color or higher contrast modes on devices.\n- The article receives criticism for poor mobile readability and scroll hijacking.\n- There is a broader discussion on the role of aesthetics in web design and the need for accessible design.\n- The article has not been updated since 2011, and readers note the lack of responsive design.\n- Some comments address the intersection of color and psychology in web design.",
    "hn_summary": "- Practical solutions such as respecting user preferences and using tools like Dark Reader are suggested. \n- The balance between aesthetics and accessibility in web design is discussed, emphasizing the need for accessible design."
  }
]
