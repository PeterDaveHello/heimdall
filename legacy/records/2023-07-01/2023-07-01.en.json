[
  {
    "id": 36540957,
    "timestamp": 1688153793,
    "title": "Twitter now requires an account to view tweets",
    "url": "https://techcrunch.com/2023/06/30/twitter-now-requires-an-account-to-view-tweets/",
    "hn_url": "http://news.ycombinator.com/item?id=36540957",
    "content": "twitter(opens in a new window)facebook(opens in a new window)linkedin(opens in a new window)reddit(opens in a new window)mail(opens in a new window)Copy Share LinkSocialTwitter now requires an account to view tweetsAmanda Silberling@asilbwrites / 5:35 PM UTC\u2022June 30, 2023comment CommentcameraImage Credits: Justin Sullivan / Getty ImagesIf you\u2019re not logged into your Twitter account and try to view a tweet, you\u2019ll be presented with a sign-in screen. And if you don\u2019t want to have an account on the bird app, too bad!Twitter hasn\u2019t commented on this change, and given how sloppy the platform has been since Elon Musk\u2019s takeover, it might just be a glitch. However, in a time when Twitter is struggling to grow its user base, it\u2019s possible that this is a tactic to force silent lurkers into creating an account.Like many of Twitter\u2019s recent changes, this could easily backfire. If tweets aren\u2019t publicly accessible, search engine algorithms could rank the site\u2019s content lower, meaning that fewer people would be directed to the site from Google. Also, it\u2019s just kind of annoying.Musk \u2014 who is no longer CEO of Twitter, but still deeply involved in operations \u2014 may also be motivated by a desire to prevent AI tools from searching Twitter. Musk has previously admonished Microsoft, which dropped Twitter from its advertising platform, by saying: \u201cThey trained illegally using Twitter data. Lawsuit time.\u201dAs new CEO Linda Yaccarino settles into her new role, Twitter has remained riddled with technical errors. Earlier this week, a disproportionate amount of users were notified that they had been suspended for three days due to spam. We\u2019re still not sure what happened there (and Twitter won\u2019t answer our emails), but with Musk in the C-suite, policies can change faster than you can say \u201c$44 billion,\u201d so anything\u2019s possible.More TechCrunchFidelity deepens valuation cut for Reddit and DiscordTheranos founder Elizabeth Holmes isn't headed to jail tomorrow after allAustin Russell became the youngest self-made billionaire in 2021; now he owns ForbesWhy automakers are rushing to adopt Tesla\u2019s NACS plug and what it means to driversTechCrunch DisruptSept 19-21 San Francisco, CARegister NowSign up for NewslettersSee all newsletters(opens in a new window)DailyWeek in ReviewStartups WeeklyEvent UpdatesAdvertising UpdatesTechCrunch+ AnnouncementsTechCrunch+ EventsTechCrunch+ RoundupEmailSubscribetwitter(opens in a new window)facebook(opens in a new window)linkedin(opens in a new window)reddit(opens in a new window)mail(opens in a new window)Copy Share LinkCopyTagsTwitter",
    "summary": "- Twitter now requires users to have an account in order to view tweets, meaning that if you're not logged in, you'll be prompted to sign in.\n- This change could be a tactic to try to increase Twitter's user base, but it could also backfire by potentially reducing the visibility of tweets on search engines like Google.\n- Elon Musk, who was previously CEO of Twitter but still involved in operations, may be motivated by a desire to prevent AI tools from searching Twitter.",
    "hn_title": "Twitter now requires an account to view tweets",
    "original_title": "Twitter now requires an account to view tweets",
    "score": 989,
    "hn_content": "- Twitter now requires an account to view tweets due to extreme levels of data scraping.\n- Scraping data from social media platforms, like Twitter, has become a hot topic as it is often used by AI companies to train their models.\n- Elon Musk and others argue that scraping is a form of stealing and that regulations and compensation models need to be developed.\n- There are concerns about the ethics and legality of scraping, as well as the ownership of user-generated content on social media platforms.\n- The move by Twitter to require login for viewing tweets has disrupted third-party services like Nitter, and some users are considering leaving the platform.\n- The post highlights the changing landscape of the internet, with concerns about data privacy, content curation, and centralized platforms.\n- The discussion also touches on potential solutions, such as decentralized platforms like the fediverse, where users have more control over their identity and data.- Social media platforms such as Twitter and Reddit are facing backlash from users due to changes in their policies and features.\n- Users are expressing dissatisfaction with the increasing restrictions on accessing content without logging in or creating an account.\n- The moves by these platforms to monetize their services and implement paywalls are leading users to explore alternative platforms.\n- The internet is experiencing a trend of centralized businesses trying to extract more profit from users, which is negatively impacting user experience.\n- Users are expressing nostalgia for the earlier days of the internet when content was freely accessible and not heavily monetized.\n- The dissatisfaction with current platforms is leading users to seek out decentralized and open-source alternatives for social media and forums.\n- Some popular alternatives mentioned by users include Lemmy, Fritter, and Matrix.\n- Users are hopeful that these alternatives will provide a more user-centric and less profit-oriented experience.\n- The current changes in social media platforms are seen as part of a larger trend of the internet moving towards a more monetized and controlled environment.",
    "hn_summary": "- Twitter now requires an account to view tweets due to concerns about extreme levels of data scraping from the platform.\n- Users and experts are discussing the ethics, legality, and ownership of user-generated content on social media platforms, as well as the need for regulations and compensation models.\n- The move by Twitter and other social media platforms to implement restrictions and monetize their services has led users to explore decentralized and open-source alternatives for social media and forums."
  },
  {
    "id": 36543894,
    "timestamp": 1688166925,
    "title": "Apollo is dead. Long live Apollo",
    "url": "",
    "hn_url": "http://news.ycombinator.com/item?id=36543894",
    "content": "",
    "summary": "- The post discusses the end of the Apollo project and the implications for the tech industry.\n- It highlights the significance of Apollo in space exploration and the development of new technologies.\n- The post explores the reasons for the end of the project and what it means for the future of space exploration.",
    "hn_title": "Apollo is dead. Long live Apollo",
    "original_title": "Apollo is dead. Long live Apollo",
    "score": 794,
    "hn_content": "- The popular Apollo app, used to browse Reddit, has suddenly stopped working, leaving users without a way to access the site on their phones.\n- The demise of Apollo has sparked a discussion about the changing nature of the internet and the loss of open-source, creativity, and entrepreneurial spirit that many users associate with the platform.\n- Some users have expressed disappointment and frustration with the official Reddit app, finding it to be lacking in features and usability compared to Apollo.\n- The shutdown of the app has led to a sense of loss and nostalgia among longtime Reddit users who have relied on the platform for many years.\n- Many communities and discussions on Reddit, particularly in niche interest areas, will be missed, as finding equivalent communities outside of Reddit can be challenging.\n- This situation highlights the ongoing issues with large platforms and the power dynamics between users and the companies that control these platforms.- Users of third-party Reddit apps, such as Apollo and Reddit is Fun, are experiencing issues as Reddit implements a new pricing model for its API.\n- The new pricing model has led to increased costs for developers, forcing some popular third-party apps to shut down or restrict features.\n- Some users are expressing disappointment and frustration over the loss of their preferred third-party apps, highlighting their superior user experience compared to the official Reddit app.\n- Developers of exempted apps, like Dystopia for iOS and Reddit clients on the Fediverse, have been granted exemptions from the new API pricing.\n- Alternative platforms like Lemmy and Kbin on the Fediverse are being explored by some users as replacements for Reddit.\n- Some users are considering giving up internet comment sections altogether and focusing on other activities to regain lost time.\n- The closure of Apollo and other third-party apps has prompted discussions about the future of open-source, creativity, and entrepreneurial spirit on the internet.\n- There is speculation that a new Reddit competitor or federated alternative could arise, potentially attracting users from Reddit.\n- Concerns are raised about online moderation, censorship, and the decline of niche bulletin boards and RSS-based blogs.\n- Users are discussing alternative platforms and ways to reduce engagement and addictive behavior on social media platforms.\n- The official Reddit app is being criticized by some users for its poor user experience compared to third-party apps.\n- Some users are skeptical about the feasibility of creating a new platform to compete with Reddit, citing technical and regulatory challenges.\n- Users are divided on their plans following the closure of third-party apps, with some disengaging from Reddit entirely and others exploring alternatives.",
    "hn_summary": "- The popular Apollo app, used to browse Reddit, has suddenly stopped working, leaving users without a way to access the site on their phones.\n- The shutdown of the app has led to a sense of loss and nostalgia among longtime Reddit users who have relied on the platform for many years.\n- Users of third-party Reddit apps, such as Apollo and Reddit is Fun, are experiencing issues as Reddit implements a new pricing model for its API."
  },
  {
    "id": 36533193,
    "timestamp": 1688125471,
    "title": "Terrible real estate agent photographs",
    "url": "https://terriblerealestateagentphotos.com",
    "hn_url": "http://news.ycombinator.com/item?id=36533193",
    "content": "After a couple of years Jeff began to wonder if it really was a bonsai tree.#bonsai#Property#interior design#interiors#landscape gardening#real estate#real estate agents#estate agent#Estate agents#photography27 JUN 2023285 NOTES",
    "summary": "- The post discusses terrible photographs taken by real estate agents.\n- The author wonders if a bonsai tree shown in one of the photographs is actually real.\n- The post includes hashtags related to property, interior design, landscape gardening, and real estate.",
    "hn_title": "Terrible real estate agent photographs",
    "original_title": "Terrible real estate agent photographs",
    "score": 723,
    "hn_content": "- Terrible real estate agent photographs are being featured on a blog called terriblerealestateagentphotos.com.\n- The author of the blog verifies that the photos come from real estate marketplaces and are not user-generated content.\n- One photograph features a house on fire, which actually helped in marketing the property and it got sold.\n- It is important for sellers to be honest about the condition of a property, as buyers may find out later and it can cause trust issues.\n- In some areas, houses can be sold \"as is\" without insurance, which can lead to bargains for cash buyers.\n- Insurers have strict rules regarding the condition of the property, including the levelness of the floor.\n- Some houses with fire or water damage can be sold to people who are interested in customizing and rebuilding them.\n- Real estate agents play an important role in facilitating complex, emotionally charged transactions and providing market knowledge.\n- Agents can negotiate on behalf of buyers and sellers, guide them through the process, and provide valuable insights.\n- The real estate industry, like any other, has its share of scammers and unethical practices.\n- It is important to choose a reputable and competent agent who has a strong understanding of the market and can advocate for their client's interests.\n- Real estate agents can provide value through their experience, network, and knowledge of the market.\n- The commission structure in the real estate industry can be exploitative, with brokerages taking a significant portion of the agent's fees.\n- There is a need for transparency and more fair practices in the industry.- Real estate agents are discussed in the comments section.\n- Some people find real estate agents helpful, especially when renting, while others find them lazy and useless.\n- The role of real estate agents varies depending on the market and location.\n- Agents can assist in avoiding bad decisions and provide valuable insights about properties.\n- There are mixed opinions about the value and commission rates of real estate agents.\n- Agents' value can depend on their expertise and experience.\n- Some buyers and sellers have successfully navigated the real estate process without an agent.\n- Agents can play important roles in negotiating strategies and providing local market knowledge.\n- Real estate photos can be misleading or poorly captured.\n- There are entertaining and amusing examples of bad real estate agent photographs.\n- Some agents use manipulative tactics in their photography to make rooms appear larger or more appealing.\n- The discussion also touches on other related topics, such as estate agents in the UK and the use of brokers in NYC.\n- Some commenters argue that agents provide a valuable role in facilitating deals, while others see them as unnecessary middlemen.\n- The conversation explores the challenges and quirks of the real estate industry.",
    "hn_summary": "- Terrible real estate agent photographs are being featured on a blog called terriblerealestateagentphotos.com.\n- Real estate agents play an important role in facilitating complex, emotionally charged transactions and providing market knowledge.\n- There is a need for transparency and more fair practices in the industry."
  },
  {
    "id": 36539144,
    "timestamp": 1688147055,
    "title": "Hurl 4.0.0",
    "url": "https://hurl.dev/blog/2023/06/30/announcing-hurl-4.0.0.html",
    "hn_url": "http://news.ycombinator.com/item?id=36539144",
    "content": "HomeDocsBlog GitHub Theme SearchAnnouncing Hurl 4.0.0Jun. 30, 2023The Hurl team is happy to announce Hurl 4.0.0 !Hurl is a command line tool powered by curl, that runs HTTP requests defined in a simple plain text format:GET https://example.org/api/tests/4567HTTP 200[Asserts]header \"x-foo\" contains \"bar\"certificate \"Expire-Date\" daysAfterNow > 15jsonpath \"$.status\" == \"RUNNING\"  # Check the status codejsonpath \"$.tests\" count == 25   # Check the number of itemsjsonpath \"$.id\" matches /\\d{4}/   # Check the format of the idWhat\u2019s new in this release:Improved HTML Report with Request WaterfallDetailed Error for CI/CDNew Filters: decode and xpathJSONPath ChangeCustom HTTP MethodsImproved HTML Report with Request WaterfallWe\u2019ve improved Hurl HTML report. The HTML report is pure HTML, without any JavaScript and with inlined CSS, so it\u2019s should be easy to integrate in your favorite CI/CD solution (like GitLab CI/CD or GitHub Actions for instance). Now, each run produces:a waterfall timeline: each request/response is displayed on a beautiful graph, with easy access to response timings (DNS, TCP handshake, time to first byte etc...). These timings are provided by libcurl and you can find an explanation of each indicator in the documentationa run log with request and response headers, certificate info etc...a syntax colored source file with inline errorsThe timings used to construct the requests timeline are also exposed through --json option. --json gives you a structured view of a Hurl run with errors, asserts, certificates, captures, cookies and so timings. You can even use it to produce your own report!Once you see it, you can\u2019t unsee itWhat\u2019s interesting with rich visualisation is it can reveal hidden or not obvious things. For instance, you can have this kind of gaps on some runs:After analysis, the gap between requests in this sample test is caused by a huge numbers of assertions on the HTTP response. We have, as of Hurl 4.0.0, a naive approach of asserts computation: each asserts of the same response is independent, and we parse and recompute every assert from scratch. Until we see these edge cases, we were very proud of Hurl speed (due to the combination of libcurl and Rust). Now, we know that we have to improve assert performance for the next release !Detailed Error for CI/CDWhen you\u2019ve error in some test, the analysis can be difficult because you don\u2019t have a lot of information apart of the expected values:$ hurl --test test.hurltest.hurl: Running [1/1]error: Assert failure --> test.hurl:4:0  | 4 | header \"Control-Security-Policy\" contains \"default-src 'self'\"  |  actual:  none  |  expected: contains string <default-src 'self'>  |test.hurl: Failure (1 request(s) in 128 ms)--------------------------------------------------------------------------------Executed files: 1Succeeded files: 0 (0.0%)Failed files:  1 (100.0%)Duration:    130 msWith the new --error-format option, you can opt in for a longer error description. In this mode, the response header and the response body are automatically logged:$ hurl --error-format long --test test.hurltest.hurl: Running [1/1]HTTP/2 200date: Thu, 29 Jun 2023 16:06:58 GMTcontent-type: text/htmlcontent-length: 58941last-modified: Thu, 29 Jun 2023 14:37:22 GMTetag: \"649d9722-e63d\"strict-transport-security: max-age=31536000; includeSubDomainscontent-security-policy: default-src 'self'; script-src 'self' 'unsafe-eval' 'wasm-unsafe-eval'x-frame-options: SAMEORIGINx-content-type-options: nosniffaccept-ranges: bytes<!DOCTYPE html><html lang=\"en\">  <head>    <meta charset=\"utf-8\" /><meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" /><link rel=\"apple-touch-icon\" href=\"/assets/img/hurl-icon-120.png\" />.........  </body></html>error: Assert failure --> test.hurl:4:0  | 4 | header \"Control-Security-Policy\" contains \"default-src 'self'\"  |  actual:  none  |  expected: contains string <default-src 'self'>  |test.hurl: Failure (1 request(s) in 146 ms)--------------------------------------------------------------------------------Executed files: 1Succeeded files: 0 (0.0%)Failed files:  1 (100.0%)Duration:    148 msIn this example, we can see that there is actually a Content-Security-Policy whereas we\u2019re querying a Control-Security-Policy header. The bug is now really simple to solve because the response headers and body are logged.This option is really useful in CI/CD where you want to have all the available context to debug your session, without re-running your tests. Beware that, as the body response is logged, the log can be really long.New Filters: decode and xpathTextual asserts in Hurl work by automatically decoding the response body bytes, based on the Content-Type response header. That way, if we have a Latin 1 encoded HTML or an UFT-8 encoded HTML we can write the same assert without any encoding concern:# UTF-8 encoded document:GET https://example.org/charset/utf8HTTP 200Content-Type: text/html; charset=utf-8[Asserts]body == \"<p>caf\u00e9</p>\"# Latin1 encoded document:GET https://example.org/charset/latin1HTTP 200Content-Type: text/html; charset=latin1[Asserts]body == \"<p>caf\u00e9</p>\"To decode a response from bytes to text, Hurl uses charset hint from Content-Type response header. But sometimes the Content-Type response header doesn\u2019t specify any encoding. Or the encoding is indicated inside the HTML document through <meta> tag:<!DOCTYPE html><html>  <head>    <meta http-equiv='Content-Type' content='text/html; charset=gb2312'>  </head>  <body>\u4f60\u597d\u4e16\u754c</body></html>In this case, a decode filter can now be used to explicitly decodes bytes to text and do checks:GET https://example.com/hello_gb231HTTP 200[Asserts]header \"Content-Type\" == \"text/html\"bytes contains hex,c4e3bac3cac0bde7; # \u4f60\u597d\u4e16\u754c encoded in GB2312bytes decode \"gb2312\" xpath \"string(//body)\" == \"\u4f60\u597d\u4e16\u754c\"As hinted in the previous Hurl snippet, you can now evaluate XPath expression on response part with a xpath filter.JSONPath ChangeIn Hurl 4.0.0, we\u2019ve slightly changed the evaluation of JSONPath query. There is no proper specifications for JSONPath. The de-facto one, that Hurl tries to follow as closely as possible, is still https://goessner.net/articles/JsonPath/. There are a few edge cases for which several implementations differ. For instance, standard JSONPath always returns a collection, which most of the time is not meaningful, and harder to test. Some implementations (such as the Java library https://github.com/json-path/JsonPath) also distinguish between node value (definite path) and collection (indefinite path).Basically, in Hurl 4.0.0, the only selectors returning a value are:array index selector ($.store.book[2])object key selector ($.store.bicycle.color/$.store.bicycle['color'])Other selectors, that use filters (for instance ?(@.price >= 10) or $[*].id) will return a collection. You can then use nth filter to extract a value from this collection.GET https://example.com/booksHTTP 200[Asserts]jsonpath \"$.store.book[0].title\" == \"Dune\"jsonpath \"$.store.book[*].title\" nth 0 == \"Dune\"Custom HTTP methodsHurl 4.0.0 supports now any custom HTTP method. The only constraint is to write the method in uppercase. You can right-away experiment the incoming new QUERY method:QUERY https://example.org/contactsContent-Type: example/queryAccept: text/csvHTTP 200Content-Type: text/csv```surname, givenname, emailSmith, John, john.smith@example.orgJones, Sally, sally.jones@example.comDubois, Camille, camille.dubois@example.net```OthersThere are other improvements and bug fixes, you can check a complete list in our release note. If you like Hurl, don\u2019t hesitate to give us a star on GitHub or share it on Twitter!We\u2019ll be happy to hear from you, either for enhancement requests or for sharing your success story using Hurl! RSS feedBuild rev. 3b01949Hurl\u21c4 by CCMD Team",
    "summary": "- Hurl 4.0.0 is a command line tool that allows users to run HTTP requests defined in a simple text format.\n- The new release includes improved HTML reports with a detailed request waterfall, making it easier to analyze and debug requests.\n- Additional features in Hurl 4.0.0 include new filters for decoding and XPath, changes to JSONPath evaluation, and support for custom HTTP methods.",
    "hn_title": "Hurl 4.0.0",
    "original_title": "Hurl 4.0.0",
    "score": 550,
    "hn_content": "Hacker News new | past | comments | ask | show | jobs | submit loginHurl 4.0.0 (hurl.dev)549 points by jicea 16 hours ago | hide | past | favorite | 91 commentskrat0sprakhar 15 hours ago | next [\u2013]> Hurl is a command line tool powered by curl, that runs HTTP requests defined in a simple plain text format: <code sample>This is how every new version announcement should start! I'd never heard of Hurl before and that intro + code sample on top instantly made me want to install and try it out.Congrats on what seems like a great releasereplyjicea 13 hours ago | parent | next [\u2013]Hi, maintainer of Hurl and avid reader of Hacker News for years. I've noted every advice for presentations (put a sample of your language asap, explain your concept every time succinctly, etc...). I've tried to put it in practice on hurl.dev so thank you for noticing it!replyTavsiE9s 13 hours ago | root | parent | next [\u2013]That's one of the reasons why I bookmarked it and will test it in various CI pipelines on Monday. ;-)replyrockwotj 7 hours ago | root | parent | prev | next [\u2013]Mind sharing this list? :)reply9935c101ab17a66 3 hours ago | root | parent | next [\u2013]Yes! I would love to see the list even if it\u2019s rough around the edges.replywanderingstan 13 hours ago | parent | prev | next [\u2013]Amen. Far too many announcements and readmes jump right into installation requirements and \u201cwe\u2019ve fixed X, Y and Z\u201d but never actually tell you what the thing is!replybandrami 1 hour ago | root | parent | next [\u2013]What irks me is when the project description focuses on \"Updog is written from scratch in Deactivated Typeflange\" or whatever. So many github readme's where I have a pretty good idea about why the devs chose the language and toolchain they chose but zero idea of what the project does and why I might want to use it.replyconvalescindrey 12 hours ago | root | parent | prev | next [\u2013]A changelog is supposed to tell you what has changed.A general greeting/landing page is supposed to tell you what the thing is.Trouble is if a link to a changelog is submitted to HN. Most people who don't know what the thing is click on it, have no clue what they are looking it, close it again and then downvote the submission.Submissions for not-widely-known stuff should be a landing page, not a changelog page.(In other words, this hurl page is kind of a mix between these two which is odd and arguably misusing what a changlog / news announcement page should be.)replyjicea 12 hours ago | root | parent | next [\u2013]We've a more \"classic\" changelog in GitHub [1], I see the blog post as an editorial view of the changelog: highlights of main features/changes with some context.[1] https://github.com/Orange-OpenSource/hurl/releases/tag/4.0.0replyphist_mcgee 8 hours ago | root | parent | prev | next [\u2013]My favourite is landing on a github repo for a project and reads like the following:  Schmaggle is the new hyperlayer to solve excess Flingles when re-routing Blumbles in non-zero p=np equations.  Please open a PR if you're interested.Or something to that effect.replyjpalomaki 3 hours ago | root | parent | prev | next [\u2013]Happy to notice the \"Locate the logo on top left corner and click\" works in this case! I'm immediately forward to a page that provides exactly what I need.replyShadowBanThis01 10 hours ago | parent | prev | next [\u2013]True, except most of that should have been in the title of the post. Such as:Hurl: Run HTTP requests in a simple plain-text formatreplysmarkov 15 hours ago | prev | next [\u2013]Please make this the industry standard for testing APIs.I'm tired of having to look at Postman screenshots sent from QA. I'm tired of having to wait for them to press Send once I've implemented a fix. I know they're tired of waiting for me to do that, too. Hurl is something both the devs and QA can speak and write. It can be automated and a part of CI. It makes communicating expectations straightforward. It can be chucked along with PRs as a starting point for QA. I don't see a reason not to use it wherever possible.replydigikata 15 hours ago | parent | next [\u2013]I have been using it for API testing manual and in CI of one of our services and it's been very nice. You can basically put a series of http exchanges for a workflow per hurl file and get a nice test suite that also checks directly into git.replyvidyesh 14 hours ago | parent | prev | next [\u2013]For a team using VSCode you can try the vscode-restclient[1]But really Hurl looks really interesting, being editor agnostic is the best solution for your problem, I agree.[1] https://github.com/Huachao/vscode-restclientreplykxrm 13 hours ago | root | parent | next [\u2013]I use the vscode-restclient and my primary reason is the conversational flows you can build against an API. Does Hurl support this? If so I would absolutely switch. All I would need to complete the experience is a plugin to do highlighting and integration with the Hurl files.replysteve_adams_86 13 hours ago | root | parent | next [\u2013]digikata\u2019s comment above suggests it is possible. It would be great to have something that isn\u2019t attached to the editor of choice.replykxrm 11 hours ago | root | parent | next [\u2013]Indeed it does with https://hurl.dev/docs/capturing-response.htmlAlso for VS Code integration specifically there is https://marketplace.visualstudio.com/items?itemName=JacobPfe...replyjicea 14 hours ago | parent | prev | next [\u2013]Hi maintainer here! Thanks a lot for the kind words!replyconvalescindrey 12 hours ago | root | parent | next [\u2013]Great project!A comment I'd have is that it's quite hard to find out who authored this fine piece of software.replyimiric 11 hours ago | parent | prev | next [\u2013]Have you tried https://k6.io/ ? (Full disclosure: I'm one of the maintainers.)It allows you to write load/performance tests in JS, commit them to your repo, easily automate them in CI, send metrics to several backends, use protocols besides HTTP, with a modern CLI, and many more features.There's also a Postman-to-k6 converter[1]. The conversion might not be perfect, but it will give you a head start.Note that the k6 philosophy is for developers to write these tests, similarly to how you write unit/integration tests, and to break the classic QA-dev cycle.I don't want to steal Hurl's thunder, it does look great, but it's limited in features compared to existing peformance testing tools, and I'd personally rather write tests in a programming language, than in a bespoke text format.[1]: https://github.com/apideck-libraries/postman-to-k6replyFridgeSeal 2 hours ago | root | parent | next [\u2013]> but it's limited in features compared to existing peformance testing tools, and I'd personally rather write tests in a programming language, than in a bespoke text format.I\u2019d hardly call hurl\u2019s config bespoke, it basically amounts to HTTP codes and some header stuff, which basically everyone is familiar with.From personal experience a couple of weeks ago I needed some http tests. I got a CI-ready Hurl config working on some endpoints for work sorted within like, 5 minutes of downloading it. In comparison I opened the page for K6, saw the \u201cwrite tests using JS\u201d and basically noped out immediately,replyimiric 30 minutes ago | root | parent | next [\u2013]That's fair, and k6 is not for everyone. JS was chosen as it's a popular language with a large web ecosystem, but the tool itself is written in Go.That said...> I got a CI-ready Hurl config working on some endpoints for work sorted within like, 5 minutes of downloading it.I'm obviously biased, but I'd argue that k6 is equally easy to get started with. Take a look at the docs[1].> I\u2019d hardly call hurl\u2019s config bespokeBut it is. It has a unique syntax, and no other tool uses it, AFAIK. I'm not saying it's not simple or easy to understand, but it's not as expressive as a programming language. Which is fine if your tests don't require any logic, but from experience, in order to simulate accurate real-world traffic, which you probably want when writing a load/performance test, you do need some logic, different scheduling options, a way to process and analyze the metrics, etc.I don't want to turn this into a versus battle, as there is a place for tools such as Hurl, ab, and wrk to coexist with tools like k6 and Locust. I just wanted to mention it as an option for anyone who hasn't heard about it, as any personal biases aside, I do think it's a great tool.[1]: https://k6.io/docs/replygavinray 10 hours ago | root | parent | prev | next [\u2013]If you maintain k6, can I log a complaint?I feel like I used to be able to run the CLI with just an URL and it would issue GET requests to it -- without needing a .js script to runAm I crazy, did this never exist? Please bring back/add this featurereplyimiric 52 minutes ago | root | parent | next [\u2013]I think you're mistaking k6 for another tool. k6 has only supported writing tests in JS. There are several other tools that are better suited for this single URL use case: ab, wrk, even Hurl. I doubt this will ever be supported in k6, since the focus is on scripting test logic, not firing off requests to a single URL (though this is certainly possible with a simple script).replycmgriffing 13 hours ago | parent | prev | next [\u2013]I personally like the approach of defining things via an OpenAPI and then using Dredd to validate the spec against itself.Even for tools that generate the spec from source code, it is usually still possible for user error to define the metadata for an endpoint incorrectly. Dredd catches that.replyTheBigRoomXXL 12 hours ago | root | parent | next [\u2013]I also think that validating an API against it's OpenAPI schema is a great methodology. You should checkout schemathesis, it's fantastic for doing that.https://github.com/schemathesis/schemathesisreplykbenson 13 hours ago | parent | prev | next [\u2013]Not that I necessarily think it's best to stay with Postman, but have you looked at newman, which is the CLI runner for postman configs? We had postman as a test suite for something (which is more an API than an app), and I got tired of having to deal with setting up extra steps to test and of exporting the postman config to save in the repo, so I put newman on the test system and just run against the config directly in the test environment and check the output.I don't necessarily recommend editing the postman config json directly to set up new tests as it's a PITA, but it's generally what I do so I don't need to keep importing and exporting it with Postman.A tool designed for working with on the shell is likely better than what I'm doing with newman (since the config is not the most accessible), but it also meant I didn't need to rewrite a bunch of existing tests and verify they actually did the same thing.replyjug6ernaut 12 hours ago | root | parent | next [\u2013]The problem Newman/postman have is the same for every GUI based testing application. They almost always produce non human readable config files. Making any kind of code review of such changes at best extremely painful and at worst impossible.IMO any testing tool that does not save it's test classes in a human readable format is DoA.replyrecroad 12 hours ago | parent | prev | next [\u2013]The bigger problem here is that you have QA, not the lack of tooling.replydijit 12 hours ago | root | parent | next [\u2013]The bigger problem here is that you have devs, devs make bugs.if you don't have devs there are no bugs, problem solved.replybandrami 1 hour ago | root | parent | next [\u2013]When I'm not expecting guests my house is always cleanreplyconvalescindrey 12 hours ago | root | parent | prev | next [\u2013]If devs have to do QA themselves, many issues magically disappear.replydijit 12 hours ago | root | parent | next [\u2013]Honestly that sounds like making pilots build aircraft engines.these are different disciplines that deserve to be done well.Maybe I am biased because I spent the last 10 years in gamedev, or maybe this is another push to make devs do basically everything tech related: but if a developer tells me a feature is done I always look to QA for a nod.That nod rarely comes, the feature is not done, the developer merely got it to work on their machine.replyconvalescindrey 12 hours ago | root | parent | next [\u2013]Then your developer should learn that \"done\" means more than \"works on their machine\".The difference between devs and dedicated QA people is that devs know the dark corners of the implementation. They know the edge cases and scenarios that they struggled with getting right. That's where most testing focus has to be. QA doesn't know any of that. They can play through some scenarios that are the expected ones from the spec, perhaps have some hunch of what could be the tricky cases, but they don't actually know.I love seeing all those downvotes for my GP comment. That's all the people working at companies where stuff that devs feel is below them is dumped on QA people, which is the main reason my company is well-known for shipping top quality (without having a QA dept) while our competitors struggle with quality (despite having a QA dept). That's all the evidence I need to back up my claim.replyQuikinterp 11 hours ago | root | parent | next [\u2013]How big is your company and product?replyconvalescindrey 11 hours ago | root | parent | next [\u2013]Anual revenue is in the ballpark of about $1bn-$5bn.replytechnion 8 hours ago | root | parent | next [\u2013]If this happens to be a reference to Microsoft, their famous laying off of qa people has been regarded as a disaster by everyone outside Ms, with windows update quality dropping off a cliff.replydmw_ng 11 hours ago | root | parent | prev | next [\u2013]never underestimate the ingenuity of a good QA person. \"app freezes while triple-clicking About button while changing wifi network when storage is 89% full and screen reader is enabled\"it's the same with good security folk. sure you can pretend you'll catch 100% of issues, but it's a delusion, good security or quality testing is a totally different mode of thoughtreplyconvalescindrey 11 hours ago | root | parent | next [\u2013]> never underestimate the ingenuity of a good QA person. \"app freezes while triple-clicking About button while changing wifi network when storage is 89% full and screen reader is enabled\"If such feature interactions matter then your application has bigger problems than a QA department.> it's the same with good security folk. sure you can pretend you'll catch 100% of issues, but it's a delusion, good security or quality testing is a totally different mode of thoughtOh I'm not saying that good QA isn't a valuable skill! Of course it is, it doesn't just happen on its own. What I'm claiming is that it's a skill that should be employed as close as possible to the creation of the thing that it's assuring the quality of. So, ideally within the developer themselves.Same thing with security. You will have a terrible security in your product if you first design and implement it and then put security in there as an afterthought by a dedicated security team. Ideally it's been at the table from day 1. So, a good security team works on educating your devs to do things right from day 1. Just like QA.replythrowway120385 10 hours ago | root | parent | next [\u2013]> If such feature interactions matter then your application has bigger problems than a QA department.QA doesn't exist to check that your crap architecture solves the problem. They're there to be the skeptical person in the chain of custody from developer to production. The old adage \"you can't test quality into software\" exists for a reason. It's true. And you're right that it's the wrong architecture. But that's dismissing the very real purpose of QA which is to catch these kinds of bad architecture problems by testing for conditions that the dev team possibly didn't consider during development. QA is also there to make sure you're not making any unfounded assumptions about the context the software exists in.To the extent you actually care about checking all of your assumptions and not just the ones you're cognizant of, QA is very useful.replyushakov 14 hours ago | parent | prev | next [\u2013]There\u2019s also Step CI: https://stepci.com(I\u2019m one of the authors)Hurl is brilliant thoughreplyrandomsofr 11 hours ago | root | parent | next [\u2013]I was just looking at this. We might use it at my company, but i was wondering, is this funded? Or is this just an open source side project for you guys.replybityard 13 hours ago | prev | next [\u2013]This is one of the best examples of a modern Unix program I have seen:- It accepts input on stdin- It sends output to stdout- Does not appear to be littered with unicode emoji everywhere- It comes with man pages (and pretty good ones too!)- The hurl file extension is four characters long instead of three, thank goodness we're finally past MS-DOS compatibility concerns!This looks like something I might take seriously.replyEdwardDiego 12 hours ago | parent | next [\u2013]I never realised how much the emojis in my terminal annoyed me, until you mentioned this didn't have them, and I got excited.replysedatk 12 hours ago | parent | prev | next [\u2013]> thank goodness we're finally past MS-DOS compatibility concerns!and VMS!replymiki123211 13 hours ago | prev | next [\u2013]Speaking of command line HTTP handling, my favorite tool for that is Httpie[1], or rather its faster Rust rewrite, XH[2]. It lets you issue HTTP requests from the command line with much nicer, more HTTP-like syntax than CURL and without the need to learn so many switches. If you already know curl well, it probably won't be of much use, but it's far, far more intuitive for casual use.[1] https://httpie.io/ [2] https://github.com/ducaale/xhreplydebarshri 14 hours ago | prev | next [\u2013]We at Adaptive[1] extensively use hurl.dev to automate our testing. All our internal product flows are tested via hurl. It is the best thing that we have ever implemented in our org to stabilize the product. Everytime before we deploy, we run bunch of automated tests written in hurl, for onboarding, signups, critical flows etc. That are containerized and can run in parallel. We have been building internal tools around hurl.dev too.I really would recommend this tool. Nice thing is even analyst and business users can build these tests as it is fairly easy to pickup.[1] https://adaptive.livereplysedatk 12 hours ago | parent | next [\u2013]Does it support OAuth flow out of the box, or do you need hardcoded tokens for that? (I checked the docs, couldn't find anything about it)replydebarshri 12 hours ago | root | parent | next [\u2013]To my best knowledge, it does not support oauth flow out of the box. This is also where we built some custom tooling around hurl.replyklysm 12 hours ago | root | parent | next [\u2013]It seems reasonable to not support all the different auth schemes though. There are so many implementation quirks that it would be a huge burden to do that as part of the hurl projectreplymalablaster 45 minutes ago | prev | next [\u2013]Hurl looks like a game changer for me. The fact that there\u2019s a session shared within a file means as a backend dev I may be able to trivially eliminate the browser from my dev flow (without a bunch of annoying scripts). I\u2019m on vacation and can\u2019t wait to try this back at work.replyezekiel68 1 hour ago | prev | next [\u2013]Can anyone who's used hurl explain whether there are any use cases where something like Postman can do something hurl can't or can do it much better? I haven't used Postman very often previously but at work my role may change to require much more testing work (that many in the industry would have traditionally used Postman for).replyjiehong 14 hours ago | prev | next [\u2013]Great job to the team! Hurl is growing rapidly!One question if someone knows: while testing an endpoint, authentication is always needed.Having written the authentication in 1 file, how can I import this file at the beginning of every other file that requires authentication and the associated token?replybityard 14 hours ago | parent | next [\u2013]It doesn't look like Hurl has any functionality for inclusions, macros, and the like. I'm not sure those would be the best way to store and use secrets anyway. But the docs say you can pass variables into hurl files via command line args and through the environment: https://hurl.dev/docs/templates.htmlreplywraptile 3 hours ago | prev | next [\u2013]I feel like DSL is becoming obsolete these days in favor of general programming (e.g. Python). I really like Hurl but every time we use it we revert back to simple Python because something is slightly off or missing (they just added XPath support) or different and just writing up Python script is easier and more powerful. Onboarding people on Python test suite is much easier than teaching them whole DSL that they'll be using few times every month.replygossamer 15 hours ago | prev | next [\u2013]I have never wanted to hurl more than I do now. But in a good way. :-)replyklysm 12 hours ago | parent | next [\u2013]I have no idea what you are trying to sayreplyISO-morphism 11 hours ago | root | parent | next [\u2013]To hurl means to throw forcefully, and is commonly used as a synonym for vomiting, c.f. \"throw up\"replythunfisch 13 hours ago | prev | next [\u2013]Hurl and it's test cases have been awesome at our Ops team. We're managing an autogenerated config for hundreds of complex webserver rules, and we've been able to (auto-)generate hurl test cases for every single rule and test them in both CI and the actual infrastructure after deploying.It's simplicity but powerfulness is amazing!replysmartmic 13 hours ago | prev | next [\u2013]Emacs enthusiasts have https://github.com/pashky/restclient.elI see some parallels to Hurl, but having everything inside Emacs is hard to beat, just thinking about using M-x jq-interactivly for json responses ...replyrrgok 12 hours ago | prev | next [\u2013]I've been following hurl for sometime. Where it shines from others is that it has its own DSL For testing. It is not only to make http request, but to assert response and capture data. Having said that, and hoping the maintainer is reading this: please please make it such that assertion can passed to an external script. Why am I asking this? Because, an example, you cannot still assert that a property in a collection of items all have the same value (ex.: all titles should be XXX without using nth selector or make it possible to do nth = * ). And proving a DSL for all use cases is kinda huge effort. Would be great to pass the the output of jsonpath to jq for example and if that returns true, the test pass.replyklysm 12 hours ago | parent | next [\u2013]The DSL would slowly creep to a Turing complete general purpose language so I agree that invoking external scripts seems reasonable. The could be quite a can of worms though because it makes the files less hermeticreplymcpeepants 11 hours ago | root | parent | next [\u2013]> it makes the files less hermeticwhat if the script was inline in the DSL? e.g. some syntax for opening a script \u201cblock\u201d, with an annotation of the command to exec or pipe the script intoreplyklysm 4 hours ago | root | parent | next [\u2013]That seems fine but what language do you use? Lua?replyutybo 14 hours ago | prev | next [\u2013]I really like httpyac for this purpose: https://httpyac.github.ioPretty similar with JS scripting capabilities. Has great VS Code integration in addition to its CLI.replybrewmarche 11 hours ago | parent | next [\u2013]httpyac is also very compatible to .http support in JetBrains IDEs. JetBrains also offers a free CLI tool to generate jUnit test reports from .http files.replyjohntash 10 hours ago | prev | next [\u2013]hurl is great, glad to see it's being improved on. I wrote a small wrapper around it a while back to be able to re-use some auth stuff in different requests, but a simple \"include <file.hurl>\" would be an awesome addition in a future release.Getting started with it was way easier than figuring out postman or any of the many other http testing frameworks with their own languages/dslsreplyv3ss0n 4 hours ago | prev | next [\u2013]Check: https://hexmos.com/lama2/tutorials/examples.html#headersSimilar to hurl and it has built-in postman import.replyletmeinhere 13 hours ago | prev | next [\u2013]Is anybody else wary of a new grammar with no transformer available to/from anything more common (e.g. json/xml)?I did find [this][1] tree-sitter parser, so that's a start, but it seems like writing these would be a lot easier to write these if the interface was a library in a general purpose language or a subset of json.[1] https://github.com/pfeiferj/tree-sitter-hurlreplyjicea 13 hours ago | parent | next [\u2013]You can export Hurl file to JSON with hurlfmt. We've done this so you can go to another tool if you prefer and convert your tests. It may be a start. The Hurl parser is also available as a library through Rust crates.replykemotep 14 hours ago | prev | next [\u2013]At first, I thought this was the toy language Hurl[0] and was shocked the developer made it to version 4 so quickly.Really cool tool built with curl. Certainly could replace a bash script or two with something more robust.[0]: https://news.ycombinator.com/item?id=36393673replyryenus 9 hours ago | parent | next [\u2013]Turned out that one was, as you said, a totally unrelated toy language, nothing like this hurl.dev one.replydgellow 15 hours ago | prev | next [\u2013]I learned today that Visual Studio 2022 has support for something similar with .http files: https://learn.microsoft.com/en-us/aspnet/core/test/http-file....Hurl seem to have way more features.replyisanjay 15 hours ago | parent | next [\u2013]And way fasterreplybdcravens 14 hours ago | parent | prev | next [\u2013]I've used the VS Code extension this feature was based on for a while.replyhermanradtke 15 hours ago | prev | next [\u2013]Nice QoL improvements. Hurl is my go-to for any Postman-like problem. It is much easier to maintain and share hurl script then it is for me to share a Postman json blob.replyhiddew 15 hours ago | prev | next [\u2013]Never heard of this! I will definitely take a look if this can replace some handwritten bash curl-based test scripts to validate HTTP-level interactions. The combination of documentation and testing in a single text file looks promising.replybachrc 13 hours ago | prev | next [\u2013]As other people, I really think this is a great piece of software, but I didn't ser any way of reusing hurl file in anothers? For int\u00e9gration testing, this would be much more cleanerreplykristopolous 13 hours ago | prev | next [\u2013]Are there use cases beyond testing that anyone here has actually done?replymxuribe 13 hours ago | parent | next [\u2013]Actually done? No. However, one use-case that i couild think of - beyond testing - would be to modularize some dev work. For example, maybe i have a junior dev who knows some http, but not experienced enough to be a lead dev, or something like that. I could give the junior dev a task like draft up some tech spec...Or, i could have them use their basic http skills and craft Hurl files...one for each function that will inevitably be a function in code...either to be done by a more senior dev, or who knows, maybe this same junior dev could eventually learn to code based on their own hurl files...which someone else might call pseudo-code (or pseudo-code in tech docs)...which eventually gets turned into production code...and those same hurl files can also be turned into test cases.Anyway, for me, hurl looks like an evolution of curl...which makes sense since its built off of curl (https://hurl.dev/#powered-by-curl). So, for uses-cases that might reach beyond curl, that's when i might reach for hurl as well. No doubt, there could be other use-cases for hurl.replylfconsult 12 hours ago | prev | next [\u2013]I really do love this project . Using it in production for testing purposes. Great job guys.replyinsanitybit 13 hours ago | prev | next [\u2013]This is great, I love the native jsonpath support.replyisanjay 15 hours ago | prev | next [\u2013]I used it briefly and found it very fast.replyAlifatisk 15 hours ago | prev | next [\u2013]Interesting project, might try it out!replysergiotapia 13 hours ago | prev | next [\u2013]I will try to integrate this into our workflows. Hurl looks great!replyzgluck 13 hours ago | prev | next [\u2013]Feedback: The homepage (https://hurl.dev/) doesn't really make it clear - is this an interactive tool or not?If I understand it correctly, you're supposed to save that example as a file and run 'hurl example.hurl'. It would make it easier to understand if that sample code box had a headline saying e.g. [example.hurl].replymxuribe 13 hours ago | parent | next [\u2013]I'm not the author, but after reading the manual (https://hurl.dev/docs/manual.html), it seems to me that the tool can be used both ways. That being said, i think the value of this tool (beyond a tool like curl, wget, etc.) is that its likely preferable to base usage on non-interactive use, or at least leverage the tool via its .hurl files. While i actually like the succinctness of the homepage in describing this tool, you're not wrong that the author could have added an additional sentence stating the interactive or not point slightly more clearly. Even still, the documentation is much better for this tool, than other tools that i have seen. For this i'm thankful!replyjicea 13 hours ago | parent | prev | next [\u2013]Noted, I'll try to make it clearer. We\u2019ve been more explicit on the samples page [1][1] https://hurl.dev/docs/samples.htmlreplypmarreck 14 hours ago | prev | next [\u2013]This looks like a great tool to put in charge of regularly testing your site performance in a dashboard or incorporating into CI somehow.Has anyone done anything like this as, say, a Github Action, in a workflow? I see that there is this https://github.com/marketplace/actions/install-hurl-cross-pl... but I'm not sure how it would look in such a use case- a \"performance test\" stage perhaps? with logging over time to some other service?replycompumike 14 hours ago | prev [\u2013]Pretty interesting! It makes me wonder, would anyone want a hosted version that runs checks against your production API endpoints / websites periodically? We have these basic capabilities (for example, assert headers, status code) as part of Heii On-Call\u2019s HTTP outbound probes [1] but a more powerful assertion syntax might be interesting for some use cases. (Or are the basics good enough for Continuous Monitoring? And the advanced assertions more interesting for CI?)[1] https://heiioncall.com/blog/enhanced-api-monitoring-with-exp...replyGuidelines | FAQ | Lists | API | Security | Legal | Apply to YC | ContactSearch:",
    "hn_summary": "- Hurl 4.0.0 is a command line tool powered by curl, used for running HTTP requests defined in a plain text format.\n- The introduction and code sample on the website are praised for sparking interest and making users want to try it out.\n- Users appreciate the simplicity of Hurl and find it easy to use for API testing and integration testing."
  },
  {
    "id": 36530662,
    "timestamp": 1688100938,
    "title": "Anna's Archive: Open-source data library",
    "url": "https://annas-archive.org/",
    "hn_url": "http://news.ycombinator.com/item?id=36530662",
    "content": "annas-archive.orgChecking if the site connection is secureannas-archive.org needs to review the security of your connection before proceeding.Ray ID: 7dfdd3b58bb4315fPerformance & security by Cloudflare",
    "summary": "- The website \"annas-archive.org\" requires a security review before it can be accessed.\n- The security review is being conducted by Cloudflare.\n- The review is necessary to ensure the performance and security of the website.",
    "hn_title": "Anna\u2019s Archive: Open-source data library",
    "original_title": "Anna\u2019s Archive: Open-source data library",
    "score": 525,
    "hn_content": "Hacker News new | past | comments | ask | show | jobs | submit loginAnna\u2019s Archive: Open-source data library (annas-archive.org)525 points by janandonly 1 day ago | hide | past | favorite | 101 commentsdevinprater 19 hours ago | next [\u2013]This is important for blind people too, since a lot of stuff like Kindle, Apple Books and such, use DRM. That means that if I wanted to read a book on my Braille EReader, without using my phone which adds another device, another battery, and so on, I'd have to un-DRM the book. Lately though, Kindle have changed their DRM stuff so the tools used don't work anymore. So getting them from these types of sites; thankfully EPUB versions are available, is the only way I can choose what device I read my book on.It's a bit like using emulators to read text from the screen using OCR.replypilimi_anna 5 hours ago | parent | next [\u2013]This is great to hear. We've put a decent amount of time into accessibility when building the site. If you have any feedback for us on this, that'd be very helpful!replymdp2021 1 day ago | prev | next [\u2013]And the first available text isDavid K Levine; Michele Boldrin - Against Intellectual Monopoly (2008)> So-called intellectual property is in fact an \"intellectual monopoly\" that hinders rather than helps the competitive free market regime that has delivered wealth and innovation to our doorstepsreplydefrost 1 day ago | parent | next [\u2013]Plenty of others to tickle the norms; eg two editions of, and commentary on:Small is Beautiful: Economics as if People Mattered (1975)~ E.F. Schumacher  \u201cSmall is Beautiful is E. F. Schumacher's stimulating and controversial study of world economies.  This remarkable book is as relevant today and its themes as pertinent and thought-provoking as when it was first published thirty years ago.  Small is Beautiful looks at the economic structure of the Western world in a revolutionary way.  Schumacher maintains that Man's current pursuit of profit and progress, which promotes giant organisations and increased specialisation, has in fact resulted in gross economic inefficiency, environmental pollution and inhumane working conditions.  Schumacher challenges the doctrine of economic, technological and scientific specialisation and proposes a system of Intermediate Technology, based on smaller working units, communal ownership and regional workplaces utilising local labour and resources.\u201dhttps://annas-archive.org/search?q=Small+is+BeautifulreplyBarrin92 1 day ago | parent | prev | next [\u2013]Schumpeter pointed out that innovation is rarely the result of free market regimes but instead of monopolistic competition. A situation in which individual winners temporarily capture markets and use high surplus returns to fund fundamentally expensive innovation. In dynamic economies usually a handful of firms dominate in the medium term. They're replaced across time, they don't compete in the same space. More and more complex and developed economies naturally move towards this because progress requires immense capital.Under conditions of extremely free markets firms profits are reduced due to competition, consumers capture immediate value, but the sectors remain stagnant. An example are many service industries.This also applies to open source software. it is by its nature extremely competitive and as a result almost all value is captured by its users. This is great at any given point in time, but it also means that open source software is constantly underfunded, and research is in fact ironically driven by surpluses of large firms.replymdp2021 1 day ago | root | parent | next [\u2013]All effortful \"culture\" comes from surplus. And investment is crucial, not marginal.Let us not forget that the surplus need not be astronomical to create innovation - e.g. some innovative design comes from a shop\u00b9, some comes from very expensive prototyping. Still surplus, but on remote points in the scale.(\u00b9Think of the Rietveld Meubel Makerij - in the picture, Gerrit Rietveld is sitting on the prototype of what will become the \"Rood blauwe stoel\" - https://www.spectrumdesign.nl/wp-content/uploads/2019/06/ger... )If the circulation of tools is curbed, surely the freedom to progress is limited. Comparatively in outcomes to other scenarios, that is to be analyzed. But surely a reply to Schumpeter should be found in Levine and Boldrin: their work is explicit part of the discussion against competing theories.replyimmibis 16 hours ago | root | parent | next [\u2013]In modern capitalism, resources are not invested to find better ways to create things, but to find better ways to lock people out of the things you create until they pay you.replyjustinclift 1 day ago | root | parent | prev | next [\u2013]> This is great at any given point in time, but it also means that open source software is constantly underfunded, and research is in fact ironically driven by surpluses of large firms.Blender seems to be showing a different path?replyArchelaos 18 hours ago | root | parent | prev | next [\u2013]> ... and use high surplus returns to fund fundamentally expensive innovationWe might still see examples of this, but in the more than 70 years since Schumpeter developed his theories, the financial sector as well as state spending (military budget, infrastructure, public research, pension funds, etc.) expanded a lot. So there are many other sources for large capital needs available today.replytheptip 18 hours ago | root | parent | prev | next [\u2013]Thanks for sharing, found this interesting. Presumably this could be quantified/tested empirically? Are you aware of evidence in favor? What would be the strongest case against this position?Presumably there are NBER papers etc arguing this to death, but I don\u2019t know the literature.replyBiteCode_dev 21 hours ago | root | parent | prev | next [\u2013]You mean softwares VLC, Linux, Python all came out of a monopoly position?Or maybe you mean great greater than life concepts like the press, the Web or vaccines have been invented by big monopolistic entities?Or do you mean unicorns like Google, Amazon and Facebook were born out of monopoly?replynoduerme 1 day ago | root | parent | prev | next [\u2013]\"Monopolistic competition\" only exists between states at war, since any \"monopoly\", by definition, has no competition in the same polis.Willing to confuse cause with effect for a moment, is it true that innovation has mainly been the child of centralized monopolies competing under their respective wartime governments? ...mayyybe... but much of what they did militarily was built on the back of peacetime (or at least freelance) amateur discoveries by their respective member bodies.That's actually why, supposedly, America \"won\" the cold war. We promoted the birth of Mom's Garage Engineering.[edit: Strike. \"Engineering your home PC in your mom's garage\" is what I meant to say. And clearly, that more than any military/industrial/monopolistic program has made America the dominant power in the global technocracy today.]replylifeisstillgood 1 day ago | root | parent | prev | next [\u2013]That is incredible insight.Do you know which schumpter book he write this in?replymdp2021 1 day ago | root | parent | next [\u2013]Can I suggest that you check, for a first glance and orientation, Schumpeter\u2019s View on Innovation and Entrepreneurship (by Karol \u015aledzik, Uni Gdansk) - https://www.researchgate.net/publication/256060978_Schumpete...> In his earlier view (emphasized in The Theory of Economic Development, originally published in 1912), Schumpeter highlighted the function of entrepreneurs who is carrying out new combinations. He viewed the occurrence of discontinuous and \u201crevolutionary\u201d change as the core of \u201ceconomic development\u201d which breaks the economy out of its static mode (\u201ccircular flow\u201d) and sets it on a dynamic path of fits and starts. Three decades later, in his Capitalism, Socialism, and Democracy (1942), Schumpeter took the view that dynamic capitalism was executed to fail because the very efficiency of capitalist enterprise would lead to monopolistic structures and the disappearance of the entrepreneurreplyjacquesm 18 hours ago | root | parent | next [\u2013]> Schumpeter took the view that dynamic capitalism was executed to fail because the very efficiency of capitalist enterprise would lead to monopolistic structures and the disappearance of the entrepreneurWhich seems to be more or less spot on, except that 'the entrepreneur' also includes the lucky few that end up with the new monopolies.replymdp2021 15 hours ago | root | parent | next [\u2013]Hi J.; I am not sure about your interpretation but if I understand correctly, the reply would be:that \u00abfail\u00bb refers to the spirit of entrepreneur-iality, i.e. the dynamism centered on innovation. Schumpeter was called (by Joan Robinson) \u00abMarx with the adjectives changed\u00bb: his idea was that innovation be \"the driving force of capitalism\", but since efficiency creates bloat, the lean becomes heavy, the dynamism becomes bureaucracy, the \"entrepreneur\" becomes a \"\"\"manager\"\"\" (an insulting label in Sch.), capitalism proceeds towards atrophy and finally transforms into socialism. In Schumpeter, \"entrepreneur\" means \"the dynamic innovator\"; the monopolistic phase is that of the heavy bureaucracies - that would be the failure. The Schumpeterian school (Sch. died in 1950 - crucial time) deals consequently with \"why socialism did not happen\".If it was you that hit my parent post: I only reported that quote to help the poster asking for a bibliography - the paragraph contains reference to the two main books, with short descriptions left to the writing researcher (my own competence on Schumpeter is minimal). I am not personally defending their theories.replyTechBro8615 1 day ago | prev | next [\u2013]I followed the \"blog\" link in the footer and found some interesting posts, like this one [0] about the technical and operational details of running the archive.[0] https://annas-blog.org/how-to-run-a-shadow-library.htmlreplySamuelAdams 22 hours ago | parent | next [\u2013]I was impressed by this part:> Cloudflare does not accept anonymous payments, so we can only use their free plan. This means that we can\u2019t use their load balancing or failover features. We therefore implemented this ourselves at the domain level. On page load, the browser will check if the current domain is still available, and if not, it rewrites all URLs to a different domain.Are there any free and open source tools for load balancing that rival Cloudflare\u2019s paid offerings?replyMacsHeadroom 17 hours ago | root | parent | next [\u2013]No, but there are anonymous bill payment services and pre-paid crypto debit cards which support privacy coins like Monero.replyFindeton 23 hours ago | parent | prev | next [\u2013]I fully agree with them, copyright is a limited monopoly granted by governments. It doesn't have the properties of private property, it's an artificial limitation to creative work/ideas, which is basically unlimited by nature. It's government intervention creating scarcity where there isn't scarcity, it's an evil intervention of government on the free market.replypilimi_anna 16 hours ago | prev | next [\u2013]Anna here. Thanks for the support and feedback in these comments!replyculi 16 hours ago | parent | next [\u2013]Really cool archives. Another project you might wanna check out is DocuWiki (not to be confused with DokuWiki the software). It often gets looked over because it leverages the Ed2k network but it's often been the only source I've found for certain rare documentarieshttps://docuwiki.net/index.php?title=Special:NewpagesThanks kindly for your workreplypilimi_anna 10 hours ago | root | parent | next [\u2013]Thanks. Added to our list of libraries and archives to look at.replyqingcharles 13 hours ago | root | parent | prev | next [\u2013]Great link, thank you. I'd not heard about this wiki before. Now I'm going to lose more time I don't have to spare watching some documentaries.replyglietu 23 hours ago | prev | next [\u2013]Well, sometimes it\u2019s better to have best kept secrets as \u2026 secrets. Don\u2019t wanna lose this, after what happened to zLib.replypilimi_anna 16 hours ago | parent | next [\u2013]Opsec + open source > gatekeepingreplyglietu 4 hours ago | root | parent | next [\u2013]How do?replyjacooper 17 hours ago | parent | prev | next [\u2013]Zlib is still live btwreplynanny 16 hours ago | parent | prev | next [\u2013]For real. Please delete!replymrweasel 1 day ago | prev | next [\u2013]I don't get it, on the frontpage you have books like \"Harry Potter\", I'm fairly sure that's not open source or even available for free distribution. It also seems counter intuitive that you get preferential treatment if you login, why would that be the case, if it's truly open?replyvidyesh 1 day ago | parent | next [\u2013]In this case open-source does not mean only open-source books. Anna's Archive is a shadow library, they also maintain a pirate library mirror. So you can think of them like an anarchist(?) archivist?I think only the high-speed direct downloads require logging-in but other downloads and torrents are freely available.replymrweasel 1 day ago | root | parent | next [\u2013]Okay, but isn't Project Gutenberg the true open source library, without the risk of me misunderstanding the licensing and violating copyright?replyTechBro8615 1 day ago | root | parent | next [\u2013]Violating copyright is the whole point. The contention of this archive seems to be that Project Gutenberg is in fact not \"open,\" because it's constrained by its adherence to copyright laws.replyjug 23 hours ago | root | parent | next [\u2013]Weird definition of \"open source\".\"It's open because we violated copyright and uploaded it in the open.\"Call it what it is. Pirated books. People that must use them still will but at least now we'll know what it is.replyTakennickname 23 hours ago | root | parent | next [\u2013]> Call it what it is. Pirated books.You're missing the entire argument. The argument here is that they are not pirates, because copyright is stifles the spread of knowledge and should therefore be completely abolished.Whether you get it or not is something different all together. But that's what people are fighting for.replygjvc 22 hours ago | root | parent | next [\u2013]this is a good example of the difference between \"understanding\" and \"agreement\" :-)replyagumonkey 21 hours ago | root | parent | prev | next [\u2013]Where do they discuss the topic ? as much I loved zlib .. I cannot forget that copyrights is what allows knowledge to be spread most of the time. If people couldn't at least live from their writing (not even make a big profit) how else would book emerge ?replyabeppu 20 hours ago | root | parent | next [\u2013]Somewhere, a publisher is giggling as they change the constants in problems in an otherwise unchanged first semester physics book with an upcoming new edition.I think a lot of good books never pay their authors much, at least in proportion to the effort that goes into researching and writing them. Scihub was also violating copyright, but academic paper authors don't get paid by publishers; they the journals. Lots of intellectual labor goes into producing a good where the author would much rather you read it without paying than buy it but not read it.This is all to say, the publishers, who are perhaps no longer needed in the 21st century, are sales motivated, but there's at least a substantial category of authors who are not.replyagumonkey 16 hours ago | root | parent | next [\u2013]Fair point, maybe it's about rebalancing the system more than going fully one way.replymistermann 22 hours ago | root | parent | prev | next [\u2013]None of us approved or were even asked our opinion on this design, so I wouldn't get too bent out of shape over it.replymdp2021 1 day ago | root | parent | prev | next [\u2013]Project Gutenberg has been fought (censored, blocked, sued) by statal entities, like germany and italy - it may happen because of occasional improper insertions, or because of local legislation inconsistent with that which the Project references, or because of bestiality of the attacker.replyddeck 1 day ago | root | parent | prev | next [\u2013]The Internet Archive might be better example, depending on your definition of open. They have over 4 million books archived. I believe Project Gutenberg have around 70k.The Internet Archive include books still in copyright, which can be read by \"borrowing\" them virtually.https://archive.org/details/internetarchivebooksreplymdp2021 1 day ago | root | parent | next [\u2013]> which can be read by \"borrowing\"Reminder: based on the idea that \"if the library holds a physical copy it can lend an electronic view over it, respecting the same principle of the physical object, i.e. one user per item per period (i.e. one user per use instance)\". Such principle is being fought.replyvidyesh 1 day ago | root | parent | prev | next [\u2013]The idea of a shadow library is to disseminate knowledge to everyone, to provide easy access to readily available content which is made inaccessible through paywalls, copyright, or other similar barriers.At inception, these databases were created to make academic content freely available which generally does not compensate the original publishers. But now it has been expanded to support the knowledge for free movement.The legal status is questionable as creators can provide their own content to such libraries but their publishers might not agree to it.replyTeddyDD 20 hours ago | root | parent | prev | next [\u2013]I don't get why there is a DMCA form: https://annas-archive.org/copyrightreplylostmsu 19 hours ago | root | parent | next [\u2013]Wasting resources of copyright owners?replypilimi_anna 10 hours ago | root | parent | prev | next [\u2013]Free high-quality metadatareplyfoobarbecue 21 hours ago | root | parent | prev | next [\u2013]An anarchivist!!reply_shadi 23 hours ago | root | parent | prev | next [\u2013]how different is it then from libgen?replyvidyesh 3 hours ago | root | parent | next [\u2013]Apart from the content they add it also include other shadow libraries like sci-hub, zlib, libgen and some more[1][1] https://annas-archive.org/datasetsreplyjrflowers 1 day ago | parent | prev | next [\u2013]> why would that be the case, if it's truly open?Traffic management would make sense.replyftxbro 1 day ago | parent | prev | next [\u2013]> \"it also seems counter intuitive that you get preferential treatment if you login\"what preferential treatment is thatreplyjer0me 1 day ago | root | parent | next [\u2013]> Fast downloads from our partners (requires logging in)https://annas-archive.org/md5/224c5b1195fd2fb4650c3b75c2908d...replyftxbro 1 day ago | root | parent | next [\u2013]oh that's weird are they honeypotting me like if I try to fast-download harry potter the intellectual property police will come at me for violating the wizarding world extended universe franchisereplyyard2010 1 day ago | root | parent | next [\u2013]I think it lies in the jurisdiction of the books police.replyftxbro 1 day ago | root | parent | next [\u2013]I would expect a nasty letter delivered by an owl, followed by a visit by a stern gandalf looking mf flanked by two furries guards each seven feet tall and armed with a different medieval polearmreplydeepnet 1 day ago | root | parent | next [\u2013]Dementors to take one to AzkhabanreplyRobotToaster 21 hours ago | parent | prev | next [\u2013]do what you want 'cause a pirate is freereplymdp2021 18 hours ago | root | parent | next [\u2013]> freeActually, per the meaning of its own name, is /daring/ (\"per-ya\", ex PIE for \"to try, risk\").replyfoobarbecue 17 hours ago | root | parent | next [\u2013]https://youtu.be/i8ju_10NkGYreplydharmab 1 day ago | prev | next [\u2013]I love this website. I find lots of obscure texts here I can't find anywhere else.replynetfortius 1 day ago | prev | next [\u2013]Is this just to get some HN karma points? Posting here makes almost sure another z-lib alternative gets shutdown... :(replyrootkea 19 hours ago | parent | next [\u2013]\"How to help:...2. Spread the word about Anna\u2019s Archive on Twitter, Reddit, Tiktok, Instagram, at your local cafe or library, or wherever you go! We don\u2019t believe in gatekeeping \u2014 if we get taken down we\u2019ll just pop right up elsewhere, since all our code and data is fully open source.\"Source: https://annas-archive.org/aboutreplynetfortius 17 hours ago | root | parent | next [\u2013]https://news.ycombinator.com/item?id=35300200replyawestroke 1 day ago | parent | prev | next [\u2013]Yeah. It's such a shame that archiving is a zero-sum game. If I archive some books, nobody else can archive them.replygigglesupstairs 23 hours ago | parent | prev | next [\u2013]It has already been posted here multiple times before.replynetfortius 17 hours ago | root | parent | next [\u2013]And this (repetitive postings) makes it right ... how?replypixelbath 13 hours ago | root | parent | next [\u2013]And sharing the link with other people (a desire stated on the website itself) makes it wrong...how?replynathancahill 23 hours ago | parent | prev | next [\u2013]Does anyone have the Z-lib Discord that's floating around? Contact in profile if you don't want to post it publicly.replynetfortius 17 hours ago | root | parent | next [\u2013]Sent ...replylevitaet 8 hours ago | root | parent | next [\u2013]can u send it to me please?replydr_kiszonka 12 hours ago | prev | next [\u2013]While I wouldn't download books via this website, the search engine is excellent! (Better than Amazon and Google.) Could you consider adding filtering the results by year? Also, just out of curiosity, how much storage does your archive take? I am guessing it is in the order of petabytes.replygigatexal 1 day ago | prev | next [\u2013]I think Aaron Swartz would love this effort.replybeefield 18 hours ago | prev | next [\u2013]I kind of understand many of the books in the front page, but is there a message for example in harry potter or game of thrones that I do not get?replytheptip 18 hours ago | parent | next [\u2013]\u201cWe have the popular copyrighted stuff too\u201d?replyiguana_lawyer 20 hours ago | prev | next [\u2013]Recent attempts in the United States to ban books and close libraries has made sharing books without concern for copyright law a moral imperative.replywiz21c 22 hours ago | prev | next [\u2013]Dumb question: is this legal ?replyimmibis 17 hours ago | parent | next [\u2013]Blatantly not. Smart question: How much do the politicians who made this illegal care about YOUR finances?replyhk__2 16 hours ago | root | parent | next [\u2013]> Smart question: How much do the politicians who made this illegal care about YOUR finances?How is that a smart question? You very likely can\u2019t name the \"politicians who made this illegal\" because haring others\u2019 intellectual property without permission has been illegal by definition since the beginning of intellectual property.replyimmibis 14 hours ago | root | parent | next [\u2013]Yup. How much do the politicians who created intellectual property care about YOUR finances?replyhedora 12 hours ago | parent | prev | next [\u2013]The front page of Anna\u2019s archive makes it clear they want to organize the would\u2019s information, and make it universally accessible, so no.The next question is why the courts would say that Anna\u2019s archive is illegal, but Google is not.There are some tests around encouraging copyright infringement, and Google is very careful to pass those tests despite providing extremely similar services over similarly-illegal sites.The mental and legal gymnastics required for all this are fascinating. I suggest studying internet IP law.reply__anon-2023__ 5 hours ago | root | parent | next [\u2013]> organize the would\u2019s information, and make it universally accessible, so no.That's similar one of Google's goals, and they do it (mostly) legally.replymadphilosopher 13 hours ago | parent | prev | next [\u2013]Illegal but not immoral.replytiagod 22 hours ago | parent | prev | next [\u2013]Depends on your jurisdiction (but in most likelihood not)replymdp2021 18 hours ago | root | parent | next [\u2013]It could be a greatest lead to know where it may be - places where cultivation is a paramount value.replyMezzie 21 hours ago | parent | prev | next [\u2013]In the US and Canada (the only countries whose copyright law I have studied), it is not.replysaxomoose 1 day ago | prev | next [\u2013]Is this also your go-to since LE action on Zlibrary?replyrjaco31 12 hours ago | parent | next [\u2013]They removed the public DNS, but z-library is working just fine with Tor. I think you even have the .onion url on their Wikipedia page.replyranting-moth 1 day ago | parent | prev | next [\u2013]zlib is back, singlelogin.re.replymaxiwer 1 day ago | prev [\u2013]What's the point of these kind of \"Free books\"? It would be better if we could organize something like real book exchanging worldwide.replysheepdestroyer 1 day ago | parent | next [\u2013]Are you really asking what's the points of making almost any book freely available online?This is extremely valuable to anyone who ever needed a book but could not easily get it for whatever reason.You're free to contact book clubs from all over the world to locate and trade paper ones with you if you're not in a hurry, but you obviously don't depend on getting the ressource fast, reliably or at all.replyjrflowers 1 day ago | parent | prev | next [\u2013]Why would you post this question online rather than simply writing it in a nice card and sending it to me?replyCthulhu_ 1 day ago | parent | prev | next [\u2013]I mean libraries are a thing, but it's a logistics problem. My local library has thousands of Dutch language books, how is an expat or student in the US going to get to them? And that's between two countries with good relationships and transport links - although said transport is prohibitively expensive for the vast majority of people.Consider another argument: book bannings are a thing in the US again, a facist practice [0]. Making these banned books accessible to all despite the bans is a clear anti-facist statement and move.[0] https://www.theguardian.com/us-news/2023/feb/13/african-amer...replymdp2021 1 day ago | root | parent | next [\u2013]> book bannings are a thing ... againYou may have missed a t-shirt photographed a couple of days ago, on a demonstrator, going along the lines of \"We do not delegate education to the state\" (oblivious of the principle that schools are there to fix the issue of faulty parental education, and conversely parents orient the children which are necessarily exposed to the world). it is from a group that demands censorship - it counts over 100'000 members. I understood they are also those who want the genitals of Achilles and Hector covered on Greek urns (or them urns hidden altogether from culture, \"what is their use\").And of course, each similar group has a different set of \"books to burn\".reply_ink_ 22 hours ago | parent | prev | next [\u2013]I was in a Kindle Book Club some years ago. The idea was to pay a little fee, from which books are centrally bought. Which books to buy was decided by voting. The books then would be shared with the members. There were never more concurrent users than copies purchased.Buuut, apparently that violates some TOS and Amazon was terminating the accounts. So it's back to the shadow libs.replyhedora 6 hours ago | root | parent | next [\u2013]You could always buy DRM free books, or destructively scan + OCR dead tree books.For destructive scanning, the obvious question is why you\u2019d go through the trouble and not upload it to some sort of shadow libs.I get the impression that the pendulum is rapidly swinging back to piracy as a moral imperative.I was happy paying for HBO Max due to the high quality original content, but then they fired all the actors.So, there was an implicit social contract (you produce tv/movies that generate revenue, we distribute it, and pay you for the next one), but now it has been broken.From a customer perspective, paying the middle man, knowing the people that produced the product will not be paid is immoral.(Yes, I know residuals exist. That\u2019s not good enough.)replydraugadrotten 1 day ago | parent | prev | next [\u2013]This is an amazing resource for students in e.g. rural Africa. They do not have access to physical libraries like you would.replymdp2021 1 day ago | root | parent | next [\u2013]> like you wouldLike many would. Do not take libraries for granted - not even in \"rich\" countries.replyCthulhu_ 1 day ago | root | parent | next [\u2013]Indeed, and even if you do have access to a library, due to logistics / volume, they only represent a fraction of the available knowledge worldwide.If they offer internet access though, AND if projects like these are still around, the access to information is infinite.replymdp2021 1 day ago | parent | prev | next [\u2013]Kindly present your arguments explicitly, because it is unclear what you mean - why this would be unimportant, why that more important etc. We cannot invest hours trying to reconstruct a \"best interpretation\".replyvorpalhex 13 hours ago | parent | prev [\u2013]There are some books for which official ebooks don't exist.. but those ebooks appear on Anna's archive. And they are well done conversions, not just OCR copies.There are books on the archive that do exist in real life but are _extremely_ rare or may as well not exist.I'm lucky enough to have a real dead tree library in my home but I still use ebooks heavily, and often duplicate books in both collections.replyGuidelines | FAQ | Lists | API | Security | Legal | Apply to YC | ContactSearch:",
    "hn_summary": "- Anna's Archive is an open-source data library that provides easy access to a wide range of books.\n- The archive includes books that may not be available through official channels, such as rare or out-of-print books.\n- The archive is valuable for people who have difficulty accessing physical libraries or need access to books quickly and reliably."
  },
  {
    "id": 36528984,
    "timestamp": 1688085920,
    "title": "MdBook \u2013 A command line tool to create books with Markdown",
    "url": "https://rust-lang.github.io/mdBook/",
    "hn_url": "http://news.ycombinator.com/item?id=36528984",
    "content": "IntroductionUser Guide1. Installation2. Reading Books3. Creating a BookReference Guide4. Command Line Tool4.1. init4.2. build4.3. watch4.4. serve4.5. test4.6. clean4.7. completions5. Format5.1. SUMMARY.md5.1.1. Draft chapter5.2. Configuration5.2.1. General5.2.2. Preprocessors5.2.3. Renderers5.2.4. Environment Variables5.3. Theme5.3.1. index.hbs5.3.2. Syntax highlighting5.3.3. Editor5.4. MathJax Support5.5. mdBook-specific features5.6. Markdown6. Continuous Integration7. For Developers7.1. Preprocessors7.2. Alternative BackendsContributorsmdBook DocumentationIntroductionmdBook is a command line tool to create books with Markdown. It is ideal for creating product or API documentation, tutorials, course materials or anything that requires a clean, easily navigable and customizable presentation.Lightweight Markdown syntax helps you focus more on your contentIntegrated search supportColor syntax highlighting for code blocks for many different languagesTheme files allow customizing the formatting of the outputPreprocessors can provide extensions for custom syntax and modifying contentBackends can render the output to multiple formatsWritten in Rust for speed, safety, and simplicityAutomated testing of Rust code samplesThis guide is an example of what mdBook produces. mdBook is used by the Rust programming language project, and The Rust Programming Language book is another fine example of mdBook in action.ContributingmdBook is free and open source. You can find the source code on GitHub and issues and feature requests can be posted on the GitHub issue tracker. mdBook relies on the community to fix bugs and add features: if you'd like to contribute, please read the CONTRIBUTING guide and consider opening a pull request.LicenseThe mdBook source and documentation are released under the Mozilla Public License v2.0.",
    "summary": "- MdBook is a command line tool that helps create books with Markdown, making it easy to create product or API documentation, tutorials, and course materials.\n- It has features like integrated search support, color syntax highlighting for code blocks, and customizable theme files for formatting the output.\n- MdBook is written in Rust, which ensures speed, safety, and simplicity, and it is used by the Rust programming language project.",
    "hn_title": "MdBook \u2013 A command line tool to create books with Markdown",
    "original_title": "MdBook \u2013 A command line tool to create books with Markdown",
    "score": 428,
    "hn_content": "Hacker News new | past | comments | ask | show | jobs | submit loginMdBook \u2013 A command line tool to create books with Markdown (rust-lang.github.io)428 points by swatson741 1 day ago | hide | past | favorite | 115 commentstoastal 1 day ago | next [\u2013]IIRC, this platform uses CDN-hosted libraries rather than bundling/vendoring. As a result, users are exposed to not just outages of the CDNs but also the data collected by these servers. That\u2019s a bummer.\u2026but it\u2019s not the only bummer. The usage of Highlight.js + MathJax on the front-end is horribly wasteful. Why? It demands all clients parse & render the syntax/LaTeX which is not only taxing on CPUs and batteries, but this action is idempotent meaning every user agent on every page visit is going to do the same wasteful parsing to get the same result. There is no good reason that syntax highlighting shouldn\u2019t be done at build time nor should it require JavaScript.replycodetrotter 1 day ago | parent | next [\u2013]Looks like MathJax is hosted on a CDN. Everything else, from css to other js files, is hosted alongside the HTML files.Seems a bit strange. I wonder why they chose to use a CDN for that one js file.Perhaps because MathJax support is optional? https://rust-lang.github.io/mdBook/format/mathjax.htmlEven though the MathJax js file will in turn probably load more things hosted on the CDN. I don\u2019t understand why they are not putting all of the MathJax files alongside the generated HTML files. So that one does not have to rely on any CDN.replytoastal 1 day ago | root | parent | next [\u2013]Now that I\u2019m at my laptop I can see that you are correct on most things at least now being vendored\u00ad\u2013though it took me a while to find it since the scripts in the <body> like it\u2019s last decade instead of in the <head> with async or defer attributes.replysinghrac 17 hours ago | root | parent | prev | next [\u2013]Maybe it\u2019s because MathJax loading slow would delay rendering, and using a CDN-hosted MathJax increases the chance the content is cached?That\u2019s usually why people use CDNs. It\u2019s more important for MathJax than, say, interactive scripts, since it can cause rendering.I don\u2019t think MathJax loads any additional files (I don\u2019t remember seeing any additional network requests).replytoastal 16 hours ago | root | parent | next [\u2013]With first-party isolation being the standard for the last couple of years, there are no \u201cshared caches\u201d. A third-party CDNs might load a particular resource faster, but at the cost of user privacy & reliability. You can know, barring exceptional circumstances, that if your site loaded, it can load its own libraries. Look at the news of Cloudflare, Fastly, et al. going down and the \u2018internet breaking\u2019 because there\u2019s been too much centralization and bad advice that all site\u2019s need these sorts of \u2018optimizations\u2019.replyYgg2 1 day ago | parent | prev | next [\u2013]Interesting enough there seems to be an open PR for that: https://github.com/rust-lang/mdBook/pull/1918replymsravi 1 day ago | prev | next [\u2013]So far, in this thread (in no particular order):- [Jekyll](https://jekyllrb.com/)- [Hugo Book](https://github.com/alex-shpak/hugo-book)- [MdBook](https://rust-lang.github.io/mdBook/)- [MkDocs](https://www.mkdocs.org/)- [MkDocs Material](https://squidfunk.github.io/mkdocs-material/)- [GitBook](https://www.gitbook.com/)- [Antora](https://antora.org/)- [Docusaurus](https://docusaurus.io/)- [Nextra](https://nextra.site/)- [Astro](https://astro.build/)- [Starlight](https://starlight.astro.build/)- [Clowncar](https://github.com/secretGeek/clowncar)- [Keenwrite](https://github.com/DaveJarvis/keenwrite)- [Quarto](https://quarto.org/)- [Honkit](https://github.com/honkit/honkit)- [JupyterBook](https://jupyterbook.org/)replyelcritch 23 hours ago | parent | next [\u2013]Nice list! I've also used [nimibook](https://pietroppeter.github.io/nimibook/).Its a port of mdbook to Nim, but also extends it with the ability to generate interactive content as well using Nim's Javascript backend. Though I haven't tried this piece myself I like the idea of an all in one way to make interactive elements when desired: https://pietroppeter.github.io/nimib/interactivity.htmlreplypyeri 19 hours ago | parent | prev | next [\u2013]Notable mention to [Sphinx](https://www.sphinx-doc.org/). It's workflow is more tuned to the \"book\" format rather than the blog, forum or thread format.replygeoffreymcgill 3 hours ago | parent | prev | next [\u2013]How about Retype? https://retype.comreplyd4rkp4ttern 22 hours ago | parent | prev | next [\u2013]HackMD is often my go-to to create a shareable (and collaboratively editable) markdown document that supports math notation.https://hackmd.io/replyjtbayly 19 hours ago | parent | prev | next [\u2013]I'd like to see a feature comparison table/site for these tools?Which ones have...? - search built in - PDF output - ePub output - more than one theme - lots of other stuffreplyagoose77 1 day ago | parent | prev | next [\u2013]Also, https://jupyterbook.org/en/stable/(nb) I collaborate on Jupyter BookreplyCosi1125 20 hours ago | parent | prev | next [\u2013]Also, Bookdown (https://bookdown.org/)replyskimdesk 17 hours ago | parent | prev | next [\u2013]Shameless plug for Doctave [0], which offers a solid way to combine markdown and OpenAPI specs into a documentation site.It's a hosted SaaS, so it's technically not a static-site generator, but it's an alternative to the above.[0]: https://www.doctave.com/replythrow_a_grenade 19 hours ago | parent | prev | next [\u2013]Plz add [Lektor](https://getlektor.com).Happy user here.replyklodolph 1 day ago | prev | next [\u2013]I\u2019ve tried MdBook, Jekyll, and MkDocs. MdBook is slick for basic projects, but I felt it was too minimalistic for me. When I dug into the source for the MdBook sites that I liked, I saw that they had extended MdBook with some custom Rust code.My recommendations are:- MkDocs: Good default choice, reasonably flexible.- Jekyll: For people who want a little more flexibility\u2014things like landing pages, blogs, etc.- Antora: For people who want the best docs, and are willing to put in the most effort. It will manage, for you, the process of generating documentation sites that collect documentation from multiple projects and possibly multiple versions of each project. Asciidoc is full of features you\u2019ll find useful.Hugo looks like it has a lot of flexibility like Jekyll, but it seems to take more effort to get everything working the way you want, and it also seems like there\u2019s just too much variation in how the different themes work. To be honest, I never really managed to make anything with it\u2014I found out that the theme I was using didn\u2019t have some features I wanted, so I switched to a different theme, but it\u2019s not easy to switch themes. I was too frustrated and gave up.It looks like MdBook is reasonably active, so I\u2019m sure it will catch up.replydcchambers 1 day ago | parent | next [\u2013]I am a long time Jekyll user and I still think it's a great tool for blogs, but by far the best SSG for documentation websites I have found is Docusaurus. (https://docusaurus.io/)I resisted trying it for the longest time because I didn't want a JavaScript based tool, but I am glad I caved. It's so easy to get started, crazy fast, and the sites are absolutely beautiful out of the box yet easy to customize. The mdx support is awesome too.replyslorber 15 hours ago | root | parent | next [\u2013]Docusaurus maintainer here, happy to read your feedback ;)replyklodolph 1 day ago | root | parent | prev | next [\u2013]Somehow I missed Docusaurus when I surveyed documentation generators\u2014it looks very good!I can understand the desire to want something not written in JavaScript, and I certainly have my own language prejudices, but when I surveyed static site generators, language choice was all over the map. Like, I was willing to wrangle Ruby installations and gems to get Jekyll working, something I have nearly no experience with.replyKRAKRISMOTT 1 day ago | root | parent | prev | next [\u2013]Alsohttps://nextra.site/replybccdee 1 day ago | parent | prev | next [\u2013]Wow, what is up with the material mkdocs theme (https://squidfunk.github.io/mkdocs-material/)? That's an extremely spiffy landing page, especially given that it's for a theme designed for a totally separate piece of software.replyjonasdoesthings 1 day ago | root | parent | next [\u2013]mkdocs-materials is underselling itself as only a theme imo. It bundles a lot of value that mkdocs is missing out of the box as plugins and tweaks, like a good client-side search, page tags, or easy support for a lot of markdown extensions (e.g. code syntax highlighting, admonitions/callouts).From my personal experience mkdocs+mkdocs-material is like GNU+Linux.replyd4rkp4ttern 22 hours ago | root | parent | next [\u2013]At least for Python documentation, this plus mkdocstrings is great.replyd4rkp4ttern 22 hours ago | root | parent | prev | next [\u2013]Check out the Pydantic docs pages - they use Mkdocs-materialhttps://docs.pydantic.dev/latest/replyjames-bcn 1 day ago | parent | prev | next [\u2013]For science and statistics, I think Quarto is excellent: https://quarto.orgreplydsmmcken 20 hours ago | parent | prev | next [\u2013]Thanks, I hadn't heard of Antora, but the behaviours of assembling docs from multiple repos and using branches for versioning is exactly what I want. Too bad it's not using MDX though, as all our existing docs are markdown + interactive react components.replyBad_CRC 1 day ago | parent | prev | next [\u2013]I'm a huge user of mkdocs and totally love it.I've trying also bookstack and even it's more \"wiki\" like it's great too for less tech-savvy people (I usually edit my mkdocs projects in vscode and keet them in git repos and bookstack is all web based).replyssddanbrown 23 hours ago | root | parent | next [\u2013]> I've trying also bookstack and even it's more \"wiki\" like it's great too for less tech-savvy peopleThanks! My main goal when building BookStack was to build a platform that could be used by all departments, of varying technical confidence, of the company that I was working at since existing open source documentation/wiki systems were positioned for a more technical audience.replybheadmaster 1 day ago | parent | prev | next [\u2013]I also recommend MkDocs.It was the most painless experience I've had with quickly setting up docs from a bunch of .md files, and the plugins give it enough flexibility for most of the usual stuff I need.replyLeonB 1 day ago | prev | next [\u2013]I used to use gitbook to generate til.secretGeek.net but it got slower and slower over time, would take 45 mins to build the site\u2026 and then the parts I was using were either deprecated or made \u201cpremium\u201d - something happened. The \u201censhittification\u201d set in, basically. If there\u2019s some nice free thing you use that\u2019s too good to be true\u2026 wait a few years it will go to muck.I bit the bullet and wrote my own very minimal static site generator in .net, so the site builds in a few seconds again. Note that I\u2019m not spruiking it for others to use\u2026 because if it became popular, no doubt I\u2019d end up enshittifying it too.replywumms 1 day ago | parent | next [\u2013]> spruikspruik- in British English (\u02c8spru\u02d0\u026ak\u02c8) [Australian archaic, slang]:to speak in public (used esp of a showman or salesman)- in American English (\u02c8spru\u02d0k\u02c8) [Australian slang]:to make or give a speech, esp. extensively or elaborately; spiel; oratehttps://www.collinsdictionary.com/jp/dictionary/english/spru...replyLeonB 19 hours ago | root | parent | next [\u2013]Well done. And I am Australian.replylwhsiao 1 day ago | prev | next [\u2013]Was using mdbook for a lot of projects, but these days, I feel like material for mkdocs just has so much more built in that makes it nice to use.One example, I really like the page TOC on the right side that is notably absent from mdbook, where it seems the standard to set up SUMMARY very detailed and break what could've been a single page into many different files.replyqbasic_forever 1 day ago | parent | next [\u2013]Yeah material for mkdocs is so good it's worth slogging through a python install/venv to make it work.replyblooalien 1 day ago | parent | prev | next [\u2013]I been a huge fan of mkdocs for a while now. It really does just get the job done with a minimum of fuss and muss, and has a lotta nice themes to choose from (as well as being fairly easy to customize or build your own).replyasicsp 1 day ago | parent | prev | next [\u2013]I use https://github.com/JorelAli/mdBook-pagetoc to get Table of Contents for chaptersreplyrmrfchik 1 day ago | prev | next [\u2013]Started using mdBook couple days ago for documenting small project. This is exactly what I need: small static pages generator. Tried HUGO, but it seems so huge and bloated comparing to mdBook. Now I edit doc with Obsidian/VIM, push to Gitea and in minute get public documentation.replymsravi 1 day ago | parent | next [\u2013]I use hugo with the book theme (https://github.com/alex-shpak/hugo-book). It takes a bit of getting used to (if you're not familiar with hugo) but after that it's pretty good with all the flexibility that hugo provides for shortcodes, etc. You can get auto numbering of figures, equations, etc. with appropriate shortcodes. Is it possible to get autonumbering in mdBook?It also gives a nice toc/tags on the right side (if you want it), and the ability to split the page into columns. The katex support is good (looks like mdBook uses mathjax) and publishing is easy and is just a push/rsync.replybluejekyll 1 day ago | parent | prev | next [\u2013]I\u2019ve started using a plantuml extension for it recently, helps embed architectural diagrams in the docs.replyeddythompson80 1 day ago | prev | next [\u2013]I recently started exploring, and slowly migrating, to .mdx over .md for content. So far it\u2019s been a breath of fresh air tbh. My biggest problem of markdown was the specific flavor I happen to be using and the type of cliffs I\u2019d run into, then how to extend them.I\u2019m extremely satisfied with 80-90% of the standard Gitbook markdown flavor. Then every now and then I really wanna make a complicated table, or a code block highlighting few lines while maintaining syntax highlighting, or an interactive slider, or a formula calculator that\u2019s built-in the documentation instead of a complicated function, or a particular graph/chart etc. I don\u2019t know how something like mdx would work for a large team (ever tried to clone Microsoft\u2019s doc repo?) but at least for my own stuff, it seems like a definite improvement.replyrapnie 1 day ago | parent | next [\u2013]> My biggest problem of markdown was the specific flavor I happen to be using and the type of cliffs I\u2019d run into, then how to extend them.First time I heard of .mdx and looked up the site [0]. I am insufficiently in the loop of frontend standardization. Now it would be great to get rid of flavors and have one universal approach. In the Docs I read:> MDX is not coupled to React. You can also use it with Preact, Vue, Emotion, Theme UI, etc. Both the classic and automatic JSX runtimes are supported.A sibling comment already mentions a Svelte implementation [1]. So I fail to see how this doesn't open a pandora's box of yet more flavors, this time coupled to frontend frameworks. First in .mdx and then incompatible with .mdExtensibility. Yes, I guess, if your stack is supported by any of the existing implementations.[0] https://mdxjs.com/docs/what-is-mdx/[1] https://mdsvex.com/docsreplyfriendzis 1 day ago | root | parent | next [\u2013]JSX is evidence that new generation of programmers are not taught engineering. There are very valid reasons why we went for encapsulation and separation of concerns. JSX throws the baby with the bath water and goes back to PHP5 sites with markup and code interspersed. Even authors of JSX cannot make it work reliably in their flagship product. MDX couples JSX with markdown.I cannot see how this yields maintainable source. Sure, spaghetti code is nice for quick, one off scripts, but if you'd volunteer for helpdesk shift to be yelled at rather than fix a bug in 5k SLOC collection of Windows Batch scripts, then maybe you should reconsider mdx.replyFractalHQ 1 day ago | parent | prev | next [\u2013]I couldn\u2019t agree more. Mdsvex was life changing when I discovered it: https://mdsvex.comreplyFireInsight 1 day ago | parent | prev | next [\u2013].mdx can be used with https://astro.build/ very easily, which is a JS metaframework and no-JS-shipped SSG-first approach. There are themes you can use, but for any modern web developer it would be pretty easy to roll your own.replythangalin 1 day ago | prev | next [\u2013]I wrote KeenWrite, a free and open-source cross-platform tool, to create Markdown-based books. KeenWrite calls out to ConTeXt to typeset the documents and uses my KeenType fork for typesetting math while in preview mode. KeenWrite can generate PDF files from the command-line.* https://github.com/DaveJarvis/keenwriteFor example:  java -jar keenwrite.jar \\   --all \\   --r-dir=$PWD/bin \\   --r-script=$PWD/bin/editor.R \\   --image-dir=$PWD/images \\   --variables=$PWD/variables.yaml \\   --theme-dir=$HOME/dev/java/keenwrite/themes/boschet \\   --metadata=title={{book.title}} \\   --metadata=byline={{book.author.byline}} \\   --metadata=keywords={{book.keywords}} \\   --metadata=copyright={{book.copyright}} \\   --metadata=\"reviewer=$1 $2, $3\" \\   --chapters=\"-14\" \\   --input=\"$PWD/chapter/01.Rmd\" \\   --output=\"${TEMP_NAME}\"That mouthful compiles the book that I'm writing. The book defines numerous variables that are referenced throughout the prose and defined in an external file. Variables can also be passed in as metadata, which tells ConTeXt various PDF properties to embed. The chapters argument allows selecting a subset of chapters to build (e.g., 1-3,5,9-15,22). Lastly, the theme directory points ConTeXt to the instructions to use when typesetting the document, which controls colours, fonts, layout, annotations, etc.Some sample outputs:* https://github.com/DaveJarvis/keenwrite-themes/tree/main/exa...replystill_grokking 22 hours ago | prev | next [\u2013]Tangent question: What are currently viable Markdown alternatives?Imho Markdown is a overall terrible and (especially regarding technical writing!) very limited format. But nothing else seems popular. Why actually?Are there any realistic alternatives?Thanks for some hints!replyzoogeny 18 hours ago | parent | next [\u2013]In all seriousness, HTML started out as a markup language for documents. That is why tags like <p> for paragraphs and <b> for boldness etc. are so prominent.If you aren't trying to build a SPA or something like that and you just want to mark up some text for formatted output ... HTML is kinda made for that task.That being said, I tend to stick with Markdown since I find angle bracket tags to be noisy and distracting when I view documents in plain text.replyhoofhearted 15 hours ago | root | parent | next [\u2013]Yes! I agree with this!It\u2019s just plain old dumb boring static text that is being moved around the web.The internet was essentially created so that CERN could share plain old text documents with others remotely.Why do I need a big bloated overly complicated PHP webserver that talks to an overly complicated database, when it\u2019s just plain old static text after all?replypie_flavor 16 hours ago | parent | prev | next [\u2013]Markdown is a formalization of formatting conventions that people were using well before it was invented as a separate product. It was slightly different - the link syntax was novel, and asterisks usually meant bold instead of italics - but it was close enough that the allure of 'your reflexes still work' held. Nothing else is as popular as Markdown because it isn't actually Markdown that's popular, it's what preceded it.Personally I'm happy for it because it'll finally stop programming languages from inventing their own domain-specific oddly-syntaxed subset of HTML; the way Rust uses it is something others have no reason not to copy. For your own technical writing, AsciiDoc works pretty well.replyBanazirGalbasi 18 hours ago | parent | prev | next [\u2013]> But nothing else seems popular. Why actually?I think markdown's popularity comes from its simplicity. For things like bulleted lists, especially nested ones, I can just type an asterisk and keep going. The raw input is still very readable (for the most part) and adding formatting is quick and easy. For anything basic - such as chat systems, social media posts/comments, or quick note systems - I don't think anything more is needed.Something like reStructuredText (.rst) is a similar alternative, but I think that if you're irritated by the limits of Markdown then rST isn't going to be any better. If you really want good formatting options, then LaTeX is the best I can think of at the moment.replytpreetham 21 hours ago | parent | prev | next [\u2013]org-mode is a brilliant format. The limitation is that you would have to use Emacs or something which support .org files.https://youtube.com/playlist?list=PLVtKhBrRV_ZkPnBtt_TD1Cs9P...replystill_grokking 21 hours ago | root | parent | next [\u2013]What else besides EMACS supports .org files?Form the alternatives I've seen so far it looks best. But EMACS? (I'm on Linux, but never liked EMACS or Vi(m)).The second best looking alternative seems AsciiDoc. It has some more tooling as I see it.But really like the .org syntax best so far. So any recommendations for tooling?replyBenFeldman1930 16 hours ago | root | parent | next [\u2013]AsciiDoc still has no footnotes, but only endnotes. Therefore not really useful for writing non-fiction books. As org-mode files are only text files, you can use any editor you like. If you want all the goodies (agenda, TODOs etc), you have to use Emacs, yes.replytoastal 20 hours ago | parent | prev | next [\u2013]In the future, Djot might be up to the task, but currently it\u2019s more fixing issues with Markdown & roadmapping improvements.replyletmeinhere 21 hours ago | parent | prev | next [\u2013]AsciiDoc, org-mode, ReStructured Text are some of the other light markup contendersreplyqwerty456127 1 day ago | prev | next [\u2013]I just wonder why Markdown (or whatever alike, I know there are alternatives superior in numerous ways) is not the default format for books, documents and everything. Some years ago I switched to Typora and discovered I hardly ever need Word/Writer for anything I write and I only use it to open documents others would send me. 90% of books I read don't look like having a serious reason for not being in the Markdown format either. I understand there is typesetting one has to do to print a nice-looking paper book but the majority of the text read on a computer/smartphone or printed from MS/Libre Office lacks this job done anyway.replyThe_Colonel 23 hours ago | parent | next [\u2013]Markdown is a really poor storage format. There is quasi-official standard (CommonMark), but since it's feature-poor, people mostly use something else, like GitHub Markdown. Individual apps often extend Markdown in various incompatible ways.There are better alternatives (e.g. AsciiDoc, but it's specialized towards documentation), but they don't have anything close to the momentum of Markdown.> 90% of books I read don't look like having a serious reason for not being in the Markdown format either.Markdown is a late comer to the game, so the better question is - why should books be in Markdown? Markdown's biggest (or the only?) advantage compared to binary/XML based formats is sort-of readability in plain text, but that's just not that important for the majority of publishers and readers.replyqwerty456127 22 hours ago | root | parent | next [\u2013]> Markdown is a really poor storage format. There is quasi-official standard (CommonMark), but since it's feature-poor, people mostly use something else, like GitHub Markdown. Individual apps often extend Markdown in various incompatible ways.I hope GitHub and Obsidian are going to synchronise their MarkDown extensions in near future and this will become The Standard. Whatever a case, anybody can easily write a script to automatically convert any Markdown flavour to another.> why should books be in Markdown? Markdown's biggest (or the only?) advantage compared to binary/XML based formats is sort-of readability in plain text, but that's just not that important for the majority of publishers and readers.Read anywhere. I mean anywhere. Without a need for software as complex and resource-hungry as a web browser engine ePub would require. I used to read TXT books on a pocket MP3 player during the pre-Android era. Also very easy automated processing.In fact my actual preferred format for books is FB2. I mostly convert ePub books to FB2 to read on a PocketBook eInk device because it would use book-specified fonts and pages (which I never want) if I don't and FB2 is sort-of Markdown-like (in terms of its logic and features) XML. FB2 also has a great metadata section to store information about the book.And besides books there also are documets. Word/LibreOffice documents others would send me often are real pain to modify as WYSIWYG word processors bundle tons of redundant invisible formatting details for every bit of text even when not asked for.\u201cPerfection is achieved, not when there is nothing more to add, but when there is nothing left to take away.\u201d \u00a9replyThe_Colonel 22 hours ago | root | parent | next [\u2013]> Without a need for software as complex and resource-hungry as a web browser engine ePub would require.I know that technology purists love that, but any electronic reading device handles HTML easily (especially the simple HTML in ePubs).The point becomes moot when your book contains images/illustrations and you (like a normal reader) want to view them within the content. You will use some Markdown formatter/viewer which is again based on browser.> Word/LibreOffice documents others would send me often are real pain to modify as WYSIWYG word processors bundle tons of redundant invisible formatting details for every bit of text even when not asked for.Markdown is just insufficient for any non-trivial document. There isn't any standard way to set image size for example. There's no standard way to create even rudimentary tables.> \u201cPerfection is achieved, not when there is nothing more to add, but when there is nothing left to take away.\u201dThen go for plain text. All those headings and asterisks are a distraction anyway. Years ago, many e-books used to be distributed in plain text in fact.replyqwerty456127 20 hours ago | root | parent | next [\u2013]> Then go for plain text. All those headings and asterisks are a distraction anyway. Years ago, many e-books used to be distributed in plain text in fact.Markdown is more semantic. E.g. it gives you a ToC (a very important feature of a good book, and it has to be semantic markup-based when you decouple the text from the view by omitting explicit pagination) for free.replyThe_Colonel 20 hours ago | root | parent | next [\u2013]HTML is also semantic. It also has a good standard, its support is omnipresent, is extensible, actually supports tables etc.replyghnws 1 day ago | parent | prev | next [\u2013]That looks like a great tool!I write a lot of documentation as part of my job and having Markdown side by side with the rendered output is great. Once you get the hang of the syntax, markdown is so much faster to write than using any text editor like Word. Just writing a list in text editors is painful.replygiraffe_lady 20 hours ago | parent | prev | next [\u2013]There is a lot of nuance and complication to typesetting books that isn't apparent to an untrained observer, and markdown + css simply isn't sophisticated enough to handle it. Even html/css + js is technically capable but far far behind the state of the art in digital typesetting.This is also a very classic \"well I could do it better\" engineer trap so please don't assume that without some research. It's an ancient domain relative to what we're talking about here and has accumulated a lot of valuable insight & technique that should not be simply discarded because markdown is almost good enough for some things.replygglitch 16 hours ago | root | parent | next [\u2013]Do you have recommendations? (La)TeX, maybe, or *roff?replygiraffe_lady 16 hours ago | root | parent | next [\u2013]I don't have any professional typesetting experience, just some adjacency from having done some work for a type foundry at one point, that gave me some insight into how much actually goes into it.Most professionals use expensive professional software for it. Latex or pollen or other pure markup solutions only work for smallish documents, or digital ones. Once you're going to print, esp in different formats, you need to care about page imposition, aligning with folios & signatures, widows & orphans etc. Just generally the physical reality of paper leaking into your abstraction of \"the book\" in ways markup alone can't accommodate.replyasicsp 1 day ago | prev | next [\u2013]I found mdBook easy to use, especially like that users can choose themes. I primarily use it for online version of my ebooks [0] and curated resources [1][2][0] https://github.com/learnbyexample/scripting_course#ebooks[1] https://learnbyexample.github.io/py_resources/[2] https://learnbyexample.github.io/curated_resources/replyusrme 1 day ago | prev | next [\u2013]I haven't seen the newcomer Starlight[1] being mentioned, so just throwing that out there as well. It's by the wonderful folks who created Astro[2] and my own limited usage of it has been great![1]: https://starlight.astro.build/[2]: https://astro.build/replyElCapitanMarkla 1 day ago | parent | next [\u2013]My friend introduced me to Astro the otherday. I have a few Gatsby projects under my belt but I could never really get into it, Astra looks fantastic compared to itreplyharry8 1 day ago | prev | next [\u2013]Way to bury the lede.Like gitbook but Free.The rust zealotry put me right off fwiw. As it does my interest in the language itself. I wish those guys would calm down they're totally detracting from whatever the strengths of rust are with that nonsense.edit: gitbook pricing for comparison https://www.gitbook.com/pricingreplyrapnie 1 day ago | parent | next [\u2013]I don't think it is zealotry. They offer features explicitly for Rust programmers, and the major examples of the project's use are by Rust itself.> Automated testing of Rust code samples> mdBook is used by the Rust programming language project, and The Rust Programming Language book is another fine example of mdBook in action.replyvalbaca 1 day ago | parent | prev | next [\u2013]What zealotry? Rust isn't mentioned until the last two points of eight:mdBook is a command line tool to create books with Markdown. It is ideal for creating product or API documentation, tutorials, course materials or anything that requires a clean, easily navigable and customizable presentation.- Lightweight Markdown syntax helps you focus more on your content - Integrated search support - Color syntax highlighting for code blocks for many different languages - Theme files allow customizing the formatting of the output - Preprocessors can provide extensions for custom syntax and modifying content - Backends can render the output to multiple formats - Written in Rust for speed, safety, and simplicity - Automated testing of Rust code samplesIt mentions Rust because it's written in Rust and used by the Rust project.In other words, the project wouldn't exist without Rust butreplyharry8 1 day ago | root | parent | next [\u2013]> What zealotry?The headline has been silently edited, hence the confusion. I don't much care for silent editing for just this reason.replyxcdzvyn 1 day ago | parent | prev | next [\u2013]I think they'd be best served not using the words \"Rust\" nor \"GitBook\" in their marketing, given it lacks most of the features of GitBook (that's probably why it isn't free!); mdBook appears to just be a static site generator.replypietroppeter 1 day ago | prev | next [\u2013]Md book is great! We created a Nim version to support content written with nimib (a framework to publish html pages with Nim code and its results) and it has been very useful! https://pietroppeter.github.io/nimibook/index.htmlAs people are sharing other SSG (I think material for MkDocs is the absolute best for documentation sites), let me share a relatively unknown one that I find very interesting: https://github.com/dmulholl/arkI have as next project to try and port this ark to Nim/nimib (and ideally nimibook should be refactored to use it).replycheela 1 day ago | parent | next [\u2013]It\u2019s also surprisingly nice for things other than documentation, such as personal notes or journals. Or even novels:https://mdpub.github.io/cheela/replyhoofhearted 15 hours ago | prev | next [\u2013]I have used a number of different solutions over the years for simple documentation. Started with Wordpress, ended up on Docusaurus.Docusaurus is an amazing tool for startups, but it started to show its weaknesses as we tried to scale it.Our project requirements needed something more, so I ended up forking Docusaurus and started working on my own free open-source solution.Check it out, I\u2019d love to hear what everyone thinks! :)https://github.com/elegantframework/elegant-clihttps://www.elegantframework.com/docs/installationreplygilmi 1 day ago | prev | next [\u2013]I've written an online book with mdbook (https://lhbg-book.link) and it was a breeze. I believe mdbook was one of the reasons I even finished the book.1. It's super easy to install. If you have a rust toolchain, just `cargo install mdbook`2. One command to initialize: `mdbook init my-book`3. One command to get immediate continuous feedback: `mdbook serve`4. It allowed me to keep writing in my preferred environment (emacs)5. It looked good by default. I could focus on the content.6. Setting up auto deploy ci on github is about 30 lines for yamlThough one point of improvement would be better support for other export formats such as pdf and epub.tl;dr mdbook allowed me to use the path of least resistence to complete my project, and I highly recommend it.Also it is possible other platforms can do the same or better but I haven't tried them.replymraza007 1 day ago | parent | next [\u2013]I have been planning to learn haskell thanks for sharing the bookreplygilmi 1 day ago | root | parent | next [\u2013]you welcome :)replymr_o47 1 day ago | prev | next [\u2013]I have been using Mdbook for a while and its been great,I maintain a simple knowledge base for myself https://til-mraza007.vercel.app/I love how simple it isreplygbraad 1 day ago | parent | next [\u2013]You might have to update the Bluetooth article; you do not stop bluetooth with 'enable' ;-)replygbraad 19 hours ago | root | parent | next [\u2013]MkDocs with Obsidian Mkdocs? https://obsidian-publisher.netlify.appreplymr_o47 16 hours ago | root | parent | prev | next [\u2013]Thank you for pointing out its a mistake on my endreplygbraad 16 hours ago | root | parent | next [\u2013]these things happen; copy-paste and moved on...replypickledish 1 day ago | prev | next [\u2013]Since I see a few people in these comments mourning the general dive that gitbook has taken over the last few years, you might like this, an actively-maintained fork of gitbook as it was before it got bad:https://github.com/honkit/honkitI don\u2019t spent a lot of time looking at these SSGs, so this one\u2019s still my favoritereplydylanowen 1 day ago | prev | next [\u2013]I love MdBook. It's also dirt simple to customize it with plugins or rendering backends: * https://github.com/dylanowen/mdbook-graphviz * https://github.com/dylanowen/mdbook-confluencereplyfrafra 1 day ago | parent | next [\u2013]You might be interested in https://kroki.io and https://github.com/JoelCourtney/mdbook-kroki-preprocessor.replydylanowen 22 hours ago | root | parent | next [\u2013]Oh nice! This has so many great diagramming tools I'm now learning about.replythrowawaaarrgh 1 day ago | prev | next [\u2013]> It is ideal for creating product or API documentation, tutorials, course materials or anything that requires a clean, easily navigable and customizable presentation.Markdown is really crap for any of that.Any real writer knows that the best way to communicate an idea quickly and effectively is to present it the right way. Markdown does not have good presentation. It was not designed for good presentation. It was designed to write an incredibly basic-looking document, such that the plaintext and rendered document look similar.I know this is going to be a shock to everyone. But it turns out that ASCII isn't the best way to encode presentation. On behalf of the poor SOBs that have to read what you churn out: Please stop subjecting people to your shitty presentation and get a real document format. Thanks.replyrcarmo 1 day ago | parent | next [\u2013]I disagree. All it takes is a CSS file, some semantic HTML in the right places and some inline Mermaid diagrams and you have a pretty decent document. I routinely write one-pagers, memos and architecture summaries in Markdown and generate PDFs with weasyprint (or even just iOS\u2019s print to PDF feature), and all I use is a print CSS file and whatever JS is required to render the diagrams.I would love to not use a browser engine at all (and moderately detest Mermaid because it cannot work fully in-memory without instantiating one), but it works.replytoastal 1 day ago | parent | prev | next [\u2013]> *Note:* my complete disregard for <blockquote> semantics because I wanted to put a box around something, but my lightweight syntax doesn\u2019t offer richer features##### This* is not a* definition listreplychrisco255 23 hours ago | parent | prev | next [\u2013]You know that HTML is valid in Markdown, right?replycsk111165 1 day ago | prev | next [\u2013]It suggest that , when I use build command it gives html files, what if I want to compile all these in PDF format? Since PDF format is quite suitable for all the ebooksreplyjs2 1 day ago | prev | next [\u2013]For producing online documentation, how does this compare to MkDocs?replyklodolph 1 day ago | parent | next [\u2013]I\u2019ve used both, I recommend MkDocs over MdBook for most people. MdBook is simpler and easier to get started with, MkDocs has more features, more plugins, more themes. Both MkDocs and MdBook are easy to use. IMO, MdBook is a little too simple.Recommend using the material design theme for MkDocs as a starting point. If you are working on a Rust project, use MdBook instead. If you have lots of docs / multiple projects / multiple versions, use Antora. If you want cooler landing pages, use Jekyll.replypotatochup 1 day ago | parent | prev | next [\u2013]Embarrisngly, I'm using both for docs at work (they were both projects I started).Mkdocs is more flexible, has more themes, better ecosystem. Mdbook has better defaults, easier deployment, is more standard across rust projectsreplyd4rkp4ttern 22 hours ago | prev | next [\u2013]Anyone know what Qdrant uses in their doc pages? I really like the style.https://qdrant.tech/documentation/quick-start/#replykacperlukawski 21 hours ago | parent | next [\u2013]It's Hugo, with a custom styling. https://gohugo.io/documentation/replygbraad 1 day ago | prev | next [\u2013]I used to do this with GitBook, but it has not seem active development for some time. Wonder how easy it would be to move from GitBook to an Obsidian workflow with mdbook. The links are written like a wiki as [[]]. Would this tool understand?replygbraad 1 day ago | parent | next [\u2013]Found: https://github.com/zoni/obsidian-export but hope this can be part of a single solution.replyfreediver 1 day ago | prev | next [\u2013]Shout out to MdBook, this is what powers Kagi documentation currently.https://help.kagi.com/kagi/index.htmlreplyra1n 1 day ago | prev | next [\u2013]I have been wondering about using a set of *nix tools backed by a git repository as a planner/diary. This tool seems to be an interesting addition for the presentation front.replybad_username 1 day ago | prev | next [\u2013]> The options and formatting will be different for other output formats such as PDF.This is the only reference to PDF in the documentation. Is it possible to render a PDF (presuming a single file)?replylfo 1 day ago | parent | next [\u2013]They know pandoc won MD to PDF battle. https://youtu.be/3f9YvjqUTlwreplynovakinblood 22 hours ago | prev | next [\u2013]My unconscious bias made me read this as \u201cMaryland Book\u201d.replyShadowBanThis01 1 day ago | prev | next [\u2013]Why? I'm mystified as to why there are vanishingly few VIEWERS for Markdown. One open-source project after another offers up .md files for documentation, but have you ever tried to find a plain VIEWER for Markdown?replywwtdtgotiatl 23 hours ago | parent | next [\u2013]vscode has one built in ctrl + shift + vreplyShadowBanThis01 20 hours ago | root | parent | next [\u2013]Thanks, but I mean a dedicated viewer\u2026 not an editor that has preview capability. There are several of those.Just a lightweight viewer.replyxwowsersx 1 day ago | prev [\u2013]Me: Are we past \"x but in Rust\" where Rust is a totally irrelevant internal detail I don't \u2014 nor should anyone \u2014 care about?[Checks HN]: Nope.replykinghajj 1 day ago | parent | next [\u2013]Eh, in this case it's a tool created by Rust programmers for generating documentation for the Rust language, and has particular features for validation of Rust code snippets in said documentation. I think in this case, mentioning Rust in the description is reasonable.replyliberty-dreamer 1 day ago | parent | prev | next [\u2013]Well, if it is implemented in Rust, then who cares whether it works or not? It's implemented in Rust!replymetabagel 1 day ago | root | parent | next [\u2013]The good thing is you don\u2019t have to rewrite it!replytimeon 1 day ago | parent | prev | next [\u2013]I hope not since I use it as keyword filter in my RSS feed. Why are you bothered?replyvalbaca 1 day ago | parent | prev [\u2013]It matters in that it helps people contribute, which contributes to growth.Oh. and it's free.replyGuidelines | FAQ | Lists | API | Security | Legal | Apply to YC | ContactSearch:",
    "hn_summary": "- MdBook is a command line tool used to create books with Markdown.\n- It is ideal for creating product or API documentation, tutorials, course materials, or anything that requires a clean, easily navigable, and customizable presentation.\n- MdBook is lightweight, easy to install, and has integrated search support, color syntax highlighting for code blocks in various languages, and the ability to render output in multiple formats.\n- It has been used by the Rust programming language project, and The Rust Programming Language book is an example of mdBook in action.\n- MdBook is actively maintained and has an active community of contributors."
  },
  {
    "id": 36539235,
    "timestamp": 1688147392,
    "title": "Case study: Algorithmic trading with Go",
    "url": "https://polygon.io/blog/case-study-algorithmict-trading-with-go/",
    "hn_url": "http://news.ycombinator.com/item?id=36539235",
    "content": "30 JUNE 2023/CASE STUDYCase Study: Algorithmic Trading With GoIn this case study, we are excited to share an insider's perspective and look under the hood of how a Polygon.io customer built an automated retail trading bot that is capable of monitoring the entire stock market in real-time. We now pass the baton to Justin, who will narrate his own captivating journey.Hi, I'm Justin. The early versions of my bot could have easily won an award for 'The Fastest Money-Losing Machine Ever'. But, after lots of trial and error, and iterative improvements, it evolved into a breakeven machine, and sometimes even turns a profit. It remains a work in progress, but the trajectory is promising. I wanted to share my story as a blueprint for those who might want to attempt something similar.No tale of algorithmic trading would be complete without the obligatory screenshot of an impressive multi-monitor setup. Behold my data-driven empire, brought to life on three vertical 4K screens.So, buckle up and join me as we navigate the exciting crossroads of finance, programming, and data analytics.The ChallengeHave you ever had one of those ideas that you cannot shake? Sort of like a song that gets stuck in your head? Well, I've had that but for this stock trend following idea. The goal here is to automate the execution and management of around 500 short lived trades across the entire stock market and then take small profits off each trade.My attempts at doing this manually underscored why this needed to be automated. First, there was the issue of human bandwidth, the risk associated with pouring all my investment into a single stock was astronomical, yet monitoring tens of short-lived bets was a task beyond my ability. Second, this strategy only worked with highly liquid stocks that allowed swift in-and-out trading, and even then, I did not want to acquire too many shares to make for faster fills at prices I liked.Position management proved to be a massive issue for me. How do you track multiple bets, say 25+ at a time, all while timing the entries and exits was very complex. There was also the question of scalability. The strategy I am using only works with smaller amounts of money, so as my bank roll increased so did the amount of bets needed. Finally, the costs associated with trading - price spread, commissions, price slippage, API fees, and taxes - all need to be calculated quickly to see if this trade even makes sense. That\u2019s how I started to explore automating it.The SolutionThe journey to develop an automated trading tool capable of monitoring over 5500+ stocks on the NYSE and NASDAQ in real-time and making quick trading decisions has taken a few years. It has been a constant cycle of trial, error, and lots of tweaking, a far cry from the few months I initially anticipated. The application is running under Linux on a high-powered gaming system with 16 cores, 128GB of RAM, and 8TB of NVMe storage via a 1Gbps internet connection.Here is a breakdown of the three fundamental components:Data Provider: Initially, I had no idea what to even search for here? Candlestick data? What was tick data? This was a massive learning curve and finding a reliable data feed had so many obstacles. Many providers had unconventional APIs, insisted on using their preferred programming languages, or required installation of obscure libraries. My lack of knowledge combined with these other factors created a highly cumbersome process. However, I hit the jackpot with Polygon.io. They have both historical and real-time data coverage of the entire market, developer friendly and intuitive APIs, and amazing documentation and libraries. I cannot express how much they stood out compared to everyone else. They also had a simple pricing model that gives you access to all market data without artificial limits like other providers.The Application: This Go app is basically the heart of the solution. It ingests and interprets the data feeds, makes calculated trading decisions, and translates these decisions into buy and sell orders. These orders are then sent to the broker API for execution. We will dive deeper into the specifics of the application in the following section.The Broker: When it came to finding a broker, my regular brokerage account did not provide an API. While I would like to say that I conducted extensive search, in reality, a quick Google search revealed that Interactive Brokers was the go-to choice for many. After checking their APIs and finding them to be quite straightforward, I decided to go with them.Why Go, you might be asking yourself? A quick glance at any hedge fund job posting reveals that the industry leans heavily towards C++ and Python. But this project was for me. Having used Go for many years, I found it to be an excellent fit for processing a stream of data and interacting with another API. So, it just seemed so obvious.Let's break down the main functions of the Go application:Data Ingestion Loop: This function is responsible for continuously gathering real-time data from over 5500+ stocks via polygon.io. The quality of data ingested at this step directly impacts every subsequent operation, so you want to put a lot of thought into this step and make it as simple as possible. Initially, I tried storing the data in a database but quickly realized that it couldn't handle the high volume of events (upwards of 60k+ events per second at market open and close). Instead, I opted to store everything in memory and have not looked back.Build Our View Of The Stock Market: The application uses the ingested data to create a real-time, in-memory view of the entire market, tracking every stock (price, spread, trading activity, etc). This custom view allows the system to spot and trade on opportunities way before they hit mainstream news. This also gives you access to pre-market, regular market, and after hours trading activity.BUY Signal Loop: Upon spotting an opportunity, this function sends the broker an API request to place a buy order. But it's not just a simple trigger. The function carries out pre-calculations such as estimating profit based on price spread, determining the number of shares needed, and factors in commissions and taxes. It also incorporates logic for situations where the price moves, or where we only get a partial fill, or maybe need to cancel the order if it doesn\u2019t make sense any more.Position Tracking System: Once trades are executed and we own stock, it's vital to monitor the positions. I consider this system like a vigilant shepherd overseeing its flock of positions. Essentially, it is a loop that continuously compares the position table with current prices, tracking gains and losses in real-time. There is also a GUI here where you can go and inspect the trade to see why it was triggered, what the current state is, and when it would sell. This has been instrumental in helping me refine the logic for the BUY and SELL loops.SELL Signal Loop: As crucial as knowing when to buy is knowing when to sell. This function calls the broker API to execute a sell order when the system detects a good exit (nice profit or we are losing too much money). Similar to the BUY function, this one incorporates complex logic too. It manages scenarios like updating the price for fast-moving stocks and handling partial fills.At a glance, the core components might seem straightforward, but as time goes by and you encounter various corner cases, you will inevitably add more logic to these areas.ScreenshotsHaving a built- in web interface has been immensely helpful in understanding the inner workings of a complex project, in that you can explore all of the data structures, visualize data, and dive deep into trades and see why they were triggered and their current status. To help bring this to life, I have included a series of screenshots. These not only offer a glimpse into the user interface of the trading system but also provide visual demonstrations of the system's key structural and functional elements.This is an overview of all 5500+ tickers, complete with their prices, spread, and other relevant data.This is a specific symbol page for Tesla (TSLA), showing tick bars and other pertinent information.This interface displays the win/loss ratios and current open positions for active trades. You can see for this session we're down about -$900. This bot doesn't win all the time that's for sure.Here you'll see a live trade in action, complete with all its associated metadata and an accompanying chart to visualize the trade's progress. The orange line is where we bought 24 shares.Lastly, a glimpse into the console that logs real-time events such as order placements, both buying and selling.I hope these screenshots have shed some light on the inner workings of this trading tool and helped illustrate the key functionalities more vividly. My aim was to bring the abstract concepts and processes to life, making it easier for you to understand and appreciate the complexities of the system.Strategy Development and BacktestingYou might be expecting to read about specific strategies and perhaps their associated Sharpe ratios. However, you won't find that here. I think of the Go application, the strategies it employs, and backtesting as three distinct, yet equally crucial components. My primary focus has been on creating my own platform that allows me to test and run custom strategies in real-time, and also to backtest them. This aspect, the platform itself, seems to be often overlooked in most discussions. Many conversations revolve around strategies (mean reversion, trend following, linear regression, etc.), and backtesting, without fully addressing the practical mechanics or logistics of strategy implementation, particularly in the context of live, intraday trading.In parallel to developing this platform, I've been leveraging the a wide range of historical trade and quote data provided by Polygon.io. This data is fundamental for exploring strategies using Python and backtesting them. Hence, the reason for the 8TB of NVMe storage on my machine. This approach enables me to download and structure the data, and then brainstorm and visualize potential trades. While it's often said that backtesting is akin to trying to drive forward while looking in the rearview mirror, it provides a valuable sanity check and offers insight into past performance. This helps me to make educated guesses, especially about spread, taxes, commissions, entry, and exit points, among other factors.Ultimately, the insights gleaned from strategy development and backtesting are translated into logic that is incorporated into the 'BUY signal loop'. Algorithmic trading may sound sophisticated, but at its core, it's about identifying trends and patterns and trying to capture them programmatically.Now that we've covered the overview, let's delve into some pseudocode to understand how it all comes together.Code ExamplesIn the interest of giving you a more concrete understanding of how this system functions, I have included some high-level pseudo code and actual Go code samples below. These snippets provide a simplified depiction of the system's structure and the logical flow it follows. Please note that the Go code, while outlining the essential data structures and steps, is not functional and just example code (the real app is around 7k lines). It's merely a high-level depiction of how you might set up the primary data structures and routines in Go.Create an empty map for symbolsCreate a websocket connection to the trades and quotes websocket data feedsWhile the websocket connection is open:  Wait for events from the websocket    If the event has a stock symbol (aka ticker):    Extract the stock symbol from the event        If the symbol is not in the symbol aggregates:      Add the symbol to the symbol map (our in-memory index of all symbols)          Update the symbol with the event data (add tick and quote data)    Build a custom aggregate that merges tick and quote data (enrich data)        For each aggregate in the symbol aggregates:      If the aggregate triggers a buy event:        Execute the buy event (if we do do not already own it)    If we have an open position for this symbol (aka ticker):      Check the status and see if we need to sell        Execute the sell eventHere's what that sort of looks like in Go. This code doesn't work but gives you the high-level details of the major data structures.type TrackedSymbols struct { Symbol       map[string]*Symbol // symbol map TradingEnabled   bool        // auto trading on/off L          sync.Mutex     // global lock}type Symbol struct { Symbol     string      // TSLA, AAPL, etc RawTrades    []TradeEvent   // unprocessed trades RawQuotes    []QuoteEvent   // unprocessed quotes Aggregates   []Aggregate   // combined trades + quotes into tick bars Positions    []Position    // order tracking ...}type TradeEvent struct {  // Define the trade event structure, like symbol, price, volume, etc.}type QuoteEvent struct {  // Define the quote event structure, like symbol, price, volume, etc.}type Aggregate struct {  // Define the aggregate structure}type Position struct {  // Define how you want to track orders}var trackedSymbols TrackedSymbolsfunc main() {  // init the global map  trackedSymbols.Symbol = make(map[string]*Symbol)  // connect to polygon.io websocket for trades and quotes  // data ingestion loop  for {   // read messages    _, message, err := c.ReadMessage()    // parse trades and quote events (lots of logic in here for event types)    event := parseEvent(message)    // have we seen this symbol before?    if _, ok := trackedSymbols.Symbol[event.Symbol]; ok {      trackedSymbols.Symbol[event.Symbol] = Symbol{Symbol: event.Symbol}    }    // logic to turn trades + quotes into aggregates    // use go channel to signal buy and sell logic  }  // new price event; buy loop  for {    // loops over all trackedSymbols.Symbol looking for buy signals    // all your super secret signal trigger stuff goes here  }  // new price event; sell loop  for {    // loops over all trackedSymbols.Symbol.Positions looking for sell signals  }  // http server that enables you to inspect everything  // - trackedSymbols.Symbol (all symbols)  // - trackedSymbols.Symbol.Positions (all trades)  // - build and view custom watch lists}The code presented here barely scratches the surface and is intended to providing a glimpse into the thought process and structure behind it. This includes defining key data structures, maintaining an in-memory index of symbols, handling real-time events, and integrating buy and sell trade logic. For a fully functional trading bot, you would need to incorporate much more sophisticated features but hopefully you get the idea.Lessons LearnedCreating an automated trading tool has been nothing short of an adventure that crosses multiple domains, from finance and programming to data analytics. Through this project, I have come to learn and appreciate the complexity of the stock market and how hundreds of billions of dollars change hands each day. There are countless trading strategies out there and having your own platform to play around with them is incredibly cool. Once you have a system like this you cannot easily go back to a normal broker since you feel blind. I wanted to share of the key lessons out of all this:Understanding Abstractions: The stock market, and exchanges like NYSE are NASDAQ, are not monolithic entities but are actually large distributed systems built up from 19+ exchanges, each with its own quirks and features. Candlestick data is a massive abstraction built from raw trade or tick data, and understanding these abstractions at a deep level is essential. Then you have market trading times such as pre-market, regular market, or after-hours where different rules apply. Getting as close to the source data as possible and thoroughly understanding its origins and usage will significantly enhance your ability to leverage it.Order Management: It is not as simple as sending buy and sell orders. Factors such as pre-computed position sizing (the number of shares to buy and your total money percentage), the ability to quickly buy and sell shares, having the ability to manage 25+ active positions and act on them instantly, tax and commission calculations, slippage management, and order state monitoring all contribute significantly to successful trading.Edge Cases: Order execution, tracking, modifications, cancellations, partial orders, market halts and more, there are so many edge cases to consider and these cost you money if you miss something. It is absolutely essential to test these scenarios with simulated money, also known as paper trading, rather than real funds to minimize potential losses. I lost a lot of money when my system detected a trend in the pre-market and the stock jumped 40%, I bought at the absolute high, and then it quickly dropped, and my system did not adjust the sell order correctly. I basically lost 40% on that trade in minutes. You can make and lose money extremely fast in pre-market or after hours trading sessions since the normal market rules are different and you can see wild swings take place extremely quickly.Embrace Randomness: Many of us might be tempted to think that the key to a successful trading bot lies in discovering some secret, all-powerful strategy. While strategies are undeniably important, they are not everything. One of the most valuable lessons I learned was the utility of random buying to test the core functionalities of the system. For example, try to make 1000 trades per day across random stocks for a week and you'll learn so much about your system. By introducing random buy orders into the system, you can effectively test your buying and selling logic, manage partial fills, test cancel logic, and critically evaluate the overall position tracking system. Does your system keep track of them as expected? Can you delve into the trade details? Do the positions exit based on the established criteria? Is the logging working as intended? I incorporated random stock buying using my paper trading account into my testing process, which turned out to be an incredibly efficient way to verify multiple aspects of the system simultaneously. Not to mention, it made testing a lot more unpredictable and fun.Tick Bars vs Time Bars: When you look at a candlestick bar offered by your broker, it will have an open, high, low, close, number of trades, volume, etc, this covers a known time frame, for example 30 seconds. However, the issue here is that there are times where the market is moving extremely quickly and not all bars are created equally, some might have 100 trades while others have 1,000s of trades in the same time span. So, I am taking the raw tick and quote data and building my own bars based off a set number of trades. This not only provides much better resolutions during times of increased trade activity, like market open and close, but also enables me to add in things like price spread, and other custom metrics. This is where really understanding the data you are using comes in and you can build your own abstractions rather than using someone else's.Going In-Memory: In the early stages, I faced numerous challenges attempting to maintain state in a database because of the large spikes in activity around market open and close. Eventually, I decided to go entirely in-memory, utilizing a large map with mutex locking that virtually every component of my system interacts with. Although it was very challenging to construct and debug, this solution ultimately solved all my scalability issues. I configured the system to dump the struct that holds all data into a compressed gob file for storage, with a method to reload it in case I needed to restart the application. It can grow to be 40GB+ throughout the day and I needed to patch the Go build to support dumping gobs this large. This ensured no loss of my stateful data. Another lesson learned the hard way was the need for uninterruptible power supply. I found this out when a power outage occurred while my system was live. Without power, I lost all state data, leaving my positions unmonitored. A proper power backup system became a necessity to prevent such incidents from occurring in the future.Complex and Lonely: This project proved much more challenging and time-consuming than initially anticipated. As I said, this has turned from a minor hobby into a full blown obsession. It can be lonely too. All you are basically doing is trying to increase the money in your account. This can be an extremely wild roller costing.Using Go and Python: I have moved to a hybrid approach where my trading system is written in Go but I do most of my data exploring in Python just because it has extensive data science libraries, and it simplified certain aspects of looking at data or trying to find patterns.Leveraging Personal Computers: Modern desktop PCs are extremely powerful and able to handle real-time monitoring of the entire stock market if you hack on it enough.ChatGPT enters the Chat: ChatGPT has been a game-changer for me. With it, I can easily ask questions, use it for sanity checks, and even have it generate code. I went from not knowing how to solve a problem, blindly googling around and reading books, to just telling ChatGPT the problem, and then asking how it would solve it, then asking it to code the solution. This is absolutely insane and has easily 3x my productivity.In retrospect, I would probably keep adding things here. For example, hunting down all types of market anomalies, things like the meme stock adventures, wild IPO events, market booms and busts, Fed news and interest rate hikes, all this just in the last few years. It\u2019s pretty cool to have your own system to look at all this stuff, detect it, and then see it appear in the news. You definitely feel like you have a front row seat when market events are unfolding right in front of you.ResourcesI hope you found this at least entertaining and a somewhat useful guide, even if you are just interested in paper trading for now. Diving into a project like this allows you to gain a wealth of knowledge about programming, the stock market, and data analysis. Also, these insights and skills are likely to directly apply to problems you will encounter in your professional life too. I want to share a list of resources that I found invaluable during my journey.Mathematics With Applications In FinanceQuantitative Finance Stack Exchangereddit.com/r/algotradingAdvances in Financial Machine LearningQuantitative Trading: How to Build Your Own Algorithmic Trading BusinessSystematic Trading: A unique new method for designing trading and investing systemsAlgorithmic Trading: Winning Strategies and Their RationaleTrading Systems 2nd edition: A new approach to system development and portfolio optimisationMachine Learning for Algorithmic Trading: Predictive models to extract signals from market and alternative data for systematic trading strategies with Python, 2nd EditionImplementing Derivative ModelsFirst Course in Probability, ABayesian Statistics the Fun Way: Understanding Statistics and Probability with Star Wars, LEGO, and Rubber DucksThe Man Who Solved the Market: How Jim Simons Launched the Quant RevolutionOption Volatility and Pricing: Advanced Trading Strategies and Techniques, 2nd EditionSubscribe to Polygon.ioGet the latest posts delivered right to your inboxSubscribeTeam PolygonRead more posts by this author.Read More",
    "summary": "- This case study explores the development of an automated retail trading bot using the programming language Go.\n- The bot is capable of monitoring the entire stock market in real-time and making quick trading decisions.\n- The study provides insights into the challenges faced, the solution implemented, and key lessons learned during the development process.",
    "hn_title": "Case study: Algorithmic trading with Go",
    "original_title": "Case study: Algorithmic trading with Go",
    "score": 396,
    "hn_content": "- The post discusses the author's experience building an algorithmic trading system using Go.\n- It emphasizes the importance of having a solid platform for strategy implementation, rather than focusing solely on trading strategies.\n- The trading industry is highly competitive and regulated, requiring top talent and robust trading systems.\n- High-frequency trading (HFT) operates on a different level than other market participants, with races to enter/exit lasting only a few seconds or microseconds.\n- Building a low-latency software trading system is not as time-consuming or costly as it may seem, depending on the complexity of the system and trading venue specifics.\n- The post raises questions about the allocation of top talent to activities like fintech and advertising, rather than more socially beneficial endeavors.\n- It acknowledges the utility of advertisements but highlights the industry's susceptibility to scams and grift.\n- The discussion extends to the role of capitalism and efficient markets in society.\n- The post mentions the potential role of index funds and supermarkets in driving technological advancements.\n- Inequality and rising levels of poverty are mentioned as counterarguments.\n- The value of liquidity in markets, particularly in HFT, is emphasized.\n- The article showcases the benefits of using Go for algorithmic trading, despite it not being the most widely used language in the industry.\n- The author shares their approach to plugging in various trading strategies and the process of backtesting using raw trades/quotes data.\n- The post mentions the prevalence of scams and the difficulty of developing successful trading algorithms unless one has significant expertise.\n- The importance of risk management and the limitations of individual trading strategies are discussed.\n- Some readers express interest in forming a community or chat group to discuss algorithmic trading.- The author discusses their experience building a trading bot using the Interactive Brokers API.\n- They explain the challenges they faced, such as scale and data cleaning, and share their strategies for managing risk.\n- The author mentions the importance of having a reliable power supply and the potential consequences of network or power outages during trading.\n- They also discuss the concept of high-frequency trading (HFT) and its impact on the market, highlighting the benefits of liquidity and lower costs.\n- The author emphasizes the competitive nature of the HFT industry and the continuous improvement in market efficiency.\n- They address the question of whether their trading bot has been able to outperform the market and become highly successful, stating that they have not yet achieved that level of success.\n- The post sparks a discussion among readers about HFT, its impact, and the need for regulatory measures.\n- Some readers express skepticism about the profitability of HFT strategies and question the fairness and transparency of the market.\n- There is also debate about market structure and the role of exchanges in providing liquidity and efficient trading.\n- The author shares their perspective as a practitioner in the field and highlights the continuous reduction in intermediation costs and improvement in efficiency in capital markets.\n- The conversation touches on topics such as the effects of regulations, the role of dark pools and internalizers, and the impact of HFT on retail traders.\n- The discussion highlights differing opinions and experiences regarding HFT and its overall impact on the financial markets.",
    "hn_summary": "- The post discusses the author's experience building an algorithmic trading system using Go, emphasizing the importance of a solid platform for strategy implementation.\n- The post raises questions about the allocation of top talent to fintech and advertising rather than socially beneficial endeavors, highlighting the susceptibility of the trading industry to scams.\n- The benefits of using Go for algorithmic trading are showcased, despite it not being the most widely used language, and the importance of risk management and the limitations of individual trading strategies are discussed."
  },
  {
    "id": 36531485,
    "timestamp": 1688108630,
    "title": "How the great firewall of China detects & blocks fully encrypted traffic [pdf]",
    "url": "https://gfw.report/publications/usenixsecurity23/data/paper/paper.pdf",
    "hn_url": "http://news.ycombinator.com/item?id=36531485",
    "content": "- The author shares their experience and insights on algorithmic trading with Go.\n- The article focuses on the development of a trading platform and the practical mechanics of strategy implementation.\n- The author highlights the competitiveness and complexity of the trading industry.\n- Different strategies, such as mean reversion and trend following, are mentioned.\n- The author emphasizes the importance of having a solid platform as a foundation for implementing strategies.\n- The challenges of discussing trading strategies due to different participants playing different games are mentioned.\n- The author shares their perspective on the allocation of talent in the fintech industry.\n- The discussion extends to the impact of financial advertising and the role of ads in business.\n- The debate on the impact of capitalism and efficient markets is briefly touched upon.\n- The article generates interest among tech-savvy individuals due to its exploration of algorithmic trading with Go and the practical insights shared by the author.- The author discusses the challenges of algorithmic trading and the impact of increasing bank roll on betting strategies.\n- Warren Buffet's comments on the difficulty of achieving high returns with larger sums of money are mentioned.\n- The article mentions the use of a platform and trend following strategies in algorithmic trading.\n- The author discusses the importance of managing risk in algorithmic trading and shares personal experiences of losses.\n- The concept of compounding returns is explored.\n- The use of the Martingale betting system is referenced.\n- The potential benefits and drawbacks of shorting stocks in algorithmic trading are mentioned.\n- The author highlights the role of technical analysis in trading strategies and the importance of understanding market jargon.\n- The impact of infrastructure issues, such as power outages, on trading activity is discussed.\n- The benefits of using the Interactive Brokers API for trading are mentioned.\n- The author shares his experience with the Interactive Brokers API and his struggles with existing libraries.\n- The potential for partnership or collaboration in the field of algorithmic trading is mentioned.\n- The challenges of algorithmic trading and the risks associated with financial investments are acknowledged.\n- The author reflects on his personal experiences and regrets in the field of algorithmic trading.\n- The role of high-frequency trading (HFT) and its impact on the market are mentioned.\n- The importance of competition among exchanges and market participants is discussed.\n- The benefits of HFT in terms of liquidity provision and cost reduction are emphasized.\n- The idea of a single, regulated exchange is debated.\n- The potential risks and challenges of relying on a single exchange are mentioned.\n- The role of market makers in providing liquidity is explained.\n- The author suggests cracking down on payment for order flow (PFOF) to reduce market-maker profits.\n- The author highlights the decreasing profits in the HFT industry over the years.\n- The benefits of HFT in terms of improved efficiency and reduced costs are discussed.\n- The limitations of relying on academic market models to understand HFT are mentioned.\n- The author encourages a better understanding of the financial markets and the role of HFT before forming opinions.",
    "summary": "- The article explores algorithmic trading with Go and provides practical insights into its development and implementation.\n- The author discusses the challenges and complexities of algorithmic trading, including managing risk and understanding market jargon.\n- The impact of high-frequency trading (HFT) on the market is discussed, highlighting its benefits in terms of liquidity provision and cost reduction, as well as the importance of competition among exchanges and market participants.",
    "hn_title": "How the great firewall of China detects and blocks fully encrypted traffic [pdf]",
    "original_title": "How the great firewall of China detects and blocks fully encrypted traffic [pdf]",
    "score": 346,
    "hn_content": "- The Great Firewall of China can detect and block fully encrypted traffic, including VPNs.\n- The use of unauthorized VPN services in China is illegal and can lead to potential legal risks.\n- The Chinese government's crackdown on VPNs is not limited to protecting its authority, as demonstrated by the case of Vera Zhou, who was arrested and sent to an internment camp for using a VPN to access her school homework.\n- The Chinese government enforces strict surveillance and control over its citizens, including monitoring their online activities.\n- The GFW has become increasingly sophisticated over the years and can block various circumvention techniques.\n- Some researchers have reverse-engineered the GFW's detection algorithm and found that it checks for low entropy in encrypted traffic.\n- There are ways to bypass the GFW, such as using obfuscated protocols like Shadowsocks or tunneling traffic through non-standard ports.\n- The GFW's efforts to control and monitor online communication can hinder internet freedom and limit access to information.\n- The GFW has inspired researchers and developers to create innovative circumvention tools and techniques.\n- The GFW's impact extends beyond China, as it has implications for internet freedom and censorship worldwide.- Tunneling traffic in China is getting blocked within the first minute\n- SSH proxies are popular but are also being blocked or slowed down\n- Wireguard is detected and blocked after a short usage\n- Fully encrypted traffic is being degraded, but steganography and protocol mimicry may work as circumvention strategies\n- China constantly updates their detection schemes and blocks traffic that doesn't match typical patterns\n- Trojan, Vision, and Hysteria are examples of GFW bypassing tools that masquerade as HTTPS\n- Implementing a MitM proxy for HTTPS traffic like many companies do is not feasible in China\n- Chinese citizens have limited access to websites like Google, Facebook, and Twitter\n- GFW authors are becoming more considerate of collateral damage, but VPN authors should maximize collateral damage to frustrate GFW\n- Mimicking common protocols and critical applications may help evade detection\n\nOverall, the GFW in China is becoming more sophisticated in detecting and blocking various circumvention techniques. Users are resorting to steganography and protocol mimicry as potential solutions, but the situation continues to evolve.",
    "hn_summary": "- The Great Firewall of China is capable of detecting and blocking fully encrypted traffic, including VPNs.\n- The Chinese government enforces strict surveillance and control over its citizens' online activities, with a crackdown on unauthorized VPN services.\n- Researchers and developers are constantly innovating circumvention tools and techniques to bypass the GFW's control and monitoring efforts."
  },
  {
    "id": 36529456,
    "timestamp": 1688088898,
    "title": "File for divorce from LLVM",
    "url": "https://github.com/ziglang/zig/issues/16270",
    "hn_url": "http://news.ycombinator.com/item?id=36529456",
    "content": "Skip to contentProductSolutionsOpen SourcePricingSign inSign upziglang/zigPublicSponsorNotificationsFork 1.7kStar 23.6kCodeIssues2.3kPull requests118ActionsProjects3WikiSecurityInsightsNew issueFile for Divorce from LLVM #16270Open2 of 19 tasksandrewrk opened this issue yesterdayJun 29, 2023 \u00b7 124 commentsyesterdayThis issue suggests modifications. If it also has the \"accepted\" label then it is planned.CommentsMemberandrewrk commented yesterdayJun 29, 2023 \u2022editedI'm sorry honey, it's just not working out. Our relationship worked when we were younger, but we're both older now and we've grown apart.This issue is to fully eliminate LLVM, Clang, and LLD libraries from the Zig project. The remaining ties to these projects are as follows:LLDMach-O (maintained by @kubkon)ELF (work in progress by @kubkon)COFFWebAssembly (work in progress by @Luukdegram)LLVMdirectly output LLVM bitcode rather than using LLVM's IRBuilder API #13265C backend (99% done) (@jacobly0 et al.)x86 backend (90% done) (@jacobly0, @kubkon, et al.)wasm backend (87% done) (@Luukdegram)aarch64 backendoptimization passesClangupstream Aro and use it for translate-c instead of clang #16268use Aro to compile C code instead of clang #16269C++ source files in zig's repository are built by clang when bootstrapping[WIP] src/windows_sdk.cpp: port to Zig #15657compiling assembly fileszig ar: a drop-in llvm-ar replacement #9828This will remove C++, Objective-C, and Objective-C++ compilation capabilities from Zig. In the near term, the machine code generated by Zig will become less competitive. Long-term, it may catch up or even surpass LLVM and GCC.In the near term it would also reduce the number of targets Zig supports, since LLVM has a nice laundry list. However, LLVM supports fewer targets than you think... we are constantly running into bugs and embarrassing O(N^2) code for pretty much every target except x86, aarch64, and webassembly. Long-term, Zig plans to have Contributor-Friendly IR, or something equivalent, to optimize for low maintenance for supporting many targets that LLVM would never even dream of, for example MOS #6502.Note that there would still be an LLVM backend for outputting .bc files (#13265), but the Zig compiler would lack the capability to compile .bc files into object files. LLVM or Clang would need to be installed and invoked separately for that use case.In exchange, Zig gains these benefits:All our bugs are belong to us.The compiler becomes trivial to build from source and to bootstrap with only a C compiler on the host system.We stop dealing with annoying problems introduced by Linux distributions and package managers such as Homebrew related to LLVM, Clang, and LLD. There have been and continue to be many.The Zig compiler binary goes from about 150 MiB to 5 MiB.Compilation speed is increased by orders of magnitude.We can implement our own optimization passes that push the state of the art of computing forward.We can attract research projects such as alive2We can attract direct contributions from Intel, ARM, RISC-V chip manufacturers, etc., who have a vested interest in making our machine code better on their CPUs.388InKryption, alichraghi, Beyley, Mindgibber, jtriley-eth, imlodinu, foucist, watsy0007, ccapitalK, guzba, and 378 more reacted with thumbs up emoji144MPLew-is, ringoz, musi-musi, loic-sharma, zexa, bermanboris, TeddyDD, zenith391, asiekierka, Jarred-Sumner, and 134 more reacted with thumbs down emoji46jvyden, viriw, andrewschaaf, lin72h, aelzeiny, vemv, thushan, mx0c, icylace, kaiserthe13th, and 36 more reacted with laugh emoji30lin72h, pietmichal, den-mentiei, imarko, unreal-skif, Senjosei, glepnir, mcela, jorangreef, Maeiky, and 20 more reacted with hooray emoji68scheibo, Jarred-Sumner, pdeva, Phalangers, zekexiao, RohanKapurDEV, yihongang, xdBronch, candrewlee14, smasher164, and 58 more reacted with confused emoji72mlugg, alichraghi, theoparis, Beyley, ianprime0509, batiati, usdogu, Mindgibber, jtriley-eth, imlodinu, and 62 more reacted with heart emoji67mlugg, travisstaloch, alichraghi, imlodinu, achille-roussel, GithubPrankster, foucist, andrewschaaf, artob, vithalreddy, and 57 more reacted with rocket emoji67rodrimati1992, Congee, 190n, chiumichael, aelzeiny, XVilka, taosx, sbseltzer, avimar, maleyva1, and 57 more reacted with eyes emojiandrewrk added the proposal This issue suggests modifications. If it also has the \"accepted\" label then it is planned.label yesterdayJun 29, 2023andrewrk added this to the 1.0.0 milestone yesterdayJun 29, 2023ContributorxdBronch commented yesterdayJun 29, 2023I see the 1.0.0 milestone for this, is it meant to be a blocker for 1.0? or simply the goalMemberAuthorandrewrk commented yesterdayJun 29, 2023The milestone, on an issue labeled \"proposal\", means that a decision must be made to accept or reject that proposal before tagging the release corresponding to that milestone.For an issue labeled \"accepted\", the milestone means that it must be implemented by then. So, if this proposal is accepted, then I will evaluate at that time which milestone to move it to.22rofrol, icylace, lin72h, iamevie, cassepipe, cristaloleg, unreal-skif, rice7th, serhiisp, jorangreef, and 12 more reacted with thumbs up emojiContributorJarred-Sumner commented yesterdayJun 29, 2023In the near term, the machine code generated by Zig will become less competitive. Long-term, it may catch up or even surpass LLVM and GCC.IMO, this is the biggest question. One of the most compelling reasons to use Zig is runtime performance of software written in Zig. Without LLVM's optimization passes, what will that look like?33anacrolix, vjpr, fabiospampinato, GoWind, kentkost, moenie99, olingern, iliazeus, fnpdaml, dev-ardi, and 23 more reacted with thumbs up emoji45scheibo, pdeva, bryanhelmig, chiumichael, maxzhao, candrewlee14, except, a-tarasyuk, mohsinhijazee, gilice, and 35 more reacted with heart emoji1vojtechmares reacted with eyes emojiContributornektro commented yesterdayJun 29, 2023Long-term, it may catch up or even surpass LLVM and GCC.We can implement our own optimization passes that push the state of the art of computing forward.We can attract research projects such as alive2We can attract direct contributions from Intel, ARM, RISC-V chip manufacturers, etc., who have a vested interest in making our machine code better on their CPUs.Zig will continue to implement optimization passes of its own over time and get faster.12anta40, kaiserthe13th, lin72h, rice7th, nikandfor, Delta456, Passw, Airbus5717, den-mentiei, tekakutli, and 2 more reacted with thumbs up emojiSponsorContributormlarouche commented yesterdayJun 30, 2023 \u2022editedSo here the projects that depend on the ability to compile C++ that I currently developing:https://github.com/Cold-Bytes-Games/wwise-zig: I am using the C++ ability to compile glue code to create a C binding. I plan to use this for audio in my game BioMech Catalyst written in Zig.https://github.com/Cold-Bytes-Games/wwise-zig-demo: Using previous mentioned library plus zgui that does a nice Zig binding on top of Dear IMGUIStill planning to use zgui for my game editor in the future.And also some NDA game platform that have C++ only API that will require some C++-to-C glue code to be compiled, but obviously not implemented.To me, the ability to seamlessly build any C, C++ and Obj-C is a big selling point of the Zig toolchain even if it is behind a optional flag to enable LLVM and Clang when compiling Zig. A part of the hype momentum around Zig is due to that fact.If this happens, I think I will remove my donation to the Zig Software Foundation.TL;DR: Lots of libraries in the game development world (closed or open source) require the ability to compile C++.123InKryption, feenor, foxnne, scheibo, GeffDev, yalopov, wub, directionless, nornagon, serxka, and 113 more reacted with thumbs up emoji8andrewrk, butera-simone, MKRhere, erlend-sh, crim4, LordSk, jojoqc, and vojtechmares reacted with eyes emojiContributorMasterQ32 commented yesterdayJun 30, 2023 \u2022editedI think this proposal would hurt the Zig ecosystem more than it would help it, due to several reasons:Adoption of compilers and languages in the embedded is basically driven by the code generation quality in terms of size. We have to be on-par or better than GCC and LLVM to be even considered tmto be adopted. 2%-5% bigger code is often not an annoyance, but a technical problem.A lot of projects use C++ code and might benefit from build.zig \"as is\". This could lead to adoption of Zig, with the build system as a kick-start. Removing support for C++ will hurt adoption a lot, because now the build of C++ projects with some additional Zig code will be even worse than just adding more cmake. Thus, a lot of projects wouldnt benefit from Zig in terms of quality of life, as it is yet another build tool.Zig is with its \"batteries included\" cross-compilation the best toolchain for doing native development. We would basically downgrade our toolchain to something Go where we rely on external tools to successfully build more complex projects. Even in the current state, its often so much easier to yeet zig at something to get it to build than even trying to get a cross-build running with existing toolsConsidering the scenario i have at work, introducing Zig as a build environment for several million lines of C++ would make a lot of people happy, as the builds would be faster, easier maintainable and trivially portable to other OS. With C++ and LLVM support removed, i dont see any chance of Zig adoption at this companyImho, this proposal strongly violates theTogether we serve end usersidea, as the current direction we're heading is a really good unified native build environment based on a single static executable that can serve projects in arbitrar, sizes, shipping compilers for several major languages, a huge ass support for targets and a build system, making work in systems programming fun, even if one doesnt use Zig as a language.We are on a good way to replace a huge list of tools with a single executable, making contributions to projects build on Zig fun, easy and platform independent.When this proposal is accepted, in addition to Zig one will need to have the following tools installed:(GNU) MakepremakemesonCMakeninja(arch)\u2212(os)-$(abi)-gccllvm/clangGNU autotoolsm4vcpkggradleconanqmakeSConsmaven...We can potentially replace all of those tools wit a single, equally powerful executable, making the live easier for all native devs out therepersonal projects that would be affected:https://github.com/MasterQ32/cg-workbench (fully written in C++)https://github.com/MasterQ32/zero-graphics (Scintilla is written in C++)https://github.com/MasterQ32/zig-assimp (Assimp is the de-facto standard solution for generic 3D model loading, written in C++)137InKryption, foxnne, feenor, scheibo, GeffDev, pdeva, wub, mattnite, teburd, andrevoget, and 127 more reacted with thumbs up emoji4lin72h, strager, cgriepsma, and tmtvl reacted with thumbs down emoji1avindra reacted with laugh emoji26mlarouche, xdBronch, foxnne, feenor, wub, a-tarasyuk, fabioarnold, mohsinhijazee, SoraTenshi, moenie99, and 16 more reacted with heart emoji4andrewrk, moenie99, rafaelbreno, and infogulch reacted with eyes emojifoxnne commented yesterdayJun 30, 2023I'm still a beginner I believe, but if it is at all worth it for me to give my point of view, Zig's ability to replace all of the build tools mentioned above is a big reason I was interested in Zig in the first place. I struggled a lot with all the different build systems and Zig is a really refreshing breath of fresh air.I have two personal projects that use zgui heavily and I had planned on continuing.PixiAftersun28GeffDev, andrewvc, PhilippWendel, rohlem, SoraTenshi, photex, zenith391, paperdev-code, steeve, cassepipe, and 18 more reacted with thumbs up emojiSponsorContributorslimsag commented yesterdayJun 30, 2023With Mach engine we have two dependencies that would be very, very painful to remove (would set us back years):DirectXShaderCompiler (DXC) - a Microsoft fork of LLVM 3.7, which generates DXIR (LLVM IR) which is what direct3d graphics drivers consume. Microsoft is trying to upstream support for emitting DXIR (specifically LLVM v3.7 IR) to the latest LLVM/clang version.Calling into Apple's Metal shader compiler - which converts Metal's text shading language into (yet another fork) LLVM IR bytecode, which is what the Metal API consumes - only this one is proprietary and undocumented. Obj-C is the only way to invoke it, I believe.It will be a long time before Zig's SPIRV backend is capable enough to generate non-GPGPU shaders for graphics APIs (if ever, since it would likely require major language changes) - so I don't see a way for us to escape these aside from replicating what these two projects -- LLVM forks -- do on our side.Every other C++ dependency I believe we could safely escape from.33dustyrockpyle, serxka, fifty-six, gwenzek, zenith391, seandewar, rottencandy, doanamo, lasagnaphil, bertie-wheen, and 23 more reacted with thumbs up emoji1yash1th reacted with confused emoji4andrewrk, cassepipe, nahuakang, and rafaelbreno reacted with eyes emojiSponsorContributorslimsag commented yesterdayJun 30, 2023 \u2022editedA positive long-term effect of this change is that it would push us as a community away from wrapping C++ code and towards more pure-Zig solutions.Many of the comments in this thread are about people using zgui, wwise, zig-gamedev, assimp, and other C++ libraries wrapped with Zig. It gives you a leg up in the short term, but I worry in the long-term that people's gamedev experiences coming to Zig will be 'initially I saw a nice language... then I encountered the guts of the libraries I was told to use were large, clunky C++ codebases'22rofrol, icylace, Chanyon, westrik, pietmichal, silversquirl, johynpapin, jorangreef, Ayawen01, tmtvl, and 12 more reacted with thumbs up emoji24creshal, lin72h, lwwmanning, doanamo, moenie99, rajsite, DerekZiemba, dev-ardi, Himujjal, MineGame159, and 14 more reacted with thumbs down emojiGeffDev commented yesterdayJun 30, 2023Also a beginner, but I think being able to use Zig as a C++ build system (which is what I use for all my private C++ projects) is an invaluable feature to me and I believe many other people. The simplicity of Zig, having a compiler and a build system contained within a single executable (with the added bonus of being easily cross platform), is really cool, and it would be kinda unfortunate to see that feature be removed as an effect of removing clang and friends. However, if this does go through, the ability to fallback to generating .bc files and invoking clang is nice.12foxnne, WilliamRagstad, zenith391, xNaCly, lwwmanning, ProkopRandacek, jevinskie, WardBrian, felix91gr, skell999, and 2 more reacted with thumbs up emojiContributoryujiri8 commented yesterdayJun 30, 2023One of my friends pointed out that nothing stops you from invoking clang in a build.zig to compile C++ dependencies, even if Zig stops including clang. I wonder how much of a problem that would really be for these projects?14wkhere, cassepipe, cristaloleg, tmtvl, transmutrix, fnpdaml, den-mentiei, DavidJFelix, dropwhile, DurandA, and 4 more reacted with thumbs up emojiContributorxdBronch commented yesterdayJun 30, 2023doing that would be an additional dependency without the ease of zigs cross compilation11yujiri8, directionless, zenith391, seandewar, xNaCly, cassepipe, ProkopRandacek, rajsite, GabrielRavier, 8bitprodigy, and widberg reacted with thumbs up emojiContributoryujiri8 commented yesterdayJun 30, 2023Hmm, the more I think about this proposal the less I like it. I'm feeling it would be better to make the LLVM backend non-default (that is, switch -fno-LLVM for -fLLVM or something) but not remove it. It seems like this would solve most of the issues: the existence of many bugs that are LLVM's fault, and the slow compile speed, aren't strong reasons to remove the LLVM backend so much as make it non-default. It wouldn't solve the issues of the binary size of the zig compiler or difficulties with building it, of course.30ethernetsellout, dcow, truemedian, zenith391, GalaxySnail, seandewar, lwwmanning, rice7th, erlend-sh, jevinskie, and 20 more reacted with thumbs up emojimusi-musi commented yesterdayJun 30, 2023I think I can speak for all gamedevs by saying that removing C++ compilation would be a disaster. Too many amazing existing gamedev libraries and tools are built on C++ that disallowing easy use would strangle adoption in that field, as well as complicate existing projects. dear imgui is the obvious example but it's not the only one.29zenith391, seandewar, lorenzogatti, Ipotrick, floooh, tomc1998, ProkopRandacek, erlend-sh, tw1nk, Skarsh, and 19 more reacted with thumbs up emojimusi-musi commented yesterdayJun 30, 2023It's easy to imagine that in the long term, this change will push us towards \"rewrite it in zig\" with all the benefits that would entail, but the downside is that the existing corpus becomes inaccessible; limiting our options heavily even once zigs ecosystem matures6bertie-wheen, doawoo, justinian, RoyalIcing, nogira, and Kobzol reacted with thumbs up emojiContributorJack-Ji commented yesterdayJun 30, 2023I think llvm is needed until ecosystem of pure-zig library is very very mature and rich.Yeah we want faster compiling speed and smaller tarball, but not at the risk of losing one-zig-to-rule-all.42yujiri8, fifty-six, lacc97, strager, TeddyDD, zhangyoufu, seandewar, lwwmanning, cassepipe, ssnailed, and 32 more reacted with thumbs up emojiethernetsellout commented yesterdayJun 30, 2023I love the ambition of this proposal, but to reiterate what has already been stated, losing c++ compilation would be losing one of the main selling points of zig. I was drawn to zig in part because it reduces the hellishness of depending on c/c++ projects. Zig having a c++ compiler inside it also has the benefit of there being less c++ to have to deal with, less python to have to deal with, less cmake to have to deal with.On the other hand, the core of this proposal has too many benefits for it to be rejected entirely. I think reducing the scope would be beneficial. How about:Eliminate dependencies on LLVM & LLDKeep clang as an optional dependency for easy cross-compilation24bcrist, lacc97, icylace, zexa, isaac-fain, seandewar, cassepipe, lwwmanning, prenaux, doanamo, and 14 more reacted with thumbs up emojiContributoralexrp commented yesterdayJun 30, 2023 \u2022editedI totally get the desire to get rid of huge third-party dependencies that bring a lot of baggage. There's also something to be said for avoiding an LLVM monoculture in the programming language space.Even so, I see this as a net negative for users. What drew me to Zig in the first place was the pragmatic approach of acknowledging that there is a world outside of Zig that needs to be interoperated with for the foreseeable future and even providing a best-in-class cross-compilation experience along with that. I built my project integrating Zig build support with the .NET/MSBuild ecosystem on that selling point.On the whole, I think this proposal would be an unfortunate (if well-intentioned) bait-and-switch, considering the Zig website for a while has advertised this:In addition, these blog posts drove a lot of attention to Zig in the past:zig cc: a Powerful Drop-In Replacement for GCC/ClangMaintain it With ZigJust to be super clear: I don't mean to insinuate bad faith or anything of the sort here. But I think it's fair to say that you have to contend with the fact that this proposal would pull features that are not only usable today, but are also prominently advertised.All that said... assuming this is even remotely practical, maybe there's a potential middle ground: Would it be possible for Zig to continue to use the Clang frontend to provide C-family support, but rip out the LLVM IR lowering and replace it with lowering to ZIR/AIR? (I guess this is more or less how Aro would be integrated too?)If this could be done, the codegen dependency on LLVM could be killed, achieving at least some of the goals of this proposal. There's probably also no reason to keep LLD support around as long as zld can catch up, so that eventually goes too. And users remain happy. Some of the build and distro woes would remain, of course, but, that's compromise.102ccapitalK, axojhf, mitchellh, mlarouche, ethernetsellout, wedow, truemedian, candrewlee14, jnbooth, smasher164, and 92 more reacted with thumbs up emoji14cq2 reacted with thumbs down emoji2FavoritoHJS and vojtechmares reacted with eyes emojiContributorAdamGoertz commented yesterdayJun 30, 2023 \u2022editedI\u2019m fully in favor of making it possible to use Zig without any LLVM components, but I agree with many of the comments here that it\u2019s important for Zig to maintain the capabilities that it currently has in terms of cross-compilation, compiling C/C++ code seamlessly, and generating maximally performant binaries.These factors are big drivers of Zig\u2019s adoption, and I fear that damaging them (even temporarily as in the case of code generation quality) would seriously hurt Zig\u2019s future.Personally, I work in the robotics space, where C++ is the dominant language for many libraries and frameworks. I think Zig has a lot of potential in this space, but being able to integrate with existing libraries is absolutely essential for adoption.37PhilippWendel, fifty-six, rohlem, creshal, zenith391, paperdev-code, lwwmanning, floooh, notcancername, scheibo, and 27 more reacted with thumbs up emojiSponsorContributorhryx commented yesterdayJun 30, 2023Is there a story in this proposal for JIT compilation? I have a Zig project with currently relies on LLVM's Orc to JIT-compile audio DSP functions. I'm not particularly stoked about or attached to Orc itself, but it does give me in-process compilation with low-milliseconds latency, something I'd need for dynamic real-time audio applications.WebAssembly would not be an issue here because I wrote the Wasm compiler myself, but for x86_64 and friends I would need a replacement. Passing LLVM bitcode to a separate process might work but would feel like a downgrade. Vendoring and embedding the Zig compiler source might be the best option in that case.(Aside: I have started work on reading and writing LLVM bitcode from Zig, and if this is accepted would be happy to resume work on that.)1jevinskie reacted with thumbs up emojiSponsorContributormitchellh commented yesterdayJun 30, 2023I'll start by stating my opinion: the C language frontends are super important to me for Zig to maintain.I agree with others on the point that Zig being a C/C++ compiler is a big point of attraction that brought me to the language. I started with loving that idea, and ultimately fell in the love with the language, and now I use both. I don't have anything more to add to that that the others above haven't.I'll add my own personal experience. I have many personal Zig projects, but my biggest one that people tend to know about in the community is my terminal emulator. There are two important dependencies that would be impacted by this:Harfbuzz - The far and away single most complete cross platform text shaping engine. Text shaping for those that don't know is the process of laying out text, processing things like multi-codepoint emoji into single glyphs, Asian language handling, etc. This is not something you want to really maintain in your own language (i.e. write natively in Zig) because Harfbuzz is so good and so well supported. This is shipped as a single large C++ file with no other dependencies. Without access to Harfbuzz, gaming and manual-GUI applications (not using a mega framework) would surely suffer.Objective-C for Mac work. Admittedly, this is probably deprecated over the long term since Apple is pushing very hard into Swift. Still, I use Zig's ability to compile Objective-C files to augment my native Zig Mac applications. I've personally written Zig objective-C bindings using the C API, but I also still like to just write some ObjC sometimes which would otherwise take a big mess of Zig/ObjC-runtime code. Again, I think I could find a way around this one, but I think its worth noting for now that ObjC is still a part of [low-level] macOS GUI development.Andrew, your dislike of C++ is well known! I don't love it either (to put it kindly). If, as an audacious goal, you wanted Zig to lower C++ usage, I think Zig being able to compile existing projects and enable iterative migration away from C++ to Zig is the way to do it. I think if Zig doesn't support C++, the C++ \"people\" would just avoid Zig altogether.97mlarouche, axojhf, shepherdjerred, jiacai2050, tamalsaha, zacksiri, PT600, candrewlee14, yujiri8, rcousens, and 87 more reacted with thumbs up emoji3anacrolix, j0nimost, and cultab reacted with laugh emojiTUSF commented yesterdayJun 30, 2023Main gripe seems to be the need/desire to be able to compile C++ due to the mountain of pre-existing libraries that are already being used in the Zig ecosystem. For this proposal to satisfy people and not to break a huge selling point for Zig, a C++ (and ObjC?) compiler in Zig would have to be up-streamed.Dunno what madman will be the one to write that tho.At the very least, any kind of serious effort towards removing LLVM should be done after reaching 1.0.That said, I don't think divorcing from LLVM itself is a bad idea, if the Zig toolchain itself can slowly grow to replace its functionality, just so long as it sticks around until opting out of it doesn't result in Zig losing out on its existing features.5rofrol, SoraTenshi, fnpdaml, skell999, and 8bitprodigy reacted with thumbs up emojipresentfactory commented yesterdayJun 30, 2023 \u2022editedWhile I can see this being a good thing in theory I like others have concerns over what it will do more short term. Zig to me is expected to be a highly performant language competitive with languages like C, if it is not performant then it impacts my ability to use it for writing the projects I am making in it because it simply will be a worse option in practice for such things.Perhaps this could be mitigated if the C backend becomes fully functional to allow projects to compile to C code and have those compile with typical C compilers for when performance is needed, but otherwise I do not think this would be well-advised until some sort of reasonable performance guarantee can be made. Even with the Zig->C->Machine Code process I feel like you'd be losing some optimization potential as no longer would Zig be able to annotate LLVM IR directly and would instead be confined by whatever C can express language wise so that might not even be a foolproof option either (though at the very least it'd hopefully put it on the level of C for most things).Edit: Apparently I've been told this is what the bitcode support could be used for, I've never used LLVM bitcode stuff myself before but yeah if that's a supported target and still gets focus knowing people will be using it to generate higher quality optimized code until Zig can compete maybe this is less of an issue, albeit a bit more convoluted in how a project would have to be compiled.Frankly with how insanely complex x86 is and how much work has gone into LLVM over the years I am doubtful Zig would ever reach the same standard of performance. Other larger languages like Rust which aren't even as entangled with C++ haven't tackled this sort of challenge yet either for instance despite the some similar motivation to and more developer resources at their disposal, and to me that is not a very promising sign for its feasibility (though of course Zig could always be the first thing to prove this long-held mindset of LLVM being impossible to replace wrong...).Also as an aside while I am not as invested in the C++ compilation support as others may be I do think that it'd hurt a lot of projects. Being a gamedev myself losing the ability to use ImGui would be unfortunate as others have mentioned, and personally I also use Tracy in some of my Zig projects which is also C++-based. It wouldn't be too hard to just compile these libraries and link to their binaries (or use a system library I suppose) but still that just makes Zig a bit more pain to interface with this stuff.15LouisGariepy, McSinyx, nektro, shadowndacorner, cassepipe, Semisol, RealY700, mlarouche, Skarsh, jevinskie, and 5 more reacted with thumbs up emojiContributorxdBronch commented yesterdayJun 30, 2023Another thing that I don't think has been mentioned/considered yet, if this proposal were to go through, and that were to happen around or after the time that 1.0 is released, it could cause a split in the zig community.Some people who rely on zig's current toolchain might choose to simply stick to an old version of zig so they aren't forced to migrate their codebase. This would harm everyone involved. Users and devs on the old version would miss out on any future features and optimizations, while the other ones, who chose to update, would be unable to use any of these libraries within their own projects without jumping through hoops to do so.16williamstein, fifty-six, zenith391, shadowndacorner, lorenzogatti, itsokk, mlarouche, Skarsh, jevinskie, kkysen, and 6 more reacted with thumbs up emojiSponsorXVilka commented yesterdayJun 30, 2023 \u2022editedI agree that apart from the mentioned problems with LLVM, it also struggles with the a baggage of legacy code, e.g. in TableGen modules, in how Clang is tied to LLVM compared to the newer compilers that use middle-level intermediate languages, how story of migration from FastISel and SelectionDAG to GlobalISel stalled for many years and isn't really progressing for all supported architectures, and so on and so forth. Using C++ language for writing such a complex piece of software doesn't help either. But even Rust didn't dare to get rid of it just yet. Thus, I think it would be prematurely to do that for Zig either. Long-term it might be a worthy goal, but definitely not in the upcoming 5 years or so, in my opinion. Just my 2c.I second @yujiri8 here, having optional LLVM target for many years while working on the Zig backends would be a perfect strategy, reducing the maintenance of LLVM parts and providing room for experimentation and optimization of the mainstream targets directly in the Zig code: ARM64 and x86_64, probably RISC-V in the future, if it really takes off. GHC (Haskell) uses the similar approach for at least a decade already, it seems to work for them.P.S. Why PE format is not in the list for linker?7fifty-six, structure-charger, jevinskie, luc-tielen, kkysen, FlatMapIO, and patrakov reacted with thumbs up emojiPhilippWendel commented yesterdayJun 30, 2023 \u2022editedMaybe the best long-term solution would be to offer some kind of plugin system for the zig compiler.Pros:The compiler itself could take advantage of all the stuff listed by AndrewStuff that the community considers important, like compiling c++ could still be supportedYou only \"pay\" for what you are actually usingWe need some way to interact with different compilers/tool anyway to take full advantage of the c-backend, e.g. compiling zig code for some exotic platform that only has an compiler for c. This could be a more stable approach than just scripting with build.zig.It would make it easier for people to add interoperability for even more languages than just c/c++ and experimenting with features in generalCould result in some federation. While a second implementation of zig compiler is a long time away, having a plugin system would allow different implementation of parts by the community, e.g. clang and aroccCons:Duck tons of workEven more stuff breaking when a new compiler version releases5rlapz, chrboesch, kkysen, ritalin, and zeroows reacted with thumbs up emoji3bcrist, Beyley, and VAbsoluteZero reacted with thumbs down emojiducktype commented yesterdayJun 30, 2023 \u2022editedAt least create a new external project to mantain the goodness of \"zig cc\" likes embedded platform SDK .h and cross compilation!!5LinuxUserGD, lxhillwind, photex, theoparis, and jamii reacted with thumbs up emojigithub-actions bot mentioned this issue yesterdayJun 30, 2023Hacker News Daily Top 30 @2023-06-30 meixger/hackernews-daily#285Open75 hidden itemsLoad more\u2026Contributorjagt commented 17 hours agoJun 30, 2023If zig itself get rid of clang, I strongly suggest there's another standalone, official project that bundles clang and support the existing use case of building C++ code.zig being a painless c++ toolchain which also handles cross compilation is such a great idea and attracts a lot of good attention, which is pity to lose them.24sywhang, bluskript, doanamo, tim-janik, Warkanlock, 3O11, paperdev-code, joseluisq, InKryption, Lokathor, and 14 more reacted with thumbs up emojifelix91gr commented 16 hours agoJun 30, 20232 cents.If this is a breaking change, then it is probably adequate to make a migration tool for the codebases that depend on the features this would dispose of.If that can't be done, I don't see how this wouldn't split the Zig codebase.Sponsorjamii commented 15 hours agoJun 30, 2023 \u2022editedSeveral people have suggested splitting out a separate tool. To make a concrete proposal:zig is a small executable that can compile zig projects, install zig packages, translate c headers and output native code or .bczig-cc is a tool that can be installed via the zig package manager (or downloaded separately) and supports cross-compilation of c/c++/objc/.bcThis achieves some of the goals. Certainly the compiler architecture would get simpler. Bootstrapping and incremental compilation would get easier. Mixed zig/c++ projects would still benefit from easy cross-compilation. The bc backend would provide high quality codegen while the native zig codegen catchs up.But zig-cc would still be a large maintenance burden for the core team. Perhaps the ideal resolution would be for some of the companies that depend on it to get together and employ a maintainer, freeing up the core team for zig-specific work.EDIT Obviously this comment should be titled \"File for divorce but don't throw out the baby\".43bvisness, kprotty, srdjan, InKryption, mariansimecek, alichraghi, 4cq2, ducktype, onthebusiness, LinuxUserGD, and 33 more reacted with thumbs up emoji1paperdev-code reacted with thumbs down emoji11andrewrk, doanamo, alichraghi, natecraddock, davidthomas426, goodhoko, frizadiga, jiacai2050, PT600, j0nimost, and cadesalaberry reacted with laugh emoji2LinuxUserGD and frizadiga reacted with hooray emojiarjunkathuria commented 15 hours agoJun 30, 2023 \u2022editedLFG !I recently moved projects from an old GHC version that used LLVM to compile, to a newer GHC version that had a native code-generator for the platform. The Compilation speed gains alone were pretty sweet.1CGMossa reacted with thumbs up emojiBeyley commented 15 hours agoJun 30, 2023 \u2022editedIn the Silk.NET project, we use zig cc and zig c++ to provide reproducable build environments for our native libraries, we build aarch64, x86_64, and x86_32 libraries for MacOS, Linux, and Windows, all from a single Linux CI runner, losing out on true clang C/C++ cross compilation would be a huge blow, as we rely on the ease of cross compilation and easy local setup of the Zig compiler to provide a true easy compiler target, we have ported a number of libraries to use the zig build system through build.zig, and even in non-build.zig environments, we use zig cc/zig c++ to provide a set of better sane defaults for the compilerFor my personal projects, i use zig cc and zig c++ to compile even more libraries, for my game, i depend on ImGui, SDL, and iconv-win, 2 of those including C++ code, i have rewritten all of those projects to be built with a single build.zig, allowing me to easily use a single Linux machine to cross compile an executable to all my targets with no fussing about with cross compiler settings or external dependencies, i clone my project, then i can just do zig build -Dtarget=X and everything \"just works\"12InKryption, Lokathor, chpf, LinuxUserGD, mark-dawn, seemsindie, raftario, amerkoleci, fluxehub, Khitiara, and 2 more reacted with thumbs up emojideflock commented 15 hours agoJun 30, 2023Meanwhile Intel\u00ae C/C++ Compilers Complete Adoption of LLVMThe latest Intel C/C++ compilers, using LLVM, deliver faster compiler times, better optimizations, enhanced standards support, and support for GPU and FPGA offloading.If it would be possible to move the llvm part to a separate community-maintained zig-llvm project which will use a zig's officially supported bridge interface then I'm in favor of it.13Mindgibber, photex, doanamo, onthebusiness, LinuxUserGD, CuriouserThing, fluxehub, VAbsoluteZero, Leimy, axojhf, and 3 more reacted with thumbs up emojiSponsorphotex commented 14 hours agoJun 30, 2023 \u2022edited@polak-janI can definitely see where you are coming from, but dismissing Zig over a proposal seems pretty extreme ...Sorry, I phrased it poorly. If the proposal was accepted in such a way as to remove what I consider to be the primary selling point of the toolchain specifically (which means, compiling C++ with a fully provided clang), then yeah Zig would be a lot less useful to me.For personal work, or open source things, it's all still fine and I'm sure I'll love every minute of it. I'm only talking about the very awesome way Zig solves actual problems I have today while I can look forward to a cool future of primarily using Zig.Another point worth mentioning, in the business I work in (professional audio hardware/software), LLVM is becoming standard and a lot of important tooling is now being implemented on LLVM instead of having to create limited C++ front-ends themselves. By adopting LLVM it's possible to use really any front-end for it. Real doors are opening where previously the only option was C++. If Zig were to no longer use LLVM then it's actually no longer feasible for me to adopt. EDIT: It's clear, that signals keep getting crossed in the messaging here. As I understand having gone back to the top here, Zig never intends not to emit llvm bitcode. So no technical impediment, it's just less useful.2geo-ant and eLeCtrOssSnake reacted with thumbs up emojiandrewrk mentioned this issue 14 hours agoJun 30, 2023directly output LLVM bitcode rather than using LLVM's IRBuilder API #13265Openandrewmd5 commented 13 hours agoJun 30, 2023 \u2022editedWe can attract direct contributions from Intel, ARM, RISC-V chip manufacturers, etc., who have a vested interest in making our machine code better on their CPUs.we use Zig internally for a lot of cross compilation so this proposal is concerning for a few reasons. That aside, the goal stated above just seems unrealistic and based on wishful thinking given Intel just completed a full migration of their compiler to LLVM.22michal-z, LinuxUserGD, LouisGariepy, zenith391, jasikpark, Hammersamatom, rrbutani, nico-abram, seandewar, q121q, and 12 more reacted with thumbs up emojivanc mentioned this issue 12 hours agoJun 30, 2023linker: support \"zig cc\" mesonbuild/meson#11918Openhiljusti commented 10 hours agoJun 30, 2023 \u2022editedFor those who are unhappy about the removal of C++ (or ObjC/ObjC++) I'd like to suggest reading this as:It costs a lot of time/effort to support thisThat time/effort is just not in the budgetI don't think there's a way to argue against these, they are very clearly demonstrated in the proposal. I see a lot of \"it's valuable to me\" posts, and I think they're all valid, but nothing is really talking to the 2 points above.If anyone is interested in preserving this costly integration, I think it's gotta come in the form of either money (to hire someone to do it) or time (ramp-up contributing significantly).(Edit: Or I guess in the form of taking focus away from all other features and goals of Zig)9rofrol, torodop, felix91gr, Mindgibber, casaca24, klmr, dannote, vdm, and drathier reacted with thumbs up emoji11ethernetsellout, AnErrupTion, Jared-Miller, OBenjaminT, taishi-sama, andrewmd5, silbinarywolf, Yay295, eLeCtrOssSnake, GabrielRavier, and SLiV9 reacted with thumbs down emojiAnErrupTion commented 10 hours agoJun 30, 2023I don't think there's a way to argue against these, they are very clearly demonstrated in the proposal.The issue is that way too much people are relying on it. Removing support for this would effectively put those users in the dark.hiljusti commented 10 hours agoJun 30, 2023If it can't actually be supported (with the current budget) then it's far better to stop as soon as possible. The alternative is to gain more users, string along a poor experience that can't be supported, and let it get worse over time.My suggestion is just to consider pitching in for the value you want. (Or have your employer do it.)3felix91gr, FavoritoHJS, and casaca24 reacted with thumbs up emojithechampagne commented 10 hours agoJun 30, 2023This is a good thing if there is other tool that support LLVM. Like in D, which has three compilers that support different backends.Contributoralexrp commented 10 hours agoJul 1, 2023For those who are unhappy about the removal of C++ (or ObjC/ObjC++) I'd like to suggest reading this as:It costs a lot of time/effort to support thisThat time/effort is just not in the budgetI don't think there's a way to argue against these, they are very clearly demonstrated in the proposal. I see a lot of \"it's valuable to me\" posts, and I think they're all valid, but nothing is really talking to the 2 points above.If anyone is interested in preserving this costly integration, I think it's gotta come in the form of either money (to hire someone to do it) or time (ramp-up contributing significantly).Consider that:The feature has existed for a while.The feature is advertised prominently as a major advantage of Zig.The feature has many users.The ZSF has been receiving community funding for years now.One would assume that, under these circumstances, people who fund Zig would think that they are in fact funding such a major feature.As I've said previously, it's perfectly fine to argue that Zig getting into this position was a mistake from the beginning. But then just say that. There's no shame in admitting that the team bit off more than they could chew. There's no need to beat around the bush with arguments like these that, IMO, don't actually hold up to scrutiny.13sizumam, hiljusti, amzamora, TUSF, strager, geo-ant, strokirk, doanamo, IntegratedQuantum, eLeCtrOssSnake, and 3 more reacted with thumbs up emoji14cq2 reacted with thumbs down emoji2TimSimpson and ityonemo reacted with heart emojikattkieru commented 9 hours agoJul 1, 2023If it can't actually be supported (with the current budget) then it's far better to stop as soon as possible. The alternative is to gain more users, string along a poor experience that can't be supported, and let it get worse over time.My suggestion is just to consider pitching in for the value you want. (Or have your employer do it.)Gimme a dollar amount.SponsorSoraTenshi commented 9 hours agoJul 1, 2023If it can't actually be supported (with the current budget) then it's far better to stop as soon as possible. The alternative is to gain more users, string along a poor experience that can't be supported, and let it get worse over time.My suggestion is just to consider pitching in for the value you want. (Or have your employer do it.)I am not entire sure how big the maintenance effort is, but isn't writing Optimization passes a whole new chapter that chews away a lot more of the budget, if not even more?I have a somewhat neutral opinion on getting rid of LLVM, it may even come with a long-term benefit, however, gettinc ompletely rid of C++ and Obj-C(++) is a bad take as many people above me have already mentioned it. It's a huge selling point and at least to how i understand it a relatively major part in the Philosophy.I would, however, be completely fine if the Zig compiler gets cut off in a smaller, more lightweight binary, with the potential to additionally add LLVM Capabilities / the clang frontend to it. Sort of like an \"extension\".4Yay295, strager, doanamo, and casaca24 reacted with thumbs up emojiheadllines bot mentioned this issue 9 hours agoJul 1, 2023Hacker News Daily Top 10 @2023-07-01 headllines/hackernews-daily#1081Opengithub-actions bot mentioned this issue 9 hours agoJul 1, 20232023-06-30 Hot Posts jiacai2050/hot-posts#330OpenTUSF commented 8 hours agoJul 1, 2023For those who are unhappy about the removal of C++ (or ObjC/ObjC++) I'd like to suggest reading this as:It costs a lot of time/effort to support thisThat time/effort is just not in the budgetUhh, what? Supporting C/C++/ObjC, as far as I know, comes free with the fact that Zig already uses LLVM/clang internally. Maintaining this, as far as I know, doesn't really cost much, when Zig already uses LLVM.What would really cost a lot of time and effort is re-writing all the codegen for all of the intended architectures, along with getting the optimizations to parity with LLVM. Not to mention that the budget will probably shrink considerably if C++ compilation support is dropped.3superstructor, lacc97, and GabrielRavier reacted with thumbs up emojisxlijin commented 7 hours agoJul 1, 2023For those who are unhappy about the removal of C++ (or ObjC/ObjC++) I'd like to suggest reading this as:It costs a lot of time/effort to support thisThat time/effort is just not in the budgetI don't think there's a way to argue against these, they are very clearly demonstrated in the proposal. I see a lot of \"it's valuable to me\" posts, and I think they're all valid, but nothing is really talking to the 2 points above.If anyone is interested in preserving this costly integration, I think it's gotta come in the form of either money (to hire someone to do it) or time (ramp-up contributing significantly).(Edit: Or I guess in the form of taking focus away from all other features and goals of Zig)This implies that builtin LLVM interop is not an important feature of the Zig ecosystem.MemberAuthorandrewrk commented 7 hours agoJul 1, 2023 \u2022editedI see a lot of speculation in this GitHub Issue from folks who are not involved in Zig in any way. I would respectfully ask you to please take such speculation elsewhere. This issue tracker is for focused technical discussion by those who are actually using Zig, today. The noise in this thread distracts from the valuable comments by users who are sharing their use cases for the relevant features of Zig...which, by the way, I'm one of. For example, my music player reboot branch depends on chromaprint which is, dun dun dun, C++ code.I'm not going to simultaneously shoot myself and valuable community members in the face by yanking a load-bearing feature out from underneath us, without any kind of upgrade path. It's a bit unfortunate that the Internet has taken that narrative and run with it.For example, one thing to explore, later - once all those boxes above are checked - is whether we can satisfy the C++ compilation use case, as well as the LLVM optimization use case, with the package manager. The results of this exploration will heavily impact the ultimate decision of whether to accept or reject this proposal.Please, relax. Nothing is going to happen overnight, and nothing is more important than making sure our esteemed Zig users' needs are taken care of, one way or another. Whatever happens will happen in due time, with due respect for real world projects. This proposal is aspirational - something to look forward to and consider in the coming years.54alexrp, cactusbento, ymndoseijin, Ayawen01, xdBronch, davidgm94, rohlem, Jayrod246, slimsag, PT600, and 44 more reacted with thumbs up emoji62silbinarywolf, mlarouche, travisstaloch, nektro, TUSF, Ratakor, ianprime0509, c1m50c, ethernetsellout, cactusbento, and 52 more reacted with heart emojiSlashScreen commented 5 hours agoJul 1, 2023I personally can see both sides of the argument, but if C/C++ compilation can be added back in as a package, and zig can at least emit something LLVM can use (as cumbersome as that may be), then I say go for it.I personally like the idea of a compiler that can bootstrap using only a C compiler without fussing with external dependencies. One of my personal projects is making/finding ways to provide tools to make and use apps for the Plan 9 operating system. Since almost nobody actually builds things for Plan 9, having a zero-dependency bootstrapper that opens up the Zig language to Plan 9/[insert obscure platform] users is a valuable tool. This use case is admittedly very niche.However, I am somewhat worried about the optimization promise. Not that I've ever written much more than a basic code optimizer, but I'm doubtful that any compiler could match GCC and LLVM, who have had decades to fine-tune their compilers (although I do see you mention the O(n^2) mess it generated). But, the Zig team has surprised me in the past.Sponsorpolak-jan commented 5 hours agoJul 1, 2023@andrewrk I sadly think you brought this on yourself to some degree, because the initial post wasn't very specific about it being just a proposal. And in situations like these you really have to be overly explicit because the internet will automatically assume the worst possible case. (me included to some degree, as I initially misunderstood the meaning of the checklist in the post).11strager, Boshen, RoyalIcing, CuriouserThing, doanamo, michal-z, fmajestic, zakiego, zero9178, SLiV9, and jabcross reacted with thumbs up emoji9gozzarda, tato, seandewar, berezovskyi, venkatd, bfredl, chazhaws, loonatick-src, and satvik007 reacted with thumbs down emojiContributorityonemo commented 4 hours agoJul 1, 2023@andrewrk I sadly think you brought this on yourself to some degree, because the initial post wasn't very specific about it being just a proposal. And in situations like these you really have to be overly explicit because the internet will automatically assume the worst possible case. (me included to some degree, as I initially misunderstood the meaning of the checklist in the post).It's tagged \"proposal\" and \"1.0.0\".Sponsorpolak-jan commented 4 hours agoJul 1, 2023 \u2022edited@andrewrk I sadly think you brought this on yourself to some degree, because the initial post wasn't very specific about it being just a proposal. And in situations like these you really have to be overly explicit because the internet will automatically assume the worst possible case. (me included to some degree, as I initially misunderstood the meaning of the checklist in the post).It's tagged \"proposal\" and \"1.0.0\".I know, but I think we both agree that a large amount of people missed that. Which was the point I was making. In situations like this you have to be extremely explicit, and make it very obvious, not just put a small tag on the sidebar. This post in comparison does not mention the fact it's a proposal even once in the text itself, and uses a language that sounds very definitive. And the text is all most people will actually read.Honestly the fact your response is to blame the users is not great. (meaning specifically the reply I am quoting, not necessarily other contributor replies) The amount of people that interpreted it incorrectly makes it pretty clear that it wasn't communicated well enough. And if you just blame the users and don't change anything this situation will just keep repeating until you do.11strager, CAD97, felix91gr, CuriouserThing, lacc97, doanamo, Yay295, michal-z, GabrielRavier, zero9178, and SLiV9 reacted with thumbs up emoji8gozzarda, rlapz, casaca24, seandewar, berezovskyi, venkatd, bfredl, and chazhaws reacted with thumbs down emojiSponsorphotex commented 3 hours agoJul 1, 2023@andrewrk Thanks for the clarification. I'm new to Zig, totally unaware of the tags or their usage (they are not prominent to my eyes and I rarely use them in Github because of it). Human factors like this can lead to miscommunication sometime.When I see an issue/ticket/todo-list then I think a decision was made and a plan is underway. I'm probably not alone in this misconception here (at least I hope). Maybe having '[Proposal]' in the title could help to clarify?Would it be possible to start using discussions/forums for proposals like this? Having a dedicated forum or topic for proposals to be discussed might make things much clearer (but perhaps not since it's the internet and we're all cats).The zig toolchain is solving real-world problems today and is valuable. Discussing approaches for the future on a topic with so many facets as this, could probably benefit from a more threaded format. I guess the e-mail list someplace is not as widely used as GitHub though.6polak-jan, Yay295, onthebusiness, michal-z, fmajestic, and RoyalIcing reacted with thumbs up emoji1chazhaws reacted with thumbs down emojifelix91gr commented 3 hours agoJul 1, 2023 \u2022edited@SlashScreen However, I am somewhat worried about the optimization promise. Not that I've ever written much more than a basic code optimizer, but I'm doubtful that any compiler could match GCC and LLVM, who have had decades to fine-tune their compilersThey can and they will be matched. In fact, I believe that they will eventually be surpassed. There's two reasons for that.The C limitsWhy do people keep using Fortran for raw speed? It's because it can be optimized further than C and C++. It has a higher performance ceiling, and it has already gone above what is possible for C and C++.LLVM, however \"universal\", still looks at the world through the lenses of C and C++. It is more conservative than it could be, because it has to work with the few guarantees those languages make. The perspective of C is limiting it from a design standpoint.The C++ burdenLLVM is made in C++. This imposes a cost that the project pays every day. It's harder to maintain, harder to modify and harder to introduce newcomers to it.Eventually it will reach an equilibrium of improvement v/s burden, after which it won't get any better. A project built with more modern tooling (like Zig) will reach such an equilibrium as well, but much further ahead because the burden side grows so much more slowly.I don't expect them to be surpassed very quickly. But they will be. About this, I'm certain.5rlapz, onthebusiness, murdho, karoofish, and spytheman reacted with thumbs up emoji5strager, candrewlee14, onthebusiness, GabrielRavier, and LinuxUserGD reacted with confused emojiContributorstar-tek-mb commented 3 hours agoJul 1, 2023I think this proposal is good for those who actually write code in Zig, and not very good for those who use Zig as toolchain.I am myself, a lazy person, prefer to use C dependencies for my personal projects. And I'm not trying to contribute to Zig with writing a code in Zig that will help Zig community later. I support the idea of removing LLVM or rather binaries in ziglang.org will be provided with non-LLVM binaries, and if you want LLVM support - build it yourself.I will call it like: if Rust users prefer to rewrite it in Rust, Zig users prefer to reuse existing code in C/C++, and not contribute any further to development of language itself. Removing LLVM will definitely encourage someone to write pure Zig libraries. IMHO.5strager, rlapz, casaca24, onthebusiness, and eLeCtrOssSnake reacted with thumbs up emoji2felix91gr and LinuxUserGD reacted with confused emoji1onthebusiness reacted with heart emojieLeCtrOssSnake commented 1 hour agoJul 1, 2023I like zig state of art optimization. And it's all thanks to language decisions and LLVM. And while I agree that we could make custom compilers(for example for something that LLVM doesn't support), wouldn't abandoning the LLVM giant introduce issues. Tons of architectures and only one backend, with bug and security fixes.So my take on this is to continue support LLVM as firat class backend and then perhaps zig has abilities to overgrow LLVM and be better, but until then, it might make ZSF spend tons of time for backends that won't be optimal for every architecture.Yes I know, LLVM is a burden to support and work with but I think it's sure worth it.4felix91gr, GabrielRavier, LinuxUserGD, and IntegratedQuantum reacted with thumbs up emojiSign up for free to join this conversation on GitHub. Already have an account? Sign in to commentAssigneesNo one assignedLabelsproposalThis issue suggests modifications. If it also has the \"accepted\" label then it is planned.ProjectsNone yetMilestone1.0.0DevelopmentNo branches or pull requests82 participantsand othersFooter\u00a9 2023 GitHub, Inc.Footer navigationTermsPrivacySecurityStatusDocsContact GitHubPricingAPITrainingBlogAbout",
    "summary": "- The proposal suggests removing LLVM, Clang, and LLD libraries from the Zig project.\n- Zig plans to implement its own optimization passes and attract contributions from chip manufacturers to improve machine code.\n- While the removal of C++ compilation capabilities may impact some projects, Zig aims to have a contributor-friendly IR and a more lightweight compiler binary.",
    "hn_title": "File for divorce from LLVM",
    "original_title": "File for divorce from LLVM",
    "score": 333,
    "hn_content": "Hacker News new | past | comments | ask | show | jobs | submit loginFile for divorce from LLVM (github.com/ziglang)333 points by detaro 1 day ago | hide | past | favorite | 155 commentswyldfire 1 day ago | next [\u2013]Andrew is super sharp so I imagine he and the team will get there now that it's declared as a goal.But man, it seems to me (uneducated on the challenges zig faces w/LLVM) that this shifts the team's capacity away from zig and towards things like binutils. When I read the headline I assumed that they were throwing out the compiler (IIRC they had mostly/totally excised it already). But for a project like zig it just seems like there's a lot to be gained from keeping it.That said -- the prospect of rewriting a lot of the stuff that's in the LLVM project now in zig instead of c++ - that's pretty cool and ambitious. Just as ambitious as it was for Lattner to create LLVM, I suppose.But code that's accidentally quadratic - well, that's bound to happen to zig too, if it's as popular and useful as LLVM project is.replyjimwhite42 22 hours ago | parent | next [\u2013]There's a document that I think was an unofficial project management document from NASA, I can't find it now, but one of the items was something along the lines of 'if your space mission isn't reusing an existing launch vehicle, it will be a launch vehicle development project and everything else, including what you think is the focus of your mission, will be secondary to this'.Edit: additional bit I remembered, this statement is prefixed with something like 'you may start thinking you project will be cheaper/more efficient if you develop a launch vehicle suited to your particular mission instead of compromising on an existing one, but', then the above.replyrunlevel1 21 hours ago | root | parent | next [\u2013]Akin's Laws of Spacecraft Designhttps://spacecraft.ssl.umd.edu/akins_laws.htmlreplycbsks 19 hours ago | root | parent | next [\u2013]The relevant law is:39. Any exploration program which \"just happens\" to include a new launch vehicle is, de facto, a launch vehicle program.replyHermitian909 1 day ago | parent | prev | next [\u2013]I'm reminded of a recent interview with Chris Latner about the success of Swift - he credits the success to the fact that you could start with a large objective C project and begin writing Swift without rewriting anything. Part of Rust's success is off the back of a similar compatibility with C/C++.It is difficult for me to imagine Zig succeeding without a similar capability - which is to say I hope they do not follow through on this milestone.replyAshymad 1 day ago | root | parent | next [\u2013]But rust absolutely does not have any C/C++ compatibilty besides arguably very good FFI. And that's where zig shines. They have a c/c++ compiler built into the zig compiler via zig cc, that's even easier to use than clang or GCC due to having the benefits of a buildscript and baked in libcs for different architectures, making crosscompilation a breeze.In zig you _can_ actually start with a c codebase and rewrite it file by file in zig and you _can_ include c headers in your zig files verbatim. Both of these are not possible in rust.This milestone is only gonna remove the c++ (and objective c/c++) compiler for now from zig cc. So while you could argue this will ostracize people rewriting their c++ codebases in zig, I don't imagine there's actually many people like that. EDIT: I just looked at the discussion and there's actually a lot of people that use the c++ capapbilities.replycolinsane 1 day ago | root | parent | next [\u2013]> In zig you _can_ actually start with a c codebase and rewrite it file by file in zig and you _can_ include c headers in your zig files verbatim. Both of these are not possible in rust.well, you can: i have done this, with Rust. but yes, it\u2019s more the type of thing that well-resourced companies do rather than solo devs, because even with Bindgen and the like Rust really wants the atomic codegen unit to be the \u201clibrary\u201d, not C\u2019s notion of a \u201ccompilation unit\u201d. still, C FFI compatibility is exactly why porting from C to rust incrementally is feasible while C to, say Java, is probably a bigger leap.replyflohofwoe 1 day ago | root | parent | next [\u2013]You still need a separate compiler toolchain next to Rust in order to compile the C, C++ and ObjC dependencies which is a massive build system headache (especially across UNIX-oids and Windows).In Zig that all \"just works\" with the standard Zig install.replyduped 19 hours ago | root | parent | next [\u2013]Show me a C/C++ project that doesn't need a build system.replyflohofwoe 19 hours ago | root | parent | next [\u2013]My stuff for instance:https://github.com/floooh/sokol...inspired by:https://github.com/nothings/stb(here's how the sokol headers are integrated into a Zig project, note that there is only a build.zig which builds everything: https://github.com/floooh/kc85.zig)But it's not so much about build systems, but requiring a separate compiler toolchain to build any C++ or ObjC dependencies (Rust needs this, Zig currently does not - unless that controversial proposal is implemented).(also even complex C++ libraries can be wrapped in a build.zig, so you don't require a separate build system like cmake for the C++ dependencies)replyduped 18 hours ago | root | parent | next [\u2013]I still don't see why this is a problem. Single-header dependencies are cute but blow up compile times, and most of the world needs CMake/Meson/Autotools anyways so there's not an added cost to using it for your own projects.Similarly I don't really understand why you want one toolchain for a multi-language project. It's not that useful or convenient since it's going to need to be orchestrated with a buildsystem somehow.Like with Rust, you probably only have a build.rs file. It invokes a separate (possibly multiple) toolchains. Or with CMake. A simple project has a single CMakeLists.txt that can invoke any number of toolchains. I don't see why zig can't do that with a build.zig file, or why it matters.replyflohofwoe 17 hours ago | root | parent | next [\u2013]Did you try the stuff you are proposing? This is all a royal pita in real world projects which the Zig toolchain solved wonderfully.(also it's a myth that STB style libs increase compile time, that's only true for typical C++ header-only libs with inline methods and template code)replyhigherhalf 1 day ago | root | parent | prev | next [\u2013]> But rust absolutely does not have any C/C++ compatibilty besides [..]> In zig you _can_ actually start with a c codebase and rewrite it file by file in zig and you _can_ include c headers in your zig files verbatim. Both of these are not possible in rust.You can. Either via FFI and bindgen-ing headers, or by using c2rust. The latter is not just a toy ambitious project, but actually a very impressive piece of engineering and does produce a result where you can transpile a project or file and start rewriting file-by-file or function-by-function.replythe_duke 22 hours ago | root | parent | next [\u2013]c2rust is definitely cool, but it also supports transpiling to a single architecture, which often misses a lot of architecture dependent code and specialisations in real world c code. Especially because it has to do macro expansion and you only get the expanded code.It also doesn't supportal a good amount of more complicated c features.It's a help for sure, but the few times I tried I ended up just doing the rewrite by hand instead to actually cover all the cases.replyflohofwoe 1 day ago | root | parent | prev | next [\u2013]Can Swift really be called a success when it's only being used in the very narrow niche (the Apple software ecosystem - and only because it's essentially dicated by the platform owner)?replypjmlp 1 day ago | root | parent | next [\u2013]Yes, that is how languages become a success on the market, either being pushed by the platform owner no matter what, or by having a framework written in them that everyone feels like using.Everything else are aspiring extras in the cinema of programing languages, waiting on the sidelines for that major role that will come someday, it really will, one just has to believe enough.replythrowawaymaths 4 hours ago | root | parent | next [\u2013]Counterexample: pythonreplymike_hearn 23 hours ago | root | parent | prev | next [\u2013]Counter-example: Kotlin.replypjmlp 21 hours ago | root | parent | next [\u2013]Not at all, given the way Google is pushing it on Android, they are even mischievous enough to compare Kotlin with Java 6 when going on about why Kotlin.For all practical purposes ART has turned into the Kotlin Virtual Machine.However it so happens, that to keep the advantage of using Java libraries in the Android ecosystem, they actually need to support newer Java libraries unless they feel like rewriting all of them into Kotlin.So Android 12 and 13 got a subset of Java 11 LTS, and Android 14 is getting Java 17 LTS support.That doesn't change the reasoning that Android is all about Kotlin nowadays, unless one is writing platform code itself.replymike_hearn 18 hours ago | root | parent | next [\u2013]The idea Kotlin wouldn't be successful without Android isn't right. It was taking off in a big way even before Android did anything with it officially. Google's stated rationale for adopting it was because developers were already migrating to it regardless of what Google wanted.replypjmlp 18 hours ago | root | parent | next [\u2013]Google is in bed with JetBrains in what concerns Android.replydoctor_eval 22 hours ago | root | parent | prev | next [\u2013]How is that a counter example? Doesn\u2019t Kotlin fulfil a similar role for Android?replymike_hearn 18 hours ago | root | parent | next [\u2013]Kotlin wasn't created by Google and wasn't pushed by them. It's more like they accepted it because the Android developer base was adopting it organically en-masse anyway. That's also the case for many other places where Java is used.replypjmlp 18 hours ago | root | parent | next [\u2013]It was pushed by Android team, the same folks that came up with Jetpack stuff.Additionally JetBrains has their fingers all over the place in Android.Kotlin, Android Studio a mix of InteliJ and Clion, Compose,...replystill_grokking 21 hours ago | root | parent | prev | next [\u2013]That's not a counter example:https://miro.medium.com/v2/resize:fit:720/format:webp/1*sojK...Kotlin would be likely still nowhere without Google and Android.replymasklinn 1 day ago | parent | prev | next [\u2013]> Just as ambitious as it was for Lattner to create LLVM, I suppose.A big difference is there was an element of no choice to LLVM, at least in Apple\u2019s takeover of the project: GCC didn\u2019t want to allow / do what Apple wanted / needed out of it.replyvon_lohengramm 16 hours ago | parent | prev | next [\u2013]> now that it's declared as a goalNo. It's an unaccepted proposal.replytredre3 15 hours ago | root | parent | next [\u2013]By the creator and benevolent dictator of the Zig language.I think it's same to assume it's an official goal, now.replysomethingor 13 hours ago | root | parent | next [\u2013]Here\u2019s a list of rejected proposals made by the BDFL:https://github.com/ziglang/zig/issues?q=is%3Aissue+label%3Ap...replyTUSF 12 hours ago | root | parent | next [\u2013]And most of those were rejected without all that much pushback, as opposed to this one where there's about 100 comments already.replywhizzter 1 day ago | parent | prev | next [\u2013]binutils is quite a bit of a jack-of-all-trades code for handling binary code formats in portable ways, a compiler doesn't need half of it (incl legacy) if you focus it more like TCC, the larger part will be code-generation across a bunch of architectures.replybjourne 1 day ago | prev | next [\u2013]Two issues here. The first is code generation and the other is bootstrapping.Ime, the optimizing passes of a compiler are easy and fun to write. You have to read research papers to understand how register allocation and ssa form works, but it's fun code to write. You just send the ir through various optimizing passes, each refining it in some way. You can write high-quality optimization passes without llvm. But then you want to linearize your ir into machine code. This step is boring and mundane to write unless you care about all the different ways x86-32/64 can encode a \"mov [eax+8*ebx], 123\" instruction. If you are optimizing for binary size, do you want to bother measuring on which platforms \"push eax; push eax; push eax\" is shorter than \"add rsp,12\"? And this is just for x86. Multiply it tenfold for all the other non-x86 architectures irrelevant to most developers. The chance of having major bugs in the code generator for obscure architectures that stay undetected for years is very high.The second issue is bootstrapping. What compiles the Zig compiler written in Zig? You could, for example, have a non-optimizing minimal Zig compiler written in C that compiles the Zig compiler. But since it's non-optimizing, the Zig compiler would need to be recompiled with the optimizing Zig compiler. Not unsolvable problems, but ime long and complicated build processes risk driving away potential contributors.replyjakelazaroff 19 hours ago | parent | next [\u2013]I think this blog post addresses the bootstrapping issue: https://ziglang.org/news/goodbye-cpp/replybjourne 16 hours ago | root | parent | next [\u2013]Suppose you are implementing a new feature, how do you test it? First you compile the bootstrapping compiler. Then you use the bootstrapping compiler to compile an unoptimized optimizing compiler. Then you use the optimizing compiler to compile an optimized optimizing compiler. If the compiler doesn't rely on llvm then there will be more code to compile which will make this procedure slower. Especially since the bootstrapping compiler probably isn't very fast (though idk if this is the case with Zig).replysanxiyn 9 hours ago | root | parent | next [\u2013]No. Bootstrap is involved only if you are making a breaking change. For normal development, this doesn't change anything.replybjourne 3 hours ago | root | parent | next [\u2013]Any change to the compiler can break or cause unintended side-effects to bootstrap. For example, adding an import to a module in the compiler might break bootstrap if the imported module uses syntactic constructs the bootstrap compiler doesn't support. The problems are often very subtle.replysanxiyn 21 hours ago | parent | prev | next [\u2013]Zig already bootstraps from its C backend, so the second issue is not a problem.replythrowawaymaths 4 hours ago | root | parent | next [\u2013]Wasm, I believe.replyrunevault 1 day ago | prev | next [\u2013]With the amount Zig promoted being able to use it to compile c (and maybe c++ I forget) only to decide no LLVM at all seems wild. Without a LOT more people chipping in to support the odds of even coming close to the platform support of LLVM seems incredibly unlikely as well. I would understand planning to add another backend of their own for those who want that, but just getting rid of LLVM seems... rash?replyhryx 1 day ago | parent | next [\u2013]It might be rash if work had already started on it, but as with the other proposals on the issue tracker not labeled with \"accepted\", this is just a call for discussion and counter-proposals. At this point it's just the team collecting feedback, learning about affected use cases, and gauging feasibility -- opposite of rash, I'd say.replyaudunw 1 day ago | parent | prev | next [\u2013]If you read the text in the linked issue you'll see that there they're not entirely removing the LLVM backend. They're just decoupling it from the main binary, so you can still easily use LLVM as a backend if you have it installed on your system.Makes sense, kind of silly to have to bundle a 100MB+ copy of LLVM if you don't need it for the common case, and if you're a developer you'll probably have it installed already anyway.The problem could be that it'll be hard to guarantee that your Zig installation works properly with the version of LLVM you have installed? We'll see..replycobbzilla 1 day ago | parent | prev | next [\u2013]It\u2019ll still output LLVM bitcode, but it won\u2019t depend on LLVM libs anymorehttps://github.com/ziglang/zig/issues/13265replychrsig 1 day ago | parent | prev | next [\u2013]This was exactly my take on it.I'd recently been reading a bit more about zig, and even tried out using it as an easy way to compile c++ with llvm without having to fuss with system packages -- transitioning from c/c++ to zig was a major selling pointIt just seems really abrupt, certainly unexpected. I'm not saying it's the right/wrong thing for the project -- just really really out of left field from my point of viewreplyrunevault 20 hours ago | root | parent | next [\u2013]I did the pre-1.0 language thing once with Clojure and don't really feel like doing it again, but I've certainly been keeping my eye on Zig because it has some interesting ideas. But this set of changes, even if it is still possible to wire it up yourself, makes me way less interested.replyHamuko 1 day ago | parent | prev | next [\u2013]>and maybe c++ I forgetI use Zig as a C++ compiler on my Rust project since it was the least painful way to do cross-compilation in GitHub Actions.replyComputerGuru 17 hours ago | prev | next [\u2013]Approaching this from the lens of an interested observer with experience with other projects working on non-LLVM backends for their languages, I'm just struck by the amount of hubris in the linked proposal.If it weren't for the author, I'd have dismissed the whole thing as a low-effort GitHub issue by a Zig newbie. The underestimation of the work involved, the backhanded dismissal of all the work that has gone into LLVM, the \"obviously we can do it cheaper, faster, better\" confidence/machoism that exudes from each sentence or claim.. I'm disappointed.I've had nothing but respect for Andrew's work in the past so I'm going to extend him some grace and the benefit of the doubt and say that maybe it was just written in haste or on a whim without paying attention to how it came across. But it's not something that inspires me with confidence or lends me to give the proposal itself more of a chance.replyrcme 17 hours ago | parent | next [\u2013]I know nothing about LLVM backends, but it\u2019s pretty common that libraries aiming to solve 100% of users problems eventually become unwieldy and slow compared to a more optimized alternative. Web Pack vs. esbuild is an example of this.replyComputerGuru 15 hours ago | root | parent | next [\u2013]I get what you are trying to say but I have experience with both web and native tooling. This isn\u2019t a valid comparison. Moreover, llvm isn\u2019t one tool, it\u2019s modular, fairly well-architectured, and can be compiled with or without any of a million different features.replydagmx 1 day ago | prev | next [\u2013]While on one hand, I admire the fastidious desire to reduce dependencies, the trade offs seem pretty dire.The loss of C++ compatibility effectively removes the biggest thing that my Zig fan friends mention to me.The loss of performance (however temporary they say) is the other piece they mention.replychubot 1 day ago | parent | next [\u2013]Yeah it seems like most of the responses are against this proposalFor casual readers, it's a proposal, not something decidedreplytyg13 1 day ago | root | parent | next [\u2013]Sure, but it's a proposal from Andrew Kelley, the language creator, and it's got a bunch of thought-out subitems that seem to have real progress being made. It seems more likely than not that this will come to pass, unless the community reaction really is heavily against.replytiehuis 1 day ago | root | parent | next [\u2013]I wouldn't assume that just because Andrew has written the proposal it will be accepted. There have been plenty of times where proposals from Andrew have been rejected and/or reworked.The sub-items of this task are still valuable to complete even if this overarching proposal were declined. Most of them are not being completed as a prerequisite for this proposal. There are benefits gained even without the full removal of LLVM.I can really respect the really wide-reaching views and goals of Andrew with zig and in proposals like this, even if I don't agree.replypaddw 1 day ago | root | parent | prev | next [\u2013]I mean, one of the checkboxes under LLVM is literally \"optimization passes\", so... I don't know how close they are to the end goal in terms of progress actuallyreplytyg13 1 day ago | root | parent | next [\u2013]I did get quite a hearty chuckle out of that.replyfrmdstryr 1 day ago | prev | next [\u2013]So I spent ~4 years writing all my embedded projects (and libraries) in Zig and now several \"tier 1\" supported arches are just going to be dropped?It's your language so do whatever you want but please adjust the branding accordingly...replyaudunw 1 day ago | parent | next [\u2013]Are they being dropped?Im guessing you'll have two categories of tier 1 support: - Built-in tier 1 support. - Tier 1 support through the optional LLVM backend.If they already have tier 1 support for an architecture, I don't see why they'd loose that support when they make the LLVM backend an optional dependency?And as Andrew writes in the proposal, this way might provide a path for better support for more obscure architectures. I would happily work on a backend for Zig for some interesting processor architecture. No way I will ever contribute to LLVM. Working with C++ in not something I'll ever do to funreplyfrmdstryr 23 hours ago | root | parent | next [\u2013]\"In the near term it would also reduce the number of targets Zig supports\", I hope not but it sure sounds like it.replyMuffinFlavored 1 day ago | parent | prev | next [\u2013]They're dropping LLVM by re-implementing everything it does in their own homegrown fashion?...To what benefit? Isn't this a waste of resources?replydelphLonepaw 1 day ago | root | parent | next [\u2013]LLVM just works well on the front that clang uses, after that, llvm itself is a wild beast full of worms, which is becoming more and more painful to work with if you are a language creator/mantainer, A lot of untested paths, and hidden bugs that zig has hit before... many times.It will NOT reimplement everything, if you read the proposal, it's in favour of changing the LLVM dependency (the libs) not dropping LLVM IR generation, this will come with performance regression since now will be up to the team to get the correct IR, and making decisions LLVM IR generation does already in LLVMThe problem is that clang is being dropped, which means, unless we have a new C++ front made in zig (a-la AroCC for C) we are gonna suffer quite a bit for projects using C++ with zig.replyqalmakka 1 day ago | root | parent | next [\u2013]> unless we have a new C++ front made in zigWriting a C++ compiler is several order of magnitude more complicated than writing a C, Java, Go or Zig compiler. There's a very good reason there are only 3 in existence despite how ubiquitous C++ is (and even then, it takes years for them to keep up with the latest standards). C++'s grammar is type 0, there's isn't even an EBNF definition of it because it's pratically impossible to write a complete one. Clang only succeeded thanks to massive investments from the biggest players in the industry, and GCC/MSVC simply grew alongside the language. All other C++ compilers died a horrible death a long time ago.replyDylanSp 17 hours ago | root | parent | next [\u2013]Out of curiosity, does Intel's icc compiler see much use? It looks like it uses LLVM these days, but its frontend presumably still needs to handle all of C++'s complexity.replytyg13 15 hours ago | root | parent | next [\u2013]ICC is deprecated and will no longer see a release, but it uses the EDG front-end. Its replacement, ICX (the oneAPI compiler), uses clang as its front-end.There are essentially only four extant C++ front-end implementations: GCC, Clang, MSVC, and EDG. All other C++ compilers are based on one of these four implementations, or have since gone extinct. (Except maybe Green Hills, but I can't recall anymore if their front-end is still in-house.)replyDylanSp 15 hours ago | root | parent | next [\u2013]Got it, thanks! I knew that Intel had a compiler for C and C++ from reading blogs about compiler research, but I didn't know any details about its current architecture.replygpderetta 1 day ago | root | parent | prev | next [\u2013]> unless we have a new C++ front made in zigthat seems a monumental undertaking.replybrucethemoose2 1 day ago | root | parent | prev | next [\u2013]The reasoning seems to be the flood of LLVM bugs, but I don't think reinventing such a large wheel will be any easier.replyprpl 1 day ago | root | parent | next [\u2013]It sounds like some of those bugs are just related to people using distro compilers?replyharerazer 1 day ago | parent | prev | next [\u2013]I mean, it\u2019s no secret that zig is pre 1.0. I\u2019m not sure this is on them, although it does seem like a drastic proposal.replybrabel 1 day ago | root | parent | next [\u2013]One of the mantras for Andrew Kelly has been \"do not use Zig in production\" until it hits 1.0.People know that, but it's difficult to avoid using it for real things once you've tried it and it works :D.I haven't done that with Zig, but with Kotlin things like serialization/coroutines/kotest/KAPT (it was the same feeling: oh this stuff is \"Experimental\" but so cool, I can't do real Kotlin without them!!)... well yeah, I spent many hours rewriting stuff due to that, and totally acknowledge that was on me.replyTUSF 1 day ago | parent | prev | next [\u2013]This is only still at the proposal stage. The Github issue is mostly for posting usecases for and against, etc\u2026 It's not \"Accepted\".replyjanpolak 21 hours ago | parent | prev | next [\u2013]Just wanted to point out that this is just a proposal, so if enough people voice their opinion, which many have already done, I am sure the core team will adjust their approach.replyblindseer 1 day ago | prev | next [\u2013]One of the main reasons Zig was interesting to me was the fact that I could drop it in as an alternative to a C/C++ compiler. On Windows, my friends have mentioned how it is easier to install Zig as a C/C++ compiler than any other alternative.If this proposal is accepted, I personally think Zig will drop to the popularity level of Hare or other extremely niche languages. Getting my colleagues to even try Zig out required me sending them articles about how Uber was using it in production. There is no way my colleagues would even have given it a second thought if it didn't have immediate value to their existing projects.But I get where the proposal is coming from. LLVM compile times can seem awful, and there's lots of neat optimization tricks you could implement with your own byte code. And dealing with bugs in LLVM is basically a no-go, I've seen this happen in the Julia ecosystem as well.If my recommendations are worth anything, I think Zig should1. Use a custom bytecode for debug builds - fast build times, fast debug times etc 2. Use LLVM for release builds - fast runtime performance, slow release performanceIf they can manage 1.) while still maintaining support for cross compiling C/C++ (just pass that part off to LLVM?) I think that might be the best of all worlds, with the tradeoff that there's additional backend code to maintain.replyvchuravy 17 hours ago | parent | next [\u2013]> And dealing with bugs in LLVM is basically a no-go, I've seen this happen in the Julia ecosystem as well.As one of the folks dealing with LLVM bugs in the Julia ecosystem.Yes it requires a distinct skillet different from working on the higher-level Julia compiler and yes it can sometimes take ages to merge bugfixes upstream, but we actually have a rather good and productive relationship with upstream and the project would get a lot less done if we decided to get rid of LLVM.In particular GPU support and HPC support (hello PPC) depends on it.But this is also why we maintain the stance that people need to build Julia against our patchset/fork and will not invest time in bugs filled against Julia builds that didn't use those patches. This happens in particular with distro builds.replyWalterBright 1 day ago | prev | next [\u2013]The DLang has 3 compilers:1. gdc - based on the Gnu compiler collection back end2. ldc - based on the LLVM back end3. dmd - based on the x86 code generator that I wrote for Zortech/Symantec/Digital MarsThey each have their pluses, minuses, and targets. But the D language each supports is the same.Overall, our users like the choice. Some even use more than one.replyaudunw 1 day ago | parent | next [\u2013]Ah, the obligatory comment from Walter Bright talking about D in posts about Zig(Nothing wrong with it, just a bit funny how predictable it has become)I guess the interesting difference in approach here, is that D seems to have completely separate compilers, while it looks like the main Zig compiler will support LLVM as a backend if you have it installed? If true, I like the approach Zig is going for.replyagos 1 day ago | root | parent | next [\u2013]yesterday on a thread on DMD somebody quipped \"Funny how WalterBright seems to comment in every single HN thread other than this one...\" and I thought it was hyperbole. Next HN thread I open, I'm proven wrongreplyAndyKelley 16 hours ago | root | parent | next [\u2013]C'mon, y'all, give him a break. It's cool that we get to hang out with the creator of D here.replybrabel 1 day ago | parent | prev | next [\u2013]That's cool. Another language with multiple compilers is Common Lisp, which has a dozen or so production-ready compilers (some commercial, but most free).That allows people to use the fastest compiler during development, and the fastest runtime (or smallest memory footprint) compiler for the final release, which is really useful.Also, just having a language specification which all compilers adhere to ensures that the language is stable and won't just break things under you (for better or worse, there are advantages for languages like Zig that can still change anything they want in order to make the language more consistent/cleaner/more powerful). I tend to value this stability a lot more these days - it lets me put all my effort in creating real value for users instead of constantly keeping up with development tools.replymhh__ 21 hours ago | parent | prev | next [\u2013]Having the choice for advanced users is a plus but I think having to choose is a big negative.replyWalterBright 16 hours ago | root | parent | next [\u2013]Ironically, when there was only one choice that was described as a big negative. Our experience with the troika has been a clear positive.replymhh__ 15 hours ago | root | parent | next [\u2013]15 years later it's negative. The user experience of having to download and switch compilers (or even think about it at all) is terrible, especially given that (after performance) one of the main motivators of switching to ldc (i.e. all serious use of D to make money) is either a bug or lack of platform support in dmd.replyjanpolak 20 hours ago | root | parent | prev | next [\u2013]Most importantly it results in a significantly increased workload for the maintainers, and spreads out effort over a bigger area. So the most likely outcome is a language with multiple mediocre compilers, instead of one really good one that everyone works on.Which is the exact opposite of what the intention behind this proposal is, which is to make the language more maintainable.replymhh__ 19 hours ago | root | parent | next [\u2013]LDC and GDC are both very good compilers.Technologically D suffers more from having a single frontend implementation than having multiple backends.replycoldtea 1 day ago | parent | prev | next [\u2013]>Overall, our users like the choice.All 10 of them? I mean, if Zig's target is eventual wide adoption, DLang is not a good precedent to model upon.replymmastrac 1 day ago | prev | next [\u2013]The correct time to build something without LLVM was years ago, but taking the C++ functionality out now will probably be the end of Zig. I'm surprised they didn't announce a plan to write their own C++ compiler in Zig instead of phasing it out.replysidewndr46 1 day ago | parent | next [\u2013]Just writing a parser for C++ is a gargantuan project. I'm not even sure if an individual can write a C++ compiler if they started on their 18th birthday. There may not be enough hours left in their life to write a functioning compiler.replypjmlp 1 day ago | root | parent | next [\u2013]Check the history of Circle, not only did Sean Baxter implement a full C++ compiler frontend, it has lots of extensions from all C++ wannabe replacements and a Rust like borrow checker.replystrager 1 day ago | root | parent | prev | next [\u2013]Sean Baxter is doing a decent job with his Circle compiler, so I hear. https://www.circle-lang.org/replyjuunpp 1 day ago | root | parent | prev | next [\u2013]I forget, but what was that C++ parser test suite that almost no compiler passed?I bet you'll solve P=NP before finishing that C++ parser.replyoverflyer 20 hours ago | prev | next [\u2013]One of the its biggest features is that the Zig toolchain is vastly superior to any other and opens up new possibilities to Devs of C/C++/Obj-C. One of its biggest selling points is to be able to use build.zig inside of projects with a C/C++/Obj-C codebase and thus get around using a shit ton of build tools.If zig cc and zig c++ die I would instantly stop using the language!replymorning-coffee 17 hours ago | parent | next [\u2013](Rust user here, but admirer from afar of Zig and the principles it seems rooted in.)My peanut gallery observation is that a very bright person named Andrew set out on a journey of hard work to come up with a new language. Along the way he (and others) solved many tough ancillary problems related to the toolchain of this new language and how it should provide a useful path for interoperability and migration from code written in other languages.The toolchain innovations were noticed, embraced, and leveraged by users of other languages as it made their lives easier in contexts where they weren't even using the Zig language.Now, for Andrew to make even more innovative progress on his endeavor, he needs to undo some of the toolchain innovation and remove complexity that was initially used to bootstrap his endeavor. Removing complexity (from language) is one of the admired traits of this bright person, and here they are applying that good trait again to move the whole project forward.But 'lo! Other users of the toolchain innovation will be affected... some would say they even appear \"entitled\" to these innovations... as if their collective need somehow outweighs Andrew's right to direct his energies to his project in the way he decides.This whole thing smells like a story I read once... I think it was called \"The Fountainhead\".replyrichardwhiuk 7 hours ago | root | parent | next [\u2013]The net result might be a split into zig-cc and zig-lang.I think the disappointment might come with the ratio who choose zig-cc.replylll-o-lll 1 day ago | prev | next [\u2013]Zig wants to be the world new C not so much the worlds new C++. You\u2019ll note that C cross compilation would still be supported under this proposal.I think this might be the right choice. C is currently used heavily in the embedded world, and that\u2019s a space where llvm is not good. If I was Zig, I\u2019d want to be able to target all the microcontrollers and this is the only real way to achieve that.replyDannyBee 1 day ago | prev | next [\u2013]Some of this reasoning is just wild.1. \"We can attract direct contributions from Intel, ARM, RISC-V chip manufacturers, etc., who have a vested interest in making our machine code better on their CPUs.\"They are nowhere near popular enough (or used enough by some particularly important customer) for any major architecture vendor to spend any time contributing except as someone's random side project. To think otherwise is ... really out there.2. \"We can implement our own optimization passes that push the state of the art of computing forward.\"There are in fact, no magic bullets. Once you pass the baseline of optimization capability, the reason these compilers do well is because they've been worked on forever, and made better 0.2% at a time.Also, anything you implement they can implement. Maybe it takes annotations, or whatever, but that's about speed and not capability.3. \"Compilation speed is increased by orders of magnitude.\"Uh, not if you are doing #2. Most optimization passes, especially when you are first productionizing research, are quite bad. It takes a tremendous amount of applied engineering to make them fast.This is what i did on both GCC and LLVM. Implement and speed up ad nauseum. I implemented plenty of high-optimization-value, never been productionized before algorithms. It usually took a few versions and lots of slow-compiler bugs to figure out the best way to implement. It turns out most researchers are not spending their time working on the compilation speed. At best, they care that it's passable.For existing well-productionized algorithms (which don't push the state of the art), you will not get orders of magnitude speedup. You may get some percent depending on how you structure your compiler.There are certainly slow parts of LLVM, but it's hubris to believe you are going to make something both better optimizing, and seriously faster, for this kind of language. There are other languages for which it is true. Zig is super unlikely to to be one of them.The way you gain compilation speed for this kind of language is to optimize less. Spend as little time processing things into machine code as possible, using as fast of algorithms as possible, and where you can't, relying on heuristics and such more to help generate good enough code most of the time.There is more, but man, this feels out there.If they said \"we want to get 90% of the performance at 60% of the cost\", sure, maybe. But saying, basically, we will get >100% of the performance at \"orders of magnitude\" (their claim) less cost is just, as i said, a wild idea. I wish them the best of luck.Everyone who tries to reinvent good infrastructure is doomed to discover why that infrastructure was invented in the first place .replyjroesch 1 day ago | parent | next [\u2013]Long time compiler hacker/engineer and compiler/programming language PhD here all great points. Worth saying out loud that many reasons why this stuff is slow is not due to bad code, its due to the fact that many of the best algorithms are in higher complexity classes and just scale poorly with program/translation unit size. For example when I was working on `rustc` a big challenge was heavy reliance on inlining and inlining has a cost, plus it increases program sizes making everything else take longer as well.I feel like Go already went through a whole saga of this where the community started with \"LLVM and SSA are bad and slow\", then a few years go by and they end up building their own SSA IR and spending a bunch of time trying to bring compilation time closer to what it was before as it made everything much slower.replyvocx2tx 1 day ago | root | parent | next [\u2013]> I feel like Go already went through a whole saga of this where the community started with \"LLVM and SSA are bad and slow\"I've been a contributor since the Go compiler was a tree-based C program and I've never heard anyone say that. What they said (and it's in the Go FAQ page) is: \"At the beginning of the project we considered using LLVM for gc but decided it was too large and slow to meet our performance goals.\" [1]If you're building a language with the explicit goal to make it compile fast, it's objectively true that starting out with LLVM is not the best approach. You'll get incredible runtime performance of the generated code since the early days, but NOT fast compilation. The Go makers choose a different tradeoff.> and they end up building their own SSA IRThey switched to a SSA IR because it was a good idea to begin with, after an initial phase with the tree-base prototype. I've also never heard anyone argue that \"SSA is bad\", despite what you claim. The first compiler was tree-based because they reused a simple tree-based C compiler from plan9.> building their own SSA IR and spending a bunch of time trying to bring compilation time closer to what it was before as it made everything much slowerThe new compiler was ported to Go (machine-rewritten from C) and that's the main reason it was ~2x slower than the old compiler. It's not due to the switch to a SSA-IR.[1] https://go.dev/doc/faq#ImplementationreplyDannyBee 20 hours ago | root | parent | prev | next [\u2013]\"Worth saying out loud that many reasons why this stuff is slow is not due to bad code, its due to the fact that many of the best algorithms are in higher complexity classes and just scale poorly with program/translation unit size\"Yes, this is totally true.It's also possible to affect this in theory but hard in practice. Usually you shoot for making it O(N^2) (or whatever) where N is the number of variables you want to try to optimize instead of N being number of blocks.The complete GVN and GVN-PRE in LLVM is theoretically N^3 or N^4, but as engineered it's often much faster (while getting more optimization) or at least not more than a few percent slower than the the existing O(N^2) GVN. It achieves this by being sparser in most cases. The old GVN has to iterate the algorithm, and iterates non-sparsely. Everything is reprocessed because it doesn't know what can change. The new one iterates only the things that could change using fine grained dependency tracking (something akin to how sparse constant prop works). This is often the best you can do.I will say it's possible to affect these time bounds in theory because if you go down the single static rabbit hole, you realize it's more generally applicable. Kenny (and others) proved this in his thesis about sparse dataflow. That was the whole point. SSA is just one example of a form that enables things to be linear time (and in fact, you can do it without SSA at all using interval methods and such). There are papers that show this about other SS* forms and show examples, but they were mostly (sadly) ignored.Concretely, for most optimizations like PRE/etc, there are linear time single static transforms of the IR that will make the optimization linear time (Or at least remove a factor of N for you) by explicitly exposing the dataflow in a way that matches what the optimization algorithm wants.This is awesome in theory - like really cool when you think about it (if you are a compiler nerd), but also completely impractical (at least, AFAIK). Rewriting the IR form for each optimization to the exact requirements of the optimization (single static use, single static exposed uses, single static upwards exposed uses, single static exposed defs, etc) is much more expensive in practice than well engineered, higher complexity, \"N in the number of variables\" optimizations.Equality saturation stands more of a chance, IMHO.replydefen 1 day ago | parent | prev | next [\u2013]I agree that it's probably impossible to write something that is orders of magnitude faster than LLVM and better than LLVM at optimizing, but I don't see that claim in the original text.It seems like a lot of work but also doable to create something that is orders of magnitude faster than LLVM for unoptimized debug builds. Furthermore, the Zig compiler might be an easier thing to work with than LLVM/Clang for doing productionizing of optimization research.replyDannyBee 21 hours ago | root | parent | next [\u2013]Sure, the latter is possible.I read the claims and comments differently than you, fwiw. It definitely reads like people who think they can make it both faster and better.replySolvency 1 day ago | root | parent | prev | next [\u2013]Just to play devils advocate..who would've thought Javascript would ever end up as blazingly fast as it has become since V8. Maybe Zigworld can do it.replyjroesch 1 day ago | root | parent | next [\u2013]As the parent comment said, and I mentioned in my reply. JavaScript was just incredibly poorly optimized/not compiled and they applied 20-30 years worth of compiler research to make it significantly faster. You also had an alliance of every hyperscaler working on the tooling for a decade plus with help from all major hardware vendors to bring the best performance out of it. One driver of LLVM was Apple and WebKit which at one point was using LLVM for its JIT compiler so many improvements figured out in that period have also already been applied to LLVM.LLVM already has decades of research applied to it to make it produce fast code, it will be incredibly challenging to even match its performance across all the targets it supports let alone improve on it in significant ways. It would be better to spend the time building an optimization pipeline for Zig itself and being more thoughtful about what code you send to LLVM versus trying to replace it wholesale.replysaagarjha 1 day ago | root | parent | next [\u2013]Apple, of course, dropped LLVM at some point after it didn\u2019t meet their latency needs.replydagmx 19 hours ago | root | parent | next [\u2013]Apple\u2019s entire ecosystem is based on clang. How does that mean they dropped LLVM? They\u2019re one of the primary maintainers.replysaagarjha 13 hours ago | root | parent | next [\u2013]For WebKit.replydagmx 2 hours ago | root | parent | next [\u2013]Ah of course. Sorry the thread was long and winding so I didn\u2019t realize that\u2019s the part you were referring to.For reference to anyone else, this is what they\u2019re referring tohttps://webkit.org/blog/5852/introducing-the-b3-jit-compiler...replypjmlp 1 day ago | root | parent | prev | next [\u2013]Anyone that has ever played with dynamic languages like Smalltalk and SELF, or read their research papers.replyanonymoushn 1 day ago | parent | prev | next [\u2013]My impression is that LLVM spends the bulk of its time chasing pointers, so one could fix the issue by \"only\" changing the layout of the data to one that is friendlier to computers.replyanonymoushn 7 hours ago | root | parent | next [\u2013]downvoters are of course free to post perf traces demonstrating that LLVM retires many instructions per cycle :)replyfulafel 1 day ago | prev | next [\u2013]Surprising that the issue is full of comments from users who are currently using Zig to compile C++. Hopefully this won't be the deciding thing.replyflohofwoe 1 day ago | parent | next [\u2013]There's a ton of C++ libraries that won't be rewritten in C anytime soon, and even loss of ObjC support is very painful for anybody caring about the Mac platform.The ability to build mixed C/C++/ObjC/Zig projects without having to deal with multiple compiler toolchains was indeed one of the killer features of Zig to me and the one thing that separated Zig from other \"better C\" attempts.Hopefully the Zig project is at least thinking about bundling a Clang toolchain with the vanilla Zig distribution, and call Clang from 'zig cc'. To the user this wouldn't make a difference compared to the current feature set (apart from losing backend support for some CPU architectures), but still decouple Clang and LLVM from Zig.replyschemescape 1 day ago | prev | next [\u2013]I'll admit that I've only considered using Zig for its ability to easily compile (and cross-compile) C/C++ code into static binaries.Hopefully if any of that functionality gets removed someone manages to fork off the \"C/C++ magic\" part into its own project. Clang itself is much less convenient to use.replypfdietz 1 day ago | prev | next [\u2013]This move... is it for great justice?replytimmytokyo 1 day ago | parent | next [\u2013]I see your comment is getting downvotes, but that's probably because people didn't get the joke. In addition to being the name of the programming language, Zig is a character in the old Namco 'Zero Wing' game, which is where the meme \"All your base are belong to us\" comes from [1]. \"For great justice\" is part of the same meme.[1] https://en.wikipedia.org/wiki/All_your_base_are_belong_to_usreplythaliaarchi 1 day ago | root | parent | next [\u2013]Andrew Kelley even referenced this in the proposal:> In exchange, Zig gains these benefits:> - All our bugs are belong to us.> - \u2026replysteveklabnik 18 hours ago | root | parent | prev | next [\u2013]> but that's probably because people didn't get the joke.It\u2019s more that Hacker News tends to collectively frown upon posts that are only jokes, if I had to guess.replyolliej 1 day ago | root | parent | prev | next [\u2013]I did not get this, and appreciate you providing the contextreplyjuunpp 1 day ago | root | parent | next [\u2013]It does require a bit of a PhD on gaming and Internet history.replyCTDOCodebases 1 day ago | prev | next [\u2013]I misread the title and expected to see a LLM that was designed for the specific use case of filing for divorce.replyyathaid 1 day ago | parent | next [\u2013]Same! :)replykeyle 1 day ago | prev | next [\u2013]Every time I hear about LLVM, it turns into a rant. Clearly there is a problem there that needs to be fixed. Maybe the LLVM project team should address those issues.replytyg13 1 day ago | parent | next [\u2013]The \"problem\" with the LLVM project is its massive success, coupled with its incredibly difficult problem domain. Turns out it's actually really hard to write modular compiler infrastructure that serves as the optimizer and code generator for N different arbitrary programming languages. The fact that it works in this capacity at all, and still manages to be competitive with GCC in its original use-case (being a C/C++ backend) is a monumental and unmatched achievement.As someone who works on an LLVM-based compiler at $DayJob and also has written a compiler front-end that uses LLVM in my free time, I do have a ton of gripes, but any time I feel particularly frustrated by them, I spend a little bit of time working on my non-LLVM backend. After a few days of angry swearing with little to show for it, I go back to working with LLVM with a much greater appreciation for what it's giving me.replyjuunpp 1 day ago | root | parent | next [\u2013]You got pro tips for working with LLVM types after parsing LLVM IR? I can't for the life of me figure out where in the class hierarchy I am, and the doxygen is... interesting. Language wrangling is much nicer in a language with proper ADTs like Haskell, but I also feel like there's probably that bit of LLVM documentation that I haven't read.replyDylanSp 15 hours ago | root | parent | next [\u2013]I'm also interested in this. I tried using the Node bindings from https://github.com/ApsarasX/llvm-bindings in Typescript, its types look like they map pretty closely to the original LLVM types; figuring out even a basic example was a bit tricky with LLVM's documentation.replybitcoinmoney 1 day ago | root | parent | prev | next [\u2013]Btw, is there a good learning pathway for LLVM/MLIR for folks w/o compiler background? I come mostly from HW but is super interested in the topic due to work-related stuff. Since your day job is LLVM related maybe you can give great advice.replyfuncDropShadow 1 day ago | root | parent | next [\u2013]Yes, learn about compilers. I am only half joking here.replypjmlp 1 day ago | root | parent | prev | next [\u2013]When clang came about, GCC was already renamed into GNU Compiler Collection.replydagmx 1 day ago | parent | prev | next [\u2013]Part of the issue is that LLVM is stuck between two very hard places.1. Needing to support tons of different platforms with various different documented and undocumented behaviours2. Needing to support many languages with specifically undefined behaviour.Trying to bridge the undefined nature of the two sides means that things can be fragile. Assumptions that worked for one set of undefined problems may not work for another.But so much depends on LLVM these days that I can\u2019t think of it as anything but a success. A flawed success but one that is doing its best to bring order to a naturally chaotic problem space.GCC and MSVC have similar problems because it\u2019s inherent to the problem space. So while it\u2019s frustrating hitting those bugs, everyone in the space knows they aren\u2019t fundamental issues with the project itself.replyplorkyeran 1 day ago | parent | prev | next [\u2013]It's not obvious that \"LLVM, but not incredibly frustrating\" is a thing which can exist. I don't think it's likely, but it's possible that in a few decades the widespread view will be that the very concept of LLVM was a mistake, and a universal compiler backend is just a trap which makes it easy to bootstrap a language but inevitably causes massive problems down the road.LLVM does have plenty of incidental problems which are clearly fixable and just need a lot of work, but even if you fixed all of them you'd still have people who use LLVM ranting about it.replysanxiyn 1 day ago | root | parent | next [\u2013]MLIR is \"LLVM done better\", in fact by the same person. It fixes many of unforced LLVM problems, for example LLVM's inability to parallelize code generation.replyfulafel 23 hours ago | root | parent | next [\u2013]MLIR is part of LLVM, no? And going by the website sounds like it uses LLVM (or bring-your-own) backend for platform specific code generation.replyDennip 22 hours ago | prev | next [\u2013]Does anyone have any good examples of Zig being used as a build system for a large project?Coming from a Windows world when my gigantic C++ project is hidden inside a vcxproj I dont delve into that often, I tried to compile a standard autoconf based project into wasm the other week and eventually gave up.Use autoconf to create your cmake to create your make which builds your lib? and wrap all those calls with emscripten calls...or something along those lines. It was exhausting. Eventually it errored out becuase it couldn't decide if the size of a size_t was available. I was tempted to just remove that line from the cmake.replykprotty 22 hours ago | parent | next [\u2013]Do any of these count?https://www.uber.com/blog/bootstrapping-ubers-infrastructure...https://github.com/tigerbeetledb/tigerbeetle/blob/main/build...https://github.com/oven-sh/bun/blob/main/build.zigreplyDennip 22 hours ago | root | parent | next [\u2013]Yes! Thanks!replyJediPig 16 hours ago | prev | next [\u2013]Andrew even thinking about dropping LLVM, says all I need to know. Its going to become the next D language of 2020s. LLVM has decades of mistakes FIXED, and rewriting the first time, even the 6th time is always... filled with huge mistakes and security issues...HUGE.brew uninstall zig. Thats what I did when I read it. I do not want to waste any of my time on soon to be dustbin tech.replyfouc 1 day ago | prev | next [\u2013]Since they only mention dropping support for C++, Objective-C, and Objective-C++, I assume this means C is still supported?replyxouncle 1 day ago | parent | next [\u2013]yeah, but not using ClangreplyPufPufPuf 2 hours ago | prev | next [\u2013]Oh no, Zig is going down the Elm pathreplyDrNosferatu 19 hours ago | prev | next [\u2013]My feeling is that if Zig drops C++ support, there seems to be enough momentum on the C++-dependent users, that they will just fork Zig...Can't LLVM be optional, and have unit tests guarantee that it works as before?The above, or - as mentioned elsewhere, implement a C++ compiler in Zig: quickly, and before making any breaking changes - quite a tall order.Or bring into Zig an existing pure-C, C++ compiler....TinyC/libtcc? PCC? LCC? (wild guesses)replyDrNosferatu 18 hours ago | parent | next [\u2013]...or include an external C++ to C transpiler?replystephc_int13 22 hours ago | prev | next [\u2013]I think they should keep LLVM as a fallback or as an optimizing backend.This part is pretty solid, even if all the dependencies is hard to deal with, I am not convinced that building your own would lead to better results.The most annoying part is the slow compilation in non-release, this can be fixed more easily with support for a minimal number of targets.replythrowawaymaths 4 hours ago | parent | next [\u2013]I don't think the proposal says that llvm will be dropped as an optimising backend. It also doesn't say that you can't call clang at compile time using some other mechanism. It just says the zig compiler will not depend on llvm.replydhab 22 hours ago | prev | next [\u2013]Really commend the ambitious move here. If successful it would be such a differentiator blazing a new trail!replyvsskanth 1 day ago | prev | next [\u2013]Did they consider MLIR ? If not, Did they mention why?replytrogdc 1 day ago | parent | next [\u2013]Not sure how MLIR would solve anything, there's no bridge from C++ to MLIR, or from MLIR to assembly, other than going through LLVM.replytriggercut 22 hours ago | prev | next [\u2013]Hands up if you initially parsed this as using a LLM to file for divorce?replyKamq 1 day ago | prev | next [9 more]KingMob 1 day ago | prev | next [2 more]hota_mazi 1 day ago | prev [\u2013]Given the barrage of negative comments on the PR and here as well, it really feels like Andrew is the only person in favor of that change.It's his language, obviously, but I strongly suspect that if this PR goes through, it will completely kill any kind of momentum that Zig has today and will most likely doom the language to obscurity.Which would be a real shame.replypjmlp 1 day ago | parent [\u2013]Unless they sort out the issues related to use-after-free, the value preposition is hardly any better than using C and C++, with the memory corruption tooling there is around from the last 30 years.replyGuidelines | FAQ | Lists | API | Security | Legal | Apply to YC | ContactSearch:",
    "hn_summary": "- The Zig programming language is considering moving away from its dependency on LLVM, which has raised concerns among users.\n- Some users believe that removing support for C++ and Objective-C in Zig could hinder its popularity and adoption.\n- There are concerns about the potential loss of performance and the resources required to build and maintain a new compiler backend for Zig if it moves away from LLVM."
  },
  {
    "id": 36532812,
    "timestamp": 1688122610,
    "title": "Microwaved plastic containers release microplastics into food",
    "url": "https://pubs.acs.org/doi/10.1021/acs.est.3c01942",
    "hn_url": "http://news.ycombinator.com/item?id=36532812",
    "content": "pubs.acs.orgChecking if the site connection is securepubs.acs.org needs to review the security of your connection before proceeding.Ray ID: 7dfdd45119c2e966Performance & security by Cloudflare",
    "summary": "N/A",
    "hn_title": "Microwaved plastic containers release microplastics into food",
    "original_title": "Microwaved plastic containers release microplastics into food",
    "score": 306,
    "hn_content": "- Microwaved plastic containers release microplastics into food, according to a study\n- Plastic containers labeled as \"safe\" or \"BPA-free\" may still contain harmful substances\n- More than 50 different chemicals are being used as alternatives to BPA in plastics, some of which may be worse\n- Storing warm or liquid foods in plastic containers can increase the likelihood of plastic contamination\n- Glass containers are a safer alternative to plastic for storing and heating food\n- The Aeropress, a popular coffee maker, will be releasing a premium version made out of glass later this year\n- Glass containers are durable, easy to clean, and can look new for years with proper care\n- Using glass containers helps to reduce plastic waste and potential health risks from microplastics\n- Some people prefer stainless steel or ceramic containers for their food storage and heating needs\n- Plastics, including those labeled as safe, may still contain harmful chemicals or cause unknown side effects\n- The choice of containers for food storage and heating can affect health and the environment- The post discusses the potential dangers of microwaving food in plastic containers, as it can result in the release of microplastics into the food.\n- Multiple studies have found microplastics in various sources, including water bottles, plastic baby bottles, and plastic containers.\n- Microplastics can have negative effects on human health, and their consumption is a concern.\n- Plastic utensils, such as spatulas, can also degrade when exposed to high heat, making them less useful and potentially releasing microplastics.\n- There is ongoing research to understand the impact of microplastics on human health, including their role in reproductive issues and cognitive impairments.\n- It's important to consider alternatives to plastic containers, such as glass, which can be a safer option for storing and heating food.\n- The post highlights the need for further research and regulations regarding the use of plastics in food storage and preparation.\n- Personal experiences and opinions regarding plastic usage vary, but it's essential to consider the potential risks associated with the release of microplastics.",
    "hn_summary": "- Microwaved plastic containers release microplastics into food, which can have negative effects on human health.\n- Plastics labeled as \"safe\" or \"BPA-free\" may still contain harmful substances, as over 50 different chemicals are used as alternatives to BPA.\n- Glass containers are a safer alternative for storing and heating food, as they do not release microplastics and are durable and easy to clean."
  }
]
