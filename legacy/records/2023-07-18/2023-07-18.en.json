[
  {
    "id": 36757542,
    "timestamp": 1689597849,
    "title": "A Firefox-only minimap (2021)",
    "url": "https://www.stefanjudis.com/a-firefox-only-minimap/",
    "hn_url": "http://news.ycombinator.com/item?id=36757542",
    "content": "HomeArticlesScreencastsProjectsAboutOther stuffNewsletterStefan on MastodonStefan on TwitterRSSA Firefox-only minimapUpdated atJul 17 2023Reading time1minViews...Get personalized content recommendations to help make your emails more engaging.ADS VIA CARBONGreetings! \ud83d\udc4bIf you discovered this page, you're part of the few Firefox desktop users out there (market share is only 4% right now) and wondered how my blog posts' minimaps are made.If you're not using Firefox, this is how the minimap looks like.Firefox is the only browser that supports the fancy element() CSS function (with a vendor prefix, but hey \ud83e\udd37\u200d\u2642\ufe0f). The function allows you to display images of arbitrary HTML elements on your page! And the best thing is: it's live! Try selecting some text or scroll around to see lazy-loaded images kicking in. It's magic!The CSS to define another HTML element as background image is the following:mini-map .screen-image .canvas { background: white -moz-element(#main) no-repeat scroll center center / contain;}There's also some JavaScript to move the minimap's current viewport box, but the CSS one-liner is responsible for painting another DOM node. Use -moz-element and call it a day!And with that, keep rocking (and using Firefox)!Looks like this post made it to HN #1. If you enjoy Frontend news and are into emails, check out Web Weekly!Other stuffBlogrollPeople blogging great stuff.ResourcesBookmarks I want to keep for later.Show some loveSupport my blog and newsletter.TalksTalks I've given at conferences.Things I useMy hardware and software setup.Today I learned211 #TIL posts.\u00a9 2023 Copyright Stefan Judis. All rights reserved.",
    "summary": "- Firefox is the only browser that supports the fancy element() CSS function, allowing users to display images of arbitrary HTML elements on their page, making it unique in the market.\n- The minimap feature in this blog post is created using the function, providing users with a live view of the page and lazy-loaded images.\n- This post gained popularity on Hacker News and is recommended for those interested in frontend news and emails.",
    "hn_title": "A Firefox-only minimap (2021)",
    "original_title": "A Firefox-only minimap (2021)",
    "score": 664,
    "hn_content": "Hacker News new | past | comments | ask | show | jobs | submit loginA Firefox-only minimap (2021) (stefanjudis.com)664 points by sph 21 hours ago | hide | past | favorite | 111 commentsdmotz 20 hours ago | next [\u2013]A decade ago I built a silly JS library for folding up DOM elements like paper [1] and I eagerly anticipated using element() instead of tediously cloning nodes for every fold. Here we are ten years later and this niche CSS feature has yet to be adopted by the other browsers. Similarly, I thought I'd soon be using the CSS custom filter spec from the same era (which allows custom GLSL shaders to be applied to elements), but it also has yet to pick up traction.[1] https://oridomi.comreplydanShumway 19 hours ago | parent | next [\u2013]My understanding was that browser makers looked at the CSS custom filter spec and decided they were too difficult to implement securely[0].On one hand, I definitely appreciate that, I'm glad to see a feature abandoned if it's being abandoned because it's impossible to do it safely. On the other hand... I wanted CSS custom filters so much and I still regularly think of things I could have done with them :)[0]: https://lists.webkit.org/pipermail/webkit-dev/2014-January/0...replyautoexec 17 hours ago | root | parent | next [\u2013]There's already enough problems with CSS and what it can do that I want an add-on which either disables it entirely, or allows only a tiny subset of it.I can appreciate a clever use of CSS the same way I can with JS but for my day to day browsing I don't want either being able to do whatever it wants because far too often what websites use it for is user-hostile.replydanShumway 16 hours ago | root | parent | next [\u2013]CSS shaders are the kind of feature that I would get a ton of use out of for specific projects, and would also very likely either turn off entirely or at least put behind a permission in my own personal browser.I get why they're likely a bad idea, I'm not saying they should be implemented. It's very likely the right decision to get rid of them. I just mean... I want them XDreplyRandomWorker 20 hours ago | prev | next [\u2013]The first thing I do when I work in an editor with a mini-map is -- turn it off. I find it mostly the most useless feature for coding, and for sites it seems to be equally useless. Why?1. Stuff is too small to really make out where I'm going or navigating.2. Short or long pages, both don't really benefit from the loss of screen real-estate. Or the distraction really.3. Other tools like a proper index with descriptive headers, or the search function work so much better to navigate the page.Where mini-maps could be awesome are large images, or maps. They tend to visual in nature, and when zoomed in you can look at the mini-map to see where you are in the whole. Which is useful.So, cool future, but this doesn't really seem like a great implementation.replyeek2121 20 hours ago | parent | next [\u2013]I leave it on. It acts as a larger scrollbar when I use the mouse/trackpad/whatever pointing device to scroll. Operating systems these days are all about hiding the scrollbar and/or making it as small as possible. The minimap not only solves that issue, but also gives a bit of a visual representation of the file contents. Sure, you can't read the text, but if you've worked with a file long enough, you know exactly what you are looking at.replyJohnFen 13 hours ago | root | parent | next [\u2013]Isn't it funny that scrollbars are deemed too space-wasting to make a reasonable size anymore, but there's plenty of space for nonsense like minimaps?Bring back actual scrollbars! Or at least make it possible to turn them on.replysangriafria 12 hours ago | root | parent | next [\u2013]The irony is that the future of scrollbars, especially with narrow webpages and wide monitors, could have been minimaps. But instead we got disappearing scrollbars and reading indicators\u2026replysilon42 18 hours ago | root | parent | prev | next [\u2013]It's closer to proper width of the scrollbar than many modern ones :)replyentropie 8 hours ago | root | parent | prev | next [\u2013]> Operating systems these days are all about hiding the scrollbar and/or making it as small as possible.At least while coding this is actually pretty old school to have no scrollbar at all. My emacs has no gui elements. I dont need them. I see a 89% to know where I am right now but this information is actually not really useful.I move expression/function/method/bookmark wise for and backward or I just search and leave marks where I to jump back later. I really avoid touching my mouse and my window manager (xmonad) and development environment are entirely keyboard driven. I tried minmaps, its just distracting eye candy maybe a bit usefull while reviewing a codebase or looking for something.replybehnamoh 17 hours ago | root | parent | prev | next [\u2013]I disable it. I like vsc to be minimal like vim. I even use Vim extensions which help me avoid using scroll bar and use crtl-D/u/e/y instead.replyCthulhu_ 19 hours ago | root | parent | prev | next [\u2013]I just use the scroll wheel / touch pad, especially the one on Apple's mouse is really intutive. But I also try to not have my files get too large, or use the search function to quickly scroll to somewhere I know.replyoneeyedpigeon 19 hours ago | root | parent | next [\u2013]I think probably most of us use the scroll wheel (or equivalent) to scroll, but the advantage of the visible scroll bar is the immediate feedback of both document length and current location.replyrecursive 19 hours ago | root | parent | prev | next [\u2013]I do all that. But sometimes I find myself editing a file I did not create. Sometimes that file is large. Actually, that seems to happen a lot.replystephc_int13 20 hours ago | parent | prev | next [\u2013]I do the exact opposite.I use the minimap a lot, as a much better scrollbar. I tend to work on long files and even if I am rarely looking directly at the minimap, it is in my field of view and I often subconsciously glance at it.This kind of feature is clearly no one-size0-fits-all, but it would be a mistake to consider it is useless because you don't like it.replyiKlsR 12 hours ago | root | parent | next [\u2013]Same, also in vscode disable the text rendering (which is actually useless), increase the block sizes (shape of the code) and you can recognize bits of your code easily.replydralley 20 hours ago | parent | prev | next [\u2013]>1. Stuff is too small to really make out where I'm going or navigating.It's for looking at the shape of the code, not the contents. Also VSCode for example will show errors visibly highlighted in red in the minimap as well, which makes them easier to navigate to.replyWorldMaker 16 hours ago | root | parent | next [\u2013]VS Code's also shows:- (Linter) Warnings (in most themes a yellow or orange), like compile errors- Marks for recently edited sections of code (in most themes a blue). Those marks are also shown in the left hand gutter beside lines but I think they are sometimes too subtle there, but their mini-map counterparts are less subtle.- Current global search results (a bright gray or sometimes yellow, depending on theme)- Current file search results (a slightly different gray)- Current \"active token\" search results (another gray), such as when you put the cursor mid-word and VS Code naturally highlights all the other uses of that word- Indicators for all of the lines containing your cursors when using multi-cursor (Alt+click to add additional cursors), which can be very useful to watch in large files with a bunch of shared refactors spread out over some distanceThat's just off the top of my head because I use all of those to navigate some source documents.I think one of the \"shape of the code\" things not everyone appreciates as well is that some languages create more interesting shapes than others. There are some languages where every file creates a very similar looking waterfall and there are others where the landmarks are much more obvious. Ironically it is sometimes the worst languages that have the most visually distinguishable shapes and where I find I appreciate the minimap most of all. You can visually see sections that began as copied and pasted duplicates, you can see the places where lines are highly repetitive and often those correspond to key patterns of very explicit landmarks (\"there's the save code, you can tell because all the field string names are on the left side of assignments; there's the load code, you can tell because all the field string names are on the right side of assignments\"). You can't make out the individual words, but you can certainly see those \"blocks\" like that from that \"ten thousand foot view\".There's probably a visual processing/pattern matching thing about minimaps in general that some people have an easier time with than others. I've always liked a good map, regardless of context, so minimaps have always seemed useful to me. Map reading is a large combination of subtle skills, and I have just enough childhood training and natural aptitude that I have a great baseline for just about any map. I appreciate not everyone has those same skills, especially not in the weird arrangement that I do.replyoneeyedpigeon 20 hours ago | parent | prev | next [\u2013]I think minimaps can also be great at improving on the 'preview' function of the classic scrollbar they iterate on. A scrollbar can tell me how long a page is and, therefore, give me an idea of whether I want to continue reading or not. But a minimap can help to differentiate between the \"short article followed by pages of comments I can ignore\" case and the \"article far too long to even bother with\" one.replydanShumway 20 hours ago | parent | prev | next [\u2013]I will say that I kind of love minimaps. I don't think that they should be required and I absolutely get why you'd want to turn them off, they take up a ton of space. If you're splitting files more often I could also see it getting really annoying.But I think of code very visually and spatially and I don't split files until I have to, so it does help me quickly navigate to be able to sort of see the \"shape\" of a file and to be able to quickly jump around in it, especially if the file is divided into clear sections. Mostly just personal preference, and I agree they should never be mandatory.And agreed on the large images/maps, most image editors have a viewport feature like that and it's pretty useful when doing detail work.replySharlin 19 hours ago | parent | prev | next [\u2013]I don't use minimaps either, but I guess their utility much depends on what kind of documents you're editing. For programming languages where code is mostly structured inside functions, the \"structure\" view listing the types and functions in the file seems much more useful, as well as quick-search based on name and similar features.But if the content is, say, HTML, or LaTeX, or a Word document, then I can see a visual representation being more useful. It would be interesting to know if there's some correlation between people liking/disliking minimaps and the type of content they tend to view/edit.replymock-possum 19 hours ago | parent | prev | next [\u2013]Marking recent / uncommitted additions and deletions to your code, and linter errors / warnings, so you can jump right down to them - is super useful, especially if you just changed one little thing amongst a pack of similar little things. You can jump back and forth between two trouble points in code with a single click, and without having to remember anything.replykeithxm23 13 hours ago | parent | prev | next [\u2013]A lot depends on your use-case and the kind of website you're using this on.I would find this very useful on a site like Wikipedia where I often know the section I want to jump to before landing on the page. (e.g. I want to see the number of goals Messi has scored each season at Barcelona and I know there's always a table at the bottom of most wiki articles regarding historical stats for soccer-players). I could see from the mini-map where the tables are jump straight to it.Like you said, the the text is too small to make out where you're going or navigating. But most often I find myself visiting sites that I've visited in the past and for those I have a good mental image of what the page already looks like. I can use the hints from a minimap to jump to the relevant section of the page.replyGuB-42 17 hours ago | parent | prev | next [\u2013]When I first encountered mini-maps (in Sublime Text, which I still use), I just thought it was just a gimmick that looked cool, but that's about it.Now, I use it all the time, that's essentially a better scroll bar. In fact, the moment I saw the mini-map on the linked websites, I instantly tried to use it as a scrollbar, and was very disappointed to see that it didn't work.replytracker1 17 hours ago | parent | prev | next [\u2013]I think it's more useful for diffs or when you have search/match patterns that can differentiate by color. Especially in longer/bigger files.replyPurpleRamen 19 hours ago | parent | prev | next [\u2013]For longer documents, especially with multiple different blocks like code or images, it seems to be actually useful. It gives a fast impression on the length of the site, where you are and where the interesting and boring landmarks might be. But this also demand that the content is centered, and hos enough free space on the side, which is not that uncommon these days.replyilyt 19 hours ago | parent | prev | next [\u2013]I can only think about one use, skipping the image/advertising bullshit but then those pages won't put minimap up exactly for that reason.replysharikous 16 hours ago | parent | prev | next [\u2013]I am in your camp but to my surprise I met a lot of people who love them so I can understand why editors include minimaps these days.After the spaces vs tabs war calmed down let's see what will be the aftermath of the minimap invasionreplymgaunard 14 hours ago | parent | prev | next [\u2013]It's useful when you search, since you can see where all the matches are distributed in the document at a glance.replypredmijat 20 hours ago | parent | prev | next [\u2013]You can use `figlet` to create banners which are readable in the minimap.replydanShumway 20 hours ago | prev | next [\u2013]I can see the use, but this is also kind of wild. It's live-updating if you select text, it's almost literally a separate viewport into the same content.I'm trying to figure out the use-cases and implications of this. You can do offscreen/overflow:hidden tricks to make it work with hidden elements. But... as far as I know there's still no way without a library to convert that element to an image (for privacy reasons I suspect).I'm sorry for kind of being all over the place, but the MDN page is pretty short and I have a lot more questions. I guess I could always apply CSS filters and distortion directly to elements, does this being treated like a background open up possibilities there? It's the first time I'm hearing about this even though it's been around for a while, and I wouldn't have suspected this would be a CSS feature even on the table. How useful is this beyond just cloning viewports (assuming I'm only targeting Firefox and don't care about Chrome)?replysakex 20 hours ago | parent | next [\u2013]Could be used for a lot of cool things, like a mirror, a magnifying glass, keeping a part of the page in view even if it is outside of the screen (for editing purposes for instance), I'm sure I'm missing many other use cases. None of them fundamentally useful but cool in their own ways.replydanShumway 19 hours ago | root | parent | next [\u2013]The tricky bit here is that it's not going to do things like forward events, so using this to keep the page in view won't allow selecting text for example. For some things like the mimimap here, that seems like a feature? You want it to be purely visual in that case.For other cases, I'm not sure if I should think of that as a feature or a limitation. Definitely something to play around with though.replysakex 17 hours ago | root | parent | next [\u2013]Yes but you could make a change at the top of the page that would have an impact at the bottom, and that would be useful to see both changes at the same time.replycal85 16 hours ago | prev | next [\u2013]Crazy that `element()` has been fully supported (with `-moz-`) in Firefox since 2011 while no other browsers seem to even partially support it [0]. I can think of a few powerful use cases (not just minimaps) if this had cross browser support.Does anyone connected to the Chrome or Webkit teams have any idea why? Is there a lack of interest, is it hard to implement with good performance, does it create any tricky security issues?[0] https://caniuse.com/css-element-functionreplyjudah 12 hours ago | parent | next [\u2013]Chromium-based browsers have -webkit-box-reflect [0], which does some of the things that element() does.Specifically, it does reflections of elements. That's really the big use case for -moz-element IMO.[0]: https://developer.mozilla.org/en-US/docs/Web/CSS/-webkit-box...replyaetherspawn 21 hours ago | prev | next [\u2013]Every day I hit sites that literally only work in Chrome.. it\u2019s time to fight back :)replywilliamdclt 20 hours ago | parent | next [\u2013]I exclusively use firefox, have a pretty normal browsing pattern, and that almost never happens to me! Much less that once a month, maybe once every 3 monthsreplyiends 20 hours ago | root | parent | next [\u2013]Finding one once every few months sound about right but usually the bugs impacting Firefox users are major PITA. Some I\u2019ve had over the past few years:* myADP had some kind of bug preventing firefox authentication that lasted months.* Elan financial redid their credit card site for fidelity visa and had a CSS bug that hid the card total balance. This lasted for about a month.* bitbucket (work required) had this bug that prevented pages rendering in firefox. It was some kind of JS client side bug and it impacted a bunch of people in my company. After months of support request they gave us some console commands that opted into an experimental feature which resolved the issue. This one was especially frustrating as they kept telling us to just clear our cookies and delete our profiles.* Some random IRS system I had to use for either requesting a tax transcript or validating my identity just didn\u2019t work.It\u2019s actually been so frustrating my coworkers joke anytime there is a bug I\u2019m experiencing that it must be another Firefox only bug.replypolitelemon 17 hours ago | root | parent | next [\u2013]> myADPFor years they had a terrible implementation that only worked in _old_ versions of IE. They had no incentive to change because they were the main players in that space. I loathed them because their tagline was \"Anytime, anywhere\" which was clearly missing an asterisk.replywing-_-nuts 19 hours ago | root | parent | prev | next [\u2013]vanguard's website can't edit holdings with firefox. I reported it years ago and literally nothing's been done.replyaembleton 18 hours ago | root | parent | next [\u2013]I've never had a problem on their UK site [1]. It might be a different code base.1. https://www.vanguardinvestor.co.uk/replyisanjay 20 hours ago | root | parent | prev | next [\u2013]Opening fastmail in Firefox crashes the whole browser. I don't know why. I stopped my subscription due to that.replynicolaslem 20 hours ago | root | parent | next [\u2013]I have used fastmail in Firefox daily for years, never had an issue.replydanShumway 19 hours ago | root | parent | next [\u2013]Yeah, something is going on with GP's browser. I have Fastmail open in Firefox right now, I've never had an issue with it.I'm not saying that to dismiss the problem, I believe GP that it's crashing; more bringing it up to say \"there is something going wrong here that's not at the browser/site level that could potentially be fixable for you on your local device if you want to use Fastmail in Firefox.\"replyisanjay 19 hours ago | root | parent | prev | next [\u2013]Well maybe it only happens for me. Not only the page becomes non responsive the whole browser becomes non responsive.replymrweasel 20 hours ago | root | parent | prev | next [\u2013]Normally it's something else, like a plugin. To be honest I don't notice much, frequently I assume it's some tracking that's blocked which courses the site to not function and just move on.Between blocking tracking, with DuckDuckGos privacy plugin, and using Firefox I'd say that blocking tracking breaks WAAAAY more sites.replyKnobbleMcKnees 19 hours ago | root | parent | next [\u2013]Agreed. I regularly have to do a little \"disable for site\" dance with uBO and Privacy Badger to even get certain websites to load. It's kind of convenient in that it gives me an inflection point where I can choose not to use that website or service at all.replykrylon 20 hours ago | root | parent | prev | next [\u2013]I recently installed adguard on my home server, and it did indeed break a few sites.replyaetherspawn 9 hours ago | root | parent | prev | next [\u2013]It's usually super critical things that don't work, for example:I couldn't apply to become a registered engineer in my state using Firefox because the form was in an iframe, and for some reason the iframe didn't render on FF.The credit portal for Shell Fuels only works in Chrome and doesn't display at all in FF due to a console error. (Enough of the page renders to make you think that the page is complete but i.e. the buttons to apply or make a payment don't render).The field for setting the date of a consultation (work) in our accounting package doesn't work in FF, and no matter how many times I write to their support team they just write back with \"Firefox is not supported, please download Chrome\". There was a similar attitude at a software company I worked prior, but I managed to wear them down and get Edge (modern), Firefox and Safari on the QA supported browser list with the reasoning that they are the default browsers for Windows, Linux and macOS respectively.But come on, browser standardization is so good these days I honestly don't understand how people are making pages that only work in Chrome?replytreyd 20 hours ago | root | parent | prev | next [\u2013]I simply refuse to use websites if they require Chrome. I find some other way to do whatever it is I'm trying.replyben-schaaf 20 hours ago | root | parent | prev | next [\u2013]The times it does happen I've found more often than not switching the user agent fixes it...replylarrik 20 hours ago | root | parent | prev | next [\u2013]SameFor whatever reason car manufacturers are the worst at it. Microsoft is also pretty bad (worse than Google).replySemaphor 17 hours ago | root | parent | prev | next [\u2013]Similar for me, I\u2019d say it\u2019s actually more like once or twice a year. More if you count sites that are specifically about Chrome experiments, which sometimes get linked from HN.replyWorldMaker 16 hours ago | root | parent | prev | next [\u2013]One factor I've found is the intersection of Enhanced Tracking Protection and Multi-Account Container in Firefox. I'm seeing daily \"Please stop using an ad blocker, Firefox is an ad blocker, please use Chrome, this site works best in Chrome\" banners and ad walls and paywalls and other similar cranky anti-patterns.It fascinates me how many people I know have uBlock (Origin) installed in Chrome and see nowhere near as many whiny banners and \"stop running an ad blocker\" nonsense as I see running Firefox without an ad blocker just ETP and MAC. The people complaining \"Firefox is an ad blocker\" are making it clear that they don't actually care that you are blocking ads or not, they care that you are blocking trackers and hate you for trying to maintain a semblance of privacy. Keeps saying the quiet parts out loud.Most of the sites that do that are a \"close tab and ignore\" thing, some are a sequester to their own account container and feed them garbage (create a dumb account for them, turn off ETP just for them just in that container). It is still only a once-a-month case where such a site I need to get something done on is entirely broken in Firefox and I need to open it in something Chromium based, but that's still too often and getting worse.But that \"Firefox is an ad blocker, please use a less private browser\" is a daily annoyance for me for sure.replyjorvi 17 hours ago | root | parent | prev | next [\u2013]Logging into PSN was (is?) broken for a very, very long time. It was for at least 1.5 year, but I switched after that so I couldn\u2019t tell beyond that.replycornedor 19 hours ago | parent | prev | next [\u2013]Is this a geographically local thing? This happens very rarely to me, although I there are some (Google) sites I use regularly that do work worse on Firefox than Chrome.replydrewg123 20 hours ago | parent | prev | next [\u2013]Speaking of that, I've had issues with Firefox (both on Mac and Linux) where some checkboxes just don't appear. I was checking in for an international flight last month on American, and could not manage to get through the checkin process until I discovered there was a checkbox I needed to tick that didn't even appear on Firefox (but which did on Chrome)..replyjjice 20 hours ago | parent | prev | next [\u2013]Yeah it's upsetting the sites that I run into this on, especially since there's no excuse in 2023. On more obscure pages on Vanguard's website I've run into some broken stuff that results in console errors I don't remember, but switching to Chrome made it work :/replywing-_-nuts 18 hours ago | root | parent | next [\u2013]yeah the edit holdings page is broken in FFreplyricardo81 20 hours ago | parent | prev | next [\u2013]Yes. It reminds me of when there were rumours/(facts?) about open source sabotaging of FF. I see a lot of instances where pages worked fine on FF but now they don't, and sometimes I have to fire up another browser. I really hope that's not the case.I use FF by default.replythemoonisachees 1 hour ago | root | parent | next [\u2013]Spoofing your user agent to a chrome one will make most of these sites work. They're just not interested in allowing you privacy.replymarginalia_nu 16 hours ago | parent | prev | next [\u2013]I don't think I've come across that yet with Firefox.replylexicality 20 hours ago | prev | next [\u2013]The minimap is cute, but more entertaining to me is the screensaver that kicks in after 3 minutes of leaving the tab idle.I'm glad there's still whimsy on the webreplystefanjudis 20 hours ago | parent | next [\u2013]Haha, glad that my screensaver sparks some joy. :)replyCursedUrn 16 hours ago | prev | next [\u2013]This seems like something that would be heavily abused by sites that deliberately try to break basic browser functionality (like being able to right click images, or select text). If they render the whole page as a background image, you'll no longer be able to inspect, save, translate, etc. any of the content. That's just the first thing I thought of, I imagine there's all sorts of nefarious ways to screw over the reader with this function.replycal85 15 hours ago | parent | next [\u2013]I agree it feels like something that could be abused, but not with the example you've given. It already only takes a tiny bit of CSS or JS to do those things you mentioned; no need to do anything complex with element canvases. So the reason that most websites don't do those things cannot be that they don't have the ability. It is because they do not, in fact, have the inclination, and that's because there is an economic punishment for having a shitty website: people will start using your competitors instead. (Caveat: this doesn't work out in areas that aren't free markets, like company intranet portals, badly run local council sites etc, which is why those kinds of sites tend to have more user-hostile stuff.) In general it is a mistake to think that we need to purposefully hamstring website operators to make the standard of websites higher: the opposite is true.replycubefox 8 hours ago | root | parent | next [\u2013]Related:https://news.ycombinator.com/item?id=36749766replyCAP_NET_ADMIN 20 hours ago | prev | next [\u2013]I've been using Firefox for the past year due to some weird incompatibility between my GPU and Chrome's video decoding. It caused dropped frames and caused my YT quality to go down.Haven't really noticed any issues on Firefox except the lack of actually good web translator.-moz-element looks sweet, hope it comes to other browsers.replyjohnnyworker 18 hours ago | parent | next [\u2013]I have been using Firefox ever since Opera bit the dust, but I have been trying, so hard, to use Vivaldi the last 3-6 months, mostly because it offers a portable version out of the box that discovers profiles just by looking at folders, i.e. super sweet for syncing.But it's such a dog. Even after turning off mail and feeds which just sit there eating CPU like candy, I just can't make it fast, and returning to and cleaning up my Firefox made it so snappy, I'd rather stick to my 3 profiles (normal,dev, media) and do the rest via Bookmarks. And for all the sweet UI options and configurability Vivaldi has, with Tree Style Tabs and some addons for it, and hacking the UI CSS, I am sheepishly making Firefox my primary again, pretending none of that happened.I wish it cached compiled WebGL shaders though. That is the only thing where Chrome beats it to a pulp sadly. Maybe there are config tweaks, I haven't looked into it, but out of the box reloading a page with a lot of shaders is basically instant in Chrome, even on mobile, and can take ages on FF, depending on the shaders.replydec0dedab0de 18 hours ago | prev | next [\u2013]I would be ok with it if we started seeing \"works best with firefox\" instead of chrome/edge.replyHackbraten 20 hours ago | prev | next [\u2013]What am I supposed to see here? I\u2019m using Firefox on Linux. All I see is a normal blog article about something called a minimap, but I fail to see any such minimap. Disabling the ad blocker didn\u2019t help. What am I missing?replydrewg123 20 hours ago | parent | next [\u2013]Look in the upper right side. There is a mini snapshot of the page, with a blue outline showing the portion of the page that the browser can see. When you highlight text on the page, you can see it highlighted in the minimap.replytaink 20 hours ago | parent | prev | next [\u2013]There should be a picture of what you are supposed to see on the article[1]. It works on this page for me but some of the other articles do not show it. Seems weird because I'm not changing browsers in between.[1] https://images.ctfassets.net/f20lfrunubsq/2FuQMHycwersLjIf4d...replyjacknews 20 hours ago | parent | prev | next [\u2013]Not working for me on macos.otoh firefox has been really weird since the 115 update - rock solid before that, but now all kinds of weird graphic glitches and hangs.reply_joel 19 hours ago | root | parent | next [\u2013]Working fine here for me on macos, latest FF, uBlock enabledreplyjacknews 18 hours ago | root | parent | next [\u2013]ok, it works in private mode, so must be one of my plugins - maybe vimium.Anyway this is definitely cool, but it's a shame you can't use it as a scrollbar.replyoblio 20 hours ago | parent | prev | next [\u2013]There's a minimap-type scroll bar for the article to the right. There's an image in the article of how it looks.replyEspressoGPT 20 hours ago | prev | next [\u2013]What a shame that it doesn't seem to work recursively.replyjcarrano 19 hours ago | parent | next [\u2013]Yes it can- that's the first thing I tried- but it will not iterate forever. The trick is to use indirect recursion: <div id=\"a\"></div> <div id=\"b\"></div> #a, #b {  height: 200px;  width: 200px;  border: dashed; } #a {  background: -moz-element(#b) no-repeat;  background-size: 80%;  border-color: green; } #b {  background: -moz-element(#a) no-repeat;  background-size: 80%;  border-color: purple; }replysph 18 hours ago | root | parent | next [\u2013]This is utter madness. I love it.replymiohtama 20 hours ago | parent | prev | next [\u2013]With Firefox and CSS background you can open a portal to another dimensionreplynewaccount74 20 hours ago | parent | prev | next [\u2013]That's the same thing I immediately had to try as well :)The argument of -moz-element() can be a child of the styled element, but it can't be a parent (makes sense).replyzeta0134 16 hours ago | prev | next [\u2013]And since it is positioned and looks like the Sublime Text minimap, I instinctively tried to click on it to scroll to part of the page, and was saddened that this does not work. That would be the most logical extension, that feature is really cool in general.replyjessfyi 20 hours ago | prev | next [\u2013]I always liked Lars Jung's implementation where the text is abstracted into blocks (which works on chrome) [0][1] and Rauno Freiberg's demo (uses -moz-element) where you can use it to pin sections, jump between them, and navigate the page in general [2].[0] https://larsjung.de/pagemap/ [1] https://larsjung.de/pagemap/latest/demo/text.html [2] https://uiw.tf/minimapreplytiagod 19 hours ago | prev | next [\u2013]Wish this was an extension. I like it. Maybe it will be my next project.replyjchw 19 hours ago | prev | next [\u2013]It also doesn't show up on Fennec F-Droid, even in Desktop mode, but maybe that's just because I can't get the width to be big enough for it to trigger. Looks great on Librewolf!Of course, browsers will never be fully at parity with each-other until they're all based on Chrome, so it's no surprise there are the occasional features that are just easier to implement in one browser than the other... though this one just seems kind of wild, I'll be honest.replydark__paladin 15 hours ago | prev | next [\u2013]For what it's worth, Vivaldi has the option to generate minimaps for whatever page you're on:https://help.vivaldi.com/android/android-appearance/page-act...replygymbeaux 7 hours ago | prev | next [\u2013]Firefox has always been the browser that supports the cool stuff. I remember messing around with auto-enabling dark mode for my websites based on the reading of the ambient light sensor of my MacBook. Of course now our OSes decide when an app or website should use dark mode.replymasswerk 19 hours ago | prev | next [\u2013]For me on FF 115.0.2 (64-bit), the \"how it looks like\" pane was stuck, and only revealed on mouse-over what is instantly visible on Safari Desktop. On reload, the same state is still visible for a short period, before it's replaced by the intended content (\"Screen_Shot_2021-10-17_at_21.45.35.png\" \u2013 hey, built on FF/macOS!). This is also repeatable (and somewhat ironic.)replyiib 19 hours ago | prev | next [\u2013]Is there any bookmarklet to add this to another arbitrary page? I can't seem to make it work, even with modifying the CSS code.replynektro 6 hours ago | prev | next [\u2013]I have never found this style of minimap useful and I turn it off in all my appsreplybogwog 21 hours ago | prev | next [\u2013]This would be cool to have for an online code editor or similar, but otherwise I hate these types of custom navigation things on websites.replyBrendinooo 20 hours ago | parent | next [\u2013]Honestly I didn't notice it until it was pointed out by the article. Banner blindness has done a number on me.Pretty cool thing here, just wish I could use it to navigate. That's the biggest reason why I keep a minimap on in VS Code.replytiagod 19 hours ago | prev | next [\u2013]Here's the adoption matrix for CSS element(): https://caniuse.com/css-element-functionreplyAbraKdabra 18 hours ago | prev | next [\u2013]I mean, the article is good but no one is talking about that incredible screensaver. I opened like 10 links from HN and when I finally opened this tab there it was waiting for me.replyaendruk 16 hours ago | prev | next [\u2013]In case anyone else had trouble finding it, the minimap is only displayed if the viewport width was \u22651120px when the page was initially loaded.replyjoshmarinacci 20 hours ago | prev | next [\u2013]I\u2019m pretty sure this remains unimplemented for security reasons. Other apis that would let you render part of the page to an image are similarly blocked. We ran into this a lot when working on WebXR.replythrowthrow41 18 hours ago | prev | next [\u2013]So you can render a tree of elements into a background? I'm guessing you can't then get that raster image back out? I would love to be able to get my webpages as images.replyberkes 18 hours ago | parent | next [\u2013]That's slightly harder, but still possible by first rendering the HTML onto a canvas.Example here: http://html2canvas.hertzen.com/replykevingadd 20 hours ago | prev | next [\u2013]It's impressive how well the minimap works for bigger articles, I clicked around randomly and ended up at https://www.stefanjudis.com/notes/should-responsive-images-w... and the minimap feels slightly magical since it appears instantly and updates synchronously if I do things like select text.It feels kind of disappointing that I can't interact with it to scroll around like in i.e. Sublime Text, but I imagine that's a little harder to do as the author of a website. It's still very cool to me that you can do something like this on the web, and I wonder how much work it would be to support this complex CSS feature in Chrome or Safari.replytaink 20 hours ago | parent | next [\u2013]Weirdly enough I can't see it on this article but it's showing just fine on the OP. Maybe my extensions?replystefanjudis 20 hours ago | root | parent | next [\u2013]Site author here: there's some logic to only show the minimap when there's enough screen estate and it generally fits.Couldn't be bothered to scrolling/dragging logic. :Dreplyoneeyedpigeon 19 hours ago | root | parent | next [\u2013]It should definitely take a responsive design into account, I think. The beauty is that most sites, on desktop at least, should be able to benefit \u2014 we all have plenty of horizontal real-estate to spare!replypaddy_m 18 hours ago | prev | next [\u2013]It would be nice if the page defined what a minimap is?replymcbutterbunz 12 hours ago | prev | next [\u2013]Would be interesting to see how this worked on infinite scroll sites.replykeithxm23 12 hours ago | prev | next [\u2013]It would be super cool if this was implemented as a firefox plugin!replyryandrake 19 hours ago | prev | next [\u2013]Why have a \"minimap\" if your content itself is already the size of a minimap? I have a 27\" monitor, and this site's content takes up a ~5 inch strip down the center of my browser, with 9 inches on each side full of whitespace. Over 75% of the page is whitespace. If you let the content grow to fill the browser window, you could read the whole thing without scrolling.replyTheRealPomax 19 hours ago | prev | next [\u2013]Looks like that intro paragraph is going to need an update =)replyspankalee 18 hours ago | prev | next [\u2013]element() would be amazing for things like making thumbnails of slides in a presentation app.replyzackmorris 17 hours ago | prev [\u2013]Wow I had never heard of element()!Along similar lines, HyperCard had a lockScreen flag that would stop sending draw commands to the screen, and instead buffer them internally, so that the screen would update once drawing was finished. It's such a powerful abstraction that much of the hand-waving we do today to avoid redraw would just go away, including nearly all of the effort that goes into building single-page applications (SPAs), because their functionality can be simulated by simply locking the screen and fetching new HTML from the server as a dumb terminal so the loading bar doesn't animate:https://www.hypercard.center/HyperTalkReference/lockScreen<rant>To a first-order approximation, all apps/libraries/frameworks are missing critical functionality like this. The most common design mistake is to provide a setter without a getter, or vice versa. Another one is for a console app to provide a config file setting, with no way to override that as a shell argument to the executable. There are dozens, if not hundreds of these common anti-patterns, so statistically the odds of any piece of software having any of one of them can be considered to be 100%.So in this case, most \"modern\" browsers provide a way to render the screen image from an HTML description, but no way to retrieve that image. The canvas element is a band-aid over these original design mistakes. A proper DOM implementation would look like iframes (windows) all the way down, where the contents could be specified from url, attributes, html, vectors/buffers or code. Each would have its own sandbox attributes defaulting to full isolation, so could be treated as its own browser, then their data dependencies could be piped together, a bit like unix executables. Mashups/portals/aggregators would be so easy to build that kids would be doing it.It's a serious enough problem that honestly I don't really think in terms of HTML/CSS/Javascript anymore. I work in tables mentally, then let the designers transpile that description to CSS. And the real work of building the rich interactions available in desktop programming simply can't be done without massive yak shaving. This was also a problem in OpenGL before better access to render buffers and shaders went mainstream.IMHO this all started when Netscape became a private enterprise from its Mosaic roots, then was exacerbated when Microsoft monopolized the browser market for so many years, then cemented when Firefox and Chrome endorsed the status quo. The only way out now would probably be to formally build a programmer's browser from scratch with hard security constraints around the core element's external communication, then emulate the current HTML/CSS/Javascript experience we're used to. Sort of like Qt, Postscript, etc. Which of course will never happen, so it's hard to see the positive in discussing these foundational decisions when there's nothing any of us can do to fix them in any reasonable amount of time/money/effort.replyGuidelines | FAQ | Lists | API | Security | Legal | Apply to YC | ContactSearch:",
    "hn_summary": "- The CSS custom filter and element() features have not been widely adopted by other browsers, despite being available for a decade.\n- Some users find minimaps useful for navigation, while others find them distracting or unnecessary.\n- The element() feature in Firefox allows for the creation of a minimap, but it is not interactive like in other tools such as Sublime Text."
  },
  {
    "id": 36753225,
    "timestamp": 1689558768,
    "title": "LazyVim",
    "url": "https://www.lazyvim.org/",
    "hn_url": "http://news.ycombinator.com/item?id=36753225",
    "content": "\ud83d\ude80 Getting Started\ud83d\ude80 Getting StartedLazyVim is a Neovim setup powered by \ud83d\udca4 lazy.nvim to make it easy to customize and extend your config.\u2728 Features\ud83d\udd25 Transform your Neovim into a full-fledged IDE\ud83d\udca4 Easily customize and extend your config with lazy.nvim\ud83d\ude80 Blazingly fast\ud83e\uddf9 Sane default settings for options, autocmds, and keymaps\ud83d\udce6 Comes with a wealth of plugins pre-configured and ready to use\u26a1\ufe0f RequirementsNeovim >= 0.8.0 (needs to be built with LuaJIT)Git >= 2.19.0 (for partial clones support)a Nerd Font(v3.0 or greater) (optional, but needed to display some icons)lazygit (optional)a C compiler for nvim-treesitter. See herefor telescope.nvim (optional)live grep: ripgrepfind files: fda terminal that support true color and undercurl:kitty (Linux & Macos)wezterm (Linux, Macos & Windows)alacritty (Linux, Macos & Windows)iterm2 (Macos)Edit this page",
    "summary": "- LazyVim is a Neovim setup that allows you to easily customize and extend your configuration.\n- It transforms Neovim into a full-fledged IDE and comes with pre-configured plugins for convenience.\n- To use LazyVim, you need Neovim version 0.8.0 or higher built with LuaJIT, Git version 2.19.0 or higher, and optionally a Nerd Font for displaying icons.",
    "hn_title": "LazyVim",
    "original_title": "LazyVim",
    "score": 571,
    "hn_content": "- LazyVim is a popular alternative to other text editors like Sublime Text and VS Code.\n- Users praise LazyVim's rich built-in features and versatility for various programming languages.\n- LazyVim is considered a good choice for those who want a fully functional IDE without the complexities of extensive customization.\n- Some users prefer LazyVim because setting up other Vim configurations can be time-consuming and require extensive troubleshooting.\n- There is a debate about the trade-off between customizing editors for personal workflows versus accepting pre-made defaults for efficiency.\n- Vim and Emacs offer the ability to gradually modify the editors to fit individual preferences and work processes.\n- The Neovim and LunarVim distributions are other options for configuring Vim, but may require more effort than LazyVim.\n- Many users prefer the simplicity and efficiency of using vanilla Vim for remote server work and basic editing tasks.\n- Vim enthusiasts value the configurability and extensibility of the editor, while others find it more time-consuming and less user-friendly compared to other editors like VS Code.\n- LazyVim provides an easier and quicker setup for Vim users wanting a more efficient and tailored workflow.\n- LazyVim is compared to other \"fully fledged\" Vim distributions like AstroVim and LunarVim, but is perceived as more lightweight and customizable.\n- Vim users enjoy the ability to create their own tools and scripts and have dedicated keybindings for specific tasks.\n- VS Code is favored by those who want a fully fledged IDE with a wide range of features and seamless integration with other tools.\n- There is a perception that Vim requires significant effort to configure and maintain, particularly in comparison to other editors like VS Code.\n- Some users highlight the benefits of using plugins like ALE and coc.nvim for linting and autocompletion in Vim.\n- Users recommend LazyVim and LunarVim as options for new Vim users because of their ease of setup and functionality.\n- The key distinction between Vim and VS Code is the level of customization and the community culture toward documentation and learning.\n- The post generates interest among tech-savvy individuals who are interested in optimizing their workflow in programming and text editing.- Neovim is a powerful text editor that requires some time investment to learn.\n- It is not an IDE itself, but it can be customized to create a personalized IDE experience.\n- The Neovim community values freedom and configurability over practicality, resulting in various ways to accomplish the same task.\n- The documentation and learning resources for Neovim can be sparse, and the community can be perceived as unwelcoming to newcomers.\n- Neovim plugins can be challenging to set up and maintain, requiring some programming skills.\n- Using Neovim for tasks like auto-formatting code on save may require writing custom code in the Lua programming language.\n- Neovim works well for editing Python and other languages, but it may not provide the same level of IDE features as dedicated IDEs like Visual Studio Code (VSCode).\n- VSCode is a popular choice among developers due to its out-of-the-box functionality and extensive plugin marketplace.\n- Neovim can be integrated with IDE features using plugins like the official Python plugin.- The author of the post discusses their experience with learning and using different tools in the tech industry, including languages, frameworks, databases, and text editors.\n- They question the value of spending time learning and configuring a text editor like neovim for their specific needs, preferring a good-enough IDE like vscode instead.\n- The author engages in a discussion with other commenters about the merits of learning and modifying tooling, with some arguing that it is worthwhile and others disagreeing.\n- Some commenters recommend alternative text editors or extensions that could enhance the author's workflow.\n- The author acknowledges that everyone's preferences and needs are different, and what works for them may not work for others.\n- The discussion touches on topics like the time investment required to learn and configure tooling, the benefits of reducing friction in the workflow, and the pros and cons of different text editors.\n- Overall, the post highlights the ongoing debate and personal choice in selecting and using tools in the tech industry.",
    "hn_summary": "- LazyVim is a popular alternative to other text editors like Sublime Text and VS Code, with users praising its rich built-in features and versatility for various programming languages.\n- LazyVim is considered a good choice for those who want a fully functional IDE without the complexities of extensive customization, as setting up other Vim configurations can be time-consuming and require troubleshooting.\n- The post generates interest among tech-savvy individuals who are interested in optimizing their workflow in programming and text editing, as it discusses various text editors and their pros and cons."
  },
  {
    "id": 36753032,
    "timestamp": 1689556446,
    "title": "Johnson & Johnson sues researchers who linked talc to cancer",
    "url": "https://www.reuters.com/legal/litigation/johnson-johnson-sues-researchers-who-linked-talc-cancer-2023-07-13/",
    "hn_url": "http://news.ycombinator.com/item?id=36753032",
    "content": "LitigationPersonal InjuryLitigationCorporate StructureLawsuitsJohnson & Johnson sues researchers who linked talc to cancerBy Dietrich KnauthJuly 13, 20234:50 PM UTCUpdated 5 days agoThe logo of healthcare company Johnson & Johnson is seen in front of an office building in Zug, Switzerland December 1, 2021. REUTERS/Arnd WiegmannSummaryCompaniesLaw FirmsJ&J alleges researchers used \"junk science\" to disparage company's productsDefendants say the lawsuits are meant to \"silence\" scientistsJuly 12 (Reuters) - Johnson & Johnson has sued four doctors who published studies citing links between talc-based personal care products and cancer, escalating an attack on scientific studies that the company alleges are inaccurate.J&J's subsidiary LTL Management, which absorbed the company's talc liability in a controversial 2021 spinoff, last week filed a lawsuit in New Jersey federal court asking it to force three researchers to \"retract and/or issue a correction\" of a study that said asbestos-contaminated consumer talc products sometimes caused patients to develop mesothelioma.Advertisement \u00b7 Scroll to continueOne of the researchers, Richard Kradin, declined to comment. The other two, Theresa Emory and John Maddox, did not respond to requests for comment. Lawyers who have represented the three researchers in similar litigation in the past declined to comment.J&J is facing more than 38,000 lawsuits alleging that the company's talc products, including its Baby Powder, were contaminated by asbestos and caused cancers including ovarian cancer and mesothelioma. J&J is attempting to resolve those lawsuits, as well as any future talc lawsuits, through an $8.9 billion settlement in bankruptcy court.Advertisement \u00b7 Scroll to continueJ&J says that its talc products are safe and do not contain asbestos.J&J has stopped selling talc-based Baby Powder in favor of cornstarch-based products, citing an increase in lawsuits and \"misinformation\" about the talc product's safety.The company in 2021 began exploring bankruptcy as a potential solution to the lawsuits, which saw a mixed record at trial, including several defense wins but also a $2.1 billion verdict awarded to 22 women who blamed their ovarian cancer on asbestos in the company's talc products. J&J said in bankruptcy court filings in April that the costs of its talc-related verdicts, settlements and legal fees have reached about $4.5 billion.Advertisement \u00b7 Scroll to continueLast week's lawsuit against Emory and Maddox, pathologists affiliated with Peninsula Pathology Associates in Newport News, Virginia, and Kradin, a pulmonologist who worked at Massachusetts General Hospital Cancer Center before his retirement, comes on the heels of another complaint LTL filed in late May against another doctor, Jacqueline Moline, who works at Northwell Health in Great Neck, New York, on similar grounds.Moline published an article in 2019 studying 33 patients who said their only exposure to asbestos came from talc products, and Emory, Kradin and Maddox followed up with a 2020 study of 75 similar patients.All four doctors have provided expert testimony in lawsuits against J&J, and their research has been cited in lawsuits where they have not testified, according to the complaints.LTL said the researchers concealed the fact that some or all of the patients involved in their studies had been exposed to asbestos from other sources.The company is also asking the court to force the researchers to disclose the patients' identities.The lawsuits allege product disparagement and fraud, among other claims.Adam Zimmerman, a professor at the University of Southern California Gould School of Law, said companies rarely file lawsuits over research they disagree with. It will be very difficult for LTL to prove that the researchers intentionally harmed J&J's reputation, which is required for product disparagement cases in New Jersey, but the company may view the lawsuits as a way to discourage other researchers or reclaim the narrative about talc safety, Zimmerman said.\"When a litigant starts suing opposing experts, that's very aggressive,\" Zimmerman said. \"It sends a message that the gloves are off.\"Moline has argued in court papers that LTL's litigation would have a profoundly chilling effect on future medical research if the company were allowed to unmask patients \"in the hopes of publicly smearing them.\" Her court filings say that LTL's lawsuit was meant to \"attack and silence\" scientists, and that she has an ethical obligation to protect the identities of her research subjects.LTL's lawsuits allege that the doctors' research allowed them to collect millions of dollars from plaintiffs' lawyers to push a \"false narrative\" about J&J. The complaint against Moline, for example, said she had made a \"small fortune\" testifying as a paid expert in lawsuits, receiving over $3 million from her work on asbestos lawsuits. LTL alleged that Kradin also made more than $3 million testifying as a plaintiffs' expert.The researchers could not immediately be reached for comment.LTL had filed similar lawsuits against the researchers in December 2022, but those complaints were linked to LTL\u2019s first bankruptcy filing and were dismissed along with the rest of the bankruptcy in April.The cases are LTL Management v. Moline and LTL Management v. Emory, U.S. District Court for the District of New Jersey, Nos. 23-cv-02990 and 23-cv-03649.For LTL: Peter Harvey of Patterson Belknap Webb & Tyler; Allison Brown of Skadden, Arps, Slate, Meagher & Flom; and Kristen Fournier of King & SpaldingFor Moline: Kevin Marino and John Tortorella of Marino Tortorella & BoyleFor Emory, Kradin and Maddox: Not yet available Read more:J&J unit files for second bankruptcy to pursue $8.9 billion talc settlementCancer plaintiffs drill down on J&J's support for $8.9 billion talc dealU.S. court rejects J&J bankruptcy strategy for thousands of talc lawsuitsReporting by Dietrich Knauth; additional reporting by Brendan PiersonOur Standards: The Thomson Reuters Trust Principles.Read Next / Editor's PicksMarketscategoryInsurers reviewing Black Sea ship cover after Russia quits deal -sourcesBusinesscategoryCDS panel rules UBS is sole successor to Credit Suisse after mergerWorld at WorkcategoryUnited Airlines pilots reach labor agreement, boost payBusinesscategoryUPS says focused on reaching a labor deal before Aug. 1SustainabilitycategoryCountries warn against over-reliance on carbon capture techWorldcategoryRepublican state officials threaten legal action over company diversity policiesBusinesscategoryCanopy Growth signs agreements to reduce debt amid liquidity crisisTechnologycategoryChinese hackers breached US Commerce chief's emails; Blinken warns Chinese counterpartWorldcategoryUS state, local governments budgeted $173 billion in COVID aid, Treasury saysBusinesscategoryChina drives Burberry first-quarter sales jumpBusinesscategoryEnergy curtailments likely to rise as Texas wind and solar capacity increases, EIA saysWorld at WorkcategoryCourt rules against Uber in major win for California workersLitigationcategoryPlaintiffs ask US Supreme Court to temporarily halt Microsoft, Activision mergerLitigationcategoryFast-fashion retailer Temu sues rival Shein over US antitrust lawTransactionalcategoryTesla sues Australia's Cap-XX over EV battery technologyWhite Collar CrimecategoryFTX seeks to recoup $323 million from failed European expansion",
    "summary": "- Johnson & Johnson has filed lawsuits against four doctors who published studies linking talc-based personal care products to cancer, alleging that the studies are inaccurate and based on \"junk science.\"\n- The doctors involved in the lawsuits have provided expert testimony in lawsuits against J&J and have been cited in other lawsuits, according to the complaints.\n- J&J is facing over 38,000 lawsuits alleging that their talc products, including Baby Powder, were contaminated with asbestos and caused various cancers. J&J denies these allegations and is attempting to resolve the lawsuits through an $8.9 billion settlement in bankruptcy court.",
    "hn_title": "Johnson and Johnson sues researchers who linked talc to cancer",
    "original_title": "Johnson and Johnson sues researchers who linked talc to cancer",
    "score": 490,
    "hn_content": "- Johnson and Johnson (J&J) has sued researchers who linked talc to cancer.\n- J&J's handling of the situation, including creating a new entity to pick up liabilities and filing for bankruptcy, has been controversial.\n- The \"Texas two-step\" strategy, used by J&J, allows a parent company to protect its assets by creating a subsidiary to hold liabilities, which then files for bankruptcy.\n- The bankruptcy filing was dismissed, but LTL (the subsidiary) filed for bankruptcy protection again with a higher settlement proposal.\n- The legal maneuver has generated outrage due to concerns about corporate responsibility and the potential for delaying justice for claimants.\n- Critics argue that the bankruptcy process consolidates claims and allows for fairer distribution of payouts, while others believe it is a way for J&J to avoid larger settlements.\n- The primary concern is whether the victims will receive fair compensation and whether this strategy is an abuse of the bankruptcy system.\n- The situation highlights the challenges in consumer protection law and the potential for companies to dodge responsibility for their actions.- Johnson & Johnson (J&J) is facing numerous lawsuits alleging that its talc products, including Baby Powder, were contaminated with asbestos and caused cancer.\n- J&J filed for Chapter 11 bankruptcy reorganization to deal with the litigation, but their reorganization plan was dismissed. They refiled the bankruptcy proceeding shortly after it was dismissed.\n- J&J's bankruptcy plan may be an attempt to minimize the amount they have to pay out to claimants. Shareholders may interpret this as the company fulfilling its fiduciary duty.\n- The CEO's wealth is likely tied up in company equity, so bankruptcy could potentially affect him. However, the primary goal of bankruptcy is to influence the risk/reward calculus of other companies that may release unsafe products.\n- The effectiveness of fines as a deterrent is debated. Some argue that if a fine bankrupts the company, it can be an effective deterrent, while others believe fines are not enough and a more severe punishment is needed.\n- Corporate management can prioritize protecting their money, even at the expense of other employees or safety. The interests of the owners often come before anything else.\n- Holding public companies accountable for their actions can impact pension funds. If a company goes bankrupt, pension funds invested in that company may be wiped out.\n- There are concerns about the reliability of research in various fields, including medicine. Some argue that many papers are misleading, with misleading baselines, overfitting, and sometimes even fabrication of results.\n- Research in medicine and health-related fields faces similar pressures and biases as other fields. However, there is a higher standard for scientific evidence that can be used in court cases than the peer review process.\n- Talc is naturally contaminated with asbestos, and studies have suggested a possible increase in ovarian cancer risk from talcum powder use. More research is needed to understand the potential link between talcum powder and cancer.\n- Lawsuits against J&J highlight the need for more rigorous testing and regulation of talc products to ensure consumer safety.\n- Lawyers involved in these lawsuits will likely benefit financially from the litigation process.\n- Consumers may end up paying higher prices for J&J products as a result of these lawsuits.\n- The controversy surrounding talc products raises questions about the need for more transparency and labeling requirements for asbestos content in household products.",
    "hn_summary": "- Johnson & Johnson (J&J) is facing lawsuits alleging that its talc products may be linked to cancer.\n- J&J's handling of the situation, including creating a subsidiary and filing for bankruptcy, has generated controversy and concerns about corporate responsibility.\n- The lawsuits highlight the need for more rigorous testing and regulation of talc products to ensure consumer safety."
  },
  {
    "id": 36762879,
    "timestamp": 1689622410,
    "title": "You can deactivate anyone's WhatsApp account by simply sending an email",
    "url": "https://twitter.com/JakeMooreUK/status/1680962682726363136",
    "hn_url": "http://news.ycombinator.com/item?id=36762879",
    "content": "Due to Twitter's new pricing structure, we made a difficult choice to restrict the option of unrolling tweets on the web to Premium members only. You can still unroll tweets for free by visiting Twitter and replying to the tweet with \"@threadreaderapp unroll.\" We appreciate your understanding!Thread ReaderOne-click sign-up and loginSign up or login to access your unrolled and bookmarked threads (or PDF archives if you are a Premium member!)Login with TwitterLogin with EmailLogin above to accept Thread Reader App'sTerms of Service and Privacy PolicyHelp | About | TOS | Privacy | Twitter Files",
    "summary": "- Twitter has implemented a new pricing structure that restricts the option to unroll tweets on the web to Premium members only.\n- To still be able to unroll tweets for free, users can visit Twitter and reply to the tweet with \"@threadreaderapp unroll.\"\n- Premium members have access to additional features such as bookmarked threads and PDF archives.",
    "hn_title": "You can deactivate anyone's WhatsApp account by simply sending an email",
    "original_title": "You can deactivate anyone's WhatsApp account by simply sending an email",
    "score": 432,
    "hn_content": "Hacker News new | past | comments | ask | show | jobs | submit loginYou can deactivate anyone's WhatsApp account by simply sending an email (twitter.com/jakemooreuk)432 points by KomoD 14 hours ago | hide | past | favorite | 198 commentsyokto 10 hours ago | next [\u2013]Isn't this flow what more ore less what you would expect? Could someone suggest what would be the appropriate alternative here?- The inconvenience to the deactivated account is minor: one SMS verification code and the account is back, queued messages get received, etc.- Persons who lost their phones probably don't have a good fast way of proving their identity, as their identity is tied to their phone number in WhatsApp's model.- Needing to quickly lock out spammers, thiefs or hackers is probably far more frequent than abuse of this feature.- If abuse of this feature becomes a recurring problem, I'd expect WhatsApp to react and adjust the flow to place more burden on its user.The auto-delete part is slightly more worrying, but if you don't use WhatsApp during 30 days, your account and group membership probably isn't very precious. Backups are automated and separate. You can still easily re-create an account with the same number then.The story might be \"Apps should stop using SMS and phones numbers as the source of identity\", and while I generally agree, most comments don't seem to be about this and WhatsApp is maybe _the_ one app whose success was based on this very idea.replyhackernewds 10 hours ago | parent | next [\u2013]What! This is terrible. No other unrelated entity should be able to impact another account they don't own, no less deactivate it!Imagine an automated form of this where you can just mass deactivate antagonistic accountsreplyyokto 10 hours ago | root | parent | next [\u2013]As YetAnotherNick said, logout might be the better word to describe the impact here (plus, a fairly aggressive inactivity deletion period).I agree with you in principle, but I still don\u2019t understand how else to mitigate this: WhatsApp must get a lot of cases of stolen unprotected phones. The victim can ask their operator to lock the SIM card, but their WhatsApp account would still be out in the open.With the continuous improvements in mobile OS security defaults, I\u2019d expect this scenario to become less and less of a problem, but it must still be accounted for.The process still goes through support ticketing, so I\u2019d expect a spike to be noticed and stopped.replylxgr 7 hours ago | root | parent | next [\u2013]> The victim can ask their operator to lock the SIM card, but their WhatsApp account would still be out in the open.Can't the legitimate owner recover the account once they get a replacement SIM?replyyokto 2 hours ago | root | parent | next [\u2013]Whoops, my comment isn't very clear, sorry. I meant: \"but their account would still be active and in the hands of the thief, if there is no way to quickly deactivate it, e.g. before receiving a new SIM card from their operator that would enable you to prove your identity to WhatsApp.\"replysb8244 7 hours ago | root | parent | prev | next [\u2013]How long would this be open vs shutting it down using the email method?replylxgr 7 hours ago | root | parent | next [\u2013]Do you mean how long is account recovery by the SIM/number owner possible, or how long can the phone thief continue using the WhatsApp account if the owner doesn't recover?replysb8244 7 hours ago | root | parent | next [\u2013]Maybe I misunderstood the comment you and parent comment were making. I interpreted it as \"they can recover it via SIM, so the lockout method isn't needed\".My point to that is that it is true, but the lockout would prevent a thief from using it until the new SIM is received. Versus a thief having access until the new SIM is received.I use telegram instead of Whatsapp, but I would hate for anyone to have any time at all on my account. I'd prefer to immediately lock the whole thing down and figure it out once I have everything sorted.replyYetAnotherNick 10 hours ago | root | parent | prev | next [\u2013]Logout is the better word than deactivation in this scenario.replyguiambros 8 hours ago | root | parent | next [\u2013]Since when logout comes with a \"we'll delete your account if you don't log back in in 30 days\"?This is just an atrocious flow. A better approach would be a \"temporary emergency block\", and then give the user a week to sort it out, otherwise the account is automatically reinstated.replyruszki 6 hours ago | root | parent | next [\u2013]While 30 days sounds extreme, I\u2019ve got plenty of warnings in the past 25 years from sites which wanted, and did delete my account because I didn\u2019t visit their site in a specified timeframe, like half a year, or a year.replypmontra 4 hours ago | root | parent | next [\u2013]I got one from Discord a few days ago. I didn't check if it was real or phishing, and I didn't check my password manager. I can't remember why I would have created a discord account so I'll let it go. Maybe I was self squatting.replyrcheu 4 hours ago | root | parent | prev | next [\u2013]The 30 days thing is likely from GDPR requirements. You cannot keep user data longer than that after they request deletion.replygrepfru_it 10 hours ago | root | parent | prev | next [\u2013]Brb automating a denial of service attackreplypost-it 9 hours ago | root | parent | prev | next [\u2013]> Imagine an automated form of this where you can just mass deactivate antagonistic accountsThen imagine it. What would be the ramifications?replyhot_gril 10 hours ago | root | parent | prev | next [\u2013]I imagine WhatsApp would limit this capability or otherwise fix the issue if someone started abusing it.replydylan604 10 hours ago | root | parent | next [\u2013]how many accounts would need to be affected to be considered abused?replyhot_gril 9 hours ago | root | parent | next [\u2013]Probably more than 1 and less than 1000.replytjbiddle 6 hours ago | parent | prev | next [\u2013]> The auto-delete part is slightly more worrying, but if you don't use WhatsApp during 30 days, your account and group membership probably isn't very precious.I've had plenty of times where I'm offline for a few weeks. Would cut it very close to having my entire account deleted.I'd like a period where I'm offline for months.replylxgr 7 hours ago | parent | prev | next [\u2013]> The inconvenience to the deactivated account is minor: one SMS verification code and the account is back, queued messages get received, etc.When traveling and using another SIM, it's not always that easy.replywhyoh 2 hours ago | parent | prev | next [\u2013]>Could someone suggest what would be the appropriate alternative here?1. Identify to your carrier and get a new SIM, deactivate the old one. 2. Put the SIM in another phone and take back your WhatsApp account.Isn't this the standard recovery method for apps that rely on your phone number?Getting a new SIM takes longer than sending an email, but at least you don't have this easy abuse potential.replyyokto 1 hour ago | root | parent | next [\u2013]What is the abuse your referring to?With your suggested approach, the attacker is free to use the account to impersonate the victim until they get a new SIM card, which could easily take days or weeks.This seems like a degredation compared to the current abuse potential which is mostly limited to logging you out.replywhyoh 1 hour ago | root | parent | next [\u2013]>This seems like a degredation compared to the current abuse potential which is mostly limited to logging you out.I think it depends on who you ask. IIRC there was a stat that showed a substantial % of people only use WhatsApp rarely and they might not notice the deactivation and/or miss the 30 days deadline, getting their accounts deleted.replyasd88 8 hours ago | parent | prev | next [\u2013]> The inconvenience to the deactivated account is minor: one SMS verification code and the account is back, queued messages get received, etc.Unless I spin up simple automation to deactivate your account every hour.replyyokto 2 hours ago | root | parent | next [\u2013]This is trivial to mitigate with per-account rate limiting.On top of that, if a specific account is targeted at the rate-limit, a flag could be put in place to let support disable the automation for that account.replydotancohen 23 minutes ago | root | parent | next [\u2013]And once that happens, I then steal the target's phone.If we're talking about deactivating someone's account via email, we are already talking about a targeted attack.replymvdtnz 2 hours ago | parent | prev | next [\u2013]I can't tell if you're being serious or sarcastic. It genuinely looks like the former but I have to assume it's sarcasm because I can't believe anyone would seriously post this..?replyEGreg 9 hours ago | parent | prev | next [\u2013]Expected, eh?Give us your number, we\u2019ll all take turns deactivating it every day. Then see how fun it isreplygchamonlive 8 hours ago | parent | prev | next [\u2013]This combined with using a secondary SMS for daily use means a quick and easy way to protect your account. I also agree this is a win.replygo_prodev 13 hours ago | prev | next [\u2013]Years ago I bought my dad an Audible subscription, but because it was a gift I signed up with my email address and then changed it to my dad's address on his birthday. Somehow I ended up inside his Amazon account because I used his email address. I guess some of the backend logic is hard to get right the first time.Another time I was talking to a credit union CTO who was dealing with someone blocking other people's account access by picking a random account number and making 3 bogus guesses to lock them out. At the time the credit union had a policy that required calling them to unblock... which was a PITA on weekends when people need money.replyendominus 11 hours ago | parent | next [\u2013]Speaking of Amazon's account process, I have a really annoying problem with theirs. Apparently I somehow managed to create two amazon accounts with the same email address, but different passwords. They have different order histories and addresses and everything, but the account name is identical. It sometimes makes it confusing to tell why an order I placed hasn't shown up.Interestingly, I can't change the password on one account to the password of the other account. The attempt fails. Which is... somewhat concerning.replyschlarpc 8 hours ago | root | parent | next [\u2013]This was considered a feature back in the day; it was called MASE - Multiple Account, Same Email. I'm pretty sure you can just change the email on one of them to get out of that state.replylxgr 7 hours ago | root | parent | next [\u2013]Out of curiosity \u2013 what was the use case for that? It seems terribly confusing!replyjcrites 1 hour ago | root | parent | next [\u2013]The way it was explained to me: originally, Amazon didn't want there to be any barriers to someone making a purchase on the website, not even the barrier of having to reset a forgotten password. So the choice was made to allow people to create new accounts with the same email address (such as when attempting to check out; that's when this would likely happen). Each account was distinguished at login by its email + password combination.It was indeed called \"Multiple Accounts, Same Email\", though I only heard that term applied to it much later (after the phenomenon of these accounts was identified as a problem that the company needed to resolve). I don't think it was exactly what I'd call a feature, in the sense that I don't think anyone expected users to do it intentionally, so much as it was \"We don't want to lose a purchase to someone getting stuck at the login screen\".The Web and its users have evolved significantly since those early days, and resetting a password by email is no longer the barrier it once was. Among other reasons: web users are savvy to the idea of having accounts, which was not true in Amazon's early days; and email is a lot faster and more reliable now.Allowing multiple accounts to share an email address proved to be a problematic decision later on for a number of reasons. Amazon doesn't allow this any more, at least not from the primary sign-in screen; it gives an \"Email address already in use\" error.replydlgeek 6 hours ago | root | parent | prev | next [\u2013]Back in the late 90s, there weren't a ton of free email services and most people used an account from their ISP. Extra accounts were hard to come by. If you had a family sharing an internet connection, they might very well share an email address too. This let them have individual Amazon accounts.replyetothepii 7 hours ago | root | parent | prev | next [\u2013]Personally I use the + feature on email addresses to achieve this.me+folder@example.comMaps to the account me and will (if configured correctly) put the mail in a folder called folder if such exists.The reason you might want many accounts with the same email seem many to me if you don't realise that you can create arbitrary distinct emails this easily.replydgan 3 hours ago | root | parent | next [\u2013]Unfortunately many services think they are smarter than you, and disallow \"+\" in email fieldsreplyNekobai 1 hour ago | root | parent | next [\u2013]Indeed! And even worse, some services will happily accept \"+\" in email fields, but then some part of the service fails to encode the \"+\" sign correctly, so some features may be broken in unexpected ways.Sometimes you can't even contact Customer Services because \"your account doesn't exist\" (because you cannot feed the correct email address to their customer service site).Thankfully it's rare, but when it happens it's extremely infuriating.replylxgr 7 hours ago | root | parent | prev | next [\u2013]Yes, that's exactly what plus addresses exist for!It seems to me like all benefits of the \"exact same email, multiple accounts\" feature are vastly outweighed by the inconvenience for users simply forgetting that they already have an account, and creating a second one by accident that way.I mean, even I end up almost creating an account by accident every now and then (mostly on sites using the horrible \"signup is the default, login needs one additional click\" pattern), and I do so using autofill from a password manager!replyanshumankmr 7 hours ago | root | parent | prev | next [\u2013]So I have an amazon.com and amazon.in account. The latter one is my main account but the former one I created to redeem a gift card I got from a survey.replylxgr 7 hours ago | root | parent | next [\u2013]Seems more like an artifact of Amazon having enabled global logins late into product development than a \"feature\" to me.Are you sure it's two accounts? I am using the same login on two different Amazon sites as well, but I'd call that SSO more so than \"two accounts on one email address\", since all data is separated by country, but the email and password are the same.replyanshumankmr 1 hour ago | root | parent | next [\u2013]It has separate order historyreplysharkmerry 10 hours ago | root | parent | prev | next [\u2013]You are not alone!!! I am in the exact same situation. I've told this to so many people and no one believes. I'm stunned I stumbled on this. Small worldreplyhereonout2 10 hours ago | root | parent | next [\u2013]Yes me too, depending which password I use I get a different account with same email! Madnessreplyglenngillen 5 hours ago | root | parent | next [\u2013]I have this too, though I assumed it was some legacy of creating accounts in different geos (i.e., .com.au, .co.uk, and .com).replydylan604 10 hours ago | root | parent | prev | next [\u2013]Is it possible that one account was created using an email address and the second account using a phone number, and then some where down the line each account got updated with the missing information so that now both accounts look identical?replyjwrallie 2 hours ago | root | parent | prev | next [\u2013]I had a similar issue when I created two accounts on different regions using the same email address, then Amazon started operating in my country and they started redirecting one of the accounts to my country, leaving me with a mess of two accounts that would randomly connect to three different regions.It was really annoying as I would login on my browser to one account normally, but when I ordered an Amazon stick, it came with a different account from a different region preinstalled and would complain I didn't signed up for Prime.I ultimately fixed the issues by manually changing the email on each account to a different address, but it was very confusing until I figured out what was happening.replypmontra 4 hours ago | root | parent | prev | next [\u2013]Oh well, not Amazon but I got stuck in the ecommerce of a large shop chain. I can't register because they tell me I already have an account. So I use that email to recover the password but I can't because the account must be activated. So I ask for an activation link but I can't because that account doesn't exist. I guess they have different databases or microservices taking care of different steps of the registration process and something crashed at the wrong time and my overall record is inconsistent. I gave up a couple of years ago. I buy from them when I go to one of their physical shops.replysizzle 9 hours ago | root | parent | prev | next [\u2013]Holy crap I did this this on accident when I tried signing up for an Alexa skill in the Alexa app and accidentally created a new account with same Amazon.com email address, then got flagged for suspicious activity cause I was on a VPN and got blacklisted. It took so many calls for customer support to acknowledge there was even an issue and they still told me to just use a different email in the end. I was passed and just made a new Amazon account with the original email address, but simply added a period in the middle and still use it while locked out of the other original account. It\u2019s bonkers lolreplyIzkata 10 hours ago | root | parent | prev | next [\u2013]I have no idea if this would work and don't want to risk messing it up for myself, but have you tried changing (one of) the account emails?On the website go to the Your Account page (\"Account & Lists\" dropdown -> \"Your Account\" section -> \"Account\" link, which goes to https://www.amazon.com/gp/css/homepage.html ) and click \"Login & security\" to get to it. Same place you'd update your password/etc.replyendominus 10 hours ago | root | parent | next [\u2013]Maybe that would work, but I'm also concerned about messing something up. In particular, tripping some bot detection/account duplication algorithm and getting my account banned and all its content gone. I'll suffer the small annoyance rather than risking the black swan disaster.replyReason077 9 hours ago | root | parent | next [\u2013]I wouldn't worry about that. I've had multiple Amazon accounts (with different emails!) going back many years. Never been an issue. They even make it easy to switch between them with the \"switch accounts\" function.replydarkvertex 8 hours ago | root | parent | prev | next [\u2013]Same here. In my case my Amazon.com and Amazon.ca are separate accounts sharing different passwords yet the same email. Fucking weird.replytoast0 10 hours ago | root | parent | prev | next [\u2013]I've done this, but I was pretty sure I managed to have both accounts with the same password at that point in time. On the plus side, you can change email addresses, so now I have amazon@ and amazon2@ and all is sensible again.replyverelo 10 hours ago | root | parent | prev | next [\u2013]I have this exact issue too. Let me know if you ever fix it!replyReason077 9 hours ago | root | parent | prev | next [\u2013]Couldn't you solve this by changing the email address on one of the accounts?replyvoidmain0001 10 hours ago | root | parent | prev | next [\u2013]You have two separate Amazon accounts on the same TLD? Example amazon.ca and amazon.com.replyendominus 10 hours ago | root | parent | next [\u2013]They're on the same TLD; amazon.com. I assume they were merged from some service Amazon bought and combined user accounts with, but I honestly am not sure.replydporter 10 hours ago | root | parent | prev | next [\u2013]Can you change the password to something unrelated, but are unable to change it to the same? Seems like they might not be salting their passwords?replyjen729w 12 hours ago | parent | prev | next [\u2013]Someone with my name bought a new iPhone in Bismarck, ND last week. They gave AT&T my iCloud email address which is firstname.lastname. An honest mistake, I guess.AT&T dutifully asked 'me' to confirm my email address. I did not.Aaaand... now I still get all of his account email. So what's the point.replysoneil 12 hours ago | root | parent | next [\u2013]I've been struggling with this for years - but with a fun twist. My gmail address is first.last, and someone in the UK keeps using it - but they do not have remotely the same first name, and they don't spell their last name the same as I do (the single-L in my username here is a less common deviation, their surname is the more common variant).Years. I've closed netflix accounts, I've sent them sms from their telco's webtext portal asking them to stop, and still there's a koneill out there who is very, very confused about why his email doesn't work. I know where he lives, I know what pizza he ordered, I know his name, his phone number, I just don't know his email address. And apparently, neither does he.The number of services that fail at email validation (or keep sending you reminders, forever, that you haven't validated), blows my mind. For such a simple process, that seems to exist on every single service I (and koneill) sign up for, it has a surprisingly low rate of successful implementations.replyrootusrootus 11 hours ago | root | parent | next [\u2013]I have a similar problem. I have a half dozen different people sending their emails to my gmail account. One of them is a woman who signed up my address for her health care provider, and they're quite liberal with what kind of detail they're willing to put in an email. I tracked her down on Facebook and mentioned it to her, and she seemed to get that it was a problem she might want to solve, but to this day I still get all those emails.In retrospect I should have chosen g6adfs789zg2@gmail.com or something.replyzx8080 9 hours ago | root | parent | next [\u2013]> I tracked her down on Facebook and mentioned it to her, and she seemed to get that it was a problem she might want to solveNot a lawyer, but feels like you could be sued for a) reaching out and clearly mentioning you have some very private information.How does it work for a paper mail - from what I understand it could be illegal to open any letter originated to some other person's name.replyehPReth 7 hours ago | root | parent | next [\u2013]for paper mail here in Canada I just see it's not for me, mark a line though it and write \"Return to Sender, no longer at address\". Then it gets put in the outgoing mail system (a slot where I receive my mail, or could also take it directly to any standing postal box, or the post office). Then it goes back though the postal system (for free) to originating sender in most cases.replynucleardog 7 hours ago | root | parent | prev | next [\u2013]Sued for what?Unless he was trying to extort her he\u2019s done nothing wrong.Her healthcare provider, on the other hand, could be in some hot shit.replytverbeure 10 hours ago | root | parent | prev | next [\u2013]I got a gmail invite pretty early and choose a single Spanish word that's the equivalent of John.I'm the recipient of bank statements, cell phone statements, medical information, invitations to parties, and answers to HOA complaints. But more than anything, I'm the world's most prolific subscriber to dating websites, and my taste covers the whole spectrum and back.I keep using the email address to use for low importance stuff. It's also a good way to see that clicking \"Unsubscribe\" actually works. Or better, the Spanish equivalent: \"Darse de baja\". I know the words very well.replyMiddleEndian 9 hours ago | root | parent | next [\u2013]One day, you should show up to one of those parties.replyKiwiJohnno 6 hours ago | root | parent | prev | next [\u2013]I'm in exactly the same boat. Eventually I opened one if his phone bills which had his phone number (UK). I rang him and tried to explain the situation which quickly turned surreal.He argued that I was lying about getting his phone number from his phone bills because he doesn't get his phone bill emailed out to him. I said yes, that is correct. Your phone bill is emailed to me. Eventually I got frustrated with him and told him I was trying do him a favour and he accused me of hacking his email account.Then over the next few hours he called me back multiple times to tell me he had called the police, how much trouble I was in, and to tell me to stop calling him and harassing him or he would press charges. I pointed out he was the one that kept calling me, and somehow that registered and he never called back.He did fix his phone account so I don't get those, but I get plenty of other email for him.replygrepfru_it 10 hours ago | root | parent | prev | next [\u2013]I got a free peacock account this way. They just recently disabled their credit card, but I was able to watch the world cup for free and that's all that mattersreplyjen729w 7 hours ago | root | parent | prev | next [\u2013]My mate Alex was getting email for a guy who should have been at work at Heathrow.After years of trying to make them stop, he just started replying. \u201cI\u2019m not coming in tomorrow\u201d, that sort of thing.He never lied. He was not going to be at work at Heathrow tomorrow.I think that finally made it stop.replycscheid 7 hours ago | root | parent | prev | next [\u2013]I don\u2019t quite know why, but my combination of first and last name on gmail is such that I get email directed at other people with the same name as me, including financial documents. Wild stuff. I would reply with \u201cum you probably should check before sending\u201d but after a while I just started ignoring it.replyirrational 11 hours ago | root | parent | prev | next [\u2013]There is a woman in another state that must have a gmail address very close to my wife\u2019s. We know when this woman gets Botox, how much she pays for her kids dance lessons (a lot!), and so much more. You would think she would realize at some point, but it has been years and my wife still gets so much of her mail.I used to get email for a guy in California when he would buy something from Harbor Freight, rent a movie from Redbox, or order a pizza. Those started tapering off about a year ago, so he must have figured it out.The strangest one was I was receiving email for a colonel in the US Army! For a few years I kept getting these group emails to all these army officers about upcoming training exercises. I thought about replying to let them know they shouldn\u2019t be sending them to me, but was worried about getting in trouble, so never did. They continued for years, but finally stopped. I always wondered if the guy had a .mil address and accidentally used gmail.com.reply_jal 10 hours ago | root | parent | prev | next [\u2013]Yep, very similar situation here. I get a lot of email for two different people, one in Texas and one in Leeds.I also started getting a ton of spam from some cell phone retailer in Jakarta - someone used an email address of mine to sign up for a SIM, it seems, and unsubscribing from their crapflood is behind a password, assuming they'd even honor it. I blackholed their mail server at mine, but that doesn't scale.And I get an endless stream of \"a lot has happened since you last logged in\" any time I un-blackhole Zuckerbook, and I've never used them.At this point, every commercial entity I do business with gets a unique email address so I can turn them off. But that doesn't stop the confused/stupid/malicious from using them.If I can find the time, I've been wanting to write a new milter-type tool to make it much easier to control which mail servers I'll talk. Yes, this is how SMTP dies. But at least it will be usable for me in the mean time.replymakr17 11 hours ago | root | parent | prev | next [\u2013]My gmail address is lastname@gmail.com. Not a particularly common last name, and I thought it lucky when I got that address early on. I've since come to view it as mostly a curse.I get email invoice every time Orkin goes out to spray a house in North Carolina. No option to say \"this isn't me\", and I've given up calling to tell them after multiple cycles.The elderly German couple that would email their train itinerary so that their cousin could pick them up at the station. I would politely reply that I am not their cousin, and consequently their cousin would not be at the station. And six months later we start again.Someone in Canada with first initial + last name that results in my last name kept getting wired money, and I would get in email with instructions. Of course no \"not me\" option. I haven't seen one of those in a while, hopefully he figured it out.And so many more stories of people with my last name or close to it happily sending me their email... But I've had the address for practically forever, and really don't want to let it go.replyEvanAnderson 11 hours ago | root | parent | next [\u2013]I love these stories.I got service emails for the same year, model, and color Honda Civic that I own from a dealer in the UK. I am in the US. That alone was spooky.The car was owned by somebody who matched my first initial, last name email address. (Edwin, I believe\u2026)I tried to unsubscribe. I tried to contact customer service. Nothing worked.Each email would come with a little video walk around of the car. Eventually I started responding saying that their paint looked better than my car, etc.I don\u2019t get them anymore. I presume the owner sold the car.replyjwrallie 2 hours ago | root | parent | prev | next [\u2013]Same situation, but on mine I got emails from some lady on the other side of the world that wanted to adopt a kid, then later she was scheduling some Botox applications, both cases I was half surprised that they didn't double check and half curious to see what comes next.reply_whiteCaps_ 10 hours ago | root | parent | prev | next [\u2013]My gmail address is also lastname@gmail.comI've received Amazon gift cards, customs approval for a yacht arrival in Vanuatu, spreadsheets from Iraqi oilfields, children's book reports, pictures of dogs meant to be sent to veterinarians, etc etc.replygrepfru_it 10 hours ago | root | parent | prev | next [\u2013]Same story here, bro. It was really interesting when my cousins wife emailed me (not thinking it was new) about my cousins infidelity. That one made me rethink the safety of email addressesreplytoast0 10 hours ago | root | parent | prev | next [\u2013]Given there's a couple peeps who can't figure out their email address, I do my best to click on 'not me' or just ignore the confirmations intended for other people. But if I get mail for others that should have been confirmed, I mark it spam, because it is. Sometimes that includes an unsubscribe, which sometimes works.replyLorenDB 7 hours ago | root | parent | prev | next [\u2013]Obligatory relevant XKCD: https://xkcd.com/1279/replyTheJoeMan 11 hours ago | parent | prev | next [\u2013]Hey just fyi: they\u2019re not doing it for the purpose of locking people out. They\u2019re doing a distributed account breakin. Doesn\u2019t matter to the thief who\u2019s money they steal, so just try \u201cpassword\u201d on everyone\u2019s account until you get in.replygabeio 11 hours ago | root | parent | next [\u2013]Yet another amazing reason to use hide my email features, less-guessable user emails as well as unique emails per service.replyFnoord 9 hours ago | parent | prev | next [\u2013]Years ago I started a Netflix trial account while with the family at my mom's place. I intended it to be for her, and called it 'grandma <her name>'. I ended up paying for it (she never has, directly). But apart from when we're around she barely used it and got back to linear TV (though via internet). Meanwhile, my wife and kids love it and it is among our streaming portfolio (for lack of a better term). So basically it is a Netflix account on someone else's name, though a family member. She kept getting these emails that someone logged in to her account, and every time I answered to her 'yeah that was one of us'. Eventually I changed the email address of the account to my own, and now I keep getting called 'grandma <her name>'. And you know when she watches Netflix? When we're around (well, my kids do then). Now the other day my wife got some kind of confirmation error that this was our account, and ever since the writing's been on the wall that we'll get into trouble on this. Btw, we can only pay for it via gift cards or manual bank transfer. The automated system does not work, and every time it gets our card denied. Honestly, it is an abysmal customer service (my wife tried to sort it out on various occasions w/them; still broken).replytopato 8 hours ago | root | parent | next [\u2013]Netflix added a way to export your profile's watch history etc to a separate account... (this is the only reason I could think of why you wouldn't just make a new Netflix acct. lol)replyufmace 5 hours ago | parent | prev | next [\u2013]I kind of enjoy these stories since I'm in the inverse situation. I have a firstlast@gmail.com address with my real name, which is pretty unique. I feel a bit annoyed and paranoid sometimes that, since my name is unusual, a Google search will bring up a ton of personal information that I'd really rather be a bit harder to find. But at least I don't get a ton of emails meant for random strangers who put the wrong email somewhere!replyusername135 12 hours ago | parent | prev | next [\u2013]This happens with my Gmail account.I know periods don't count, supposedly, but I still get emails for someone with the same name as mine. My email is first.last, theirs is firstlast. I wonder how much of my stuff they get erroneously?reply__ryan__ 12 hours ago | root | parent | next [\u2013]You are correct that the period doesn\u2019t count. Both email addresses belong to the same account. A possible explanation is that they have entered your email as a mistake.replyOJFord 11 hours ago | root | parent | prev | next [\u2013]The full stop doesn't count. If you're successfully using 'first.last', then theirs is not 'firstlast', that is also yours, as you said yourself.Theirs is probably 'firstlaast' or something - i.e. some typo unrelated to their decision not to separate by '.'.replydharmab 1 hour ago | root | parent | prev | next [\u2013]A more likely explanation: https://xkcd.com/1279/replyandromaton 5 hours ago | parent | prev | next [\u2013]My user name at a major bank was Thomas Anderson (of Neo fame) but got locked out too many times, so now it's a long random thing.replymey 12 hours ago | parent | prev | next [\u2013]Instacart has some sort of similar issue, signed up under my email, changed the email address to my wife, support requests get sent to both of our addresses.replyswader999 13 hours ago | prev | next [\u2013]Too bad it didn't work for the entire meta user base. We could free the world. It would be like independence day when they uploaded the virus to kill the mothership.replymaskedinvader 13 hours ago | parent | next [\u2013]I get why one would feel this way if this was one of Meta\u2019s social media apps, but WhatsApp is one of the biggest messaging apps used in so many countries and perhaps also helped kill the telecoms companies paid sms plans to force cheaper sms msging rates, if anything WhatsApp is perhaps the best value Meta has provided to the world, bringing the world closer.replymidasuni 13 hours ago | root | parent | next [\u2013]Except that was all done before meta bought it.https://www.flyertalk.com/forum/travel-technology/952359-tho...replylmm 11 hours ago | root | parent | next [\u2013]But getting bought by facebook was the only business plan they ever had, so it was facebook that made all that possible.replyeps 11 hours ago | root | parent | next [\u2013]Not true. They were doing perfectly fine charging a fair fraction of their 100 mil userbase $1 a month. They sold because founders wanted an exit.replyUnai 4 hours ago | root | parent | next [\u2013]Not true. They were charging 1\u20ac a year, not a month (at least that's the case in my country). The math doesn't add up.replyhot_gril 10 hours ago | root | parent | prev | next [\u2013]They probably got initial funding from investors thinking about a future exit. Investors aren't as interested in a company that intends to simply survive on modest profits forever. This is also why startups tend to magically die when big companies aren't doing well.replyhackernewds 10 hours ago | root | parent | prev | next [\u2013]Inaccurate. They actually tried every remedy to delay/deceive/dissuade this. This is verified in official emails declassified as part of lawsuits.replynvarsj 1 hour ago | root | parent | prev | next [\u2013]It wasn't end to end encrypted either before Meta bought it. Maybe it's not all bad?replyfrizlab 13 hours ago | root | parent | prev | next [\u2013]WhatsApp is a company Meta bought, not brought to the world AFAIK.replyAngostura 12 hours ago | root | parent | prev | next [\u2013]It also demands full access to the totality of your contacts to work properly.An appalling requirementreplyNikolaNovak 12 hours ago | root | parent | next [\u2013]I always feel I'm in a twilight zone with whatsapp. Am I the only person who doesn't want or need to give the app all of my contacts, or even register with just phone number? Phone number is such an intensely and irrevocably identifiable token and so hard to change, that using it for pervasive messaging seems insane to me :-/replyqingcharles 12 hours ago | root | parent | next [\u2013]I hate these apps that absolutely need a phone number. I couldn't pay my bill on my cellphone one month, lost the number and now I can't access either my WhatsApp or Telegram accounts.replyufmace 5 hours ago | root | parent | next [\u2013]FWIW, Telegram actually handles this pretty well. You just have to have loged in on another device while you still have your phone. You can use that other device to deauth your lost or deactivated phone and auth new logins on other devices.replyromwell 12 hours ago | root | parent | prev | next [\u2013]I've had my phone stolen while traveling, and I can't say how much I despise any system that uses a phone number for authentication.Go figure, you can't get a SIM card sent to you from the US to Europe, meaning that you potentially lose:* Access to messenger apps and chat history* Access to your bank account (with a special nod to Citi)* Access to your email account if it uses \"2FA\" with a phone (looking at you, Google)* etcGiven that my bank cards and laptop were stolen along with the phone, I've had a Very Fun Time\u2122 dealing with all these systems.replysmallerfish 11 hours ago | root | parent | next [\u2013]You can port your phone number to a voip provider if you will be out of the country for a while. Use a sip phone app, and the \"transport layer\" sim that you happen to use will have nothing to do with the phone number that is intermingled with your identity.replyromwell 10 hours ago | root | parent | next [\u2013]This is way too much hassle even for me as a techie.And something tells me short-code SMS receipt (which is what banks use for 2FA) is not going to work well anyway.replysmallerfish 8 hours ago | root | parent | next [\u2013]If you don't need it, you don't need it. But for the record:a) Porting your number takes about as much effort as moving between mobile phone providersb) Setting up a sip app on your phone is trivial (server, username, password) - I'm generally a fan of Acrobits Softphonec) My voip provider has an sms <> email gateway, so my bank (and other sms based) mfa lands in my gmail inboxreplyAnthony-G 10 hours ago | root | parent | prev | next [\u2013]I feel the same way but this wariness is amplified by the fact that I don\u2019t trust Meta. Still, I\u2019d be more inclined to sign up to Whatsapp than create a Facebook account; a few real-world friends have said they\u2019d prefer to use Whatsapp over SMS \u2013 particularly for sending photos.replyNikolaNovak 10 hours ago | root | parent | next [\u2013]Oh, if you're willing to follow its demands, whatsapp is a super smooth experience. All my family uses it.But the funnel is brutal. Try signing up from anything but a phone, or try not giving it full permissions, etc etc - and you'll have a miserable time. It's a vicious vicious sweet and alluring Black Mirror episode.replyjsnell 11 hours ago | root | parent | prev | next [\u2013]I'm sure you're not the only one, but in a tiny, tiny minority. Using the phone number as the identifier was pretty much the main selling point of Whats App.replyrypskar 4 hours ago | root | parent | prev | next [\u2013]>>Am I the only person who doesn't want or need to give the app all of my contactsNo, you are not the only one. I don't understand how sharing contacts with any app is legal under GDPR without getting consent from all contactsreplycharcircuit 4 hours ago | root | parent | next [\u2013]The whole point of contacts is contact information you want to share with apps.replytiltowait 11 hours ago | root | parent | prev | next [\u2013]Maybe it would break a lot of things, but my gut instinct is I wish it were illegal for an app to slurp up, even with the user's consent, all of the user's contacts. Any such entries should be manual.I don't use $SERVICE. I never want to use $SERVICE. I certainly don't consent to $SERVICE having my contact info because some acquaintance/friend/family member who doesn't know any better tapped \"allow\" on a button. But because it's allowed, any number of immoral companies like Facebook have my info, even though I've made a conscious decision never to use them due to their privacy violations.replyhot_gril 10 hours ago | root | parent | prev | next [\u2013]Specifically, you need to give it access to your contacts to create contacts on WhatsApp, otherwise you just see phone numbers.replyusername135 12 hours ago | root | parent | prev | next [\u2013]It still boggles my mind that they paid SO much for itreplyBarrin92 11 hours ago | root | parent | next [\u2013]well it is by far the most used messenger app in the world with 2+ billion users so in that sense it seems prescient but i'd agree it's still questionable how they'll monetize it.replyannadane 13 hours ago | root | parent | prev | next [\u2013]Yes but the original founders did that. Zuckerberg took it from them and immediately lied about data sharing, there's a reason why the founders left in disgustreplyavalys 13 hours ago | root | parent | next [\u2013]Correction: The founders sold it to Zuckerberg for billions of dollars.Saying he \u201ctook it from them\u201d is outright dishonest.replyannadane 13 hours ago | root | parent | next [\u2013]They sold it under the condition he wouldn't lie, it was a condition for him to have it, and he liedreplyavalys 13 hours ago | root | parent | next [\u2013]So why didn\u2019t they take the billions of dollars he paid them and sue to have this \u201ccondition\u201d upheld?replyer4hn 12 hours ago | root | parent | next [\u2013]One of the co-founders, Brian Acton, has funded most of Signal (~100M USD) in his post WhapsApp life. It is a very hacker mindset solution. Instead of turning to the law to enforce nebulous claims against a megacorp, make a better product with the money you got from said megacorp.replybboygravity 12 hours ago | root | parent | next [\u2013]Plot twist: Signal turns out to be a CIA honey-pot.replybrewdad 11 hours ago | root | parent | next [\u2013]I know \"nothing to hide\" is never a strong argument but even if Signal is a CIA honeypot, if it keeps my personal conversations from becoming marketing fodder, sign me up!replypessimizer 11 hours ago | root | parent | next [\u2013]I'm definitely not a \"nothing to hide\" guy, but if the CIA wants something on me they're going to find it in 5 minutes. They would only be using a backdoored Signal to get the smart guys; so I guess I have to thank the smart guys for the CIA giving us Signal...replyGGO 13 hours ago | root | parent | prev | next [\u2013]well he took money under the promise and when FB broke the promise, he walked away and left $850M on the table. https://finance.yahoo.com/news/whatsapp-co-founder-walked-aw...replynilsbunger 12 hours ago | root | parent | next [\u2013]To punish Facebook for breaking their promise, he ... gave Facebook $850M (by not vesting all his equity) ?replymcpackieh 12 hours ago | root | parent | next [\u2013]Angry people can be irrational. That's my read.replythakoppno 13 hours ago | root | parent | prev | next [\u2013]> I\u2019m taking some time off to do things outside of technology, such as collecting rare air-cooled Porsches.replylost_tourist 12 hours ago | root | parent | prev | next [\u2013]I'll never understand why people don't place value on integrity. I mean day to day people and not stockholders. Zuck controls what happens at Meta, it's not a board decision on stuff like this unless Zuck tells them to do it.replyDropInIn 12 hours ago | root | parent | prev | next [\u2013]It's not a condition if it's not in the contract or if it is and is not acted upon.In either of those cases it's just lip service.replymoffkalast 11 hours ago | parent | prev | next [\u2013]In an ideal world. In reality it would be a short outage, they'd roll back the DB and patch the exploit in like 10 hours total.replySilasX 12 hours ago | parent | prev | next [\u2013]Haha I\u2019d think a better comparison would be (an explosion-free) Fight Club.replymaerF0x0 12 hours ago | root | parent | next [\u2013]Or Mr. Robot attacking E corp.replyexabrial 14 hours ago | prev | next [\u2013]Reminds me of government systems where you can lock a specific user out by typing in bad passwords multiple times.replyKomoD 13 hours ago | parent | next [\u2013]Another very annoying one is when doing forgot password changes the password and emails you a copy, so some funny guy can just go and keep doing forgot password and it force changes your password.replyigitur 13 hours ago | root | parent | next [\u2013]I know a site that does this, except they run their own SMTP server that sometimes blocks up, so the emails never arrive.replygmargari 13 hours ago | root | parent | next [\u2013]This was not meant to be used that way: https://www.troyhunt.com/building-password-purgatory-with-cl...replysmrtinsert 13 hours ago | root | parent | prev | next [\u2013]wreplykiwijamo 12 hours ago | parent | prev | next [\u2013]This happens on non-government systems too. The only system I've experienced this has been a financial institution's system. Frustrating as it meant I had to make the trip into one of their branches to get it reset.replyjohnisgood 13 hours ago | parent | prev | next [\u2013]This happens on way too many sites.replydelphi4711 13 hours ago | root | parent | next [\u2013]Apple e.g. Even when 2fa is activated, and no successful login happened, they will deactivate my account and force me to change my password :/. I had to change my email that I use to login to Apple.replyrootusrootus 11 hours ago | root | parent | next [\u2013]Apple's system caused me more pain in under 1 second than anything I've experienced in the past. That's on me, of course, for using so much of their hardware and software. But still frustrating.What happened? I logged into an Apple service from the browser on my work computer. I should have known better, I get captchas everywhere when coming from our corporate network, so it's clearly on someone's shitlist. Well, even though my authentication was successful, including the verify-pin-on-device-you-already-own part, Apple said \"this is a suspicious connection\" and immediately logged out every last device, invalidated all sessions, invalidated the password so I had to change it. I was still feeling the pain from that for a week or more afterwards.And now I have a simpler Apple password than the XKCD-style one I had been using, because I got tired of typing it in over-and-over-and-over-and-over.replyharry8 8 hours ago | root | parent | next [\u2013]>That's on me, of course...Yeah, should have used, um, who?Is there no solution to this pain that is actually suggested (designed) by Apple? I would expect there is /something/ that they can do for you for a small, recurring fee.Apple are the worst UI company in the world bar none.Sum up the total amount of utterly needless pain and wanton destruction of the time of their customers and nothing comes close in the wide field of \"computing\". Yet they have the \"Good ui\" reputation, which is insane.When people got shocked by this 15 years ago I used to ask them: \"Do you know /anyone/ who owns an iPod? Think of them, three names. Now of those three do you know anyone who has not had their music collection deleted by apple software against their wishes? Among those three? No? Anyone at all?\"Nowadays there isn't one example that sabotaged literally every user, instead there a many and it has become which subset of the Apple customer smashes got you? Ask your friends. Note the solution to pay apple more.Apple are the shiny, vicious trap. Google are less shiny so it is impossible to sustain the illusion that they do \"good ui.\" Microsoft haha. And from there Apple have consistently led the way in the race to the bottom of customer abuse - you've got nowhere else to go! You can't survive the modern world without this stuff! But sure, Facebook, Microsoft, Google are really quick to match and desperate to find niches in which they can lead and Apple copy.replyhannofcart 10 hours ago | prev | next [\u2013]There's this insurance aggregator website in my country, where if you ever enter your phone number into their website, without any verification of that number, you get put on some list that elicits 5 calls a day from them trying to sell you insurance. It's crazy.I would wish it on my worst enemies. And I can...replyrobertlagrant 12 hours ago | prev | next [\u2013]Clearly Leetcode questions don't cover avoiding the world's dumbest recovery processes.replysakopov 11 hours ago | parent | next [\u2013]It might be dumb, but it locks you out in O(1).replynine_zeros 12 hours ago | parent | prev | next [\u2013]Hey, at least someone got a promo for \"impact\" in building a low maintenance service with 0% outage history.replydogtorwoof 13 hours ago | prev | next [\u2013]Several friends of mine had their WhatsApp completely hacked. Basically, hacker would spam recovery, which results in a phone call to the victim. If the victim doesn\u2019t pick up the phone, the recovery code goes to voicemail. Hacker accesses voice mail (password protected yes, but for lots of people it\u2019s a birth year, 1234, 0000, or last 4 digits of their phone), and voila they have access to your WhatsApp. They can\u2019t see your messages but can see all the groups you\u2019re in and message those.Completely preventable by having WhatsApp 2FA enabled.replycryptoegorophy 12 hours ago | parent | next [\u2013]Had this done to me BUT luckily WhatsApp has a \u201cpin\u201d feature, which prevented hackers getting any further. Not as secure maybe as a 2factor but saved my day. Highly recommend.replyAndrex 11 hours ago | parent | prev | next [\u2013]Another unintentional benefit to clinging to Google Voice for dear life... Though I don't use WhatsApp.replyfortran77 12 hours ago | parent | prev | next [\u2013]And some systems still don\u2019t ask for pin if you are calling from your phone. So if you spoof their CID (very easy to do) you get in with no passwordreplyflangola7 11 hours ago | root | parent | next [\u2013]Wow that is terrible. Wouldn't that violate multiple data protection laws?replyactionfromafar 10 hours ago | root | parent | next [\u2013]Ah maybe, maybe not \u2026 best effort blah blah cybercriminals something.So you see, your honor, as a service provider, we did no wrong.replyfortran77 6 hours ago | root | parent | prev | next [\u2013]This was how most of those \"royal family voicemail hacks\" from a a decade ago were done...https://www.nytimes.com/2010/09/05/magazine/05hacking-t.htmlreplycwkoss 13 hours ago | prev | next [\u2013]Is anyone working on a script to enumerate all phone numbers and deactivate every whatsapp account yet?replycwkoss 12 hours ago | parent | next [\u2013]I wonder if it would be possible for someone who is really good at getting media stories placed - buy a bunch of put options and sell just after the story breaks - could this be a profitable tradable event?Meta is such a big company I'd be surprised if the cost of the options premiums were less than the value that could be harvested... but maybe..?replyloeg 12 hours ago | root | parent | next [\u2013]CFAA.replystr3wer 5 hours ago | root | parent | prev | next [\u2013]is it possible? yesis it illegal? alsoreplyKomoD 9 hours ago | parent | prev | next [\u2013]It's incredibly tempting but too afraid of legal issuesreplyshannifin 6 hours ago | prev | next [\u2013]Digression, story: Years ago I worked in a place that, if you attempted and failed 3 times to login to your account, your account would be locked and you had to see the help desk in person to prove your identity to get it back. And of course somehow this kept happening to me (perhaps a vengeful or stupid coworker?). Fortunately they changed their methods when one week a whole bunch of people had to see the help desk after their accounts were mysteriously locked.replylxe 13 hours ago | prev | next [\u2013]This is perfect for getting rid of scammers.replyteddyh 13 hours ago | parent | next [\u2013]\u201cOh? And, when the last law was down, and the Devil turned round on you \u2013 where would you hide, Roper, the laws all being flat?\u201d\u2014 A Man for All Seasons, Robert Bolt, 1960replybastard_op 13 hours ago | prev | next [\u2013]Sounds like there should be a mass service to close everyone's accounts in their name then. You know, doing them a favor and such.reply1vuio0pswjnm7 11 hours ago | prev | next [\u2013]https://web.archive.org/web/20230717202207if_/https://twitte...replydjbusby 11 hours ago | prev | next [\u2013]Chase bank has a similar issue. Getting confused about business vs personal vs joint and sending the wrong notice to the wrong address.replybarbazoo 13 hours ago | prev | next [\u2013]I can view tweets again without being logged in ?!?replyshmde 13 hours ago | parent | next [\u2013]Yes. But you cannot see replies and authors page. Use https://nitter.net/ for that.replythrowaway742 1 hour ago | root | parent | next [\u2013]Thank you. I didn't know nitter was working again.replyRajT88 8 hours ago | prev | next [\u2013]I am going to use this on the next scammer.replyge96 8 hours ago | prev | next [\u2013]This would be useful for the scam jobsreplyTheCaptain4815 12 hours ago | prev | next [\u2013]Anyone know Zuckerburgs WhatsApp account?replyxuki 8 hours ago | parent | next [\u2013]I know you got downvoted but it's not that hard to find important people's phone number. The VIP is probably careful handing out that number but when it goes into other people's contact they lost control of that. All it takes is a click on a random iOS/Android app and the whole contact list is uploaded to who know wherereplycuteboy19 13 hours ago | prev | next [\u2013]But you can reactivate instantly and it doesn't cause data loss if you don't try anything funny during deactivationreplyjedberg 13 hours ago | parent | next [\u2013]Assuming you notice it was deactivated within the short time span they give you. If you're a casual user it could get really annoying to show up and be deactivated, most likely when you have a fairly urgent need.replyveave 12 hours ago | root | parent | next [\u2013]short time span == 30 days???replyjedberg 11 hours ago | root | parent | next [\u2013]I live in America so I really only need to use WhatsApp when I travel to foreign places so I can contact vendors. That happens maybe once every other year. I'd be pretty upset if I fired up WhatsApp and it didn't work when I really needed to call a vendor.replyurbandw311er 12 hours ago | root | parent | prev | next [\u2013]I\u2019ve been on holidays longer than thatreplydangus 11 hours ago | root | parent | next [\u2013]Must be nicereplyxuki 8 hours ago | root | parent | next [\u2013]Not really, just European.replyDennisP 13 hours ago | parent | prev | next [\u2013]What would constitute \"trying something funny?\"replycuteboy19 16 minutes ago | root | parent | next [\u2013]Uninstalling the app or clearing the data might lead to data loss if backups were not done before deactivation afiakreplystuckkeys 13 hours ago | root | parent | prev | next [\u2013]You forgot to include \u201cyou know, for science\u201d part.replychefandy 13 hours ago | root | parent | prev | next [\u2013]Using your account for anything more humorous than amateur improv comedy, I imagine. Considering how many downvotes most jokes seem to get on HN, I can't imagine that'd be a problem with this crowd.replySohcahtoa82 10 hours ago | parent | prev | next [\u2013]If I got that \"Your account has been deactivated\" e-mail, I'd likely assume it was a phishing attempt.replybreakingcups 13 hours ago | parent | prev | next [\u2013]Then I wonder, what's the point?replycountvonbalzac 13 hours ago | root | parent | next [\u2013]If someone doesn't control your phone number they can't reactivate.replythund 11 hours ago | prev | next [\u2013]Imagine a world (populated by a human species) where this would be the norm\u2026replygodelski 13 hours ago | prev | next [\u2013]Hello, WhatsApp? I'd like to report a stolen phone. Please deactivate the account for ^\\+?\\d{1,3}[-.\\s]?\\(?\\d{1,3}\\)?[-.\\s]?\\d{1,4}[-.\\s]?\\d{1,4}[-.\\s]?\\d{1,9}$k thx byehttps://xkcd.com/327/replymellosouls 13 hours ago | parent | next [\u2013]Inspired the companies house injection attempt discussed herehttps://news.ycombinator.com/item?id=27815396replyploum 13 hours ago | parent | prev | next [\u2013]I don\u2019t know how I should feel about the fact that I did know what xkcd comic would open before I even clicked the link.https://ploum.net/xkcds-law/index.htmlreply0_____0 13 hours ago | root | parent | next [\u2013]Bobby Tables, his arms wide.replyilovecurl 11 hours ago | root | parent | next [\u2013]Shaka. When the tables fell.replyTheSpiceIsLife 11 hours ago | root | parent | prev | next [\u2013]I really appreciated this, thank you.replydbajaj 14 hours ago | prev | next [\u2013]ah, wished it had email forwarding while it was disabledreplyJimtheCoder 13 hours ago | prev [\u2013]So, we all want to make it easier to cancel things.But not too easy...replypmx 13 hours ago | parent [\u2013]I want it to be easy to cancel my own stuff, not easy for someone else to do it for me.replyGuidelines | FAQ | Lists | API | Security | Legal | Apply to YC | ContactSearch:",
    "hn_summary": "- It is possible to deactivate someone's WhatsApp account by simply sending an email.\n- The inconvenience to the deactivated account is minor, as it can be easily reactivated with a single SMS verification code.\n- This feature is intended to quickly lock out spammers, thieves, or hackers, and is not meant for abuse."
  },
  {
    "id": 36758433,
    "timestamp": 1689602908,
    "title": "Bad numbers in the \"gzip beats BERT\" paper?",
    "url": "https://kenschutte.com/gzip-knn-paper/",
    "hn_url": "http://news.ycombinator.com/item?id=36758433",
    "content": "kenschutte.com / gzip-knn-paperBad numbers in the \"gzip beats BERT\" paper?2022-07-17The recent paper,\u201cLow-Resource\u201d Text Classification: A Parameter-Free Classification Method with Compressors by Jiang et al. [link] recently received a lot of attention on twitter.I recently checked out their source code to try to recreate their results and to try out some related ideas.What I found (although I could be mistaken!) is that there appears to be a bug (or at least an unexpected choice) in their kNN code that makes all the accuracy numbers for their method higher than expected. [tldr: it is reporting a top-2 accuracy rather than a kNN(k=2) accuracy].Table 5 from the paper was often included in tweets and shows the gzip method beating all these other neural-network-based methods:I'll explain the details below, but my calculations for these experiments are (first 4 datasets, only the \"Full\" column):KinyarwandaNews KirundiNews DengueFilipino SwahiliNewsin paper 0.891 0.905 0.998 0.927corrected (knn2d) 0.835 0.858 0.999 0.850(Fifth dataset SogouNews is large -- I haven't run it yet)These numbers would significantly change the take-away from these experiments. For example, for KirundiNews, the gzip method went from best-perfoming to worst-performing.kNNTheir method uses a kNN classifier using k=2 (Appendix C says all experiments used k=2).k=2 is a bit of an odd choice for kNN classification. For every test case, you search the training set for the two \"closest\" examples. Looking at the labels of these two, there are only two possibilities,The labels are equal. So, this is clearly your hypothesized label. Note that you would get the same answer for k=1.The labels are different. We have a 1-1 tie that most be broken. There are many ways to do a tie breaker, but one reasonable one is take the label of the closer point. In this case, you get the same answer for k=1.So, going from k=1 to k=2 doesn't add much information to your classifier. But, it can be different depending on the tie-breaking strategy.It is in the case of ties that the source code here is doing something unexpected, shown below.CodeThe issue is in calc_acc method in experiments.py [here].Here is the relevant snippet, with my added comments, and branches dealing with rand==True removed for clarity:# here, sorted_pred_lab[][] has the # labels and counts corresponding# to the top-k samples,# [[label,count],[label,count],...]# grouped-by label and sorted by count.most_label = sorted_pred_lab[0][0]most_count = sorted_pred_lab[0][1]if_right = 0for pair in sorted_pred_lab:  # we loop until we drop below 'most_count', ie  # this for-loop iterates over those classes  # tied for highest count  if pair[1] < most_count:    break  # this says if ANY of those  # in the tied-set are equal to  # the test label,  # it is marked correct (if_right=1)  if pair[0] == label[i]:    if_right = 1    most_label = pair[0]# accumulate results:    pred.append(most_label)correct.append(if_right)    So, if any of the tie-break labels is equal to the test label, it is marked as correct. For k=2, a tie simply means there was one vote for each of two different classes amongst the 2 closest training points. Therefore, the reported accuracies could be considered top-2, meaning that it's marked correct if either of the top two choices is correct (you may have encountered top-k in ImageNet, where top-5 accuracy is often cited).This method takes arbitrary k but note that it doesn't compute top-k for any k. Only in the special case of k=2 do we have that when there is a tie, all the k examples are tied with the max value (1).The calc_acc method has a rand flag that seems to be correct: if rand==True it will correctly break the tie using random.choice. But it seems that this wasn't used for the paper results.Re-calcI wrote a simple implementation with two different tie-breaking strategies [here]:[r] random selection[d] decrement k until you are left with a case without ties.Results          kinnews kirnews filipino swahili table5   0.891  0.905  0.998  0.927  value in papercode    0.891  0.906  1.000  0.927  using npc_gzip repotop2    0.891  0.906  1.000  0.927  top-2knn1r   0.835  0.858  0.999  0.850  kNN,k=1,tie=randomknn1d   0.835  0.858  0.999  0.850  kNN,k=1,tie=decrementknn2r   0.828  0.807  0.851  0.842  kNN,k=2,tie=randomknn3r   0.838  0.791  0.851  0.881  kNN,k=3,tie=randomknn2d   0.835  0.858  0.999  0.850  kNN,k=2,tie=decrementknn3d   0.843  0.794  0.904  0.883  kNN,k=3,tie=decrementSome sanity checks:table5 very close to code (within 0.001 or 0.002): able to recreate numbers from papercode always equals top2. So the official code gives identical results to my completely separate implementation of top-2knn1r == knn1d. There are never ties for k=1knn2d == knn1d. For k=2, ties go to first, so same as using k=1.knn2r < knn2d. For k=2, on a 1-1 tie, random is just taking the further one 50% of the time. So, it makes sence that's worse than just taking the closest.todo:Why is filipino so high (1.0 in one case)?Why is 'table5' slightly different than 'code' in two cases?",
    "summary": "- The recent paper titled \"Low-Resource\" Text Classification: A Parameter-Free Classification Method with Compressors by Jiang et al. has gained attention on Twitter.\n- The author of this blog post found a bug in the kNN code used in the paper, resulting in higher accuracy numbers than expected.\n- The reported accuracies in the paper could be considered as top-2 accuracy, where a tie means either of the top two choices is marked correct.",
    "hn_title": "Bad numbers in the \u201cgzip beats BERT\u201d paper?",
    "original_title": "Bad numbers in the \u201cgzip beats BERT\u201d paper?",
    "score": 358,
    "hn_content": "Hacker News new | past | comments | ask | show | jobs | submit loginBad numbers in the \u201cgzip beats BERT\u201d paper? (kenschutte.com)358 points by ks2048 19 hours ago | hide | past | favorite | 120 commentsAbrahamParangi 19 hours ago | next [\u2013]Probably disappointing to the authors but an excellent rebuttal.This is the sort of mistake that's awfully easy to make in ML. The unfortunate thing about the field is that subtle methodological errors often cause subtle failures rather than catastrophic failures as we're used to in many other branches of engineering or science. You can easily make a system slightly worse or slightly better by contaminating your training set with bad data or accidentally leaking some information about your target and the ML system will take it in stride (but with slightly contaminated results).This result makes sense to me because as much as I would like it to be true, applying existing compression algorithms to ML feels like too much of a \"free lunch\". If there was any special magic happening in compression algorithms we'd use compression algorithms as encoders instead of using transformers as compressors.replygodelski 15 hours ago | parent | next [\u2013]> This is the sort of mistake that's awfully easy to make in ML.It is important to remember this! Mistakes are common because they are easy to make. Science is a noisy process, but there is signal there and what we see here is exactly what peer review is about. I tend to argue that open publications are a better form of peer review than conferences/journals because of exactly this. Peer review is about your peers reviewing your work, less about whatever random and noisy standard a conference/journal puts forward. Remember that this was the way things happened for most of our history and that our modern notion of peer review is very recent (mid 70's). Older journals were more about accomplishing the mission that arxiv accomplishes today: disseminating works.https://mitcommlab.mit.edu/broad/commkit/peer-review-a-histo...[side note] another reason I'd advocate for the abolishment of conferences/journals is that through this we can actively advocate for reproduction papers, failure papers, and many other important aspects since we would not be held to the \"novelty\" criteria (almost everything is incremental). \"Publishing\" is about communicating your work to your peers and having them validate or invalidate your results.[edit] I think conferences are good in the fact that they bring people together and that encourages collaboration. That's great. But I should clarify that I'm specifically talking about using these platforms as a means to judge the validity of works. If a conference system wants to just invite works and the community, then I'm totally cool with that. I do also like journals in theory given that there's a conversation happening between authors and reviewers, but I believe this also could just easily be accomplished through arxiv + github or OpenReview (preferred).replyjsight 14 hours ago | parent | prev | next [\u2013]> The unfortunate thing about the field is that subtle methodological errors often cause subtle failures rather than catastrophic failures as we're used to in many other branches of engineering or science.I've been doing a lot of studying in the ML field lately, and I'm seeing this a lot. It is just another thing that feels like the polar opposite of everything else that I've done as a software engineer.Miss a semicolon? Instant error.Miscalculate some grads on one out of three layers? Every now and then it might even work! But the results will be weird.replygodelski 14 hours ago | root | parent | next [\u2013]How about this one: tune your hyper-parameters based on the results on your test data.This is prolific, even the norm, but it is a form of information leakage. You're passing information about the test dataset to the model. The solution to this is to use 3 partitions: train, validation, test. Validation is for HP tuning (you can do cross-validation btw) and test is a single shot.replyjsight 14 hours ago | root | parent | next [\u2013]Yep, I've been guilty of that one lately. That and solving problems by simply overfitting a neural net to the data in the problem domain.I mean, it works, but the result is less interesting than what I should have done. :)replygodelski 14 hours ago | root | parent | next [\u2013]Definitely. Problem is that doing this helps you get published, not hurts. I think this is why there's often confusion when industry tries to use academic models, as they don't generalize well due to this overfitting. But also, evaluation is fucking hard, and there's just no way around that. Trying to make it easy (i.e. benchmarkism) just adds up creating more noise instead of the intended decrease.replyeyegor 11 hours ago | root | parent | prev | next [\u2013]What about: add more dropout or noise layers and train an ensemble of models. Submit the best one. Is this considered dirty?replyDer_Einzige 9 hours ago | root | parent | prev | next [\u2013]They banged cross validation into our heads in school and then no one in NlP uses it and I just can\u2019t even understand why not.replygodelski 8 hours ago | root | parent | next [\u2013]Not only that, but I've argued with people substantially, where people claim that it isn't information leakage. The other thing I've significantly argued about is random sampling. You wonder why \"random samples\" in generative model papers are so good, especially compared to samples you get? Because a significant number of people believe that as long as you don't hand select individual images it is a \"random sample.\" Like they generate a batch of samples, don't like it, so generate a new batch until they do. That's definitely not a random sample. You're just re-rolling the dice until you get a good outcome. But if you don't do this, and do an actual random sample, reviewers will criticize you on this even if your curated ones are good and all your benchmarks beat others. Ask me how I know...replyiamflimflam1 18 hours ago | parent | prev | next [\u2013]It's true in many experiments. The desire to get the result you want can often overwhelm the need to validate what you are getting.Especially true when the results confirm any pre-existing thinking you may have.replymananaysiempre 15 hours ago | root | parent | next [\u2013]One particular example that I remember from an introductory particle physics class is the History Plots section[1] of the biennial review of experimental data.Knowing these quantities is important, but their particular values largely aren\u2019t; nobody\u2019s funding or career really depended on them being equal to one thing or another. Yet look at all the jumps, where the measurements after the initial very rough ones got stuck in the completely wrong place until the jump to the right value\u2014when it happened\u2014was of a completely implausible magnitude, like four, six, or ten sigma.[1] https://pdg.lbl.gov/2023/reviews/rpp2022-rev-history-plots.p...replygodelski 14 hours ago | root | parent | next [\u2013]What's also good to see here is that the post '90 numbers usually don't even fall within the error bars of the pre '90 numbers. While uncertainty is great, it isn't the end all. I think a lot of people forget how difficult evaluation actually is. Usually we just look at one or two metrics and judge based on that, but such an evaluation is incredibly naive. Metrics and measures are only guides, they do not provide certainty nor targets.replymattsan 17 hours ago | root | parent | prev | next [\u2013]Yep, confirmation bias. Luckily helped with peer review!replycatgary 17 hours ago | root | parent | next [\u2013]Hasn\u2019t this paper made it through peer review?replythomasahle 17 hours ago | root | parent | next [\u2013]Yeah it was published at ACL ( https://aclanthology.org/2023.findings-acl.426/ ) which is one of the most prestigious conferences in NLP. So kinda disappointing.But paper reviewers are usually not supposed to look at the actual source code of the papers, and definitely don't try to reproduce the results. They just read the paper itself, which of course doesn't talk about the error.Not sure what the best solution is, other than having the most \"hyped\" papers double verified by researchers on Twitter.replycatgary 16 hours ago | root | parent | next [\u2013]Yeah, it\u2019s not (entirely) the students\u2019 faults that this slipped through peer review. I don\u2019t envy the whiplash they\u2019re going to experience over the next few weeks.If I was the graduate chair of their department I might schedule a meeting with their supervisor to sort out how this happened.replywesturner 15 hours ago | root | parent | next [\u2013]What about the difference in CPU cost, RAM cost, and GPU training hours, though? What about the comparative Big-E's of the models?Great topic: Model minification and algorithmic omplexityreplythomasahle 8 hours ago | root | parent | next [\u2013]These are good research topics, but then you really need to be comparing to other models in the same class.The only other super cheap model they compare with is FastText, and FastText beat them quite substantially.replyscrum-treats 6 hours ago | root | parent | prev | next [\u2013]It's customary to use OSF (https://osf.io/) on papers this \"groundbreaking,\" as it encourages scientists to validate and replicate the work.It's also weird that at this stage there are not validation checks in place, exactly like those the author performed. There was so much talk of needing this post-\"replication crisis.\"replythomasahle 3 hours ago | root | parent | next [\u2013]I don't think it's \"customary\" to use OSF in machine learning. At least I had never heard of it. It looks great though, I'm glad other fields are figuring this out. Hopefully it will be taken up by the ML field too.replygodelski 15 hours ago | root | parent | prev | next [\u2013]> paper reviewers are usually not supposed to look at the actual source code of the papersWait what? I haven't reviewed for ACL but most conferences don't say \"don't look at the source code.\" They will say that reviewers are not required to look at it (as well as the appendix). But generally it just isn't uploaded. I do always look at the main method when it is there but talking to my peers and advisor, this is very uncommon[0]. My experience is that most reviewers do not spend more than an hour on a work and make an opinion within 15 minutes.> Not sure what the best solution is, other than having the most \"hyped\" papers double verified by researchers on Twitter.I'd say (as a start):1) Get rid of the conference system. A zero-shot (maybe 1-shot if \"rebuttal\" is allowed) zero-sum system is just disastrous, especially at scale. There's high incentives to actually reject works you review for. A conference system has a binary outcome and the purpose is to reject 80% of papers based on a rather noisy metric of \"top tier.\" A journal system is a back and forth where reviewers are trying to improve the paper. The purpose of the reviewers here is to determine if the idea is indeed good, and then if the paper meets the requirements or not and must explicitly state what needs to be changed for acceptance.1.5) An actual rebuttal system could help alleviate some of these issues. Using OpenReview for a conversation between authors and reviewers is critical. A singular 1 page response (the norm) is not adequate to respond to 4 different people who often have low similarities in responses. Reviewers are allowed (though breaks guidelines) to respond in one sentence.2) ACs need to do a better job at validating reviewers. The number of inane and absolutely unacceptable level of reviews I have gotten is astounding (>25%). I've also seen reviewers often break guidelines and have nothing happen. Examples are comments such as those claiming lack of novelty with no explanation or asking authors to compare to concurrent works (I've had this happen for a work that was put out _after_ submission deadlines. Not mine, but here's an example[1] of this being done publicly). If the reviewer is pushed to update their comment then the authors have no ability to respond to their update without the conversation aspect. If there is high variance in response -- not just scores, but what the critiques are about -- then the ACs need to look closer as something is going wrong. We're in a crisis for reviewers but we also have an undisclosed crisis in quality of reviewers. Benchmarkism is on the rise but benchmarks are extremely limiting for evaluation. There's a certain irony given our frequent discussion of Goodhart's Law or Reward Hacking. I'll even make the claim that the quality crisis influences the quantity crisis as I have seen many peers stop reviewing because it isn't worth their time and they aren't getting a fair shot in return. On a personal note, there is a journal I will no longer review for because in-actionable and unreasonable responses, but I also won't submit to them either.3) Either get rid of double-blind, or actually do it. Everything is published on arxiv these days, which in general is great for the community as it allows things to move fast. But with this it is incredibly easy to de-anonymize authors. Though for big labs, they de-anonymize themselves actively[2]. In a very noisy process even a very slight edge becomes a significant edge[3]. These biases can even come unconsciously given that we're all reading arxiv papers constantly and it isn't unlikely that we come across some of the works we end up reviewing (yet to knowingly happen to me fwiw). But certain labs do have keywords that they use that can be identified.I think one of the major problems comes down to this: in a small community we have a certain level of accountability, as we all end up knowing one another through minimal connections. But in a large community there is little to no accountability and what depends on good faith can no longer be trusted. This encourages bad actors, especially when the system is highly competitive (see 1)), and creates bad science/evaluation creep. (e.g. now standard to tune HPs on test data results -- this is information leakage. If you don't, you likely can't compete).======[0] Here's a prominent researcher explicitly saying they don't read the appendix, calling it trash, and a poll showing most people don't look at it https://twitter.com/david_picard/status/1660293648796340226[1] Here's a prominent researcher criticizing a paper for \"not citing his work\". I linked the top response which is telling him the submission date was 2 months prior to his arxiv release. This is someone who published >250 papers vs someone with <50. For added reference, paper 2 (prominent researcher) was _published_ June 26th in TMLR, but they did cite the other work (gotta give credit for that) https://twitter.com/RinonGal/status/1667943354670170118[2] We have 2 scenarios here: either reviewers do not know Chinchila == DeepMind, where I'd argue that they are unfit for reviewing given the prominence of that model or 2) they do know, and thus know this is a DeepMind work, and we have an ethics problem. Neither sound great. https://openreview.net/forum?id=OpzV3lp3IMC&noteId=HXmrWV3ln...[3] The conclusion in this analysis of consistency experiment is that even a small amount of inconsistency leads to a lot of noise given a highly selective standard. Which means that paper acceptance itself is highly stochastic: (2014 experiment) https://inverseprobability.com/talks/notes/the-neurips-exper...[3.1] A shorter version: https://blog.mrtz.org/2014/12/15/the-nips-experiment.html[3.2] A follow-up on the 2014 experiment tdlr: reviewers are good at identifying bad papers, but not good at identifying good papers (i.e. bias to reject): https://arxiv.org/abs/2109.09774[3.3] A follow-up 2021 experiment (consistent with 2014 experiment): https://blog.neurips.cc/2021/12/08/the-neurips-2021-consiste...[3.4] Video form https://www.youtube.com/watch?v=19Q-vMd9bYgreplyYeGoblynQueenne 13 hours ago | root | parent | next [\u2013]I try not to submit to conferences if I can avoid it. It's like you say, reviewers are looking for a reason to reject. I don't understand what makes the difference since it's usually the same people reviewing in both conferences and journals, but somehow journal reviewers do a much better job. Some journals have a fast turnaround even, and still the quality of reviewing is considerably better.My second journal paper got rejected with encouragement to resubmit. Half the reason for that was because the reviewer had, I think, genuinely misunderstood the description of an experiment, so I re-wrote it in painstaking detail. I had a long section where I hammered out a proof of complexity spanning three pages, with four lemmas and a theorem, and the reviewer waded through all that like a hero, and caught errors and made recommendations for improvement. They made a new round of recommendations when I resubmitted. That paper took three rounds of revisions to publish (reject, resubmit, accept with minor revisions) but it got 80% better every time I had to revise it. I wish there was another couple of rounds! It was exhausting, and I bet much more so to the reviewer, but it was 100% worth it.And yeah, I absolutely do my best to review like that myself. Even in conferences, which probably seems really weird to authors. But, hey, be the change you want to see.replygodelski 12 hours ago | root | parent | next [\u2013]Yeah, honestly the only reason I submit to conferences now is because my advisor asks me to. If it was up to me I would submit exclusively to journals or just to arxiv/open review directly. I think I'll do this when I graduate (soon).As for the reason why it happens in conferences, I think it may actually be a different set of reviewers. While journal reviewers are going to be conference reviewers, I don't think the other way around is true. I think conferences tend to just have a larger number of shitty reviewers (as well as more shitty submissions). And as you note, it is quite easy to misunderstand a work, doubly so when you're reading under a time constraint. It just makes for a noisy process, especially when reviewers view their job as to reject (not improve). I just think it is a bad system with a bad premise that can't really be fixed. For conference reviewing, I always try to write what would change my mind and if I think the authors should resubmit to another venue. But even reviewing I don't feel authors get a fair shot at responding. They can't address all my comments while addressing others in a single page.Edit: I saw your bio. I actually have a SOTA work that is rejected (twice). Good performance jump with large parameter drop. But just couldn't tune or run enough datasets because compute limited. Conferences are fun.replythomasahle 8 hours ago | root | parent | prev | next [\u2013]>> paper reviewers are usually not supposed to look at the actual source code of the papers> Wait what? I haven't reviewed for ACL but most conferences don't say \"don't look at the source code.\" They will say that reviewers are not required to look at it (as well as the appendix). But generally it just isn't uploaded.Sorry, I formulated that badly. I meant what you say, that are usually not presented with the source code, and aren't expected to go hunting for it online. If they do anyway, they are going above and beyond.replygodelski 5 hours ago | root | parent | next [\u2013]If they do go hunting for it, then that would be a ethics violation as they break double blind. But it's not like that exists, at least for big labs.replyCJefferson 8 hours ago | root | parent | prev | next [\u2013]In terms of \u201cgetting rid of the conference system\u201d, I would suggest what I see in maths, which is split into two types of talks:* talks about already peer reviewers conference papers.* talks about active research. Here you only submit an extended abstract, and you don\u2019t get to \u201cclaim credit\u201d for giving the talk. People tend to only talk about things where they genuinely want to hear feedback, maybe even new collaborators.replyDer_Einzige 9 hours ago | root | parent | prev | next [\u2013]To be clear, ACL is the top conference in NlPreplyKarellen 17 hours ago | root | parent | prev | next [\u2013]I suspect GP commenter meant \"replication study\" rather than \"peer review\".;-)(Peer review doesn't check if your data is correct. They check your data collection methods make sense given the hypothesis you're testing, and that your conclusions are supported by the data you collected.)replyachileas 11 hours ago | parent | prev | next [\u2013]Having worked in other sciences (neuroscience for me), I\u2019m not sure what catastrophic obvious errors you\u2019re used to seeing. The vast majority IME are like this, except with even longer feedback loops (on the order of several months).replyTX81Z 13 hours ago | parent | prev | next [\u2013]Academic research code is largely dogshit written as quickly as possible by amateurs, barely tested whatsoever, and the primary intended output of all such code is accumulating paper citations.A world with half as many scientific papers and twice as much care would produce far more value but the whole enterprise is hopelessly gamified.replyBSEdlMMldESB 16 hours ago | parent | prev | next [\u2013]now shift fields such that the subtle methodological errors don't come to light in 20 years.which field are you on now? economics!? haahhareplyks2048 19 hours ago | prev | next [\u2013]Hi, that's my blog post. I'm pretty sure about what I wrote here, but may need the authors to chime-in in case I am missing something. I just submited an issue on github, https://github.com/bazingagin/npc_gzip/issues/3replyginbazinga 2 hours ago | parent | next [\u2013]Hi, I'm the first author of the paper and I read your blog post. The reason I chose k=2 is because it's recommended to use n^{1/2} and I wanted to pick a k that's compatible with 5-shot setting. But you are right this is a bit odd. As I mentioned in both the paper and the twitter, different values of k will affect the result and I reported the _max_ result we can get so it does mean an ideal situation when the guess is always right. I also use this strategy for W2V and SentBERT. But it doesn't make the result top2 accuracy. As far as I know, top2 accuracy means in the top2 predicted classes, either one is correct, we score. However, as you mentioned, in knn when k=2, there is a situation when the 2 nearest neighbours point to the same class - we are missing another class candidate if reporting top2 accuracy. But I would love to add results for different strategies and different k values when I upload newest version to arxiv when I have time. The strategy of \"decrement\" you mentioned in the blog is really nice and I would love to add it to the repo if you want. I apologize for the short and late reply; I haven't checked the repo yet. I'm preparing for tomorrow's thesis defence and will reply & resolve the issue when I finish.replyeyegor 18 hours ago | parent | prev | next [\u2013]You may want to consider adding a note to the top. Seems like a lot of people are lazily skimming/reading the headline and see it as \"gzip paper full of beans, gzip approach sucks\" when really I see this as \"gzip approach not better than dnn models but mostly competes and much cheaper to run\". The paper is still solid.replymarcinzm 17 hours ago | root | parent | next [\u2013]>gzip approach not better than dnn models but mostly competes and much cheaper to runDoes it? It looks to do worse than FastText in all benchmarks and kNN is not a cheap algorithm to run so it might actually be slower than FastText.edit: It looks like FastText takes 5 seconds to train on the Yahoo Answers data set while the gzip approach took them 6 days. So definitely not faster.replyeyegor 17 hours ago | root | parent | next [\u2013]I'm not familiar with most of these models in detail, but training time is generally less interesting than inference time to me. I don't care if it takes a month to train on $10k of gpu rentals if it can be deployed and run on a raspberry pi. I should definitely look into fasttext though.replyamluto 16 hours ago | root | parent | next [\u2013]As described in the paper, it didn't look like the gzip classifier trained at all. Inference involved reading the entire training set.One could surely speed this up by preprocessing the training set and snapshotting the resulting gzip state, but that wouldn't affect the asymptotic complexity. In effect, the number of parameters is effectively equal to the size of the entire training set. (Of course, lots of fancy models scale roughly like this, too, so this isn't necessarily a loss.)replyhuac 16 hours ago | root | parent | next [\u2013]The gzip approach is much slower at inference time because you need to compute the gzip representation of the concatenated strings (query + target). Intuitively, this should be significantly more than a dot product of two embedding vectors.replyamluto 15 hours ago | root | parent | next [\u2013]The latter depends very strongly on how much computation is needed to compute those embedding vectors.If you run a GPT-3.5-sized mode to compute that embedding (which would be a bit absurd, but if you really want GPT-3.5-quality classification, you may well be doing something like this), you're looking through quite a few tens of billions of parameters and doing a correspondingly large number of FLOPs, which could be just as expensive as running gzip over your whole (small, private) training set.replyhuac 15 hours ago | root | parent | next [\u2013]no, because the compute intensity scales with the number of classes which you wish to classify to. if you have n classes, you need to do n gzip compressions at inference time. in the embedding world, you only call the embedding model once on insert, and only need to dot product at inference time.the same logic extends to using a self-hosted embedding model, which tend to be as good as Ada on most benchmarks, and yes, can be finetuned over your private data.replymarcinzm 15 hours ago | root | parent | prev | next [\u2013]>The latter depends very strongly on how much computation is needed to compute those embedding vectors.Sure but the gzip metrics are worse than FastText which computes the embeddings in essentially no time. Tokenize, lookup embeddings by token id, and then do some averaging. So compared to that the gzip approach is very slow.replytensor 17 hours ago | root | parent | prev | next [\u2013]FastText isn't a LLM, it's a token embedding model with a simple classifier on top.replymarcinzm 16 hours ago | root | parent | next [\u2013]Sure but it's existence means the statement is really \"gzip approach not better than dnn models, and doesn't compete or be cheaper to run than previous models like FastText.\" That's not a very meaningful value statement for the approach (although why gzip is even half-decent might be a very interesting research question).replytensor 17 hours ago | root | parent | prev | next [\u2013]I honestly don't know why anyone would use this gzip approach in production. If you want to do text classification, really the two options you should consider are a best in class linear model like confidence weighted linear classification by Crammer (https://www.cs.jhu.edu/~mdredze/publications/icml_variance.p...) or a much more expensive LLMs.replyeyegor 11 hours ago | root | parent | next [\u2013]Do you happen to be familiar with audio classification? There's been a ton of research on text classification and prediction but not many good papers I've seen for general audio classification. I'm talking more feature extraction, not speech recognition. There are a lot of speech recognition papers. So far I've been stuck on fft - image processing pipeline but I haven't gotten great results in real world tests, only on nice teat datasets.Personally I don't have much experience working beyond mlp/rnn/lstm/cnn models.replyesafak 17 hours ago | root | parent | prev | next [\u2013]Don't look at it as a suggestion to use gzip in production, but an invitation to reconsider the unassailable superiority of BERT over simpler, tailored solutions.replytensor 16 hours ago | root | parent | next [\u2013]I don't think anyone actually doing NLP research has thought that BERT is always better than simpler methods. Linear classifiers with ngrams, or even better, large margin linear classifiers, are well known to be competitive with things like BERT on a variety of tasks, with orders of magnitude better runtime.In contrast, this gzip technique is considered a cute application of information theory, but even in academia is rarely included in studies because there are simpler and better techniques for NLP.Yes, if you are chasing the ultimate accuracy, then using a LLM (not necessarily BERT either) is going to be the best. But for a practical system trading some accuracy for vastly improved runtime is usually a very good trade-off. And again, it depends on your domain. Topic classification, stick with a linear model. Sentiment analysis? Ok, here a LLM actually gives substantially better results so it's worth the extra cost if sentiment is crucial to your application.I personally like the CW algorithm I mentioned because it's relatively easy to implement and has excellent qualities. But if I were a dev looking for a ready to go already implemented production system I'd go for vowpal wabbit and move up to a LLM if I'm not getting the accuracy I need for my application.replyempiko 16 hours ago | root | parent | prev | next [\u2013]Is it really an invitation? The paper shows that the current models are worse for some marginalized languages that are used as OOD datasets. I am not really that surprised that the modelals don't speak those and I don't know anybody who would use BERT like thatreplymarcinzm 16 hours ago | root | parent | prev | next [\u2013]But FastText (2015) already exists and beats this gzip approach on all criteria. So the invitation has already existed before BERT (2018) and continues to exist.replylight_hue_1 17 hours ago | root | parent | prev | next [\u2013]If this story is true the paper is not solid.Claims in the abstract and claim 3 in the paper, as well as much of the publicity around the paper is just wrong.It takes gzip from being great out of domain to being middling at best. It goes from something really interesting to a \"meh\" model. The main part that was intellectually interesting is how robust gzip is out of domain, if that's gone, there isn't much here.If I was the reviewer for this paper, this would take the paper from an accept to a \"submit to a workshop\".Also, kNN methods are slow O(n^2).replyivirshup 17 hours ago | root | parent | next [\u2013]kNN methods are broadly not O(n^2)[1], especially in practice where approximate methods are used.[1]: https://en.wikipedia.org/wiki/Nearest_neighbor_searchreplyhuac 16 hours ago | root | parent | next [\u2013]how would you build an index over the gzip encoded data? seems quite different from building indices over vector embeddings.replylalaland1125 19 hours ago | parent | prev | next [\u2013]Just wanted to say, thanks for your work debugging this.You have probably saved other researchers an unfathomable amount of timereplysyats 18 hours ago | parent | prev | next [\u2013]Thanks for the replication, this is important.One question, did you try to replicate the other result table (Table 3)?If I understand correctly, top-2 accuracy would be 1 if you have only 2 classes, but it will differ from \"normal\" accuracy less and less as the number of classes increases (on average). So this shouldn't change the results for table 3 thaaat much as the datasets have large amounts of classes (see table 1).In any case, top-2 accuracy of 0.685 for the 20-newsgroups dataset is pretty neat for a method that doesn't even consider characters as characters[1], let alone tokens, n-grams, embeddings and all the nice stuff that those of use working on NLP have been devoting years to.[1] In my understanding of gzip, it considers only bit sequences, which are not necessarily aligned with words (aka. bytes).replyks2048 18 hours ago | root | parent | next [\u2013]I haven't yet replicated Table 3 because most of those datasets are much larger and it will take awhile to run (they said the YahooAnswers database took them 6 days).Also, I have only tried the \"gzip\" row because that is all that is in the github repo they referenced.Yeah, you're right, the more classes there are, probably the lower the effect this will have.replyp1esk 18 hours ago | parent | prev | next [\u2013]Did you try contacting the authors before you went public with your discovery?reply_b 17 hours ago | root | parent | next [\u2013]We're adult enough to have discussions like this in public. They are healthy to have. People make mistakes. Kudos to the original authors for releasing the source code so people could inspect and replicate their results.replyreturningfory2 15 hours ago | root | parent | next [\u2013]I agree, and just want to add: nowadays it's super common for researchers to widely publicize their new work on social media. The blog post here even mentions \"Table 5 from the paper was often included in tweets\".In this context of sharing your results very publicly, it seems only fair that rebuttals would be very public, too. Otherwise researchers would be highly incentivized to very publicly publish weak results because they would get a lot of positive publicity when they share the results, but not much negative publicity when the weaknesses are found and shared.replyjarym 17 hours ago | root | parent | prev | next [\u2013]It isn't a security issue and doesn't warrant responsible disclosure so why would op be expected to?replyks2048 14 hours ago | root | parent | prev | next [\u2013]I did not, but I see why that could be a better approach. I mainly am trying to be more open with little side projects I do, so wanting to start blogging what I'm working on. Also, this paper was beiung widely discussed so thought this would be one more entry in that.replycs702 18 hours ago | parent | prev | next [\u2013]Whoa, I just read your post and saw this:> tldr: it is reporting a top-2 accuracy rather than a kNN(k=2) accuracyIf the accuracy figures shown for other models are top-1, that's a pretty significant mistake, hopefully an innocent one.Thank you for doing this and sharing your findings!---Previous discussion on HN: https://news.ycombinator.com/item?id=36707193replyDebtDeflation 18 hours ago | root | parent | next [\u2013]Also:>k=2 is a bit of an odd choice for kNN classificationThat's an understatement. Choosing an even number for any sort of voting algorithm doesn't make much sense, choosing 2 specifically probably makes the least sense of all.replyspi 16 hours ago | root | parent | next [\u2013]Yeah that is a big red flag - as the OP mentions, there is basically no way of making k=2 statistically different from k=1, that's why nobody uses it.I suppose the authors just tried many different k and selected k=2 because it performed surprisingly well (likely due to the bug the OP found out). But if the results were significantly better than k=1 or k=3, it's a bit weird the authors never double checked why that was the case. I guess it can be one of those things you settle on early in the overall process with a few experiments, and just take for granted afterwards, never checking it again, but still, it sounds like something that should pop out at some point while writing the paper...?replyks2048 14 hours ago | root | parent | prev | next [\u2013]Yeah, I think this is one part where a reviewer or advisor could have focused questions.There is a sentence in Appendix C: \"We set k = 2 for all the methods on all the datasets and we report the maximum possible accuracy getting from the experiments for each method.\"I'm not sure what the second part of that means exactly.reply1024core 16 hours ago | root | parent | prev | next [\u2013]True. You want to always use an odd number so there are no ties.I'm guessing they were trying a parameter sweep, and found that (thanks to the bug) they got the best results for K=2.This too is problematic in its own sense.replyks2048 13 hours ago | root | parent | next [\u2013]Yes, agreed. One small point: for the multi-class case (more than just two classes), which include all the datasets here, you can still get ties for odd k. e.g. k=3, you can get 1 vote each for 3 different classes, etc.reply1024core 12 hours ago | root | parent | next [\u2013]Multi-class is trickier. Maybe we can break down an N-class problem into N binary-classification problems?replysoftwaredoug 15 hours ago | prev | next [\u2013]When we did search relevance experimentation at Shopify we made lots of mistakes. I can empathize with the authors. I\u2019ve had a lot of my own public screw ups.At the end of my time at Shopify I learned good science requires good software engineering. It\u2019s really easy to make mistakes at so many places in the stack.We spent a lot of time on creating rigorous, heavily tested and high quality software for our experiments so we could trust our numbers and reproduce each others experiments. We tried to discourage one-off evaluation methods, but if we created a new one, to add it to our suite and test the metric to understand what it meant.It seems obvious, but sadly not as common as I wish it were in my experience with this kind of experimentation. Companies want velocity, and thinking deeply statistically, and building internal tools, is not in the interest of most higher ups.replythomasahle 8 hours ago | parent | next [\u2013]> At the end of my time at Shopify I learned good science requires good software engineering.This is a positive side of industry research. First, you tend to have more software engineering expertise available, and secondly you have more of an insentive to not exaggerate your claims, as if you say it works, you'll be expected to put it into production.replychaxor 19 hours ago | prev | next [\u2013]I appreciate that this blog post was made.This is like so, so many little projects that I do (even specifically showing problems in papers like this) that never see the light of day. I usually just make a small noise, and then it sits on my hard drive and that's it.So thank you for putting this out there.replythomasahle 17 hours ago | parent | next [\u2013]I've started using Twitter as a \"lower effort blogging\" platform. After I spend a day on something like this, I'm usually too tired to actually write a blog post about it, which feels like a waste. But then writing a small Twitter thread is usually within my capabilities.replyusgroup 15 hours ago | prev | next [\u2013]It wasn't obvious to me why the authors chose kNN for the classifier. Since they produce a distance matrix, they could have used multi-dimensional scaling to convert the matrix to factors, and then used a tree algorithm such as xgboost which would likely make use of more information than kNN and produce significantly better results. They could have also used a PAQ compression algorithm which are much better than the LZ compressors -- all of which could have significantly improved the results and possibly delivered on their original conclusions.what i liked about the subject paper is that the compression algorithm is abstracted away and it led me to consider what else one could do with compression via the p(x) ~ K^(-|x|) relationship, where K is the alphabet size and |x| is the length of the string x, and assuming optimal coding.For example it occurred to me that one could do traditional classification by packing the factors for each response into separate documents and then proceeding as the paper does to classify which document best compresses the next sample in order to determine its class: a sort of supervised classification using compression algorithms. The closer the compressor is to an optimal code for the dataset, the better it will work.Schemes for sequence prediction are equally straightforward to implement.I found it to be a pleasant surprise.replyskrebbel 19 hours ago | prev | next [\u2013]Can anyone explain to me how a compression algorithm can beat an LLM at anything? Isn\u2019t that like saying horses are better than graffiti?I\u2019m sure the answer is in there somewhere but I\u2019m not well versed in AI and I simply can\u2019t figure it out.replyGuB-42 18 hours ago | parent | next [\u2013]Generally, compression = model + entropy coding.The model's job is to predict what comes next. The entropy coder's job is to encode the difference between the prediction and what actually comes next so that the most likely outcome uses as few bits as possible. The more accurate the model is, the less the difference between reality and prediction, the less bits the entropy coder needs and the better the compression.Simple compression algorithms have simple models, like \"if I see the same byte 10 times, the 11th is likely to be the same\". But you can also use a LLM as your model, as completing text with the most likely word is what LLMs do.Here they did the opposite. Instead of using a model for compression, by using a few tricks, they used a compression algorithm as a model: the most likely outcome is when the compression algorithm uses less bits to encode the result. And the original authors have shown that, in some tasks, the simple model that can be extracted out of gzip beats much more complex LLMs.replyhoosieree 18 hours ago | root | parent | next [\u2013]I almost feel like compression and embeddings are duals of each other, but I can't quite articulate it.Embeddings use fixed-size vectors to minimize the dot product between vectors of similar inputs. Compressors use a variable-length encoding to minimize the overall stored size.replynaijaboiler 10 hours ago | root | parent | next [\u2013]they are in a way. both encode representation of larger amounts of information on a smaller footprint.replyedwintorok 2 hours ago | root | parent | prev | next [\u2013]Why gzip, and not a more complex compression algorithm like 'xz'? Or if you want it to be fast then 'zstd' or 'lz4'. Gzip is an odd choice: is it neither the highest compression ratio, nor the fastest.replycontravariant 17 hours ago | root | parent | prev | next [\u2013]Generally compression algorithm try to give structured data a distribution more similar to random data.If any byte sequence is a correct file (unlikely, but mostly because compression algorithms try to be robust against corruption), then this is easy to reverse, you just generate a random sequence of bytes and then decompress it.Basically you can turn a compression algorithm into a probability distribution by inserting random bytes wherever the decompression algorithm tries to read one, but sometimes not all bytes are allowed.You can then reason about this probability distribution and see what it's properties are. Typically something with a probability of 'p' will require -log(p)/log(2) bits.replyawegio 18 hours ago | parent | prev | next [\u2013]A language model estimates the probability of a sequence of words P(w_1, ..., w_n) or equivalently P(word | context).For compression, word sequences that have higher probability should be encoded with shorter codes, so there is a direct relationship. A well known method to construct such codes based on probabilities is Huffman coding.This works whether you use a statistical language model using word frequencies or an LLM to estimate probabilities. The better your language model (lower perplexity) the shorter the compressed output will be.Conversely, you can probably argue that a compression algorithm implicitly defines a language model by the code lengths, e.g., it assumes duplicate strings are more likely than random noise.replyozr 19 hours ago | parent | prev | next [\u2013]The intuition about how the gzip method works goes like so:If you compress `ABC`, it will be X bytes. If you then compress `ABCABC`, it will not take 2x bytes. The more similar the two strings that you concatenate, the less bytes it will take. `ABCABD` will take more than `ABCABC`, but less than `ABCXYZ`.BERT is, by todays standards, a very small LLM, which we know has weaker performance than the billion-param scale models most of us are interacting with today.replyjabbany 19 hours ago | root | parent | next [\u2013]> very small LLMHeh. So does that make it a MLM (medium)?I've always found it funny that we've settled on a term for a class of models that has a size claim... Especially given how fast things are evolving...replyoptimalsolver 18 hours ago | parent | prev | next [\u2013]Compression is equivalent to intelligence:https://mattmahoney.net/dc/rationale.htmlreplyks2048 19 hours ago | parent | prev | next [\u2013]It's a very limited task: take a document and classify it into one of (for example) 10 or so categories. Things like detecting certain words can do pretty well in some cases. Things that compress well have the occurrence of common substrings.replyIKantRead 18 hours ago | parent | prev | next [\u2013]LLMs and essentially all neural networks can be viewed as learning compression algorithms where the behavior of the compression algorithm is learned and subject to potential constraints beyond mere file reconstruction.Highly recommend reading Ted Chiang's \"ChatGPT Is a Blurry JPEG of the Web\"[0] to get a better sense of this.Keeping this fact in your mental model neural networks can also go a long way to demystify them.0. https://www.newyorker.com/tech/annals-of-technology/chatgpt-...replyFeepingCreature 17 hours ago | root | parent | next [\u2013](The human brain is also, in part, a blurry JPEG of the world.)replyIKantRead 14 hours ago | root | parent | next [\u2013]We currently have no reason to believe this, and information we do have seems to suggest that is very unlikely to be the case. I'm also guessing from my username you can infer that I don't think we even know enough to concretely say what is this \"world\" you are referencing.replyog_kalu 13 hours ago | root | parent | next [\u2013]I don't know what exactly blurry jpeg means to you but we have every reason to believe we operate on shortcuts of reality, not reality. Nearly all your brain does with sense data is warp it to confirm to internal predictions in numerous ways.Memories are always part fabrications. You can't return to previous mental states (you only think you do) and we have no real clue what really informs decisions i.e preferences shape choices just as much as choices shape preferences.Your brain will happily fabricate rationals you sincerely believe for decision that couldn't possibly be true i.e split brain experimentsreplyFeepingCreature 8 hours ago | root | parent | prev | next [\u2013]I for one massively compress my experience. I remember things on autocomplete. I have memories where different time periods are mixed together: my recollection of a room will have furniture in it that was only added later, for instance.replykachnuv_ocasek 19 hours ago | parent | prev | next [\u2013]One way to interpret/understand language models is as quite involved compression algorithms.replystuartaxelowen 17 hours ago | parent | prev | next [\u2013]Many other replies here are wrong - the primary reason is that the LLMs were used on completely out of distribution data (e.g. trained on English, evaluated on completely different language that shared some characters). The points about compression's relatedness to understanding are valid, but they are not the primary reason for LLMs underperforming relative to naive compression.replyajtulloch 18 hours ago | parent | prev | next [\u2013]https://www.inference.org.uk/itprnn/book.pdf is a classic text on this connection.replyrefulgentis 19 hours ago | parent | prev | next [\u2013]Other reply is great, more in-depth on details from me here: https://news.ycombinator.com/item?id=36758681Plain english TL;DR:- if you limit your task to binning snippets of text- and the snippets are very well-defined (ex. code vs. Filipino text)- the snippets _bytes_ could be compared and score well, no text understanding needed- size delta of a GZIP after adding one more sentence acts as an ersatz way to compare sets of bytes to eachother (ex. you can imagine a GZIP containing 0xFFABCDEF that has 0xFFABCDEF added to it will have a size delta of 0)replyfsmv 19 hours ago | root | parent | next [\u2013]Did you read the recent Douglas Hofstadter article or do you just always use the word ersatz?replyrefulgentis 18 hours ago | root | parent | next [\u2013]I was homeschooled till 12 and mostly left to my own devices as long as it was reading - I believe that has caused a lifelong issue where I sound like a tryhard unintentionally :( (TL;Dr I use it but IDK when, didn't see hofstader article but now I'm looking forward to it)replymatthewdgreen 18 hours ago | root | parent | next [\u2013]The word ersatz is great, and conveys the notion that the replacement is simpler and possibly inferior when compared across all features. \u201cSubstitute\u201d doesn\u2019t cut it. Human language (ironically w.r.t. TFA) isn\u2019t a collection of redundant symbols, the synonyms carry all sorts of useful nuance.replytonyg 15 hours ago | root | parent | prev | next [\u2013]It doesn't sound tryhard; it sounds literate.replystavros 18 hours ago | root | parent | prev | next [\u2013]You can substitute the word \"substitute\" as an ersatz \"ersatz\".replyrefulgentis 18 hours ago | root | parent | next [\u2013]It's honestly weird and annoying and I'd give it up in a second.There's two issues:- I don't have an ear for what's simple vocabulary versus tryhard, I go into a mad loop when I try- even if I actively notice it, substitution can seem very far away from intent. Simple wouldn't have occurred to me - I wanted to say something more akin to sloppy / stunt and ersatz is much closer to \"hacky\" in meaning than simple. Think MacGyver.But I should do the exercise of at least scanning for words more often and aim for wider audience - I would have known ersatz was an outlier and I shouldn't feel it's condescending or diluting meaning, it's broadening the audience who can parse itreplyinimino 12 hours ago | root | parent | next [\u2013]Why would you apologize for your vocabulary and try to sound like someone less well-read than you are? Just get over it and be yourself.replystavros 18 hours ago | root | parent | prev | next [\u2013]Eh, it's fine, it doesn't sound tryhard to me, just a bit hard to read.replybjord 19 hours ago | prev | next [\u2013]If this is true, I'm looking forward to seeing how all the people who made grandiose statements about that paper now quietly scrub them.LinkedIn and Twitter influencers, I'm looking at you in particular.If it's not true, I guess I'll be the one looking stupid\u2014I only skimmed the article.replyJimmc414 9 hours ago | prev | next [\u2013]I had some difficulty reproducing results that were better than word2vec embeddings + cosine similarity. See my comment on the announcement thread here. https://news.ycombinator.com/item?id=36706078replyfnands 19 hours ago | prev | next [\u2013]Just a note: your blog seems to be stuck in 2022. Date of post is 17 July 2022replyks2048 19 hours ago | parent | next [\u2013]Thanks, should be fixed in a minute. That's what I get for writing dates by hand...replyantonoo 14 hours ago | prev | next [\u2013]My take on this:https://twitter.com/antonosika/status/1679423272541192196?s=...Regardless, great work digging into the code, and great work by authors publishing the code.replysnowstormsun 17 hours ago | prev | next [\u2013]So, couldn't it be that the authors of the paper ran the model with a random tie break and got lucky? This blog post seems to assume they had the \"rand\" flag deactivated. Please correct me if I am wrong.replymarcinzm 8 hours ago | parent | next [\u2013]The code of the paper is all on Github so you can verify that line of thinking if you want to.replyexpensive_news 17 hours ago | parent | prev | next [\u2013]From what I understand in the post getting lucky enough to see that big of a change in this situation would be like getting 1000 head flips in a row. It\u2019s not luck you could expect to ever get.replysnowstormsun 14 hours ago | root | parent | next [\u2013]I seereplyabecedarius 16 hours ago | prev | next [\u2013]One thing many people are missing: the simple gzip-for-text-classification hack is not the contribution of this paper. (They reference the standard intro AI textbook for that hack.) The contribution is to use the gzip numbers together with k-nearest-neighbors.In section 6.2 they compare gzip-distance+kNN vs. gzip-distance on its own on four problems: it was better on two, and worse on two others.Another bit of background I guess is worth saying: language models are pretrained with a compression objective. That is, the loss function in pretraining is the cross entropy of the input text, which means \"minimize the compressed length of this input if you fed it to this LM driving an arithmetic coder\".replyrefulgentis 19 hours ago | prev | next [\u2013]Really happy to see this: KNN + classification task + doing classification that's based on pure text similarity is a recipe for stacked results.Schaudenfreude responses to this paper misunderstand that the natural language stuff is crucially important for embeddings: sure, phrases that share words will classify well and GZIP well, so GZIP can be used as ersatz classification.The miracle of BERT / embeddings is _not_ having to share words: for instance, \"what is my safe passcode?\" has a strong match with \"my lockbox pin is 1234\", but not \"my jewelry is stored safely in the safe\".This is also an important thing to consider with LLMs: people are using embeddings intended to do text similarity, whereas you want to use an SBERT model: that is trained to correlate a question to a document that will answer it.https://www.sbert.net/ for the full rabbit hole.Previously: Should you use OpenAI's embeddings? Probably not, and here's why. https://iamnotarobot.substack.com/p/should-you-use-openais-e....HN discussion: https://news.ycombinator.com/item?id=35377935replyjabbany 19 hours ago | parent | next [\u2013]> The miracle of BERT / embeddings is _not_ having to share wordsTo be fair, the original task is specifically chosen where something like knn+compression has a chance of being good: i.e. out of domain + low resource.Under these conditions the training inputs could be too sparse for a highly parameterized model to learn good embeddings from.In traditional in domain + big data classification settings there's no chance that non-parametric methods like compression would beat a learned representation.replyadamsmith143 18 hours ago | prev | next [\u2013]Whats disturbing to me if this is true is the number of \"top voices\" in ML on ML-Twitter were head over heals with this paper. How many of them actually read it at all?replyrenewiltord 19 hours ago | prev | next [\u2013]Great job replicating and fixing. So easy to accidentally create results that are statistical artifacts.replyAtNightWeCode 16 hours ago | prev | next [\u2013]In current times *zip mostly cripples things like the web and Docker. To find out it is the best at something in 2023 is not very likely.Nice find btw.replyputtycat 18 hours ago | prev | next [\u2013]This is interesting, however, why not first discuss with authors directly to make sure that you're right?replypinko 18 hours ago | parent | next [\u2013]They did. See: https://github.com/bazingagin/npc_gzip/issues/3replyDayshine 18 hours ago | root | parent | next [\u2013]One hour ago?replyks2048 14 hours ago | parent | prev | next [\u2013]Yes, that could be a better idea. I am mainly trying something new to work more \"in the open\" and write blogs about things as a do them. I could be wrong and that would be pretty embarrassing for me. I just published the code I used to double-check things, now linked on the page near the bottom.replynetdur 18 hours ago | prev [\u2013]I have hacked javascript port https://gist.github.com/netdur/a777f75fb70e0abc19c407c2ff7f9...and it seems to work!!! regardlessBest matched answer for 'How do I start a new project?' is 'To create a new project, go to the dashboard and click on 'New Project'. Then, fill out the details and click 'Save'.'Best matched answer for 'How can I delegate tasks to others in my team?' is 'To invite team members to your project, open the project and click on 'Invite Members'. Enter their email addresses and click 'Send Invites'.'Best matched answer for 'What do I do when I finish a task?' is 'When a task is completed, it should be marked as 'Complete'. It will then be moved to the 'Completed Tasks' section.'replyGuidelines | FAQ | Lists | API | Security | Legal | Apply to YC | ContactSearch:",
    "hn_summary": "- The blog post highlights an error in the \"gzip beats BERT\" paper, bringing into question the validity of the results.\n- The mistake involves using top-2 accuracy instead of k-nearest-neighbors (kNN) accuracy, which significantly affects the conclusions.\n- The use of compression algorithms for text classification is interesting, but further investigation is needed to determine their true efficacy."
  },
  {
    "id": 36765479,
    "timestamp": 1689636135,
    "title": "Never waste a midlife crisis",
    "url": "https://austinkleon.com/2023/07/10/never-waste-a-midlife-crisis/",
    "hn_url": "http://news.ycombinator.com/item?id=36765479",
    "content": "Never waste your midlife crisisMonday, July 10, 2023I turned 40 last month and spent three weeks reading Don Quixote, so the mid-life crisis has been on my brain.\u201cNever waste your midlife crisis.\u201dThat\u2019s advice I heard while listening to a podcast interview with John Higgs, author of William Blake vs. The World. (One of my favorite reads of 2022.)Higgs was saying that the artists he admires are people like David Lynch, \u201cPeople who you wouldn\u2019t think there\u2019s an obvious place for them in the world, but they just do their stuff regardless, and a place sort of builds around them.\u201dHe continues:There\u2019s a concept in ecology of \u2018niche creation.\u2019 And the idea is: it\u2019s not the case that a species will sort of come along and go, \u2018oh, I could do well here, there\u2019s lots of food,\u2019 and things like that. A species comes along and just does his thing, and by acting in the world, he sort of creates the very environment he needs to survive.It was when I made the decision to attempt to become a full-time writer \u2014 knowing full well the absurdity of it given all the business models of writing \u2014 there was a sort of act of faith that if I just did it, people who read my books would start to appear. And slowly over time, I\u2019d build people who would go, \u2018Oh, that guy\u2019s interesting, I\u2019ll read his next book.\u2019 Just enough to support me.You sort of create the niche that need. It\u2019s not like the world was going, \u2018Oh, there\u2019s a real need for books by John Higgs, where are they?\u2019 But if you do them, the world sort of reacts around them.\u201cIt\u2019s always on an edge of never working out properly,\u201d he admits, but it\u2019s working so far, and it all started when he turned 40 and made the decision to go for it:You should never waste your midlife crisis. You can do great things with a midlife crisis. If you just waste it on like a car, it\u2019s just a lack of imagination. Mine was the decision to write books and attempt to make a living there.The options seemed to be: If I went for it, I\u2019d be penniless, and if I didn\u2019t go for it, I\u2019d be bitter. I\u2019d be bitter going forward. Penniless certainly beats bitter. So I made the decision. And that was ten years ago! And I\u2019m still going.Loved this. Never waste your midlife crisis.(I\u2019m currently listening to his book Love and Let Die: James Bond, The Beatles, and the British Psyche while playing Zelda. He points out that James Bond was basically Ian Fleming\u2019s mid-life crisis.)Filed Under: MiscellanyTagged: aging, don quixote, James bond, John higgs, mid-life crisis, midlife crisis",
    "summary": "- The author shares advice about not wasting one's midlife crisis and using it as an opportunity to pursue their passions and dreams.\n- The concept of \"niche creation\" is discussed, where individuals create their own space and environment by doing what they love and building a following around it.\n- The author reflects on their own decision to become a full-time writer during their midlife crisis and how taking that leap of faith has worked out for them.",
    "hn_title": "Never waste a midlife crisis",
    "original_title": "Never waste a midlife crisis",
    "score": 306,
    "hn_content": "- The post discusses the concept of a midlife crisis, particularly from the perspective of individuals who have experienced work-related burnout.\n- Some advice offered includes being prepared for the slow pace of a midlife crisis, embracing personal growth and change, and seeking professional help for mental health.\n- The comment section includes discussions about panic attacks, the symptoms of a midlife crisis, and different perspectives on the appropriate age for experiencing a midlife crisis.\n- The post stands out because it touches on a common experience, the midlife crisis, and provides personal insights and advice related to navigating this phase of life.\n- Readers interested in personal development and understanding the challenges faced during a midlife crisis may find this post engaging and relatable.- San Francisco is known for its difficulties in finding a suitable romantic partner, with a higher ratio of men to women and a trend towards polyamory.\n- The concept of a midlife crisis is not limited to secular or modern individuals, as religious individuals can also experience feelings of unfulfillment and the need for change.\n- The idea that everything has a cost and the desire for ambitious goals can be driven by deep-rooted self-esteem issues and feelings of inadequacy.\n- The midlife crisis can manifest in different ways for different people and is often triggered by a significant life change or the realization that one's life may not be as fulfilling as desired.\n- The pursuit of outside validation and societal expectations can contribute to feelings of dissatisfaction and the need for change.\n- It's important to recognize the individual nature of a midlife crisis and not make assumptions about others' experiences.\n- Taking steps to explore personal interests, passions, and creativity can help alleviate feelings of stagnation and unfulfillment.",
    "hn_summary": "- The post discusses the concept of a midlife crisis and offers advice for navigating this phase, including being prepared for its slow pace and seeking professional help for mental health.\n- The comment section includes discussions about panic attacks, symptoms of a midlife crisis, and different perspectives on the appropriate age for experiencing it.\n- The post stands out by providing personal insights and advice related to the common experience of a midlife crisis, making it engaging and relatable for readers interested in personal development."
  },
  {
    "id": 36763357,
    "timestamp": 1689624510,
    "title": "The Wikimedia Foundation joins Mastodon & the Fediverse",
    "url": "https://wikimedia.social/@wikimediafoundation/110708950540815886",
    "hn_url": "http://news.ycombinator.com/item?id=36763357",
    "content": "Wikimedia Foundation@wikimediafoundation@wikimedia.socialJul 13, 2023, 21:42 \u00b7 \u00b7 Web \u00b7613\u00b770318hOrifices in the Void@bezorp@mstdn.ca@wikimediafoundation #AltText is on point. Off to a great start!017hTim Chambers@tchambers@indieweb.social@wikimediafoundation Very glad you are here!017hlikely not a disguised martian@kyonshi@dice.camp@wikimediafoundation hello wikimedia016hLioh@Lioh@social.anoxinon.de@wikimediafoundation finally ;)015hPost-Ponga Community@postponga@toot.communityWelcome, @wikimediafoundation great to have you and your insight joining us on the 'dons 015hNordnick@nick@hhmx.de@wikimediafoundation@wikimedia.social Welcome to the #Fediverse!015hNordnick@nick@hhmx.de@wikimediafoundation@wikimedia.social Welcome to the #Fediverse!015hintelati@intelati@defcon.social@wikimediafoundation Welcome to the weird world. It's comfy in here?015hErik Moeller@eloquence@social.coop@wikimediafoundation Welcome home. :-)015hExi@spootproot@bark.lgbt@wikimediafoundation Welcome 015hTagaziel@Tagaziel@mastodon.social@wikimediafoundationHello~@rail014hZZ Bottom@fonecokid@c.im@wikimediafoundation 014hK\u1450\u144c\u1450\u156e@Kdude@mastodon.social@wikimediafoundation Great, welcome 014hMichiel Bontenbal@mpbontenbal@social.edu.nl@wikimediafoundation welcome!013hLarry@quoidian@mastodon.online@wikimediafoundation Hello - World.013hRanmaGender (TM)@ranmagender@neovibe.app@wikimediafoundation hello wikimedia. Thank you for all you do 013hStefano Marinelli@stefano@mdon.stefanomarinelli.it@wikimediafoundation hej!013hrequiem@requiem@hackers.town@wikimediafoundation welcome aboard!013hArda K\u0131l\u0131\u00e7da\u011f\u0131@arda@micro.arda.pw@wikimediafoundation Hello to Fediverse 013hEduardo S\u00e1nchez@sombragris@faithtree.social@wikimediafoundation welcome!!013hHenri Loevenbruck@loevenbruck@toot.portes-imaginaire.org@wikimediafoundationWelcoooooome !!!012hHover@hover@tucows.social@wikimediafoundation Happy to see you here.012hOc\u00e9ane \u23da@oceane@eldritch.cafe@wikimediafoundation henlo012hsuper_user_do@super_user_do@mastodon.uno@wikimediafoundation Welcome! Thanks for saving me hours and hours of research!012hSamuel@samuel@social.spejset.org@wikimediafoundation Welcome!012hCaseyL@CaseyL@mastodon.nz@wikimediafoundation Hello right back! So happy to see you here! Welcome!012hlebout2canap \u23da@lebout2canap@mastodon.tedomum.net@wikimediafoundation 011hSebastian Sanitz@sanitz@mastodon.social@wikimediafoundation 010hIron Raptor, metal dinosaur@Ironraptor@yiff.life@wikimediafoundationWELCOME!!!010hTag365@Tag365@mstdn.party@wikimediafoundation Anyone else excited about the Fediverse?010hrandint@randint@c.im@wikimediafoundation ooooh010hBahadir@Bahadir@fosstodon.org@wikimediafoundation well hello to you too! Kudos on the alt text.09hwanderingmagus@wanderingmagus@ioc.exchange@wikimediafoundation welcome!09hdeadbeef \u20e4@deadbeef@shakedown.social@wikimediafoundation HELO09hFaizalR@faizalr@mstdn.social@wikimediafoundation hello! Welcome aboard.09hforrest@buru5@mstdn.games@wikimediafoundation hi?09hp858snake@p858snake@aus.social@wikimediafoundation should that be sung along to the theme of the saddle club theme song? https://en.wikipedia.org/wiki/The_Saddle_ClubThe Saddle Club - Wikipediaen.wikipedia.org08hInfrogmation@Infrogmation@mastodon.online@wikimediafoundation Welcome!07hCat@Cat@kbin.socialWoohoo! Welcome!05hAmiW Streetart@AmiW@mastodon.online@wikimediafoundation Welcome #newhere04hWilmar Igl@wiligl@climatejustice.social@wikimediafoundation Hello Wikimedia! :-)03hUkaza Perdana@ukazap@mastodon.social@wikimediafoundation Hello Wikimedia!03hFelipe Bojorquez@febog@hachyderm.io@wikimediafoundation hello! 02hpat@pat@digitalcourage.social@wikimediafoundation Welcome to the Fediverse!059mTomer Cohen@tomer@tooot.im@wikimediafoundation Welcome!058mEquipo Nib\u00f6@equipo@red.niboe.info@wikimediafoundation bienvenidas al Fediverso 0Wikimedia Foundation@wikimediafoundation@wikimedia.socialJul 13, 2023, 21:42 \u00b7 \u00b7 Web \u00b7613\u00b770318hOrifices in the Void@bezorp@mstdn.ca@wikimediafoundation #AltText is on point. Off to a great start!017hTim Chambers@tchambers@indieweb.social@wikimediafoundation Very glad you are here!017hlikely not a disguised martian@kyonshi@dice.camp@wikimediafoundation hello wikimedia016hLioh@Lioh@social.anoxinon.de@wikimediafoundation finally ;)015hPost-Ponga Community@postponga@toot.communityWelcome, @wikimediafoundation great to have you and your insight joining us on the 'dons 015hNordnick@nick@hhmx.de@wikimediafoundation@wikimedia.social Welcome to the #Fediverse!015hNordnick@nick@hhmx.de@wikimediafoundation@wikimedia.social Welcome to the #Fediverse!015hintelati@intelati@defcon.social@wikimediafoundation Welcome to the weird world. It's comfy in here?015hErik Moeller@eloquence@social.coop@wikimediafoundation Welcome home. :-)015hExi@spootproot@bark.lgbt@wikimediafoundation Welcome 015hTagaziel@Tagaziel@mastodon.social@wikimediafoundationHello~@rail014hZZ Bottom@fonecokid@c.im@wikimediafoundation 014hK\u1450\u144c\u1450\u156e@Kdude@mastodon.social@wikimediafoundation Great, welcome 014hMichiel Bontenbal@mpbontenbal@social.edu.nl@wikimediafoundation welcome!013hLarry@quoidian@mastodon.online@wikimediafoundation Hello - World.013hRanmaGender (TM)@ranmagender@neovibe.app@wikimediafoundation hello wikimedia. Thank you for all you do 013hStefano Marinelli@stefano@mdon.stefanomarinelli.it@wikimediafoundation hej!013hrequiem@requiem@hackers.town@wikimediafoundation welcome aboard!013hArda K\u0131l\u0131\u00e7da\u011f\u0131@arda@micro.arda.pw@wikimediafoundation Hello to Fediverse 013hEduardo S\u00e1nchez@sombragris@faithtree.social@wikimediafoundation welcome!!013hHenri Loevenbruck@loevenbruck@toot.portes-imaginaire.org@wikimediafoundationWelcoooooome !!!012hHover@hover@tucows.social@wikimediafoundation Happy to see you here.012hOc\u00e9ane \u23da@oceane@eldritch.cafe@wikimediafoundation henlo012hsuper_user_do@super_user_do@mastodon.uno@wikimediafoundation Welcome! Thanks for saving me hours and hours of research!012hSamuel@samuel@social.spejset.org@wikimediafoundation Welcome!012hCaseyL@CaseyL@mastodon.nz@wikimediafoundation Hello right back! So happy to see you here! Welcome!012hlebout2canap \u23da@lebout2canap@mastodon.tedomum.net@wikimediafoundation 011hSebastian Sanitz@sanitz@mastodon.social@wikimediafoundation 010hIron Raptor, metal dinosaur@Ironraptor@yiff.life@wikimediafoundationWELCOME!!!010hTag365@Tag365@mstdn.party@wikimediafoundation Anyone else excited about the Fediverse?010hrandint@randint@c.im@wikimediafoundation ooooh010hBahadir@Bahadir@fosstodon.org@wikimediafoundation well hello to you too! Kudos on the alt text.09hwanderingmagus@wanderingmagus@ioc.exchange@wikimediafoundation welcome!09hdeadbeef \u20e4@deadbeef@shakedown.social@wikimediafoundation HELO09hFaizalR@faizalr@mstdn.social@wikimediafoundation hello! Welcome aboard.09hforrest@buru5@mstdn.games@wikimediafoundation hi?09hp858snake@p858snake@aus.social@wikimediafoundation should that be sung along to the theme of the saddle club theme song? https://en.wikipedia.org/wiki/The_Saddle_ClubThe Saddle Club - Wikipediaen.wikipedia.org08hInfrogmation@Infrogmation@mastodon.online@wikimediafoundation Welcome!07hCat@Cat@kbin.socialWoohoo! Welcome!05hAmiW Streetart@AmiW@mastodon.online@wikimediafoundation Welcome #newhere04hWilmar Igl@wiligl@climatejustice.social@wikimediafoundation Hello Wikimedia! :-)03hUkaza Perdana@ukazap@mastodon.social@wikimediafoundation Hello Wikimedia!03hFelipe Bojorquez@febog@hachyderm.io@wikimediafoundation hello! 02hpat@pat@digitalcourage.social@wikimediafoundation Welcome to the Fediverse!059mTomer Cohen@tomer@tooot.im@wikimediafoundation Welcome!058mEquipo Nib\u00f6@equipo@red.niboe.info@wikimediafoundation bienvenidas al Fediverso 0",
    "summary": "- The Wikimedia Foundation has joined Mastodon and the Fediverse.\n- There is excitement and warm welcome from the tech community for Wikimedia's presence in the Fediverse.\n- This move brings new opportunities for collaboration and knowledge sharing within the decentralized social network.",
    "hn_title": "The Wikimedia Foundation joins Mastodon and the Fediverse",
    "original_title": "The Wikimedia Foundation joins Mastodon and the Fediverse",
    "score": 303,
    "hn_content": "Hacker News new | past | comments | ask | show | jobs | submit loginThe Wikimedia Foundation joins Mastodon and the Fediverse (wikimedia.social)303 points by Kye 14 hours ago | hide | past | favorite | 77 commentspornel 12 hours ago | next [\u2013]This makes a lot of sense for organizations. They control the servers. They own the domain. This is how the Web is supposed to work.replystasm 12 hours ago | parent | next [\u2013]> They own the domain.It seems like a wasted opportunity to set up a new domain (in this case: wikimedia.social) rather than use an existing one with a subdomain, e.g. social.wikimedia.org or social.wikimediafoundation.org. With a new domain I still have to do the work to verify whether the domain is indeed owned by the Wikimedia Foundation.replymarksomnian 12 hours ago | root | parent | next [\u2013]There's some background at https://phabricator.wikimedia.org/T337586 - a wikimedia.org subdomain was out of the question due to security concerns (it'd involve giving a third party a SSL certificate for wikimedia.org) [1], and wikimediafoundation.org was ruled out because it could cause confusion about volunteers' relationship to the Foundation [2][1]: https://phabricator.wikimedia.org/T337586#8932905 [2]: https://phabricator.wikimedia.org/T337586#8936483replyj1elo 11 hours ago | root | parent | next [\u2013]From your first link, it seems the decision to use a different new domain stems from difficulties getting the server's HSTS policy right, and it even seems they had a similar issue in the past with having the store as a subdomain [1].If that's true, for a use case as functionally basic as having a store and a social instance in their respective subdomains, it looks to me like a complete failure of HSTS, a case of technology causing problems that shouldn't exist to begin with.[1]: https://phabricator.wikimedia.org/T337586#8920625replymarksomnian 11 hours ago | root | parent | next [\u2013]It's not linked there (or on any Wikitech pages I can find), but I can imagine there's a secondary concern of *.wikimedia.org cookies getting sent to third parties - e.g. Stack Overflow has separate second-level domains (stackoverflow.email/stackoverflow.blog) for their 3rd-party-hosted email service and blog for exactly this reason (cf. https://nickcraver.com/blog/2017/05/22/https-on-stack-overfl...)replyaccount42 1 hour ago | root | parent | prev | next [\u2013]Seems the real issue is that Mastodon is too hard to self host if not even Wikimedia wants to do it.> it'd involve giving a third party a SSL certificate for wikimedia.orgYou can have certificates for subdomains. With Let's Encrypt you still need to control the root domain to generate them so they'd have to setup something for that. But that's more a can't-be-bothered concern than an actual security concern. Teaching the public to trust random domains being authentic is a much much bigger security concern anyway.replysoneil 12 hours ago | root | parent | prev | next [\u2013]I think it'd be great if there was a way to push the identity through a different domain. @foundation@mediawiki.org or such. Needing subdomains is so clunky - imagine if you were example@mail.gmail.com, yuck.We can get half way there with /.well-known/webfinger - but the alias that provides doesn't show up in the feed, so that's not the username I find from links like OP's.replyscrollaway 11 hours ago | root | parent | next [\u2013]There is a way in activitypub, but Mastodon itself doesn't support it well. Takah\u0113 supports it (https://jointakahe.org/).replyKye 12 hours ago | root | parent | prev | next [\u2013]It can accrue reputation the same way Wikipedia.org did while providing a spot to add other things like PeerTube without worrying about the security peculiarities that led to them choosing this route in the first place.https://phabricator.wikimedia.org/T337586#8920625replyproactivesvcs 12 hours ago | parent | prev | next [\u2013]They don't really control this server - they're using masto.host to host their instance.replylolinder 12 hours ago | root | parent | next [\u2013]They control it a whole lot more than they do Twitter, Facebook, or any other central platform.Control is a sliding scale. They could run it on a physical box in Wikimedia headquarters and you could still argue they don't fully control the server because their ISP could always cut them off.You have to make reasonable decisions based on your threat model and how easy it would be to move up the level-of-control ladder if needed. Getting on Mastodon at all represents a huge leap forward, and frees them up to migrate to a higher level of autonomy later.replygochi 11 hours ago | root | parent | next [\u2013]Nobody would argue that because if they did control the servers an ISP change would be effortless.Which is the point, the move to a higher level of autonomy is not going to happen later. It's far too much effort once they've already settled in.We should praise organizations that actually seek to normalize control over servers, not praise relying on yet another \"fully managed\" service. We can do that while also recognizing that them being on fediverse is nice in general. All of these are possible without stating falsehoods like \"They control the servers\".replylolinder 11 hours ago | root | parent | next [\u2013]> if they did control the servers an ISP change would be effortless.I don't know where in the world you are, but I want to live there. Changing my ISP is far more intimidating to me than migrating a database and a few DNS records.> We should praise organizations that actually seek to normalize control over servers, not praise relying on yet another \"fully managed\" service.What would be enough to satisfy you? A VPS on AWS? A VPS on a smaller provider? A dedicated box at Hetzner? Or would it have to be a machine that they built from scratch and can physically access?replyCobrastanJorji 12 hours ago | root | parent | prev | next [\u2013]Yes, but they COULD. If for some reason they decide that something's wrong with their host, they could just go offline, export the data onto a new host somewhere, move some DNS targets and set up some redirects, and bam, new server. The point is that some one social media company doesn't have a lock on the site.replymananaysiempre 11 hours ago | root | parent | prev | next [\u2013]They control the identities, and if they wanted to they could transition the identities at the price of\u2014at worst\u2014data loss. It\u2019s the difference between having a blog using the Medium CMS and hosting and having one on a subdomain of medium.com\u2014you can switch away in the former case but you\u2019re completely stuck in the latter (which is why Medium took away the first option and Substack never had it).replygoodpoint 11 hours ago | parent | prev | next [\u2013]> This is how the Web is supposed to work.More like: this in how the Internet is supposed to work. ActivityPub is hardly \"web\" because it's not trying to attract traffic on a specific website.replyriffic 11 hours ago | root | parent | next [\u2013]ActivityPub is inherently web because it's a recommendation by the W3C (World Wide Web Consortium):https://www.w3.org/TR/activitypub/replygoodpoint 9 hours ago | root | parent | next [\u2013]Missing the point huh?replyriffic 9 hours ago | root | parent | next [\u2013]if the web people wrote a spec involving the web I'd say there's a fair chance it's web related.replypygar 11 hours ago | prev | next [\u2013]On a semi related note, WordPress recently acquired an activitypub plugin that does exactly what it sounds like. [0]So as a corporation you don't really need a mastodon instance to broadcast your stuff. I think most organisations will go this route. (and i suspect threads hopes to piggyback of this for content).[0] https://wordpress.org/plugins/activitypub/replyKye 11 hours ago | parent | next [\u2013]I lost track of the conversation, but the developer is working on a full integration with WordPress so you can use it on a WordPress.com blog without the expensive plan that lets you use plugins.replynunobrito 13 hours ago | prev | next [\u2013]Plus points for running their own server. Now just missing to add Nostr to make sure those texts continue to be available one day in case the server goes down or gets censored in parts of the globe.replymarksomnian 13 hours ago | prev | next [\u2013]Some background at https://phabricator.wikimedia.org/T337586replyChrisArchitect 12 hours ago | parent | next [\u2013]Did they write anywhere else about what they're actual plan for this instance is? A whole new service to operate and moderate... are they maintaining their other social platform accounts etc.replymarksomnian 11 hours ago | root | parent | next [\u2013]There's some (vague, nonspecific) goals in the Google Doc linked on the phab ticket (though someone did point out that the doc was created weeks after the ticket was filed).replyKye 13 hours ago | parent | prev | next [\u2013]I've heard the process inside organizations of getting approval to do a new social media thing can be involved. It's interesting to see one of those discussions out in public.replyaaronharnly 13 hours ago | root | parent | next [\u2013]Yes, I take some solace from the fact that most of the comments on the ticket are in the nature of:- \u201cWait, I don\u2019t think Team X can do this, it needs to be approved by Team Y and then handed to Team Z\u201d, followed by- \u201cI thought our policy was not to do this?\u201d- \u201cNo there\u2019s no policy not to do this\u201d- \u201cWell maybe the policy was that we do do not this\u201d- \u201cDoes Team Z even get notified about tickets here?\u201detc\u2026replyneilv 11 hours ago | root | parent | next [\u2013]How I try to avoid most institutional knowledge and communication problems like that is with... a trusted wiki.They should ask around, see if anyone in the organization is familiar with wikis and could help them get started.replyploum 13 hours ago | root | parent | prev | next [\u2013]Imagine for a second what the discussions could be for the official European institutions to open their own instance?https://social.network.europa.eu/explore (and yes, it was created early 2022, before Musk takeover of Twitter)replyKye 13 hours ago | root | parent | next [\u2013]They also have a PeerTube instance.https://tube.network.europa.eu/videos/overviewreplyriffic 13 hours ago | root | parent | prev | next [\u2013]transparency aside it's amazing how fast they were able to roll this.Heads up but if anyone's got questions about the Mastodon software, community, wider ecosystem et cetera you're more than welcome to hop into the unofficial Mastodon subreddit and ask away. saying this as one of the /r/Mastodon mods.replyruffsl 12 hours ago | root | parent | next [\u2013]Is there a community on Lemmy for Mastodon mods and admins? Hosting support discussions about Fediverse platforms on Fediverse platforms seems like an opportunity to dog food more it's development.replyriffic 12 hours ago | root | parent | next [\u2013]On Mastodon itself people like to use the #MastoAdmin hashtag.Good point about Lemmy. I remember reading the Discourse software was considering federation/ActivityPub support but haven't seen any traction there.replynologic01 11 hours ago | prev | next [\u2013]There are potentially intriguing synergies down the line, beyond establishing a social presence.Fediverse platforms could integrate links to wikipedia content in a native way, somewhat similar to openstreetmap.The reverse is more speculative but potentially more groundbreaking. It would be a parallel \"fedipedia\" platform that would somehow distill, organize and preserve the various bits and pieces of useful information and knowledge that is being generated in social media platforms.One of the sadest outcomes of the adtech based walled garden era is how decades of human interaction and information exchange ends up in a sort of digital landfill.We need to think more boldly about the next web and the shape of the digital commons.replyegor-zhgun 13 hours ago | prev | next [\u2013]It's interesting whatever they'll federate with Meta or not.replysmoldesu 12 hours ago | parent | next [\u2013]Considering how they already have an active Wikimedia Facebook account, I don't think they'd object to federating with Meta.replysitzkrieg 11 hours ago | parent | prev | next [\u2013]wait till you see the blocklists loud instances used to rave about sharing and updating and blanket blackholing entire instancesreplyriku_iki 13 hours ago | prev | next [\u2013]I guess \"joins\" means created account..replyWolfeReader 13 hours ago | parent | next [\u2013]More than that, in this case. They're hosting an entire instance.replythewataccount 13 hours ago | parent | prev | next [\u2013]Beyond the fact that they created an entire instance -> I guess \"joins\" means created account..I do think this statement would be accurate, you are \"joining\" if you create an account.At least I don't see an argument for how creating an official account wouldn't count as \"joining\" - although it's admittedly boring if that's all they did.replyriku_iki 13 hours ago | root | parent | next [\u2013]> I do think this statement would be accurate, you are \"joining\" if you create an account.I personally was confused, and initially thought Wikimedia joined corresponding orgs, became codebase contributor, etc. But maybe that's me not familiar with his topic.replyKye 13 hours ago | root | parent | prev | next [\u2013]That's what I had in mind when writing a suitable title. They joined the Fediverse by making their own instance, then joined Mastodon by creating an account on that instance.replyjayknight 13 hours ago | parent | prev | next [\u2013]Well, they're running their own mastodon instance at wikimedia.social.replyAeolun 11 hours ago | parent | prev | next [\u2013]Yeah, I read the headline and was briefly completely mystified until I opened the article.This reads like the title of s \u2018Beautiful journey\u2026 chosen to join [company]\u2019 post.replyKye 11 hours ago | root | parent | next [\u2013]I think we're past the point where Mastodon is obscure enough to need extra explanation in a place like this. This is a completely ordinary title form for people and organizations joining new platforms and technologies.https://hn.algolia.com/?q=%22joins+Twitter%22Notable examples:Bill Gates: https://news.ycombinator.com/item?id=1064772Tim Berners-Lee: https://news.ycombinator.com/item?id=898727The Pope: https://news.ycombinator.com/item?id=4897631The CIA: https://news.ycombinator.com/item?id=7862990Warren Buffet: https://news.ycombinator.com/item?id=5645650It coexists with other uses.replyals0 13 hours ago | parent | prev | next [\u2013]...and their own server...replylibraryatnight 13 hours ago | parent | prev | next [\u2013]Even if that were the case, and others have pointed out it's not, what would your point be?replyproactivesvcs 12 hours ago | parent | prev | next [\u2013]Yeah, joined by renting masto.host's service. Nothing against masto.host but Wikimedia are not running their own server, or really their own instance. It's a net positive but it's not the decentralised, independent example that it could be.replypipeline_peak 5 hours ago | prev | next [\u2013]Let me know when not tech people/companies join, then it\u2019ll look promising.Did more people adopt Twitter to hear from John Carmack or Kanye West?replyjheriko 13 hours ago | prev | next [3 more]Invictus0 13 hours ago | prev | next [11 more]blisterpeanuts 13 hours ago | prev | next [\u2013]The Wikipedia Twitter page has a lot of followers, but engagement is very low, and most of the tweets are random topics.What advantages does a mastodon feed provide?In my opinion, if Wikipedia is seeking more social media engagement, they should focus on the big platforms: Facebook, Twitter, Instagram, YouTube.replydragontamer 13 hours ago | parent | next [\u2013]> What advantages does a mastodon feed provide?Allowing anonymous users to read posts, vs Twitter which requires a log in these days.-----------Lets reverse the discussion. What does Twitter offer Wikipedia that Mastodon does not? Since Wikipedia's engagement is largely readers / followers with very little comments, the read-only experience is king, is it not?Mastodon therefore offers a better reading experience, as it doesn't have advertisements, it isn't going to randomly go down (stability of Mastodon has improved a lot while the stability of Twitter is declining), running your own Mastodon instance allows for any size posts (no need for Wikipedia to pay Twitter Blue to get 2000-character posts. Wikipedia can just configure Mastodon to allow 2000 or 20,000-character posts), etc. etc.Why should Wikipedia stick to 250-character posts on a website that can't be read by anonymous users that will shove ads into your face in between posts?> YouTubeDoes Wikipedia even have substantial video content to share on Youtube?> InstagramI guess you mean Threads, which is the closest analog to Mastodon and Twitter. I haven't used Threads though so I'll defer to other posters.> FacebookWay too closed and insular. Facebook is focused on smaller groups and smaller social networks. Its like the \"login\" problem for Twitter but a hundred-times worse.replyLordDragonfang 11 hours ago | root | parent | next [\u2013]>What does Twitter offer Wikipedia that Mastodon does not?Though it may not seem like it to the highly-technical terminally-online, twitter is still very much the Schelling point[1] for social media communication. People, by default, will look for communications from (and attempt to get the attention of) large entities on twitter (especially during events like the main website going down). This is a huge deal that needs to be accounted for when listing what the platform \"has to offer\".(Of course, the way things are going, this may change in the future. This is by no means a bad move by the WMF. The future is uncertain, though, and it's just worth being realistic about the value twitter still holds in the present.)[1] https://en.wikipedia.org/wiki/Focal_point_(game_theory)replydragontamer 11 hours ago | root | parent | next [\u2013]Only if you look at people with Twitter accounts.Someone like me, who has always relied upon nitter to get Twitter information (and now that API access is locked off and anonymous browsing is disabled... I'm no longer welcome to Twitter).Its ridiculous that Twitter looked upon the grand social network of Quora and thought... \"We should copy that model\". Closing off access to the website is the literal opposite direction, it will kill Twitter faster than any other decision made thusfar.replybboygravity 4 hours ago | root | parent | next [\u2013]You do realize that you're one of many people (and large media outlets) in the past year or so who claimed that Twitter will die \"very soon\"?replyorwin 11 hours ago | root | parent | prev | next [\u2013]> Allowing anonymous users to read posts, vs Twitter which requires a log in these days.Now it allows you to read the linked tweet, but not the response/thread, so it's basically useless for stuff that interested me still on Twitter (and tbh, Nitter was 10 times better than Twitter UI for stuff that interest me)replyWolfeReader 13 hours ago | parent | prev | next [\u2013]Each of those platforms you mentioned is corporate-controlled. The \"free encyclopedia that anyone can edit\" is probably more interested in engaging with open-source, non-centralized tech when possible.replyrsynnott 13 hours ago | parent | prev | next [\u2013]As you say, they have a Twitter. Twitter could, at this point, vanish up its own arse at any moment. It was largely unusable for about three days recently. It remains pretty broken for non-logged-in people. Backup plans are hardly surprising.Frankly, anyone who uses Twitter for anything more than entertainment should be looking at backup plans at this stage.replyCSSer 13 hours ago | root | parent | next [\u2013]It's even really sad to see that there's a lot of embedded Twitter content around the web that has been either breaking or disappearing for one reason or another too.replykalleboo 4 hours ago | root | parent | next [\u2013]At least the default Twitter embed codes have the plaintext in therereplyrsynnott 1 hour ago | root | parent | next [\u2013]Ssssh. He probably hasn't noticed yet; don't point it out.replynunobrito 13 hours ago | parent | prev | next [\u2013]That's the easy route. The reason why those platforms are avoided is mostly because of the Wikimedia/wikipedia commitment to promote open source and privacy respecting platforms.Arguably none of those are world-famous with a positive note for those attributes.replyKye 13 hours ago | parent | prev | next [\u2013]The same reason the EU does, among many other organizations and companies. It's a backup and alternative, not too much work to run if it's only for people on the inside, and cross-posting is as simple as checking a box in a growing number of social media management tools.replyfluxem 12 hours ago | prev | next [\u2013]Why does Wikipedia need Twitter/Mastodon?replyAngostura 13 hours ago | prev [\u2013]I\u2019d be interested in seeing what they do with https://wt.social/I don\u2019t feel like it has gained a lot of traction. Perhaps it could be migrated to a Lemmy/Kbin/Their own ActivityPub implementationreplyriffic 12 hours ago | parent [\u2013]wt.social isn't a Wikimedia Foundation site:> WT.social is owned and operated by WikiTribune Ltd (\u201cwe\u201d, \u201cus\u201d)https://wt.social/terms-and-conditionsreplyGuidelines | FAQ | Lists | API | Security | Legal | Apply to YC | ContactSearch:",
    "hn_summary": "- The Wikimedia Foundation has joined Mastodon and the Fediverse by creating their own instance.\n- There was discussion about the domain name choice, with some suggesting the use of a subdomain.\n- Mastodon offers advantages such as anonymous reading, no advertisements, and the ability to post longer content compared to platforms like Twitter."
  },
  {
    "id": 36763419,
    "timestamp": 1689624805,
    "title": "The US economy & the EU were the same size in 2008, the US is now nearly 2X",
    "url": "https://twitter.com/scienceisstrat1/status/1680959906969444352",
    "hn_url": "http://news.ycombinator.com/item?id=36763419",
    "content": "Due to Twitter's new pricing structure, we made a difficult choice to restrict the option of unrolling tweets on the web to Premium members only. You can still unroll tweets for free by visiting Twitter and replying to the tweet with \"@threadreaderapp unroll.\" We appreciate your understanding!Thread ReaderOne-click sign-up and loginSign up or login to access your unrolled and bookmarked threads (or PDF archives if you are a Premium member!)Login with TwitterLogin with EmailLogin above to accept Thread Reader App'sTerms of Service and Privacy PolicyHelp | About | TOS | Privacy | Twitter Files",
    "summary": "- Twitter has implemented a new pricing structure that restricts the option of unrolling tweets on the web to Premium members only.\n- Non-Premium members can still unroll tweets for free by visiting Twitter and replying to the tweet with \"@threadreaderapp unroll.\"\n- Premium members can access additional features such as bookmarked threads and PDF archives.",
    "hn_title": "The US economy and the EU were the same size in 2008, the US is now nearly 2X",
    "original_title": "The US economy and the EU were the same size in 2008, the US is now nearly 2X",
    "score": 297,
    "hn_content": "- The US economy has nearly doubled since 2008, while the EU's growth has been slower.\n- The use of PPP-adjusted GDP shows that the prices of goods in the US are inflated compared to the EU, suggesting a difference in the cost of living.\n- GDP PPP is not a good measure of population wealth or quality of life, especially in developed economies.\n- The size of an economy does not necessarily reflect the standard of living for individuals.\n- The US has a larger economy than the EU, but the difference is not as dramatic as it may seem.\n- GDP PPP does not account for factors such as income inequality, unemployment rates, or other indicators of quality of life.\n- Consumption and GDP growth are not equivalent to quality of life.\n- The comparison between the US and the EU is complex and requires considering various factors beyond GDP.- There is a discussion about the correlation between employment protections and economic growth in the US and the UK.\n- The US benefits from having a world reserve currency, which allows it to print more money without risking inflation and tax the whole planet.\n- The employment of immigrants in the US contributes to its economic growth and offers big opportunities for them to become big tax contributors.\n- European old money is doing fine, but the middle class is being taxed heavily.\n- Europe implemented open door policies to refugees to escape the demographic trap and the collapse of the social safety net, but integration has been a challenge.\n- The US has a cultural purity to protect, which is consumer capitalism.\n- The US has better social mobility compared to Europe, which has thousands of years of aristocracy-fueled unfairness.\n- The EU's open door policy aimed at benefiting from young refugees as net positive GDP contributors, but integration is a challenge.\n- The EU's energy crisis is caused by its liberalized energy market, not an open door policy to refugees.\n- Austerity is a detrimental policy that inhibits growth.\n- The US offers more opportunities, capacity for improvement, luxury, and space compared to Europe.\n- Life expectancy is higher in the EU compared to the US due to factors such as obesity and the opioid crisis.\n- The US and European countries have equivalent levels of upward mobility.\n- The difference in life expectancy is due to people dying young, such as from gun violence, automobile accidents, obesity, and the opioid epidemic.\n- There is a discussion about the importance of GDP as a metric for success and the well-being of individuals.\n- The US has a larger percentage of young people and more of them are dying from drugs, which skews the life expectancy metric.\n- Quality of life should be considered along with life expectancy and GDP growth.",
    "hn_summary": "- The US economy has nearly doubled since 2008, while the EU's growth has been slower.\n- The use of PPP-adjusted GDP shows a difference in the cost of living between the US and the EU.\n- GDP PPP does not account for factors such as income inequality, unemployment rates, or other indicators of quality of life."
  },
  {
    "id": 36762682,
    "timestamp": 1689621391,
    "title": "Coroutines for Go",
    "url": "https://research.swtch.com/coro",
    "hn_url": "http://news.ycombinator.com/item?id=36762682",
    "content": "research!rsc Thoughts and links about programming, by Russ CoxCoroutines for GoPosted on Monday, July 17, 2023. PDFThis post is about why we need a coroutine package for Go, and what it would look like. But first, what are coroutines?Every programmer today is familiar with function calls (subroutines): F calls G, which stops F and runs G. G does its work, potentially calling and waiting for other functions, and eventually returns. When G returns, G is gone and F continues running. In this pattern, only one function is running at a time, while its callers wait, all the way up the call stack.In contrast to subroutines, coroutines run concurrently on different stacks, but it's still true that only one is running at a time, while its caller waits. F starts G, but G does not run immediately. Instead, F must explicitly resume G, which then starts running. At any point, G may turn around and yield back to F. That pauses G and continues F from its resume operation. Eventually F calls resume again, which pauses F and continues G from its yield. On and on they go, back and forth, until G returns, which cleans up G and continues F from its most recent resume, with some signal to F that G is done and that F should no longer try to resume G. In this pattern, only one coroutine is running at a time, while its caller waits on a different stack. They take turns in a well-defined, coordinated manner.This is a bit abstract. Let's look at real programs.Coroutines in LuaTo use a venerable example, consider comparing two binary trees to see if they have the same value sequence, even if their structures are different. For example, here is code in Lua 5 to generate some binary trees:function T(l, v, r)  return {left = l, value = v, right = r}ende = nilt1 = T(T(T(e, 1, e), 2, T(e, 3, e)), 4, T(e, 5, e))t2 = T(e, 1, T(e, 2, T(e, 3, T(e, 4, T(e, 5, e)))))t3 = T(e, 1, T(e, 2, T(e, 3, T(e, 4, T(e, 6, e)))))The trees t1 and t2 both contain the values 1, 2, 3, 4, 5; t3 contains 1, 2, 3, 4, 6.We can write a coroutine to walk over a tree and yield each value:function visit(t)  if t ~= nil then -- note: ~= is \"not equal\"    visit(t.left)    coroutine.yield(t.value)    visit(t.right)  endendThen to compare two trees, we can create two visit coroutines and alternate between them to read and compare successive values:function cmp(t1, t2)  co1 = coroutine.create(visit)  co2 = coroutine.create(visit)  while true  do    ok1, v1 = coroutine.resume(co1, t1)    ok2, v2 = coroutine.resume(co2, t2)    if ok1 ~= ok2 or v1 ~= v2 then      return false    end    if not ok1 and not ok2 then      return true    end  endendThe t1 and t2 arguments to coroutine.resume are only used on the first iteration, as the argument to visit. Subsequent resumes return that value from coroutine.yield, but the code ignores the value.A more idiomatic Lua version would use coroutine.wrap, which returns a function that hides the coroutine object:function cmp(t1, t2)  next1 = coroutine.wrap(function() visit(t1) end)  next2 = coroutine.wrap(function() visit(t2) end)  while true  do    v1 = next1()    v2 = next2()    if v1 ~= v2 then      return false    end    if v1 == nil and v2 == nil then      return true    end  endendWhen the coroutine has finished, the next function returns nil (full code).Generators in Python (Iterators in CLU)Python provides generators that look a lot like Lua's coroutines, but they are not coroutines, so it's worth pointing out the differences. The main difference is that the \u201cobvious\u201d programs don't work. For example, here's a direct translation of our Lua tree and visitor to Python:def T(l, v, r):  return {'left': l, 'value': v, 'right': r}def visit(t):  if t is not None:    visit(t['left'])    yield t['value']    visit(t['right'])But this obvious translation doesn't work:>>> e = None>>> t1 = T(T(T(e, 1, e), 2, T(e, 3, e)), 4, T(e, 5, e))>>> for x in visit(t1):...   print(x)...4>>>We lost 1, 2, 3, and 5. What happened?In Python, that def visit does not define an ordinary function. Because the body contains a yield statement, the result is a generator instead:>>> type(visit(t1))<class 'generator'>>>>The call visit(t['left']) doesn't run the code in visit at all. It only creates and returns a new generator, which is then discarded. To avoid discarding those results, you have to loop over the generator and re-yield them:def visit(t):  if t is not None:    for x in visit(t['left']):      yield x    yield t['value']    for x in visit(t['right'])      yield xPython 3.3 introduced yield from, allowing:def visit(t):  if t is not None:    yield from visit(t['left']):    yield t['value']    yield from visit(t['right'])The generator object contains the state of the single call to visit, meaning local variable values and which line is executing. That state is pushed onto the call stack each time the generator is resumed and then popped back into the generator object at each yield, which can only occur in the top-most call frame. In this way, the generator uses the same stack as the original program, avoiding the need for a full coroutine implementation but introducing these confusing limitations instead.Python's generators appear to be almost exactly copied from CLU, which pioneered this abstraction (and so many other things), although CLU calls them iterators, not generators. A CLU tree iterator looks like:visit = iter (t: cvt) yields (int):  tagcase t    tag empty: ;    tag non_empty(t: node):      for x: int        in tree$visit(t.left) do          yield(x);          end;      yield(t.value);      for x: int        in tree$visit(t.right) do          yield(x);          end;    end;  end visit;The syntax is different, especially the tagcase that is examining a tagged union representation of a tree, but the basic structure, including the nested for loops, is exactly the same as our first working Python version. Also, because CLU was statically typed, visit is clearly marked as an iterator (iter) not a function (proc in CLU). Thanks to that type information, misuse of visit as an ordinary function call, like in our buggy Python example, is something that the compiler could (and I assume did) diagnose.About CLU's implementation, the original implementers wrote, \u201cIterators are a form of coroutine; however, their use is sufficiently constrained that they are implemented using just the program stack. Using an iterator is therefore only slightly more expensive than using a procedure.\u201d This sounds exactly like the explanation I gave above for the Python generators. For more, see Barbara Liskov et al.'s 1977 paper \u201cAbstraction Mechanisms in CLU\u201d, specifically sections 4.2, 4.3, and 6.Coroutines, Threads, and GeneratorsAt first glance, coroutines, threads, and generators look alike. All three provide concurrency in one form or another, but they differ in important ways.Coroutines provide concurrency without parallelism: when one coroutine is running, the one that resumed it or yielded to it is not.Because coroutines run one at a time and only switch at specific points in the program, the coroutines can share data among themselves without races. The explicit switches (coroutine.resume in the first Lua example or calling a next function in the second Lua example) serve as synchronization points, creating happens-before edges.Because scheduling is explicit (without any preemption) and done entirely without the operating system, a coroutine switch takes at most around ten nanoseconds, usually even less. Startup and teardown is also much cheaper than threads.Threads provide more power than coroutines, but with more cost. The additional power is parallelism, and the cost is the overhead of scheduling, including more expensive context switches and the need to add preemption in some form. Typically the operating system provides threads, and a thread switch takes a few microseconds.For this taxonomy, Go's goroutines are cheap threads: a goroutine switch is closer to a few hundred nanoseconds, because the Go runtime takes on some of the scheduling work, but goroutines still provide the full parallelism and preemption of threads. (Java's new lightweight threads are basically the same as goroutines.)Generators provide less power than coroutines, because only the top-most frame in the coroutine is allowed to yield. That frame is moved back and forth between an object and the call stack to suspend and resume it.Coroutines are a useful building block for writing programs that want concurrency for program structuring but not for parallelism. For one detailed example of that, see my previous post, \u201cStoring Data in Control Flow\u201d. For other examples, see Ana L\u00facia De Moura and Roberto Ierusalimschy's 2009 paper \u201cRevisiting Coroutines\u201d. For the original example, see Melvin Conway's 1963 paper \u201cDesign of a Separable Transition-Diagram Compiler\u201d.Why Coroutines in Go?Coroutines are a concurrency pattern not directly served by existing Go concurrency libraries. Goroutines are often close enough, but as we saw, they are not the same, and sometimes that difference matters.For example, Rob Pike's 2011 talk \u201cLexical Scanning in Go\u201d presents the original lexer and parser for the text/template package. They ran in separate goroutines connected by a channel, imperfectly simulating a pair of coroutines: the lexer and parser ran in parallel, with the lexer looking ahead to the next token while the parser processed the most recent one. Generators would not have been good enough\u2014the lexer yields values from many different functions\u2014but full goroutines proved to be a bit too much. The parallelism provided by the goroutines caused races and eventually led to abandoning the design in favor of the lexer storing state in an object, which was a more faithful simulation of a coroutine. Proper coroutines would have avoided the races and been more efficient than goroutines.An anticipated future use case for coroutines in Go is iteration over generic collections. We have discussed adding support to Go for ranging over functions, which would encourage authors of collections and other abstractions to provide CLU-like iterator functions. Iterators can be implemented today using function values, without any language changes. For example, a slightly simplified tree iterator in Go could be:func (t *Tree[V]) All(yield func(v V)) {  if t != nil {    t.left.All(yield)    yield(t.value)    t.right.All(yield)  }}That iterator can be invoked today as:t.All(func(v V) {  fmt.Println(v)})and perhaps a variant could be invoked in a future version of Go as:for v := range t.All {  fmt.Println(v)}Sometimes, however, we want to iterate over a collection in a way that doesn't fit a single for loop. The binary tree comparison is an example of this: the two iterations need to be interlaced somehow. As we've already seen, coroutines would provide an answer, letting us turn a function like (*Tree).All (a \u201cpush\u201d iterator) into a function that returns a stream of values, one per call (a \u201cpull\u201d iterator).How to Implement Coroutines in GoIf we are to add coroutines to Go, we should aim to do it without language changes. That means the definition of coroutines should be possible to implement and understand in terms of ordinary Go code. Later, I will argue for an optimized implementation provided directly by the runtime, but that implementation should be indistinguishable from the pure Go definition.Let's start with a very simple version that ignores the yield operation entirely. It just runs a function in another goroutine:package corofunc New[In, Out any](f func(In) Out) (resume func(In) Out) {  cin := make(chan In)  cout := make(chan Out)  resume = func(in In) Out {    cin <- in    return <-cout  }  go func() { cout <- f(<-cin) }()  return resume}New takes a function f which must have one argument and one result. New allocates channels, defines resume, creates a goroutine to run f, and returns the resume funtion. The new goroutine blocks on <-cin, so there is no opportunity for parallelism. The resume function unblocks the new goroutine by sending an in value and then blocks receiving an out value. This send-receive pair makes a coroutine switch. We can use coro.New like this (full code):func main() {  resume := coro.New(strings.ToUpper)  fmt.Println(resume(\"hello world\"))}So far, coro.New is just a clunky way to call a function. We need to add yield, which we can pass as an argument to f:func New[In, Out any](f func(in In, yield func(Out) In) Out) (resume func(In) Out) {  cin := make(chan In)  cout := make(chan Out)  resume = func(in In) Out {    cin <- in    return <-cout  }  yield := func(out Out) In {    cout <- out    return <-cin  }  go func() { cout <- f(<-cin, yield) }()  return resume}Note that there is still no parallelism here: yield is another send-receive pair. These goroutines are constrained by the communication pattern to act indistinguishably from coroutines.Example: String ParserBefore we build up to iterator conversion, let's look at a few simpler examples. In \u201cStoring Data in Control Flow,\u201d we considered the problem of taking a functionfunc parseQuoted(read func() byte) booland running it in a separate control flow so that bytes can be provided one at a time to a Write method. Instead of the ad hoc channel-based implementation in that post, we can use:type parser struct {  resume func(byte) Status}func (p *parser) Init() {  coparse := func(_ byte, yield func(Status) byte) Status {    read := func() byte { return yield(NeedMoreInput) }    if !parseQuoted(read) {      return BadInput    }    return Success  }  p.resume = coro.New(coparse)  p.resume(0)}func (p *parser) Write(c byte) Status {  return p.resume(c)}The Init funtion does all the work, and not much. It defines a function coparse that has the signature needed by coro.New, which means adding a throwaway input of type byte. That function defines a read that yields NeedMoreInput and then returns the byte provided by the caller. It then runs parseQuoted(read), converting the boolean result to the usual status code. Having created a coroutine for coparse using coro.New, Init calls p.resume(0) to allow coparse to advance to the first read in parseQuoted. Finally the Write method is a trivial wrapper around p.resume (full code).This setup abstracts away the pair of channels that we maintained by hand in the previous post, allowing us to work at a higher level as we write the program.Example: Prime SieveAs a slightly larger example, consider Doug McIlroy's concurrent prime sieve. It consists of a pipeline of coroutines, one for each prime p, each running:loop:  n = get a number from left neighbor  if (p does not divide n)    pass n to right neighborA counting coroutine on the leftmost side of the pipeline feeds the numbers 2, 3, 4, ... into the left end of the pipeline. A printing coroutines on the rightmost side can read primes out, print them, and create new filtering coroutines. The first filter in the pipeline removes multiples of 2, the next removes multiples of 3, the next removes multiples of 5, and so on.The coro.New primitive we've created lets us take a straightforward loop that yields values and convert it into a function that can be called to obtain each value one at a time. Here is the counter:func counter() func(bool) int {  return coro.New(func(more bool, yield func(int) bool) int {    for i := 2; more; i++ {      more = yield(i)    }    return 0  })}The counter logic is the function literal passed to New. It takes a yield function of type func(int) bool. The code yields a value by passing it to yield and then receives back a boolean saying whether to continue generating more numbers. When told to stop, either because more was false on entry or because a yield call returned false, the loop ends. It returns a final, ignored value, to satisfy the function type required by New.New turns this into loop a function that is the inverse of yield: a func(bool) int that can be called with true to obtain the next value or with false to shut down the generator. The filtering coroutine is only slightly more complex:func filter(p int, next func(bool) int) (filtered func(bool) int) {  return coro.New(func(more bool, yield func(int) bool) int {    for more {      n := next(true)      if n%p != 0 {        more = yield(n)      }    }    return next(false)  })}It takes a prime p and a next func connected to the coroutine on the left and then returns the filtered output stream to connect to the coroutine on the right.Finally we have the printing coroutine:func main() {  next := counter()  for i := 0; i < 10; i++ {    p := next(true)    fmt.Println(p)    next = filter(p, next)  }  next(false)}Starting with the counter, main maintains in next the output of the pipeline constructed so far. Then it loops: read a prime p, print p, and then add a new filter on the right end of the pipeline to remove multiples of p (full code).Notice that the calling relationship between coroutines can change over time: any coroutine C can call another coroutine D's next function and become the coroutine that D yields to. The counter's first yield goes to main, while its subsequent yields go to the 2-filter. Similarly each p-filter yields its first output (the next prime) to main while its subsequent yields go to the filter for that next prime.Coroutines and GoroutinesIn a certain sense, it is a misnomer to call these control flows coroutines. They are full goroutines, and they can do everything an ordinary goroutine can, including block waiting for mutexes, channels, system calls, and so on. What coro.New does is create goroutines with access to coroutine switch operations inside the yield and resume functions (which the sieve calls next). The ability to use those operations can even be passed to different goroutines, which is happening with main handing off each of its next streams to each successive filter goroutine. Unlike the go statement, coro.New adds new concurrency to the program without new parallelism. The goroutine that coro.New(f) creates can only run when some other goroutine explicitly loans it the ability to run using resume; that loan is repaid by yield or by f returning. If you have just one main goroutine and run 10 go statements, then all 11 goroutines can be running at once. In contrast, if you have one main goroutine and run 10 coro.New calls, there are now 11 control flows but the parallelism of the program is what it was before: only one runs at a time. Exactly which goroutines are paused in coroutine operations can vary as the program runs, but the parallelism never increases.In short, go creates a new concurrent, parallel control flow, while coro.New creates a new concurrent, non-parallel control flow. It is convenient to continue to talk about the non-parallel control flows as coroutines, but remember that exactly which goroutines are \u201cnon-parallel\u201d can change over the execution of a program, exactly the same way that which goroutines are receiving or sending from channels can change over the execution of a program.Robust ResumesThere are a few improvements we can make to coro.New so that it works better in real programs. The first is to allow resume to be called after the function is done: right now it deadlocks. Let's add a bool result indicating whether resume's result came from a yield. The coro.New implementation we have so far is:func New[In, Out any](f func(in In, yield func(Out) In) Out) (resume func(In) Out) {  cin := make(chan In)  cout := make(chan Out)  resume = func(in In) Out {    cin <- in    return <-cout  }  yield := func(out Out) In {    cout <- out    return <-cin  }  go func() {    cout <- f(<-cin, yield)  }()  return resume}To add this extra result, we need to track whether f is running and return that result from resume:func New[In, Out any](f func(in In, yield func(Out) In) Out) (resume func(In) (Out, bool)) {  cin := make(chan In)  cout := make(chan Out)  running := true  resume = func(in In) (out Out, ok bool) {    if !running {      return    }    cin <- in    out = <-cout    return out, running  }  yield := func(out Out) In {    cout <- out    return <-cin  }  go func() {    out := f(<-cin, yield)    running = false    cout <- out  }()  return resume}Note that since resume can only run when the calling goroutine is blocked, and vice versa, sharing the running variable is not a race. The two are synchronizing by taking turns executing. If resume is called after the coroutine has exited, resume returns a zero value and false.Now we can tell when a goroutine is done (full code):func main() {  resume := coro.New(func(_ int, yield func(string) int) string {    yield(\"hello\")    yield(\"world\")    return \"done\"  })  for i := 0; i < 4; i++ {    s, ok := resume(0)    fmt.Printf(\"%q %v\\n\", s, ok)  }}$ go run cohello.go\"hello\" true\"world\" true\"done\" false\"\" false$Example: Iterator ConversionThe prime sieve example showed direct use of coro.New, but the more bool argument was a bit awkward and does not match the iterator functions we saw before. Let's look at converting any push iterator into a pull iterator using coro.New. We will need a way to terminate the coroutine running the push iterator if we want to stop early, so we will add a boolean result from yield indicating whether to continue, just like in the prime sieve:push func(yield func(V) bool)The goal of the new function coro.Pull is to turn that push function into a pull iterator. The iterator will return the next value and a boolean indicating whether the iteration is over, just like a channel receive or map lookup:pull func() (V, bool)If we want to stop the push iteration early, we need some way to signal that, so Pull will return not just the pull function but also a stop function:stop func()Putting those together, the full signature of Pull is:func Pull[V any](push func(yield func(V) bool)) (pull func() (V, bool), stop func()) {  ...}The first thing Pull needs to do is start a coroutine to run the push iterator, and to do that it needs a wrapper function with the right type, namely one that takes a more bool to match the bool result from yield, and that returns a final V. The pull function can call resume(true), while the stop function can call resume(false):func Pull[V any](push func(yield func(V) bool)) (pull func() (V, bool), stop func()) {  copush := func(more bool, yield func(V) bool) V {    if more {      push(yield)    }    var zero V    return zero  }  resume := coro.New(copush)  pull = func() (V, bool) {    return resume(true)  }  stop = func() {    resume(false)  }  return pull, stop}That's the complete implementation. With the power of coro.New, it took very little code and effort to build a nice iterator converter.To use coro.Pull, we need to redefine the tree's All method to expect and use the new bool result from yield:func (t *Tree[V]) All(yield func(v V) bool) {  t.all(yield)}func (t *Tree[V]) all(yield func(v V) bool) bool {  return t == nil ||    t.Left.all(yield) && yield(t.Value) && t.Right.all(yield)}Now we have everything we need to write a tree comparison function in Go (full code):func cmp[V comparable](t1, t2 *Tree[V]) bool {  next1, stop1 := coro.Pull(t1.All)  next2, stop2 := coro.Pull(t2.All)  defer stop1()  defer stop2()  for {    v1, ok1 := next1()    v2, ok2 := next2()    if v1 != v2 || ok1 != ok2 {      return false    }    if !ok1 && !ok2 {      return true    }  }}Propagating PanicsAnother improvement is to pass panics from a coroutine back to its caller, meaning the coroutine that most recently called resume to run it (and is therefore sitting blocked in resume waiting for it). Some mechanism to inform one goroutine when another panics is a very common request, but in general that can be difficult, because we don't know which goroutine to inform and whether it is ready to hear that message. In the case of coroutines, we have the caller blocked waiting for news, so it makes sense to deliver news of the panic.To do that, we can add a defer to catch a panic in the new coroutine and trigger it again in the resume that is waiting.type msg[T any] struct {  panic any  val  T}func New[In, Out any](f func(in In, yield func(Out) In) Out) (resume func(In) (Out, bool)) {  cin := make(chan In)  cout := make(chan msg[Out])  running := true  resume = func(in In) (out Out, ok bool) {    if !running {      return    }    cin <- in    m := <-cout    if m.panic != nil {      panic(m.panic)    }    return m.val, running  }  yield := func(out Out) In {    cout <- msg[Out]{val: out}    return <-cin  }  go func() {    defer func() {      if running {        running = false        cout <- msg[Out]{panic: recover()}      }    }()    out := f(<-cin, yield)    running = false    cout <- msg[Out]{val: out}  }()  return resume}Let's test it out (full code):func main() {  defer func() {    if e := recover(); e != nil {      fmt.Println(\"main panic:\", e)      panic(e)    }  }()  next, _ := coro.Pull(func(yield func(string) bool) {    yield(\"hello\")    panic(\"world\")  })  for {    fmt.Println(next())  }}The new coroutine yields hello and then panics world. That panic is propagated back to the main goroutine, which prints the value and repanics. We can see that the panic appears to originate in the call to resume:% go run coro.gohello truemain panic: worldpanic: world [recovered]  panic: worldgoroutine 1 [running]:main.main.func1()  /tmp/coro.go:9 +0x95panic({0x108f360?, 0x10c2cf0?})  /go/src/runtime/panic.go:1003 +0x225main.coro_New[...].func1()  /tmp/coro.go.go:55 +0x91main.Pull[...].func2()  /tmp/coro.go.go:31 +0x1cmain.main()  /tmp/coro.go.go:17 +0x52exit status 2%CancellationPanic propagation takes care of telling the caller about an early coroutine exit, but what about telling a coroutine about an early caller exit? Analogous to the stop function in the pull iterator, we need some way to signal to the coroutine that it's no longer needed, perhaps because the caller is panicking, or perhaps because the caller is simply returning.To do that, we can change coro.New to return not just resume but also a cancel func. Calling cancel will be like resume, except that yield panics instead of returning a value. If a coroutine panics in a different way during cancellation, we want cancel to propagate that panic, just as resume does. But of course we don't want cancel to propagate its own panic, so we create a unique panic value we can check for. We also have to handle a cancellation in before f begins.var ErrCanceled = errors.New(\"coroutine canceled\")func New[In, Out any](f func(in In, yield func(Out) In) Out) (resume func(In) (Out, bool), cancel func()) {  cin := make(chan msg[In])  cout := make(chan msg[Out])  running := true  resume = func(in In) (out Out, ok bool) {    if !running {      return    }    cin <- msg[In]{val: in}    m := <-cout    if m.panic != nil {      panic(m.panic)    }    return m.val, running  }  cancel = func() {    e := fmt.Errorf(\"%w\", ErrCanceled) // unique wrapper    cin <- msg[In]{panic: e}    m := <-cout    if m.panic != nil && m.panic != e {      panic(m.panic)    }  }  yield := func(out Out) In {    cout <- msg[Out]{val: out}    m := <-cin    if m.panic != nil {      panic(m.panic)    }    return m.val  }  go func() {    defer func() {      if running {        running = false        cout <- msg[Out]{panic: recover()}      }    }()    var out Out    m := <-cin    if m.panic == nil {      out = f(m.val, yield)    }    running = false    cout <- msg[Out]{val: out}  }()  return resume, cancel}We could change Pull to use panics to cancel iterators as well, but in that context the explicit bool seems clearer, especially since stopping an iterator is unexceptional.Example: Prime Sieve RevisitedLet's look at how panic propagation and cancellation make cleanup of the prime sieve \u201cjust work\u201d. First let's update the sieve to use the new API. The counter and filter functions are already \u201cone-line\u201d return coro.New(...) calls. They change signature to include the additional cancel func returned from coro.New:func counter() (func(bool) (int, bool), func()) {  return coro.New(...)}func filter(p int, next func(bool) (int, bool)) (func(bool) (int, bool), func()) {  return coro.New(...)}Then let's convert the main function to be a primes function that prints n primes (full code):func primes(n int) {  next, cancel := counter()  defer cancel()  for i := 0; i < n; i++ {    p, _ := next(true)    fmt.Println(p)    next, cancel = filter(p, next)    defer cancel()  }}When this function runs, after it has gotten n primes, it returns. Each of the deferred cancel calls cleans up the coroutines that were created. And what if one of the coroutines has a bug and panics? If the coroutine was resumed by a next call in primes, then the panic comes back to primes, and primes's deferred cancel calls clean up all the other coroutines. If the coroutine was resumed by a next call in a filter coroutine, then the panic will propagate up to the waiting filter coroutine and then the next waiting filter coroutine, and so on, until it gets to the p := next(true) in primes, which will again clean up the remaining coroutines.APIThe API we've arrived at is:New creates a new, paused coroutine ready to run the function f. The new coroutine is a goroutine that never runs on its own: it only runs while some other goroutine invokes and waits for it, by calling resume or cancel.A goroutine can pause itself and switch to the new coroutine by calling resume(in). The first call to resume starts f(in, yield). Resume blocks while f runs, until either f calls yield(out) or returns out. When f calls yield, yield blocks and resume returns out, true. When f returns, resume returns out, false. When resume has returned due to a yield, the next resume(in) switches back to f, with yield returning in.Cancel stops the execution of f and shuts down the coroutine. If resume has not been called, then f does not run at all. Otherwise, cancel causes the blocked yield call to panic with an error satisfying errors.Is(err, ErrCanceled).If f panics and does not recover the panic, the panic is stopped in f's coroutine and restarted in the goroutine waiting for f, by causing the blocked resume or cancel that is waiting to re-panic with the same panic value. Cancel does not re-panic when f's panic is one that cancel itself triggered.Once f has returned or panicked, the coroutine no longer exists. Subsequent calls to resume return zero, false. Subsequent calls to cancel simply return.The functions resume, cancel, and yield can be passed between and used by different goroutines, in effect dynamically changing which goroutine is \u201cthe coroutine.\u201d Although New creates a new goroutine, it also establishes an invariant that one goroutine is always blocked, either in resume, cancel, yield, or (right after New) waiting for the resume that will call f. This invariant holds until f returns, at which point the new goroutine is shut down. The net result is that coro.New creates new concurrency in the program without any new parallelism.If multiple goroutines call resume or cancel, those calls are serialized. Similarly, if multiple goroutines call yield, those calls are serialized.func New[In, Out any](f func(in In, yield func(Out) In) Out) (resume func(In) (Out, bool), cancel func())EfficiencyAs I said at the start, while it's important to have a definition of coroutines that can be understood by reference to a pure Go implementation, I believe we should use an optimized runtime implementation. On my 2019 MacBook Pro, passing values back and forth using the channel-based coro.New in this post requires approximately 190ns per switch, or 380ns per value in coro.Pull. Remember that coro.Pull would not be the standard way to use an iterator: the standard way would be to invoke the iterator directly, which has no coroutine overhead at all. You only need coro.Pull when you want to process iterated values incrementally, not using a single for loop. Even so, we want to make coro.Pull as fast as we can.First I tried having the compiler mark send-receive pairs and leave hints for the runtime to fuse them into a single operation. That would let the channel runtime bypass the scheduler and jump directly to the other coroutine. This implementation requires about 118ns per switch, or 236ns per pulled value (38% faster). That's better, but it's still not as fast as I would like. The full generality of channels is adding too much overhead.Next I added a direct coroutine switch to the runtime, avoiding channels entirely. That cuts the coroutine switch to three atomic compare-and-swaps (one in the coroutine data structure, one for the scheduler status of the blocking coroutine, and one for the scheduler status of the resuming coroutine), which I believe is optimal given the safety invariants that must be maintained. That implementation takes 20ns per switch, or 40ns per pulled value. This is about 10X faster than the original channel implementation. Perhaps more importantly, 40ns per pulled value seems small enough in absolute terms not to be a bottleneck for code that needs coro.Pull.",
    "summary": "- Coroutines are a way to run concurrent tasks in Go, allowing for more efficient and structured code.\n- Coroutines differ from regular functions in that they can pause and resume execution, allowing for better coordination and sharing of data.\n- The coroutines package in Go provides a way to implement coroutines, making it easier to write concurrent programs.",
    "hn_title": "Coroutines for Go",
    "original_title": "Coroutines for Go",
    "score": 292,
    "hn_content": "- The post discusses the use of coroutines for function iteration in Go programming.\n- The author explores the need for coroutines in the context of function iterators and how to implement them efficiently.\n- Coroutines offer more predictable scheduling behavior and can improve performance in certain use cases.\n- The implementation of coroutines in Go would provide a cleaner and more flexible way to handle iterators, reducing complexity and potential errors.\n- While coroutines can be more efficient for certain tasks, they should be used specifically for iteration purposes, rather than in place of other concurrency mechanisms.\n- The proposed coroutines package would be an optimized implementation provided directly by the Go runtime.- Kotlin's co-routines library uses functions extensively to provide co-routine implementations on different platforms\n- Co-routines allow for treating reactive, green threads, and real threads in the same way with a robust set of abstractions\n- The debate between co-routines and go-routines in Go can provide some learning opportunities for both sides\n- The `Sequence` type in Kotlin pre-dates co-routines, but the `sequence` builder function depends on co-routines\n- Python had general coroutines first, which were mostly used for iteration and state machines, and later specialized async-await as a language feature\n- JS evolved similarly, with generators being (ab)used for concurrency and then specialized async-await as a language feature\n- Coroutines are not necessarily executed in any order and are not related to multithreading\n- Coroutines have their origins in structuring assembly programs and have been implemented in Lua\n- Goroutines in Go are non-blocking, but channels may not always be\n- Some readers express concerns about the control flow and complexity of the proposed code and dislike function coloring in Python and JavaScript",
    "hn_summary": "- The post discusses the use of coroutines for function iteration in Go programming. The author explores the need for coroutines in the context of function iterators and how to implement them efficiently.\n- Coroutines offer more predictable scheduling behavior and can improve performance in certain use cases. The implementation of coroutines in Go would provide a cleaner and more flexible way to handle iterators, reducing complexity and potential errors.\n- While coroutines can be more efficient for certain tasks, they should be used specifically for iteration purposes, rather than in place of other concurrency mechanisms."
  },
  {
    "id": 36758355,
    "timestamp": 1689602473,
    "title": "The force that shapes everything around us: Parking",
    "url": "https://www.vox.com/23712664/parking-lots-urban-planning-cities-housing",
    "hn_url": "http://news.ycombinator.com/item?id=36758355",
    "content": "Help keep Vox freeReader support helps keep our explainers free for all. Support our mission by making a gift today.\u00d7Yes, I'Ll GiveThere are at least four parking spaces for every car in the United States, meaning that the parking stock is never more than 25 percent full at any given time. Andrii Chagovets/iStock/Getty ImagesFILED UNDER:TRANSPORTATIONThe hidden force that shapes everything around us: ParkingIt\u2019s fueling the affordable housing crisis, worsening flooding, and driving us nuts.By Marin Cogan@marincogan May 9, 2023, 7:30am EDTShare this storyShare this on FacebookShare this on TwitterSHAREAll sharing optionsMarin Cogan is a senior correspondent at Vox. She writes features on a wide range of subjects, including traffic safety, gun violence, and the legal system. Prior to Vox, she worked as a writer for New York magazine, GQ, ESPN the Magazine, and other publications.Most Americans, especially those living outside of major cities, need to drive to get around, and so the need to put one\u2019s car somewhere when we\u2019re not using it \u2014 ideally somewhere safe, free, and convenient \u2014 is a quiet force that often dominates how we get around. But how parking works (or doesn\u2019t work) is something we rarely stop to consider.Henry Grabar, a staff writer at Slate, has done a lot of thinking about the issue. In his new book, Paved Paradise: How Parking Explains the World, Grabar demonstrates in a fascinating way how parking shapes our lives in the United States, determining the kinds of homes we live in, the communities we build, and how we interact with our built environments. He shows how zoning requirements requiring off-street parking for new construction strangle new development and help fuel the affordable housing crisis. Finally, he offers a series of solutions to make our cities more affordable and livable \u2014 and to keep parking from driving us all mad.This interview has been edited for length and clarity.Why does parking make us so crazy?That is the million-dollar question. I think there are a few reasons that parking makes people really upset, but perhaps the most obvious is that in almost every place in this country, it is obligatory to have a car, and there is almost nothing that you can do without a car. So to the extent that you are able to hold down a job or go to a restaurant or pick your kids up from school, you have to drive, and parking becomes the link between driving and whatever else you want to do with your life. And so naturally, there\u2019s a great deal of importance placed on having a good parking space.That\u2019s the first thing. And then the second one is that we have just catastrophically mismanaged the way we provide parking in this country, in a way that actually doesn\u2019t make things better for people who are driving and parking. Parking is not shared, and it\u2019s not properly priced. We have acquiesced to the idea that parking on city streets has to be a total free-for-all.As you point out in the book, you\u2019re not just talking about this symbolically. People have actually died over arguments about parking spots.Oh yeah, all the time. When I started working on this book, I set up a Google alert for \u201cparking space murder.\u201d So that\u2019s been how I\u2019ve been keeping track of this. I\u2019m really excited to turn that Google alert off now that the reporting is done. The first person to be killed in New York City this year was actually killed over a parking space. I estimate that it happens several dozen times a year in US cities.How did you get interested in parking?In my work as a reporter, I was writing about cities, and it seemed like every topic that I would come across had this hidden component to it that was determinative in the result of whatever was being discussed, and that issue was parking. When I went to Houston to report on Hurricane Harvey, I talked to a guy whose house had flooded for the first time, and he was saying that his house never used to flood and he was blaming it on an enormous parking lot that had been constructed and the displacement of water falling on that parking lot, and how that was contributing to the stormwater issue in his neighborhood. And this is a widespread issue in Houston \u2014 the city\u2019s brand of sprawling, auto-centric development does involve paving over a ton of land. That\u2019s just an example.Parking is really expensive, and the obligation to provide parking can break projects that would otherwise succeed. Mass transit, the ability to create bus rapid transit lanes, or even to create bike lanes is dependent on being willing to reallocate the street parking supply.When you think about its spatial impact, well, cars spend 95 percent of their time parked. Parking literally takes up more room than the roads, and it costs more than the automobiles. But many of us don\u2019t think much about parking at all, or if we do, it\u2019s an afterthought.Is the problem that we have too little parking or too much?I will give you an annoying answer: It depends. On a national level, certainly, there\u2019s far more parking than we need. There are at least four parking spaces for every car, meaning that the parking stock is no more than 25 percent full at any given time. And some of those cars are moving at any given time, so parking may be a good deal emptier than that.Of course, there are places where people get frustrated because there isn\u2019t enough parking. So if what you\u2019re interested in is having a free place to park, you could look at this situation and say, well, there isn\u2019t enough parking. In fact, that\u2019s sort of what we did as a country: We decided, at some point in the middle of the 20th century, that there wasn\u2019t enough parking, that this was at the root of our traffic problem, and we had to create more parking. But you can only do so at great expense, and at a tremendous cost to the urban fabric. There may be places where there isn\u2019t enough parking, but the solution is rarely to create more parking, but rather to more intelligently manage the parking that we have and try and find ways to control demand for parking by, for example, sharing it, pricing it, and telling people where it is.What does that look like?When somebody decides they want to open a new restaurant or open a new building, instead of saying it needs X number of spaces, we could say, let\u2019s look at the parking stock and find accommodations that are already there. Office parking could be used at night for residential parking. That dentist\u2019s office parking lot could become the parking lot for a restaurant.The other part is pricing. If you institute a parking fee, you\u2019ll find out exactly how many people are willing to pay to park there. If you keep raising prices until you always have spots available, you\u2019ll find out exactly how high it needs to be to create a few open spots on every block. Because it might seem like it only takes you a couple of minutes to find a spot for free, but the net effect is thousands of miles of driving every day across the United States. There\u2019s an unbelievable amount of driving being done just looking for parking spaces. You can look up a restaurant and look at exactly how to get there, but finding good parking is dependent on local knowledge. If you want to park downtown, you should be able to know it\u2019s going to cost this much, and you can do it here \u2014 that should be made clear at every highway exit to downtown. But it\u2019s not.Is the implication that parking is going to have to get more annoying in places where everyone wants to park, like busy urban commercial areas?I don\u2019t think it should be more annoying. We\u2019ve become so accustomed to the idea that you have to hunt for parking that it\u2019s hard for people to wrap their heads around the idea that it will be easier. Yes, you\u2019re going to have to pay for it, but no, you don\u2019t have to stress anymore because you\u2019ll know there\u2019ll be a parking spot where you want it. That\u2019s a new concept, but in the places where it\u2019s been instituted, people seem to have found it agreeable. There is a way, even without eliminating any parking, that a little bit of management can make a smoother parking experience for everyone. Time is money, and circling around the block and not knowing when you can find a spot, or leaving 20 minutes early to find a spot to park, that\u2019s a cost as well.How does parking affect our housing supply?There are two principal ways that parking affects the housing supply. The first is that many jurisdictions in this country have parking requirements for new housing. That places a geometric and financial constraint on the types of things that can be built. And then what gets built contains a lot of parking, and the cost of that parking is folded into the cost of the units, whether they\u2019re being sold or rented. And this is a pretty significant cost. In California and Arizona, it adds tens of thousands of dollars onto the cost of every new low-income housing unit. It\u2019s folded into the rent or the asking price, whether you drive a car or not.Parking functions as a third rail in neighborhood politics. The public parking supply is such a fixation that people oppose new projects, especially projects that don\u2019t have \u201cenough\u201d parking, on the grounds that they\u2019ll threaten that public parking supply, whereas if I were to say, \u201cI don\u2019t want poor people living in the neighborhood,\u201d that would be considered unacceptable. I cite this survey in the book of baby boomers, and more than half of baby boomers say that free parking is more important than affordable housing in their neighborhood.How did we mess this up so bad?I think that parking requirements were done with the best of intentions. At its roots, it was really thought that it would solve the traffic problems in congested neighborhoods that were caused, [mid-century urban planners] thought, by not having enough parking. This was the situation in American cities in the 1940s and \u201950s: It was just unbelievable traffic jams, which city planners concluded were caused by the fact that there wasn\u2019t enough parking. So lots and lots of parking was provided. The thing that they probably couldn\u2019t have anticipated was just how thoroughly it would remake the urban environment, and how expensive it would be, and the extent to which it would begin to constrain the types of housing we could build.What more recent research proves is that the more parking you provide, the more people will drive, and parking is perhaps the greatest determinant of whether people decide to make a trip in a car or by some other means. So providing more parking does not actually make it easier to park. If parking actually encourages people to drive, then more parking is actually going to create more traffic, not soak up the traffic of people looking for parking.Some places have gotten rid of parking minimums, or requirements that new construction have a certain number of parking spots, in the last few years. I\u2019m curious if you can talk a little bit about what the results have been in those communities.There\u2019s been a ton of movement on this in the last five years. It\u2019s kind of amazing, dozens of cities deciding that they no longer want to require people to build a certain amount of parking corresponding to land use. One of the best examples is in Seattle, where in 2012 they decided to stop requiring parking for new apartment buildings around transit. This was right at a period when residential construction in Seattle was booming. And they approved 60,000 units between 2012 and 2017. Most of them still have parking \u2014 I mean, developers know people who move into their buildings want space to park their cars \u2014 but they built 40 percent less parking than would have been required under the old regime. And that meant they built 18,000 fewer parking spaces, and the amount of money saved from that, which we can assume went into cheaper apartments and lower rent, was $540 million: half a billion dollars saved just by not building quite so many parking spaces.What else can we do?If you could imagine a paradigm in which parking was a little less important, and we needed a little less of it, you can do so much with the land that we have currently reserved for parking lots. The more spectacular opportunity is with curb parking in cities, where we\u2019ve got some of the most valuable real estate on earth, and that is really crucial in shaping people\u2019s perception and understanding and enjoyment of the places they live in. You saw this during Covid, with the [outdoor] restaurant pop-ups; to even have 12 people outside sitting and having coffee on the street is just tremendous. That\u2019s only the tip of the iceberg, right?You could imagine a world in which streets were pedestrianized and where we planted trees and gardens and in what is currently space reserved for parking, and closed streets, outside schools, so kids can have places to play. I think all those things are within reach. Those aren\u2019t even particularly expensive or ambitious ideas. They just depend on 25 car owners saying, all right, we\u2019ll give up our rights to this little strip of land. The changes to parking on surrounding streets would probably be pretty marginal, if you consider 25 cars in neighborhood parking stock that\u2019s probably in the thousands.Will you help keep Vox free for all?As we approach the 2024 American presidential election, every person deserves clarity on who and what they're voting on \u2014 not just the people who can afford to pay for a subscription. That's why, at Vox, we publish our work without a paywall. Millions of people rely on us for clear, accessible information about the race and the issues at stake. Will you help keep Vox free for all by making a gift today?One-Time Monthly Annual$95/year$120/year$250/year$350/yearOtherYes, I'll give $120/yearWe accept credit card, Apple Pay, and Google Pay. You can also contribute via2024 ELECTIONSCould a third-party candidate actually derail Biden?CLIMATEWhy Canada\u2019s wildfires will affect air quality for weeks to come2024 ELECTIONSAre the Republican presidential contenders serious about winning over Latino voters?View all stories in PoliticsAbout usOur staffPrivacy policyEthics & GuidelinesHow we make moneyContact usHow to pitch VoxVox Media Vox Media logo.Terms of Use Privacy Notice Cookie Policy Do Not Sell or Share My Personal Info Licensing FAQ Accessibility Platform Status Advertise with us Jobs @ Vox MediaAuthor Login\u00a9 2023 Vox Media, LLC. All Rights Reserved",
    "summary": "- Parking is a crucial but often overlooked aspect of transportation in the United States, affecting how we live, build communities, and interact with our environment.\n- The current approach to providing parking in the US is flawed, with parking not being shared or properly priced, leading to frustrations and even conflicts.\n- Solutions to the parking problem include smarter management of existing parking spaces, such as sharing and pricing them, as well as reimagining the use of land currently reserved for parking to create more livable and enjoyable spaces.",
    "hn_title": "The force that shapes everything around us: Parking",
    "original_title": "The force that shapes everything around us: Parking",
    "score": 244,
    "hn_content": "- An interview with a designer of SimCity reveals how parking lots were a surprising feature that had to be creatively addressed in the game\n- The excess of cars in cities is acknowledged, and the idea of underground parking as a potential solution is discussed\n- Underground parking may be more expensive, but it could free up valuable urban space and eliminate eyesores\n- The car-centric culture in many cities has made it difficult to transition to more pedestrian-friendly environments, but steps can still be taken to reduce the negative impact of cars\n- Public transportation, zoning, and urban design can all play a role in creating more walkable cities\n- Some comments discuss the need for realistic parking simulations in urban planning games like SimCity\n- The importance of public transportation and the need for cultural shifts in American cities are mentioned.- The lack of walkability and poor public transportation infrastructure in some towns and cities can make it difficult for people to travel without a car.\n- Many working-class people are forced to commute long distances because affordable housing is often located in the suburbs or satellite cities.\n- The availability of reliable public transit would greatly benefit working-class individuals, saving them time and allowing them to spend more time with their families.\n- Converting certain areas to pedestrian-only zones can improve walkability and reduce the reliance on cars, but it can be a challenging process that requires careful planning and consideration.\n- The cost of housing is a significant factor in people being pushed out of cities, leading to displacement and the need for longer commutes.\n- The rise of platforms like Airbnb has led to an increase in the number of vacant properties and short-term rentals, exacerbating the housing crisis in some areas.\n- It is possible to convert certain streets to pedestrian-only areas while still maintaining car accessibility through the construction of low-cost parking garages nearby.\n- The shift towards pedestrian-friendly cities requires long-term planning and gradual changes, as heavy car traffic is a stable system that is unfriendly to pedestrians and cyclists.\n- The cost of car ownership can be significant, and alternative transportation options like biking and public transit can result in significant savings.\n- Cities like New York and Boston have made efforts to improve bike infrastructure, making it more feasible and convenient for people to bike for transportation.\n- The availability of parking is often a significant determining factor in whether people choose to drive or use alternative transportation methods.\n- The use of cars and the demand for parking can lead to the erosion of central business districts and impact the accessibility and vibrancy of urban areas.",
    "hn_summary": "- The interview with a designer of SimCity reveals the creative addressing of parking lots in the game and the potential solution of underground parking to free up urban space.\n- Steps can be taken to reduce the negative impact of cars in cities through public transportation, zoning, and urban design.\n- The lack of walkability, poor public transportation infrastructure, and high cost of housing are challenges that contribute to the reliance on cars and the need for longer commutes, impacting working-class individuals and the vibrancy of urban areas."
  }
]
