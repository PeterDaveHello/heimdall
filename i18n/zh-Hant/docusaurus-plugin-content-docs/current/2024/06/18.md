---
slug: '/2024/06/18'
---

# 2024-06-18

## [必須立即停止聊天控制](https://threema.ch/en/blog/posts/stop-chat-control)

- 歐盟委員會的「聊天控制」提案旨在實施大規模監控，可能會損害公民的隱私和數據安全。
- 如果通過，這將要求服務提供商掃描訊息中的兒童性虐待材料(CSAM)，但批評者認為這對犯罪分子無效，並且對民主有害。
- Threema，一個安全的通訊服務，反對該提案，並可能為了避免遵守而離開歐盟，這突顯了潛在的濫用問題以及隱私倡導者的反對意見。

### [反應](https://news.ycombinator.com/item?id=40715449)

- 實施一個全球系統來監管互聯網隱私將面臨隱私倡導者和科技公司的巨大阻力。
- 由於各國對隱私和互聯網自由的承諾程度不同，在全球範圍內強制執行這樣的系統幾乎是不可能的。

## [聊天控制：與基本權利不相容 (2022)](https://freiheitsrechte.org/en/themen/digitale-grundrechte/chatkontrolle)

- 歐盟委員會的《聊天控制條例》草案旨在打擊兒童性暴力，但引發了對基本權利的重大擔憂。
- 重點問題包括隱私侵犯、對自由表達的寒蟬效應、容易出錯的過濾義務、網站封鎖和強制年齡驗證。
- GFF認為這些措施違反了《歐盟基本權利憲章》，並呼籲重新考慮該草案法規。

### [反應](https://news.ycombinator.com/item?id=40715695)

- 「歐洲議會正在辯論一項可能侵犯基本權利的“聊天控制”立法，該立法要求用戶選擇加入才能發送圖片和視頻。」
- 批評者認為，該提案與歐盟的《通用數據保護條例》(GDPR)原則相矛盾，可能導致被迫同意，從而引發對隱私和政府過度干預的擔憂。
- 該立法可能很快會由歐洲理事會通過，引發對大規模監控的擔憂，並質疑歐盟對保護個人權利的承諾。

## [歐盟將於明天批准聊天控制](https://www.patrick-breyer.de/en/council-to-greenlight-chat-control-take-action-now/)

- 歐盟理事會將於2024年6月20日就涉及大規模搜索私人通信的聊天控制進行投票。
- 投票的時間安排在歐洲選舉之後不久，被視為試圖避免公眾監督。
- 公民社會被敦促立即行動，通過聯繫他們的政府、在網上提高意識和組織抗議活動，因為目前的草案被認為是不可接受的。

### [反應](https://news.ycombinator.com/item?id=40710993)

- 歐盟準備批准“聊天控制”，這是一項規定，要求對Reddit、Twitter、Discord和Steam等平台上的所有直接消息進行掃描，以檢查兒童性虐待材料(CSAM)。
- 批評者認為這項措施是前所未有的，可能無效，因為違法者可能會轉向私人服務，並且這引發了重大的隱私和過度干預的擔憂。
- Signal 基金會已宣布，如果該法規被強制執行，將退出歐盟，這突顯了該提案的爭議性。

## [已發布 Htmx 2.0.0](https://htmx.org/posts/2024-06-17-htmx-2-0-0-is-released/)

- htmx 2.0.0 已經發布，結束對 Internet Explorer 的支持，並在不改變核心功能或 API 的情況下收緊了一些默認設置。
- 主要變更包括將擴展移至新倉庫、移除已棄用的屬性以及修改 HTTP DELETE 請求處理。
- 「此版本在 2025 年 1 月 1 日之前不會在 NPM 上標記為最新版本，以避免強制升級；在此之前，1.x 版本將保持為最新版本。」

### [反應](https://news.ycombinator.com/item?id=40709769)

- 已發布 Htmx 2.0.0，主要進行了清理工作並停止支援 Internet Explorer (IE)，而不是新增重大功能。
- 開發者們讚揚 htmx 簡化了網頁開發，一位用戶用幾個 htmx 屬性取代了 500 行 JavaScript (JS) 代碼，提高了效率和樂趣。
- 這次發布引發了關於潛在改進和與其他工具比較的討論，突顯了htmx在減少對複雜JS框架依賴方面的作用。

## [網絡稻草人](https://www.cyberscarecrow.com/)

- “Scarecrow 是一款目前處於 alpha 階段的網絡安全工具，旨在在您的電腦背景中運行，以防止病毒和惡意軟件。”
- 它可在 Windows 10 和 11 上下載。

### [反應](https://news.ycombinator.com/item?id=40715250)

- 網絡稻草人是一種工具，它創建假進程和註冊表項來欺騙惡意軟件，使其認為正在被分析，從而阻止其執行。
- 用戶對該工具的透明度表示擔憂，包括缺少“關於我們”頁面、GitHub鏈接和代碼簽名證書。
- 作者已經承認了這些問題，提到證書的高成本，並且有建議將該工具開源，以建立信任並通過實際測試驗證其有效性。

## [“對Fandom的注意力攻擊”](https://j3s.sh/thought/stop-using-fandom.html)

- Fandom，一個受歡迎的維基網站，因為侵入性廣告(包括自動播放視頻和不斷的打擾)而受到批評，優先考慮利潤而非用戶體驗。
- 「在2023年，Fandom有爭議地用麥當勞的Grimace Shake廣告取代了用戶內容，導致大量維基遷移到獨立域名，如Runescape、Minecraft和Hollow Knight。」
- 鼓勵用戶通過使用像Indie Wiki Buddy這樣的工具、使用廣告攔截器以及將他們的維基從Fandom遷移來支持獨立維基。

### [反應](https://news.ycombinator.com/item?id=40711086)

- 社群正在將他們的維基從Fandom遷移到自託管或替代平台，因為Fandom上有侵入性廣告和過時的內容。
- “值得注意的例子包括Runescape和Minecraft的維基，它們已成功從Fandom轉移。”
- “像 Indie Wiki Buddy 和 LibRedirect 這樣的工具通過將用戶重定向到更友好的來源，幫助用戶避免使用 Fandom，強調了風險投資對用戶驅動內容平台的不利影響。”

## [在 Arc-AGI 上使用 GPT-4o 獲得 50% (SoTA)](https://redwoodresearch.substack.com/p/getting-50-sota-on-arc-agi-with-gpt)

### [反應](https://news.ycombinator.com/item?id=40711484)

- Ryan 在 GPT-4o 上達到 Arc-AGI 公共評估集 50% 的工作被認為在「大型語言模型推理」研究領域中是新穎且有趣的。
- 該方法涉及生成大約8,000個Python程序來實現轉換，選擇正確的程序，並將其應用於測試輸入，展示了深度學習(DL)和程序綜合的混合體。
- 雖然結果令人鼓舞，但它是基於公共評估集的，尚未在私人集上驗證類似的結果，這表明需要進一步的審查和驗證。

## [來自DeepComputing的新RISC-V主板](https://frame.work/blog/introducing-a-new-risc-v-mainboard-from-deepcomputing)

- DeepComputing 推出了一款適用於 Framework Laptop 13 的新型 RISC-V 主板，該主板配備了來自 StarFive 的 JH7110 處理器，擁有來自 SiFive 的四個 U74 RISC-V 核心。
- 此項發展通過允許用戶選擇不同的處理器架構，促進了靈活性和個性化，從而增強了框架生態系統。
- 主板針對開發者和愛好者，將在歐洲RISC-V峰會上進行演示，並通過與Canonical和Red Hat的合作來支持強大的Linux兼容性。

### [反應](https://news.ycombinator.com/item?id=40718124)

- DeepComputing 推出了一款適用於 Framework 筆記型電腦的新 RISC-V 主板，配備 JH7110 處理器和 microSD 存儲，外觀類似於 Framework 形態的 RISC-V 單板電腦 (SBC)。
- 主板針對開發者和愛好者，提供模組化設計和在 x86 與 RISC-V 板之間切換的潛力，儘管與 x86 相比，性能會有顯著下降。
- “這次 Framework 和 DeepComputing 之間的合作被視為多元化和擴展 Framework 生態系統的一步，增加了 RISC-V 技術的可見度。”

## [Sam Altman 不在 YC 的董事會中。那麼為什麼聲稱自己是主席呢？](https://www.bizjournals.com/sanfrancisco/inno/stories/news/2024/04/15/sam-altman-y-combinator-board-chair.html)

- 薩姆·奧特曼，前Y Combinator總裁兼首席執行官，在SPAC(特殊目的收購公司)文件中聲稱自己是其董事會主席。
- “Y Combinator 否認了阿特曼的說法，稱他從未在其董事會中任職，儘管他在公司中扮演了重要角色。”

### [反應](https://news.ycombinator.com/item?id=40710417)

- 「薩姆·阿特曼(Sam Altman)，前Y Combinator(YC)首席執行官和總裁，在多份官方文件中被錯誤地列為YC的主席，包括美國證券交易委員會(SEC)的文件和一家特殊目的收購公司(SPAC)網站。」
- 這個錯誤引發了辯論，有些人認為這只是小的文書錯誤，而另一些人則強調在美國證券交易委員會(SEC)文件中出現不準確信息的法律影響。
- 批評者指出，這些錯誤如果是故意的，可能會被視為誤導並削弱信任，儘管證明意圖和實質性損害是複雜的。

## [“人類在60萬年前開始迅速積累技術知識”](https://news.asu.edu/20240617-science-and-technology-asu-study-points-origin-cumulative-culture-human-evolution)

- 亞利桑那州立大學的研究人員指出，大約在60萬年前，人類通過社會學習開始迅速積累技術知識，這標誌著累積文化的起源。
- “這項研究發表在《美國國家科學院院刊》上，分析了超過330萬年的石器製造技術，並指出在大約60萬年前複雜性顯著增加。”
- 這個時期，可能在中更新世時期，也見證了如控制使用火和建造木製結構等進步，這表明累積文化早於尼安德塔人和現代人類的分化。

### [反應](https://news.ycombinator.com/item?id=40711284)

- 人類大約在60萬年前開始收集技術知識，可能有多個智人物種共享和交流技術。
- “‘人類’這個術語可以指現代人類和整個人屬，但‘古人類’更為精確；關於尼安德特人和丹尼索瓦人是否被視為人類，存在爭議。”
- 知識的快速積累與通信的進步有關，可能包括早期形式的語言，這突顯了語言在技術轉移中的作用。

## [400 多個 LLM 的代幣價格計算器](https://github.com/AgentOps-AI/tokencost)

- Tokencost 是一個實用程式庫，旨在通過計算提示和完成中的標記數量並應用特定模型的定價來估算與大型語言模型 (LLM) 相關的成本。
- 它解決了在各種模型和定價方案中跟蹤成本的挑戰，通過提供實時成本估算幫助用戶避免意外賬單。
- “由AgentOps開發的Tokencost現在是開源的，允許開發者將其整合到他們的項目中以更好地管理成本。”

### [反應](https://news.ycombinator.com/item?id=40710154)

- Tokencost 是一個實用程式庫，旨在通過計算提示和完成中的標記數量並乘以模型成本來估算超過 400 個大型語言模型 (LLM) 的成本。
- 由AgentOps開發並開源，它幫助開發者追蹤支出並避免意外賬單，使用簡單的成本字典和實用函數。
- “用戶建議改進，例如增加對 Rust 的支持、標準化成本以及包括圖像和函數調用成本，儘管對於沒有公開分詞器的模型，準確性仍然存在顧慮。”

## [Sei 支付了 200 萬美元的漏洞賞金](https://usmannkhan.com/bug%20reports/2024/06/17/sei-bug-report.html)

- 在2024年4月，Sei Network的第一層區塊鏈中報告了兩個關鍵漏洞，影響了鏈的可用性和完整性。
- Sei 基金會分別為這些漏洞報告頒發了 $75,000 和 $2,000,000，這些漏洞在產品發布前已被識別並修復，確保沒有資金處於風險中。
- Sei 基金會的積極措施和快速反應防止了 Sei 代幣市值的潛在危險，展示了對用戶保護的強烈承諾。

### [反應](https://news.ycombinator.com/item?id=40710201)

- Sei Network 已支付了 200 萬美元的漏洞賞金，突顯了加密貨幣領域中發現安全漏洞的重大財務激勵。
- “漏洞賞金是通過Immunefi處理的，這是一個專門處理加密漏洞賞金的平台，經常看到超過100萬美元的支付。”
- 這筆支付強調了在加密貨幣行業中安全性的重要性，因為潛在漏洞的成本相比傳統金融可能是天文數字。

## [Google DeepMind從研究實驗室轉型為AI產品工廠](https://www.bloomberg.com/news/articles/2024-06-17/google-deepmind-shifts-from-research-lab-to-ai-product-factory)

### [反應](https://news.ycombinator.com/item?id=40711600)

- Google DeepMind 正從一個研究實驗室轉變為一個人工智慧產品工廠，這引發了關於這一轉變的挑戰和潛在陷阱的辯論。
- 批評者認為，將來自 Google 的經驗豐富的產品團隊與 DeepMind 的研究整合在一起，可能比將研究機構轉變為以產品為中心的實體更有效。
- 擔憂包括對基礎研究的影響以及生產倉促、不成熟產品的風險，儘管有些人認為這一轉變可能會導致人工智慧產品的重大進展。

## [從LLMs獲取結構化輸出的每一種方法](https://www.boundaryml.com/blog/structured-output-from-llms)

- 這篇文章探討了從大型語言模型(LLMs)獲取結構化輸出(如 JSON)的挑戰，因為這些模型通常以自然語言返回回應。
- 它提供了對各種框架的詳細比較，這些框架旨在將LLM輸出轉換為結構化格式，並根據語言支持、JSON處理、提示控制和支持的模型提供者等標準進行評估。
- “比較的框架包括 BAML、Instructor、TypeChat、Marvin、Outlines、Guidance、LMQL、JSONformer、Firebase Genkit、SGLang 和 lm-format-enforcer，每個框架在處理結構化數據提取方面都有其獨特的功能和能力。”

### [反應](https://news.ycombinator.com/item?id=40713952)

- BAML 的文章探討了從大型語言模型 (LLM) 獲取結構化輸出的方法，強調了 BAML 處理格式錯誤的 JSON 的獨特解析方法。
- BAML 提供開源和付費功能，付費選項專注於監控和增強 AI 管道。
- 這篇文章比較了各種框架，並討論了在強制結構化輸出時的挑戰和權衡，指出有些用戶更喜歡像 Pydantic 這樣的簡單方法來進行 JSON 驗證。

## [關於基本複雜性的一點說明](https://olano.dev/blog/a-note-on-essential-complexity)

- 軟體工程師有多個重疊且有時相互衝突的目標，例如編寫代碼、管理複雜性和滿足客戶需求。
- 本質複雜性是問題本身固有的，而偶然複雜性則來自於性能問題或次優工具；減少這兩者都是至關重要的。
- “資深工程師可以通過挑戰假設和與利益相關者協商來重新定義問題，從而有可能簡化需求並減少複雜性。”

### [反應](https://news.ycombinator.com/item?id=40711661)

- 軟體工程師有時會擁抱複雜性來證明他們的角色，這在像企業Java、.NET和JavaScript(JS)這樣的社群中可以看到。
- 這篇文章幽默地提及了Stroustrup的C++諷刺作品，以強調程式語言中的故意複雜性。
- “它認為，最小化複雜性對於良好的工程至關重要，平衡短期和長期決策，並確保一致性以避免不必要的複雜化。”

<head>
  <meta property="og:title" content="必須立即停止聊天控制" />
  <meta property="og:type" content="website" />
  <meta property="og:image" content="https://og.cho.sh/api/og/?title=%E5%BF%85%E9%A0%88%E7%AB%8B%E5%8D%B3%E5%81%9C%E6%AD%A2%E8%81%8A%E5%A4%A9%E6%8E%A7%E5%88%B6&subheading=2024%E5%B9%B46%E6%9C%8818%E6%97%A5%20%E6%98%9F%E6%9C%9F%E4%BA%8C%3A%20%E9%A7%AD%E5%AE%A2%E6%96%B0%E8%81%9E%E6%91%98%E8%A6%81" />
</head>
