---
slug: '/2024/05/29'
---

# 2024-05-29

## [Fones de ouvido com IA isolam um único alto-falante em meio a multidões por meio da detecção do olhar](https://www.washington.edu/news/2024/05/23/ai-headphones-noise-cancelling-target-speech-hearing/)

- A Universidade de Washington (UW) desenvolveu um sistema de IA chamado "Target Speech Hearing" que ajuda os usuários a se concentrarem em um único orador em ambientes ruidosos, olhando para ele por três a cinco segundos.
- Apresentado na Conferência ACM CHI, esse sistema usa o aprendizado de máquina para isolar e amplificar a voz do locutor desejado em tempo real, mesmo quando o usuário se move.
- Atualmente no estágio de prova de conceito, a tecnologia foi testada em 21 indivíduos que relataram uma melhora significativa na clareza, com planos futuros de expansão para fones de ouvido e aparelhos auditivos.

### [Reações](https://news.ycombinator.com/item?id=40508278)

- O texto explora estratégias e tecnologias para melhorar as experiências auditivas em ambientes ruidosos, com foco em fones de ouvido com IA, design de som avançado e tecnologias de cancelamento de ruído.
- Ele destaca os desafios dos materiais dos restaurantes modernos que contribuem para o ruído e o uso de técnicas de amortecimento de som, apesar dos problemas estéticos e de manutenção.
- Os avanços tecnológicos, como microfones direcionais, reconhecimento de fala em tempo real e filtragem seletiva de som, são discutidos, juntamente com as preocupações com a privacidade e o possível uso indevido.

## [Ex-membro da diretoria da OpenAI revela mentiras e má conduta por trás da breve destituição de Sam Altman](https://www.businessinsider.com/openai-board-member-details-sam-altman-lied-allegation-ousted-2024-5)

- Helen Toner, ex-membro da diretoria da OpenAI, revelou que Sam Altman foi brevemente removido do cargo de CEO devido a vários casos de desonestidade e retenção de informações da diretoria.
- Os exemplos incluíram o fato de a diretoria ter tomado conhecimento do lançamento do ChatGPT pelo Twitter e de Altman não ter revelado seu interesse financeiro na empresa, além de acusações de fornecimento de informações de segurança imprecisas e de "abuso psicológico" por parte de dois executivos.
- Altman foi reintegrado ao cargo de CEO menos de uma semana depois, após os funcionários ameaçarem se demitir e a Microsoft manifestar interesse em contratar sua equipe; Toner pediu demissão logo após seu retorno.

### [Reações](https://news.ycombinator.com/item?id=40506582)

- O CEO da OpenAI, Sam Altman, foi brevemente destituído e depois recontratado, expondo as tensões entre a autoridade da diretoria e a influência dos principais investidores e fundadores.
- A forma inadequada como a diretoria lidou com a demissão de Altman levou a uma reação significativa dos funcionários e a ameaças de demissão em massa, ressaltando a complexa dinâmica da governança corporativa, a influência dos funcionários e os interesses financeiros.
- O incidente provocou discussões mais amplas sobre liderança em tecnologia, implicações éticas do comportamento impiedoso e o papel da comunicação e da ética na governança corporativa.

## [Reconsiderando o redirecionamento de HTTP para HTTPS para APIs para aumentar a segurança](https://jviide.iki.fi/http-redirects)

- O redirecionamento de HTTP para HTTPS pode expor dados confidenciais ou permitir ataques de MITM (Man-In-The-Middle), especialmente para APIs acessadas por software que pode não lidar com cabeçalhos de segurança.
- Técnicas como o HSTS (HTTP Strict Transport Security) e os modos HTTPS-Only melhoram a segurança, mas podem não ser suficientes para as APIs, destacando a necessidade de uma abordagem rápida para detectar erros antecipadamente.
- As práticas recomendadas devem ser atualizadas para recomendar que as APIs rejeitem totalmente as solicitações não criptografadas e revoguem as credenciais de API enviadas por conexões não criptografadas para evitar riscos à segurança.

### [Reações](https://news.ycombinator.com/item?id=40504756)

- A discussão enfatiza o aprimoramento da segurança da API, redirecionando o HTTP para HTTPS e revogando as chaves de API enviadas por HTTP para evitar ataques Man-in-the-Middle (MITM).
- Ele destaca a importância do gerenciamento adequado de chaves de API, usando hashes assinados, nonces e carimbos de data/hora para autenticação, e a necessidade de HTTPS para integridade e privacidade dos dados.
- A conversa critica a dependência de autoridades de certificação e sugere soluções práticas, como URLs exclusivos ou chaves de API para controle de acesso seguro em contextos específicos.

## [Llama3-V: Um modelo multimodal de US$ 500 que supera o GPT-4V em desempenho](https://aksh-garg.medium.com/llama-3v-building-an-open-source-gpt-4v-competitor-in-under-500-7dd8f1f6c9ee)

- O Llama3-V é um novo modelo multimodal baseado no Llama3, projetado para competir com modelos maiores, como o GPT-4V, mas a um custo significativamente menor (menos de US$ 500).
- Ele supera o modelo atual de última geração, o Llava, em 10 a 20% nos benchmarks de compreensão multimodal, usando o SigLIP para incorporação de imagens e alinhamento de tokens visuais e textuais por meio de um bloco de projeção com camadas de autoatenção.
- As principais otimizações incluem a pré-computação de imagens incorporadas e o aproveitamento do MPS/MLX para treinamento eficiente, com um processo de treinamento que envolve pré-treinamento em 600.000 exemplos e ajuste fino supervisionado em 1 milhão de exemplos.

### [Reações](https://news.ycombinator.com/item?id=40505099)

- O artigo compara vários modelos de IA multimodal, concentrando-se no Llama 3-V, que tem como objetivo igualar o desempenho do GPT-4V, mas é menor e mais barato.
- Ele destaca que modelos como InternVL-1.5 e CogVLM superam o Llava, com modelos específicos que se destacam em tarefas como OCR (reconhecimento óptico de caracteres) e compreensão de GUI (interface gráfica do usuário).
- Os usuários discutem aplicações práticas, limitações e a relação custo-benefício desses modelos, incluindo o uso do GPT-4V na produção de tarefas visuais e a eficácia de ferramentas modernas de OCR, como PaddleOCR e TrOCR.

## [Mistral AI revela Codestral: Uma poderosa IA generativa para geração de código](https://mistral.ai/news/codestral/)

- Em 29 de maio de 2024, a Mistral AI lançou o Codestral, um modelo de IA generativo de peso aberto para geração de código, treinado em mais de 80 linguagens de programação.
- O Codestral apresenta um tamanho de modelo de 22B e uma janela de contexto de 32k, superando os concorrentes em benchmarks como o RepoBench e o HumanEval.
- Disponível sob a licença Mistral AI Non-Production License, o Codestral pode ser acessado por meio de um endpoint dedicado ou integrado a ferramentas como VSCode e JetBrains, e os desenvolvedores elogiam sua velocidade, precisão e impacto na produtividade.

### [Reações](https://news.ycombinator.com/item?id=40512250)

- O Modelo de Código da Mistral, lançado pelo mistral.ai, tem uma licença restritiva que proíbe o uso comercial, condições ao vivo e uso interno da empresa, limitando suas aplicações práticas e atraindo críticas.
- O debate em torno da licença da Mistral destaca questões mais amplas de direitos autorais e licenciamento em conteúdo gerado por IA e o uso indevido do termo "código aberto" em IA.
- Os usuários expressam frustração com a geração de código inconsistente da IA, especialmente em tarefas complexas, e discutem as limitações e os recursos de vários modelos de IA, incluindo os modelos Llama da Meta e GPT da OpenAI.

## [Principais lições de um ano de desenvolvimento com modelos de idiomas grandes (Parte I)](https://www.oreilly.com/radar/what-we-learned-from-a-year-of-building-with-llms-part-i/)

- O artigo "What We Learned from a Year of Building with LLMs (Part I)", de Eugene Yan e colegas, explora os rápidos avanços e as aplicações práticas dos modelos de linguagem de grande porte (LLMs), ao mesmo tempo em que aborda os desafios no desenvolvimento de produtos de IA eficazes.
- As principais lições incluem práticas recomendadas de solicitação, geração aumentada de recuperação (RAG), engenharia de fluxo e avaliação, com ênfase em técnicas como solicitações de n-shot e solicitação de cadeia de pensamento.
- O artigo também fornece conselhos operacionais sobre o gerenciamento de agentes de IA, refinamento de prompts, modelos de ajuste fino e redução de custos e latência por meio de armazenamento em cache, enfatizando avaliações práticas e abordagens centradas no ser humano.

### [Reações](https://news.ycombinator.com/item?id=40508390)

- As percepções de um ano de trabalho com modelos de linguagem ampla (LLMs) destacam a importância da amostragem múltipla para reduzir as taxas de alucinação e gerar justificativas antes das decisões para obter resultados mais precisos.
- O artigo discute os desafios de avaliar os resultados do LLM, o impacto da temperatura na aleatoriedade dos resultados e as concepções errôneas sobre amostragem, além de experiências com o uso de ferramentas como patchbots e busca de feixes.
- Ele aborda as preocupações do setor, como as altas taxas de erro, os investimentos orientados pelo FOMO e o impulso agressivo de empresas como o Google para integrar a IA, apesar dos possíveis problemas de qualidade do serviço.

## [Mandatos de retorno ao escritório correm o risco de perder os melhores talentos, alerta especialista](https://www.rte.ie/brainstorm/2024/0521/1450272-return-to-office-mandates-employees-work-from-home/)

- O professor Kevin Murphy, da Universidade de Limerick, afirma que os trabalhadores remotos são mais produtivos e satisfeitos em comparação com os que trabalham em escritórios.
- A pressão por mandatos de retorno ao escritório (RTO) pós-pandemia corre o risco de perder os melhores talentos, pois muitos funcionários agora rejeitam as normas tradicionais de escritório.
- Os executivos devem apresentar motivos e incentivos convincentes para o retorno ao escritório, reconhecendo a mudança na dinâmica de poder que favorece os funcionários, ou correm o risco de perder talentos valiosos para concorrentes mais flexíveis.

### [Reações](https://news.ycombinator.com/item?id=40509409)

- O debate entre o trabalho remoto e as exigências de retorno ao escritório (RTO) está centrado na flexibilidade, no conforto e na possível perda de funcionários que preferem o trabalho remoto.
- O deslocamento para o trabalho oferece uma pausa mental para alguns, mas apresenta desafios como poluição, altos custos e limites confusos para outros, afetando o equilíbrio entre vida pessoal e profissional e o crescimento na carreira.
- O trabalho remoto é visto como mais eficiente e sustentável, oferecendo benefícios como maior tempo para a família e redução das emissões de carbono, mas pode negligenciar a equipe júnior e exigir uma comunicação clara dos benefícios da RTO.

## [Projeto de lei C-26 do Canadá: Poderes controversos para instalar backdoors de rede para vigilância](https://www.theglobeandmail.com/opinion/article-ottawa-wants-the-power-to-create-secret-backdoors-in-our-networks-to/)

- O projeto de lei C-26, uma lei federal de segurança cibernética no Canadá, concede ao governo poderes para forçar as empresas de telecomunicações a instalar backdoors em redes criptografadas, o que pode comprometer a segurança.
- Os críticos, incluindo o Citizen Lab da Universidade de Toronto, argumentam que essas medidas enfraqueceriam a criptografia 5G e outros recursos de segurança, aumentando a vulnerabilidade a ameaças cibernéticas.
- Apesar dos avisos de especialistas, o projeto de lei avançou sem emendas, contradizendo a posição pró-criptografia do Canadá e, potencialmente, estabelecendo um precedente perigoso para outros países.

### [Reações](https://news.ycombinator.com/item?id=40512509)

- O governo canadense está buscando autoridade para criar backdoors secretos em redes de telecomunicações para vigilância, contornando a supervisão legal tradicional, o que gera preocupações significativas com a privacidade e a possibilidade de abuso por parte das autoridades policiais.
- Os críticos argumentam que isso poderia levar a um monitoramento invasivo semelhante às práticas da NSA, envolvendo debates sobre a constituição do Canadá, a "cláusula de não obstante" e os recursos de interceptação legal.
- A discussão inclui exemplos históricos de vigilância, como durante os protestos dos caminhoneiros, e temas mais amplos de abuso do governo, privacidade e respostas da sociedade à autoridade.

## [Três leis fundamentais que regem a inevitável complexidade dos sistemas de software](https://maheshba.bitbucket.io/blog/2024/05/08/2024-ThreeLaws.html)

- O artigo discute três leis fundamentais que contribuem para a complexidade desnecessária na engenharia de software, especialmente em sistemas de infraestrutura.
- **Primeira Lei**: Sistemas bem projetados se transformam em sistemas mal projetados ao longo do tempo devido a modificações contínuas.
- **Segunda Lei**: A complexidade aumenta à medida que os sistemas bem-sucedidos priorizam a participação no mercado em detrimento de um bom design de abstração, levando a sistemas difíceis de modificar.
- **Terceira Lei**: Não há limite superior para a complexidade do software, impulsionada pelas diversas habilidades e filosofias dos desenvolvedores, resultando em projetos intrincados.

### [Reações](https://news.ycombinator.com/item?id=40509572)

- A discussão aborda os desafios de gerenciar a complexidade do software, especialmente em sistemas legados, e as compensações entre custo e qualidade, muitas vezes levando a dívidas técnicas.
- Ele enfatiza a importância da refatoração incremental, da manutenção de uma forte cultura de engenharia e da distinção entre complexidade essencial e acidental para gerenciar o software de forma eficaz.
- Os participantes destacam a necessidade de manutenção contínua, o impacto das escolhas ruins de desenvolvimento e o papel do suporte gerencial para justificar os esforços de refatoração.

## [Do início à venda: A jornada de Michael Lynch com o TinyPilot](https://mtlynch.io/i-sold-tinypilot/)

- Michael Lynch criou o TinyPilot em meados de 2020, um dispositivo para controle remoto de servidores, que rapidamente ganhou popularidade e se transformou em uma empresa com receita anual de US$ 1 milhão e uma equipe de sete pessoas.
- Lynch vendeu a TinyPilot por US$ 600 mil, obtendo um lucro líquido de US$ 490.803 após as despesas, devido ao estresse de gerenciar um negócio de hardware e ao desejo de voltar a programar e começar uma família.
- A venda, facilitada pela Quiet Light Brokerage, envolveu desafios como equilibrar o estresse do fundador, encontrar um comprador e gerenciar a devida diligência; o comprador foi Scott, um profissional de mídia corporativa.

### [Reações](https://news.ycombinator.com/item?id=40512500)

- Michael Lynch vendeu sua empresa, a TinyPilot, e discutiu os custos significativos envolvidos na venda, incluindo comissões de corretores e honorários advocatícios, que totalizaram cerca de 18% do preço de venda.
- A jornada empresarial de Lynch incluiu a transição de um emprego bem remunerado no Google para a valorização da autonomia e da criatividade, destacando o valor educacional do empreendedorismo e criticando o foco do setor de tecnologia na remuneração total.
- Lynch planeja iniciar futuros empreendimentos, concentrando-se em produtos educacionais e Software as a Service (SaaS), evitando hardware devido às suas complexidades e desafios.

## [Ex-membro da diretoria da OpenAI revela as razões por trás da demissão e reintegração de Sam Altman](https://www.theverge.com/2024/5/28/24166713/openai-helen-toner-explains-why-sam-altman-was-fired)

- Em novembro de 2023, a diretoria da OpenAI demitiu inesperadamente o CEO Sam Altman, citando "mentiras descaradas" e comportamento manipulador, o que desgastou a confiança.
- Questões específicas incluíam a propriedade não revelada de Altman do OpenAI Startup Fund, o fornecimento de informações de segurança imprecisas e a criação de um ambiente de trabalho tóxico.
- Apesar dessas alegações, as pressões internas e externas, incluindo o apoio dos funcionários e da Microsoft, levaram à reintegração de Altman, com uma análise independente que não encontrou problemas com a segurança do produto ou com as operações da empresa.

### [Reações](https://news.ycombinator.com/item?id=40509399)

- Um ex-membro da diretoria da OpenAI revelou que Sam Altman foi demitido por desonestidade, levantando questões sobre o conhecimento da diretoria sobre o lançamento do ChatGPT.
- A situação gerou discussões sobre transparência organizacional, supervisão da diretoria e governança ética, com comparações a falhas corporativas como a Enron.
- Há ceticismo em relação às práticas de confiança e segurança da OpenAI, com a saída de funcionários e críticas à liderança de Altman, além de debates sobre a proficiência técnica e o papel da diretoria.

## [Vazamento de informações sobre a pesquisa do Google revela segredos do algoritmo de classificação e 2.596 módulos](https://searchengineland.com/google-search-document-leak-ranking-442617)

- Um grande vazamento de documentos internos da Pesquisa Google revelou aspectos críticos do algoritmo de classificação do Google, incluindo o uso de cliques, links, conteúdo, entidades e dados do Chrome.
- Os especialistas do setor Rand Fishkin e Michael King analisaram os documentos, revelando 2.596 módulos de classificação, a importância da diversidade de links, a relevância, os cliques bem-sucedidos e o reconhecimento da marca.
- Os documentos também revelam o uso pelo Google de informações de autor, autoridade do site e "twiddlers" para ajustar as classificações, oferecendo insights valiosos para SEOs, apesar do desconhecimento da ponderação exata dos fatores de classificação.

### [Reações](https://news.ycombinator.com/item?id=40510125)

- Um documento da Pesquisa Google que vazou deu início a debates sobre o algoritmo de classificação e a influência do programa de anúncios do Google nos resultados da pesquisa.
- Os usuários estão discutindo alternativas como Kagi e search.marginalia.nu, com críticas mistas sobre a personalização do Kagi, o foco não comercial e problemas com spam e conteúdo gerado por IA.
- A conversa destaca o desejo de mecanismos de pesquisa que priorizem as preferências do usuário em relação à receita de anúncios, abordando a manipulação de SEO, o potencial dos modelos de linguagem ampla (LLMs) e as preocupações com a autenticidade das avaliações on-line e os critérios de classificação do Google.

## [ChatTTS: modelo avançado de TTS de código aberto para diálogo natural em inglês e chinês](https://github.com/2noise/ChatTTS)

- O ChatTTS é um modelo de conversão de texto em fala (TTS) otimizado para diálogos, compatível com inglês e chinês e treinado com mais de 100.000 horas de dados.
- A versão de código aberto do HuggingFace inclui um modelo pré-treinado de 40.000 horas, excelente em síntese de fala natural e expressiva com controle prosódico refinado.
- O modelo destina-se apenas ao uso acadêmico, com planos futuros de abrir o código-fonte de recursos adicionais e melhorar a estabilidade.

### [Reações](https://news.ycombinator.com/item?id=40507039)

- A discussão destaca o desenvolvimento e o desempenho de modelos TTS, como o ChatTTS e o Piper TTS, observando problemas como processamento lento e desafios de qualidade de voz.
- Os usuários enfatizam a necessidade de TTS de alta qualidade em vários idiomas e debatem a eficácia das vozes humanas em relação às vozes automatizadas em audiolivros.
- Há uma crítica às alegações enganosas de "código aberto" em projetos de TTS e uma chamada para uma lista abrangente de modelos e dados de TTS genuinamente de código aberto.

## [Google silencia sobre suposto vazamento de 2.500 páginas que detalham o algoritmo de busca](https://www.theverge.com/2024/5/28/24166177/google-search-ranking-algorithm-leak-documents-link-seo)

- Um vazamento de 2.500 páginas de documentos internos do Google, compartilhado pelo especialista em SEO Rand Fishkin, pode revelar discrepâncias entre as declarações públicas do Google e suas práticas reais em relação aos algoritmos de pesquisa.
- Os documentos sugerem o uso de dados do Chrome em classificações e rastreamento de informações de autores, desafiando as afirmações anteriores do Google e provocando um debate sobre a transparência da empresa.
- O Google não comentou sobre a legitimidade dos documentos, e o incidente destaca as preocupações contínuas sobre a natureza opaca das operações de pesquisa do Google em meio ao escrutínio antitruste.

### [Reações](https://news.ycombinator.com/item?id=40505310)

- Um vazamento da documentação do algoritmo de pesquisa do Google revelou possíveis discrepâncias entre as declarações públicas do Google e suas práticas reais.
- O vazamento sugere que os representantes do Google podem ter desacreditado descobertas precisas das comunidades de marketing, tecnologia e jornalismo, levantando preocupações éticas sobre a manipulação de SEO.
- As discussões jurídicas no GitHub estão debatendo a importância e a legalidade do vazamento, com opiniões variadas sobre seu impacto no status de segredo comercial e nas proteções de direitos autorais.

<head>
  <meta property="og:title" content="Fones de ouvido com IA isolam um único alto-falante em meio a multidões por meio da detecção do olhar" />
  <meta property="og:type" content="website" />
  <meta property="og:image" content="https://og.cho.sh/api/og/?title=Fones%20de%20ouvido%20com%20IA%20isolam%20um%20%C3%BAnico%20alto-falante%20em%20meio%20a%20multid%C3%B5es%20por%20meio%20da%20detec%C3%A7%C3%A3o%20do%20olhar&subheading=quarta-feira%2C%2029%20de%20maio%20de%202024%3A%20Resumo%20do%20Hacker%20News" />
</head>
