---
slug: '/2024/05/29'
---

# 2024-05-29

## [시선 감지를 통해 군중 속에서 한 명의 화자를 격리하는 AI 헤드폰](https://www.washington.edu/news/2024/05/23/ai-headphones-noise-cancelling-target-speech-hearing/)

- 워싱턴 대학교(UW)는 시끄러운 환경에서 사용자가 3~5초 동안 한 명의 화자를 바라보면서 집중할 수 있도록 도와주는 '타겟 음성 청각'이라는 AI 시스템을 개발했습니다.
- ACM CHI 컨퍼런스에서 선보인 이 시스템은 머신러닝을 사용하여 사용자가 움직이더라도 원하는 화자의 음성을 실시간으로 분리하고 증폭합니다.
- 현재 개념 증명 단계에 있는 이 기술은 21명의 피험자를 대상으로 테스트한 결과 선명도가 크게 개선되었다고 보고되었으며, 향후 이어버드와 보청기 등으로 확대할 계획입니다.

### [반응](https://news.ycombinator.com/item?id=40508278)

- 이 글에서는 AI 헤드폰, 고급 사운드 디자인, 노이즈 캔슬링 기술을 중심으로 시끄러운 환경에서 청각적 경험을 개선하기 위한 전략과 기술을 살펴봅니다.
- 유지 보수 및 미관 문제에도 불구하고 소음을 유발하는 현대식 레스토랑 자재와 소음 저감 기술 사용의 문제점을 강조합니다.
- 지향성 마이크, 실시간 음성 인식, 선택적 사운드 필터링과 같은 기술 발전과 개인정보 보호 및 오용 가능성에 대한 우려에 대해 논의합니다.

## [전 OpenAI 이사회 멤버, 샘 알트먼의 짧은 축출 뒤에 숨은 거짓말과 부정행위를 폭로하다](https://www.businessinsider.com/openai-board-member-details-sam-altman-lied-allegation-ousted-2024-5)

- 전 OpenAI 이사회 멤버인 헬렌 토너는 샘 알트먼이 이사회에서 여러 차례 부정직하고 정보를 숨긴 사례로 인해 잠시 CEO에서 해임되었다고 공개했습니다.
- 예를 들어, 이사회가 트위터를 통해 ChatGPT의 출시 사실을 알게 된 것과 알트먼이 회사에 대한 재정적 이해관계를 공개하지 않은 것, 부정확한 안전 정보 제공과 두 명의 임원이 '정신적 학대'를 했다는 비난을 받은 것 등이 있습니다.
- 알트먼은 직원들의 퇴사 위협과 Microsoft가 그의 팀 채용에 관심을 표명하자 일주일도 채 지나지 않아 CEO로 복귀했고, 토너는 복귀 직후 사임했습니다.

### [반응](https://news.ycombinator.com/item?id=40506582)

- OpenAI의 CEO인 샘 알트먼이 잠시 축출되었다가 다시 고용되면서 이사회의 권한과 주요 투자자 및 창업자들의 영향력 사이에 긴장이 노출되었습니다.
- 이사회가 알트먼의 해고를 잘못 처리하면서 직원들의 반발과 대량 사직 위협이 이어졌고, 이는 기업 지배구조, 직원 영향력, 재정적 이해관계의 복잡한 역학 관계를 강조하는 계기가 되었습니다.
- 이 사건은 기술 분야의 리더십, 무자비한 행동의 윤리적 의미, 기업 거버넌스에서 커뮤니케이션과 윤리의 역할에 대한 광범위한 논의를 촉발시켰습니다.

## [보안 강화를 위한 API의 HTTP-to-HTTPS 리디렉션 재검토](https://jviide.iki.fi/http-redirects)

- 특히 보안 헤더를 처리하지 않을 수 있는 소프트웨어가 액세스하는 API의 경우 HTTP에서 HTTPS로 리디렉션될 경우 민감한 데이터가 노출되거나 중간자(MITM) 공격이 발생할 수 있습니다.
- HSTS(HTTP 엄격한 전송 보안) 및 HTTPS 전용 모드와 같은 기술은 보안을 향상시키지만 API에는 충분하지 않을 수 있으므로 오류를 조기에 포착할 수 있는 빠른 실패 방지 접근법의 필요성이 강조됩니다.
- 보안 위험을 방지하기 위해 API가 암호화되지 않은 요청을 완전히 거부하고 암호화되지 않은 연결을 통해 전송된 API 자격 증명을 취소하도록 권장하도록 모범 사례를 업데이트해야 합니다.

### [반응](https://news.ycombinator.com/item?id=40504756)

- 이 논의에서는 중간자(MITM) 공격을 방지하기 위해 HTTP를 HTTPS로 리디렉션하고 HTTP를 통해 전송된 API 키를 취소하여 API 보안을 강화하는 것을 강조합니다.
- 인증에 서명된 해시, 논스, 타임스탬프를 사용하는 적절한 API 키 관리의 중요성과 데이터 무결성 및 개인정보 보호를 위한 HTTPS의 필요성을 강조합니다.
- 이 대화에서는 인증 기관에 대한 의존도를 비판하고 특정 상황에서 안전한 액세스 제어를 위한 고유 URL 또는 API 키와 같은 실용적인 솔루션을 제안합니다.

## [Llama3-V: 성능 면에서 GPT-4V와 경쟁하는 500달러짜리 멀티모달 모델](https://aksh-garg.medium.com/llama-3v-building-an-open-source-gpt-4v-competitor-in-under-500-7dd8f1f6c9ee)

- Llama3-V는 Llama3를 기반으로 한 새로운 멀티모달 모델로, GPT-4V와 같은 대형 모델과 경쟁하도록 설계되었지만 훨씬 저렴한 비용(500달러 미만)으로 제공됩니다.
- 이미지 임베딩에 SigLIP을 사용하고 자체 주의 레이어가 있는 프로젝션 블록을 통해 시각 및 텍스트 토큰을 정렬하여 멀티모달 이해 벤치마크에서 현재의 최신 모델인 Llava를 10~20% 능가합니다.
- 주요 최적화 사항으로는 이미지 임베딩을 사전 계산하고 효율적인 학습을 위해 MPS/MLX를 활용하며, 60만 개의 예제에 대한 사전 학습과 100만 개의 예제에 대한 감독 미세 조정이 포함된 학습 프로세스가 있습니다.

### [반응](https://news.ycombinator.com/item?id=40505099)

- 이 기사에서는 GPT-4V의 성능과 비슷하지만 더 작고 저렴한 라마 3-V에 초점을 맞춰 다양한 멀티모달 AI 모델을 비교합니다.
- 이 보고서는 InternVL-1.5 및 CogVLM과 같은 모델이 Llava보다 성능이 뛰어나며, 특정 모델은 OCR(광학 문자 인식) 및 GUI(그래픽 사용자 인터페이스) 이해와 같은 작업에서 탁월한 성능을 보인다고 강조합니다.
- 시각적 작업을 위한 프로덕션에서의 GPT-4V 사용과 PaddleOCR 및 TrOCR과 같은 최신 OCR 도구의 효과 등 이러한 모델의 실제 적용 사례, 한계, 비용 효율성에 대해 논의합니다.

## [미스트랄 AI, 코드스트랄을 공개합니다: 코드 생성을 위한 강력한 제너레이티브 AI](https://mistral.ai/news/codestral/)

- 2024년 5월 29일, 미스트랄 AI는 80개 이상의 프로그래밍 언어로 학습된 코드 생성을 위한 개방형 제너레이티브 AI 모델인 코드스트랄(Codestral)을 출시했습니다.
- 코데스트랄은 22B 모델 크기와 32k 컨텍스트 창을 지원하여 RepoBench 및 HumanEval과 같은 벤치마크에서 경쟁사보다 뛰어난 성능을 발휘합니다.
- Mistral AI 비프로덕션 라이선스로 제공되는 Codestral은 전용 엔드포인트를 통해 액세스하거나 VSCode 및 JetBrains와 같은 도구에 통합할 수 있으며, 개발자들은 속도, 정확성 및 생산성 향상 효과에 대해 호평하고 있습니다.

### [반응](https://news.ycombinator.com/item?id=40512250)

- 미스트랄이 공개한 코드 모델은 상업적 사용, 라이브 조건 및 회사 내부 사용을 금지하는 제한적인 라이선스를 가지고 있어 실제 적용에 제한이 있고 비판을 받고 있습니다.
- 미스트랄의 라이선스를 둘러싼 논쟁은 AI가 생성한 콘텐츠의 저작권과 라이선스, 그리고 AI에서 '오픈소스'라는 용어의 오용이라는 광범위한 문제를 강조합니다.
- 사용자들은 특히 복잡한 작업에서 일관성 없는 코드 생성에 대한 불만을 표출하고 Meta의 Llama, OpenAI의 GPT 모델 등 다양한 AI 모델의 한계와 기능에 대해 논의합니다.

## [대규모 언어 모델로 구축한 1년간의 주요 교훈(1부)](https://www.oreilly.com/radar/what-we-learned-from-a-year-of-building-with-llms-part-i/)

- 유진 얀과 동료들이 작성한 'LLM으로 1년 동안 구축하며 배운 것(1부)' 글에서는 효과적인 AI 제품 개발의 어려움을 해결하면서 대규모 언어 모델(LLM)의 빠른 발전과 실제 적용에 대해 살펴봅니다.
- 주요 강의에는 프롬프트, 검색 증강 생성(RAG), 흐름 엔지니어링 및 평가의 모범 사례와 함께 엔샷 프롬프트 및 생각의 사슬 프롬프트와 같은 기술이 강조되어 있습니다.
- 또한 이 문서에서는 AI 에이전트 관리, 프롬프트 개선, 모델 미세 조정, 캐싱을 통한 비용 및 대기 시간 단축에 대한 운영 조언을 제공하며 실질적인 평가와 인간 중심의 접근 방식을 강조합니다.

### [반응](https://news.ycombinator.com/item?id=40508390)

- 1년간 대규모 언어 모델(LLM)을 사용해 얻은 인사이트는 환각률을 줄이기 위한 다중 샘플링의 중요성과 보다 정확한 결과를 위해 의사 결정 전에 근거를 생성하는 것의 중요성을 강조합니다.
- 이 글에서는 LLM 출력 평가의 어려움, 온도가 출력 무작위성에 미치는 영향, 샘플링에 대한 오해와 함께 패치봇 및 빔 검색과 같은 도구를 사용한 경험에 대해 설명합니다.
- 높은 오류율, FOMO에 따른 투자, 잠재적인 서비스 품질 문제에도 불구하고 Google과 같은 기업이 AI를 통합하려는 공격적인 추진과 같은 업계의 우려를 해결합니다.

## [사무실 복귀 의무화로 인해 최고의 인재를 잃을 위험, 전문가 경고](https://www.rte.ie/brainstorm/2024/0521/1450272-return-to-office-mandates-employees-work-from-home/)

- 리머릭 대학교의 케빈 머피 교수는 원격 근무자가 사무실 근무자에 비해 생산성과 만족도가 더 높다고 주장합니다.
- 팬데믹 이후 많은 직원이 기존의 사무실 규범을 거부하면서 사무실 복귀(RTO)를 의무화함에 따라 최고의 인재를 잃을 위험이 있습니다.
- 경영진은 직원들에게 유리한 권력 역학 관계의 변화를 인정하면서 사무실로 복귀해야 하는 설득력 있는 이유와 인센티브를 제공해야 하며, 그렇지 않으면 더 유연한 경쟁자에게 소중한 인재를 잃을 위험이 있습니다.

### [반응](https://news.ycombinator.com/item?id=40509409)

- 원격 근무와 사무실 복귀(RTO) 의무 사이의 논쟁은 유연성, 편의성, 원격 근무를 선호하는 직원들의 잠재적 손실에 초점을 맞추고 있습니다.
- 출퇴근은 어떤 사람들에게는 정신적 휴식을 제공하지만 다른 사람들에게는 공해, 높은 비용, 모호한 경계와 같은 문제를 야기하여 일과 삶의 균형과 경력 성장에 영향을 미칩니다.
- 원격 근무는 가족 시간 증가, 탄소 배출량 감소와 같은 이점을 제공하여 더 효율적이고 지속 가능한 것으로 여겨지지만, 하위 직원을 소홀히 할 수 있으며 RTO 혜택에 대한 명확한 커뮤니케이션이 필요합니다.

## [캐나다의 법안 C-26: 감시를 위한 네트워크 백도어 설치에 대한 논란의 여지가 있는 권한](https://www.theglobeandmail.com/opinion/article-ottawa-wants-the-power-to-create-secret-backdoors-in-our-networks-to/)

- 캐나다의 연방 사이버 보안 법안인 C-26 법안은 통신 회사가 암호화된 네트워크에 백도어를 설치하도록 강제할 수 있는 권한을 정부에 부여하여 잠재적으로 보안을 손상시킬 수 있습니다.
- 토론토 대학교의 시민 연구소를 비롯한 비평가들은 이러한 조치가 5G 암호화 및 기타 보안 기능을 약화시켜 사이버 위협에 대한 취약성을 증가시킬 것이라고 주장합니다.
- 전문가들의 경고에도 불구하고 이 법안은 수정 없이 진행되어 캐나다의 암호화 찬성 입장과 모순되며 다른 국가에 위험한 선례가 될 수 있습니다.

### [반응](https://news.ycombinator.com/item?id=40512509)

- 캐나다 정부는 기존의 법적 감독을 우회하여 통신 네트워크에 비밀 백도어를 만들어 감시하는 권한을 추구하고 있으며, 이는 심각한 개인정보 보호 문제와 법 집행 기관의 악용 가능성을 제기합니다.
- 비판자들은 캐나다 헌법, '그럼에도 불구하고' 조항, 합법적인 감청 기능에 대한 논쟁을 포함하여 NSA의 관행과 유사한 침입적 감시로 이어질 수 있다고 주장합니다.
- 이 토론에는 트럭 운전사 시위와 같은 감시의 역사적 사례와 정부의 과잉 대응, 프라이버시, 권위에 대한 사회적 대응이라는 광범위한 주제가 포함됩니다.

## [소프트웨어 시스템의 불가피한 복잡성을 지배하는 세 가지 기본 법칙](https://maheshba.bitbucket.io/blog/2024/05/08/2024-ThreeLaws.html)

- 이 글에서는 소프트웨어 엔지니어링, 특히 인프라 시스템에서 불필요한 복잡성을 유발하는 세 가지 기본 법칙에 대해 설명합니다.
- **첫 번째 법칙**: 잘 설계된 시스템은 지속적인 수정으로 인해 시간이 지남에 따라 제대로 설계되지 않은 시스템으로 저하됩니다.
- **제2의 법칙**: 성공적인 시스템이 좋은 추상화 설계보다 시장 점유율을 우선시할수록 복잡성이 증가하여 수정하기 어려운 시스템이 됩니다.
- **세 번째 법칙**: 소프트웨어 복잡성에는 상한선이 없으며, 개발자의 다양한 능력과 철학에 따라 복잡한 설계가 이루어집니다.

### [반응](https://news.ycombinator.com/item?id=40509572)

- 이 토론에서는 특히 레거시 시스템에서 소프트웨어 복잡성 관리의 어려움과 종종 기술 부채로 이어지는 비용과 품질 간의 절충점에 대해 다룹니다.
- 소프트웨어를 효과적으로 관리하기 위해 점진적 리팩토링, 강력한 엔지니어링 문화 유지, 필수적인 복잡성과 우발적인 복잡성을 구분하는 것이 중요하다는 점을 강조합니다.
- 참가자들은 지속적인 유지 관리의 필요성, 잘못된 개발 선택의 영향, 리팩토링 노력을 정당화하기 위한 관리 지원의 역할에 대해 강조합니다.

## [창업에서 판매까지: 마이클 린치의 타이니파일럿 여정](https://mtlynch.io/i-sold-tinypilot/)

- 마이클 린치는 2020년 중반에 원격 서버 제어용 디바이스인 TinyPilot을 만들었는데, 이 디바이스는 빠르게 인기를 얻으며 연 매출 100만 달러, 7명의 팀을 보유한 기업으로 성장했습니다.
- 린치는 하드웨어 사업 관리로 인한 스트레스와 코딩으로 돌아가 가정을 꾸리고 싶다는 생각에 TinyPilot을 60만 달러에 매각하여 비용 후 490,803달러의 수익을 올렸습니다.
- 콰이어트 라이트 브로커리지가 진행한 이 매각에는 창업자의 스트레스 해소, 구매자 발굴, 실사 관리 등의 과제가 수반되었으며, 구매자는 기업 미디어 전문가인 Scott이었습니다.

### [반응](https://news.ycombinator.com/item?id=40512500)

- 마이클 린치는 자신의 비즈니스인 TinyPilot을 매각하면서 중개인 수수료와 법률 수수료 등 매각과 관련된 상당한 비용(매각 가격의 약 18%에 달함)에 대해 논의했습니다.
- 린치의 기업가적 여정에는 고임금 직장에서 벗어나 자율성과 창의성을 중시하고 기업가 정신의 교육적 가치를 강조하며 기술 업계가 총보상에 초점을 맞추는 것을 비판하는 내용이 포함되어 있습니다.
- Lynch는 복잡하고 어려운 하드웨어를 피하고 교육용 제품 및 서비스형 소프트웨어(SaaS)에 초점을 맞춰 향후 벤처를 부트스트랩할 계획입니다.

## [전 OpenAI 이사회 멤버, 샘 알트먼의 해고와 복직의 이유를 밝히다](https://www.theverge.com/2024/5/28/24166713/openai-helen-toner-explains-why-sam-altman-was-fired)

- 2023년 11월, OpenAI의 이사회는 "노골적인 거짓말"과 신뢰를 약화시키는 조작적인 행동을 이유로 CEO인 샘 알트먼을 갑작스럽게 해고했습니다.
- 구체적인 문제로는 알트먼의 OpenAI 스타트업 펀드 미공개 소유권, 부정확한 안전 정보 제공, 유해한 업무 환경 조성 등이 있습니다.
- 이러한 의혹에도 불구하고 직원들과 Microsoft의 지원을 포함한 내외부의 압력으로 알트먼은 독립적인 검토 결과 제품 안전이나 회사 운영에 문제가 없는 것으로 밝혀져 복귀하게 되었습니다.

### [반응](https://news.ycombinator.com/item?id=40509399)

- 전 OpenAI 이사회 멤버가 샘 알트먼이 부정행위로 인해 해고되었다고 밝히면서, ChatGPT 출시에 대한 이사회의 인식에 의문이 제기되었습니다.
- 이러한 상황은 엔론과 같은 기업 실패 사례와 비교되면서 조직의 투명성, 이사회 감독, 윤리적 거버넌스에 대한 논의를 촉발시켰습니다.
- 직원들의 이탈과 알트먼의 리더십에 대한 비판, 그리고 기술적 능력과 이사회의 역할에 대한 논쟁과 함께 OpenAI의 신뢰와 안전 관행에 대한 회의론이 제기되고 있습니다.

## [구글 검색 유출로 밝혀진 순위 알고리즘과 2,596개 모듈의 비밀](https://searchengineland.com/google-search-document-leak-ranking-442617)

- Google 내부 검색 문서의 대규모 유출로 인해 클릭 수, 링크, 콘텐츠, 엔티티 및 Chrome 데이터 사용 등 Google 순위 알고리즘의 중요한 측면이 공개되었습니다.
- 업계 전문가인 랜드 피쉬킨과 마이클 킹이 문서를 분석하여 2,596개의 순위 모듈, 링크 다양성, 관련성, 클릭 성공률, 브랜드 인지도의 중요성 등을 밝혀냈습니다.
- 이 문서에는 Google이 순위를 조정하기 위해 작성자 정보, 사이트 권한 및 '트위들러'를 사용하는 방법도 공개되어 있어 순위 요소의 정확한 가중치는 알 수 없지만 SEO에 유용한 인사이트를 제공합니다.

### [반응](https://news.ycombinator.com/item?id=40510125)

- 유출된 Google 검색 문서가 순위 알고리즘과 검색 결과에 대한 Google 광고 프로그램의 영향력에 대한 논쟁을 촉발시켰습니다.
- 사용자들은 Kagi 및 search.marginalia.nu와 같은 대안에 대해 논의하고 있으며, Kagi의 맞춤 설정, 비상업적 초점, 스팸 및 AI 생성 콘텐츠에 대한 문제 등에 대한 평가가 엇갈리고 있습니다.
- 이 대화에서는 광고 수익보다 사용자 선호도를 우선시하는 검색 엔진에 대한 열망을 강조하고, SEO 조작, LLM(대규모 언어 모델)의 잠재력, 온라인 리뷰의 신뢰성 및 Google의 순위 기준에 대한 우려에 대해 다룹니다.

## [ChatTTS: 영어와 중국어로 자연스러운 대화를 위한 고급 오픈 소스 TTS 모델](https://github.com/2noise/ChatTTS)

- ChatTTS는 영어와 중국어를 모두 지원하고 10만 시간 이상의 데이터로 학습된 대화에 최적화된 TTS(텍스트 음성 변환) 모델입니다.
- 허깅페이스의 오픈 소스 버전에는 40,000시간의 사전 학습을 거친 모델이 포함되어 있어 세밀한 운율 제어를 통해 자연스럽고 표현력 있는 음성 합성에 탁월합니다.
- 이 모델은 학술용으로만 사용되며, 향후 추가 기능을 오픈소스화하고 안정성을 개선할 계획입니다.

### [반응](https://news.ycombinator.com/item?id=40507039)

- 이 토론에서는 느린 처리 및 음성 품질 문제와 같은 문제를 지적하면서 ChatTTS 및 Piper TTS와 같은 TTS 모델의 개발 및 성능을 강조합니다.
- 사용자들은 여러 언어로 된 고품질 TTS의 필요성을 강조하고 오디오북에서 사람 목소리와 자동화된 음성의 효과에 대해 토론합니다.
- TTS 프로젝트에서 오해의 소지가 있는 '오픈 소스' 주장에 대한 비판과 진정한 오픈 소스 TTS 모델 및 데이터의 포괄적인 목록이 필요하다는 요구가 있습니다.

## [구글, 검색 알고리즘을 상세히 설명하는 2,500페이지 유출 의혹에 침묵하다](https://www.theverge.com/2024/5/28/24166177/google-search-ranking-algorithm-leak-documents-link-seo)

- 검색엔진 최적화 전문가 Rand Fishkin이 공유한 2,500페이지 분량의 Google 내부 문서 유출로 인해 검색 알고리즘과 관련한 Google의 공개적인 입장과 실제 관행 사이에 불일치가 있을 수 있습니다.
- 이 문서에는 순위를 매기고 작성자 정보를 추적하는 데 Chrome 데이터를 사용한다는 내용이 담겨 있어 구글의 이전 주장에 도전하고 회사의 투명성에 대한 논쟁을 촉발시켰습니다.
- 구글은 해당 문서의 적법성에 대해 언급하지 않았으며, 이번 사건은 반독점 조사에 따른 구글 검색 운영의 불투명성에 대한 지속적인 우려를 강조하고 있습니다.

### [반응](https://news.ycombinator.com/item?id=40505310)

- 구글의 검색 알고리즘 문서가 유출되어 구글의 공식 발표와 실제 관행 사이에 잠재적인 불일치가 있는 것으로 밝혀졌습니다.
- 이번 유출은 구글의 담당자가 마케팅, 기술 및 저널리즘 커뮤니티의 정확한 조사 결과를 신뢰하지 않았을 수 있음을 시사하며 SEO 조작에 대한 윤리적 우려를 불러일으켰습니다.
- GitHub에 대한 법적 논의에서는 유출의 중요성과 적법성에 대해 논의 중이며, 영업비밀 지위와 저작권 보호에 미치는 영향에 대해 다양한 의견이 있습니다.

<head>
  <meta property="og:title" content="시선 감지를 통해 군중 속에서 한 명의 화자를 격리하는 AI 헤드폰" />
  <meta property="og:type" content="website" />
  <meta property="og:image" content="https://og.cho.sh/api/og/?title=%EC%8B%9C%EC%84%A0%20%EA%B0%90%EC%A7%80%EB%A5%BC%20%ED%86%B5%ED%95%B4%20%EA%B5%B0%EC%A4%91%20%EC%86%8D%EC%97%90%EC%84%9C%20%ED%95%9C%20%EB%AA%85%EC%9D%98%20%ED%99%94%EC%9E%90%EB%A5%BC%20%EA%B2%A9%EB%A6%AC%ED%95%98%EB%8A%94%20AI%20%ED%97%A4%EB%93%9C%ED%8F%B0&subheading=2024%EB%85%84%205%EC%9B%94%2029%EC%9D%BC%20%EC%88%98%EC%9A%94%EC%9D%BC%3A%20%ED%95%B4%EC%BB%A4%EB%89%B4%EC%8A%A4%20%EC%9A%94%EC%95%BD" />
</head>
