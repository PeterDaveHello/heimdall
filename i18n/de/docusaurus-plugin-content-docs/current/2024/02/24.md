---
slug: '/2024/02/24'
---

# 2024-02-24

## [Betrüger nutzen den guten Ruf von FedEx für Phishing-Angriffe](https://www.troyhunt.com/thanks-fedex-this-is-why-we-keep-getting-phished/)

- Betrüger nutzen den Ruf von FedEx aus, um Menschen zu Phishing-Betrügereien zu verleiten, was zu einem Anstieg der betrügerischen Aktivitäten führt.
- Der Artikel hebt den zunehmenden Trend hervor, bekannte Firmennamen für Phishing-Betrügereien zu verwenden.
- Erhöhte Wachsamkeit und Sensibilisierung sind von entscheidender Bedeutung, um zu vermeiden, dass man Opfer solcher betrügerischen Taktiken wird.

### [Reaktionen](https://news.ycombinator.com/item?id=39479001)

- Die Diskussion befasst sich mit Sicherheitsschwachstellen bei Lieferdiensten wie FedEx und den Herausforderungen bei Passwortrichtlinien gemäß den NIST-Richtlinien.
- Die Teilnehmer berichten von ihren persönlichen Erfahrungen mit Unternehmen, die Ineffizienzen, Sicherheitsrisiken und Frustrationen mit technischen Problemen im digitalen Zeitalter offenbaren.
- Der Schwerpunkt liegt auf der Verbesserung von Sicherheitspraktiken, Kommunikationsmethoden und Passwortmanagement in verschiedenen Branchen.

## [Erstellen eines GPT-Modells in SQL: Eine Vertiefung](https://explainextended.com/2023/12/31/happy-new-year-15/)

- Der Artikel befasst sich mit dem Aufbau eines aussagekräftigen Sprachmodells in SQL, geht auf Skeptiker wie ChatGPT ein und befasst sich mit Tokenisierung, Vektoreinbettungen, Aufmerksamkeitsmechanismen und Backpropagation für ein Generative Pre-trained Transformer (GPT) Modell.
- Die Verwendung von PostgreSQL für die Tokenisierung wird für eine effiziente Textkodierung hervorgehoben, um die Leistung neuronaler Netze zu verbessern, einschließlich Codeausschnitten und Beispielen.
- Das positive Feedback der Leser wird zur Kenntnis genommen, mit der Aufforderung, weitere SQL-Projekte auf GitHub zu entdecken und zu erforschen.

### [Reaktionen](https://news.ycombinator.com/item?id=39488668)

- In diesem Beitrag wird die Implementierung von GPT mit 500 Zeilen SQL-Code untersucht. Die Nutzer applaudieren der Demonstration und diskutieren über Training, Inferenz und die Integration neuronaler Netze in Tabellenkalkulationen.
- Die Nutzer bewundern den Inhalt und die Präsentation des Artikels, der mit zusätzlichen Ressourcen verlinkt ist, um mehr über GPT und LLM zu erfahren, was ein tieferes Verständnis der behandelten Themen fördert.

## [Modularer Rahmen für Heimroboter: OK-Robot lädt zur Zusammenarbeit mit der Gemeinschaft ein](https://ok-robot.github.io/)

- OK-Robot ist ein offenes und modulares Framework, das für die Roboternavigation und -manipulation in häuslichen Umgebungen entwickelt wurde und es dem Benutzer ermöglicht, es auf einem Roboter einzusetzen, den Bereich zu scannen und die Bewegung von Objekten mühelos zu steuern.
- Obwohl sie nicht fehlerfrei ist, nutzt sie moderne Modelle des maschinellen Lernens und fördert das Engagement der Community für Verbesserungen, was ihr Engagement für eine kontinuierliche Verbesserung unterstreicht.
- Der Code des Frameworks ist quelloffen und wird von einem Discord-Server für die Unterstützung und den Dialog mit der Community unterstützt. Er wurde in verschiedenen Heimumgebungen getestet und ist somit offen für Feedback und Beiträge.

### [Reaktionen](https://news.ycombinator.com/item?id=39483482)

- OK-Robot ist ein offenes, modulares Heimroboter-Framework, das maschinelle Lernmodelle für die Navigation und Manipulation in Wohnungen nutzt, wobei der Schwerpunkt auf der Unterstützung von Behinderten, älteren Menschen und anderen Bedürftigen liegt.
- Die Diskussionen drehen sich um die Herausforderungen bei der Entwicklung von Robotern für unübersichtliche Umgebungen und die Zugänglichkeit für Menschen mit Behinderungen sowie um das Potenzial der Robotik bei Haushaltsaufgaben und die Auswirkungen der Automatisierung auf die Wirtschaft und die Arbeitskräfte.
- Die Teilnehmer erforschen die Kostenaspekte beim Bau von Robotern, betonen die präzisen Bewegungen in der Robotik und denken über die Rolle von Robotern in verschiedenen Branchen und die Notwendigkeit eines allgemeinen Grundeinkommens aufgrund der Automatisierung nach.

## [Satoshi und Sirius: Bitcoin-Entwicklungsdiskussionen 2009-2011](https://mmalmi.github.io/satoshi/)

- Der E-Mail-Verkehr zwischen Martti Malmi (Sirius) und Satoshi Nakamoto aus den Jahren 2009-2011 beleuchtet die Bitcoin-Entwicklung und behandelt Themen wie Website-Entwicklung, serverseitiges Scripting und Knotenbetrieb.
- Martti schlägt vor, eine Website und eine FAQ mit gesicherten privaten Schlüsseln zu erstellen, während Satoshi Hilfe bei der Erstellung von Website-Inhalten und Server-Skripten sucht.
- Die Korrespondenz befasst sich mit Themen wie Blöcken, Transaktionen, Skalierbarkeit, Proof of Work, Spam, Funktionserweiterungen, Website-Verbesserungen, Einrichtung von Bitcoin-Austauschdiensten und Software-Upgrades.

### [Reaktionen](https://news.ycombinator.com/item?id=39480407)

- Die Diskussion befasst sich mit der mysteriösen Identität von Satoshi Nakamoto, dem Kopf hinter Bitcoin, und geht auf Spekulationen über Motive, Verbindungen zur Regierung und die Folgen der Aufdeckung von Satoshis Identität ein.
- Zu den verschiedenen Themen gehören Anonymität, Datenschutzfunktionen in Kryptowährungen wie Monero, digitale Zentralbankwährungen, Kryptowährungs-Mining, Opsec in kritischen Situationen und linguistische Analyse zur Überprüfung der Urheberschaft.
- Er betont die Bedeutung von Ehrlichkeit, operativer Sicherheit (opsec) und die Risiken, die mit der Schaffung und Verwaltung eines bahnbrechenden Projekts wie Bitcoin verbunden sind.

## [Gemma.cpp: Leichtgewichtige Inferenzmaschine für Gemma-Modelle](https://github.com/google/gemma.cpp)

- Gemma.cpp ist eine leichtgewichtige Inferenz-Engine für Gemma-Foundation-Modelle von Google, die auf Kaggle zugänglich ist und ideal für Forschung und Experimente ist.
- Benutzer können auf Kaggle auf Modellgewichte und Tokenizer für verschiedene Gemma-Modelle zugreifen.
- Es wird empfohlen, Python-Frameworks wie JAX, Keras, PyTorch und Transformers für die Bereitstellung von Modellen auf Edge-Geräten zu verwenden, und Beiträge der Community werden durch die kontinuierliche Entwicklung im Dev-Zweig gefördert.

### [Reaktionen](https://news.ycombinator.com/item?id=39481554)

- Gemma.cpp ist eine C++ Inferenz-Engine, die von Google für Gemma-Modelle entwickelt wurde. Der Schwerpunkt liegt auf Portabilität und einfacher Modifikation, wobei der Schwerpunkt auf CPU-SIMD-Leistung und zukünftiger GPU-Unterstützung liegt.
- Die Kritik bezieht sich auf die Wiederholungsstrafe, die Verzerrung und die Modellgröße und weckt Bedenken hinsichtlich der Transparenz, des Vertrauens und des Wettbewerbs mit OpenAI, während gleichzeitig die organisatorischen Herausforderungen und die Talentbindung von Google hervorgehoben werden.
- Die Debatten in der KI-Gemeinschaft betreffen Leistung, Kompatibilität und Entwicklungsaspekte wie Modellverpackungsformate, Fähigkeiten und Größenbeschränkungen von Gemma-Modellen.

## [Searchformer: Revolutionäre Planung mit Transformatoren](https://arxiv.org/abs/2402.14083)

- Searchformer ist ein Transformer-Modell, das entwickelt wurde, um komplizierte Planungsaufgaben mit weniger Suchschritten als bei herkömmlichen Methoden zu bewältigen.
- Es übertrifft die Ausgangsleistung bei der Navigation im Labyrinth und bei Sokoban-Rätseln, was darauf hindeutet, dass es auch umfangreichere Entscheidungsaufgaben bewältigen kann.
- Das Training von Transformatoren zur Vorwegnahme der Suchdynamik erweist sich als vorteilhaft und verbessert die Leistung bei reduzierten Modellgrößen und Trainingsdaten.

### [Reaktionen](https://news.ycombinator.com/item?id=39479478)

- Transformatoren werden für die Bewegungsplanung von Robotern erforscht. Sie haben das Potenzial, bei hochdimensionalen und kontinuierlichen Problemen schneller optimale Pfade zu erzeugen als frühere Techniken.
- Die Debatten umfassen alternative Algorithmen, Technologien und Nachteile von Transformatoren, wobei die Rolle der KI bei der Verbesserung klassischer Algorithmen und der Effizienzunterschied zwischen Transformatoren und herkömmlichen Methoden wie A\* hervorgehoben wird.
- Diskutiert werden die Modellnomenklatur in der KI, Effizienzvergleiche zwischen Transformatormodellen und traditionellen Strategien wie A\* und die Untersuchung von Algorithmen zur explorativen Entscheidungsfindung wie Bellman-Ford und MCTS bei Herausforderungen der Pfadplanung.

## [Meta's TestGen-LLM: Steigerung der Entwicklerproduktivität](https://read.engineerscodex.com/p/metas-new-llm-based-test-generator)

- Meta hat TestGen-LLM auf den Markt gebracht, einen neuen Testgenerator, der die LLM-Technologie nutzt, um die Produktivität von Entwicklern durch die Generierung von Codeverbesserungen mit verifizierten Garantien zu erhöhen, wobei der Schwerpunkt auf der Verbesserung bestehender Tests liegt.
- TestGen-LLM stellt sicher, dass die generierten Tests praktikabel, ausführbar und stabil sind und die Testabdeckung erhöhen, was sich in hohen Akzeptanzraten bei den Entwicklern und einer nahtlosen Integration in die Arbeitsabläufe von Meta niederschlägt.
- Das Tool unterstreicht die Bedeutung von LLM-Nischenanwendungen in der Softwareentwicklung und betont die Wichtigkeit der Bewältigung unvorhergesehener Szenarien, wobei die zentrale Rolle der LLM-Integration und -Verarbeitung bei der Optimierung von Softwaretests und der Entwicklungseffizienz hervorgehoben wird.

### [Reaktionen](https://news.ycombinator.com/item?id=39486717)

- Ingenieure diskutieren über die Verwendung von Large Language Models (LLMs) zur Erstellung von Testcode oder Implementierungen, wobei die Meinungen über die Vor- und Nachteile gemischt sind.
- Einige betrachten KI-generierte Tests als vorteilhaft und effizient, während andere betonen, wie wichtig es ist, dass der Mensch an den Testverfahren beteiligt ist.
- Zu den Bedenken gehören die Qualität und Quantität der von LLMs erstellten Tests und die potenziellen Auswirkungen der KI auf künftige Softwareentwicklungsverfahren.

## [Gizmodo-Autor entgeht Entdeckung durch Umbenennung in "Slackbot"](https://www.theverge.com/2024/2/23/24081249/slack-slackbot-gizmodo-tom-mckay)

- Der ehemalige Gizmodo-Autor Tom McKay hat sich nach seinem Weggang auf Slack in "Slackbot" umbenannt und sich monatelang unbemerkt integriert.
- Indem er sein Profilbild und seinen Namen so veränderte, dass sie dem Slackbot-Symbol ähnelten, täuschte er Kollegen mit Bot-ähnlichen Nachrichten.
- Einige Firmen haben Schutzmaßnahmen gegen solche Aktionen, aber das Management von Gizmodo hat es versäumt, das doppelte Konto zu identifizieren.

### [Reaktionen](https://news.ycombinator.com/item?id=39487341)

- Die Diskussion befasst sich mit Problemen bei der Integration der Kontoverwaltung zwischen Slack und Google Office, wobei die Herausforderungen bei der plattformübergreifenden Verwaltung von Benutzernamen und Profilen hervorgehoben werden.
- Zu den Tipps gehören die Verwendung von Unicode-Zeichen und Dienstkonten zur Verbesserung der Sicherheit und zur Bekämpfung von Imitationen auf diesen Plattformen.
- Es werden Empfehlungen für die Implementierung von Single Sign-On (SSO) und System for Cross-Domain Identity Management (SCIM) gegeben, um die Sicherheit zu erhöhen und unbefugten Zugriff zu verhindern, wobei die Einschränkungen von Unternehmens-Chat-Tools behoben werden.

## [Entfaltung generativer Modelle mit INTRINSIC LoRA](https://intrinsic-lora.github.io/)

- Der Beitrag stellt INTRINSIC LoRA (I-LoRA) vor, eine Technik, die verborgene Potenziale generativer Modelle wie VQGAN, StyleGAN-XL, StyleGAN-v2 und Stable Diffusion aufdeckt, indem sie intrinsische Szenenmerkmale wie Normalen, Tiefe, Albedo und Schattierung ohne zusätzliche Schichten extrahiert.
- Diese modellunabhängige Methode erzeugt erstklassige szeneneigene Karten und übertrifft damit bestimmte etablierte überwachte Methoden.
- I-LoRA stellt die Fähigkeit unter Beweis, intrinsische Szeneneigenschaften zu extrahieren und so die Qualität der generierten Inhalte aus verschiedenen generativen Modellen zu verbessern.

### [Reaktionen](https://news.ycombinator.com/item?id=39487124)

- Die Diskussion befasst sich mit generativen Modellen wie Sora, der Umwandlung von "Bojack Horseman" von hellen zu dunklen Themen und der Komplexität von KI-Modellen, einschließlich des Renderns von 3D-Szenen und der Verständnis- und Verallgemeinerungsfähigkeiten von KI.
- Es wird auf I-LoRA, die Extraktion von Szeneneigenschaften, die Bedeutung von Modellmerkmalen und neuronale Netze, die Bilder direkt ohne Dekodierungsschichten erzeugen, eingegangen.
- Erwähnung eines von Toyota und Adobe finanzierten Forschungsprojekts zum Thema Computer Vision sowie Spekulationen über KI, die die menschliche Intelligenz übertreffen könnte.

## [Deutscher Bundestag stimmt für die Legalisierung von Cannabis für den privaten Gebrauch](https://www.bundestag.de/dokumente/textarchiv/2024/kw08-de-cannabis-990684)

- Die deutsche Regierung schlug ein Gesetz zur Legalisierung von Cannabis für den privaten Konsum durch Erwachsene vor, das den Besitz von bis zu 25 Gramm und den Anbau von bis zu drei Pflanzen für den persönlichen Gebrauch erlaubt.
- Die Gesetzgebung zielt darauf ab, einen verantwortungsvollen Konsum zu fördern, den Gesundheitsschutz zu verbessern, den illegalen Cannabismarkt einzudämmen und den Jugendschutz durch strenge Vorschriften für den privaten Anbau und Vertrieb zu verbessern.
- Der Cannabiskonsum in der Nähe von Schulen und Jugendeinrichtungen wird in einem Umkreis von 200 Metern verboten, und es wird keine Werbung oder Sponsoring erlaubt sein, während medizinisches Cannabis weiterhin nur auf Rezept erhältlich sein wird.

### [Reaktionen](https://news.ycombinator.com/item?id=39481188)

- Die Diskussion befasst sich mit der Drogenlegalisierung, dem Drogenkonsum und kriminellen Aktivitäten in verschiedenen europäischen Ländern, wobei der Schwerpunkt auf der Cannabislegalisierung in Deutschland liegt und diese mit den strengen Gesetzen in Belgien verglichen wird.
- Er befasst sich mit Herausforderungen wie Drogenabhängigkeit, den Auswirkungen der Marktregulierung, der Verfügbarkeit von Drogen über illegale Kanäle und persönlichen Erfahrungen mit Cannabisabhängigkeit.
- Die Debatte beleuchtet auch, wie sich die Legalisierung von Cannabis auf kriminelle Aktivitäten, Unternehmertum, gesellschaftliche Auswirkungen, Wohlstandsgefälle und Unterschiede in den Drogengesetzen der einzelnen Länder auswirken könnte.

## [Gemini Pro 1.5: KI - Spielveränderung in der Technologie](https://every.to/chain-of-thought/i-spent-a-week-with-gemini-pro-1-5-it-s-fantastic)

- Gemini Pro 1.5, ein KI-Modell von Google, hebt sich von anderen Modellen wie GPT-4 durch ein größeres Kontextfenster ab, in dem ganze Romane und Codebasen bearbeitet werden können, und zeichnet sich durch verbesserte Leistung und Benutzerfreundlichkeit aus.
- Dieses KI-Modell wird aufgrund seiner Code-Integrationsfähigkeiten, der Steigerung der Entwicklerproduktivität und der Hinwendung zu Transformer-Modellen als mentale Kopiloten als bahnbrechend angesehen.
- Der Artikel unterstreicht, wie wichtig es ist, die Ergebnisse des Modells zu überprüfen, persönliche Daten zur Leistungsverbesserung zu nutzen und die Herausforderungen und Vorteile der effektiven Nutzung großer Sprachmodelle durch gute Fragen und kritisches Denken zu verstehen.

### [Reaktionen](https://news.ycombinator.com/item?id=39481670)

- Die Diskussion befasst sich mit dem Einsatz fortgeschrittener KI-Modelle wie Gemini Pro 1.5 und geht dabei auf den Datenschutz, die gesellschaftlichen Auswirkungen und den möglichen Missbrauch ein.
- Zu den Debatten gehören die Auswirkungen auf soziale Interaktionen, KI-Anwendungen in verschiedenen Branchen, die Zuverlässigkeit und die Grenzen von KI-Chatbots sowie die Folgen der Abhängigkeit von Sprachmodellierungsalgorithmen.
- Bedenken hinsichtlich der KI-Systeme von Google, wie z. B. Voreingenommenheit und Leistungseinschränkungen, werfen Fragen zur Integrität, Effektivität und zu den gesellschaftlichen Auswirkungen von KI-Technologien auf Entscheidungsprozesse auf.

## [Mamba: Revolutionierung der Sprachmodelleffizienz](https://jackcook.com/2024/02/23/mamba.html)

- Mamba, ein neuartiges Sprachmodell von Albert Gu und Tri Dao, übertrifft Transformers an Skalierbarkeit und Effizienz, indem es das Problem der quadratischen Aufmerksamkeit mit einem sequentiellen Zustandsmodell löst.
- Durch die Diskretisierung kontinuierlicher Parameter ermöglicht Mamba eine schnellere Bearbeitung umfangreicher Abfragen, wobei Merkmale von rekurrenten und faltigen neuronalen Netzen zusammengeführt werden, um die Trainings- und Inferenzgeschwindigkeit zu erhöhen.
- Obwohl sie nicht für die ICLR-Präsentation akzeptiert wurden, stellten die Autoren parallele Algorithmen wie FlashAttention vor, um die Effizienz der GPU-Verarbeitung zu verbessern, und zeigten so das Potenzial von Mamba für die Steigerung der Sprachmodellierungsleistung.

### [Reaktionen](https://news.ycombinator.com/item?id=39482428)

- Der Schwerpunkt liegt auf der Skalierung von KI-Modellen, insbesondere auf der Diskussion des Mamba-Modells als mögliche Erweiterung von Transformers, wobei die potenziellen Vorteile und die Effektivität untersucht werden.
- Zu den Herausforderungen gehören das Trainieren großer Modelle, die Sicherstellung der Datenqualität und die Auseinandersetzung mit der komplizierten Natur verschiedener Modellarchitekturen beim Deep Learning.
- Es gibt Diskussionen über die Kombination von Mamba mit anderen Modellen wie MoE sowie über die Notwendigkeit maßgeschneiderter fusionierter Kernel für umfangreichere Trainingseinheiten.

## [Genius Dogs: 100+ Spielzeugnamen ohne Training lernen](https://www.scientificamerican.com/article/dog-language-geniuses-are-rare-but-apparently-real/)

- Bestimmte hochintelligente Hunde, insbesondere Border Collies, können sich die Namen von mehr als 100 Spielzeugen ohne gezieltes Training merken, wie eine Studie der Eötvös Loránd Universität in Ungarn zeigt.
- Die "Genius Dog Challenge"-Studie zeigt Hunde verschiedener Rassen und Länder mit außergewöhnlichen Fähigkeiten beim Erlernen von Wörtern, was die Forscher dazu veranlasst, die Faktoren zu untersuchen, die hinter dieser Fähigkeit stehen, und sie mit den Lernprozessen von Kindern zu vergleichen.
- Die Forscher wollen die sprachlichen Fähigkeiten dieser Hunde besser verstehen und herausfinden, wie sie sich von denen menschlicher Kinder unterscheiden.

### [Reaktionen](https://news.ycombinator.com/item?id=39481805)

- Hunde, insbesondere Rassen wie Australian Shepherds und Border Collies, zeichnen sich durch eine bemerkenswerte Intelligenz und Kommunikationsfähigkeit aus, indem sie beispielsweise Spielzeugnamen lernen und die menschliche Sprache verstehen.
- Das Potenzial von Hunden, mit Hilfe von Knöpfen zu kommunizieren, wird erforscht und wirft Fragen zur Intelligenz und Kommunikationsfähigkeit von Tieren auf.
- Der Schwerpunkt liegt auf der Bedeutung von Training, Pflege und Zuchtpraktiken für die Förderung und Verbesserung der kognitiven Fähigkeiten von Hunden.

## [Top-Sparkonten mit hohen Zinsen: APY reicht von 5,32% bis 5,15%](https://www.highinterest.io/)

- Die Übersicht zeigt die besten hochverzinslichen Sparkonten mit einem effektiven Jahreszins von 5,32% bis 5,15%, darunter Banken wie Customers Bank, Western Alliance Bank und TAB Bank.

### [Reaktionen](https://news.ycombinator.com/item?id=39480513)

- Die Debatte auf highinterest.io vergleicht die Sicherheit von FDIC-versicherten hochverzinslichen Sparkonten (HYSA) mit den Risiken, die mit Geldmarktfonds, Schatzwechseln und spezifischen Anlagen wie VUSXX-Fonds oder SPAXX bei Fidelity verbunden sind.
- Es werden verschiedene Anlagemöglichkeiten wie Schatzbriefe, Sparbriefe und börsengehandelte Fonds zur Optimierung der Finanzen, zum Aufbau von Notfallfonds und zur Maximierung der Renditen bei gleichzeitiger Minimierung der Risiken untersucht, wobei der Schwerpunkt auf Steuervorteilen und Solvenzüberlegungen liegt.
- Zu den Empfehlungen gehören die Beibehaltung eines diversifizierten Anlageportfolios und die Bewertung von Faktoren wie FDIC-Versicherung und Liquidität, um fundierte Entscheidungen für finanzielles Wachstum und Stabilität zu treffen.

## [Equifax stellt neue Anforderungen für kostenlose Kreditberichte](https://news.ycombinator.com/item?id=39485259)

- Die Person muss neue Anforderungen von Equifax erfüllen, um ihren kostenlosen jährlichen Kreditbericht zu erhalten, wie z. B. die Angabe einer E-Mail-Adresse und einer Mobiltelefonnummer.
- Bei dem Versuch, den Bericht per Telefon abzurufen, traten Schwierigkeiten auf, weil das System ihre Eingaben nicht erkannte.
- Es wurde eine Beschwerde bei annualcreditreport.com eingereicht, aber man wartet noch immer auf eine Antwort.

### [Reaktionen](https://news.ycombinator.com/item?id=39485259)

- Im Mittelpunkt der Diskussion stehen die unethischen Praktiken von Equifax und Kreditauskunfteien, wie z. B. das Sammeln von zu vielen persönlichen Daten, Sicherheitsmängel und mangelnde Rechenschaftspflicht.
- Zu den Empfehlungen gehören die Erforschung neuer Kreditbewertungssysteme, die Verbesserung der staatlichen Aufsicht und die Stärkung des Datenschutzes angesichts der zunehmenden Besorgnis über Datenschutzverletzungen und Identitätsdiebstahl.
- Um die Risiken zu minimieren, werden die Nutzer aufgefordert, ihren Kredit einzufrieren, Probleme den Aufsichtsbehörden zu melden und persönliche Daten zu schützen, um Betrug und Verletzungen der Privatsphäre zu verhindern.

<head>
  <meta property="og:title" content="Betrüger nutzen den guten Ruf von FedEx für Phishing-Angriffe" />
  <meta property="og:type" content="website" />
  <meta property="og:image" content="https://og.cho.sh/api/og/?title=Betr%C3%BCger%20nutzen%20den%20guten%20Ruf%20von%20FedEx%20f%C3%BCr%20Phishing-Angriffe&subheading=Samstag%2C%2024.%20Februar%202024%3A%20Hacker%20News%20Zusammenfassung" />
</head>
