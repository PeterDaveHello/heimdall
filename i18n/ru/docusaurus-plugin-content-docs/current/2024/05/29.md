---
slug: '/2024/05/29'
---

# 2024-05-29

## [Наушники с искусственным интеллектом выделяют одного говорящего в толпе с помощью распознавания взгляда](https://www.washington.edu/news/2024/05/23/ai-headphones-noise-cancelling-target-speech-hearing/)

- Университет Вашингтона (UW) разработал систему искусственного интеллекта под названием "Target Speech Hearing", которая помогает пользователям сосредоточиться на одном говорящем в шумной обстановке, глядя на него в течение трех-пяти секунд.
- Представленная на конференции ACM CHI, эта система использует машинное обучение для выделения и усиления голоса нужного диктора в режиме реального времени, даже когда пользователь двигается.
- В настоящее время технология находится на стадии доказательства концепции, она была протестирована на 21 испытуемом, которые отметили значительное улучшение четкости звука, а в будущем планируется распространить ее на наушники и слуховые аппараты.

### [Реакции](https://news.ycombinator.com/item?id=40508278)

- В тексте рассматриваются стратегии и технологии улучшения слухового восприятия в шумной обстановке, особое внимание уделяется наушникам с искусственным интеллектом, передовому звуковому дизайну и технологиям шумоподавления.
- В ней рассказывается о проблемах, связанных с тем, что современные материалы для ресторанов способствуют возникновению шума, а также об использовании звукопоглощающих технологий, несмотря на проблемы с обслуживанием и эстетикой.
- Обсуждаются такие технологические достижения, как направленные микрофоны, распознавание речи в реальном времени и селективная фильтрация звука, а также опасения по поводу конфиденциальности и возможного злоупотребления.

## [Бывший член совета директоров OpenAI раскрывает ложь и неправомерные действия, стоящие за кратковременным отстранением Сэма Альтмана от должности](https://www.businessinsider.com/openai-board-member-details-sam-altman-lied-allegation-ousted-2024-5)

- Бывший член совета директоров OpenAI Хелен Тонер сообщила, что Сэм Альтман был ненадолго отстранен от должности генерального директора из-за многочисленных случаев нечестности и сокрытия информации от совета директоров.
- Среди примеров - совет директоров, узнавший о выходе ChatGPT через Twitter, и Альтман, не раскрывший свою финансовую заинтересованность в компании, а также обвинения в предоставлении недостоверной информации о безопасности и "психологическом насилии" со стороны двух руководителей.
- Альтман был восстановлен в должности генерального директора менее чем через неделю после того, как сотрудники пригрозили уволиться, а Microsoft выразила заинтересованность в найме его команды; Тонер ушел в отставку вскоре после его возвращения.

### [Реакции](https://news.ycombinator.com/item?id=40506582)

- Генеральный директор OpenAI Сэм Альтман был ненадолго отстранен от должности, а затем вновь принят на работу, что выявило противоречия между властью совета директоров и влиянием ключевых инвесторов и основателей компании.
- Неправильное решение совета директоров по поводу увольнения Альтмана вызвало значительную реакцию сотрудников и угрозы массового увольнения, подчеркнув сложную динамику корпоративного управления, влияния сотрудников и финансовых интересов.
- Этот инцидент вызвал более широкие дискуссии о лидерстве в технологиях, этических последствиях безжалостного поведения, а также о роли коммуникации и этики в корпоративном управлении.

## [Пересмотр перенаправления HTTP-HTTPS для API с целью повышения безопасности](https://jviide.iki.fi/http-redirects)

- Перенаправление HTTP-HTTPS может раскрыть конфиденциальные данные или сделать возможными атаки типа "человек посередине" (MITM), особенно для API, доступ к которым осуществляется с помощью программного обеспечения, которое может не обрабатывать заголовки безопасности.
- Такие методы, как HSTS (HTTP Strict Transport Security) и режимы HTTPS-Only, повышают безопасность, но могут быть недостаточными для API, что подчеркивает необходимость безотказного подхода для раннего обнаружения ошибок.
- Лучшие практики должны быть обновлены, чтобы рекомендовать API полностью отклонять незашифрованные запросы и отзывать учетные данные API, отправленные через незашифрованные соединения, чтобы предотвратить риски безопасности.

### [Реакции](https://news.ycombinator.com/item?id=40504756)

- В ходе обсуждения особое внимание уделяется повышению безопасности API путем перенаправления HTTP на HTTPS и отзыва ключей API, отправленных по HTTP, для предотвращения атак типа "человек посередине" (MITM).
- В ней подчеркивается важность правильного управления ключами API, использования подписанных хэшей, несов и временных меток для аутентификации, а также необходимость использования HTTPS для обеспечения целостности и конфиденциальности данных.
- В беседе критикуется зависимость от центров сертификации и предлагаются практические решения, такие как уникальные URL или API-ключи для безопасного управления доступом в конкретных контекстах.

## [Llama3-V: Мультимодальная модель за 500 долларов превосходит GPT-4V по производительности](https://aksh-garg.medium.com/llama-3v-building-an-open-source-gpt-4v-competitor-in-under-500-7dd8f1f6c9ee)

- Llama3-V - это новая мультимодальная модель на базе Llama3, призванная конкурировать с такими крупными моделями, как GPT-4V, но по значительно более низкой цене (менее 500 долларов).
- Она превосходит современную модель Llava на 10-20% в тестах на мультимодальное понимание, используя SigLIP для встраивания изображений и выравнивания визуальных и текстовых лексем с помощью проекционного блока со слоями самовнушения.
- Основные оптимизации включают предварительный расчет вкраплений изображений и использование MPS/MLX для эффективного обучения. Процесс обучения включает предварительное обучение на 600 000 примерах и контролируемую тонкую настройку на 1 миллионе примеров.

### [Реакции](https://news.ycombinator.com/item?id=40505099)

- В статье сравниваются различные мультимодальные модели ИИ, особое внимание уделяется Llama 3-V, которая стремится сравниться с GPT-4V по производительности, но при этом меньше и дешевле.
- В нем подчеркивается, что такие модели, как InternVL-1.5 и CogVLM, превосходят Llava, а конкретные модели превосходят ее в таких задачах, как оптическое распознавание символов (OCR) и понимание графического интерфейса пользователя (GUI).
- Пользователи обсуждают практическое применение, ограничения и экономическую эффективность этих моделей, включая использование GPT-4V в производстве для визуальных задач и эффективность современных инструментов OCR, таких как PaddleOCR и TrOCR.

## [Mistral AI представляет Codestral: Мощный генеративный ИИ для генерации кода](https://mistral.ai/news/codestral/)

- 29 мая 2024 года компания Mistral AI запустила Codestral, генеративную модель искусственного интеллекта с открытым весом для генерации кода, обученную на более чем 80 языках программирования.
- Codestral имеет размер модели 22B и контекстное окно 32k, превосходя конкурентов в таких бенчмарках, как RepoBench и HumanEval.
- Codestral доступен по лицензии Mistral AI Non-Production License и может быть доступен через специальную конечную точку или интегрирован в такие инструменты, как VSCode и JetBrains. Разработчики отмечают его скорость, точность и влияние на производительность.

### [Реакции](https://news.ycombinator.com/item?id=40512250)

- Модель кода Mistral, опубликованная на сайте mistral.ai, имеет ограничительную лицензию, запрещающую коммерческое использование, использование в реальных условиях и внутри компании, что ограничивает ее практическое применение и вызывает критику.
- Споры вокруг лицензии Mistral освещают более широкие вопросы авторского права и лицензирования контента, создаваемого ИИ, а также неправильное использование термина "открытый исходный код" в ИИ.
- Пользователи выражают недовольство непоследовательной генерацией кода ИИ, особенно в сложных задачах, и обсуждают ограничения и возможности различных моделей ИИ, включая модели Llama от Meta и GPT от OpenAI.

## [Ключевые уроки, полученные за год работы с большими языковыми моделями (часть I)](https://www.oreilly.com/radar/what-we-learned-from-a-year-of-building-with-llms-part-i/)

- В статье "Что мы узнали за год работы с LLM (часть I)" Юджин Ян и его коллеги рассказывают о стремительном развитии и практическом применении больших языковых моделей (LLM), а также рассматривают проблемы разработки эффективных продуктов ИИ.
- Основные уроки включают в себя передовые методы подсказки, генерации с расширением поиска (RAG), разработки потока и оценки, причем особое внимание уделяется таким техникам, как подсказки n-shot и подсказки по цепочке мыслей.
- В статье также даются оперативные советы по управлению агентами ИИ, уточнению подсказок, тонкой настройке моделей, снижению затрат и задержек за счет кэширования, при этом особое внимание уделяется практическим оценкам и подходам, ориентированным на человека.

### [Реакции](https://news.ycombinator.com/item?id=40508390)

- Результаты года работы с большими языковыми моделями (LLM) подчеркивают важность многократной выборки для снижения частоты галлюцинаций и создания обоснований перед принятием решений для получения более точных результатов.
- В статье обсуждаются проблемы оценки результатов LLM, влияние температуры на случайность результатов и заблуждения о выборке, а также опыт использования таких инструментов, как патчботы и поиск луча.
- В нем рассматриваются такие проблемы отрасли, как высокий процент ошибок, инвестиции, вызванные FOMO, и агрессивное стремление таких компаний, как Google, интегрировать ИИ, несмотря на потенциальные проблемы с качеством обслуживания.

## [Эксперт предупреждает, что введение обязательного возвращения в офис чревато потерей лучших талантов.](https://www.rte.ie/brainstorm/2024/0521/1450272-return-to-office-mandates-employees-work-from-home/)

- Профессор Кевин Мерфи из Университета Лимерика утверждает, что удаленные сотрудники более продуктивны и удовлетворены работой по сравнению с теми, кто трудится в офисах.
- Принятие требований о возвращении в офис (RTO) после пандемии чревато потерей лучших кадров, поскольку многие сотрудники теперь не приемлют традиционных офисных норм.
- Руководители должны предоставить убедительные причины и стимулы для возвращения в офис, признавая изменения в динамике власти в пользу сотрудников, иначе они рискуют потерять ценные кадры в пользу более гибких конкурентов.

### [Реакции](https://news.ycombinator.com/item?id=40509409)

- Споры между удаленной работой и мандатами на возвращение в офис (RTO) ведутся вокруг гибкости, комфорта и потенциальной потери сотрудников, предпочитающих удаленную работу.
- Для одних поездка на работу дает возможность отдохнуть, но для других создает такие проблемы, как загрязнение окружающей среды, высокая стоимость и размытые границы, что влияет на баланс между работой и личной жизнью и карьерный рост.
- Удаленная работа рассматривается как более эффективная и устойчивая, дающая такие преимущества, как увеличение семейного времени и сокращение выбросов углекислого газа, но при этом может игнорировать младший персонал и требует четкого информирования о преимуществах RTO.

## [Канадский законопроект C-26: Спорные полномочия по установке сетевых черных ходов для слежки](https://www.theglobeandmail.com/opinion/article-ottawa-wants-the-power-to-create-secret-backdoors-in-our-networks-to/)

- Законопроект C-26, федеральный закон о кибербезопасности в Канаде, наделяет правительство полномочиями заставлять телекоммуникационные компании устанавливать "черные ходы" в зашифрованных сетях, что может поставить под угрозу безопасность.
- Критики, включая Citizen Lab Университета Торонто, утверждают, что эти меры ослабят шифрование 5G и другие средства защиты, что повысит уязвимость к киберугрозам.
- Несмотря на предупреждения экспертов, законопроект был принят без поправок, что противоречит позиции Канады по защите шифрования и может создать опасный прецедент для других стран.

### [Реакции](https://news.ycombinator.com/item?id=40512509)

- Канадское правительство стремится получить полномочия на создание секретных "черных ходов" в телекоммуникационных сетях для слежки в обход традиционного правового контроля, что вызывает серьезные опасения в отношении конфиденциальности и возможности злоупотреблений со стороны правоохранительных органов.
- Критики утверждают, что это может привести к инвазивному мониторингу, схожему с практикой АНБ, что повлечет за собой споры о конституции Канады, "положении о невзирании" и возможностях законного перехвата.
- Обсуждаются исторические примеры слежки, например, во время протестов дальнобойщиков, а также более широкие темы, связанные с превышением полномочий правительства, неприкосновенностью частной жизни и реакцией общества на власть.

## [Три фундаментальных закона, управляющих неизбежной сложностью программных систем](https://maheshba.bitbucket.io/blog/2024/05/08/2024-ThreeLaws.html)

- В статье рассматриваются три фундаментальных закона, способствующих возникновению излишней сложности в программной инженерии, особенно в инфраструктурных системах.
- **Первый закон**: Хорошо спроектированные системы со временем превращаются в плохо спроектированные из-за постоянных модификаций.
- **Второй закон**: Сложность возрастает по мере того, как успешные системы отдают приоритет доле рынка, а не хорошему абстрактному дизайну, что приводит к появлению трудноизменяемых систем.
- **Третий закон**: Не существует верхнего предела сложности программного обеспечения, обусловленного различными способностями и философией разработчиков, что приводит к созданию замысловатых конструкций.

### [Реакции](https://news.ycombinator.com/item?id=40509572)

- В ходе дискуссии обсуждаются проблемы управления сложностью программного обеспечения, особенно в унаследованных системах, и компромиссы между стоимостью и качеством, которые часто приводят к возникновению технического долга.
- В ней подчеркивается важность инкрементного рефакторинга, поддержания сильной инженерной культуры и различения существенной и случайной сложности для эффективного управления программным обеспечением.
- Участники рассказывают о необходимости непрерывного сопровождения, о влиянии неправильного выбора вариантов разработки и о роли поддержки руководства в оправдании усилий по рефакторингу.

## [От стартапа до продажи: Путешествие Майкла Линча с TinyPilot](https://mtlynch.io/i-sold-tinypilot/)

- В середине 2020 года Майкл Линч создал TinyPilot - устройство для удаленного управления серверами, которое быстро завоевало популярность и превратилось в бизнес с годовым доходом в $1 млн и командой из семи человек.
- Линч продал TinyPilot за 600 тысяч долларов, получив 490 803 доллара после расходов, из-за стресса, связанного с управлением аппаратным бизнесом, и желания вернуться к кодингу и завести семью.
- Продажа, осуществленная при содействии Quiet Light Brokerage, была сопряжена с такими трудностями, как преодоление стресса основателя, поиск покупателя и проведение юридической проверки; покупателем стал Скотт, специалист по корпоративным СМИ.

### [Реакции](https://news.ycombinator.com/item?id=40512500)

- Майкл Линч продал свой бизнес, TinyPilot, и рассказал о значительных расходах, связанных с продажей, включая брокерские комиссии и юридические издержки, которые составили около 18% от цены продажи.
- Предпринимательский путь Линча включал в себя переход от высокооплачиваемой работы в Google к ценности автономии и творчества, подчеркивание образовательной ценности предпринимательства и критику сосредоточенности технологической индустрии на общей компенсации.
- В планах Линча - создание будущих предприятий с упором на образовательные продукты и программное обеспечение как услугу (SaaS), избегая аппаратного обеспечения из-за его сложности и проблем.

## [Бывший член совета директоров OpenAI раскрывает причины увольнения и восстановления Сэма Альтмана](https://www.theverge.com/2024/5/28/24166713/openai-helen-toner-explains-why-sam-altman-was-fired)

- В ноябре 2023 года совет директоров OpenAI неожиданно уволил генерального директора Сэма Альтмана, сославшись на "откровенную ложь" и манипулятивное поведение, которые подорвали доверие.
- Среди конкретных вопросов - нераскрытое владение Альтманом стартап-фондом OpenAI, предоставление недостоверной информации о безопасности и создание токсичной рабочей обстановки.
- Несмотря на эти обвинения, внутреннее и внешнее давление, включая поддержку со стороны сотрудников и Microsoft, привело к восстановлению Альтмана в должности, а независимая экспертиза не выявила никаких проблем с безопасностью продукции или деятельностью компании.

### [Реакции](https://news.ycombinator.com/item?id=40509399)

- Бывший член совета директоров OpenAI сообщил, что Сэм Альтман был уволен из-за нечестности, что ставит под сомнение осведомленность совета директоров о запуске ChatGPT.
- Ситуация вызвала дискуссии о прозрачности организации, контроле со стороны совета директоров и этике управления, а также сравнения с такими корпоративными крахами, как Enron.
- Скептицизм в отношении доверия и безопасности OpenAI сопровождается уходом сотрудников и критикой руководства Альтмана, а также дебатами о технической квалификации и роли совета директоров.

## [Утечка из поисковой системы Google раскрывает секреты алгоритма ранжирования и 2 596 модулей](https://searchengineland.com/google-search-document-leak-ranking-442617)

- Крупная утечка внутренних документов Google Search раскрыла важнейшие аспекты алгоритма ранжирования Google, включая использование кликов, ссылок, контента, сущностей и данных Chrome.
- Эксперты отрасли Рэнд Фишкин и Майкл Кинг проанализировали документы, выявив 2 596 модулей ранжирования, значение разнообразия ссылок, релевантности, успешных кликов и узнаваемости бренда.
- Документы также раскрывают информацию об использовании Google информации об авторе, авторитетности сайта и "накрутчиков" для корректировки ранжирования, предлагая ценные сведения для SEO-специалистов, несмотря на неизвестность точного веса факторов ранжирования.

### [Реакции](https://news.ycombinator.com/item?id=40510125)

- Утечка документа Google Search вызвала споры об алгоритме ранжирования и влиянии рекламной программы Google на результаты поиска.
- Пользователи обсуждают такие альтернативы, как Kagi и search.marginalia.nu, и неоднозначно отзываются о настройке Kagi, его некоммерческой направленности и проблемах со спамом и контентом, создаваемым искусственным интеллектом.
- В ходе беседы было высказано пожелание, чтобы поисковые системы ставили во главу угла предпочтения пользователей, а не доходы от рекламы, затронуты вопросы SEO-манипуляций, потенциал больших языковых моделей (LLM), а также опасения по поводу подлинности онлайн-отзывов и критериев ранжирования Google.

## [ChatTTS: усовершенствованная модель TTS с открытым исходным кодом для естественного диалога на английском и китайском языках](https://github.com/2noise/ChatTTS)

- ChatTTS - это модель преобразования текста в речь (TTS), оптимизированная для диалогов, поддерживающая английский и китайский языки и обученная на более чем 100 000 часов данных.
- Версия с открытым исходным кодом на HuggingFace включает 40 000-часовую предварительно обученную модель, превосходящую по естественности и выразительности синтез речи с тонким просодическим контролем.
- Модель предназначена только для академического использования, а в будущем планируется открыть дополнительные функции и повысить стабильность.

### [Реакции](https://news.ycombinator.com/item?id=40507039)

- Обсуждаются вопросы разработки и производительности таких моделей TTS, как ChatTTS и Piper TTS, отмечаются такие проблемы, как медленная обработка и проблемы с качеством голоса.
- Пользователи подчеркивают необходимость высококачественных TTS на нескольких языках и обсуждают эффективность человеческих и автоматических голосов в аудиокнигах.
- Критика вводящих в заблуждение заявлений об "открытом исходном коде" в проектах TTS и призыв к составлению полного списка действительно открытых моделей и данных TTS.

## [Google молчит о предполагаемой утечке 2 500 страниц с подробностями алгоритма поиска](https://www.theverge.com/2024/5/28/24166177/google-search-ranking-algorithm-leak-documents-link-seo)

- Утечка 2500 страниц внутренних документов Google, которой поделился SEO-эксперт Рэнд Фишкин, может выявить расхождения между публичными заявлениями Google и ее реальной практикой в отношении поисковых алгоритмов.
- Документы свидетельствуют об использовании данных Chrome при ранжировании и отслеживании информации об авторах, опровергая предыдущие утверждения Google и вызывая споры о прозрачности компании.
- Компания Google не прокомментировала законность документов, и этот инцидент подчеркивает постоянную обеспокоенность непрозрачным характером поисковых операций Google в условиях антимонопольного контроля.

### [Реакции](https://news.ycombinator.com/item?id=40505310)

- Утечка документации по поисковым алгоритмам Google выявила потенциальные расхождения между публичными заявлениями Google и их реальной практикой.
- Утечка говорит о том, что представители Google могли дискредитировать точные выводы маркетинговых, технологических и журналистских сообществ, что вызывает этические опасения по поводу SEO-манипуляций.
- В юридических дискуссиях на GitHub обсуждаются значение и законность утечки, высказываются различные мнения о ее влиянии на статус коммерческой тайны и защиту авторских прав.

<head>
  <meta property="og:title" content="Наушники с искусственным интеллектом выделяют одного говорящего в толпе с помощью распознавания взгляда" />
  <meta property="og:type" content="website" />
  <meta property="og:image" content="https://og.cho.sh/api/og/?title=%D0%9D%D0%B0%D1%83%D1%88%D0%BD%D0%B8%D0%BA%D0%B8%20%D1%81%20%D0%B8%D1%81%D0%BA%D1%83%D1%81%D1%81%D1%82%D0%B2%D0%B5%D0%BD%D0%BD%D1%8B%D0%BC%20%D0%B8%D0%BD%D1%82%D0%B5%D0%BB%D0%BB%D0%B5%D0%BA%D1%82%D0%BE%D0%BC%20%D0%B2%D1%8B%D0%B4%D0%B5%D0%BB%D1%8F%D1%8E%D1%82%20%D0%BE%D0%B4%D0%BD%D0%BE%D0%B3%D0%BE%20%D0%B3%D0%BE%D0%B2%D0%BE%D1%80%D1%8F%D1%89%D0%B5%D0%B3%D0%BE%20%D0%B2%20%D1%82%D0%BE%D0%BB%D0%BF%D0%B5%20%D1%81%20%D0%BF%D0%BE%D0%BC%D0%BE%D1%89%D1%8C%D1%8E%20%D1%80%D0%B0%D1%81%D0%BF%D0%BE%D0%B7%D0%BD%D0%B0%D0%B2%D0%B0%D0%BD%D0%B8%D1%8F%20%D0%B2%D0%B7%D0%B3%D0%BB%D1%8F%D0%B4%D0%B0&subheading=%D1%81%D1%80%D0%B5%D0%B4%D0%B0%2C%2029%20%D0%BC%D0%B0%D1%8F%202024%20%D0%B3.%3A%20%D0%A1%D0%B2%D0%BE%D0%B4%D0%BA%D0%B0%20%D0%BD%D0%BE%D0%B2%D0%BE%D1%81%D1%82%D0%B5%D0%B9%20Hacker%20News" />
</head>
