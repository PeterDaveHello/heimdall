---
slug: '/2024/05/29'
---

# 2024-05-29

## [หูฟัง AI แยกลําโพงตัวเดียวในฝูงชนโดยการตรวจจับการจ้องมอง](https://www.washington.edu/news/2024/05/23/ai-headphones-noise-cancelling-target-speech-hearing/)

- มหาวิทยาลัยวอชิงตัน (UW) ได้พัฒนาระบบ AI ชื่อ "Target Speech Hearing" ซึ่งช่วยให้ผู้ใช้จดจ่อกับลําโพงตัวเดียวในสภาพแวดล้อมที่มีเสียงดังโดยมองไปที่ลําโพงเหล่านี้เป็นเวลาสามถึงห้าวินาที
- นําเสนอในการประชุม ACM CHI ระบบนี้ใช้แมชชีนเลิร์นนิงเพื่อแยกและขยายเสียงของผู้พูดที่ต้องการแบบเรียลไทม์
- ขณะนี้อยู่ในขั้นตอนการพิสูจน์แนวคิดเทคโนโลยีได้รับการทดสอบกับอาสาสมัคร 21 คนที่รายงานว่ามีความชัดเจนที่ดีขึ้นอย่างมีนัยสําคัญโดยมีแผนในอนาคตที่จะขยายไปยังเอียร์บัดและเครื่องช่วยฟัง

### [ปฏิกิริยา](https://news.ycombinator.com/item?id=40508278)

- ข้อความสํารวจกลยุทธ์และเทคโนโลยีเพื่อปรับปรุงประสบการณ์การได้ยินในสภาพแวดล้อมที่มีเสียงดัง โดยเน้นที่หูฟัง AI การออกแบบเสียงขั้นสูง และเทคโนโลยีตัดเสียงรบกวน
- เน้นย้ําถึงความท้าทายของวัสดุร้านอาหารสมัยใหม่ที่ก่อให้เกิดเสียงรบกวนและการใช้เทคนิคการลดเสียงแม้จะมีปัญหาด้านการบํารุงรักษาและความสวยงาม
- มีการหารือเกี่ยวกับความก้าวหน้าทางเทคโนโลยี เช่น ไมโครโฟนแบบกําหนดทิศทาง การรู้จําเสียงแบบเรียลไทม์ และการกรองเสียงแบบเลือก พร้อมกับข้อกังวลเกี่ยวกับความเป็นส่วนตัวและการใช้งานในทางที่ผิดที่อาจเกิดขึ้น

## [อดีตสมาชิกคณะกรรมการ OpenAI เปิดเผยคําโกหกและการประพฤติมิชอบเบื้องหลังการขับไล่ช่วงสั้นๆ ของ Sam Altman](https://www.businessinsider.com/openai-board-member-details-sam-altman-lied-allegation-ousted-2024-5)

- Helen Toner อดีตสมาชิกคณะกรรมการ OpenAI เปิดเผยว่า Sam Altman ถูกปลดออกจากตําแหน่ง CEO ในช่วงสั้นๆ เนื่องจากความไม่ซื่อสัตย์และการระงับข้อมูลจากคณะกรรมการหลายครั้ง
- ตัวอย่าง ได้แก่ คณะกรรมการที่เรียนรู้เกี่ยวกับการเปิดตัว ChatGPT ผ่าน Twitter และ Altman ไม่เปิดเผยผลประโยชน์ทางการเงินของเขาในบริษัท พร้อมกับข้อกล่าวหาว่าให้ข้อมูลด้านความปลอดภัยที่ไม่ถูกต้องและ "การล่วงละเมิดทางจิตใจ" โดยผู้บริหารสองคน
- Altman ได้รับการคืนสถานะเป็น CEO น้อยกว่าหนึ่งสัปดาห์ต่อมาหลังจากที่พนักงานขู่ว่าจะลาออกและ Microsoft แสดงความสนใจที่จะจ้างทีมของเขา โทนเนอร์ลาออกไม่นานหลังจากที่เขากลับมา

### [ปฏิกิริยา](https://news.ycombinator.com/item?id=40506582)

- Sam Altman ซีอีโอของ OpenAI ถูกขับไล่ชั่วครู่แล้วจ้างใหม่ เผยให้เห็นความตึงเครียดระหว่างอํานาจของคณะกรรมการและอิทธิพลของนักลงทุนและผู้ก่อตั้งรายสําคัญ
- การจัดการที่ผิดพลาดของคณะกรรมการในการไล่ออกของ Altman นําไปสู่ฟันเฟืองของพนักงานที่สําคัญและการขู่ว่าจะลาออกจํานวนมากซึ่งเน้นย้ําถึงพลวัตที่ซับซ้อนของการกํากับดูแลกิจการอิทธิพลของพนักงานและผลประโยชน์ทางการเงิน
- เหตุการณ์ดังกล่าวจุดประกายการอภิปรายในวงกว้างเกี่ยวกับความเป็นผู้นําในด้านเทคโนโลยีผลกระทบทางจริยธรรมของพฤติกรรมที่โหดเหี้ยมและบทบาทของการสื่อสารและจริยธรรมในการกํากับดูแลกิจการ

## [พิจารณาการเปลี่ยนเส้นทาง HTTP-to-HTTPS สําหรับ API อีกครั้งเพื่อเพิ่มความปลอดภัย](https://jviide.iki.fi/http-redirects)

- การเปลี่ยนเส้นทาง HTTP-to-HTTPS สามารถเปิดเผยข้อมูลที่ละเอียดอ่อนหรือเปิดใช้งานการโจมตีแบบ Man-In-The-Middle (MITM) โดยเฉพาะอย่างยิ่งสําหรับ API ที่เข้าถึงโดยซอฟต์แวร์ที่อาจไม่สามารถจัดการส่วนหัวด้านความปลอดภัยได้
- เทคนิคต่างๆ เช่น HSTS (HTTP Strict Transport Security) และโหมด HTTPS-Only ช่วยปรับปรุงความปลอดภัย แต่อาจไม่เพียงพอสําหรับ API โดยเน้นย้ําถึงความจําเป็นในการใช้วิธีการที่รวดเร็วในการตรวจจับข้อผิดพลาดตั้งแต่เนิ่นๆ
- แนวทางปฏิบัติที่ดีที่สุดควรได้รับการอัปเดตเพื่อแนะนําให้ API ปฏิเสธคําขอที่ไม่ได้เข้ารหัสทั้งหมด และเพิกถอนข้อมูลเข้าสู่ระบบ API ที่ส่งผ่านการเชื่อมต่อที่ไม่ได้เข้ารหัสเพื่อป้องกันความเสี่ยงด้านความปลอดภัย

### [ปฏิกิริยา](https://news.ycombinator.com/item?id=40504756)

- การอภิปรายเน้นย้ําถึงการเพิ่มความปลอดภัยของ API โดยการเปลี่ยนเส้นทาง HTTP ไปยัง HTTPS และเพิกถอนคีย์ API ที่ส่งผ่าน HTTP เพื่อป้องกันการโจมตีแบบ Man-in-the-Middle (MITM)
- โดยเน้นย้ําถึงความสําคัญของการจัดการคีย์ API ที่เหมาะสม โดยใช้แฮช nonces และการประทับเวลาที่มีลายเซ็นสําหรับการตรวจสอบสิทธิ์ และความจําเป็นของ HTTPS สําหรับความสมบูรณ์ของข้อมูลและความเป็นส่วนตัว
- การสนทนาวิพากษ์วิจารณ์การพึ่งพาผู้ออกใบรับรองและแนะนําวิธีแก้ปัญหาที่ใช้งานได้จริง เช่น URL ที่ไม่ซ้ํากันหรือคีย์ API สําหรับการควบคุมการเข้าถึงที่ปลอดภัยในบริบทเฉพาะ

## [Llama3-V: โมเดลต่อเนื่องหลายรูปแบบมูลค่า $500 เป็นคู่แข่งกับ GPT-4V ในด้านประสิทธิภาพ](https://aksh-garg.medium.com/llama-3v-building-an-open-source-gpt-4v-competitor-in-under-500-7dd8f1f6c9ee)

- Llama3-V เป็นโมเดลต่อเนื่องหลายรูปแบบใหม่ที่ใช้ Llama3 ซึ่งออกแบบมาเพื่อแข่งขันกับรุ่นที่ใหญ่กว่า เช่น GPT-4V แต่มีต้นทุนที่ต่ํากว่ามาก (ต่ํากว่า 500 ดอลลาร์)
- มันเหนือกว่าโมเดลที่ล้ําสมัยในปัจจุบัน Llava โดย 10-20% ในเกณฑ์มาตรฐานความเข้าใจต่อเนื่องหลายรูปแบบ โดยใช้ SigLIP สําหรับการฝังรูปภาพและจัดแนวโทเค็นภาพและข้อความผ่านบล็อกการฉายภาพที่มีเลเยอร์ความสนใจในตนเอง
- การเพิ่มประสิทธิภาพที่สําคัญ ได้แก่ การฝังภาพก่อนการคํานวณและการใช้ประโยชน์จาก MPS/MLX เพื่อการฝึกอบรมที่มีประสิทธิภาพ โดยมีกระบวนการฝึกอบรมที่เกี่ยวข้องกับการฝึกอบรมล่วงหน้ากับตัวอย่าง 600,000 ตัวอย่าง และการปรับแต่งอย่างละเอียดภายใต้การดูแล 1 ล้านตัวอย่าง

### [ปฏิกิริยา](https://news.ycombinator.com/item?id=40505099)

- บทความนี้เปรียบเทียบโมเดล AI ต่อเนื่องหลายรูปแบบ โดยเน้นที่ Llama 3-V ซึ่งมีจุดมุ่งหมายเพื่อให้ตรงกับประสิทธิภาพของ GPT-4V แต่มีขนาดเล็กกว่าและถูกกว่า
- โดยเน้นว่าโมเดลอย่าง InternVL-1.5 และ CogVLM มีประสิทธิภาพเหนือกว่า Llava โดยรุ่นเฉพาะมีความโดดเด่นในงานต่างๆ เช่น OCR (การรู้จําอักขระด้วยแสง) และความเข้าใจ GUI (ส่วนต่อประสานกราฟิกกับผู้ใช้)
- ข้อจํากัด และความคุ้มค่าของโมเดลเหล่านี้ รวมถึงการใช้ GPT-4V ในการผลิตสําหรับงานภาพ และประสิทธิภาพของเครื่องมือ OCR สมัยใหม่ เช่น PaddleOCR และ TrOCR

## [Mistral AI เปิดตัว Codestral: AI กําเนิดที่ทรงพลังสําหรับการสร้างโค้ด](https://mistral.ai/news/codestral/)

- เมื่อวันที่ 29 พฤษภาคม 2024 Mistral AI ได้เปิดตัว Codestral ซึ่งเป็นโมเดล AI กําเนิดแบบเปิดสําหรับการสร้างโค้ด ซึ่งได้รับการฝึกฝนเกี่ยวกับภาษาโปรแกรมมากกว่า 80 ภาษา
- Codestral มีขนาดโมเดล 22B และหน้าต่างบริบท 32k ซึ่งมีประสิทธิภาพเหนือกว่าคู่แข่งในเกณฑ์มาตรฐาน เช่น RepoBench และ HumanEval
- มีให้ใช้งานภายใต้ใบอนุญาตที่ไม่ใช่การผลิตของ Mistral AI Codestral สามารถเข้าถึงได้ผ่านปลายทางเฉพาะหรือรวมเข้ากับเครื่องมือต่างๆ เช่น VSCode และ JetBrains โดยนักพัฒนาต่างยกย่องความเร็ว ความแม่นยํา และผลกระทบต่อประสิทธิภาพการทํางาน

### [ปฏิกิริยา](https://news.ycombinator.com/item?id=40512250)

- Mistral's Code Model ซึ่งเผยแพร่โดย mistral.ai มีใบอนุญาตที่เข้มงวดซึ่งห้ามการใช้งานเชิงพาณิชย์สภาพความเป็นอยู่และการใช้งานภายในของ บริษัท จํากัด การใช้งานจริงและทําให้เกิดการวิพากษ์วิจารณ์
- การถกเถียงเกี่ยวกับใบอนุญาตของ Mistral เน้นประเด็นที่กว้างขึ้นเกี่ยวกับลิขสิทธิ์และการออกใบอนุญาตในเนื้อหาที่สร้างโดย AI และการใช้คําว่า "โอเพ่นซอร์ส" ในทางที่ผิดใน AI
- ผู้ใช้แสดงความไม่พอใจกับการสร้างโค้ดที่ไม่สอดคล้องกันของ AI โดยเฉพาะอย่างยิ่งในงานที่ซับซ้อน และหารือเกี่ยวกับข้อจํากัดและความสามารถของโมเดล AI ต่างๆ รวมถึง Llama ของ Meta และโมเดล GPT ของ OpenAI

## [บทเรียนสําคัญจากปีแห่งการสร้างแบบจําลองภาษาขนาดใหญ่ (ตอนที่ 1)](https://www.oreilly.com/radar/what-we-learned-from-a-year-of-building-with-llms-part-i/)

- บทความ "สิ่งที่เราเรียนรู้จากหนึ่งปีของการสร้างด้วย LLMs (ตอนที่ 1)" โดย Eugene Yan และเพื่อนร่วมงานสํารวจความก้าวหน้าอย่างรวดเร็วและการใช้งานจริงของโมเดลภาษาขนาดใหญ่ (LLM) ในขณะที่จัดการกับความท้าทายในการพัฒนาผลิตภัณฑ์ AI ที่มีประสิทธิภาพ
- บทเรียนสําคัญ ได้แก่ แนวทางปฏิบัติที่ดีที่สุดในการกระตุ้นเตือน การสร้างการดึงข้อมูล (RAG) วิศวกรรมโฟลว์ และการประเมินผล โดยเน้นเทคนิคต่างๆ เช่น การแจ้ง n-shot และการกระตุ้นห่วงโซ่ความคิด
- บทความนี้ยังให้คําแนะนําด้านการปฏิบัติงานเกี่ยวกับการจัดการตัวแทน AI การปรับแต่งพร้อมท์ การปรับแต่งโมเดลอย่างละเอียด และการลดต้นทุนและเวลาแฝงผ่านการแคช โดยเน้นการประเมินเชิงปฏิบัติและแนวทางที่เน้นมนุษย์เป็นศูนย์กลาง

### [ปฏิกิริยา](https://news.ycombinator.com/item?id=40508390)

- ข้อมูลเชิงลึกจากหนึ่งปีของการทํางานกับ Large Language Models (LLM) เน้นย้ําถึงความสําคัญของการสุ่มตัวอย่างหลายครั้งเพื่อลดอัตราการเห็นภาพหลอนและสร้างเหตุผลก่อนการตัดสินใจเพื่อให้ได้ผลลัพธ์ที่แม่นยํายิ่งขึ้น
- บทความนี้กล่าวถึงความท้าทายในการประเมินเอาต์พุต LLM ผลกระทบของอุณหภูมิต่อการสุ่มเอาต์พุต และความเข้าใจผิดเกี่ยวกับการสุ่มตัวอย่าง พร้อมด้วยประสบการณ์ในการใช้เครื่องมือต่างๆ เช่น แพตช์บอทและการค้นหาลําแสง
- มันจัดการกับความกังวลในอุตสาหกรรมเช่นอัตราข้อผิดพลาดสูงการลงทุนที่ขับเคลื่อนด้วย FOMO และการผลักดันเชิงรุกโดย บริษัท ต่างๆเช่น Google เพื่อรวม AI แม้จะมีปัญหาคุณภาพบริการที่อาจเกิดขึ้น

## [คําสั่งให้กลับเข้าสํานักงานเสี่ยงสูญเสียผู้มีความสามารถระดับสูงเตือนผู้เชี่ยวชาญ](https://www.rte.ie/brainstorm/2024/0521/1450272-return-to-office-mandates-employees-work-from-home/)

- ศาสตราจารย์ Kevin Murphy จาก University of Limerick อ้างว่าพนักงานทางไกลมีประสิทธิผลและความพึงพอใจมากกว่าเมื่อเทียบกับผู้ที่ทํางานในสํานักงาน
- การผลักดันให้ Return to Office (RTO) กําหนดให้หลังเกิดโรคระบาดมีความเสี่ยงที่จะสูญเสียผู้มีความสามารถระดับสูง เนื่องจากปัจจุบันพนักงานจํานวนมากปฏิเสธบรรทัดฐานของสํานักงานแบบดั้งเดิม
- ผู้บริหารควรให้เหตุผลและแรงจูงใจที่น่าสนใจในการกลับมาที่สํานักงานยอมรับการเปลี่ยนแปลงของพลวัตของอํานาจที่เอื้อต่อพนักงานหรือเสี่ยงต่อการสูญเสียความสามารถอันมีค่าให้กับคู่แข่งที่ยืดหยุ่นมากขึ้น

### [ปฏิกิริยา](https://news.ycombinator.com/item?id=40509409)

- การถกเถียงกันระหว่างการทํางานระยะไกลและการกลับสู่สํานักงาน (RTO) กําหนดให้มุ่งเน้นไปที่ความยืดหยุ่นความสะดวกสบายและการสูญเสียพนักงานที่ชอบทํางานระยะไกล
- การเดินทางทําให้บางคนได้พักสมอง แต่นําเสนอความท้าทาย เช่น มลพิษ ค่าใช้จ่ายสูง และขอบเขตที่พร่ามัวสําหรับผู้อื่น ซึ่งส่งผลต่อความสมดุลระหว่างชีวิตและการทํางานและการเติบโตของอาชีพ
- การทํางานทางไกลถูกมองว่ามีประสิทธิภาพและยั่งยืนมากขึ้น โดยให้ประโยชน์ต่างๆ เช่น เวลาครอบครัวที่เพิ่มขึ้นและการปล่อยคาร์บอนที่ลดลง แต่อาจละเลยพนักงานรุ่นเยาว์และต้องการการสื่อสารที่ชัดเจนเกี่ยวกับผลประโยชน์ของ RTO

## [Bill C-26 ของแคนาดา: อํานาจที่เป็นที่ถกเถียงกันในการติดตั้งแบ็คดอร์เครือข่ายสําหรับการเฝ้าระวัง](https://www.theglobeandmail.com/opinion/article-ottawa-wants-the-power-to-create-secret-backdoors-in-our-networks-to/)

- Bill C-26 ซึ่งเป็นร่างกฎหมายความปลอดภัยทางไซเบอร์ของรัฐบาลกลางในแคนาดา ให้อํานาจรัฐบาลในการบังคับให้บริษัทโทรคมนาคมติดตั้งแบ็คดอร์ในเครือข่ายที่เข้ารหัส ซึ่งอาจส่งผลต่อความปลอดภัย
- นักวิจารณ์รวมถึง Citizen Lab ของมหาวิทยาลัยโตรอนโตโต้แย้งว่ามาตรการเหล่านี้จะทําให้การเข้ารหัส 5G และคุณสมบัติด้านความปลอดภัยอื่น ๆ อ่อนแอลงซึ่งจะเพิ่มความเสี่ยงต่อภัยคุกคามทางไซเบอร์
- แม้จะมีคําเตือนจากผู้เชี่ยวชาญ แต่ร่างกฎหมายดังกล่าวก็ก้าวหน้าโดยไม่มีการแก้ไข ซึ่งขัดแย้งกับจุดยืนในการเข้ารหัสของแคนาดาและอาจเป็นแบบอย่างที่อันตรายสําหรับประเทศอื่นๆ

### [ปฏิกิริยา](https://news.ycombinator.com/item?id=40512509)

- รัฐบาลแคนาดากําลังมองหาอํานาจในการสร้างแบ็คดอร์ลับในเครือข่ายโทรคมนาคมสําหรับการเฝ้าระวัง โดยข้ามการกํากับดูแลทางกฎหมายแบบดั้งเดิม ซึ่งทําให้เกิดข้อกังวลด้านความเป็นส่วนตัวที่สําคัญและอาจนําไปสู่การละเมิดโดยหน่วยงานบังคับใช้กฎหมาย
- นักวิจารณ์โต้แย้งว่าสิ่งนี้อาจนําไปสู่การตรวจสอบที่รุกรานซึ่งคล้ายกับแนวทางปฏิบัติของ NSA ซึ่งเกี่ยวข้องกับการอภิปรายเกี่ยวกับรัฐธรรมนูญของแคนาดา "แม้จะมีมาตรา" และความสามารถในการสกัดกั้นที่ชอบด้วยกฎหมาย
- การอภิปรายประกอบด้วยตัวอย่างทางประวัติศาสตร์ของการเฝ้าระวัง เช่น ระหว่างการประท้วงของคนขับรถบรรทุก และหัวข้อที่กว้างขึ้นเกี่ยวกับการเข้าถึงของรัฐบาล ความเป็นส่วนตัว และการตอบสนองทางสังคมต่อผู้มีอํานาจ

## [กฎหมายพื้นฐานสามข้อที่ควบคุมความซับซ้อนที่หลีกเลี่ยงไม่ได้ของระบบซอฟต์แวร์](https://maheshba.bitbucket.io/blog/2024/05/08/2024-ThreeLaws.html)

- บทความนี้กล่าวถึงกฎพื้นฐานสามข้อที่ก่อให้เกิดความซับซ้อนที่ไม่จําเป็นในวิศวกรรมซอฟต์แวร์ โดยเฉพาะอย่างยิ่งในระบบโครงสร้างพื้นฐาน
- **กฎข้อที่หนึ่ง**: ระบบที่ออกแบบมาอย่างดีจะเสื่อมสภาพเป็นระบบที่ออกแบบมาไม่ดีเมื่อเวลาผ่านไปเนื่องจากการปรับเปลี่ยนอย่างต่อเนื่อง
- **กฎข้อที่สอง**: ความซับซ้อนเพิ่มขึ้นเนื่องจากระบบที่ประสบความสําเร็จให้ความสําคัญกับส่วนแบ่งการตลาดมากกว่าการออกแบบนามธรรมที่ดี ซึ่งนําไปสู่ระบบที่ปรับเปลี่ยนได้ยาก
- **กฎข้อที่สาม**: ไม่มีขีดจํากัดสูงสุดของความซับซ้อนของซอฟต์แวร์ ซึ่งขับเคลื่อนโดยความสามารถและปรัชญาที่หลากหลายของนักพัฒนา

### [ปฏิกิริยา](https://news.ycombinator.com/item?id=40509572)

- การอภิปรายกล่าวถึงความท้าทายในการจัดการความซับซ้อนของซอฟต์แวร์ โดยเฉพาะอย่างยิ่งในระบบเดิม และการแลกเปลี่ยนระหว่างต้นทุนและคุณภาพ ซึ่งมักนําไปสู่หนี้ทางเทคนิค
- การรักษาวัฒนธรรมทางวิศวกรรมที่แข็งแกร่ง และการแยกความแตกต่างระหว่างความซับซ้อนที่จําเป็นและโดยไม่ได้ตั้งใจเพื่อจัดการซอฟต์แวร์อย่างมีประสิทธิภาพ
- ผู้เข้าร่วมเน้นย้ําถึงความจําเป็นของการบํารุงรักษาอย่างต่อเนื่องผลกระทบของทางเลือกในการพัฒนาที่ไม่ดีและบทบาทของการสนับสนุนการจัดการในการพิสูจน์ความพยายามในการปรับโครงสร้างใหม่

## [จากการเริ่มต้นสู่การขาย: การเดินทางของ Michael Lynch กับ TinyPilot](https://mtlynch.io/i-sold-tinypilot/)

- Michael Lynch สร้าง TinyPilot ในช่วงกลางปี 2020 ซึ่งเป็นอุปกรณ์สําหรับควบคุมเซิร์ฟเวอร์ระยะไกล ซึ่งได้รับความนิยมอย่างรวดเร็วและเติบโตเป็นธุรกิจที่มีรายได้ต่อปี 1 ล้านดอลลาร์และทีมงานเจ็ดคน
- ลินช์ขาย TinyPilot ในราคา 600,000 ดอลลาร์ โดยหักค่าใช้จ่ายได้ 490,803 ดอลลาร์ เนื่องจากความเครียดในการจัดการธุรกิจฮาร์ดแวร์และความปรารถนาที่จะกลับไปเขียนโค้ดและเริ่มต้นครอบครัว
- การขายซึ่งอํานวยความสะดวกโดย Quiet Light Brokerage เกี่ยวข้องกับความท้าทายต่างๆ เช่น การสร้างสมดุลระหว่างความเครียดของผู้ก่อตั้ง ผู้ซื้อคือ Scott ผู้เชี่ยวชาญด้านสื่อองค์กร

### [ปฏิกิริยา](https://news.ycombinator.com/item?id=40512500)

- Michael Lynch ขายธุรกิจ TinyPilot ของเขาและหารือเกี่ยวกับค่าใช้จ่ายที่สําคัญที่เกี่ยวข้องกับการขาย รวมถึงค่าคอมมิชชั่นนายหน้าและค่าธรรมเนียมทางกฎหมาย ซึ่งคิดเป็นประมาณ 18% ของราคาขาย
- เส้นทางการเป็นผู้ประกอบการของ Lynch รวมถึงการเปลี่ยนจากงานที่ได้ค่าตอบแทนสูงที่ Google ไปสู่การให้คุณค่ากับความเป็นอิสระและความคิดสร้างสรรค์โดยเน้นคุณค่าทางการศึกษาของการเป็นผู้ประกอบการและวิพากษ์วิจารณ์การมุ่งเน้นของอุตสาหกรรมเทคโนโลยีที่ค่าตอบแทนทั้งหมด
- ลินช์วางแผนที่จะเริ่มต้นกิจการในอนาคตโดยมุ่งเน้นไปที่ผลิตภัณฑ์เพื่อการศึกษาและซอฟต์แวร์เป็นบริการ (SaaS) หลีกเลี่ยงฮาร์ดแวร์เนื่องจากความซับซ้อนและความท้าทาย

## [อดีตสมาชิกคณะกรรมการ OpenAI เปิดเผยเหตุผลเบื้องหลังการไล่ออกและการคืนสถานะของ Sam Altman](https://www.theverge.com/2024/5/28/24166713/openai-helen-toner-explains-why-sam-altman-was-fired)

- ในเดือนพฤศจิกายน 2023 คณะกรรมการของ OpenAI ได้ไล่ออก CEO Sam Altman โดยไม่คาดคิด โดยอ้างถึง "การโกหกโดยสิ้นเชิง" และพฤติกรรมบงการ ซึ่งกัดกร่อนความไว้วางใจ
- ปัญหาเฉพาะ ได้แก่ การเป็นเจ้าของกองทุน OpenAI Startup Fund ที่ไม่เปิดเผยของ Altman การให้ข้อมูลด้านความปลอดภัยที่ไม่ถูกต้อง และการสร้างสภาพแวดล้อมการทํางานที่เป็นพิษ
- แม้จะมีข้อกล่าวหาเหล่านี้ แต่แรงกดดันภายในและภายนอก รวมถึงการสนับสนุนจากพนักงานและ Microsoft นําไปสู่การคืนสถานะของ Altman โดยการตรวจสอบโดยอิสระไม่พบปัญหาเกี่ยวกับความปลอดภัยของผลิตภัณฑ์หรือการดําเนินงานของบริษัท

### [ปฏิกิริยา](https://news.ycombinator.com/item?id=40509399)

- อดีตสมาชิกคณะกรรมการของ OpenAI เปิดเผยว่า Sam Altman ถูกไล่ออกเนื่องจากความไม่ซื่อสัตย์ ทําให้เกิดคําถามเกี่ยวกับการรับรู้ของคณะกรรมการเกี่ยวกับการเปิดตัว ChatGPT
- สถานการณ์ดังกล่าวได้จุดประกายการอภิปรายเกี่ยวกับความโปร่งใสขององค์กรการกํากับดูแลคณะกรรมการและการกํากับดูแลด้านจริยธรรมโดยมีการเปรียบเทียบกับความล้มเหลวขององค์กรเช่น Enron
- มีความสงสัยเกี่ยวกับแนวทางปฏิบัติด้านความไว้วางใจและความปลอดภัยของ OpenAI ด้วยการลาออกของพนักงานและการวิพากษ์วิจารณ์ความเป็นผู้นําของ Altman ควบคู่ไปกับการอภิปรายเกี่ยวกับความสามารถทางเทคนิคและบทบาทของคณะกรรมการ

## [การรั่วไหลของการค้นหาของ Google เปิดเผยความลับของอัลกอริทึมการจัดอันดับและ 2,596 โมดูล](https://searchengineland.com/google-search-document-leak-ranking-442617)

- การรั่วไหลของเอกสาร Google Search ภายในครั้งใหญ่ได้เปิดเผยแง่มุมที่สําคัญของอัลกอริทึมการจัดอันดับของ Google รวมถึงการใช้การคลิก ลิงก์ เนื้อหา เอนทิตี และข้อมูล Chrome
- ผู้เชี่ยวชาญในอุตสาหกรรม Rand Fishkin และ Michael King วิเคราะห์เอกสารโดยเปิดเผยโมดูลการจัดอันดับ 2,596 โมดูลความสําคัญของความหลากหลายของลิงก์ความเกี่ยวข้องการคลิกที่ประสบความสําเร็จและการจดจําแบรนด์
- เอกสารดังกล่าวยังเปิดเผยการใช้ข้อมูลผู้เขียน อํานาจหน้าที่ของไซต์ และ "ผู้ทวิดเดิล" ของ Google เพื่อปรับการจัดอันดับ โดยให้ข้อมูลเชิงลึกอันมีค่าสําหรับ SEO แม้ว่าจะไม่ทราบน้ําหนักที่แน่นอนของปัจจัยการจัดอันดับก็ตาม

### [ปฏิกิริยา](https://news.ycombinator.com/item?id=40510125)

- เอกสาร Google Search ที่รั่วไหลออกมาได้จุดชนวนให้เกิดการถกเถียงกันเกี่ยวกับอัลกอริทึมการจัดอันดับและอิทธิพลของโปรแกรมโฆษณาของ Google ที่มีต่อผลการค้นหา
- ผู้ใช้กําลังหารือเกี่ยวกับทางเลือกอื่น เช่น Kagi และ search.marginalia.nu โดยมีบทวิจารณ์ที่หลากหลายเกี่ยวกับการปรับแต่งของ Kagi การมุ่งเน้นที่ไม่ใช่เชิงพาณิชย์ และปัญหาเกี่ยวกับสแปมและเนื้อหาที่สร้างโดย AI
- การสนทนาเน้นย้ําถึงความปรารถนาสําหรับเครื่องมือค้นหาที่ให้ความสําคัญกับความชอบของผู้ใช้มากกว่ารายได้จากโฆษณา สัมผัสกับการจัดการ SEO ศักยภาพของโมเดลภาษาขนาดใหญ่ (LLM) และความกังวลเกี่ยวกับความถูกต้องของบทวิจารณ์ออนไลน์และเกณฑ์การจัดอันดับของ Google

## [ChatTTS: โมเดล TTS โอเพ่นซอร์สขั้นสูงสําหรับการสนทนาที่เป็นธรรมชาติในภาษาอังกฤษและภาษาจีน](https://github.com/2noise/ChatTTS)

- ChatTTS เป็นรูปแบบการแปลงข้อความเป็นคําพูด (TTS) ที่ปรับให้เหมาะกับการสนทนา รองรับทั้งภาษาอังกฤษและภาษาจีน และได้รับการฝึกฝนเกี่ยวกับข้อมูลมากกว่า 100,000 ชั่วโมง
- เวอร์ชันโอเพนซอร์สบน HuggingFace ประกอบด้วยโมเดลที่ผ่านการฝึกอบรมล่วงหน้า 40,000 ชั่วโมง ซึ่งยอดเยี่ยมในการสังเคราะห์คําพูดที่เป็นธรรมชาติและแสดงออกด้วยการควบคุมฉันทลักษณ์ที่ละเอียด
- โมเดลนี้มีไว้สําหรับการใช้งานทางวิชาการเท่านั้นโดยมีแผนในอนาคตที่จะเปิดคุณสมบัติเพิ่มเติมและปรับปรุงความเสถียร

### [ปฏิกิริยา](https://news.ycombinator.com/item?id=40507039)

- การอภิปรายเน้นย้ําถึงการพัฒนาและประสิทธิภาพของโมเดล TTS เช่น ChatTTS และ Piper TTS โดยสังเกตปัญหาต่างๆ เช่น การประมวลผลที่ช้าและความท้าทายด้านคุณภาพเสียง
- ผู้ใช้เน้นย้ําถึงความต้องการ TTS คุณภาพสูงในหลายภาษา และอภิปรายถึงประสิทธิภาพของเสียงของมนุษย์เทียบกับเสียงอัตโนมัติในหนังสือเสียง
- มีการวิพากษ์วิจารณ์การอ้างสิทธิ์ "โอเพ่นซอร์ส" ที่ทําให้เข้าใจผิดในโครงการ TTS และการเรียกร้องให้มีรายการโมเดลและข้อมูล TTS แบบโอเพ่นซอร์สที่ครอบคลุมอย่างแท้จริง

## [Google เงียบเกี่ยวกับการรั่วไหลของ 2,500 หน้าที่ถูกกล่าวหาว่ามีรายละเอียดอัลกอริทึมการค้นหา](https://www.theverge.com/2024/5/28/24166177/google-search-ranking-algorithm-leak-documents-link-seo)

- การรั่วไหลของเอกสารภายใน Google 2,500 หน้า ซึ่งแบ่งปันโดย Rand Fishkin ผู้เชี่ยวชาญด้าน SEO อาจเปิดเผยความแตกต่างระหว่างข้อความสาธารณะของ Google กับแนวทางปฏิบัติจริงเกี่ยวกับอัลกอริทึมการค้นหา
- เอกสารดังกล่าวแนะนําให้ใช้ข้อมูล Chrome ในการจัดอันดับและติดตามข้อมูลผู้เขียน ซึ่งท้าทายการยืนยันก่อนหน้านี้ของ Google และจุดประกายการถกเถียงเกี่ยวกับความโปร่งใสของบริษัท
- Google ไม่ได้ให้ความเห็นเกี่ยวกับความถูกต้องของเอกสาร และเหตุการณ์ดังกล่าวเน้นย้ําถึงความกังวลอย่างต่อเนื่องเกี่ยวกับลักษณะที่คลุมเครือของการดําเนินการค้นหาของ Google ท่ามกลางการตรวจสอบการต่อต้านการผูกขาด

### [ปฏิกิริยา](https://news.ycombinator.com/item?id=40505310)

- การรั่วไหลของเอกสารอัลกอริทึมการค้นหาของ Google ได้เปิดเผยความคลาดเคลื่อนที่อาจเกิดขึ้นระหว่างข้อความสาธารณะของ Google และแนวทางปฏิบัติที่แท้จริง
- การรั่วไหลชี้ให้เห็นว่าตัวแทนของ Google อาจทําลายการค้นพบที่ถูกต้องจากชุมชนการตลาดเทคโนโลยีและวารสารศาสตร์ทําให้เกิดความกังวลด้านจริยธรรมเกี่ยวกับการจัดการ SEO
- การอภิปรายทางกฎหมายเกี่ยวกับ GitHub กําลังถกเถียงกันถึงความสําคัญและความถูกต้องตามกฎหมายของการรั่วไหล โดยมีความคิดเห็นที่แตกต่างกันเกี่ยวกับผลกระทบต่อสถานะความลับทางการค้าและการคุ้มครองลิขสิทธิ์

<head>
  <meta property="og:title" content="หูฟัง AI แยกลําโพงตัวเดียวในฝูงชนโดยการตรวจจับการจ้องมอง" />
  <meta property="og:type" content="website" />
  <meta property="og:image" content="https://og.cho.sh/api/og/?title=%E0%B8%AB%E0%B8%B9%E0%B8%9F%E0%B8%B1%E0%B8%87%20AI%20%E0%B9%81%E0%B8%A2%E0%B8%81%E0%B8%A5%E0%B9%8D%E0%B8%B2%E0%B9%82%E0%B8%9E%E0%B8%87%E0%B8%95%E0%B8%B1%E0%B8%A7%E0%B9%80%E0%B8%94%E0%B8%B5%E0%B8%A2%E0%B8%A7%E0%B9%83%E0%B8%99%E0%B8%9D%E0%B8%B9%E0%B8%87%E0%B8%8A%E0%B8%99%E0%B9%82%E0%B8%94%E0%B8%A2%E0%B8%81%E0%B8%B2%E0%B8%A3%E0%B8%95%E0%B8%A3%E0%B8%A7%E0%B8%88%E0%B8%88%E0%B8%B1%E0%B8%9A%E0%B8%81%E0%B8%B2%E0%B8%A3%E0%B8%88%E0%B9%89%E0%B8%AD%E0%B8%87%E0%B8%A1%E0%B8%AD%E0%B8%87&subheading=%E0%B8%A7%E0%B8%B1%E0%B8%99%E0%B8%9E%E0%B8%B8%E0%B8%98%E0%B8%97%E0%B8%B5%E0%B9%88%2029%20%E0%B8%9E%E0%B8%A4%E0%B8%A9%E0%B8%A0%E0%B8%B2%E0%B8%84%E0%B8%A1%202567%3A%20%E0%B8%AA%E0%B8%A3%E0%B8%B8%E0%B8%9B%E0%B8%82%E0%B9%88%E0%B8%B2%E0%B8%A7%E0%B9%81%E0%B8%AE%E0%B9%87%E0%B8%81%E0%B9%80%E0%B8%81%E0%B8%AD%E0%B8%A3%E0%B9%8C" />
</head>
